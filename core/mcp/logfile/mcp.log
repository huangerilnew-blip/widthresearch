2026-02-03 13:08:19,284 - __main__ - INFO - handle_download: searcher=WikipediaSearcher, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 13:08:19,285 - __main__ - INFO - handle_download: downloaded=3
2026-02-03 13:08:19,285 - __main__ - INFO - call_tool payload: source_tool=wikipedia_download, result_type=papers, count=3
2026-02-03 13:08:19,285 - __main__ - INFO - call_tool: name=wikipedia_download, result_type=papers, count=3
2026-02-03 13:08:19,286 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-03T13:07:41.662993', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-03 13:07:41', 'language': 'zh', 'saved_path': '/home/qinshan/widthresearch/data/downloads/wiki_1394764.md'}}
2026-02-03 13:08:19,290 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的80年进化编年史：从想象到现实', 'authors': [], 'abstract': '人工智能的80年进化编年史：从想象到现实\\_腾讯新闻\n# 人工智能的80年进化编年史：从想象到现实\n![头像]![] \n[\nWeb3天空之城\n] \n2023-03-01 20:44发布于浙江科技领域创作者\nAGI是Artificial General Intelligence的缩写，即通用人工智能。\nAGI的目标是实现人类般的通用智能，这意味着AI可以像人类一样理解任意通用任务, 并以人类的智力水平执行完成。基本上, 除了&quot;自我意识&quot;的生成，AGI就是人类对人工智能的终极梦想了。\n无论是近一年来火爆的AI绘画，还是当红炸子鸡ChatGPT，AI研究应用的终极目标, 都是向着AGI通用人工智能的大一统目标在迈进。\n读者是否有同感,\xa0这几年各种AI大模型的发展和突破, 着实有让人眼花缭乱之感?\n本文主要把现代到当下一些AI的重要节点做了时间线梳理和简单分析，或有助于大家来理清楚这些年AI发展的关键脉络。\n1942年\n时间回到80年前, 科幻泰斗阿西莫夫提出了著名的&quot;机器人三定律”：\n机器人不得伤害人类，或坐视人类受到伤害；除非违背第一定律，否则机器人必须服从人类命令；除非违背第一或第二定律，否则机器人必须保护自己。这三个定律是人工智能和机器人技术的哲学基础，是对如何设计人工智能系统的基本原则的阐述，至今都有着重要的参考意义。1950年\n计算机科学之父艾伦·图灵（Alan Turing）发表了具有里程碑意义的论文《Computing Machinery and Intelligence（计算机器与智能）》。论文预言了创造出具有真正智能的机器的可能性，第一次提出图灵测试（The Turing test）的概念：\n如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。1956年\nAI概念诞生。\n美国的达特茅斯学院举行了一次具有传奇色彩的学术会议（Dartmouth Conference）， 探讨用机器模拟人类智能的问题。计算机专家约翰·麦卡锡提出了AI&quot;人工智能”一词。这被广泛认为是人工智能正式诞生的日子。参与会议的学者们是最早的AI研究先驱。\n从1956年到现代，这几十年来AI研究的起伏，有兴趣的读者可以参考本号另一篇文章从爆火的chatGPT讲起: 自然语言生成式AI的前世今生, 你想了解的一切&gt;\n当今大众关于AI的记忆，或许是从1997年开始的：\n1997年\n5月11日, IBM公司的电脑&quot;深蓝”战胜了国际象棋世界冠军卡斯帕罗夫，成为首个击败国际象棋世界冠军的AI系统。\n1998年\n现代卷积神经网络CNN诞生。\n1980年，日本学者福岛邦彦（Kunihiko Fukushima）模仿生物的视觉皮层（visual cortex），设计了人工神经网络&quot;neocognitron”，这是现代卷积神经网络的雏形。\n经过多年前赴后继的研究，1998年杨立昆（Yann LeCun，现任Meta首席人工智能科学家）基于前人基础，构建了更加完备的卷积神经网络LeNet-5，在手写数字的识别问题中取得了成功。LeNet-5被认为是现代卷积神经网络的基本结构。\n卷积神经网络CNN是当今&quot;深度学习&quot;AI模型的计算基础架构。一直到2017年Transformer架构横空出世后，CNN才被取代。\n2003年\nYoshua Bengio在2003年发表了《A Neural Probabilistic Language Model》，这是第一篇基于人工神经网络打造自然语言模型的论文，提出了具有奠基意义的NNLM&quot;神经网络语言模型&quot;。它在得到语言模型的同时也产生了副产品&quot;词向量&quot;。\n2006年\n杰弗里·辛顿（Geoffrey Hinton）在science期刊上发表了重要的论文《Reducing the dimensionality of data with neural networks》，提出深度信念网络（Deep Belief Networks，DBNs），&quot;深度学习&quot;正式诞生。\n2009年\n李飞飞主导的Image Net正式发布，有超过1000万数据，两万多个类别。为全世界的AI学者提供了开放的标注图像大数据集。\n2010年开始，Image Net大规模视觉识别挑战赛（ILSVCR）开始举办，全世界图像领域深度学习的专家们同台竞技和交流，从此拉开了计算机视觉的新篇章。\n2012年\nGoogle的吴恩达和Jef Dean使用1.6万个CPU（那时的GPU生态还在婴幼儿阶段）训练了一个当时世界上最大的人工神经网络，用来教AI绘制猫脸图片。训练数据是来自youtube的1000万个猫脸图片，1.6万个CPU整整训练了3天。\n对于计算机AI领域，这是一次具有突破性意义的尝试。AI第一次&quot;生成&quot;了一个图像内容：一张模糊的猫脸\n![图片] \n2013年\nGoogle的托马斯·米科洛夫（Tomas Mikolov）带领研究团队发表了论文《Efficient Estimation of Word Representations inVector Space》，提出了Word2Vec。\nWord2Vec可以根据给定的语料库，通过优化后的训练模型可以快速有效地将一个词语表达成高维空间里的词向量形式，为自然语言处理领域的应用研究提供了新的工具。\n2014年1月\n谷歌斥资400亿美元收购了位于伦敦的明星人工智能企业DeepMind。\n2014年12月\nGAN（对抗式生成网络）诞生。\n2014 年，Lan Goodfellow从博弈论中的&quot;二人零和博弈&quot;得到启发 ，创造性的提出了生成对抗网络（GAN，Generative Adversarial Networks），他在2014年的NIPS会议上首次发表了相关论文，用两个神经网络即生成器（Generator）和判别器（Discriminator）进行对抗。在两个神经网络的对抗和自我迭代中，GAN会逐渐演化出强大的能力。\n作者在最早的文章里形象的把GAN比喻为伪造者和警察：伪造者总想造出以假乱真的钞票，而警察则努力用更先进的技术去鉴别真伪。在博弈过程中，双方都不断提升了自己的技术水平。\nGAN号称21世纪最强大的算法模型之一，&quot;Gan之父&quot;Ian Goodfellow也一跃成为AI领域的顶级专家。\n2015年12月\nOpenAI公司于美国旧金山成立。\nOpenAI诞生的原因是很有趣的：DeepMind被Google收购的消息震动了硅谷，如果发展下去，DeepMind很有可能成为最早实现AGI通用人工智能的公司。为了打破GoogleAI技术的垄断，在一次私人聚会后，大佬们一拍即合成立了OpenAI。\n其中包括，钢铁侠Elon Musk，当时已是著名创业孵化器 Y Combinator 的负责人现在成为OpenAI CEO的Sam Altman，以及著名天使投资人 Peter Thiel等硅谷大佬。\nOpenAI作为一个非营利性组织运营，并立志要做DeepMind和Google无法做到的事情：开放和共享AI技术。\n从今天的眼光看，尽管OpenAI后来的商业模式有所变化，但绝对实现了它诞生的最大愿景之一：狙击Google和DeepMind。\nChatGPT的推出加上微软Bing的推波助澜搞得Google实在是狼狈不堪。\n2015年\n11月， Google开源了重要的深度学习框架Tensor Flow；\n同年，还是Google，开源了用来分类和整理图像的 AI 程序Inceptionism，并命名为 DeepDream。尽管还很初级，但DeepDream被认为是第一个现代的AI绘画应用。\n2016年\n3月，Google的AlphaGo战胜围棋世界冠军李世石;\n4月，Google深度学习框架TensorFlow发布分布式版本;\n9月，Google上线基于深度学习的机器翻译;\n2015到2016年，Google的AI能力可谓是风头一时无两。\n2017年1月\nFacebook人工智能研究院（FAIR）开源了PyTorch。PyTorch和tensorFlow从此成为了当今两大主流深度学习框架。\n2017年7月\nFacebook联合罗格斯大学和查尔斯顿学院艺术史系三方合作得到新AI绘画模型，号称创造性对抗网络（CAN，Creative Adversarial Networks），\nCAN在测试中，有53%的观众认为AI作品出自人类之手，这是类似的图灵测试历史上首次突破半数，这是AI绘画模型小小而扎实的一步。\nFacebook在AI领域其实耕耘了很久，做过很多贡献，可惜后面搞Metaverse连公司名字都改成Meta了， 差点错过了当下这波AI的浪潮。\n不过最近小札醒悟过来，终于官宣要All in AI。Meta还是很有实力的，奋起直追应为时未晚。\n2017年12月\n颠覆性的Tranformer架构出世了!\nGoogl机器翻译团队在年底的顶级会议NIPS上发表了里程碑式的论文《Attention is all you need》，提出只使用自注意力（Self Attention）机制来训练自然语言模型，并给这种架构起了个霸气的名字：Transformer。\n所谓&quot;自我注意力&quot;机制，简单说就是只关心输入信息之间的关系，而不再关注输入和对应输出的关系。和之前大模型训练需要匹配的输入输出标注数据相比，这是一个革命性的变化。\nTransformer彻底抛弃了传统的CNN和RNN等神经网络结构。在这篇论文发布之前，主流AI模型都基于CNN卷积神经网络和RNN循环神经网络（recurrent neural network）; 而之后，便是Transformer一统天下。\nTransformer架构的详细描述不在本文范围，读者只需要知道它具有两点无敌的优势：\n自我注意力机制，让模型训练只需使用未经标注的原始数据，而无需再进行昂贵的的人工标注（标注输入和对应输出）。并行效率是之前的AI模型结构被一直诟病的地方。抛弃了传统CNN/RNN架构后，基于Transformer架构的大模型训练可以实现高度并行化，这大大提高了模型训练的效率;\n从此，大模型大数据大算力，大力出奇迹，成为了AI领域的标配。\n感慨一下，Google首先发明了划时代的Transformer架构，但在5年后的今天，却被OpenAI打得喘不过气。这是命运的偶然吗？\n2018年6月\nOpenAI发布了第一版的GPT（Generative Pre-training Transformers）系列模型 GPT-1。\n同时，OpenAI发表了论文《Improving Language Understanding by Generative Pre-training》\n从论文里可以了解到，GPT-1具有1.17个参数，采用了12层的Transformer 解码器结构，使用5GB的无标注文本数据，在8个GPU上训练了一个月，然后再进行人工监督的微调。\n不过，GPT-1并不是当年的明星，因为同年，Google的BERT大模型也发布了（当时的Google就是强啊）。\n2018年10月\n谷歌发布3亿参数的BERT（Bidirectional Encoder Representation from Transformers），意思即&quot;来自Transformers的双向编码表示”模型。\nGPT和BERT的诞生意味着预训练大模型（Pre-trained Models）成为了自然语言处理领域的主流。\n和GPT相比，BERT最大的区别就是使用文本的上下文来训练模型，而专注于&quot;文本生成&quot;的GPT-1，使用的是上文。\n基于&quot;双向编码&quot;的能力让BERT的性能在当时明显优异于第一代的GPT-1。\n幸好，Open AI 并没有那么容易放弃，一直坚持只用上文训练的&quot;单向编码&quot;纯生成模式。直到GPT-3，神功初成。\n2018年底\n在共同创立公司三年后，钢铁侠马斯克辞去了Open AI董事会职务，原因是&quot;为了消除潜在的未来冲突&quot;。\n实际情况是，2017年6月，马斯克挖走了OpenAI的核心人员Andrej Karpathy，担任Tesla的AI部门主管并直接向自己汇报，负责构建特斯拉的自动驾驶系统。\n所以，确实是存在人才竞争&quot;潜在冲突&quot;的。\n有趣的是，根据前不久的最新消息，ChatGPT大火之后，Andrej Karpathy同学又离开了Tesla回到了OpenAI。这是所谓&quot;鸟择良木而栖&quot;：）\n而马斯克放出了声音，要打造OpenAI的竞争者。不知首富同学是否遗憾当年不得不放走了OpenAI。\n2019年2月\nOpenAI发布了GPT-2。\nGPT-2有48层Transformer结构，使用40GB文本数据训练，参数量突破到了15亿。\n在同时发布的论文《Language Models are Unsupervised Multitask Learners》 中，OpenAI描述了GPT2在经过大量无标注数据生成式训练后，展示出来的零样本（zero-shot）多任务能力。\n所谓零样本学习就是用很大的通用语料去训练模型，然后不再需要做特定任务的训练，大模型就可以直接完成一些具体任务。一个典型例子是翻译。GPT-2具备了良好的语言翻译能力; 而有趣的是，专门做翻译的模型通常使用标注好的语料（即两个不同语言的匹配数据）来训练。但GPT-2并没有使用这类数据，翻译效果还超过了很多专职翻译的小模型。\nGPT-2揭示了一个有趣的现象，仅作为生成式任务来训练打造的大模型，开始具备了多种通用任务能力，比如GPT-2所具备的阅读理解和翻译等等。\n2019年3-7月\n3月份，OpenAI正式宣布重组，成为一家&quot;利润上限（caped-profit）&quot;的公司，规定了投资收益的上限。这是一个很特别的架构。\n而近期披露的OpenAI最新投资架构也再次揭示了这个公司股权结构的与众不同。简单的说，OpenAI把自己租借给了微软，赚到1500亿美金后，将重新变为非营利性组织 -- 至少说是这么说的。5月，Sam Altman辞去了 YC总裁的工作，开始担任新 OpenAI 的CEO。\n7月，重组后的OpenAI拿到了微软包括Azure云计算资源在内的10亿美金投资， 微软将作为&quot;首选合作伙伴”，今后可获得OpenAI 技术成果的独家授权。自此，OpenAI后续技术成果不再承诺开源。\n2020年5月\nOpenAI发布了GPT-3。\nGPT-3的初始版本在内部代号为&quot;davinci&quot;，使用45TB文本数据训练，有1750亿参数。根据公开信息，模型的训练费用是1200万美金。因为太贵，只训练了一次。\n随后，OpenAI发表了近70页的论文《Language Models are Few-Shot Learner》。这篇论文阐述了大模型的各种新能力，而最重要的就是标题所指出的小样本（few-shot）学习能力。\n&quot;few-shot&quot;是一个专业术语，理解起来也简单，就是通过少量的几个例子就能学习一个新的任务。人们发现，GPT-3开始具有类似人类的能力，只要在提示里展示特定任务的几个示例，GPT-3就能完成新示例的输出。而无需进行针对性的额外微调训练。这也被称之为&quot;上下文学习&quot;（in context learning）\n2020年6月\n对AI绘画有重要意义的论文 《Denoising Diffusion Probabilistic Models》发表， 引入了DDPM模型。 作为领域的奠基之作，这篇论文第一次把2015年诞生的Diffusion&quot;扩散模型&quot;用在了图像生成上。\n用扩散模型生成图像的过程，简单理解，就是我们熟知的图片&quot;降噪&quot;：把一幅全部是噪点的随机图像通过AI算法反复&quot;降噪&quot;到最清晰，一个图像便生成了。\nDDPM的出现把Diffusion扩散模型带到了一个新的高度。在不久之后，DDPM以及后续的Diffusion扩散模型就全面取代了GAN（生成式对抗网络），成为了AI绘画大模型当仁不让的主流技术。\n2020年12月\n由于不再认同转型后的公司文化和战略，OpenAI的部分核心团队出走。\n12月31日，OpenAI发布新闻稿，宣布其研究副总裁Dario Amodei在OpenAI工作了近五年后离开了OpenAI。\nOpenAI正是5年前成立的，这位研究副总看来是妥妥的创始核心。\nDario Amodei带着一些OpenAI的早期核心员工随后创办了Anthropic，推出了ChatGPT的直接竞品Claude。\n被ChatGPT逼急了的Google最近刚给Anthropic紧急投资了3亿美金，以获得其10%的股份，并绑定了其云计算提供商的身份。\n这里说个小知识，加州没有竞业协议，真的是创业者的天堂!\n2021年1月\n1月11日，Google发表论文《Switch Transformers：Scaling to Trillion Parameter Models with Simple and Efficient Sparsity》，提出了最新语言模型—Switch Transformer。\n这个Switch Transformer 模型以高达1.6 万亿的参数量打破了GPT-3 作为最大AI 模型的统治地位，成为史上首个万亿级语言模型。然而，时间会证明一切。2年后的今天，这个万亿参数的Switch大模型在当下似乎没产生任何水花，而千亿参数级别的GPT-3.5系列依然风生水起。这是不是说明一个问题：突破千亿阈值后，参数多少并不代表一切。\n2021年2月\nOpen AI开源了新的深度学习模型 CLIP（Contrastive Language-Image Pre-Training）。\nCLIP是一个多模态模型，用来判断文字和图像两个不同&quot;模态&quot;信息的关联匹配程度。\n在CLIP之前，也有人尝试过这个方向，但OpenAI最大的创意是直接使用全互联网上已经标记过的图像数据，巧妙的避免了海量数据标注的昂贵费用。最后以接近40亿的互联网&quot;文本-图像&quot;训练数据打造了CLIP。\n这次重要的开源直接推动了各大AI绘画模型的迅猛发展。CLIP的多模态能力正是各AI绘画大模型从文字到画面想象力的核心基础。\n同时，OpenAI还发布了自己基于CLIP的 AI绘画DALL-E 模型。这或许是大众听说的第一个&quot;文本生成图像&quot;的AI绘画模型了。\n从CLIP到DALL-E，显然OpenAI走在了AI绘画大模型潮流的最前端。\n只是，OpenAI在AI绘画模型的商业决策上出现了失误：因为没有开放使用DALL-E以及后续DALL-E2，而又开源了关键的CLIP模型，导致目前AI绘画模型的光芒完全被其开源继承者Stable Diffusion，还有付费的Midjourney服务掩盖了。\n正是在AI绘画模型上有苦说不出的经历，直接影响了后来OpenAI管理层的决策：决定在第一时间面向公众抢先推出 ChatGPT聊天机器人。\n2021年4月\n华为的盘古NLP大模型发布，号称是中国第一个千亿参数语言大模型。\n2021年6月\n6 月30 日，OpenAI 和GitHub 联合发布了AI 代码补全工具GitHub Copilot，这个工具可以在 VS Code 编辑器中自动完成代码片段，也是OpenAI 拿了微软10 亿美元之后的第一个重大成果。而Copilot 的AI技术核心正是OpenAI的新模型CodeX。这个模型在随后的8月份也对外发布了。\n根据相关论文《Evaluating Large Language Models Trained on Code》，OpenAI基于GPT-3，使用大量公开代码数据训练出了Codex模型。\nCodex拥有120亿参数，使用了159G代码数据进行训练，模型可以将自然语言描述转换为代码。而效果吗，看看码农们对Copilot的赞不绝口就知道了。\nAI生成代码的时代终于到来了。\n据称，Codex的训练数据来自于公共数据源的数十亿行源代码，而其中最重要的来源，无疑正是微软所买下的GitHub 这个世界上最大的开源代码平台。使用GitHub代码训练模型这个事情还引起了一些程序员关于代码版权的热烈讨论。\n不过，正如画师们对砸了自己饭碗的AI绘画大模型怨声载道而然并卵。。。能力突破的AI对人类初级技能的全面覆盖，恐怕是一个不得不接受的事实。\n从商业角度上看，CodeX的诞生和Copilot的成功证明了OpenAI和微软的商业合作确实是一个双赢。\n2021年10月\n第一个开源的AI绘画大模型Disco-Diffusion诞生!\n发布在Github上的Disco-Diffusion是整个2022年AI绘画旋风的起点。从Disco-Diffusion开始，AI绘画大模型突飞猛进的发展让所有人目不暇接，揭开了AI的新时代。\n2021年12月\n百度第三代文心语言大模型，2600亿参数的ERNIE3.0 Titan发布。\n百度文心和华为盘古都是GPT-3量级的模型，关于国产大模型的具体判断，读者有兴趣可以参考本号国产ChatGPT们的真相&gt;一文\n2022 年3 月OpenAI发布InstructGPT， 同时发表论文《Training language models to follow instructions with human feedback》。\n根据论文，InstructGPT基于GPT-3模型做了进一步微调，并且在模型训练中加入了人类的反馈评价数据。\n这里出现的RLHF &quot;从人类反馈中强化学习&quot;，正是后面ChatGPT所依赖的一个关键技术。\n2022年4月\nOpenAI发布了AI绘画大模型DALL-E 2。\n同一时间，面向公众的付费AI绘画服务Midjourney也发布了。\n和开局王炸，第一年就赚取了大把真金白银的MidJourney相比，使用受限的DALL-E 2并没有在大众人群里产生多少影响力。\n如之前所说，OpenAI在绘画大模型的开放上过于保守了，也许还有优先和微软技术合作的考量在内...\n总之，非常遗憾，绘画模型的风头完全被付费的Midjourney和随后的Stable diffusion抢走。\n2022年5月\nOpenAI发布代号为text-davinci-002的新版大模型，GPT系列正式迈入3.5时代。\n有趣的是，按照OpenAI官方文档说法：\nis a base model，so good for pure code-completion tasks\nis an InstructGPT model based on\n就是说，代号为code的002号模型是3.5系列的基础模型，而代号为text的002号模型是基于code 002模型用指令微调技术得到的 （insturctGPT）\n如果，OpenAI没有在模型名字上混淆视听，一个有趣而合理的推断是：GPT-3.5系列的基础核心模型首先是依赖于代码（Code）大数据训练，而不是普通文本（Text）训练的\n如果这个推断差不太多，那么众多ChatGPT的追随者们，如希望自家能力真正比肩基于GPT-3.5的ChatGPT， 那必须要补的一课，就是代码数据的训练了。2022年6月\n6月15日，谷歌研究院联合DeepMind和斯坦福大学等在arxiv上发表了一篇论文：《Emergent Abilities of Large Language', 'doi': '', 'published_date': '2023-03-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://view.inews.qq.com/a/20230301A08BTW00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '万字长文解读AI发展史，看人工智能将如何改变下个时代_腾讯新闻', 'authors': [], 'abstract': '万字长文解读AI发展史，看人工智能将如何改变下个时代\\_腾讯新闻\n# 万字长文解读AI发展史，看人工智能将如何改变下个时代\n![头像]![] \n[\nINDIGO的数字镜像\n] \n2022-11-15 09:06发布于中国香港科技领域创作者\n就在过去几个月里，因为美联储的加息，科技公司的资本狂欢宣告结束，美国上市的SaaS 公司股价基本都跌去了70%，裁员与紧缩是必要选项。但正当市场一片哀嚎的时候，Dall-E 2 发布了，紧接着就是一大批炫酷的AI 公司登场。这些事件在风投界引发了一股风潮，我们看到那些兜售着基于生成式AI（Generative AI）产品的公司，估值达到了数十亿美元，虽然收入还不到百万美元，也没有经过验证的商业模式。不久前，同样的故事在 Web 3 上也发生过！感觉我们又将进入一个全新的繁荣时代，但人工智能这次真的能带动科技产业复苏么？划重点本文将带你领略一次人工智能领域波澜壮阔的发展史，从关键人物推动的学术进展、算法和理念的涌现、公司和产品的进步、还有脑科学对神经网络的迭代影响，这四个维度来深刻理解“机器之心的进化”。先忘掉那些花里胡哨的图片生产应用，我们一起来学点接近AI 本质的东西。文章较长，累计22800 字，请留出一小时左右的阅读时间，欢迎先收藏再阅读！文中每一个链接和引用都是有价值的，特别作为衍生阅读推荐给大家。阅读之前先插播一段Elon Musk 和Jack Ma 在WAIC 2019 关于人工智能的对谈的经典老视频，全程注意Elon Ma 的表情大家觉得机器智能能否超过人类么？带着这个问题来阅读，相信看完就会有系统性的答案！本文在无特别指明的情况下，为了书写简洁，在同一个段落中重复词汇大量出现时，会用AI（Artifical Intelligence）来代表 人工智能，用ML（Machine Learning）来代表机器学习，DL（Deep Learning）来代表深度学习，以及各种英文缩写来优先表达。\n01\nAI 进化史对于机器是否真能&quot;知道&quot;、&quot;思考 &quot;等问题，我们很难严谨地定义这些。我们对人类心理过程的理解，或许只比鱼对游泳的理解更好一点。\n- John McCarthy\n早在1945 年，Alan Turing 就已经在考虑如何用计算机来模拟人脑了。他设计了ACE（Automatic Computing Engine - 自动计算引擎）来模拟大脑工作。在给一位同事的信中写道：&quot;与计算的实际应用相比，我对制作大脑运作的模型可能更感兴趣 ...... 尽管大脑运作机制是通过轴突和树突的生长来计算的复杂神经元回路，但我们还是可以在ACE 中制作一个模型，允许这种可能性的存在，ACE 的实际构造并没有改变，它只是记住了数据......&quot; 这就是机器智能的起源，至少那时在英国都这样定义。1.1 前神经网络时代神经网络是以模仿人脑中的神经元的运作为模型的计算机系统。AI 是伴随着神经网络的发展而出现的。1956年，美国心理学家 Frank Rosenblatt 实现了一个早期的神经网络演示- 感知器模型（Perceptron Model），该网络通过监督 Learning的方法将简单的图像分类，如三角形和正方形。这是一台只有八个模拟神经元的计算机，这些神经元由马达和转盘制成，与 400 个光探测器连接。![图片] 配图01：Frank Rosenblatt &amp; Perceptron Model\nIBM 的Georgetown 实验室在这些研究的基础上，实现了最早的机器语言翻译系统，可以在英语和俄语之间互译。1956年的夏天，在 Dartmouth College 的一次会议上，AI被定义为计算机科学的一个研究领域，Marvin Minsky（明斯基）, John McCarthy（麦卡锡）, Claude Shannon（香农）, 还有Nathaniel Rochester（罗切斯特）组织了这次会议，他们后来被称为 AI 的&quot;奠基人&quot;。\n![图片] 配图02：Participants of the 1956 Dartmouth Summer Research Project on AI\nDARPA 在这个“黄金”时期，将大部分资金投入AI 领域，就在十年后他们还发明了ARPANET（互联网的前身）。早期的 AI 先驱们试图教计算机做模仿人类的复杂心理任务，他们将其分成五个子领域：推理、知识表述、规划、自然语言处理（NLP）和感知，这些听起来很笼统的术语一直沿用至今。\n从专家系统到机器学习1966年，Marvin Minsky 和Seymour Papert 在《感知器：计算几何学导论》一书中阐述了因为硬件的限制，只有几层的神经网络仅能执行最基本的计算，一下子浇灭了这条路线上研发的热情，AI 领域迎来了第一次泡沫破灭。这些先驱们怎么也没想到，计算机的速度能够在随后的几十年里指数级增长，提升了上亿倍。在上世纪八十年代，随着电脑性能的提升，新计算机语言Prolog &amp; Lisp 的流行，可以用复杂的程序结构，例如条件循环来实现逻辑，这时的人工智能就是专家系统（Expert System），iRobot 公司绝对是那个时代明星；但短暂的繁荣之后，硬件存储空间的限制，还有专家系统无法解决具体的、难以计算的逻辑问题，人工智能再一次陷入窘境。我怀疑任何非常类似于形式逻辑的东西能否成为人类推理的良好模型。- Marvin Minsky\n直到IBM 深蓝在1997年战胜了国际象棋冠军卡斯帕罗夫后，新的基于概率推论（Probabilistic Reasoning）思路开始被广泛应用在 AI 领域，随后IBM Watson 的项目使用这种方法在电视游戏节目《Jeopardy》中经常击败参赛的人类。\n概率推论就是典型的机器学习（Machine Learning）。今天的大多数 AI 系统都是由ML 驱动的，其中预测模型是根据历史数据训练的，并用于对未来的预测。这是AI 领域的第一次范式转变，算法不指定如何解决一个任务，而是根据数据来诱导它，动态地达成目标。因为有了ML，才有了大数据（Big Data）这个概念。\n1.2 Machine Learning 的跃迁Machine Learning 算法一般通过分析数据和推断模型来建立参数，或者通过与环境互动，获得反馈来学习。人类可以注释这些数据，也可以不注释，环境可以是模拟的，也可以是真实世界。Deep Learning\nDeep Learning 是一种Machine Learning算法，它使用多层神经网络和反向传播（Backpropagation）技术来训练神经网络。该领域是几乎是由 Geoffrey Hinton 开创的，早在1986年，Hinton 与他的同事一起发表了关于深度神经网络（DNNs - Deep Neural Networks）的开创性论文，这篇文章引入了反向传播的概念，这是一种调整权重的算法，每当你改变权重时，神经网络就会比以前更快接近正确的输出，可以轻松的实现多层的神经网络，突破了 1966 年Minsky 写的感知器局限的魔咒。![图片] 配图03：Geoffrey Hinton &amp; Deep Neural Networks\nDeep Learning 在2012 年才真正兴起，当时Hinton 和他在多伦多的两个学生表明，使用反向传播训练的深度神经网络在图像识别方面击败了最先进的系统，几乎将以前的错误率减半。由于他的工作和对该领域的贡献，Hinton 的名字几乎成为Deep Learning 的代名词。数据是新的石油Deep Learning 是一个革命性的领域，但为了让它按预期工作，需要数据。而最重要的数据集之一，就是由李飞飞创建的ImageNet。曾任斯坦福大学人工智能实验室主任，同时也是谷歌云 AI/ML 首席科学家的李飞飞，早在2009 年就看出数据对Machine Learning 算法的发展至关重要，同年在计算机视觉和模式识别（CVPR）上发表了相关论文。\n![图片] 配图04：FeiFei Li &amp; ImageNet\n该数据集对研究人员非常有用，正因为如此，它变得越来越有名，为最重要的年度DL 竞赛提供了基准。仅仅七年时间，ImageNet 让获胜算法对图像中的物体进行分类的准确率从72% 提高到了98%，超过了人类的平均能力。\nImageNet 成为DL 革命的首选数据集，更确切地说，是由Hinton 领导的AlexNet 卷积神经网络（CNN - Convolution Neural Networks）的数据集。ImageNet 不仅引领了DL 的革命，也为其他数据集开创了先例。自其创建以来，数十种新的数据集被引入，数据更丰富，分类更精确。神经网络大爆发在Deep Learning 理论和数据集的加持下，2012年以来深度神经网络算法开始大爆发，卷积神经网络（CNN）、递归神经网络（RNN - Recurrent Neural Network）和长短期记忆网络（LSTM - Long Short-Term Memory）等等，每一种都有不同的特性。例如，递归神经网络是较高层的神经元直接连接到较低层的神经元。\n来自日本的计算机研究员福岛邦彦（Kunihiko Fukushima）根据人脑中视觉的运作方式，创建了一个人工神经网络模型。该架构是基于人脑中两种类型的神经元细胞，称为简单细胞和复杂细胞。它们存在于初级视觉皮层中，是大脑中处理视觉信息的部分。简单细胞负责检测局部特征，如边缘；复杂细胞汇集了简单细胞在一个区域内产生的结果。例如，一个简单细胞可能检测到一个椅子的边缘，复杂细胞汇总信息产生结果，通知下一个更高层次的简单细胞，这样逐级识别得到完整结果。\n![图片] 配图05：深度神经网络如何识别物体（TensorFlow）\nCNN 的结构是基于这两类细胞的级联模型，主要用于模式识别任务。它在计算上比大多数其他架构更有效、更快速，在许多应用中，包括自然语言处理和图像识别，已经被用来击败大多数其他算法。我们每次对大脑的工作机制的认知多一点，神经网络的算法和模型也会前进一步！1.3 开启潘多拉的魔盒从2012 到现在，深度神经网络的使用呈爆炸式增长，进展惊人。现在Machine Learning 领域的大部分研究都集中在Deep Learning 方面，就像进入了潘多拉的魔盒被开启了的时代。![图片] 配图06：AI 进化史GAN\n生成对抗网络（GAN - Generative Adversarial Network） 是Deep Learning 领域里面另一个重要的里程碑，诞生于2014 年，它可以帮助神经网络用更少的数据进行学习，生成更多的合成图像，然后用来识别和创建更好的神经网络。GANs 的创造者Ian Goodfellow 是在蒙特利尔的一个酒吧里想出这个主意的，它由两个神经网络玩着猫捉老鼠的游戏，一个创造出看起来像真实图像的假图像，而另一个则决定它们是否是真的。![图片] 配图07：GANs 模拟生产人像的进化GANs 将有助于创建图像，还可以创建现实世界的软件模拟，Nvidia 就大量采用这种技术来增强他的现实模拟系统，开发人员可以在那里训练和测试其他类型的软件。你可以用一个神经网络来“压缩”图像，另一个神经网络来生成原始视频或图像，而不是直接压缩数据，Demis Hassabis 在他的一篇论文中就提到了人类大脑“海马体”的记忆回放也是类似的机制。大规模神经网络大脑的工作方式肯定不是靠某人用规则来编程。- Geoffrey Hinton\n大规模神经网络的竞赛从成立于2011 年的Google Brain 开始，现在属于Google Research。他们推动了 TensorFlow 语言的开发，提出了万能模型Transformer 的技术方案并在其基础上开发了BERT，我们在第四章中将详细讨论这些。\nDeepMind 是这个时代的传奇之一，在2014年被 Google 以5.25 亿美元收购的。它专注游戏算法，其使命是&quot;解决智能问题&quot;，然后用这种智能来 &quot;解决其他一切问题&quot;！DeepMind 的团队开发了一种新的算法Deep Q-Network (DQN)，它可以从经验中学习。2015 年10 月AlphaGo 项目首次在围棋中击败人类冠军李世石；之后的AlphaGo Zero 用新的可以自我博弈的改进算法让人类在围棋领域再也无法翻盘。另一个传奇OpenAI，它是一个由Elon Musk, Sam Altman, Peter Thiel, 还有Reid Hoffman 在2015年共同出资十亿美金创立的科研机构，其主要的竞争对手就是 DeepMind。OpenAI 的使命是通用人工智能（AGI –Artificial General Intelligence），即一种高度自主且在大多数具有经济价值的工作上超越人类的系统。2020年推出的 GPT-3 是目前最好的自然语言生成工具（NLP - Natural Language Processing）之一，通过它的 API 可以实现自然语言同步翻译、对话、撰写文案，甚至是代码（Codex），以及现在最流行的生成图像（DALL·E）。\nGartner AI HypeCycle\nGartner 的技术炒作周期（HypeCycle）很值得一看，这是他们 2022 年最新的关于AI 领域下各个技术发展的成熟度预估，可以快速了解AI 进化史这一章中不同技术的发展阶段。![图片] 配图08：Gartner AI HypeCycle 2022\n神经网络，这个在上世纪60 年代碰到的挫折，然后在2012 年之后却迎来了新生。反向传播花了这么长时间才被开发出来的原因之一就是该功能需要计算机进行乘法矩阵运算。在上世纪70 年代末，世界上最强的的超级电脑之一Cray-1，每秒浮点运算速度 50 MFLOP，现在衡量 GPU 算力的单位是TFLOP（Trillion FLOPs），Nvidia 用于数据中心的最新GPU Nvidia Volta 的性能可以达到125 TFLOP，单枚芯片的速度就比五十年前世界上最快的电脑强大 250 万倍。技术的进步是多维度的，一些生不逢时的理论或者方法，在另一些技术条件达成时，就能融合出巨大的能量。02\n软件2.0 的崛起未来的计算机语言将更多得关注目标，而不是由程序员来考虑实现的过程。- Marvin Minsky\nSoftware 2.0 概念的最早提出人是Andrej Karpathy，这位从小随家庭从捷克移民来加拿大的天才少年在多伦多大学师从 Geoffrey Hinton，然后在斯坦福李飞飞团队获得博士学位，主要研究 NLP 和计算机视觉，同时作为创始团队成员加入了OpenAI，Deep Learning 的关键人物和历史节点都被他点亮。在2017 年被Elon Musk 挖墙脚到了Tesla 负责自动驾驶研发，然后就有了重构的FSD（Full Self-Driving）。\n按照Andrej Karpathy 的定义- “软件2.0 使用更抽象、对人类不友好的语言生成，比如神经网络的权重。没人参与编写这些代码，一个典型的神经网络可能有数百万个权重，用权重直接编码比较困难”。Andrej 说他以前试过，这几乎不是人类能干的事儿。。![图片] 配图09：Andrej Karpathy 和神经网络权重2.1 范式转移在创建深度神经网络时，程序员只写几行代码，让神经网络自己学习，计算权重，形成网络连接，而不是手写代码。这种软件开发的新范式始于第一个Machine Learning 语言TensorFlow，我们也把这种新的编码方式被称为软件 2.0。在 Deep Learning 兴起之前，大多数人工智能程序是用Python 和JavaScript 等编程语言手写的。人类编写了每一行代码，也决定了程序的所有规则。![图片] 配图10：How does Machine Learning work？（TensorFlow）\n相比之下，随着Deep Learning 技术的出现，程序员利用这些新方式，给程序指定目标。如赢得围棋比赛，或通过提供适当输入和输出的数据，如向算法提供具有&quot;SPAM” 特征的邮件和其他没有&quot;SPAM” 特征的邮件。编写一个粗略的代码骨架（一个神经网络架构），确定一个程序空间的可搜索子集，并使用我们所能提供的算力在这个空间中搜索，形成一个有效的程序路径。在神经网络里，我们一步步地限制搜索范围到连续的子集上，搜索过程通过反向传播和随机梯度下降（Stochastic Gradient Descent）而变得十分高效。\n神经网络不仅仅是另一个分类器，它代表着我们开发软件的范式开始转移，它是软件2.0。\n软件1.0 人们编写代码，编译后生成可以执行的二进制文件；但在软件2.0 中人们提供数据和神经网络框架，通过训练将数据编译成二进制的神经网络。在当今大多数实际应用中，神经网络结构和训练系统日益标准化为一种商品，因此大多数软件2.0 的开发都由模型设计实施和数据清理标记两部分组成。这从根本上改变了我们在软件开发迭代上的范式，团队也会因此分成了两个部分:2.0 程序员负责模型和数据，而那些1.0 程序员则负责维护和迭代运转模型和数据的基础设施、分析工具以及可视化界面。Marc Andreessen 的经典文章标题《Why Software Is Eating the World》现在可以改成这样：“软件（1.0）正在吞噬世界，而现在人工智能（2.0）正在吞噬软件！\n2.2 软件的演化软件从1.0 发展到软件2.0，经过了一个叫做“数据产品”的中间态。当顶级软件公司在了解大数据的商业潜力后，并开始使用 Machine Learning 构建数据产品时，这种状态就出现了。下图来自Ahmad Mustapha 的一篇文章《The Rise of Software 2.0》很好地呈现了这个过渡。\n![图片] 配图11：软件产品演化的三种状态\n这个中间态也叫大数据和算法推荐。在现实生活中，这样的产品可以是Amazon 的商品推荐，它们可以预测客户会感兴趣什么，可以是Facebook 好友推荐，还可以是Netflix 电影推荐或Tiktok 的短视频推荐。还有呢？Waze 的路由算法、Airbnb 背后的排名算法等等，总之琳琅满目。数据产品有几个重要特点：1、它们都不是软件的主要功能，通常是为了增加体验，达成更好的用户活跃以及销售目标；2、能够随着数据的增加而进化；3、大部分都是基于传统 ML 实现的，最重要的一点数据产品是可解释的。但有些行业正在改变，Machine Learning 是主体。当我们放弃通过编写明确的代码来解决复杂问题时，这个到2.0 技术栈的转变就发生了，在过去几年中，很多领域都在突飞猛进。语音识别曾经涉及大量的预处理、高斯混合模型和隐式Markov 模型，但今天几乎完全被神经网络替代了。早在1985 年，知名信息论和语言识别专家Fred Jelinek 就有一句经常被引用的段子：“每当我解雇一个语言学家，我们的语音识别系统的性能就会得到提高”。![图片] 配图12：图解软件 2.0 的代表应用除了大家熟悉的图像语音识别、语音合成、机器翻译、游戏挑战之外，AI 在很多传统系统也看到了早期的转型迹象。例如The Case for Learned Index Structures 用神经网络取代了数据管理系统的核心组件，在速度上比B-Trees 缓存优化快70%，同时节省了一个数量级的内存。\n所以，软件2.0 的范式具备了这几个新特征：1、Deep Learning 是主体，所有的功能都是围绕神经网络的输入输出构建的，例如语音识别、自动驾驶；2、可解释性并不重要，一个好的大数据推荐广告可以告诉客户用户看到这条广告的理由，但你没法从神经网络中找到规则，至少目前不行；3、高研发投入与低开发投入，现在大量的成功都来自大学和科技公司的研究部门，论文绝对比应用多。。\n2.3 软件2.0 的优势为什么我们应该倾向于将复杂的程序移植到软件2.0 中？Andrej Karpathy 在《Software 2.0》中给出了一个简单的答案：它们在实践中表现得更好！\n容易被写入芯片由于神经网络的指令集相对较小，主要是矩阵乘法（Matrix Multiplication）和阈值判断（Thresholding at Zero），因此把它们写入芯片要容易得多，例如使用定制的 ASIC、神经形态芯片等等（Alan Turing 在设计ACE 时就这样考虑了）。例如，小而廉价的芯片可以带有一个预先训练好的卷积网络，它们可以识别语音、合成音频、处理视觉信号。当我们周围充斥着低能耗的智能时，世界将会因此而大不同（好坏皆可）。非常敏捷敏捷开发意味着灵活高效。如果你有一段C++ 代码，有人希望你把它的速度提高一倍，那么你需要系统性地调优甚至是重写。然而，在软件2.0 中，我们在网络中删除一半的通道，重新训练，然后就可以了。。它的运行速度正好提升两倍，只是输出更差一些，这就像魔法。相反，如果你有更多的数据或算力，通过添加更多的通道和再次训练，你的程序就能工作得更好。模块可以融合成一个最佳的整体做过软件开发的同学都知道，程序模块通常利用公共函数、API 或远程调用来通讯。然而，如果让两个原本分开训练的软件2.0 模块进行互动，我们可以很容易地通过整体进行反向传播来实现。想象一下，如果你的浏览器能够自动整合改进低层次的系统指令，来提升网页加载效率，这将是一件令人惊奇的事情。但在软件2.0 中，这是默认行为。它做得比你好最后，也是最重要的一点，神经网络比你能想到的任何有价值的垂直领域的代码都要好，目前至少在图像、视频、声音、语音相关的任何东西上，比你写的代码要好。2.4 Bug 2.0\n对于传统软件，即软件1.0，大多数程序都通过源代码保存，这些代码可能少至数千行，多至上亿行。据说，谷歌的整个代码库大约有 20 亿行代码。无论代码有多少，传统的软件工程实践表明，使用封装和模块化设计，有助于创建可维护的代码，很容易隔离Bug 来进行修改。但在新的范式中，程序被存储在内存中，作为神经网络架构的权重，程序员编写的代码很少。软件2.0 带来了两个新问题：不可解释和数据污染。因为训练完成的神经网络权重，工程师无法理解（不过现在对理解神经网络的研究有了很多进展，第六章会讲到），所以我们无法知道正确的执行是为什么？错误又是因为什么？这个和大数据算法有很大的不同，虽然大多数的应用只关心结果，无需解释；但对于一些安全敏感的领域，比如自动驾驶和医疗应用，这确实很重要。在2.0 的堆栈中，数据决定了神经网络的连接，所以不正确的数据集和标签，都会混淆神经网络。错误的数据可能来自失误、也可能是人为设计，或者是有针对性地投喂混淆数据（这也是人工智能领域中新的程序道德规范问题）。例如iOS 系统的自动拼写功能被意外的数据训练污染了，我们在输入某些字符的时候就永远得不到正确的结果。训练模型会认为污染数据是一个重要的修正，一旦完成训练部署，这个错误就像病毒一样传播，到达了数百万部iPhone 手机。所以在这种2.0 版的Bug 中，需要对数据以及程序结果进行良好的测试，确保这些边缘案例不会使程序失败。在短期内，软件2.0 将变得越来越普遍，那些没法通过清晰算法和软件逻辑化表述的问题，都会转入2.0 的新范式，现实世界并不适合整齐地封装。', 'doi': '', 'published_date': '2022-11-15T09:06:40+00:00', 'pdf_url': '', 'url': 'https://news.qq.com/rain/a/20221112A04S4N00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '智能时代的蜕变：人工智能发展历程-百度开发者中心', 'authors': [], 'abstract': '[推荐] \n\n[数据库] \n\n[文心快码 Baidu Comate] \n\n[飞桨PaddlePaddle] \n\n[人工智能] \n\n[云原生] \n\n[超级链] \n\n[百度安全] \n\n[物联网] \n\n[开源技术] \n\n[云计算] \n\n[大数据] \n\n[开发者] \n\n[企业服务] \n\n[更多内容] \n\n[千帆大模型平台] \n\n# 智能时代的蜕变：人工智能发展历程\n\n作者： [谁偷走了我的奶酪] 2024.01.18 13:57浏览量：3\n\n_简介：_ 人工智能经历了从概念提出到实际应用的漫长历程，本文将带您了解人工智能的发展脉络和重要阶段。\n\n在过去的几十年里，人工智能已经从科幻概念逐渐成为我们日常生活的一部分。它的起源可以追溯到20世纪50年代，当时科学家们开始探索让计算机具备人类智能的可能性。人工智能的发展经历了多个阶段，每个阶段都有其独特的贡献和里程碑。第一阶段：人工智能的起源（1950-1974）人工智能的起源可以追溯到1950年，当时计算机科学家阿兰·图灵提出了著名的图灵测试。该测试旨在判断一台机器是否具备智能，通过让人类与机器对话，如果人类不能区分与机器对话的是人类还是机器，则认为这台机器具有智能。这一想法为人工智能的发展奠定了基础。第二阶段：专家系统与商业化（1980-1987）到了20世纪80年代，人工智能开始进入商业化应用阶段。专家系统是这一时期的代表，它们是包含专门领域知识的计算机系统，能够提供专业意见和建议。专家系统的流行使得人工智能开始在医疗、金融等领域得到应用。第三阶段： [神经网络] 的兴起（1987-1994）神经网络是模拟人类大脑神经元网络的 [机器学习] 算法。在20世纪80年代末和90年代初，神经网络成为人工智能领域的研究热点。然而，由于计算能力的限制和训练数据不足，神经网络的应用受到限制。第四阶段：支持向量机与核方法的兴起（1995-2008）随着计算机技术的进步，支持向量机和核方法在人工智能领域的应用逐渐普及。支持向量机是一种分类算法，核方法则用于解决非线性问题。这些方法在 [语音识别] 、图像处理等领域取得了显著成果。第五阶段： [深度学习] 的崛起（2008至今）深度学习是人工智能领域的一种重要技术，它通过构建深度神经网络来模拟人类大脑的行为。自2008年以来，随着计算能力的提升和大数据的涌现，深度学习在语音识别、 [图像识别] 、 [自然语言处理] 等领域取得了重大突破。如今，人工智能已经渗透到我们生活的方方面面，从智能手机、智能家居到自动驾驶汽车和机器人，人工智能的应用场景不断拓展。未来，随着技术的不断进步，人工智能将在更多领域发挥巨大潜力，推动人类社会的发展进步。然而，人工智能的发展也面临着一些挑战和问题。如何确保人工智能的道德和法律合规性、如何解决数据隐私和 [安全] 问题、如何提高人工智能的可解释性和透明度等都是亟待解决的问题。因此，在推动人工智能发展的同时，我们也需要关注其带来的挑战和问题，并寻求解决方案，以实现人工智能的可持续发展。总结起来，人工智能的发展历程是一个不断探索和创新的过程。通过了解人工智能的发展历程，我们可以更好地认识这一领域的现状和未来趋势。同时，我们也应该意识到人工智能的潜力和挑战，共同努力推动其健康、可持续发展。\n\n### 相关文章推荐\n\n- [**文心一言接入指南：通过百度智能云千帆大模型平台API调用** \\\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。] \n\n[十万个为什么] 2023.10.20 16:56236691199\n\n- [**从 MLOps 到 LMOps 的关键技术嬗变** \\\n本文整理自 QCon 全球软件开发大会 -从 MLOps 到 LMOps 分论坛的同名主题演讲] \n\n[百度智能云开发者中心] 2023.11.15 18:031939694\n\n- [**Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然** \\\nSugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n\n[百度智能云开发者中心] 2023.03.21 10:561652421\n\n- [**更轻量的百度百舸，CCE Stack 智算版发布** \\\n百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的 AI 工程能力面向市场推出的解决方案。] \n\n[百度智能云开发者中心] 2023.03.02 12:171187101\n\n- [**打造合规数据闭环，加速自动驾驶技术研发** \\\n今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n\n[百度智能云开发者中心] 2023.03.02 15:001377901\n\n- [**LMOps 工具链与千帆大模型平台** \\\nLMOps 相关的概念以及关键技术] \n\n[百度智能云开发者中心] 2023.11.17 15:491157113\n\n\n### 发表评论\n\n登录后可评论，请前往\xa0[登录] \xa0或\xa0[注册] \n\n评 论\n\n### 开发者关注产品榜\n\n- [_1_\\\n\\\n**千帆大模型服务与开发平台ModelBuilder** \\\n\\\n企业级一站式大模型开发及服务平台\\\n\\\n模型训练限时免费] \n- [_2_\\\n\\\n**千帆大模型应用开发平台AppBuilder** \\\n\\\n企业级大模型应用开发平台\\\n\\\n平台体验全免费] \n- [_3_\\\n\\\n**秒哒-生成式应用开发平台** \\\n\\\n不用写代码，就能实现任意想法\\\n\\\n全功能免费体验] \n- [_4_\\\n\\\n**百度智能云客悦智能客服平台** \\\n\\\n大模型重塑营销与客服体验\\\n\\\n0元试用一个月] \n\n### 最热文章\n\n- [秒哒，全面开放！] \n- [两连发！文心大模型4.5及X1，上线千帆！] \n- [即刻体验！文心大模型X1现面向企业用户全面开放！] \n- [百度智能云千帆全面支持DeepSeek-R1/V3调用，价格超低] \n- [0 Token 间间隔 100% GPU 利用率，百度百舸 AIAK 大模型推理引擎极限优化 TPS] \n- [文心快码问答智能体现场演示，重塑问题解决的体验感！] \n\n### 关于作者\n\n- 被阅读数\n- 被赞数\n- 被收藏数\n\n关 注', 'doi': '', 'published_date': '2024-01-18T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2842433', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '图说人工智能简史，每一张图片都是一个里程碑', 'authors': [], 'abstract': '图说人工智能简史，每一张图片都是一个里程碑-腾讯云开发者社区-腾讯云\n[] \n[AI大眼萌\n] \n## 图说人工智能简史，每一张图片都是一个里程碑原创**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布AI大眼萌\n**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;图说人工智能简史，每一张图片都是一个里程碑\n# 图说人工智能简史，每一张图片都是一个里程碑原创![作者头像] \nAI大眼萌\n**关注\n修改于2025-02-11 08:16:03\n修改于2025-02-11 08:16:03\n18.9K1\n举报在人类文明的漫长历程中，对于智慧的追求从未停歇。自古代哲学家对逻辑和推理的探索，到20世纪计算机科学的诞生，我们见证了人工智能（Artificial Intelligence, AI）从概念的萌芽到技术的蓬勃发展。人工智能，作为计算机科学的一个分支，其核心目标是模拟人类思维，赋予机器学习、推理乃至创造的能力。AI大眼萌将带大家回顾人工智能发展的各个阶段。\n人工智能(Artificial Intelligence，AI) 是计算机科学的一个分支领域，致力于让机器模拟人类思维，执行学习、推理等工作。人工智能的发展经历了以下六个阶段。* **前导：**萌芽阶段\n* **第一阶段-AI兴起**：人工智能的诞生（1941- 1956）\n* **第二阶段-AI早期成功**：AI黄金发展时代（1956-1974）\n* **第三阶段-AI第一次寒冬**：神经网络遇冷，研究经费减少（1974\\~1980）\n* **第四阶段-AI复兴**：第二次AI黄金发展时代，专家系统流行并商用（1980\\~1987）\n* **第五阶段-AI第二次寒冬**：专家系统溃败，研究经费大减（1987\\~1993）\n* **第六阶段-AI崛起**：深度学习理论和工程突破（1993至今）\n![图片] \n图片**00**\n**前导：萌芽阶段**\n人工智能是建立在人类思维过程可以机械化的假设之上的。中国、印度和希腊的哲学家都在公元前一千年发展出了形式演绎的结构化方法。几个世纪以来，亚里士多德Aristotle（他对三段论*Syllogism*进行形式分析）、欧几里得Euclid（他的*《几何原本》*是形式推理的一个模型）、阿尔·花拉子模al-Khwārizmī（他发展了代数，并以自己的名字命名了“*算法”*一词）等都发展了他们的思想。从古代到现在对逻辑和形式推理的研究直接导致了20世纪40年代可编程数字计算机的发明，这是一种基于抽象数学推理的机器。这个装置及其背后的想法激发了科学家们开始讨论建造电子大脑的可能性。\n![图片] \n图片Al-Jazari&#x27;s programmable automata (1206 CE)\n**01**\n**第一阶段-AI兴起：人工智能的诞生（1941- 1956）**\n* 1943**人工神经元模型Artificial\\_neuron**\n自1943年起，**沃尔特·皮茨Walter Pitts**和**沃伦·麦卡洛克Warren McCulloch**携手提出了**人工神经元模型Artificial\\_neuron**，即阈值逻辑单元（TLU），为神经网络研究奠定了基石。有趣的是，这两位大师相差25岁，却意外地在同一年离世。皮茨更是个极其低调的人，即便有人出钱，也不愿透露自己的姓名。\n![图片] \n图片![图片] \n图片* **1945年**，艾伦·图灵Alan Turing就已经在考虑如何用计算机来模拟人脑了。他设计了 ACE（Automatic Computing Engine- 自动计算引擎）来模拟大脑工作。在给一位同事的信中写道：&quot;与计算的实际应用相比，我对制作大脑运作的模型可能更感兴趣 ...... 尽管大脑运作机制是通过轴突和树突的生长来计算的复杂神经元回路，但我们还是可以在ACE 中制作一个模型，允许这种可能性的存在，ACE 的实际构造并没有改变，它只是记住了数据......&quot; 这就是机器智能的起源![图片] \n图片* **1950年**，艾伦·图灵Alan Turing发表了《计算机器与智能》，提出了著名的“图灵测试”，标志着**人工智能**概念的初步形成。\n![图片] \n图片![图片] \n图片* **1951**年，Marvin Lee Minsky 与Dean Edmonds 一道建造了第一台神经网络机，称为SNARC\n![图片] \n图片* **1956年**夏天，在美国新罕布什尔州汉诺斯小镇的达特茅斯学院，一群科学家聚集在一起，讨论了关于设计智能机器的可能性。约翰·麦卡锡、马文·明斯基等人首次提出了“人工智能”这一术语，此次达特茅斯会议Dartmouth被视为**人工智能学科**的正式诞生。会议上最引人瞩目的成果，是赫伯特·西蒙Herbert Simon和艾伦·纽厄尔Alan Newell介绍的一个程序“逻辑理论家”Logic Theorist，这个程序可以证明伯特兰·罗素Bertrand Russell和艾尔弗雷德·诺思·怀特海Alfred North Whitehead合著的《数学原理》中命题逻辑部分的一个很大子集，“逻辑理论家”程序被许多人认为是第一款可工作的人工智能程序。\n![图片] \n图片![图片] \n图片1956年8月从左至右：Oliver Selfridge, Nathaniel Rochester, Ray Solomonoff, Marvin Minsky, Trenchard More, John McCarthy, Claude Shannon.。\n![图片] \n图片![图片] \n图片* **人工智能三大学派**\n在人工智能的热潮中，涌现了从不同的学科背景出发的三大学派：![图片] \n图片* **连接主义connectionism**：又称为仿生学派或生理学派，包含感知器，人工神经网络，深度学习等技术。代表人物有**罗森布莱特**（Frank Rosenblatt）等。\n* 主张智能可以通过模拟大脑神经元网络来实现。* 强调使用神经网络和学习算法来处理信息。* 深度学习、卷积神经网络（CNN）和循环神经网络（RNN）是这一流派的现代发展。\n![图片] \n图片连接主义的代表：多层神经网络* **符号主义symbolism**：又称为逻辑主义、心理学派或计算机学派。包含决策树，专家系统等技术。代表人物有西蒙和纽厄尔、马文·明斯基等。各类决策树相关的算法，均受益于符号主义流派。\n* 主张智能可以通过符号操作来实现。* 强调使用逻辑、规则和符号来模拟人类思维过程。* 知识图谱是大数据时代的知识工程集大成者，是符号主义与连接主义相结合的产物，是实现认知智能的基石。![图片] \n图片* **行为主义**：又称为进化主义或控制论学派，包含控制论、马尔科夫决策过程、遗传算法、强化学习和某些类型的机器人技术等技术。代表人物有萨顿（Richard Sutton）等。\n* 也称为进化主义或控制论，主张智能行为可以通过与环境的交互来学习。* 强调通过试错和自然选择来优化行为。* 行为主义在后来的机器人学、自动化控制、游戏AI、自动驾驶汽车等领域有着重要应用\n![图片] \n图片麻省理工学院制造的六足机器人Genghis（成吉思汗）\n**02**\n**第二阶段-AI**\n**早期成功：AI黄金发展时代（1956-1974年）**\n* **1957 年**，美国心理学家弗兰克·罗森布拉特Frank Rosenblatt在康奈尔航空实验室发明了一个**早期的神经网络early neural networks- 感知器模型（Perceptron Model）**，感知器的设计包含三个部分：输入层、隐藏层和输出层。输入层由400个光敏元件组成，用于模拟视网膜的功能；隐藏层包含512个步进电动机，模拟神经元的兴奋和抑制过程；输出层则连接了8个执行器单元。通过“反向传播误差校正”原理，感知器可以不断调整自身的参数以提高分类准确率，从而在处理线性可分的分类问题上表现出良好的学习能力。\n![图片] \n图片感知机模型：![图片] \n图片![图片] \n图片打个比方：![图片] \n图片1958年，纽约时报记者对人工智能未来的畅想。\n![图片] \n图片* **1959年**，亚瑟·塞缪尔Arthur Samuel开发了首个自学习程序——西洋跳棋程序，并引入了“**机器学习Machine Learning”**这一概念。\n![图片] \n图片* **1960年**，Frank Rosenblatt 获得了美国海军研究办公室信息系统分支和罗马航空发展中心的资助，建造了一台定制的计算机Mark I感知器。\n![图片] \n图片![图片] \n图片* **1966年**，约瑟夫·魏岑鲍姆开发了 ELIZA，这是一个早期的**自然语言Natural language**处理程序。最著名的脚本DOCTOR模拟了Rogerian学派的心理治疗师（治疗师经常将患者的话反映给患者）,并使用脚本中规定的规则，对用户输入的非方向性问题做出回应。因此，ELIZA是第一个聊天机器人（现代的“聊天机器人”）和第一个能够尝试图灵测试的程序之一，展示了机器与人类进行自然语言交流的可能性。ELIZA可以说是现在Siri、小爱同学等问答交互工具的鼻祖。\n![图片] \n图片* **1969年**，马文·明斯基Marvin Minsky和西摩·帕珀特Seymour Papert出版的《感知器：计算几何学导论》一书，对罗森布莱特的感知器提出了质疑。书中指出：单层感知器本质上是一个线性分类器，无法求解非线性分类问题，甚至连简单的异或（XOR）问题都无法求解。人们通常错误地认为，他们也证明了类似的结果适用于多层感知器网络。然而，这是不正确的，因为Minsky和Papert已经知道多层感知器能够产生XOR函数。经常被错误引用的Minsky和Papert文本导致神经网络研究的兴趣和资金大幅下降，导致**神经网络研究**一度陷入低谷。这些先驱们怎么也没想到，计算机的速度能够在随后的几十年里指数级增长，提升了上亿倍。\n![图片] \n图片单层感知机：无法将蓝、红两类点用一条直线分开在两边。![图片] \n图片* **1970年**，第一个拟人机器人WABOT-1在日本早稻田大学建成。它由一个肢体控制系统、一个视觉系统和一个对话系统组成。\n![图片] \n图片**03**\n**第三阶段-AI第一次寒冬：神经网络遇冷，研究经费减少（1974\\~1980）**\n在20 世纪70 年代，人工智能受到批评和财务挫折。人工智能研究人员未能意识到他们所面临问题的难度。他们的巨大乐观情绪提高了公众的期望，而当承诺的结果未能实现时，针对人工智能的资金就被严重减少。1973年英国科学研究委员会消减对AI研究的资助。1973\\~1974 年，美国DARPA 大幅削减对AI研究的资助，到1974年，已经很难再找到对AI项目的资助了。\n![图片] \n图片* **1974 年**，哈佛大学沃伯斯（Paul Werbos）博士论文里，首次提出了通过误差的反向传播（BP）来训练人工神经网络，但在该时期未引起重视。\n![图片] \n图片* 在20 世纪七八十年代的“寒冬”里，仍有一些人执着于神经网络研究，科学界把他们视为狂热的疯子。比如，芬兰人戴沃·科霍宁（Teuvo Kohonen），他研究的是一个与神经网络比较接近的课题—联想记忆。再比如，还有一群日本人，与西方不同，日本的工程科学生态系统比较孤立，其中包括数学家甘利俊一Shun-Ichi Amari和一位名为福岛邦彦Kunihiko Fukushima的业内人士，后者发布了一个被他称为**认知机****Congitron**的机器，这一命名来自术语**感知机****Perceptron**。福岛邦彦前后一共发布了这个机器的两个版本，分别是 20 世纪70 年代的认知机和**1979年**发布的**神经认知机****Neocognitron**，它是一种分层、多层人工神经网络，通过无监督学习，用于日语手写字符识别和其他模式识别任务，并成为卷积神经网络的灵感来源。\n![图片] \n图片**04**\n**第四阶段-AI复兴：第二次AI黄金发展时代，专家系统流行并商用（1980\\~1987）**\n* 专家系统的兴起:AI的第一次寒冬，让研究者们的研究热点，转向了专家系统。专家系统，是模仿人类专家决策能力的计算机系统。依据一组从专门知识中推演出的逻辑规则，来回答特定领域中的问题。专家系统包含若干子系统：知识库，推理引擎，用户界面。\n![图片] \n图片知识库系统和知识工程成为80年代AI研究的主要方向，出现了许多有名的专家系统。\n* MYCIN：识别可能导致急性感染的各种细菌，根据患者的体重推荐药物。\n* DENDRAL：用于化学分析，可预测分子结构。\n* PXDES：用于预测肺癌程度和类型。\n* XCON：1980年由CMU为DEC设计，1986年之前每年为DEC省下四千万美金。\n专家系统具有明显的一些优势：* 设计简单，且能够容易地编程实现或修改* 实践证明了专家系统的实用性和经济价值* 高效、准确、迅速和不知疲倦地进行工作* 使领域专家的经验不受时间和空间的限制专家系统的这一系列优势，吸引了新一轮的政府资助。1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目，目标是造出能与人对话，翻译语言，解释图像，并像人一样推理的机器，英国开始了耗资三亿五千万英镑的Alvey工程。DARPA成立战略计算促进会，1988年向AI的投资是1984年的三倍。\n* **1982 年**，物理学家约翰·霍普菲尔德John Hopfield证明了一种神经网络（现在称为“**霍普菲尔德网络Hopfield net**&quot;”）可以学习和处理信息，并在任何固定条件下经过足够的时间后可证明收敛，因为之前人们认为非线性网络通常会混乱地演化。1986年，David Rumelhart和杰弗里·辛顿Geoffrey Hinton推广了一种适用于多层感知器（MLP）的算法，称为“**反向传播算法Backpropagation**”的神经网络训练方法，推动了多层神经网络的发展。这两项进展重新点燃了**神经网络研究**的热潮。\n![图片] \n图片多层感知器multilayer perceptron (MLP）\n![图片] \n图片![图片] \n图片* **1985 年**，朱迪亚·珀尔Judea Pearl提出贝叶斯网络，以倡导人工智能的概率方法和发展贝叶斯网络而闻名，还因发展了一种基于结构模型的因果和反事实推理理论而受到赞誉。\n![图片] \n图片![图片] \n图片* **1985年**，杰弗里·辛顿Geoffrey Hinton提出**受限玻尔兹曼机Restricted Boltzmann machine**。受限玻尔兹曼机是一种二分图结构，包含可见单元和隐藏单元。其训练算法是基于梯度的对比分歧算法，可以用于降维、分类、回归和特征学习等任务。\n![图片] \n图片**05**\n**第五阶段-AI第二次寒冬：专家系统溃败，研究经费大减（1987\\~1993）**\n在专家系统快速发展的过程中，其劣势也逐渐显露出来。专家系统的劣势有：* 知识采集和获取的难度很大，系统建立和维护费用高。* 专家系统仅限应用于某些特定情景，不具备通用性。* 使用者需要花很长时间来熟悉系统的使用“AI 之冬”一词由经历过1974 年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。**专家系统的这些劣势，使得商业化面临重重困境，从而直接引发了AI的第二次寒冬**\n* 变天的最早征兆是1987 年AI 硬件市场需求的突然下跌。Apple 和IBM 生产的台式机性能不断提升，到1987 年时其性能已经超过了Symbolics 和其他厂家生产的昂贵的Lisp 机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解* 80年代晚期，战略计算促进会大幅削减对AI的资助。\n* DARPA认为AI并非“下一个浪潮”，拨款倾向于更容易出成果的项目。\n* 1991年，日本的“第五代计算机项目”的目标未能实现，事实上其中一些目标，比如“与人展开交谈”，直到 2010 年也没有实现。与其他AI 项目一样，期望比真正可能实现的要高得多。* **1989年**，AT＆T贝尔实验室的**杨立昆Yann Lecun**和团队使用**卷积神经网络convolutional neural networks CNN**技术，实现了人工智能识别手写的邮政编码数字图像，成为深度学习在实践中的早期成功案例。\n![图片] \n图片1980年代是人工智能研究方向发生重大转折的时期。机器学习和神经网络（联结主义）加速崛起，逐渐取代专家系统（符号主义），成为人工智能的主要研究方向。我们也可以理解为，人工智能原本由知识驱动的方式，逐渐变成了由数据驱动。\n![图片] \n图片* **1991年**，互联网的出现使在线连接和数据共享成为可能，无论你是谁，无论你在哪里。由于数据是人工智能的燃料，这在以后将被理解为人工智能的一个关键时刻。\n![图片] \n图片**06**\n**第六阶段-AI崛起：深度学习理论和工程突破（1993至今）**\n![图片] \n图片* **深度学习三巨头**\n少数AI研究者在AI寒冬期以众人皆醉我独醒的态度，十年如一日地坚持坐冷板凳，开展神经网络方向的研究。其中代表人物是深度学习三巨头。**他们在2018年因在深度学习方面的卓越贡献，一同被授予了图灵奖**。\n* 杰弗里·辛顿Jeoffrey Hinton：发明了受限玻尔兹曼机，首先将反向传播算法应用于多层神经网络。培养了杨立昆Yann Lecun等一众大牛级学生。推动谷歌的图像和音频识别性能大幅提升。\n![图片] \n图片我一直以来都确信，实现人工智能的唯一方式，就是按人类大脑的方式去进行计算。——杰弗里·辛顿* 杨立昆Yann Lecun：1989年使用反向传播和神经网络识别手写数字，用来读取银行支票上的手写数字，首次实现神经网络商业化，1998 ，提出LeNet5卷积神经网络，Facebook人工智能实验室负责人。\n![图片] \n图片我们之所以为人，是因为我们具有智能，而人工智能是这一能力的扩展。——杨立昆* 约书亚·本吉奥Yoshua Bengio：推动了循环神经网络的发展，带领开发出Theano框架，启发了Tensorflow等众多后续框架的发展，创办AI顶会ICLR，开创了基于神经网络的语言模型。他也是权威教材《深度学习》一书的合著者。\n![图片] \n图片我一直认为“创造性”可通过计算的方式来实现。我们理解计算背后的原理。所以，只需找到更智能的神经网络或模型即可。——约书亚·本吉奥* **1995 年**，克里娜·柯尔特斯Corinna Cortes和弗拉基米尔·万普尼克Vladimir Vapnik提出联结主义经典的支持向量机（Support Vector Machine ,SVM），可以视为在感知机基础上的改进，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中\n![图片] \n图片* **1997 年**，IBM 深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。![图片] \n图片* **2000年**，麻省理工学院的辛西娅-布雷泽尔开发了Kismet，一种能够识别和模拟情绪的机器人。\n![图片] \n图片* **2003 年**，Google 公布3 篇大数据奠基性论文，为大数据存储及分布式处理的核心问题提供了思路：非结构化文件分布式存储（GFS）、分布式计算（MapReduce）及结构化数据存储（BigTable），奠定了现代大数据技术的理论基础。\n![图片] \n图片* **2006年**，杰弗里·辛顿等人发表了重要的论文《Reducing the dimensionality of data with neural networks（用神经网络降低数据维数）》, 提出了**深度信念网络Deep Belief Network(DBN)**，用于无监督特征学习，为深度学习的发展奠定了基础，**2006 年也被称为深度学习元年**。\n![图片] \n图片* **2006年**，英伟达（NVIDIA）推出CUDA （统一计算架构），GPU开始用于解决商业、工业以及科学方面的复杂计算，GPU与深度学习结合，模型的训练速度有了数量级的提升。\n![图片] \n图片* **2012年**，在杰弗里·辛顿的指导下，伊利亚·苏茨克沃Ilya Sutskever和亚历克斯·克里切夫斯基Alex Krizhevsky开发出 AlexNet 模型，推动了**深度卷积神经网络CNN**的发展。AlexNet在ImageNet挑战赛上取得了突破性的成果，从而引发了深度学习Deep Learning的热潮。值得一提的是，他们三人用于训练模型的，只是2张英伟达GTX 580显卡。GPU在深度神经网络训练上表现出的惊人能力，不仅让他们自己吓了一跳，也让黄仁勋和英伟达公司吓了一跳。\n![图片] \n图片作为对比，2012年的早些时候，谷歌“Google Brain”项目的研究人员吴恩达（华裔美国人，1976年生于伦敦）、杰夫·迪恩Jeff Dean等人，也捣鼓了一个神经网络（10亿参数），用来训练对猫的识别。他们的训练数据是来自youtube的1000万个猫脸图片，用了1.6万个CPU，整整训练了3天。\n![图片] \n图片深度学习Deep Learning是一Machine Learning 的一个重要分支,更准确来说，机器学习底下有一条“神经网络”路线，而深度学习，是加强版的“神经网络”学习, 它使用多层神经网络和反向传播Backpropagation技术来训练神经网络。经典机器学习算法使用的神经网络，具有输入层、一个或两个“隐藏”层和一个输出层。数据需要由人类专家进行结构化或标记（监督学习），以便算法能够从数据中提取特征。', 'doi': '', 'published_date': '2026-02-03T13:07:57.263381', 'pdf_url': '', 'url': 'https://cloud.tencent.com/developer/article/2491938', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能发展简史', 'authors': [], 'abstract': '人工智能发展简史\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能发展简史2017年01月23日 11:10来源：\n网络传播杂志[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n“人工智能之父”艾伦·图灵。**1、 人工智能的诞生（20世纪40～50年代）**\n1950年：图灵测试\n1950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n1954年：第一台可编程机器人诞生\n1954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n1956年：人工智能诞生\n1956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n1966年\\~1972年：首台人工智能机器人Shakey诞生\n1966年\\~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n1966年：世界上第一个聊天机器人ELIZA发布\n美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n1968年：计算机鼠标发明\n1968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n**3、 人工智能的低谷（20世纪70～80年代）**\n20世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n![] \n1997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n**4、 人工智能的繁荣期（1980年\\~1987年）**\n1981年：日本研发人工智能计算机\n1981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n1984年：启动Cyc（大百科全书）项目\n在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n1986年：3D打印机问世\n美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n**5、 人工智能的冬天（1987年\\~1993年）**\n“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n**6、 人工智能真正的春天（1993年至今）**\n1997年：电脑深蓝战胜国际象棋世界冠军\n1997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n2011年：开发出使用自然语言回答问题的人工智能程序\n2011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n2012年：Spaun诞生\n加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n2013年：深度学习算法被广泛运用在产品开发中\nFacebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n2015年：人工智能突破之年\nGoogle开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n2016年：AlphaGo战胜围棋世界冠军李世石\n2016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）![] \n2016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n**大事记**\n①1942年：“机器人三定律”提出\n美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。②1956年：人工智能的诞生\n达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n③1959年：第一代机器人出现\n德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n④1965年：兴起研究“有感觉”的机器人\n约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n⑤1968年：世界第一台智能机器人诞生\n美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n⑥2002年：家用机器人诞生\n美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n⑦2014年：机器人首次通过图灵测试\n在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n⑧2016年：AlphaGo打败人类\n2016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': '2017-01-23T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来', 'authors': [], 'abstract': '# 人工智能的历史、现状和未来\n\n来源：《求是》2019/04\n作者：谭铁牛\n2019-02-16 09:00:00\n\n2018年2月25日，在平昌冬奥会闭幕式“北京8分钟”表演中，由沈阳新松机器人自动化股份有限公司研发的智能移动机器人与轮滑演员进行表演。 新华社记者 李钢/摄\n\n2018年5月3日，中国科学院发布国内首款云端人工智能芯片，理论峰值速度达每秒128万亿次定点运算，达到世界先进水平。 新华社记者 金立旺/摄\n\n2017年10月，在沙特阿拉伯首都利雅得举行的“未来投资倡议”大会上，机器人索菲亚被授予沙特公民身份，她也因此成为全球首个获得公民身份的机器人。图为2018年7月10日，在香港会展中心，机器人索菲亚亮相主舞台。 ISAAC LAWRENCE/视觉中国\n\n2018年11月22日， 在“伟大的变革——庆祝改革开放40周年大型展览”上，第三代国产骨科手术机器人“天玑”正在模拟做手术，它是国际上首个适应症覆盖脊柱全节段和骨盆髋臼手术的骨科机器人，性能指标达到国际领先水平。 麦田/视觉中国\n\n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。\n\n**概念与历程**\n\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。\n\n人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n\n**现状与影响**\n\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n\n**专用人工智能取得重要突破。** 从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n\n**通用人工智能尚处于起步阶段。** 人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n**人工智能创新创业如火如荼。** 全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n**创新生态布局成为人工智能产业发展的战略高地。** 信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n\n**人工智能的社会影响日益凸显。** 一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。\n\n**趋势与展望**\n\n经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n\n**从专用智能向通用智能发展。** 如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n**从人工智能向人机混合智能发展。** 借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。\n\n**从“人工+智能”向自主智能系统发展。** 当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。\n\n**人工智能将加速与其他学科领域交叉渗透。** 人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。\n\n**人工智能产业将蓬勃发展。** 随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。\n\n**人工智能将推动人类进入普惠型智能社会。**“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n**人工智能领域的国际竞争将日益激烈。** 当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n**人工智能的社会学将提上议程。** 为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。\n\n**态势与思考**\n\n当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n**高度重视。** 党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n**态势喜人。** 据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。\n\n**差距不小。** 目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n\n**前景看好。** 我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。\n\n**树立理性务实的发展理念。** 任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n**重视固本强基的原创研究。** 人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n**构建自主可控的创新生态。** 我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。\n\n**推动共担共享的全球治理。** 目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。\n\n作者：中央人民政府驻香港特别行政区联络办公室副主任、中国科学院院士\n\n扫描二维码分享到手机\n\n标签 -\n\n网站编辑 \\- 王慧\n\n[【网站声明】] [【纠错】] [【打印】] \n\n评论登录新浪微博 [@求是] 发表评论。请您文明上网、理性发言并遵守相关规定。', 'doi': '', 'published_date': '2019-02-16T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.qstheory.cn/dukan/qs/2019-02/16/c_1124114625.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能历史', 'authors': [], 'abstract': '人工智能历史 | IBM\n[Artificial Intelligence] \n# AI 的历史![高耸入云的摩天大楼尖顶] \n## 作者[Tim Mucci] \nIBM Writer\nGather\n## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。\nGPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;\n## 20 世纪以前### 1726\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。\n学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;\n“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”\n- Jonathan Swift 的《格列佛游记》(1726)\nSwift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。\n## 1900–1950\n### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。\n### 1921\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。\n### 1939\n爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。\n虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。\n与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。\n### 1950\n英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;\n图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n## 1950–1980\n### 1951\nMarvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952\n数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n### 1955\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。\n### 1958\nJohn McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959\nArthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n### 1965\n哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。\n### 1966\nShakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969\nArthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。\nMarvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。\n### 1970\nTerry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。\n### 1973\nJames Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000\n### 1980\nWABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。\n### 1982\n日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。\n### 1986\nDavid Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。\n这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987\n在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\nRollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\nMarvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。\n### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。\n### 1993\n科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。\n这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n### 1995\nRichard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;', 'doi': '', 'published_date': '2026-02-03T13:07:57.263611', 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI 有着怎样的发展历程？', 'authors': [], 'abstract': 'AI 有着怎样的发展历程？| Cloudflare\n[注册] \n语言* [English] \n* [English (United Kingdom)] \n* [Deutsch] \n* [Español (Latinoamérica)] \n* [Español (España)] \n* [Français] \n* [Italiano] \n* [日本語] \n* [한국어] \n* [Polski] \n* [Português (Brasil)] \n* [Русский] \n* [繁體中文] \n* [简体中文] \n# AI 有着怎样的发展历程？当今最先进的AI 模型建立在几十年前的发现基础之上。AI 的历史可以追溯到第一台数字计算机诞生之前。#### 学习目标阅读本文后，您将能够：* 识别AI 发展的关键进展* 了解Alan Turing、Frank Rosenblatt 和Geoffrey Hinton 等发明家和创新者多年来对AI 发展做出的贡献* 列举促成当今AI 热潮的发展相关内容[\n什么是代理式AI？\n] [\n什么是生成式AI？\n] [\n预测式AI\n] [\n神经网络] [\n什么是人工智能(AI)？\n] \n复制文章链接## AI 有着怎样的发展历程？[人工智能 (AI)] 是指机器（通常特指计算机）模仿人类认知过程、解决问题的能力以及行动能力。如今，AI 涵盖了一系列能力，从[预测式 AI] 和[自然语言处理] ，到[大型语言模型 (LLM)] 和[代理式 AI] 。\n从古代世界的自动机到最早的计算机，这些都是AI 的前身。当今最先进的模型，其基础是几十年前发展起来的理论和算法。## AI 历史上的重大事件：时间线虽然“人工智能”一词最早出现在1955 年，但对AI 发展至关重要的事件却可以追溯到几个世纪以前。#### 20 世纪之前* **大约公元前 400 年：**根据一些古希腊文献记载，阿尔希塔斯 (Archytas of Tarentum) 制作了一只能够拍打翅膀并飞翔的木鸽。* **大约 1495 年：**莱昂纳多•达•芬奇 (Leonardo da Vinci) 绘制了一幅外形类似德国骑士的自动机详细图纸，并且可能已经制造了一台（即便确实如此，这台自动机也无法流传至今）。* **大约 1560 年：**西班牙国王费利佩二世 (Phillip II) 委托钟表匠Juanelo Turriano 模仿方济各会修士Diego de Alcalá（后来被封为圣徒 St. Diego）制作一台自动机。这种自动机由发条驱动，可以模仿人类的基本动作和姿势。\n* **1764 - 1770 年：**名为*Canard Digérateur*（或“消化鸭”）以及 Automaton Chess Player（或“自动行棋的傀儡”）的自动机令公众欣喜。虽然两者后来都被证明是骗局，但它们拓展了人们对自动化可能性的普遍理解。\n* **1822 年：**查尔斯•巴贝奇 (Charles Babbage) 完成了“差分引擎”的研制，这是一种机械计算装置，它是计算机的早期前身。#### 1900 - 1973 年* **1914年：**数学家兼发明家 Leonardo Torres y Quevedo 首次推出了"El Ajedrecista"，这是一款能够自动进行国际象棋对局并在特定情况下击败人类棋手的自动机。\n* **1943 年：**神经生理学家 Warren McCulloch 和数学家Walter Pitts 共同发表了题为《神经活动内在概念的逻辑演算》(A Logical Calculus of the Ideas Imminent in Nervous Activity) 的论文，文中介绍了神经元的数学描述。这篇论文成为了构建[人工神经网络] 的关键一步。\n* **1945 年：**第一台数字计算机 ENIAC 诞生。* **1949 年：**心理专家唐纳德•赫布 (Donald Hebb) 出版了*《行为的组织》*，这本书对神经网络的发展产生了深远的影响。\n* **1950 年：**颇具影响力的数学家和计算机科学家 Alan Turing 发表了《计算机器与智能》(Computing Machinery and Intelligence)，这篇论文探讨了“机器能否思考”的问题。论文描述了著名的“图灵测试”，用于判断计算机智能是否已变得与人类智能无法区分。\n* **1951 年：**Dean Edmunds 和Marvin Minsky 一起建造了随机神经模拟强化计算器(SNARC)，这是世界上第一台神经网络计算机。它只有 40 个神经元。* **1955 年：**在计算机科学家约翰•麦卡锡 (John McCarthy) 主持的一次研讨会上，“人工智能”一词首次出现。* **1957 年：**心理学家兼计算机科学家弗兰克•罗森布拉特 (Frank Rosenblatt) 创建了感知器，这是一种早期的人工神经网络。* **1959 年：**斯坦福大学研究员 Bernard Widrow 和Marcian Hoff 开发了出现实世界中使用的第一个神经网络模型：多自适应线性元素(Madaline)，用于消除电话线路回声。\n* **1966 年：**计算机科学家 Joseph Weizenbaum 发布了ELIZA 程序，这被认为是第一个[聊天机器人] （尽管按照如今的标准，其底层模式匹配算法相当简单）。\n* **1969 年：**Marvin Minsky 和Seymour Papert 出版了*《感知器：计算几何学导论》*(Perceptrons: An Introduction to Computational Geometry)，这本书对感知器提出了质疑（最初由 Frank Rosenblatt 提出）。引人争议的是，书中还论述了感知器的一些局限性，某些研究员后来认为这些局限性削弱了对AI 研究的资助热情。#### AI 的寒冬与复苏：1973 - 2000 年* **1973 年：**第一个“AI 寒冬”开始，英国科学研究委员会的一份报告指出，这一领域的工作未能兑现其承诺，英国削减了对AI 研究的资助。在七十年代这十年的剩余时间里，AI 研究速度放缓。* **1980 年：**人工智能促进协会 (AAAI) 召开了第一次会议。对AI 研究的兴趣开始复苏。* **1982 年：**加州理工学院的 John Hopfield 向美国国家研究院提交了一篇关于在人工神经元之间使用双向连接的论文（以前一直都只使用了单向连接）。此外，日本启动了该国的第五代计算机系统项目(FGCS)，为 AI 研究提供了更多资金。* **1987 年：**第二个 AI 寒冬开始，在此期间，由于研究进展停滞不前，AI 研究的投资极少。* **1995 年：**Richard Wallace 开发了聊天机器人A.L.I.C.E.，它以 20 世纪60 年代的聊天机器人ELIZA 为基础。* **1997 年：**IBM 的超级计算机“深蓝”(Deep Blue) 在六局棋国际象棋比赛中击败了国际象棋大师加里•卡斯帕罗夫(Garry Kasparov)。#### 21 世纪：AI 热潮* **2002 年：**Roomba 机器人发布，这是最早具备完全自主功能的消费产品之一。* **2007 年：**计算机科学家 Geoffrey Hinton 发表了题为“Learning Multiple Layers of Representation”的论文，这是一篇在[深度学习] 方面具有重大意义的论文。\n* **2009 年：**研究员 Rajat Raina、Anand Madhavan 和Andrew Ng 共同发表了题为“Large-scale Deep Unsupervised Learning using Graphics Processors”的论文，文中指出 GPU 在机器学习方面优于CPU。未来几年，向 GPU 转变将会催生出比以往任何时候都更加强大的AI 模型。* **2011 年：**IBM 的自然语言处理器Watson 参加了美国智力竞猜电视节目*《危险边缘》(Jeopardy!)*并获胜。同一年，Apple 推出了首个广受欢迎的虚拟助手Siri。\n* **2012 年：**Google 研究员Jeff Dean 和Andrew Ng 训练一个神经网络，使其能够仅使用未标记的图像识别猫。大约在这个时候，“AI 热潮”开始了。* **2016 年：**Google 计算机程序AlphaGo 在围棋比赛中击败了围棋世界冠军李世石。* **2017 年：**Google 提出了Transformer 神经网络框架，这种架构为[大型语言模型 (LLM)] 的开发铺平了道路。\n* **2020 年：**OpenAI 发布了GPT-3，这是首批 LLM 之一。* **2021 年：**Google 发布了多任务统一模型(MUM)，这是一种由 AI 驱动的搜索算法，能够理解并生成语言。* **2022 年：**ChatGPT 4.0 版本正式发布可供大众使用，彻底改变了人们对AI 能力的理解。其他LLM，例如 Bard、Llama、Bing Chat 和Copilot，也相继发布。## 什么是AI 的“第三次浪潮”？凭借一系列硬件突破和进步，AI 在经历了数十年的缓慢发展和寒冬之后，近几年迎来了加速发展。行业观察人士认为，在这一轮AI 发展热潮中，三种类型的AI[浪潮] 相继快速成为主流，它们分别是：[预测式 AI] 、[生成式 AI] （例如 LLM），以及[代理式 AI] 。\n代理式AI 可以创建计算机程序，即使没有明确的指令，也能够自主执行任务，而且也无需基于提示的特定上下文。AI 代理可以自行决策，从过去的经验中学习，并相应地调整行动。因此，它们可以独立运行，或者只需极少的人工干预就能运行。## 未来AI 将会如何发展？近年来，新的发现和更强大的硬件帮助AI 获得了前所未有的能力。AI 的历史将会继续延续，未来或许会有更多激动人心的发展。Cloudflare 赋能开发人员，让其能够为AI 的发展史贡献自己的力量。凭借遍布全球的分布式无服务器AI 基础设施、免费的训练数据出口、分布式[矢量数据库] 和其他关键的 AI 构建块，Cloudflare 平台让开发人员能够利用最先进的AI 技术进行构建。[立即为 AI 发展史贡献自己的力量] 。\n*来源：*\n* *https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html*\n* *https://www.history.com/articles/7-early-robots-and-automatons*\n* *https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(07)00217-3*\n* *https://www.historyofinformation.com/detail.php?entryid=782*\n* *https://www.historyofinformation.com/detail.php?id=4137*\n* *https://www.techtarget.com/searchenterpriseai/definition/AI-winter*\n* *https://aaai.org/conference/aaai/aaai80/*\n* *https://blog.google/products/search/introducing-mum/*\n* *https://news.harvard.edu/gazette/story/2012/09/alan-turing-at-100/*\n开始使用* [Free 计划] \n* [小型企业计划] \n* [企业级服务] \n* [获得推荐] \n* [请求演示] \n* [联系销售] \n人工智能* [什么是人工智能 (AI)？] \n* [人工智能推理与训练] \n* [AI 发展史] \n机器学习* [什么是机器学习？] \n* [什么是深度学习？] \n* [什么是大型语言模型(LLM)？] \n* [低秩自适应 (LoRA)] \n* [AI 图像生成] \n大数据* [什么是嵌入？] \n* [什么是大数据？] \n* [如何构建 RAG 管道] \n词汇* [什么是 AI 安全？] \n* [向量数据库] \n* [预测式 AI] \n* [ChatGPT 插件] \n* [神经网络] \n* [什么是生成式 AI？] \n* [什么是自然语言处理 (NLP)？] \n* [AI 幻觉] \n* [AI 量化] \n* [OWASP Top 10 for LLM] \n* [AI 数据投毒] \n* [检索增强生成 (RAG)] \n* [什么是代理式 AI？] \n* [AI 的第三次浪潮] \n* [什么是氛围编码？] \n* [模型上下文协议 (MCP)] \n* [AI 在网络安全领域的应用] \n* [如何开始氛围编码] \n* [如何管理 AI 智能体] \n* [如何阻止 AI 爬网程序] \n* [如何防止抓取] \n* [如何保护 AI 系统] \n* [如何保护 AI 训练数据安全] \n学习中心* [安全性学习中心] \n* [CDN 学习中心] \n* [DDoS 学习中心] \n* [DNS 学习中心] \n* [性能学习中心] \n* [无服务器学习中心] \n* [SSL 学习中心] \n* [机器人学习中心] \n* [云学习中心] \n* [访问管理学习中心] \n* [网络层学习中心] \n* [隐私学习中心] \n* [视频流式传输学习中心] \n* [电子邮件安全性学习中心] \n* [学习中心主页] \n[] [] [] [] [] \n©2026Cloudflare 公司[隐私政策] [使用条款] [报告安全问题] [信任与安全]![privacy options] Cookie 首选项[商标]', 'doi': '', 'published_date': '2026-02-03T13:07:57.263619', 'pdf_url': '', 'url': 'https://www.cloudflare.com/zh-cn/learning/ai/history-of-ai/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的起源、发展和未来 - SK hynix Newsroom', 'authors': [], 'abstract': '人工智能的起源、发展和未来\n[![SK hynix Newsroom]] \n选择页面[] [] \n* [English] \n* [Chinese(中文)] \n* [Korean(한국어)] \n[] \n[![sk하이닉스 뉴스룸홈]] \n[] \n* [ENG] \n* [中文] \n* [KOR] \n[![sk하이닉스 뉴스룸홈]] \n[] \n[] \n[#CXL] [#DRAM] [#eSSD] [#HBM3E] [#HBM4] [#NAND] [#面向AI的存储器] \n[技术] [사용안함] \n# 人工智能的起源、发展和未来2024年10月14日\n分享[![닫기 버튼]] \n* [] \n* [] \n* [] \n![] \n能够像人类一样行走、说话和思考的人工智能机器人，过去常常是科幻漫画和电影中的热门题材。曾经只存在于人类想象中的人工智能和机器人，如今已不再是梦想，因为它正在走进现实并且改变着人们的日常生活。那么，人工智能始于何时，经历了怎样的演变，又会创造怎样的未来呢？### “人工智能”的起源与发展![人工智能发展的历史演变进程] \n人工智能发展的历史演变进程人工智能的起源可以追溯到20世纪50年代。1950年，英国数学家艾伦·图灵（Alan Turing）声称机器能够思考，并设计了“图灵测试（The Turing Test）”作为验证方法以佐证这个观点，这被认为是首次提出人工智能概念的研究。1956年，达特茅斯会议（Dartmouth Conference）召开，向世界介绍了人工智能的概念。会议讨论了机器能否像人类一样学习和发展，并首次使用了“人工智能”这一术语。\n在这一时期，人们对人工神经网络（Artificial Neural Network）模型的研究也很活跃。1957年，弗兰克·罗森布拉特（Frank Rosenblatt）用他的 &#8220;感知器（Perceptron）&#8221;模型实证了计算机可以识别和学习模式的概念，这是对&#8221;神经网络&#8221;理论的一次实践检验。“神经网络”理论是由神经生理学家沃伦·斯特吉斯·麦卡洛克（Warren Sturgis McCulloch）和沃尔特·皮茨（Walter Pitts）于1943年提出的，他们根据神经细胞的相互作用原理组建了一个简单的计算模型。尽管这些早期的研究成果引发了公众的期待，但由于计算能力、逻辑和数据缺乏等方面的限制，人工智能的研究很快就停滞不前。\n20世纪80年代出现了 &#8220;专家系统（Expert System）&#8221;，它可以根据人类输入的规则自动做出决策。“专家系统”在医学、法律和零售业等实用领域发挥的诊断、分类和分析等功能，暂时性地再度引起了人们对人工智能的关注。然而，该系统的局限性在于仅依赖人工设定的规则运行，缺乏理解现实世界的复杂性的能力，因此发展受到了限制。\n20世纪90年代，过去只能听从人类指令的人工智能，利用“机器学习（Machine Learning）”算法开始自主发现规则进行学习，这得益于数码技术及互联网的出现。有了来自网络的大量数据，人工智能可以自主学习规则，甚至发现人类无法发现的规则。基于“机器学习”的人工智能研究开始重新产出成果。\n### 人工智能的核心技术，&#8221;深度学习&#8221;的发展\n![人工神经网络和深度学习发展的时间线] \n人工神经网络和深度学习发展的时间线人工神经网络的早期研究在1969年进入了长期停滞期，因为人们发现先前提出的感知器模型无法有效解决非线性问题1。此后，重新将这一研究推向前沿的正是被誉为&#8221;深度学习之父&#8221;的杰弗里·辛顿（Geoffrey Hinton）。\n1986年，辛顿将反向传播算法2应用到由多层人工神经网络构成的多层感知器（Multi-Layer Perceptrons）理论中，证明其可以解决感知器存在的现有问题。这一举措重燃了人工神经网络研究的热情。然而，随着神经网络深度的增加，出现了学习过程和结果异常的问题。\n2006年，辛顿发表了题为《深度信念网络的快速学习算法（A Fast Learning Algorithm for Deep Belief Nets）》的论文，确立了深度学习的基本概念，并介绍了深度信念网络（DBN，Deep Belief Network），这种生成式模型可大幅提升多层感知器的性能。深度信念网络通过无监督学习3对每一层进行预训练，然后对整个网络进行微调，显著地提高了神经网络的学习速度和效率, 这一进展为未来深度学习的发展铺平了道路。1早期感知器模型为单层感知器（Single-layer Perceptron），不能处理XOR等非线性问题，处理这类问题时，在两个输入值相同时需输出0，而不同时则需输出1。\n2**反向传播（Backpropagation）**：神经网络中的一种算法，用于计算输出值与真实值之间的差值，并从输出值开始按相反顺序调整权重，以减少误差。\n3**无监督学习（Unsupervised Learning）**：机器学习中的一种学习理论，不给出输入数据的正确答案，而是让其发现和理解隐藏结构或模式的学习方法。\n![Kien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页] \nKien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页2012年，发生了一件历史性事件，证明了深度学习的卓越性能。由辛顿率领的AlexNet在图像识别挑战赛（ILSVRC, ImageNet Large Scale Visual Recognition Challenge）中夺得冠军。基于深度学习的AlexNet模型实现了84.7%的图像识别率，远超其他模型，值得一提的是，它将上一年冠军的错误率从25.8%降至16.4%。\n自2010年以来，深度学习已成为人工智能研究的主流，其迅速发展的背后有两个主要原因。首先是包括图形处理器（GPU ，Graphics Processing Unit）在内的计算机系统的进步。GPU最初是为处理计算机图形而创建的，与中央处理器（CPU ，Central Processing Unit）相比，GPU并行处理类似的重复运算速度更快。2010年，GPU通用计算（GPGPU ，General-Purpose computing on GPU）技术的出现，使GPU取代了CPU的角色。GPU的应用领域愈发广泛，特别是在训练人工神经网络方面，极大地加快了深度学习的发展。深度学习需要对海量训练数据进行分析以提取特征，并且需要进行迭代计算，而GPU具备的并行计算结构则非常适合这一需求。\n其次是由于数据量的增加，因为训练人工神经网络需要大量数据。过去，数据仅限于输入计算机的信息，但自20世纪90年代以来，随着互联网的普及和搜索引擎的发展，可处理的数据范围呈指数级增长。2000年以来，智能手机和物联网（IoT, Internet of Things）得到发展，催生了大数据（Big Data）的概念，现实世界到处都能实时收集数不清的数据。深度学习算法经过更多数据的训练后变得更加精细化，数据模式的转变无疑为深度学习技术奠定了基础。\n2016年，深度学习再次改变了世界。谷歌DeepMind开发的人工智能AlphaGo以4胜1负的比分战胜了围棋大师李世石九段，这一壮举让全世界都铭记人工智能的存在。AlphaGo是通过融合深度学习算法、强化学习（Reinforcement Learning）4和蒙特卡洛树搜索（MCTS，Monte Carlo Tree Search）5算法而创建的。借助此种方式，它能够进行数万次的自我对弈、自主学习，并模仿人类直觉以预测数值，甚至是制定战略。“战胜人类的AI”问世，标志着人工智能时代正式到来。\n4**强化学习（Reinforcement Learning）**：人工智能学习行为的方法之一，以奖励的形式告知行动结果，并且可以在特定情况下选择最佳行动的策略。\n5**蒙特卡洛树搜索（Monte Carlo tree search）**：一种通过反复生成一系列随机数来处理近似函数值的概率算法。 其功能是将目前情况下可选择的行为结构化为探索树，并通过随机模拟推论各行为的得失来决定最佳行为。### “生成式人工智能”热潮始于ChatGPT\n![生成式人工智能概念图] \n生成式人工智能概念图2022年末，人类迎来了人工智能技术的巨大变革。OpenAI推出了ChatGPT，由大语言模型（LLM，Large Language Model）6GPT（Generative Pre-trained Transformer）3.5驱动，标志着生成式人工智能时代的开启。生成式人工智能渗透到了曾被视为人类独有的“创作”领域，能够生成各种格式的高质量内容。它超越了基于数据进行预测或分类的深度学习层面，可根据用户需求，使用LLM或各种图像生成模型（如 VAE、GAN、扩散模型等），自行生成结果。\n6**大语言模型（Large Language Model）**：以海量数据基础，进行多种自然语言处理任务的深度学习算法。\n生成式人工智能的诞生可以追溯到2014年，当时伊恩·古德费洛（Ian Goodfellow）发布了生成对抗网络（GANs，Generative Adversarial Networks）模型，该模型由两个神经网络相互竞争学习的结构而组成。一个神经网络生成与真实数据无异的新数据，另一个神经网络将其与真实数据进行比较，并做出判断，随着这一竞争和判断的过程不断重复，生成的数据也越来越精细。随着时间推移，GANs模型不断得到修改和完善，目前已被广泛应用于图像生成和转换等多个领域中。\n2017年，名为Transformer的自然语言处理（NLP，Natural Language Processing）模型问世。Transformer将数据间的关系视为重要变量，通过对特定信息给予更多&#8221;关注&#8221;，它可以学习数据之间的复杂关系和模式，捕捉更多重要信息，从而产生更高质量的输出结果。Transformer模型为语言理解、机器翻译和交互系统等自然语言处理任务带来了革命性变化，尤其是它对前文提到的GPT等LLM的出现产生了重大影响。\nGPT于2018年首次发布，由于每年都会使用更多的参数和训练数据，其性能一直在飞速提升。2022年，搭载GPT 3.5的交互式人工智能系统ChatGPT发布，彻底改变了人工智能的模式。ChatGPT能通过理解用户对话的上下文来提供适当的回复，并回答各种问题。ChatGPT推出一周内，用户数量就突破了100万，两个月内活跃用户数量就超过了1亿，在全球范围内引发了爆炸性的关注。\n2023年，Open AI推出了GPT-4，再次实现技术飞跃。GPT-4使用的数据集约为GPT-3.5的500倍，已进化为大型多模态模型（LMM，Large Multimodal Model）7，可同时处理文本之外的图像、音频和视频等各种输入数据，并生成各种数据格式。随着ChatGPT引发的生成式人工智能热潮，各企业纷纷推出了多种生成式人工智能服务。其中，谷歌推出的可同时识别并理解文本、图像和音频的Gemini、Meta推出的能准确识别并分离出图像中特定对象的SAM，和Open AI推出的可根据文本提示制作视频的Sora等均为具有代表性的生成式人工智能。\n7**大型多模式模型（Large Multimodal Model）**：一种深度学习算法，除文本外，还可处理多种不同类型的数据，包括图像、音频等。\n生成式人工智能市场才刚刚起步。根据全球市场调研公司IDC（International Data Corporation）的报告，2024年生成式人工智能市场规模有望达到401亿美元，是上一年的2.7倍。同时，该报告还预测，该市场增长速度将逐年加快，到2027年有望达到1511亿美元。展望未来，生成式人工智能将超越软件，并转向硬件和互联网服务及其他领域。其性能和便利性也将不断提升，让更多人轻松使用。\n### 改变日常生活的人工智能，未来走向会如何？就如同2000年的谷歌搜索和2010年的移动社交媒体一样，人工智能正在成为焦点，成为整个社会新变化和新机遇的驱动力。其技术进步的速度前所未有，而在此过程中，人类面临的挑战和担忧也与日俱增。\n那么，“下一代生成式人工智能技术”将是什么呢？当前最受瞩目的未来人工智能技术无疑是“端侧AI（On-Device AI）”。通常情况下，人工智能服务需要与大型云服务器进行通信，将数据传输到边缘设备。然而，端侧AI往往可以通过在手机、个人电脑或其他电子设备上安装人工智能芯片组和小型LLM （sLLM, Smaller LLM）自主运行人工智能服务。这种替代方案不仅可以解决与运行人工智能相关的安全和资源问题，同时还可以提供更加个性化的人工智能服务。\n![云侧人工智能和端侧人工智能的架构比较] \n云侧人工智能和端侧人工智能的架构比较与端侧AI一样，未来人工智能也将搭载在更多的设备上，其形式也将不断进化。市场上已经出现了一些我们只在电影中见过的创新产品。美国人工智能初创公司Humane于2023年推出的AI Pin是一款可穿戴的人工智能设备，搭载激光墨水显示屏，可以将菜单投射到用户的手掌上。2024年，在CES上引起关注的Rabbit R1和Brilliant Labs推出的Frame，同样是具有创新性的人工智能可穿戴设备。此外，如苹果公司的Vision Pro和Meta公司的Quest等采用了人工智能技术的混合现实（MR, Mixed Reality）头戴式设备，正在开辟一个超越传统虚拟现实（VR，Virtual Reality）和元宇宙的新市场。\n科技的迅猛发展为人类创造了新的机遇，但同时也带来了一系列社会问题。人工智能技术的快速发展引起了人们的担忧，担心社会无法跟上这些技术进展的步伐。同时，在现实世界中出现了不少滥用人工智能的案例，制造精巧虚假内容导致大量假新闻的产生，加剧了社会混乱。最近，围绕着美国等多个面临大型选举的国家，人们对虚假视频和图片等&#8220;深度伪造（Deepfake）&#8221;内容泛滥的情况表示深切担忧。\n![生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱] \n生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱\n人工智能在开发和使用过程中可能存在一些风险因素。由于生成式人工智能会从网络上抓取并重新组合可公开获得的资料进行预训练，许多创作作品可能会成为抄袭对象。此外，人们还担心用相同的生成式人工智能程序并用相似的提示语所生成的内容可能会产生版权纠纷。人工智能不仅可以帮助人们完成工作、提高生产率，还有可能取代一些工作岗位，对劳动力市场结构带来改变，这种前景显然并不受欢迎。人工智能创造的世界已经超出了人类的想象。一个我们从未经历过的世界正在快速逼近。面对这突如其来的未来变革，我们该如何应对？为了做出正确的回应，我们需要深入理解和分析人工智能，并进行更具体的关注和社会讨论。TAG(#)\n[#AI] [#人工智能] [#机器学习] [#生成式人工智能] [#深度学习] \n分享* [] \n* [] \n* [![link]] \n## 相关帖子[![]] \n商业사용안함## [SK海力士都承勇副社长荣获铜塔产业勋章：“以基于AI/DT的智能工厂，提升HBM等制造技术的竞争力”] \n2025年5月2日\n[![]] \n技术## [[Rulebreakers’ Revolutions]SK海力士的SOM如何引领AI时代的下一代存储器发展] \n2025年4月1日\n[![]] \n新闻稿사용안함## [SK海力士将在GTC 2025上展示业界顶级存储器技术实力] \n2025年3月18日\n[![]] \n技术사용안함## [[Rulebreakers’ Revolutions] CXL技术如何在人工智能时代扩展数据中心存储容量的极限] \n2025年1月24日\n[![]] \n商业사용안함## [[CES 2025视频] 与SK海力士携手掀起人工智能浪潮] \n2025年1月10日\n[![]] \n商业사용안함## [SK海力士在CES 2025展示人工智能驱动的创新成果，助力可持续未来] \n2025年1月7日\n[] \n分享* [] \n* [] \n* [![link]] \n搜索', 'doi': '', 'published_date': '2024-10-14T00:00:00+00:00', 'pdf_url': '', 'url': 'https://news.skhynix.com.cn/all-about-ai-the-origins-evolution-future-of-ai/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 13:08:19,291 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 13:08:19,292 - __main__ - INFO - handle_download: downloaded=4
2026-02-03 13:08:19,292 - __main__ - INFO - call_tool payload: source_tool=exa_context_download, result_type=papers, count=4
2026-02-03 13:08:19,293 - __main__ - INFO - call_tool: name=exa_context_download, result_type=papers, count=4
2026-02-03 13:08:19,293 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能发展简史', 'authors': [], 'abstract': '人工智能发展简史\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能发展简史2017年01月23日 11:10来源：\n网络传播杂志[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n“人工智能之父”艾伦·图灵。**1、 人工智能的诞生（20世纪40～50年代）**\n1950年：图灵测试\n1950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n1954年：第一台可编程机器人诞生\n1954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n1956年：人工智能诞生\n1956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n1966年\\~1972年：首台人工智能机器人Shakey诞生\n1966年\\~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n1966年：世界上第一个聊天机器人ELIZA发布\n美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n1968年：计算机鼠标发明\n1968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n**3、 人工智能的低谷（20世纪70～80年代）**\n20世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n![] \n1997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n**4、 人工智能的繁荣期（1980年\\~1987年）**\n1981年：日本研发人工智能计算机\n1981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n1984年：启动Cyc（大百科全书）项目\n在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n1986年：3D打印机问世\n美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n**5、 人工智能的冬天（1987年\\~1993年）**\n“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n**6、 人工智能真正的春天（1993年至今）**\n1997年：电脑深蓝战胜国际象棋世界冠军\n1997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n2011年：开发出使用自然语言回答问题的人工智能程序\n2011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n2012年：Spaun诞生\n加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n2013年：深度学习算法被广泛运用在产品开发中\nFacebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n2015年：人工智能突破之年\nGoogle开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n2016年：AlphaGo战胜围棋世界冠军李世石\n2016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）![] \n2016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n**大事记**\n①1942年：“机器人三定律”提出\n美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。②1956年：人工智能的诞生\n达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n③1959年：第一代机器人出现\n德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n④1965年：兴起研究“有感觉”的机器人\n约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n⑤1968年：世界第一台智能机器人诞生\n美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n⑥2002年：家用机器人诞生\n美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n⑦2014年：机器人首次通过图灵测试\n在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n⑧2016年：AlphaGo打败人类\n2016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': '2017-01-23T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'save_path': '/home/qinshan/widthresearch/data/downloads/exa_人工智能发展简史.md'}}
2026-02-03 13:08:19,354 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '人工智能的创新发展与社会影响 - 中国人大网', 'authors': [], 'abstract': '当前位置：[首页](../../../../)\xa0>\xa0 [常委会专题讲座](../../node_541.htm)\n\n## 十三届全国人大常委会专题讲座第七讲\n\n# 人工智能的创新发展与社会影响\n\n浏览字号： [大](#) [中](#) [小](#) 来源： 中国人大网 2018年10月29日 10:26:09\n\n1956年人工智能（Artificial Intelligence，简称AI）的概念被正式提出，标志着人工智能学科的诞生，其发展目标是赋予机器类人的感知、学习、思考、决策和行动等能力。经过60多年的发展，人工智能已取得突破性进展，在经济社会各领域开始得到广泛应用并形成引领新一轮产业变革之势，推动人类社会进入智能化时代。美国、日本、德国、英国、法国、俄罗斯等国家都制定了发展人工智能的国家战略，我国也于2017年发布了《新一代人工智能发展规划》，发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏等地政府也相继出台推动人工智能发展的相关政策文件，社会各界对人工智能的重大战略意义已形成广泛共识。\n\n总体上看，已过花甲之年的人工智能当前的发展具有“四新”特征：以深度学习为代表的人工智能核心技术取得新突破、“智能+”模式的普适应用为经济社会发展注入新动能、人工智能成为世界各国竞相战略布局的新高地、人工智能的广泛应用给人类社会带来法律法规、道德伦理、社会治理等方面一系列的新挑战。因此人工智能这个机遇与挑战并存的新课题引起了全球范围内的广泛关注和高度重视。虽然人工智能未来的创新发展还存在不确定性，但是大家普遍认可人工智能的蓬勃兴起将带来新的社会文明，将推动产业变革，将深刻改变人们的生产生活方式，将是一场影响深远的科技革命。\n\n为了客观认识人工智能的本质内涵和创新发展，本报告在简要介绍人工智能基本概念与发展历程的基础上，着重分析探讨人工智能的发展现状和未来趋势，试图揭示人工智能的真实面貌。很显然，在当下人工智能蓬勃发展的历史浪潮中如何选择中国路径特别值得我们深入思考和探讨。因此，本报告最后就我国人工智能发展态势、存在问题和对策建议也进行了阐述。\n\n二、人工智能的发展历程与启示\n\n1956年夏，麦卡锡（John McCarthy）、明斯基（Marvin Minsky）、罗切斯特（Nathaniel Rochester）和香农（Claude Shannon）等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能”这一概念，标志着人工智能学科的诞生。人工智能的目标是模拟、延伸和扩展人类智能，探寻智能本质，发展类人智能机器。人工智能充满未知的探索道路曲折起伏，如何描述1956年以来60余年的人工智能发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能60余年的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年-20世纪60年代初。人工智能概念在1956年首次被提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、LISP表处理语言等，掀起了人工智能发展的第一个高潮。\n\n二是反思发展期：60年代-70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入了低谷。\n\n三是应用发展期：70年代初-80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入了应用发展的新高潮。\n\n四是低迷发展期：80年代中-90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：90年代中-2010年。由于网络技术特别是互联网技术的发展，信息与数据的汇聚不断加速，互联网应用的不断普及加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年IBM深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念，这些都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年-至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器（Graphics Processing Unit，简称GPU）等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越科学与应用之间的“技术鸿沟”，图像分类、语音识别、知识问答、人机对弈、无人驾驶等具有广阔应用前景的人工智能技术突破了从“不能用、不好用”到“可以用”的技术瓶颈，人工智能发展进入爆发式增长的新高潮。\n\n通过总结人工智能发展历程中的经验和教训，我们可以得到以下启示：\n\n（一）尊重学科发展规律是推动学科健康发展的前提。科学技术的发展有其自身的规律，顺其者昌，违其者衰。人工智能学科发展需要基础理论、数据资源、计算平台、应用场景的协同驱动，当条件不具备时很难实现重大突破。\n\n（二）基础研究是学科可持续发展的基石。加拿大多伦多大学杰弗里·辛顿（Geoffrey Hinton）教授坚持研究深度神经网络30年，奠定人工智能蓬勃发展的重要理论基础。谷歌的DeepMind团队长期深入研究神经科学启发的人工智能等基础问题，取得了阿尔法狗等一系列重大成果。\n\n（三）应用需求是科技创新的不竭之源。引领学科发展的动力主要来自于科学和需求的双轮驱动。人工智能发展的驱动力除了知识与技术体系内在矛盾外，贴近应用、解决用户需求是创新的最大源泉与动力。比如专家系统人工智能实现了从理论研究走向实际应用的突破，近些年来安防监控、身份识别、无人驾驶、互联网和物联网大数据分析等实际应用需求带动了人工智能的技术突破。\n\n（四）学科交叉是创新突破的“捷径”。人工智能研究涉及信息科学、脑科学、心理科学等，上世纪50年代人工智能的出现本身就是学科交叉的结果。特别是脑认知科学与人工智能的成功结合，带来了人工智能神经网络几十年的持久发展。智能本源、意识本质等一些基本科学问题正在孕育重大突破，对人工智能学科发展具有重要促进作用。\n\n（五）宽容失败应是支持创新的题中应有之义。任何学科的发展都不可能一帆风顺，任何创新目标的实现都不会一蹴而就。人工智能60余载的发展生动地诠释了一门学科创新发展起伏曲折的历程。可以说没有过去发展历程中的“寒冬”就没有今天人工智能发展新的春天。\n\n（六）实事求是设定发展目标是制定学科发展规划的基本原则。达到全方位类人水平的机器智能是人工智能学科宏伟的终极目标，但是需要根据科技和经济社会发展水平来设定合理的阶段性研究目标，否则会有挫败感从而影响学科发展，人工智能发展过程中的几次低谷皆因不切实际的发展目标所致。\n\n三、人工智能的发展现状与影响\n\n人工智能经过60多年的发展，理论、技术和应用都取得了重要突破，已成为推动新一轮科技和产业革命的驱动力，深刻影响世界经济、政治、军事和社会发展，日益得到各国政府、产业界和学术界的高度关注。从技术维度来看，人工智能技术突破集中在专用智能，但是通用智能发展水平仍处于起步阶段；从产业维度来看，人工智能创新创业如火如荼，技术和商业生态已见雏形；从社会维度来看，世界主要国家纷纷将人工智能上升为国家战略，人工智能社会影响日益凸显。\n\n（一）专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定领域的人工智能技术（即专用人工智能）由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，因此形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域，统计学习是专用人工智能走向实用的理论基础。深度学习、强化学习、对抗学习等统计机器学习理论在计算机视觉、语音识别、自然语言理解、人机博弈等方面取得成功应用。例如，阿尔法狗在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，语音识别系统5.1%的错误率比肩专业速记员，人工智能系统诊断皮肤癌达到专业医生水平，等等。\n\n（二）通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。虽然包括图像识别、语音识别、自动驾驶等在内的专用人工智能领域已取得突破性进展，但是通用智能系统的研究与应用仍然是任重而道远，人工智能总体发展水平仍处于起步阶段。美国国防高级研究计划局（Defense Advanced Research Projects Agency，简称DARPA）把人工智能发展分为三个阶段：规则智能、统计智能和自主智能，认为当前国际主流人工智能水平仍然处于第二阶段，核心技术依赖于深度学习、强化学习、对抗学习等统计机器学习，AI系统在信息感知（Perceiving）、机器学习（Learning）等智能水平维度进步显著，但是在概念抽象（Abstracting）和推理决策（Reasoning）等方面能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n（三）人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，在其2017年的年度开发者大会上，谷歌明确提出发展战略从“Mobile First”（移动优先）转向“AI First”（AI优先）；微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿，麦肯锡报告2016年全球人工智能研发投入超300亿美元并处于高速增长，全球知名风投调研机构CB Insights报告显示2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n（四）创新生态布局成为人工智能产业发展的战略高地。信息技术（IT）和产业的发展史就是新老IT巨头抢滩布局IT创新生态的更替史。例如，传统信息产业IT（Information Technology）代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网IT（Internet Technology）代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等，目前智能科技IT（Intelligent Technology）的产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动AI技术生态的研发布局，全力抢占人工智能相关产业的制高点。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理GPU服务器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。在技术生态方面，人工智能算法、数据、图形处理器（Graphics Processing Unit，简称GPU）/张量处理器（Tensor Processing Unit，简称TPU）/神经网络处理器（Neural network Processing Unit，NPU）计算、运行/编译/管理等基础软件已有大量开源资源，例如谷歌的TensorFlow第二代人工智能学习系统、脸书的PyTorch深度学习框架、微软的DMTK分布式学习工具包、IBM的SystemML开源机器学习系统等；此外谷歌、IBM、英伟达、英特尔、苹果、华为、中国科学院等积极布局人工智能领域的计算芯片。在人工智能商业和应用生态布局方面，“智能+X”成为创新范式，例如“智能+制造”、“智能+医疗”、“智能+安防”等，人工智能技术向创新性的消费场景和不同行业快速渗透融合并重塑整个社会发展，这是人工智能作为第四次技术革命关键驱动力的最主要表现方式。人工智能商业生态竞争进入白热化，例如智能驾驶汽车领域的参与者既有通用、福特、奔驰、丰田等传统龙头车企，又有互联网造车者如谷歌、特斯拉、优步、苹果、百度等新贵。\n\n（五）人工智能上升为世界主要国家的重大发展战略。人工智能正在成为新一轮产业变革的引擎，必将深刻影响国际产业竞争格局和一个国家的国际竞争力。世界主要发达国家纷纷把发展人工智能作为提升国际竞争力、维护国家安全的重大战略，加紧积极谋划政策，围绕核心技术、顶尖人才、标准规范等强化部署，力图在新一轮国际科技竞争中掌握主导权。无论是德国的“工业4.0”、美国的“工业互联网”、日本的“超智能社会”、还是我国的“中国制造2025”等重大国家战略，人工智能都是其中的核心关键技术。2017年7月，国务院发布了《新一代人工智能发展规划》，开启了我国人工智能快速创新发展的新征程。\n\n（六）人工智能的社会影响日益凸显。人工智能的社会影响是多元的，既有拉动经济、服务民生、造福社会的正面效应，又可能出现安全失控、法律失准、道德失范、伦理失常、隐私失密等社会问题，以及利用人工智能热点进行投机炒作从而存在泡沫风险。首先，人工智能作为新一轮科技革命和产业变革的核心力量，促进社会生产力的整体跃升，推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域发展积极正面影响。与此同时，我们也要看到人工智能引发的法律、伦理等问题日益凸显，对当下的社会秩序及公共管理体制带来了前所未有的新挑战。例如，2016年欧盟委员会法律事务委员会提交一项将最先进的自动化机器人身份定位为“电子人（electronic persons）”的动议，2017年沙特阿拉伯授予机器人“索菲亚”公民身份，这些显然冲击了传统的民事主体制度。那么，是否应该赋予人工智能系统法律主体资格？另外在人工智能新时代，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题都需要我们从法律法规、道德伦理、社会管理等多个角度提供解决方案。\n\n由于人工智能与人类智能密切关联且应用前景广阔、专业性很强，容易造成人们的误解，也带来了不少炒作。例如，有些人错误地认为人工智能就是机器学习（深度学习），人工智能与人类智能是零和博弈，人工智能已经达到5岁小孩的水平，人工智能系统的智能水平即将全面超越人类水平，30年内机器人将统治世界，人类将成为人工智能的奴隶，等等。这些错误认识会给人工智能的发展带来不利影响。还有不少人对人工智能预期过高，以为通用智能很快就能实现，只要给机器人发指令就可以干任何事。另外，有意炒作并通过包装人工智能概念来谋取不当利益的现象时有发生。因此，我们有义务向社会大众普及人工智能知识，引导政府、企业和广大民众科学客观地认识和了解人工智能。\n\n四、人工智能的发展趋势与展望\n\n人工智能经过六十多年的发展突破了算法、算力和算料（数据）等“三算”方面的制约因素，拓展了互联网、物联网等广阔应用场景，开始进入蓬勃发展的黄金时期。从技术维度看，当前人工智能处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有数据、能耗、泛化、可解释性、可靠性、安全性等诸多瓶颈，创新发展空间巨大，从专用到通用智能，从机器智能到人机智能融合，从“人工+智能”到自主智能，后深度学习的新理论体系正在酝酿；从产业和社会发展维度看，人工智能通过对经济和社会各领域渗透融合实现生产力和生产关系的变革，带动人类社会迈向新的文明，人类命运共同体将形成保障人工智能技术安全、可控、可靠发展的理性机制。总体而言，人工智能的春天刚刚开始，创新空间巨大，应用前景广阔。\n\n（一）从专用智能到通用智能。如何实现从狭义或专用人工智能（也称弱人工智能，具备单一领域智能）向通用人工智能（也称强人工智能，具备多领域智能）的跨越式发展，既是下一代人工智能发展的必然趋势，也是国际研究与应用领域的挑战问题。2016年10月美国国家科学技术委员会发布了《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。DeepMind创始人戴密斯·哈萨比斯（Demis Hassabis）提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年7月成立了通用人工智能实验室，100多位感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n（二）从人工智能到人机混合智能。人工智能的一个重要研究方向就是借鉴脑科学和认知科学的研究成果，研究从智能产生机理和本质出发的新型智能计算模型与方法，实现具有脑神经信息处理机制和类人智能行为与智能水平的智能系统。在美国、欧盟、日本等国家和地区纷纷启动的脑计划中，类脑智能已成为核心目标之一。英国工程与自然科学研究理事会EPSRC发布并启动了类脑智能研究计划。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。人机混合智能得到了我国新一代人工智能规划、美国脑计划、脸书（脑机语音文本界面）、特斯拉汽车创始人埃隆·马斯克（人脑芯片嵌入和脑机接口）等的高度关注。\n\n（三）从“人工+智能”到自主智能系统。当前人工智能的研究集中在深度学习，但是深度学习的局限是需要大量人工干预：人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据（非常费时费力）、用户需要人工适配智能系统等。因此已有科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类AI”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低AI人员成本。\n\n（四）人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、材料等传统科学的发展。例如，2018年美国麻省理工学院启动的“智能探究计划”（MIT Intelligence Quest）就联合了五大学院进行协同攻关。\n\n（五）人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来十年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，在现有基础上能够提高劳动生产率40%；美、日、英、德、法等12个发达国家（现占全球经济总量的一半）到2035年，年经济增长率平均可以翻一番。2018年麦肯锡的研究报告表明到2030年人工智能新增经济规模将达到13万亿美元。\n\n（六）人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出未来五年人工智能提升各行业运转效率，其中教育业提升82%，零售业71%，制造业64%，金融业58%。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n（七）人工智能领域的国际竞争将日趋激烈。“未来谁率先掌握人工智能，谁就能称霸世界”。2018年4月，欧盟委员会计划2018-2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略》重点推动物联网建设和人工智能的应用。世界军事强国已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即提出谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n（八）人工智能的社会学将提上议程。水能载舟，亦能覆舟。任何高科技也都是一把双刃剑。随着人工智能的深入发展和应用的不断普及，其社会影响日益明显。人工智能应用得当、把握有度、管理规范，就能有效控制负面风险。为了确保人工智能的健康可持续发展并确保人工智能的发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，深入分析人工智能对未来经济社会发展的可能影响，制定完善的人工智能法律法规，规避可能风险，确保人工智能的正面效应。2017年9月，联合国犯罪和司法研究所(UNICRI)决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。2018年4月，欧洲25个国家签署了《人工智能合作宣言》，从国家战略合作层面来推动人工智能发展，确保欧洲人工智能研发的竞争力，共同面对人工智能在社会、经济、伦理及法律等方面的机遇和挑战。\n\n五、我国人工智能的发展态势与思考\n\n我国当前人工智能发展的总体态势良好。中国信通院联合高德纳咨询公司（Gartner）于2018年9月发布的《2018世界人工智能产业发展蓝皮书》报告统计，我国（不含港澳台地区）人工智能企业总数位列全球第二（1040家），仅次于美国（2039家）。在人工智能总体水平和应用方面，我国也处于国际前列，发展潜力巨大，有望率先突破成为全球领跑者。但是我们也要清醒地看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n一是高度重视。党和国家高度重视并大力发展人工智能。党的十八大以来，习近平总书记把创新摆在国家发展全局的核心位置，高度重视人工智能发展，多次谈及人工智能的重要性，为人工智能如何赋能新时代指明方向。2016年7月习总书记明确指出，人工智能技术的发展将深刻改变人类社会生活，改变世界，应抓住机遇，在这一高技术领域抢占先机。在党的十九大报告中，习总书记强调“要推动互联网、大数据、人工智能和实体经济深度融合”。在2018年两院院士大会上，习总书记再次强调要“推进互联网、大数据、人工智能同实体经济深度融合，做大做强数字经济”。在2017年和2018年的《政府工作报告》中，李克强总理都提到了要加强新一代人工智能发展。2017年7月，国务院发布了《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动，人工智能将成为今后一段时期的国家重大战略。发改委、工信部、科技部、教育部、中央网信办等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n二是态势喜人。根据2017年爱思唯尔（Elsevier）文献数据库SCOPUS统计结果，我国在人工智能领域发表的论文数量已居世界第一。从2012年开始，我国在人工智能领域新增专利数量已经开始超越美国。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成全球人工智能投融资规模最大国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。近两年，清华大学、北京大学、中国科学院大学、浙江大学、上海交通大学、南京大学等高校纷纷成立人工智能学院。2015年开始的中国人工智能大会（CCAI）已连续成功召开四届、规模不断扩大，人工智能领域的教育、科研与学术活动层出不穷。\n\n三是差距不小。我国人工智能在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在较大差距。英国牛津大学2018年的一项研究报告指出中国的人工智能发展能力大致为美国的一半水平。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，存在“头重脚轻”的不均衡现象。在Top700全球AI人才中，中国虽然名列第二，但入选人数远远低于占一半数量的美国。据领英《全球AI领域人才报告》统计，截至2017年一季度全球人工智能领域专业技术人才数量超过190万，其中美国超过85万，我国仅超过5万人，排名全球第7位。2018年市场研究顾问公司Compass Intelligence对全球100多家AI计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国制定完善人工智能相关法律法规的进程需要加快，对可能产生的社会影响还缺少深度分析。\n\n四是前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出到2030年，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n人类社会已开始迈入智能化时代，人工智能引领社会发展是大势所趋，不可逆转。经历六十余年积累后，人工智能开始进入爆发式增长的红利期。伴随着人工智能自身的创新发展和向经济社会的全面渗透，这个红利期将持续相当长的时期。现在是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧需要深入思考。\n\n（一）树立理性务实的发展理念。围棋人机大战中阿尔法狗战胜李世石后，社会大众误以为人工智能已经无所不能，一些地方政府、社会企业、风险资金因此不切实际一窝蜂发展人工智能产业，一些别有用心的机构则有意炒作并通过包装人工智能概念来谋取不当利益。这种“一拥而上、一哄而散”的跟风行为不利于人工智能的健康可持续发展。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。根据高德纳咨询公司发布的技术发展曲线，当前智能机器人、认知专家顾问、机器学习、自动驾驶等人工智能热门技术与领域正处于期望膨胀期，但是通用人工智能及人工智能的整体发展仍处于初步阶段，人工智能还有很多“不能”，实现机器在任意现实环境的自主智能和通用智能仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此发展人工智能不能以短期牟利为目的，要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，并务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n（二）加强基础扎实的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。在此发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。根据2017年爱思唯尔文献数据库SCOPUS统计结果，尽管我国在人工智能领域发表的论文数量已经排名世界第一，但加权引文影响力则只排名34位。为了客观评价我国在人工智能基础研究方面的整体实力，我们搜索了SCI期刊、神经信息处理系统大会（Conference on Neural Information Processing Systems，简称NIPS）等主流人工智能学术会议关于通用智能、深度学习、类脑智能、脑智融合、人机博弈等关键词的论文统计情况，可以清楚看到在人工智能前沿方向中国与美国相比基础实力存在巨大差距：在高质量论文数量方面（按中科院划定的SCI一区论文标准统计），美国是中国的5.34倍（1325:248）；在人才储备方面（SCI论文通讯作者），美国是中国的2.12倍（4804:2267）。\n\n我国应对标国际最高水平，建设面向未来的人工智能基础科学研究中心，重点发展原创性、基础性、前瞻性、突破性的人工智能科学。应该鼓励科研人员瞄准人工智能学科前沿方向开展引领性原创科学研究，通过人工智能与脑认知、神经科学、心理学等学科的交叉融合，重点聚焦人工智能领域的重大基础性科学问题，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n（三）构建自主可控的创新生态。美国谷歌、IBM、微软、脸书等企业在AI芯片、服务器、操作系统、开源算法、云服务、无人驾驶等方面积极构建创新生态、抢占创新高地，已经在国际人工智能产业格局中占据先机。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。美国对中兴通讯发禁令一事充分说明自主可控“核高基”技术的重要性，我国应该吸取在核心电子器件、高端通用芯片及基础软件方面依赖进口的教训，避免重蹈覆辙，着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如军民融合、产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。\n\n另外，我们需要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过标准实施加速人工智能驱动经济社会转型升级的进程。\n\n（四）建立协同高效的创新体系。我国经济社会转型升级对人工智能有重大需求，但是单一的创新主体很难实现政策、市场、技术、应用等方面的全面突破。目前我国学术界、产业界、行业部门在人工智能发展方面各自为政的倾向比较明显，数据资源开放共享不够，缺少对行业资源的有效整合。相比而言，美国已经形成了全社会、全场景、全生态协同互动的人工智能协同创新体系，军民融合和产学研结合都做得很好。我国应在体制机制方面进一步改革创新，建立“军、政、产、学、研、用”一体的人工智能协同创新体系。例如，国家进行顶层设计和战略规划，举全国优势力量设立军事智能的研发和应用平台，提供“人工智能+X”行业融合、打破行业壁垒和行政障碍的激励政策；科技龙头企业引领技术创新生态建设，突破人工智能的重大技术瓶颈；高校科研机构进行人才培养和原始创新，着力构建公共数据资源与技术平台，共同建设若干标杆性的应用创新场景，推动成熟人工智能技术在城市、医疗、金融、文化、农业、交通、能源、物流、制造、安全、服务、教育等领域的深度应用，建设低成本高效益广范围的普惠型智能社会。\n\n（五）加快创新人才的教育培养。发展人工智能关键在人才，中高端人才短缺已经成为我国人工智能做大做强的主要瓶颈。另外，我国社会大众的人工智能科技素养也需要进一步提升，每一个人都需要去适应人工智能时代的科技浪潮。在加强人工智能领军人才培养引进的同时，要面向技术创新和产业发展多层次培养人工智能创新创业人才。《新一代人工智能发展规划》提出逐步开展全民智能教育项目，在中小学阶段设置人工智能课程。目前人工智能科普活动受到各地学校的欢迎，但是缺少通俗易懂的高质量人工智能科普教材、寓教于乐的实验设备和器材、开放共享的教学互动资源平台。国家相关部门应高度重视人工智能教育领域的基础性工作，增加投入，组织优势力量，加强高水平人工智能教育内容和资源平台建设，加快人工智能专业的教学师资培训，从教材、教具、教师等多个环节全面保障我国人工智能教育工作的开展。\n\n（六）推动共担共享的全球治理。人工智能将重塑全球政治和经济格局，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能将进一步拉大发达国家和发展中国家的生产力发展水平差距。美国、日本、德国等通过人工智能和机器人的技术突破和广泛应用弥补他们的人力成本劣势，希望制造业从新兴国家回流发达国家。目前看，我国是发展中国家阵容中唯一有望成为全球人工智能竞争中的领跑者，应采取不同于一些国家的“经济垄断主义、技术保护主义、贸易霸凌主义”路线，尽快布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合国家“一带一路”战略，向亚洲、非洲、南美等经济欠发达地区输出高水平、低成本的“中国智造”成果、提供人工智能时代的中国方案，为让人工智能时代的“智能红利”普惠人类命运共同体做出中国贡献！\n\n（七）制定科学合理的法律法规。要想实实在在收获人工智能带来的红利，首先应保证其安全、可控、可靠发展。美国和欧洲等发达国家和地区十分重视人工智能领域的法律法规问题。美国白宫多次组织这方面的研讨会、咨询会；特斯拉等产业巨头牵头成立OpenAI等机构，旨在以有利于整个人类的方式促进和发展友好的人工智能；科研人员自发签署23条“阿西洛马人工智能原则”，意图在规范人工智能科研及应用等方面抢占先机。我国在人工智能领域的法律法规制定及风险管控方面相对滞后，这种滞后局面与我国现阶段人工智能发展的整体形势不相适应，并可能成为我国人工智能下一步创新发展的一大掣肘。因此，有必要大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法规环境。\n\n（八）加强和鼓励人工智能社会学研究。人工智能的社会影响将是深远的、全方位的。我们当未雨绸缪，从国家安全、社会治理、就业结构、伦理道德、隐私保护等多个维度系统深入研究人工智能可能的影响，制定合理可行的应对措施，确保人工智能的正面效应。应大力加强人工智能领域的科普工作，打造科技与伦理的高效对话机制和沟通平台，消除社会大众对人工智能的误解与恐慌，为人工智能的发展营造理性务实、积极健康的社会氛围。\n\n六、结束语\n\n人工智能经过60多年的发展，进入了创新突破的战略机遇期和产业应用的红利收获期，必将对生产力和产业结构以及国际格局产生革命性影响，并推动人类进入普惠型智能社会。但是，我们需要清醒看到通用人工智能及人工智能的整体发展仍处于初级阶段，人工智能不是万能，人工智能还有很多“不能”。我们应当采取理性务实的发展路径，扎实推进基础研究、技术生态、人才培养、法律规范等方面的工作，在开放中创新，在创新中发展，全速跑赢智能时代，着力建设人工智能科技强国！\n\n（主讲人系中国科学院院士）\n\n责任编辑： 王伟\n\n[<< 返回首页](../../../../)\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'http://www.npc.gov.cn/zgrdw/npc/xinwen/2018-10/29/content_2065419.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9990601, 'save_path': None}}, {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '![](/static/images/icons/zhwiki-25.svg)\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n![自由的百科全书](/static/images/mobile/copyright/wikipedia-tagline-zh-25-hans.svg)\n\n## 目录\n\n# 人工智能史\n\n| [人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")系列内容 |\n| --- |\n|  |\n| 主要目标  * [知识表示](/wiki/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA "知识表示") * [自动规划](/w/index.php?title=%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92%E5%92%8C%E8%B0%83%E5%BA%A6&action=edit&redlink=1 "自动规划和调度（页面不存在）")（英语：[Automated planning and scheduling](https://en.wikipedia.org/wiki/Automated_planning_and_scheduling "en:Automated planning and scheduling")） * [机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习") * [语言处理](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理") * [电脑视觉](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89 "计算机视觉") * [机器人学](/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6 "机器人学") * [强人工智慧](/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "通用人工智慧") * [弱人工智慧](/wiki/%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "弱人工智慧") * [人工智能对齐](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%B9%E9%BD%90 "人工智能对齐") |\n| 实现方式  * [符号人工智能](/wiki/%E7%AC%A6%E8%99%9F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "符号人工智能") * [深度学习](/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0 "深度学习") * [贝氏网路](/wiki/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF "贝氏网路") * [进化算法](/wiki/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95 "进化算法") * [混合智能系统](/wiki/%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%B3%BB%E7%B5%B1 "混合智能系统")   + [混合专家模型](/wiki/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B "混合专家模型") * [生成式人工智慧](/wiki/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "生成式人工智慧") * [代理式人工智能](/w/index.php?title=%E4%BB%A3%E7%90%86%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "代理式人工智能（页面不存在）")（英语：[AI agent](https://en.wikipedia.org/wiki/AI_agent "en:AI agent")） |\n| [人工智能哲学](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%93%B2%E5%AD%B8 "人工智能哲学")  * [伦理](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BC%A6%E7%90%86&action=edit&redlink=1 "人工智能伦理（页面不存在）")（英语：[Ethics of artificial intelligence](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence "en:Ethics of artificial intelligence")） * [人工智能安全](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%89%E5%85%A8&action=edit&redlink=1 "人工智能安全（页面不存在）")（英语：[AI safety](https://en.wikipedia.org/wiki/AI_safety "en:AI safety")）   + [幻觉](/wiki/%E5%B9%BB%E8%A7%89_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD) "幻觉 (人工智能)")   + [存在风险](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%98%E5%9C%A8%E9%A3%8E%E9%99%A9&action=edit&redlink=1 "人工智能的存在风险（页面不存在）")（英语：[Existential risk from artificial general intelligence](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence "en:Existential risk from artificial general intelligence")） * [图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试") * [中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间") * [可解释人工智慧](/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "可解释人工智慧") * [友好的人工智能](/w/index.php?title=%E5%8F%8B%E5%A5%BD%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "友好的人工智能（页面不存在）")（英语：[Friendly artificial intelligence](https://en.wikipedia.org/wiki/Friendly_artificial_intelligence "en:Friendly artificial intelligence")） * [人工智能监管](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9B%91%E7%AE%A1&action=edit&redlink=1 "人工智能监管（页面不存在）")（英语：[Regulation of artificial intelligence](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence "en:Regulation of artificial intelligence")） |\n| 历史  * [时间轴](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E9%97%B4%E8%BD%B4&action=edit&redlink=1 "人工智能时间轴（页面不存在）")（英语：[Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence "en:Timeline of artificial intelligence")） * [发展](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95&action=edit&redlink=1 "人工智能发展（页面不存在）")（英语：[Progress in artificial intelligence](https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence "en:Progress in artificial intelligence")） * [专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统") * [人工智慧低谷](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷") * [人工智能热潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%83%AD%E6%BD%AE "人工智能热潮") * [人工智能法案](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B3%95%E6%A1%88 "人工智能法案") |\n| [人工智能的应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")  * [应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")   + [AlphaFold](/wiki/AlphaFold "AlphaFold")   + [深度伪造](/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%AA%E9%80%A0 "深度伪造")   + [AI艺术](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%97%9D%E8%A1%93 "人工智慧艺术")   + [音乐](/wiki/%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "音乐和人工智能")   + [医疗保健](/wiki/%E5%8C%BB%E7%96%97%E9%A2%86%E5%9F%9F%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "医疗领域的人工智能")   + [工业](/wiki/%E5%B7%A5%E4%B8%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "工业人工智能")   + [机器翻译](/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91 "机器翻译")   + [军事](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BB%8D%E5%82%99%E7%AB%B6%E8%B3%BD "人工智能军备竞赛") * [项目](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B9%E7%9B%AE%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能项目列表（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） * [编程语言](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能编程语言列表（页面不存在）")（英语：[List of programming languages for artificial intelligence](https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence "en:List of programming languages for artificial intelligence")） |\n| 主题与列表  * [主题](/wiki/Portal:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Portal:人工智能") * [术语表](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AF%E8%AF%AD%E8%A1%A8 "人工智能术语表") * [AI概述](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%BF%B0 "人工智能概述") * [AI公司列表](/w/index.php?title=List_of_artificial_intelligence_companies&action=edit&redlink=1 "List of artificial intelligence companies（页面不存在）")（英语：[List of artificial intelligence companies](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies "en:List of artificial intelligence companies")） * [AI项目列表](/w/index.php?title=List_of_artificial_intelligence_projects&action=edit&redlink=1 "List of artificial intelligence projects（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） |\n| * [查](/wiki/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template:人工智能") * [论](/wiki/Template_talk:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template talk:人工智能") * [编](/wiki/Special:EditPage/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Special:EditPage/Template:人工智能") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png/250px-Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png)\n\n**人工智能的历史**源远流长。在古代的[神话](/wiki/%E7%A5%9E%E8%A9%B1 "神话")[传说](/wiki/%E4%BC%A0%E8%AF%B4 "传说")中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](/wiki/%E9%9B%BB%E8%85%A6 "电脑")的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n\n1956年，[人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")的研究领域确立于在[达特茅斯学院](/wiki/%E8%BE%BE%E7%89%B9%E8%8C%85%E6%96%AF%E5%AD%A6%E9%99%A2 "达特茅斯学院")举行的[会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2]](#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")（也被称作AI之冬）。由于[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")爵士的批评和国会方面的压力，[美国](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3]](#cite_note-3)\n\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "强人工智慧")的机器至今仍未出现。[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4]](#cite_note-TuringQuote-4)\n\n在21世纪的第一个十年，[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n| [计算历史](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） |\n| --- |\n| [硬件](/wiki/%E7%A1%AC%E4%BB%B6 "硬件") |\n| * [1960年代之前](/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2 "计算机硬体历史") * [1960年代至今](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2_(1960%E5%B9%B4%E4%BB%A3%E8%87%B3%E4%BB%8A)&action=edit&redlink=1 "计算机硬体历史 (1960年代至今)（页面不存在）")（英语：[History of computing hardware (1960s–present)](https://en.wikipedia.org/wiki/History_of_computing_hardware_(1960s%E2%80%93present) "en:History of computing hardware (1960s–present)")） |\n| [软件](/wiki/%E8%BD%AF%E4%BB%B6 "软件") |\n| * [软体](/w/index.php?title=%E8%BB%9F%E9%AB%94%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体历史（页面不存在）")（英语：[History of software](https://en.wikipedia.org/wiki/History_of_software "en:History of software")） * [Unix](/w/index.php?title=Unix%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Unix历史（页面不存在）")（英语：[History of Unix](https://en.wikipedia.org/wiki/History_of_Unix "en:History of Unix")） * [自由和开源软件](/w/index.php?title=%E8%87%AA%E7%94%B1%E5%92%8C%E9%96%8B%E6%BA%90%E8%BB%9F%E4%BB%B6%E7%9A%84%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "自由和开源软件的历史（页面不存在）")（英语：[History of free and open-source software](https://en.wikipedia.org/wiki/History_of_free_and_open-source_software "en:History of free and open-source software")） |\n| [计算机科学](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6 "计算机科学") |\n| * 人工智能 * [编译器构造](/w/index.php?title=%E7%BC%96%E8%AF%91%E5%99%A8%E6%9E%84%E9%80%A0%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "编译器构造历史（页面不存在）")（英语：[History of compiler construction](https://en.wikipedia.org/wiki/History_of_compiler_construction "en:History of compiler construction")） * [计算机科学](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算机科学历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） * [操作系统](/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%86%E5%8F%B2 "操作系统历史") * [程式语言](/wiki/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80%E6%AD%B7%E5%8F%B2 "程式语言历史") * [杰出先驱者](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%85%88%E9%A9%B1%E8%80%85%E5%88%97%E8%A1%A8&action=edit&redlink=1 "计算机科学先驱者列表（页面不存在）")（英语：[List of pioneers in computer science](https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science "en:List of pioneers in computer science")） * [软体工程](/w/index.php?title=%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体工程历史（页面不存在）")（英语：[History of software engineering](https://en.wikipedia.org/wiki/History_of_software_engineering "en:History of software engineering")） |\n| 现代概念 |\n| * [通用CPU](/w/index.php?title=%E9%80%9A%E7%94%A8%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "通用中央处理器历史（页面不存在）")（英语：[History of general-purpose CPUs](https://en.wikipedia.org/wiki/History_of_general-purpose_CPUs "en:History of general-purpose CPUs")） * [图形用户界面](/wiki/%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2 "图形用户界面") * [互联网](/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%8E%86%E5%8F%B2 "互联网历史") * [个人电脑](/w/index.php?title=%E5%80%8B%E4%BA%BA%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "个人电脑历史（页面不存在）")（英语：[History of personal computers](https://en.wikipedia.org/wiki/History_of_personal_computers "en:History of personal computers")） * [笔记型电脑](/w/index.php?title=%E7%AD%86%E8%A8%98%E5%9E%8B%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "笔记型电脑历史（页面不存在）")（英语：[History of laptops](https://en.wikipedia.org/wiki/History_of_laptops "en:History of laptops")） * [电子游戏](/wiki/%E9%9B%BB%E5%AD%90%E9%81%8A%E6%88%B2%E5%8F%B2 "电子游戏史") * [全球资讯网](/w/index.php?title=%E5%85%A8%E7%90%83%E8%B3%87%E8%A8%8A%E7%B6%B2%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "全球资讯网历史（页面不存在）")（英语：[History of the World Wide Web](https://en.wikipedia.org/wiki/History_of_the_World_Wide_Web "en:History of the World Wide Web")） |\n| 按国家 |\n| * [保加利亚](/w/index.php?title=%E4%BF%9D%E5%8A%A0%E5%88%A9%E4%BA%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "保加利亚计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Bulgaria](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Bulgaria "en:History of computer hardware in Bulgaria")） * [波兰](/w/index.php?title=%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "波兰计算历史（页面不存在）")（英语：[History of computing in Poland](https://en.wikipedia.org/wiki/History_of_computing_in_Poland "en:History of computing in Poland")） * [罗马尼亚](/w/index.php?title=%E7%BD%97%E9%A9%AC%E5%B0%BC%E4%BA%9A%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "罗马尼亚计算历史（页面不存在）")（英语：[History of computing in Romania](https://en.wikipedia.org/wiki/History_of_computing_in_Romania "en:History of computing in Romania")） * [苏联集团国家](/w/index.php?title=%E8%8B%8F%E8%81%94%E9%9B%86%E5%9B%A2%E5%9B%BD%E5%AE%B6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联集团国家计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Soviet Bloc countries](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Soviet_Bloc_countries "en:History of computer hardware in Soviet Bloc countries")） * [苏联](/w/index.php?title=%E8%8B%8F%E8%81%94%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联计算历史（页面不存在）")（英语：[History of computing in the Soviet Union](https://en.wikipedia.org/wiki/History_of_computing_in_the_Soviet_Union "en:History of computing in the Soviet Union")） * [南斯拉夫](/w/index.php?title=%E5%8D%97%E6%96%AF%E6%8B%89%E5%A4%AB%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "南斯拉夫计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Yugoslavia](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Yugoslavia "en:History of computer hardware in Yugoslavia")） |\n| [计算年表](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "计算年表（页面不存在）")（英语：[Timeline of computing](https://en.wikipedia.org/wiki/Timeline_of_computing "en:Timeline of computing")） |\n| * [1950年之前](/w/index.php?title=1950%E5%B9%B4%E4%B9%8B%E5%89%8D%E7%9A%84%E8%AE%A1%E7%AE%97%E7%A1%AC%E4%BB%B6%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "1950年之前的计算硬件年表（页面不存在）")（英语：[Timeline of computing hardware before 1950](https://en.wikipedia.org/wiki/Timeline_of_computing_hardware_before_1950 "en:Timeline of computing hardware before 1950")） * [1950–1979](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1950%E2%80%931979)&action=edit&redlink=1 "计算年表 (1950–1979)（页面不存在）")（英语：[Timeline of computing 1950–1979](https://en.wikipedia.org/wiki/Timeline_of_computing_1950%E2%80%931979 "en:Timeline of computing 1950–1979")） * [1980–1989](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1980%E2%80%931989)&action=edit&redlink=1 "计算年表 (1980–1989)（页面不存在）")（英语：[Timeline of computing 1980–1989](https://en.wikipedia.org/wiki/Timeline_of_computing_1980%E2%80%931989 "en:Timeline of computing 1980–1989")） * [1990–1999](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1990%E2%80%931999)&action=edit&redlink=1 "计算年表 (1990–1999)（页面不存在）")（英语：[Timeline of computing 1990–1999](https://en.wikipedia.org/wiki/Timeline_of_computing_1990%E2%80%931999 "en:Timeline of computing 1990–1999")） * [2000–2009](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2000%E2%80%932009)&action=edit&redlink=1 "计算年表 (2000–2009)（页面不存在）")（英语：[Timeline of computing 2000–2009](https://en.wikipedia.org/wiki/Timeline_of_computing_2000%E2%80%932009 "en:Timeline of computing 2000–2009")） * [2010–2019](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2010%E2%80%932019)&action=edit&redlink=1 "计算年表 (2010–2019)（页面不存在）")（英语：[Timeline of computing 2010–2019](https://en.wikipedia.org/wiki/Timeline_of_computing_2010%E2%80%932019 "en:Timeline of computing 2010–2019")） * [更多年表……](/wiki/Category:%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8 "Category:计算年表") |\n| [计算机科学词汇](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E8%AF%8D%E6%B1%87&action=edit&redlink=1 "计算机科学词汇（页面不存在）")（英语：[Glossary of computer science](https://en.wikipedia.org/wiki/Glossary_of_computer_science "en:Glossary of computer science")） |\n| * [分类](/wiki/Category:%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B2 "Category:计算机历史") |\n| * [查](/wiki/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Template:计算历史") * [论](/w/index.php?title=Template_talk:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Template talk:计算历史（页面不存在）") * [编](/wiki/Special:EditPage/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Special:EditPage/Template:计算历史") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)\n\n## 先驱\n\n奥特曼写道[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](/wiki/%E8%87%AA%E5%8B%95%E6%A9%9F "自动机")）的实践之中。[[5]](#cite_note-FOOTNOTEMcCorduck20045–35-5)\n\n### 神话，幻想和预言中的AI\n\n[希腊神话](/wiki/%E5%B8%8C%E8%85%8A%E7%A5%9E%E8%AF%9D "希腊神话")中已经出现了机械人和人造人，如[赫淮斯托斯](/wiki/%E8%B5%AB%E6%B7%AE%E6%96%AF%E6%89%98%E6%96%AF "赫淮斯托斯")的黄金机器人和[皮格马利翁](/wiki/%E7%9A%AE%E6%A0%BC%E9%A9%AC%E5%88%A9%E7%BF%81 "皮格马利翁")的[伽拉忒亚](/wiki/%E4%BC%BD%E6%8B%89%E5%BF%92%E4%BA%9A "伽拉忒亚")。[[6]](#cite_note-6)中世纪出现了使用巫术或[炼金术](/wiki/%E7%82%BC%E9%87%91%E6%9C%AF "炼金术")将意识赋予无生命物质的传说，如[贾比尔](/wiki/%E8%B4%BE%E6%AF%94%E5%B0%94 "贾比尔")的*Takwin*，[帕拉塞尔苏斯](/wiki/%E5%B8%95%E6%8B%89%E5%A1%9E%E5%B0%94%E8%8B%8F%E6%96%AF "帕拉塞尔苏斯")的[何蒙库鲁兹](/wiki/%E4%BD%95%E8%92%99%E5%BA%93%E9%B2%81%E5%85%B9 "何蒙库鲁兹")和Judah Loew的[魔像](/wiki/%E9%AD%94%E5%83%8F "魔像")。[[7]](#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](/wiki/%E7%8E%9B%E4%B8%BD%C2%B7%E9%9B%AA%E8%8E%B1 "玛丽·雪莱")的《[弗兰肯斯坦](/wiki/%E5%BC%97%E5%85%B0%E8%82%AF%E6%96%AF%E5%9D%A6 "弗兰肯斯坦")》和[卡雷尔·恰佩克](/wiki/%E5%8D%A1%E9%9B%B7%E5%B0%94%C2%B7%E6%81%B0%E4%BD%A9%E5%85%8B "卡雷尔·恰佩克")的《罗素姆的万能机器人》。[[8]](#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9]](#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。\n\n### 自动人偶\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)\n\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师](/wiki/%E5%81%83%E5%B8%88 "偃师")（中国西周）[[10]](#cite_note-10)，[希罗](/wiki/%E5%B8%8C%E7%BD%97 "希罗")（希腊）[[11]](#cite_note-11)，[加扎利](/wiki/%E5%8A%A0%E6%89%8E%E5%88%A9 "加扎利")[[12]](#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13]](#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](/wiki/%E5%8F%A4%E5%9F%83%E5%8F%8A "古埃及")和[古希腊](/wiki/%E5%8F%A4%E5%B8%8C%E8%85%8A "古希腊")的[圣像](/wiki/%E8%81%96%E5%83%8F "圣像")，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")（[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")）写道“当发现神的本性时，人就能够重现他”[[14]](#cite_note-14)[[15]](#cite_note-15)。\n\n### 形式推理\n\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](/wiki/%E4%BA%9A%E9%87%8C%E5%A3%AB%E5%A4%9A%E5%BE%B7 "亚里士多德")（对三段论逻辑进行了形式分析），[欧几里得](/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97 "欧几里得")（其著作《[几何原本](/wiki/%E5%87%A0%E4%BD%95%E5%8E%9F%E6%9C%AC "几何原本")》是形式推理的典范），[花剌子密](/wiki/%E8%8A%B1%E5%89%8C%E5%AD%90%E5%AF%86 "花剌子密")（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E7%9A%84%E5%A8%81%E5%BB%89 "奥卡姆的威廉")和[邓斯·司各脱](/wiki/%E9%82%93%E6%96%AF%C2%B7%E5%8F%B8%E5%90%84%E8%84%B1 "邓斯·司各脱")。[[16]](#cite_note-Berlinski_2000-16)\n\n[马略卡](/wiki/%E9%A9%AC%E7%95%A5%E5%8D%A1 "马略卡")哲学家[拉蒙·柳利](/wiki/%E6%8B%89%E8%92%99%C2%B7%E6%9F%B3%E5%88%A9 "拉蒙·柳利")（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17]](#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18]](#cite_note-18)Llull的工作对[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")产生了很大影响，后者进一步发展了他的思想。[[19]](#cite_note-19)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/250px-Gottfried_Wilhelm_von_Leibniz.jpg)\n\n在17世纪中，[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")，[托马斯·霍布斯](/wiki/%E6%89%98%E9%A9%AC%E6%96%AF%C2%B7%E9%9C%8D%E5%B8%83%E6%96%AF "托马斯·霍布斯")和[笛卡儿](/wiki/%E7%AC%9B%E5%8D%A1%E5%84%BF "笛卡儿")尝试将理性的思考系统化为代数学或几何学那样的体系。[[20]](#cite_note-20)霍布斯在其著作《[利维坦](/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF) "利维坦 (霍布斯)")》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21]](#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](/wiki/%E9%80%9A%E7%94%A8%E8%A1%A8%E6%84%8F%E6%96%87%E5%AD%97 "通用表意文字")），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22]](#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n\n在20世纪，[数理逻辑](/wiki/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91 "数理逻辑")研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](/wiki/%E4%B9%94%E6%B2%BB%C2%B7%E5%B8%83%E5%B0%94 "乔治·布尔")的《思维的定律》与[弗雷格](/wiki/%E6%88%88%E7%89%B9%E6%B4%9B%E5%B8%83%C2%B7%E5%BC%97%E9%9B%B7%E6%A0%BC "戈特洛布·弗雷格")的《[概念文字](/wiki/%E6%A6%82%E5%BF%B5%E6%96%87%E5%AD%97 "概念文字")》。基于弗雷格的系统，[罗素](/wiki/%E7%BD%97%E7%B4%A0 "罗素")和[怀特海](/wiki/%E6%80%80%E7%89%B9%E6%B5%B7 "怀特海")在他们于1913年出版的巨著《[数学原理](/wiki/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86 "数学原理")》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9 "希尔伯特")，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16]](#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")，[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")和[Alonzo Church](/wiki/Alonzo_Church "Alonzo Church")的[λ演算](/wiki/%CE%9B%E6%BC%94%E7%AE%97 "Λ演算")给出。[[16]](#cite_note-Berlinski_2000-16)[[23]](#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)\n\n[邱奇-图灵论题](/wiki/%E9%82%B1%E5%A5%87-%E5%9B%BE%E7%81%B5%E8%AE%BA%E9%A2%98 "邱奇-图灵论题")暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16]](#cite_note-Berlinski_2000-16)[[24]](#cite_note-24)\n\n### 计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](/wiki/%E6%9F%A5%E5%B0%94%E6%96%AF%C2%B7%E5%B7%B4%E8%B4%9D%E5%A5%87 "查尔斯·巴贝奇")设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](/wiki/%E6%84%9B%E9%81%94%C2%B7%E5%8B%92%E8%8A%99%E8%95%BE%E7%B5%B2 "爱达·勒芙蕾丝")预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25]](#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%95%B0 "伯努利数")的方法。）\n\n第一批现代计算机是[二战](/wiki/%E4%BA%8C%E6%88%98 "二战")期间建造的大型译码机（包括Z3，[ENIAC](/wiki/ENIAC "ENIAC")和Colossus等）。[[26]](#cite_note-26)后两个机器的理论基础是[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")和[约翰·冯·诺伊曼](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC "约翰·冯·诺伊曼")提出和发展的学说。[[27]](#cite_note-27)\n\n## 人工智能的诞生：1943 - 1956\n\n[[28]](#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n### 控制论与早期神经网络\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/250px-BRL61-IBM_702.jpg)\n\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](/wiki/%E8%AF%BA%E4%BC%AF%E7%89%B9%C2%B7%E7%BB%B4%E7%BA%B3 "诺伯特·维纳")的[控制论](/wiki/%E6%8E%A7%E5%88%B6%E8%AE%BA "控制论")描述了电子网络的控制和稳定性。[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")提出的[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")则描述了[数字信号](/wiki/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7 "数字信号")（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29]](#cite_note-29)\n\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30]](#cite_note-30)\n\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")”的学者。[[31]](#cite_note-31)[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](/w/index.php?title=SNARC&action=edit&redlink=1 "SNARC（页面不存在）")。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n### 游戏AI\n\n1951年，[克里斯托弗·斯特雷奇](/wiki/%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%BC%97%C2%B7%E6%96%AF%E7%89%B9%E9%9B%B7%E5%A5%87 "克里斯托弗·斯特雷奇")使用[曼彻斯特大学](/wiki/%E6%9B%BC%E5%BD%BB%E6%96%AF%E7%89%B9%E5%A4%A7%E5%AD%A6 "曼彻斯特大学")的Ferranti Mark 1机器写出了一个[西洋跳棋](/wiki/%E8%A5%BF%E6%B4%8B%E8%B7%B3%E6%A3%8B "西洋跳棋")（checkers）程序；[迪特里希·普林茨](/w/index.php?title=%E8%BF%AA%E7%89%B9%E9%87%8C%E5%B8%8C%C2%B7%E6%99%AE%E6%9E%97%E8%8C%A8&action=edit&redlink=1 "迪特里希·普林茨（页面不存在）")（Dietrich Prinz）则写出了一个[国际象棋](/wiki/%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B "国际象棋")程序。[[32]](#cite_note-32)[亚瑟·李·塞谬尔](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E6%9D%8E%C2%B7%E5%A1%9E%E8%AC%AC%E7%88%BE "亚瑟·李·塞谬尔")（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33]](#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。\n\n### 图灵测试\n\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34]](#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试")：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35]](#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。\n\n### 符号推理与“逻辑理论家”程序\n\n50年代中期，随着数位计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36]](#cite_note-36)\n\n1955年，[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和后来荣获诺贝尔奖的[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")在J. C. Shaw的协助下开发了“[逻辑理论家](/wiki/%E9%80%BB%E8%BE%91%E7%90%86%E8%AE%BA%E5%AE%B6 "逻辑理论家")（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37]](#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](/wiki/%E5%BF%83%E8%BA%AB%E4%BA%8C%E5%88%86%E6%B3%95 "心身二分法")，解释了物质构成的系统如何获得心灵的性质。”[[38]](#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92 "约翰·罗杰斯·希尔勒")称为“强人工智能”，即机器可以像人一样具有思想。）[[39]](#cite_note-39)\n\n### 1956年达特茅斯会议：AI的诞生\n\n1956年[达特矛斯会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")[[40]](#cite_note-40)的组织者是[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")，[约翰·麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")和另两位资深科学家[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](/wiki/IBM "IBM")。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41]](#cite_note-41)与会者包括[雷·索罗门诺夫](/w/index.php?title=%E9%9B%B7%C2%B7%E7%B4%A2%E7%BE%85%E9%96%80%E8%AB%BE%E5%A4%AB&action=edit&redlink=1 "雷·索罗门诺夫（页面不存在）")（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42]](#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")则说服与会者接受“人工智能”一词作为本领域的名称。[[43]](#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44]](#cite_note-44)\n\n## 第一波浪潮 - 黄金年代：1956 - 1974\n\n[达特矛斯](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45]](#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46]](#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47]](#cite_note-47) [DARPA](/wiki/DARPA "DARPA")（[国防高等研究计划署](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")）等政府机构向这一新兴领域投入了大笔资金。[[48]](#cite_note-48)\n\n### 研究工作\n\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n#### 搜索式推理\n\n许多AI程序使用相同的基本[算法](/wiki/%E7%AE%97%E6%B3%95 "算法")。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95 "回溯法")。这就是“搜索式推理”。[[49]](#cite_note-49)\n\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95 "启发式算法")去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50]](#cite_note-50)\n\n艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](/wiki/%E4%B8%80%E8%88%AC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%99%A8 "一般问题解决器")（General Problem Solver）”程序，将这一算法推广到一般情形。[[51]](#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52]](#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](/wiki/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6 "斯坦福大学")为控制机器人Shakey而开发的STRIPS系统。[[53]](#cite_note-53)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)\n\n#### 自然语言\n\nAI研究的一个重要目标是使计算机能够通过[自然语言](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理")（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54]](#cite_note-54)\n\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](/wiki/%E8%AF%AD%E4%B9%89%E7%BD%91 "语义网")（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55]](#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56]](#cite_note-56)\n\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57]](#cite_note-57)\n\n#### 微世界\n\n60年代后期，[麻省理工大学](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")AI实验室的马文·闵斯基和[西摩尔·派普特](/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9 "西摩尔·派普特")建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58]](#cite_note-58)\n\n在这一指导思想下，[杰拉德·杰伊·萨斯曼](/wiki/%E5%82%91%E6%8B%89%E5%BE%B7%C2%B7%E5%82%91%E4%BC%8A%C2%B7%E8%96%A9%E6%96%AF%E6%9B%BC "杰拉德·杰伊·萨斯曼")（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](/w/index.php?title=%E5%A4%A7%E8%A1%9B%C2%B7%E7%93%A6%E7%88%BE%E8%8C%B2&action=edit&redlink=1 "大卫·瓦尔兹（页面不存在）")（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](/wiki/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89 "机器视觉")领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](/wiki/SHRDLU "SHRDLU")，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59]](#cite_note-59)\n\n### 乐观思潮\n\n第一代AI研究者们曾作出了如下预言:\n\n### 经费\n\n1963年6月，[MIT](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64]](#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](/wiki/%E5%8D%A1%E5%86%85%E5%9F%BA%E6%A2%85%E9%9A%86%E5%A4%A7%E5%AD%A6 "卡内基梅隆大学")的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65]](#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](/wiki/%E7%88%B1%E4%B8%81%E5%A0%A1%E5%A4%A7%E5%AD%A6 "爱丁堡大学")建立。[[66]](#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67]](#cite_note-67)\n\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68]](#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](/wiki/Hacker "Hacker")文化的形成，[[69]](#cite_note-69)但是好景不长。\n\n## 第一次AI低谷：1974 - 1980\n\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70]](#cite_note-70)同时，由于马文·闵斯基对[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")的激烈批评，[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")（即[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")）销声匿迹了十年。[[71]](#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](/wiki/%E9%80%BB%E8%BE%91%E7%BC%96%E7%A8%8B "逻辑编程")，常识推理等一些领域还是有所进展。[[72]](#cite_note-72)\n\n### 问题\n\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73]](#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74]](#cite_note-74)\n\n### 停止拨款\n\n由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81]](#cite_note-81)1973年[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82]](#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83]](#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84]](#cite_note-84)到了1974年已经很难再找到对AI项目的资助。\n\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85]](#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86]](#cite_note-86)\n\n### 来自大学的批评\n\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")已经证明[形式系统](/wiki/%E5%BD%A2%E5%BC%8F%E7%B3%BB%E7%BB%9F "形式系统")（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87]](#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88]](#cite_note-88)[[89]](#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间")”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](/wiki/%E6%84%8F%E5%90%91%E6%80%A7 "意向性")（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90]](#cite_note-90)\n\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](/wiki/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7 "计算复杂性")和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91]](#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92]](#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93]](#cite_note-93)\n\n约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94]](#cite_note-94)\n\n### 感知器与联结主义遭到冷落\n\n[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")是[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71]](#cite_note-Perceptrons-71)\n\n### “简约派（the neats）”：逻辑，Prolog语言和专家系统\n\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95]](#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96]](#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](/wiki/Prolog "Prolog")。[[97]](#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](/w/index.php?title=%E7%94%9F%E7%94%A2%E8%A6%8F%E5%89%87&action=edit&redlink=1 "生产规则（页面不存在）")（英语：[Production\\_system\\_(computer\\_science)](https://en.wikipedia.org/wiki/Production_system_(computer_science) "en:Production system (computer science)")）”密切相关的“[霍恩子句](/wiki/%E9%9C%8D%E6%81%A9%E5%AD%90%E5%8F%A5 "霍恩子句")”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](/wiki/%E6%84%9B%E5%BE%B7%E8%8F%AF%C2%B7%E8%B2%BB%E6%A0%B9%E9%AE%91%E5%A7%86 "爱德华·费根鲍姆")的[专家系统](/wiki/%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1 "专家系统")以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")及[认知统一理论](/wiki/%E8%AA%8D%E7%9F%A5%E7%B5%B1%E4%B8%80%E7%90%86%E8%AB%96 "认知统一理论")。[[98]](#cite_note-98)\n\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](/wiki/%E9%98%BF%E6%91%A9%E5%8F%B8%C2%B7%E7%89%B9%E6%B2%83%E6%96%AF%E5%9F%BA "阿摩司·特沃斯基")，Daniel Kahneman等人的实验证明了这一点。[[99]](#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100]](#cite_note-100)\n\n### “芜杂派（the scruffies）”：框架和脚本\n\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101]](#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102]](#cite_note-102)\n\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103]](#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n## 第二波浪潮 - 繁荣：1980—1987\n\n在80年代，一类名为“[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n### 专家系统获得赏识\n\n[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104]](#cite_note-104)\n\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105]](#cite_note-105)\n\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106]](#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107]](#cite_note-107)\n\n### 知识革命\n\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108]](#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109]](#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110]](#cite_note-110)\n\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111]](#cite_note-111)\n\n### 重获拨款：第五代工程\n\n1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](/wiki/%E7%AC%AC%E4%BA%94%E4%BB%A3%E9%9B%BB%E8%85%A6 "第五代电脑")项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112]](#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](/wiki/Prolog "Prolog")作为该项目的主要编程语言。[[113]](#cite_note-113)\n\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114]](#cite_note-114)[[115]](#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116]](#cite_note-116)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/250px-Hopfield-net.png)\n\n### 联结主义的重生\n\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 "反向传播算法")，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115]](#cite_note-Norvig_25-115)[[117]](#cite_note-117)\n\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86 "分布式并行处理")”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115]](#cite_note-Norvig_25-115)[[118]](#cite_note-118)\n\n## 第二次AI低谷：1987—1993\n\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n### 人工智慧的低谷\n\n“[AI之冬](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119]](#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120]](#cite_note-120)\n\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")）））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121]](#cite_note-121)\n\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122]](#cite_note-122)\n\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123]](#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123]](#cite_note-FifthGenEnd-123)\n\n### 躯体的重要性：Nouvelle AI与嵌入式推理\n\n80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124]](#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](/wiki/%E8%8E%AB%E6%8B%89%E7%B6%AD%E5%85%8B%E6%82%96%E8%AB%96 "莫拉维克悖论")）。[[125]](#cite_note-125)他们号召“[自底向上](/wiki/%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%92%8C%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%A8%AD%E8%A8%88 "自上而下和自下而上设计")”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。\n\n另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126]](#cite_note-126)\n\n在发表于1990年的论文“大象不玩象棋（Elephants Don\'t Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](/wiki/%E7%89%A9%E7%90%86%E7%AC%A6%E8%99%9F%E7%B3%BB%E7%B5%B1 "物理符号系统")”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127]](#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](/wiki/%E9%AB%94%E5%8C%96%E8%AA%8D%E7%9F%A5 "体化认知")（embodied mind/reason/cognition）”论题。[[128]](#cite_note-128)\n\n## 第三波浪潮 - 大数据与机器学习：1993—2019\n\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129]](#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。\n\n### 里程碑和摩尔定律\n\n1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](/wiki/%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BE%85%E5%A4%AB "卡斯帕罗夫")的第一个计算机系统。[[130]](#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131]](#cite_note-131)2009年，[蓝脑计画](/wiki/%E8%97%8D%E8%85%A6%E8%A8%88%E7%95%AB "蓝脑计画")声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](/w/index.php?title=IBM_%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%A8%8B%E5%BA%8F)&action=edit&redlink=1 "IBM 沃森 (人工智慧程序)（页面不存在）")参加《[危险边缘](/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98 "危险边缘")》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](/wiki/AlphaGo "AlphaGo")击败[李世乭](/wiki/%E6%9D%8E%E4%B8%96%E4%B9%AD "李世乭")，成为第一个不让子而击败职业[围棋](/wiki/%E5%9C%8D%E6%A3%8B "围棋")棋士的[电脑围棋](/wiki/%E7%94%B5%E8%84%91%E5%9B%B4%E6%A3%8B "电脑围棋")程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](/wiki/%E4%B8%AD%E5%9B%BD%E4%B9%8C%E9%95%87%E5%9B%B4%E6%A3%8B%E5%B3%B0%E4%BC%9A "中国乌镇围棋峰会")的三局比赛中击败[[132]](#cite_note-wuzhensecond-132)当时世界排名第一[[133]](#cite_note-133)[[134]](#cite_note-134)的中国棋手[柯洁](/wiki/%E6%9F%AF%E6%B4%81 "柯洁")。\n\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135]](#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136]](#cite_note-136)这种剧烈增长可以用[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n### 智能代理\n\n90年代，被称为“[智能代理](/wiki/%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86 "智能代理")”的新范式被广泛接受。[[137]](#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138]](#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139]](#cite_note-R27-139)当经济学中的“[理性代理](/wiki/%E7%90%86%E6%80%A7%E4%B8%BB%E4%BD%93 "理性主体")（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140]](#cite_note-140)\n\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](/w/index.php?title=%E4%BB%A3%E7%90%86%E6%9E%B6%E6%9E%84&action=edit&redlink=1 "代理架构（页面不存在）")（英语：[Agent\\_architecture](https://en.wikipedia.org/wiki/Agent_architecture "en:Agent architecture")）（像Newell的[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139]](#cite_note-R27-139)[[141]](#cite_note-141)\n\n### “简约派”的胜利\n\n越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142]](#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143]](#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144]](#cite_note-RN25-144)[[145]](#cite_note-145)\n\nJudea Pearl发表于1988年的名著[[146]](#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C "贝叶斯网络")，[隐马尔可夫模型](/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B "隐马尔可夫模型")，[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144]](#cite_note-RN25-144)\n\n### 幕后的AI\n\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147]](#cite_note-147)这些解决方案在产业界起到了重要作用。[[148]](#cite_note-148)应用了AI技术的有[数据挖掘](/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98 "数据挖掘")，[工业机器人](/wiki/%E5%B7%A5%E4%B8%9A%E6%9C%BA%E5%99%A8%E4%BA%BA "工业机器人")，[物流](/wiki/%E7%89%A9%E6%B5%81 "物流")[[149]](#cite_note-149)，[语音识别](/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB "语音识别")[[150]](#cite_note-150)，银行业软件[[151]](#cite_note-CNN7242006-151)，医疗诊断[[151]](#cite_note-CNN7242006-151)和[Google](/wiki/Google "Google")搜索引擎等。[[152]](#cite_note-152)\n\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153]](#cite_note-153)[尼克·博斯特罗姆](/wiki/%E5%B0%BC%E5%85%8B%C2%B7%E5%8D%9A%E6%96%AF%E7%89%B9%E7%BD%97%E5%A7%86 "尼克·博斯特罗姆")解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154]](#cite_note-154)\n\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](/wiki/%E4%BF%A1%E6%81%AF%E5%AD%A6 "信息学")，[知识系统](/w/index.php?title=%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "知识系统（页面不存在）")，[认知系统](/w/index.php?title=%E8%AE%A4%E7%9F%A5%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "认知系统（页面不存在）")或[计算智能](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD&action=edit&redlink=1 "计算智能（页面不存在）")。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155]](#cite_note-155)[[156]](#cite_note-156)[[157]](#cite_note-157)\n\n### HAL 9000在哪里?\n\n1968年[亚瑟·克拉克](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E5%85%8B%E6%8B%89%E5%85%8B "亚瑟·克拉克")和[史丹利·库柏力克](/wiki/%E5%8F%B2%E4%B8%B9%E5%88%A9%C2%B7%E5%BA%AB%E6%9F%8F%E5%8A%9B%E5%85%8B "史丹利·库柏力克")创作的《“[2001太空漫游](/wiki/2001%E5%A4%AA%E7%A9%BA%E6%BC%AB%E6%B8%B8 "2001太空漫游")”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158]](#cite_note-158)\n\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159]](#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")））。[[160]](#cite_note-160)[雷蒙德·库茨魏尔](/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94 "雷蒙德·库茨魏尔")相信问题在于计算机性能，根据[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")，他预测具有人类智能水平的机器将在2029年出现。[[161]](#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162]](#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n### 深度学习，大数据和通用人工智能：2011至2019\n\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n#### 深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](/wiki/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86 "MNIST数据集")（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n#### 大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n## 第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n### 大型语言模型\n\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](/wiki/ChatGPT "ChatGPT")基于[GPT-3.5](/wiki/GPT-3 "GPT-3")架构的[大型语言模型](/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B "大型语言模型")并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，[GPT-4](/wiki/GPT-4 "GPT-4")正式推出，进一步加强大型语言模型的推理能力。2023年8月，中国百度公司向公众开放使用[文心一言](/wiki/%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80 "文心一言")，让中国内地民众都可以使用内地版的大型语言模型。2025年1月，[深度求索](/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2 "深度求索")推出著名的[DeepSeek-R1](/wiki/DeepSeek-R1 "DeepSeek-R1") [开源](/wiki/%E9%96%8B%E6%BA%90 "开源")大型语言模型，并使用新的算法减低训练成本。\n\n### 机器人整合与人工智能的实际应用（2025年至今）\n\n先进的人工智能（AI）系统能够高精度理解和回应人类对话，已成熟到能够与机器人无缝整合，改变了制造业、医疗保健、公共服务和材料研究等行业。[[163]](#cite_note-163) 人工智能还通过高级数据分析和假设生成加速科学研究。[[164]](#cite_note-164) 包括中国、美国和日本在内的国家在政策和资金方面进行了大量投资，以部署人工智能驱动的机器人和人工智能的实际应用，解决劳动力短缺问题，促进创新并提高效率，同时实施监管框架以确保道德和安全发展。[[165]](#cite_note-165)\n\n#### 中国\n\n2025年被誉为“人工智能机器人年”，标志著人工智能（AI）与机器人无缝整合的关键时刻。在2025年，中国投资约7300亿元人民币（约1000亿美元）用于智能制造和医疗保健领域的人工智能和机器人技术发展。[[166]](#cite_note-166) [[167]](#cite_note-167) 第十四个五年规划（2021-2025年）优先发展服务机器人，人工智能系统使机器人能够执行复杂任务，例如协助手术或自动化工厂装配线。[[168]](#cite_note-168) 例如，中国医院中的人工智能人形机器人可以解读患者请求、运送物资并协助护士完成日常任务，显示现有的人工智能对话能力足以应用于实际的机器人应用。部分资金还支持国防应用，例如自主无人机。[[169]](#cite_note-169)[[170]](#cite_note-170) 自2025年9月起，中国要求对人工智能生成的内容进行标记，以确保技术的透明度和公众信任。[[171]](#cite_note-171)\n\n#### 美国\n\n2025年1月，人工智能基础设施投资取得重大进展，[星际之门计划](/wiki/%E6%98%9F%E9%99%85%E4%B9%8B%E9%97%A8%E8%AE%A1%E5%88%92 "星际之门计划") 成立。这家由 [OpenAI](/wiki/OpenAI "OpenAI")、[SoftBank Group](/wiki/SoftBank_Group "SoftBank Group")、[Oracle](/wiki/Oracle_Corporation "Oracle Corporation") 和 [MGX](/w/index.php?title=MGX_Fund_Management_Limited&action=edit&redlink=1 "MGX Fund Management Limited（页面不存在）") 组成的合资企业宣布计划到2029年在[美国](/wiki/%E7%BE%8E%E5%9C%8B "美国")投资5000亿美元用于人工智能基础设施，首期投资1000亿美元，以支持美国的再工业化并提供保护美国及其盟友国家安全的战略能力。[[172]](#cite_note-172) 该合资企业于2025年1月21日由美国总统唐纳德·特朗普正式宣布，SoftBank Group首席执行官 [孙正义](/wiki/%E5%AD%AB%E6%AD%A3%E7%BE%A9 "孙正义") 被任命为主席。[[173]](#cite_note-reuters-173)[[174]](#cite_note-174)\n\n美国政府拨款约20亿美元用于在制造业和物流业中整合人工智能和机器人技术，利用人工智能处理自然语言和执行用户指令的能力。[[175]](#cite_note-175) 各州政府补充资金支持服务机器人，例如部署在仓库中执行口头指令进行库存管理，或在养老院中回应居民的援助请求。[[176]](#cite_note-176) 这些应用表明，将已经熟练于人类交互的高级人工智能与机器人硬体结合是一项实际的前进步骤。\n\n2025年1月，第14179号行政命令确立了“人工智能行动计划”，以加速这些技术的创新和部署。[[177]](#cite_note-177)\n\n#### 影响\n\n2020年代各国政府和机构对AI的投资加速了人工智能的发展，推动了科学进步，提高了劳动效率，并通过自动化复杂任务改变了各行业。[[178]](#cite_note-178) 通过将成熟的人工智能系统整合到各行业的应用当中，这些发展有望彻底改变智能制造和服务行业，重塑人类的日常生活。\n\n## 注释\n\n## 参考文献\n\n`|date=`\n`|date=`\n`|date=`\n\n.\n\n![](https://zh.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&type=1x1&usesul3=1)\n![Wikimedia Foundation](/static/images/footer/wikimedia.svg)\n![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99847525, 'save_path': None}}, {'paper_id': '', 'title': '人工智能简史— 深入浅出PyTorch', 'authors': [], 'abstract': 'Theme by the [Executable Book Project](https://ebp.jupyterbook.org)\n\n* [repository](https://github.com/datawhalechina/thorough-pytorch "Source repository")\n* [open issue](https://github.com/datawhalechina/thorough-pytorch/issues/new?title=Issue%20on%20page%20%2F第零章/0.1 人工智能简史.html&body=Your%20issue%20content%20here. "Open an issue")\n* [suggest edit](https://github.com/datawhalechina/thorough-pytorch/edit/master/第零章/0.1 人工智能简史.md "Edit this page")\n\n* [.md](../_sources/第零章/0.1 人工智能简史.md.txt "Download source file")\n\nContents\n\n# 人工智能简史\n\n## Contents\n\n# 人工智能简史[#](#id1 "永久链接至标题")\n\n自从图灵在1950年第一次提出“机器智能（Machine Intelligence）”这个概念以来，人工智能已经经历了七十余年的发展。在这七十多年中，人工智能的发展先后经历了三次浪潮，每一次浪潮对人工智能的发展来说，都是具有里程碑意义的。接下来我们将以这三次浪潮为主线，为大家介绍人工智能的发展历程。除此之外，我们也将会给大家介绍现在常说的Deep learning，Machine Learning和AI之间的关系。\n\n[\\* ]通过本章学习，你将收获：\n\n* 了解人工智能的三次浪潮\n* 了解Deep learning，Machine learning和AI之间的关系\n\n## 1.1 人工智能的三次浪潮[#](#id2 "永久链接至标题")\n\n### 1.1.1 第一次浪潮[#](#id3 "永久链接至标题")\n\n1950年，阿兰·图灵发表著名论文《计算机器与智能》，在这篇论文中，他提出了机器思维的概念和图灵测试，标志着“机器的智能化”正式进入人类的科技树。在此之后的数年间，机器智能有了进一步的发展。两年后的1952年，计算机科学家阿瑟·萨缪尔开发出一款跳棋程序，并提出了“机器学习”这个概念。在此之后的4年里，机器智能化也取得了一定的进步，直到1956年的达特茅斯会议上，约翰·麦卡锡正式提出了“人工智能”这个词语，1956年，也就成为了实际意义上的人工智能元年。\n\n达特茅斯会议之后，人工智能进入了一个高速发展的时期，也就是所谓的“第一次浪潮”。这次浪潮一直持续到二十世纪六十年代中期。在这近10年的时间里，计算机本身的“智能”并没有得到发展，快速进步的是人工智能的一些理论与算法方面。很多对后来人工智能发展起到奠基作用的算法——如罗森布拉特在1957年发明感知机——就是在这个时间段诞生的。感知机是机器学习人工神经网络理论中神经元的最早模型，这一模型也使得人工神经网络理论得到了巨大的突破。除此之外，强化学习的雏形也是在那段时间提出的。彼时的科学界都弥漫着快乐的气氛，大家都认为，只要坚持走下去，人工智能就一定会得到跨越式的发展。但事与愿违，不久后人工智能的第一次寒冬（AI Winter）就到来了。\n\n1966年前后，AI遭遇了瓶颈。人们发现逻辑证明器、感知器、强化学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。研究者们很快就意识到，要求程序对这个世界具有儿童水平的认识这个要求都太高了——那时没人能够做出人工智能需要的巨大数据库，也没人知道一个程序怎样才能学到如此丰富的信息。另一方面，有很多计算复杂度以指数程度增加，这成为了不可能完成的计算任务。\n\n可以说，人工智能的第一次浪潮在发展到“非智能对话机器”的智能化初级阶段时，就因为当时的技术限制不得不停摆。人工智能的发展似乎陷入了一个无解的“死胡同”里，并被计算机科学家们逐渐冷落。\n\n### 1.1.2 第二次浪潮[#](#id4 "永久链接至标题")\n\n时间来到了20世纪80年代。经过了数十年的研究，科学家们逐渐放弃了初代的符号学派思路，改用统计学的思路来研究人工智能。研究思路的改变再加上硬件技术的升级，人工智能的发展又一次迎来的新的契机。在那个时代，基于人工智能的“专家系统”受到了绝对的热捧。特定领域的“专家系统”程序被更广泛的采纳，该系统能够根据领域内的专业知识，推理出专业问题的答案，人工智能也由此变得更加“实用”，专家系统所依赖的知识库系统和知识工程成为了当时主要的研究方向。\n\n但由于专家系统仅适用于某些特定场景，很快人们就对这一系统由狂热的追捧逐渐走向巨大的失望。与此同时，现代电子计算机的出现让“知识查询”的费用进一步降低，人们更加深刻的意识到专家系统是如此的古老陈旧。因此，政府部门下调了专家系统的研发资金。缺少了资金的支持，由专家系统再次兴起的人工智能研究又一次陷入了低谷之中。\n\n虽然第二次浪潮持续的时间比较短，但它在整个人工智能发展历史中仍然起到了举足轻重的作用。它彻底改变了人工智能研究的大思路，将统计学思想引入研究之中，为人工智能在未来几十年的发展打下了基础。除此之外，在这次浪潮中提出的BP神经网络，为之后机器感知、交互的能力奠定了基础。\n\n### 1.1.3 第三次浪潮[#](#id5 "永久链接至标题")\n\n1993年后，新的数学工具，理论和摩尔定律的出现，使得计算机的算力进一步提高，以深度学习为核心的机器学习算法获得发展，新的芯片和云计算的发展使得可用的计算能力获得飞跃式提高，大数据的发展使得海量数据的储存和分析成为可能。在这样的技术背景下，人工智能的第三次浪潮即将到来。\n\n人工智能的第三次浪潮有两个重要的时间节点：2006年和2016年。2006年是深度学习发展史的分水岭。杰弗里辛顿在这一年发表了《一种深度置信网络的快速学习算法》，其他重要的深度学习学术文章也在这一年被发布，在基本理论层面取得了若干重大突破。而2016年3月，谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭，“人工智能”一词正式进入普通民众的视野并被逐渐熟知。至此，人工智能正式迈向了从“科研领域的应用型工具”到“实用性，功能性工具”的转变，人工智能有了新的研究方向和研究模式，即从过去的学术主导型研究逐渐走向了商业主导型研究。随着人类社会对智能化工具的不断追求和探索，人工智能的发展迎来了全新的时代。\n\n### 1.1.4 总结[#](#id6 "永久链接至标题")\n\n上图是对人工智能发展中经历的三次浪潮和两次寒冬的形象总结。除此之外，有观点认为，深度学习算法带来的“技术红利”，将支撑我们再发展5~10年时间，随后就会遇到瓶颈。人工智能不是一个简单的从1到100进步的过程，它往往趋向于两个极端：要么90分以上，其它的都是10分以下。目前，人工智能急需寻找到一个“技术奇点”，让人工智能迅速发展到通用人工智能甚至是超级人工智能的水平。否则，在人工智能研究商业化的今天，无法从中获利的投资人们将快速撤资退场，人工智能或将进入下一个寒冬。\n\n## 1.2 DL,ML,AI三者之间的关系[#](#dl-ml-ai "永久链接至标题")\n\n大家对“人工智能”这个词，也就是我们所谓的“AI”（Artificial Intelligence）想必是非常熟悉，无论是近几年各行各业都喜欢用作营销噱头的“智能化”还是早期电影如《黑客帝国》、《终结者》等，都让AI这个概念深入人心。但近几年，另外两个词语也在逐步进入我们的生活，即就是“机器学习（Machine Learning，ML）”和“深度学习（Deep Learning，DL）”。在接下来的叙述中，我们就将了解DL和ML究竟是什么，以及它们和AI之间的关系。\n\n### 1.2.1 DL和ML是什么[#](#dlml "永久链接至标题")\n\nMachine Learning（机器学习）。它在1959年被机器学习的先驱者之一的阿瑟·塞缪尔定义为：一门研究领域，它赋予计算机无需明确编程就能学习的能力。也就是说，机器学习程序不同于传统编程那样，使用if-then语句那样明确地输入到计算机中以便它根据条件执行。在某种意义上，机器学习程序赋予机器根据所接触到的数据进行自我调整的能力。机器学习更像是一种优化算法，如果我们在事先就对它进行了正确的调整，那么它就会在一遍又一遍的尝试和猜测之中不断减少它的错误，以无限逼近于最终的正确结果。而机器学习的基本思路，也就是将现实问题抽象成为一个数学问题，机器通过训练，寻找到解决数学问题的方法，进而解决现实问题。\n\nDeep Learning（深度学习）。它在2006年被提出，并在近些年得到了迅速的发展。它通过建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据。李开复教授在《人工智能》一书中这样解释深度学习：“假设深度学习要处理的信息是“水流”，而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。网络的入口是若干管道开口，网络的出口也是若干管道开口。这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节阀的总数可以成千上万甚至更多。水管网络中，每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来，组成一个从前到后，逐层完全连通的水流系统。”\n\n### 1.2.2 它们和AI的关系[#](#ai "永久链接至标题")\n\n众所周知，人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。既然如此，那么计算器算是人工智能吗？严格地说是算的，因为它至少做了“模拟”人在计算方面的智能，并扩展了这个能力（比人算得更快）。我们通过代码驱动计算机去帮我们干活，这个算是人工智能吗？也算的。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，说白了，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。\n\n随着人对计算机的期望越来越高，要求它解决的问题越来越复杂，仅仅算的更快，看的更准已经远远不能满足人们的诉求了。要解决的问题域越来越复杂，即使是同一个问题，其面对的场景也越来越多。传统的思路就是查找问题的条件和解决方法，在计算机程序中再加入一个if-then。但这只是治标不治本。随着我们期待解决的问题越来越多，计算机程序将越来越复杂，越来越难以维护。那怎么办呢？于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n\n至此，“机器学习”的概念，正式诞生。机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器自行学会如何执行任务。说白了，机器学习只是人们实现让机器“模拟、延伸和扩展人的智能”的一种较为轻松的方法罢了。它的成功与否取决于我们喂给机器的数据集是否准确且有效。因此，机器学习是大数据技术领域内的一个应用，人们只是借用这个应用，来发展人工智能罢了。机器学习发展了几十年之后，再次遇到了瓶颈期。随着问题场景的更加复杂多变，需要进行判断的条件更加苛刻，人们不得不重新思考一种方式来优化机器学习。深度学习就是带着这个目的被提出的。\n\n机器学习中有一个概念叫“神经网络”，深度学习正是通过优化这个网络来更好的解决通过机器学习难以解决的问题。它的基本特点，就是试图模仿大脑的神经元之间传递，处理信息的模式，通过不同的“层”来拆分问题，每一层解决问题的一个部分。比如在利用深度学习解决智能驾驶问题中，第一层可能用于识别车辆与道路边缘的距离，第二层用于识别道路标线，第三层用于识别路上的其他车辆等等。\n\n通过以上几段话的简单描述，DL,ML和AI之间的关系也就明确了。它们三者的关系就像是俄罗斯套娃：AI最大，它的目的是通过让机器模仿人类进而超越人类；ML次之，它是AI的一个分支（也是最重要分支），是让机器模仿人类的一种方法；DL更次之，它是ML的一个分支，它的目的是让机器不借助人工标注，也能自主提取目标特征进而解决问题的一种方法。\n\n最后，借用一张经典的关系图作为结尾：\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E9%9B%B6%E7%AB%A0/0.1%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99711037, 'save_path': None}}, {'paper_id': '', 'title': 'AI 简史：从神经元到现代大模型 - CSDN博客', 'authors': [], 'abstract': '* [博客](https://blog.csdn.net/)\n* [下载](https://download.csdn.net/)\n* [社区](https://devpress.csdn.net/)\n* [GitCode](https://link.csdn.net?target=https%3A%2F%2Fgitcode.com%3Futm_source%3Dcsdn_toolbar)\n* [GPU算力](https://ai.csdn.net/)\n* 更多\n\n  [会议](https://www.bagevent.com/event/9117243 "会议")[学习](https://edu.csdn.net?utm_source=zhuzhantoolbar "高质量课程·大会云会员")[InsCode](https://inscode.net?utm_source=csdn_blog_top_bar "InsCode")\n\nAI 搜索\n\n# AI 简史：从神经元到现代大模型\n\n原创\n已于\xa02024-12-25 16:28:52\xa0修改\n·\n1.8w 阅读\n\n·\n\n49\n\n·\n89\n·\n\nCC 4.0 BY-SA版权\n\n版权声明：本文为博主原创文章，遵循 [CC 4.0 BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/) 版权协议，转载请附上原文出处链接和本声明。\n\n文章标签：\n\n[#深度学习](https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#人工智能](https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#ai](https://so.csdn.net/so/search/s.do?q=ai&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#神经网络](https://so.csdn.net/so/search/s.do?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#transformer](https://so.csdn.net/so/search/s.do?q=transformer&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#卷积神经网络](https://so.csdn.net/so/search/s.do?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#机器学习](https://so.csdn.net/so/search/s.do?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n\n于\xa02024-12-25 10:54:28\xa0首次发布\n\n[2048 AI社区 文章已被社区收录](javascript:; "2048 AI社区")\n\n[生成AI\n专栏收录该内容](https://blog.csdn.net/jarodyv/category_12199878.html "生成AI")\n\n45 篇文章\n\n该文章已生成可运行项目，\n\n## AI 简史：从神经元到现代大模型\n\n人工智能 (AI) 和深度学习 (DL) 在过去的几十年中飞速发展，推动了[计算机视觉](https://so.csdn.net/so/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&spm=1001.2101.3001.7020)、自然语言处理和机器人等领域的进步。今年的诺贝尔物理学奖更是颁给了美国科学家约翰·霍普菲尔德 (John Hopfield）和英国科学家杰弗里·辛顿（Geoffrey Hinton），表彰他们“在人工神经网络机器学习方面的基础性发现和发明”。本文将为大家概述 AI 的发展历程，梳理出从早期神经网络模型到现代大型语言模型发展过程中的重要里程碑。\n\n图 1. AI 发展全景图\n\n#### 文章目录\n\n* + [1. 人工智能诞生 (1956)](#1__1956_10)\n  + [2. AI 的演进：从基于规则的系统到深度神经网络](#2_AI__36)\n  + [3. 早期人工神经网络 (1940s – 1960s)](#3__1940s__1960s_49)\n  + - [3.1 McCulloch-Pitts 神经元 (1943)](#31_McCullochPitts__1943_51)\n    - [3.2 Rosenblatt 感知机模型 (1957)](#32_Rosenblatt__1957_62)\n    - [3.3 ADALINE (1959)](#33_ADALINE_1959_82)\n    - [3.4 异或（XOR）问题 (1969)](#34_XOR_1969_106)\n  + [4. 多层感知机 (1960)](#4__1960_124)\n  + - [4.1 隐藏层 (Hidden Layers)](#41__Hidden_Layers_133)\n    - [4.2 多层感知机的历史背景与挑战](#42__142)\n  + [5. 反向传播 (1970s – 1980s)](#5__1970s__1980s_151)\n  + - [5.1 早期发展 (1970 年代)](#51__1970__166)\n    - [5.2 强化与普及（1980 年代）](#52_1980__171)\n    - [5.3 通用逼近定理 (1989)](#53__1989_182)\n    - [5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)](#54__1980___1990__191)\n    - [5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)](#55__1990___2000__200)\n    - [深度学习的复兴 (2000 年代末 – 现在)](#_2000____215)\n  + [6. 卷积神经网络 (1980s – 2010s)](#6__1980s__2010s_226)\n  + - [6.1 早期发展 (1980 – 1998)](#61__1980__1998_242)\n    - [6.2 CNN 的崛起：AlexNet (2012)](#62_CNN_AlexNet_2012_258)\n    - [6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）](#63_AlexNet_2010__280)\n    - [6.4 后续架构改进](#64__289)\n    - [6.5 CNN 的应用](#65_CNN__314)\n  + [7. 循环神经网络 (1986 – 2017)](#7__1986__2017_324)\n  + - [7.1 早期发展 (1980s – 1990s)](#71__1980s__1990s_328)\n    - [7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)](#72_LSTM_GRU__Seq2Seq__1997__2014_344)\n    - [7.3 RNN 的应用](#73_RNN__362)\n    - [7.4 RNN 的挑战](#74_RNN__370)\n  + [8. Transformer (2017 – 现在)](#8_Transformer_2017___380)\n  + - [8.1 Transformer 简介](#81_Transformer__384)\n    - [8.2 Transformer 的衍生模型](#82_Transformer__405)\n    - [8.3 OpenAI GPT 的发展历程](#83_OpenAI_GPT__423)\n    - [8.4 其他知名大语言模型](#84__439)\n  + [9. 多模态模型 (2023 – 现在)](#9__2023___457)\n  + - [9.1 GPT-4V (2023) 和 GPT-4o (2024)](#91_GPT4V_2023__GPT4o_2024_459)\n    - [9.2 Google’s Gemini (2023 – 现在)](#92_Googles_Gemini_2023___465)\n    - [9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)](#93_Claude_30__Claude_35_2023___471)\n    - [9.4 LLaVA (2023)](#94_LLaVA_2023_477)\n  + [10. 扩散模型 (2015 – 现在)](#10__2015___488)\n  + - [10.1 扩散模型简介 (2015)](#101__2015_492)\n    - [10.2 扩散模型的发展 (2020 – 现在)](#102__2020___509)\n    - [10.3 文生图模型](#103__523)\n    - [10.4 文生视频模型](#104__533)\n  + [11. 尾声](#11__566)\n\n### 1. 人工智能诞生 (1956)\n\n人工智能（AI）的概念由来已久，但现代 AI 的雏形是在 20 世纪中期逐渐形成的。“人工智能”这个术语是由计算机科学家和认知科学家约翰·麦卡锡 (John McCarthy) 在 1956 年召开的达特茅斯人工智能夏季研讨项目上首次提出并被大家接受，AI 从此走上历史舞台。\n\n图 2.\n[A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence](http://www-formal.stanford.edu/jmc/history/dartmouth.pdf) (1955)\n\n达特茅斯会议通常被视为 AI 研究的发源地。这次会议汇聚了计算机科学家、数学家和认知科学家，共同探讨创造能够模拟人类智能的机器的可能性。与会者中大佬云集，包括：\n\n* **约翰·麦卡锡 (John McCarthy)** ：计算机科学家、Lisp 编程语言发明人之一。\n* **马文·明斯基 (Marvin Minsky)**：计算机科学家、框架理论的创立者。\n* **雷·索洛莫诺夫 (Ray Solomonoff)**：算法概率论创始人，通用概率分布之父，通用归纳推理理论的创建者。\n* **纳撒尼尔·罗切斯特 (Nathaniel Rochester)** ：IBM 701 的首席设计师，编写了世界上第一个汇编程序。\n* **克劳德·香农 (Claude Shannon)** ：数学家、发明家、密码学家，信息论创始人。\n* **奥利弗·塞弗里奇 (Oliver Selfridge)**：模式识别的奠基人、人工智能的先驱，被誉为“机器知觉之父”。\n\n图 3. 参加达特茅斯会议的部分重量级人物\n\n### 2. AI 的演进：从基于规则的系统到深度神经网络\n\n纵观整个 AI 的发展史，有一条清晰的发展脉络，那就是从基于规则的系统向深度神经网络的不断进化。\n\n人工智能 (AI) 的发展始于上个世纪 50 年代，那时人们开始开发用于国际象棋和问题求解的算法。第一个 AI 程序 Logical Theorist 于 1956 年诞生。到了 1960 和 1970 年代，基于规则的专家系统如 MYCIN 被引入，它们可以帮助进行复杂的决策。1980 年代，机器学习开始兴起，使 AI 系统能够从数据中学习并不断改进，为现代深度学习技术奠定了基础。\n\n今天，大多数最前沿的 AI 技术都由深度学习驱动，深刻改变了 AI 的发展格局。深度学习是机器学习的一个独立分支，它通过多层人工神经网络从原始数据中提取复杂特征。在本文中，我们将探讨 AI 的发展历史，并重点介绍深度学习在其中的关键作用。\n\n图 4. 人工智能、机器学习、神经网络、深度学习之间的关系\n\n### 3. 早期人工神经网络 (1940s – 1960s)\n\n#### 3.1 McCulloch-Pitts 神经元 (1943)\n\n神经网络的概念可以追溯到 1943 年，当时 Warren McCulloch 和 Walter Pitts 提出了第一个人工神经元模型。McCulloch-Pitts (MP) 神经元模型是对生物神经元的一种突破性简化。这个模型通过聚合二进制输入，并利用阈值激活函数来做出决策，从而为人工神经网络奠定了基础，输出结果为二进制 \n{\n0\n,\n1\n}\n\\{0, 1\\}\n{0,1}。\n\n图 5. 人工神经元的结构与原理\n\n#### 3.2 Rosenblatt 感知机模型 (1957)\n\nFrank Rosenblatt 在 1957 年引入了感知机，这是一种能够学习和识别模式的单层神经网络。感知机模型比 MP 神经元更为通用，设计用于处理实数值输入，并通过调整权重来最小化分类错误。\n\n图 6. 感知机模型\n\nRosenblatt 还为感知机开发了一种监督学习算法，使得网络能够直接从训练数据中进行学习。  \n \nL\n(\nW\n)\n=\n−\n∑\ni\n∈\nM\nW\nT\nX\ni\ny\ni\n\\mathcal{L}(W) = - \\sum\\_{i \\in M} W^T X\\_i y\\_i\nL(W)=−i∈M∑\u200bWTXi\u200byi\u200b\n\n图 7. Mark I 感知机，是一台实现了图像识别感知机算法的机器\n\nRosenblatt 的感知机展示出识别个人和在不同语言间翻译语音的潜力，这在当时引发了公众对 AI 的极大兴趣。感知机模型及其相关的学习算法成为神经网络发展历程中的重要里程碑。然而，很快就显现出一个关键限制：当训练数据是非线性可分时，感知机的学习规则无法收敛。\n\n#### 3.3 ADALINE (1959)\n\nWidrow 和 Hoff 在 1959 年引入了 ADALINE（自适应线性神经元，也称 Delta 学习规则），对感知机学习规则进行了改进。ADALINE 解决了二进制输出和噪声敏感性等限制，并能够学习并收敛非线性可分的数据，这是神经网络发展中的一大突破。\n\n图 8. ADALINE VS. 感知机\n\nADALINE 的主要特点包括：\n\n* **线性激活函数**：不同于感知器的阶跃函数，ADALINE 使用线性激活函数，因此适用于回归任务和连续输出。\n* **最小均方（LMS）算法**：ADALINE 采用 LMS 算法，该算法通过最小化预测输出与实际输出之间的均方误差，提供更高效和稳定的学习过程。\n* **自适应权重**：LMS 算法根据输出误差自适应调整权重，使 ADALINE 即使在有噪声的情况下也能有效地学习和收敛。\n\n**ADALINE 的引入标志着神经网络第一次黄金时代的开始**，它克服了 Rosenblatt 感知机学习的限制。这一突破实现了高效学习、连续输出和对噪声数据的适应能力，推动了该领域的创新和快速发展。\n\n图 9. ADALINE 开启了神经网络第一次黄金时代\n\n然而，与感知机类似，ADALINE 仍然无法解决线性可分的问题，无法应对更复杂的非线性任务。这一局限集中体现在异或（XOR）问题上，也促进了更高级神经网络架构的发展。\n\n#### 3.4 异或（XOR）问题 (1969)\n\n1969年，Marvin Minsky 和 Seymour Papert 在他们的著作《Perceptrons》中揭示了单层感知机的一个重要局限：由于其线性决策边界，感知机无法解决异或 (XOR) 问题，而这是一个简单的二元分类任务。异或问题不是线性可分的，也就是说，没有一个单一的线性边界能够正确地将所有的输入模式分类。\n\n图 10. Marvin Minsky 和 Seymour Papert 合著的《Perceptrons: An introduction to computational geometry》\n\n这一发现强调了需要开发更复杂的神经网络架构，以便能够学习非线性的决策边界。感知机的局限性被揭露后，人们对神经网络的信心减弱，转而研究符号人工智能方法，**这标志着从 20 世纪 70 年代初到 80 年代中期的“神经网络的第一次黑暗时代”的开始**。\n\n图 11. 异或问题将神经网络代入第一次黑暗时代\n\n### 4. 多层感知机 (1960)\n\n多层感知机 (MLP) 最早于 20 世纪 60 年代提出，作为对单层感知机的改进。MLP 由多个层次的相互连接的神经元组成，能够克服单层模型的局限性。苏联科学家 A. G. Ivakhnenko 和 V. Lapa 在感知机基础上进行研究，对多层感知机的发展中做出了重要贡献。\n\n图 12. 多层感知机模型\n\n#### 4.1 隐藏层 (Hidden Layers)\n\n增加隐藏层使得 MLP (多层感知器) 可以捕捉和表达数据中的复杂非线性关系。这些隐藏层极大地增强了网络的学习能力，使其能够解决诸如异或问题这样非线性可分的问题。\n\n图 13. 隐藏层解决异或问题\n\n#### 4.2 多层感知机的历史背景与挑战\n\nMLP 的出现标志着神经网络的研究向前迈出了重大一步，展示了[深度学习架构](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9E%B6%E6%9E%84&spm=1001.2101.3001.7020)在解决复杂问题方面的潜力。然而，在 1960 年代和 1970 年代，MLP 的发展面临若干挑战：\n\n* **缺乏训练算法**：早期的 MLP 模型缺乏高效的训练算法，无法有效地调整网络权重。此时反向传播算法还未诞生，训练多层深度网络非常困难。\n* **算力限制**：当时的算力不足以应对训练深度神经网络所需的复杂计算。这一限制拖慢了 MLP 的研究和发展进程。\n\n神经网络的第一个黑暗时代在 1986 年结束，**随着反向传播算法的诞生，开启了神经网络的第二个黄金时代**。\n\n### 5. 反向传播 (1970s – 1980s)\n\n1969 年，异或问题揭示了感知机（单层神经网络）的局限性。研究人员意识到，多层神经网络能够克服这些限制，但缺乏有效的训练算法。17年后，反向传播算法的开发使得神经网络在理论上可以逼近任何函数。值得注意的是，该算法实际上在发表之前就已被发明。如今，反向传播已成为深度学习的核心组件，自 20 世纪 60 年代和70 年代以来经历了显著的发展和完善。\n\n图 14. 反向传播原理示意图\n\n反向传播的关键特性：\n\n* **梯度下降**：反向传播与梯度下降联合使用以降低误差函数。该算法计算每个权重相对于误差的梯度，从而逐步调整权重以减少误差。\n* **链式法则**：反向传播算法的核心在于应用微积分的链式法则。此法则使得误差的梯度可以被分解为一系列偏导数，并通过网络的反向传递高效计算。\n* **分层计算**：反向传播逐层运作，从输出层向输入层反向传递。这种分层计算确保梯度在网络中正确传播，使得深度架构的训练成为可能。\n\n#### 5.1 早期发展 (1970 年代)\n\n* **Seppo Linnainmaa (1970)**: 提出了自动微分的概念，这是反向传播算法的重要组成部分。\n* **Paul Werbos (1974)**: 提议使用微积分的链式法则计算误差函数对网络权重的梯度，从而能够训练多层神经网络。\n\n#### 5.2 强化与普及（1980 年代）\n\n* **David Rumelhart, Geoffrey Hinton 和 Ronald Williams (1986)**: 将**反向传播**这一高效实用的方法，用于训练深度神经网络，并展示了其在多种问题中的应用。\n\n图 15. 反向传播算法的三位主要贡献者\n\n其中 Geoffrey Hinton 因其在人工神经网络和机器学习领域的贡献获得了 2018 年图灵奖和 2024 诺贝尔物理学奖，称为继 Herbert Simon 后第二位图灵奖-诺贝尔奖双料得主。\n\n#### 5.3 通用逼近定理 (1989)\n\nGeorge Cybenko 在 1989 年提出的通用逼近定理，为多层神经网络的功能提供了数学基础。该定理表明，只要神经元数量足够，并且使用非线性激活函数，具有单个隐藏层的前馈神经网络就能够以任意精度逼近任意连续函数。这个定理突显了神经网络的强大能力和灵活性，使其能够应用于各种领域。\n\n图 16. 具有单个隐藏层的神经网络可以将任意连续函数逼近到任意所需的精度，从而在各个领域解决复杂的问题\n\n#### 5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)\n\n\\*\\*反向传播算法的出现和通用逼近定理的提出，开启了神经网络研究的第二个黄金时代。\\*\\*反向传播提供了一种高效的多层神经网络训练方法，使研究人员能够构建更深层次和更复杂的模型。通用逼近定理则为使用多层神经网络提供了理论支持，并增强了人们对其解决复杂问题能力的信心。在 1980 年代末至 1990 年代初，这一时期见证了对神经网络领域的兴趣回升和显著的进步。\n\n图 17. 反向传播和通用逼近定理开启了神经网络研究的第二个黄金时代\n\n#### 5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)\n\n然而，由于一系列因素，神经网络领域在 1990 年代初至 2000 年代初经历了“第二个黑暗时代”：\n\n* **支持向量机 (SVM) 的兴起**：支持向量机为分类和回归任务提供了更优雅的数学方法。\n* **算力限制**：由于训练深度神经网络仍然耗时且对硬件要求高，计算能力受到限制。\n* **过拟合和泛化问题**：这两个问题导致早期神经网络在训练数据上表现良好，但在新数据上表现不佳，限制了其实用性。\n\n这些挑战使得许多研究人员转而关注其他领域，导致神经网络研究的停滞。\n\n图 18. 随着 SVM 的兴起，神经网络进入第二个黑暗时代\n\n#### 深度学习的复兴 (2000 年代末 – 现在)\n\n在 2000 年代末和 2010 年代初，神经网络领域经历了复兴，这得益于以下方面的进步：\n\n* **深度学习架构的发展**（如 CNNs、RNNs、Transformers、Diffusion Models）\n* **硬件的改进**（如 GPUs、TPUs、LPUs）\n* **大规模数据集的可用性**（如 ImageNet、COCO、OpenWebText、WikiText 等）\n* **训练算法的优化**（如 SGD、Adam、dropout）\n\n这些进展带来了计算机视觉、自然语言处理、语音识别和强化学习的重大突破。通用逼近定理与实际技术的进步相结合，为深度学习技术的广泛应用和成功奠定了基础。\n\n### 6. 卷积神经网络 (1980s – 2010s)\n\n卷积神经网络 (CNN) 在深度学习领域，尤其是计算机视觉和图像处理方面，带来了革命性的变化。从上个世纪 80 年代到本世纪最初的 10 年，CNN 在架构、训练技术和应用等方面取得了显著的进步。\n\n卷积神经网络由以下三个主要组件构成：\n\n* **卷积层 (Convolutional Layers)**：这些层通过一组可调整的滤波器，从输入图像中自动学习和提取特征的空间层次结构。\n* **池化层 (Pooling Layers)**：池化层通过缩小输入的空间尺寸，来提高对输入变化的适应性，并减少计算量。\n* **全连接层 (Fully Connected Layers)**：在卷积层和池化层之后，全连接层用于分类任务，负责整合之前层中提取的特征。\n\n卷积神经网络的主要特性\n\n* **局部感受野**：CNN 利用局部感受野来捕捉输入数据中的局部特征，使其在处理图像和其他视觉任务时表现出色。\n* **权重共享**：通过在卷积层中共享权重，CNN 能够减少网络中参数的数量，从而提高训练效率。\n* **平移不变性**：池化层赋予网络平移不变性，使其能够识别输入图像中不同位置的相同模式。\n\n#### 6.1 早期发展 (1980 – 1998)\n\n1980 年代，福岛邦彦 (Kunihiko Fukushima) 首次提出了 CNN 的概念，他设计了一种称为神经认知机 (Neocognitron) 的分层神经网络，这种网络模仿了人类视觉皮层的结构。这项开创性的研究为之后 CNN 的发展奠定了基础。\n\n图 19. 福岛邦彦与他的神经认知机\n\n到了 1980 年代末和 1990 年代初，Yann LeCun 和他的团队在此基础上进一步发展了 CNN，并推出了 LeNet-5 架构，该架构专为手写数字识别而设计。\n\n图 20. Yann LeCun 与他的 LeNet-5\n\n#### 6.2 CNN 的崛起：AlexNet (2012)\n\n2012 年，AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了重大胜利，这是 CNN 发展中的一个重要里程碑。这次胜利不仅以压倒性优势赢得了比赛，也在图像分类领域取得了重大突破。\n\n图 21. ILSVRC 历年冠军及其表现\n\nILSVRC 是一个年度图像识别基准测试，用于评估算法在一个包含 1000 万多张注释图像的数据集上的表现，这些图像被划分为 1000 个类别。AlexNet 的创新之处包括：\n\n* **ReLU 激活函数**：为解决传统激活函数的问题而引入，ReLU 提高了训练速度并改善了性能。\n* **Dropout 正则化**：这种技术通过在训练过程中随机丢弃神经元来减少过拟合现象。\n* **数据增强**：通过人为增加训练数据的多样性，增强了数据集的丰富性，从而改善了模型的泛化能力。\n\nAlexNet 的成功成为 CNN 发展中的一个转折点，为图像分类和物体检测的进一步发展奠定了基础。\n\n图 22. AlexNet 架构\n\n#### 6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）\n\n自 2010 年代直至今天，当前的科技发展黄金时代以深度学习、大数据和强大计算平台的结合为特征。在这一时期，图像识别、自然语言处理和机器人技术等领域取得了显著的突破。持续的研究不断推动着人工智能（AI）能力的边界。\n\n图 23. AlexNet 开启神经网络的第三次黄金时代\n\n#### 6.4 后续架构改进\n\n继 AlexNet 之后，又相继出现了几个有影响力的架构：\n\n* **VGGNet (2014)**：由牛津大学的视觉几何组开发，VGGNet 强调使用更深的网络架构，并采用较小的卷积滤波器 (\n  3\n  ×\n  3\n  3 \\times 3\n  3×3)，从而取得了显著的准确率。\n\n  图 24. 原始 VGGNet 架构\n* **GoogLeNet/Inception (2014)**：引入了 inception 模块，使得网络能够以更高效的方式捕捉不同尺度的特征。\n\n  图 25. GooLeNet 架构\n* **ResNet (2015)**：残差网络通过引入跳跃连接，使得训练非常深的网络成为可能，同时缓解了梯度消失问题。\n\n  图 26. ResNet 架构\n\n#### 6.5 CNN 的应用\n\nCNN 的进步已经在多个领域引发了变革：\n\n* **计算机视觉**：CNN 已成为现代计算机视觉的核心，实现了图像分类、物体检测和语义分割方面的突破。\n* **医学影像**：CNN 被用于疾病诊断、肿瘤检测和图像引导手术等任务，大大提高了诊断准确性。\n* **无人驾驶**：CNN 是无人驾驶感知系统的核心，使它们能够解释和响应周围环境。\n\nCNN 从其创立到目前作为深度学习基石的历程展示了其对 AI 的重大影响。CNN 的成功也为深度学习的进一步进步铺平了道路，并激发了其他专用神经网络架构的发展，如 RNN 和 Transformer。CNN 的理论基础和实际创新显著推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 7. 循环神经网络 (1986 – 2017)\n\n循环神经网络 (RNN) 是为了处理序列数据而设计的。与传统的前馈网络（MLP）不同，RNN 拥有一个内部的隐藏状态或“记忆”，使其能够捕捉序列元素之间的时间依赖性。因此，RNN 在语言建模、时间序列预测和语音识别等任务中尤为有效。\n\n#### 7.1 早期发展 (1980s – 1990s)\n\nRNN 的概念起源于 1980 年代，John Hopfield, Michael I. Jordan 和 Jeffrey L. Elman 等先驱为这些网络的发展做出了贡献。John Hopfield在 1982 年提出的 Hopfield 网络为理解神经网络中的循环连接奠定了基础。Jordan 网络和 Elman 网络分别在 1980 年代和 1990 年代提出，是早期捕捉序列数据中时间依赖性的尝试。\n\n图 27. RNN 架构\n\nRNN 使用历时反向传播 (BPTT) 进行训练，这是前馈网络标准反向传播算法的扩展。BPTT 需要将网络在时间上展开，将每个时间步视为一层。在前向传播时，输入序列被处理，并在输出层计算误差。然后，产生的梯度从最后一个时间步反向传播到第一个时间步，以更新 RNN 的参数。然而，由于梯度消失问题，RNN 在学习长时间依赖性时遇到困难，因为梯度会变得极小，导致无法学习。相反，梯度也可能变得过大，造成训练不稳定，这被称为梯度爆炸问题。\n\n图 28. 反向传播 (BPTT)\n\n#### 7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)\n\n图 29. RNN, LSTM, GRU 单元\n\n* **长短期记忆 (LSTM) 网络 (1997)**：Sepp Hochreiter 和 Jürgen Schmidhuber 提出了 LSTM 网络，以解决传统 RNN 中的梯度消失问题。LSTM 通过使用门控机制来控制信息流动，使其能够捕捉序列数据中的长期依赖关系。LSTM 包括单元状态（用于存储长期信息）、隐藏状态（携带当前时间步的短期输出），以及三个门（输入门、遗忘门和输出门）。在每一步中，LSTM 会根据多个数学运算和门来决定需要遗忘多少信息，向单元状态添加多少信息，以及为下一步输出多少信息。\n* **门控循环单元 (GRU) (2014)**：Kyunghyun Cho 等人提出了 GRU，这是一种简化版的 LSTM，也采用门控机制来调节信息流。与 LSTM 的三个门和两个状态不同，GRUs 只有两个门和一个状态。LSTM 的遗忘门和输入门被合并为一个更新门，用于决定保留多少过去的信息和整合多少新信息。此外，GRU 用重置门代替了 LSTM 的输出门，该门决定在整合新信息之前需要“重置”或忘记多少过去的信息。由于 GRU 的参数较少，通常训练速度更快。\n* **Seq2Seq 模型 (2014)**：Ilya Sutskever 和他的团队提出了 Seq2Seq 模型，这种模型使用编码器-解码器架构，将输入序列转换为输出序列。Seq2Seq 模型已被广泛应用于机器翻译、语音识别和文本摘要等任务。\n\n  图 30. 基于 LSTM 的 Seq2Seq 编码器-解码器架构\n\n#### 7.3 RNN 的应用\n\nRNN 在多个领域产生了重大影响，包括：\n\n* **自然语言处理**：RNN 在自然语言处理领域引发了革命性变化，使得语言建模、机器翻译、情感分析和文本生成等任务取得了显著进展。\n* **语音识别**：RNN 广泛用于语音识别系统中，它们通过建模口语的时间依赖性，将语音信号转换为文本。\n* **时间序列预测**：RNN 在时间序列预测中表现出色，它们通过建模顺序数据的时间依赖性，以预测未来值。\n\n#### 7.4 RNN 的挑战\n\n尽管 RNN 在许多方面取得了成功，但其仍面临若干挑战：\n\n* **梯度消失与梯度爆炸**：传统 RNN 在处理这些问题时表现不佳，尽管 LSTM 和 GRU 提供了一些解决方案。\n* **计算复杂性**：训练 RNN 可能需要大量资源，尤其是在处理大型数据集时。\n* **并行化**：RNN 的顺序特性使得并行训练和推理过程变得复杂。\n\nRNN 的成功为深度学习的进一步发展奠定了基础，并启发了其他专门化神经网络架构的发展，例如 Transformer，它们在各种序列数据任务中取得了最先进的性能。RNN 的理论基础和实际创新大大推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 8. Transformer (2017 – 现在)\n\nTransformer 以其卓越的序列数据处理能力，深刻地改变了深度学习的格局，并在自然语言处理 (NLP) 和计算机视觉等多个领域中发挥了重要作用。\n\n#### 8.1 Transformer 简介\n\nVaswani 等人于 2017 年发表了开创性论文“Attention is All You Need”，其中提出了 Transformer 模型。这个模型放弃了 RNN 的传统序列处理方式，转而采用自注意力机制，从而实现了并行处理，并能更好地处理长距离依赖关系。\n\n图 31. 自注意力机制\n\nTransformer 具有如下核心特性：\n\n* **自注意力机制**：允许序列中每个位置灵活地关注其他所有位置，从而比 RNN 或 LSTM 更有效地捕捉上下文。\n* **并行化**：通过同时处理所有输入数据，大大提高了训练速度，这与 RNN 的顺序处理方式形成鲜明对比。\n* **编码器-解码器结构**：编码器和解码器堆栈都使用自注意力和前馈神经网络层，并通过位置编码来保持序列的顺序。\n\n图 32. Transformer 架构\n\n关于 Transformer 和自注意力机制的详细介绍，请参考 [《深度解析 Transformer 和注意力机制（含完整代码实现）》](https://jarod.blog.csdn.net/article/details/130867562) 和 [《图解 NLP 模型发展：从 RNN 到 Transformer》](https://jarod.blog.csdn.net/article/details/129564388)。\n\n#### 8.2 Transformer 的衍生模型\n\n图 33. 基于 Transformer 的模型\n\nTransformer 有众多衍生模型，其中比较重要的有：\n\n* **BERT (2018)**: BERT 是一种仅使用编码器的双向编码器表示模型，通过掩码语言建模和下一句预测的预训练，彻底革新了 NLP。\n* **GPT (2018)**: GPT 旨在预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这一基础模型为生成式语言模型的后续发展奠定了基础，展示了从大型文本语料库中进行无监督学习的潜力。\n* **T5 (2019)**: T5 是一种编码器-解码器结构的文本到文本转换模型，将 NLP 任务转化为统一的文本到文本格式，简化了模型架构和训练过程。\n\n图 34. BERT vs. GTP vs. T5\n\n#### 8.3 OpenAI GPT 的发展历程\n\nOpenAI 的生成式预训练 Transformer (Generative Pre-trained Transformer, GPT) 系列模型自 2018 年问世以来，极大地推动了自然语言处理 (Natural Language Processing, NLP) 领域的发展。每一代模型都在前一代的基础上进行改进，引入了更大规模的模型和增强的功能。以下是每个版本的详细概述。\n\n图 35. GPT 的自回归语言模型架构旨在根据之前输入的 Token 预测序列中的下一个 Token\n\n* **GPT (2018)**: 原始的 GPT 模型于 2018 年推出，作为一个仅使用自回归解码器的变换器，拥有 1.17 亿个参数。它被设计用于预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这个基础模型为后续生成式语言模型的发展奠定了基础，展示了无监督学习从大型文本语料库中获取信息的潜力。\n* **GPT-2 (2019)**: 2019 年发布的 GPT-2 在模型规模和能力上实现了显著飞跃，参数数量扩大到 15 亿个。这个版本表现出一些新兴能力，如零样本任务执行，即可以在没有专门训练的情况下执行任务。然而，它生成连贯但有时误导性文本的能力引发了关于潜在滥用的道德担忧，特别是在生成假新闻或错误信息方面。\n* **GPT-3 (2020)**: GPT-3 于 2020 年推出，进一步将模型规模扩大到惊人的 1750 亿个参数。该模型在少样本学习方面表现出卓越的能力，即可以根据提示中提供的极少量示例适应各种任务。其生成类人文本的能力使其成为许多应用的多功能工具，包括内容创作、代码辅助和对话代理。GPT-3 的架构使其能够在无需大量微调的情况下执行广泛的 NLP 任务，巩固了其作为当时最强大语言模型之一的地位。\n* **ChatGPT (2022):** 这是一个经过微调的 GPT-3.5 模型，通过人类反馈强化学习 (Reinforcement Learning from Human Feedback, RLHF) 进行优化，擅长处理后续问题和维护上下文，通过指令调优和用户偏好数据使响应更符合用户意图。\n* **GPT-4 (2023)**: GPT-4 于 2023 年发布，继续在能力和参数数量上进行扩展，尽管其架构和参数数量的具体细节目前尚未完全公开。预计将在之前几代模型的表现上进一步提升，特别是在推理能力和理解复杂上下文的能力方面。\n* **GPT-o1 (2024)**：这一版本的 GPT 与之前所有版本有了本质区别，它开创性地引入了人类的慢思考+思维链模式，将大模型从越来越离谱的参数内卷中解救出来，开辟了AI发展的新方向。GPT-o1 显著提升了逻辑推理能力，使其在数学、科研、代码等领域的表现有了质的飞跃。在若干基准测试中，GPT-o1 展现出的能力已经与博士生相当。\n\n#### 8.4 其他知名大语言模型\n\n随着越来越多优秀的大型语言模型（LLM）的涌现，人工智能领域得到了极大的丰富。这些模型各具特色，为人工智能技术带来了新的进展。以下是一些知名大语言模型的概况：\n\n* **Anthropic 的 Claude (2022)**: 该模型注重 AI 输出的安全性和伦理问题，致力于与人类价值观保持一致。\n* **Meta 的 LLaMA (2023)**: 提供多种规模的模型，以满足不同的计算需求，在自然语言处理的基准测试中表现卓越。\n* **Mistral.AI 的 Mistral (2023)**: 兼顾高性能和资源效率，适合于实时应用，专注于开源 AI 解决方案。\n* **阿里巴巴的 Qwen (2023)**: 专为创建高质量的英中双语 AI 模型而设计，促进跨语言应用并推动创新。\n* **Microsoft 的 Phi (2023)**: 强调在各种应用中的多功能性和集成能力，采用先进的训练技术以提升上下文理解和用户交互。\n* **Google 的 Gemma 系列 (2024)**: 这些轻量级的开放模型应用于多种领域，包括文本生成、摘要和信息提取，注重性能和效率。\n\n更多大语言模型及其能力评估参加下图\n\n图 36. 开源模型和闭源模型的性能\n\n### 9. 多模态模型 (2023 – 现在)\n\n#### 9.1 GPT-4V (2023) 和 GPT-4o (2024)\n\n* **GPT-4V (2023)** 是 AI 发展中的重要一步，它将多模态功能集成到已经强大的文本模型中。它不仅能够处理和生成文本，还可以处理和生成图像内容，为更全面的 AI 交互奠定了基础。\n* **GPT-4o (2024)** 是从 GPT-4V 演变而来的，通过复杂的上下文理解来增强多模态集成。与其前身相比，它在不同媒体之间提供了更好的连贯性，能够从文本提示生成更高级的图像，并基于视觉输入进行更精细的推理。此外，GPT-4o 通过高级训练机制实现伦理对齐，确保其输出不仅准确，而且负责任，并与人类价值观保持一致。\n\n#### 9.2 Google’s Gemini (2023 – 现在)\n\n* **Gemini Pro (2023)**: Google 的 Gemini 推出了一系列为多模态任务设计的模型，集成了文本、图像、音频和视频处理。特别是，Gemini Pro 因其可扩展性和效率而脱颖而出，使高级 AI 能够应用于从实时分析到跨不同媒体格式的复杂内容生成等多个领域。\n* **Gemini Ultra 和 Nano (2023)**: Gemini 模型包括适用于不同规模应用的 Ultra 和 Nano 版本，能够执行需要跨多种数据类型理解的任务。它们在视频摘要、多模态翻译和互动学习环境等任务中表现出色，体现了 Google 在推动 AI 在多媒体环境中应用的决心。\n\n#### 9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)\n\n* **Claude 3.0 (2023)** 由 Anthropic 推出，该模型专注于提高 AI 响应的安全性和可靠性，在上下文理解和伦理考虑方面进行了改进。它被设计得更具对话性和辅助性，同时严格遵循避免有害或偏见输出的原则。\n* **Claude 3.5 (2024)** 进一步提升了 Claude 3.0 的能力，在复杂任务中的表现更佳，处理效率更高，并且在用户请求的细节处理上更加细致。这个版本还强调多模态交互，虽然它主要在文本和逻辑任务中表现突出，但在处理视觉或其他感官输入方面也展现出新兴能力，提供更为综合的用户体验。\n\n#### 9.4 LLaVA (2023)\n\n* **LLaVA (Large Language and Vision Assistant)** 是一种创新的多模态 AI (Multimodal AI) 方法，将语言理解与视觉处理结合在一起。LLaVA 于 2023 年开发，能够解读图像并将其与文本内容相联系，使其可以回答关于图像的问题、描述视觉内容，甚至根据视觉线索生成文本。其架构充分利用 Transformer 模型的优势，在需要同时具备视觉和语言理解的任务中实现了最先进的性能。这个模型因其开源特性而备受关注，鼓励在多模态 AI 应用领域进行更多的研究和开发。\n\n  图 37. LLaVA 架构\n\n  这些模型的出现标志着 AI 系统的转变，这些系统不仅能够理解和生成文本，还能解释和创造跨多种模态的内容，更加贴近人类的认知能力。这种 AI 模型的发展推动了更具互动性和直观性的应用程序，它们能够结合不同的感官输入来处理现实世界中的场景，从而拓宽了 AI 在日常生活、研究和工业应用中的可能性。\n\n### 10. 扩散模型 (2015 – 现在)\n\n扩散模型已经成为生成模型中一个重要的类别，它为从复杂数据分布中生成高保真样本提供了一种全新的方法。与传统模型如 GAN 和 VAE 不同，扩散模型采用渐进去噪技术，并在许多应用中表现出色。\n\n#### 10.1 扩散模型简介 (2015)\n\n扩散模型的基础由 Sohl-Dickstein 等人于 2015 年在他们的论文中奠定。他们提出了一种生成过程，即通过逆转逐步添加的噪声，可以将噪声还原为结构化数据。\n\n图 38. 扩散模型原理概要\n\n扩散模型的关键特性：\n\n* **去噪过程**: 这些模型通过逐步添加噪声（前向过程），并学习如何逆转该过程（反向过程），以有效去噪并生成样本。\n* **马尔可夫链**: 这两个过程都被构建为马尔可夫链，每个前向步骤添加高斯噪声，模型学习如何在反向过程中去除这些噪声。\n* **训练目标**: 目标是在每一步中最小化预测噪声与实际噪声之间的差异，优化一种证据下界（ELBO）的形式。\n* **稳定性和鲁棒性**: 它们比 GAN 提供更好的稳定性，避免了模式崩溃等问题，从而能够持续生成多样化的高质量输出。\n\n关于扩散模型的详细介绍，请参考[《Diffusion Model 深入剖析》](https://jarod.blog.csdn.net/article/details/130903760)。\n\n#### 10.2 扩散模型的发展 (2020 – 现在)\n\n* **去噪扩散概率模型 (Denoising Diffusion Probabilistic Models, DDPM) (2020)**: 改进了扩散过程，在图像合成领域设立了新的标杆。\n* **去噪扩散隐式模型 (Denoising Diffusion Implicit Models, DDIM) (2021)**: 通过非马尔可夫采样提高了效率，使生成过程更加灵活。\n* **基于分数的生成模型 (2021)**: 通过使用随机微分方程提高了样本生成的效率。\n* **潜在扩散模型 (Latent Diffusion Model) (2022)**: 成为流行的文本到图像生成系统（如 Stable Diffusion）的基础，显著推动了 AI 生成图像领域的进步，并为更易于访问和高效的生成式 AI 工具铺平了道路。关于潜在扩散模型和 Stable Diffusion 的详细介绍，请参见 [《Stable Diffusion 超详细讲解》](https://jarod.blog.csdn.net/article/details/131018599) 和 [《Stable Diffusion原理详解》](https://jarod.blog.csdn.net/article/details/129280836)。\n\n  图 39. 潜在扩散模型架构\n\n#### 10.3 文生图模型\n\n* **DreamBooth (2022)**: 允许在少量特定主题的图像上训练扩散模型，从而实现个性化的图像生成。\n* **LoRA (2022)**: 代表低秩适应，是一种通过添加少量参数来微调扩散模型的技术，使其更容易适应特定任务或数据集。\n* **ControlNet (2023)**: 通过添加如草图或深度图等输入来控制扩散模型，从而对生成图像提供更多的控制。\n* **FLUX.1 (2024)**: Black Forest Lab 推出了 FLUX.1，这是一种用于 AI 图像生成的先进扩散模型，具备卓越的速度、质量和响应提示的能力。FLUX.1 提供三个版本——Schnell、Dev 和 Pro，并采用了整流流变换器等创新技术，能够生成高度逼真的图像。FLUX.1 还可以生成文字并精准处理手指和脚趾等细节，是一个全面的图像生成器。\n* **Multi-SBoRA (2024)**: Multi-SBoRA 是一种为多个概念定制扩散模型的新方法。它使用正交标准基向量来构建低秩矩阵进行微调，允许区域性和非重叠的权重更新，从而减少跨概念的干扰。这种方法保留了预训练模型的知识，减少了计算开销，并提高了模型的灵活性。实验结果显示，Multi-SBoRA 在多概念定制中表现优异，保持了独立性，并减轻了串扰效应。\n\n#### 10.4 文生视频模型\n\n2024 年 2 月，OpenAI 发布了 [Sora](https://openai.com/sora) 文生视频模型。凭借惊艳的视频生成质量，Sora 一经发布就受到各行各业的追捧和关注。尽管在 Sora 之前已经有好几个文生视频模型，但 Sora 的发布被普遍认为拉开了文生视频的大幕。\n\nSora vs. Pika vs. RunwayML vs. Stable Video 生成视频效果对比\n\n很明显可以看出 Sora 无论从分辨率、时长、精细度和对真实世界的还原程度上都远远好于其他模型。下表给出了详细的对比。\n\n图 40. Sora vs. 早期文生视频模型\n\n然而，Sora 发布后迟迟没有正式上线。全网苦等10个月，Sora 终于在 2024 年 12 月 10 日正式上线。在这 10 个月期间，国产文生视频模型迅速崛起，其中 MiniMax 的海螺和快手的可灵的视频生成质量比肩甚至超越 Sora。\n\n| 名称 | 公司 | 单次生成秒数 | 是否免费 | 生成方式 | 最低月付费 |\n| --- | --- | --- | --- | --- | --- |\n| 可灵 | 快手 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 66元 |\n| 即梦 | 字节 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 69元 |\n| 海螺 | MiniMax | 6s | 限制免费使用次数 | 文生视频、图生视频 | 68元 |\n| Vidu | 生数科技 | 4s | 限制免费使用次数 | 文生视频、图生视频 | 9.9美元 |\n| 智谱清言 | 智谱科技 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| 通义万相 | 阿里 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| FilmAction | 瀚皓科技 | 5s | 限制免费使用次数 | 图生视频 | 50元300电影币 |\n| 白日梦 | 光魔科技 | 最长6分钟 | 限制免费使用次数 | 图生视频 | 29元 |\n| Sora | OpenAl | 5s、20s | 付费使用 | 文生视频、图生视频 | 20美元 |\n| Runway | Runway | 10s | 限制免费使用次数 | 文生视频、图生视频 | 15美元 |\n\n表 1. 主流文生视频模型一览表\n\n相信 2025 年文生视频将会是各大 AI 企业主要争夺的战场。\n\n### 11. 尾声\n\n至此，我们的 AI 简史之旅就要接近尾声了。通过对 AI 发展的回顾，我们可以发现人工智能 (AI) 和深度学习的发展历史充满了突破性的进步和变革性的创新。从早期的简单神经网络到复杂的网络架构，从卷积神经网络 (CNN)、递归神经网络 (RNN) 到现在流行的 Transformer 和扩散模型，这些技术已经彻底改变了许多领域。\n\n最近的技术进步催生了大型语言模型和多模态模型，例如 OpenAI 的 GPT-4o、Google 的 Gemini Pro、Antropic 的 Claude 3.5 Sonnet 和 Meta 的 LLaMA3.1 等，它们在自然语言处理和多模态能力方面表现出色。此外，生成式 AI (Generative AI) 的突破，包括文本到图像和文本到视频生成模型如 Midjourney、DALL-E 3、Stable Diffusion、FLUX.1 和 Sora，极大地拓展了 AI 的创造潜力。\n\n随着研究继续致力于开发更高效、可解释和功能强大的模型，AI 和深度学习对社会和技术的影响将不断加深。这些技术进步不仅推动了传统行业的创新，还为创造性表达、问题解决和人机协作开辟了新可能。\n\n然而，深度学习并不是实现 AI 的唯一途径或最佳途径。符号 AI、强化学习和神经符号 AI 各自具有独特优势，并能弥补深度学习在可解释性和计算资源需求方面的不足。对 AI 的全面理解应涵盖这些多样化的方法。\n\nAI 的未来在于多种方法的协同效应。随着研究的深入，构建多元化的 AI 技术生态系统将确保其平衡和有效的发展，从而造福社会和科技领域。\n\n本文章已经生成可运行项目\n\n确定要放弃本次机会？\n\n福利倒计时\n\n*:*\n*:*\n\n立减 ¥\n\n普通VIP年卡可用\n\n[立即使用](https://mall.csdn.net/vip)\n\n[JarodYv](https://jarod.blog.csdn.net)\n\n[关注](javascript:;)\n关注\n\n* 49\n\n  点赞\n* 踩\n* [89](javascript:;)\n\n  收藏\n\n  觉得还不错?\n  一键收藏\n* [2](#commentBox)\n\n  评论\n* [分享](javascript:;)\n\n  复制链接\n\n  分享到 QQ\n\n  分享到新浪微博\n\n  扫一扫\n* [打赏](javascript:;)\n\n  打赏\n* 打赏\n  举报\n\n  举报\n\n专栏目录\n\n[*人工智能*（*AI*）*简史*：推动新时代的科技力量](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[qq\\_17153885的博客](https://blog.csdn.net/qq_17153885)\n\n12-31\n\n1万+\n\n[*人工智能*（*AI*，Artificial Intelligence）是计算机科学的一个分支，旨在研究和开发可以模拟、扩展或增强人类智能的系统。它涉及多种技术和方法，包括*机器学习*、*深度学习*、自然语言处理（NLP）、计算机视觉、专家系统等。](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[最全*AI**简史*（下）：后*深度学习*时代（*大模型*时代）](https://blog.csdn.net/jpw41/article/details/141403498)\n\n[jpw41的博客](https://blog.csdn.net/jpw41)\n\n08-21\n\n2914\n\n[💡 铺垫这么多终于到*大模型*章节了，前面两篇文章分别就*人工智能*和*深度学习*的发展历史进行了介绍，大致可以理解为：20世纪的*人工智能*发展百花齐放、坎坷中前进，进入21世纪后*深度学习*很快成为*人工智能*中的显学，2020年后则以大语言模型为代表范式。这当然不是说一些逻辑规则的、概率统计*机器学习*的甚至是非*Transformer*的*深度学习*结构已经逐渐推出历史舞台，相反大家各自在自己的领域依然是SOTA，也与*大模型*有许多交汇的地方。](https://blog.csdn.net/jpw41/article/details/141403498)\n\n2\xa0条评论\n您还未登录，请先\n登录\n后发表或查看评论\n\n[*AI*进化史*:*从图灵测试到ChatGPT](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n1-30\n\n[*AI**发展史*是一部人类探索智能本质、拓展认知边界的壮丽史诗,而我们正身处其中最具变革性的章节。DeepSeek等新一代*AI*力量的加入,正在书写着这段历史的新篇章。](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n[*人工智能*(Artificial Intelligence, *AI*)\\_*ai**发展史* csdn](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n1-20\n\n[机器翻译领域出现“ALPAC报告”*:*1966年,美国政府因机器翻译进展缓慢(如“the spirit is willing but the flesh is weak”被译为“酒是好的,但肉已变质”),停止资助相关研究,引发第一次*AI*寒冬。 1970s*:*符号主义局限性显现(如无法处理模糊、非结构化问题),加上计算能力不足,科研 funding 锐减,进入第一次*AI*寒冬。](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[CSDN\\_430422的博客](https://blog.csdn.net/CSDN_430422)\n\n07-21\n\n4621\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[收藏级！史上最通俗的*AI*发展历程综述（附*大模型*学习指南）\n\n最新发布](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[大模型教程的博客](https://blog.csdn.net/Z987421)\n\n12-27\n\n556\n\n[规则式*AI*的死板问题，催生了"让机器自主学习规律"的需求——*机器学习*（ML）技术应运而生，标志着*AI*从"规则驱动"迈入"数据驱动"时代。机器从数据中总结出的规律，最终会形成一个"可复用的计算模型"——这就是*AI*模型（Model）。对程序员而言，可理解为"一个经过数据训练的函数，输入新数据就能输出判断结果"。*AI*模型三大核心要素： - 输入：新的待处理数据（如收到的新邮件）；- 处理：用学到的规律对数据进行分析；- 输出：明确的结果（如"垃圾邮件"或"正常邮件"）。](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[*人工智能*发展*简史*, 没想到17世纪*AI*就出现了!\\_17世纪中叶*人工智能*-CSDN...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n12-17\n\n[本文回顾了*人工智能*的发展历程,从17世纪笛卡尔的构想到20世纪中叶图灵测试的提出,再到达特茅斯会议的*人工智能*定义。文章详细介绍了*AI*在商业、游戏、自动驾驶等领域的应用,以及近年来*深度学习*和无监督学习的重大突破。 部署运行你感兴趣的模型镜像一键部署 *人工智能**发展史* ...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n[*人工智能**发展史*\\_*人工智能*的夏天](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n1-17\n\n[Judea Pearl发表于1988年的名著将概率论和决策理论引入*AI*。现已投入应用的新工具包括贝叶斯网络,隐马尔可夫模型,信息论,随机模型和经典优化理论。针对*神经网络*和进化算法等“计算智能”范式的精确数学描述也被发展出来。 大数据*:*2005 - 现在 从某种意义上讲,2005年是大数据元年,虽然大部分人感受不到数据带来的变化,但是...](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n[*Ai**发展史*(个人理解)梳理](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[记录 IT 领域经验与见解的博客](https://blog.csdn.net/q6115759)\n\n04-17\n\n2355\n\n[在21世纪初期，随着计算机硬件的不断提升和大规模数据的出现，*深度学习*成为*人工智能*领域的热门研究方向。总之，*人工智能*是一项非常重要的技术，将对我们的生活和工作产生深远的影响。随着*人工智能*应用场景的不断增多，*人工智能*将更加个性化和定制化，可以根据不同用户的需求提供不同的服务。4. *人工智能*将更加智能和自主。随着*人工智能*技术的不断进步，*人工智能*将更加智能和自主，可以自主学习和决策，提高*人工智能*的效率和智能性。随着*人工智能*应用场景的不断增多，*人工智能*将更加注重安全和隐私，保护用户的数据和信息安全。](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[*人工智能**发展史*](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[JIA\\_NG\\_FA\\_N的博客](https://blog.csdn.net/JIA_NG_FA_N)\n\n06-08\n\n7819\n\n[起步发展期：1943年—20世纪60年代反思发展期：20世纪70年代应用发展期：20世纪80年代平稳发展期：20世纪90年代—2010年蓬勃发展期：2011年至今。](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[最全科普｜万字长文论*人工智能*的前世今生（下篇）](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[GentelAi的博客](https://blog.csdn.net/GentelAi)\n\n03-12\n\n1306\n\n[到1976年，MYCIN的开发工作基本完成，其诊断准确率达到65%-70%，甚至超过了一些人类医生的表现，成为*人工智能*领域的里程碑。1980年，美国数字设备公司（DEC）开发了XCON（eXpert CONfigurer），这是一个用于配置计算机系统的专家系统，成功帮助公司自动化复杂的计算机配置流程，显著降低了配置错误和成本，成为专家系统商业化的成功案例。Word2Vec的提出不仅显著提升了自然语言处理（NLP）任务的性能，也为后续的语言模型（如BERT和GPT）奠定了基础，成为NLP领域的里程碑。](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[一文了解*大模型*：*AI*（*人工智能*）的发展历程](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[m0\\_56255097的博客](https://blog.csdn.net/m0_56255097)\n\n08-23\n\n4429\n\n[*AI**大模型*作为*人工智能*领域的重要技术突破，正成为推动各行各业创新和转型的关键力量。抓住*AI**大模型*的风口，掌握*AI**大模型*的知识和技能将变得越来越重要。学习*AI**大模型*是一个系统的过程，需要从基础开始，逐步深入到更高级的技术。这里给大家精心整理了一份全面的*AI**大模型*学习资源，包括：*AI**大模型*全套学习路线图（从入门到实战）、精品*AI**大模型*学习书籍手册、视频教程、实战学习、面试题等，资料免费分享！](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[看 *人工智能**简史*](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[我相信......](https://blog.csdn.net/wireless_com)\n\n02-25\n\n2819\n\n[这个春节有些心神不定，只得靠读书和学习平复心情。《*人工智能**简史*》去年很火，在京东的销售榜中也很考前，未能免俗，自己抽空读了一遍，随记随想。（图片来自百度百科）过去只是序幕。*人工智能*缘起达特茅斯会议，在...](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[*AI**发展史*：从图灵机到*AI*大时代](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[m0\\_59164304的博客](https://blog.csdn.net/m0_59164304)\n\n05-21\n\n5806\n\n[*AI*无疑是近年来最热门的话题了，它以一种前所末有的速度影响我们的生活。然而,*AI*的发展历程并非一蹴而就,它经历了漫长的探索和曲折。本期,我们将回顾*AI*的发展历程。](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[*人工智能*与*深度学习*发展*简史*：从感知器到多模态*大模型*的技术演进](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*（*AI*）与*深度学习*的*发展史*，是一部融合数学、计算机科学、神经科学、认知心理学与工程实践的宏大叙事，其演进不仅体现了人类对智能本质的持续追问，更深刻重塑了技术范式、产业格局与社会运行逻辑。...](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*发展*简史*：从1943年M-P模型到21世纪*深度学习*爆发](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[资源摘要信息*:**人工智能*发展*简史*1所涵盖的知识点，系统性地勾勒出*人工智能*学科从思想萌芽到学科正式确立的关键演进脉络，其核心在于揭示人类如何在数学、逻辑学、神经生理学、计算机科学与认知科学的交叉融合中，逐步...](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[*AI**发展史*：从*神经网络*到*大模型*的演进之路](https://wenku.csdn.net/doc/706v1gz262)\n\n[本文以“*AI* *简史*：从*神经元*到*现代**大模型*”为题，系统梳理了从早期人工*神经网络*到当前主流*深度学习*架构的关键节点，涵盖了从理论奠基到实际应用的完整脉络，并提供了可运行的源码示例，使得开发者不仅能理解原理，还...](https://wenku.csdn.net/doc/706v1gz262)\n\n[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https://wenku.csdn.net/column/2fcd64w82r)\n\n[[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https*:*//online.visual-paradigm.com/repository/images/06393536-dbad-4462-982f-7661c65029ea/timeline-diagram-design/.png) # 1. *人工智能*...](https://wenku.csdn.net/column/2fcd64w82r)\n\n[*人工智能*发展*简史*：从图灵机、达特茅斯会议到*神经网络*与控制论的演进](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[而麦克洛奇与皮茨于1943年提出的MP*神经元*模型，则是首次用数学微分方程与阈值逻辑模拟生物*神经元*电生理活动的开创性尝试，它虽高度简化，却构建起连接主义范式的原始框架，成为后世感知机、反向传播算法及深度神经...](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[赫布理论](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[qq\\_31374615的博客](https://blog.csdn.net/qq_31374615)\n\n09-21\n\n3958\n\n[赫布理论\n本词条缺少名片图，补充相关内容使词条更完整，还能快速升级，赶紧来编辑吧！\n赫布理论（英语：Hebbian theory）描述了突触可塑性的基本原理，即突触前*神经元*向突触后*神经元*的持续重复的刺激可以导致突触传递效能的增加。这一理论由唐纳德·赫布于1949年提出，又被称为赫布定律（Hebb\'s\nrule）、赫布假说（Hebb\'s postulate）、细胞结集理论（cel](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[*人工智能**简史*\\_*人工智能**简史*](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[科技博客的分析“工具人”](https://blog.csdn.net/cxq8989)\n\n07-10\n\n387\n\n[*人工智能**简史* 在*人工智能*的早期，计算机科学家试图在计算机中重建人类思维的各个方面。 这就是科幻小说中的智力类型，即或多或少像我们一样思考的机器。 毫无疑问，这种类型的智能称为可理解性。 具有可理解性的计算机可用于探索我们如何推理，学习，判断，感知和执行脑力活动。\n可懂度的早期研究集中于在计算机中对现实世界和思维（来自认知科学家的领域）的部分进行建模。 当您考虑到这些实验是在60年前进行的时...](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[*人工智能*（*AI*）的发展历程](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[juzhi14plus的博客](https://blog.csdn.net/juzhi14plus)\n\n08-30\n\n2797\n\n[综上所述，人类在创造*人工智能*这一新物种的过程中，必须从伦理道德、法律监管、技术创新、教育和培训等方面进行应对，以确保*人工智能*的发展符合人类的利益和价值观，为人类社会的发展带来更多的机遇和福祉。十年后的 1966 年，麻省理工学院的约瑟夫・魏泽鲍姆开发了一款名为 ELIZA 的聊天机器人，这款机器人能够与人类进行简单的对话，为以后突破人类与机器之间的沟通障碍迈出了重要一步。*人工智能*的发展给人类带来了巨大的机遇和挑战，人类在创造这一新物种的过程中，必须采取积极有效的措施进行应对。](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[四张图片道清*AI**大模型*的*发展史*(1943-2023)\n\n热门推荐](https://keziyi.blog.csdn.net/article/details/132310317)\n\n[weixin\\_47567401的博客](https://blog.csdn.net/weixin_47567401)\n\n08-16\n\n1万+\n\n[快速了解大规模语言模型的发展历程](https://keziyi.blog.csdn.net/article/details/132310317)\n\n* [关于我们](//www.csdn.net/company/index.html#about)\n* [招贤纳士](//www.csdn.net/company/index.html#recruit)\n* [商务合作](https://fsc-p05.txscrm.com/T8PN8SFII7W)\n* [寻求报道](//marketing.csdn.net/questions/Q2202181748074189855)\n* 400-660-0108\n* [kefu@csdn.net](mailto:webmaster@csdn.net)\n* [在线客服](https://csdn.s2.udesk.cn/im_client/?web_plugin_id=29181)\n* 工作时间\xa08:30-22:00\n\n* [公安备案号11010502030143](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502030143)\n* [京ICP备19004658号](http://beian.miit.gov.cn/publish/query/indexFirst.action)\n* [京网文〔2020〕1039-165号](https://csdnimg.cn/release/live_fe/culture_license.png)\n* [经营性网站备案信息](https://csdnimg.cn/cdn/content-toolbar/csdn-ICP.png)\n* [北京互联网违法和不良信息举报中心](http://www.bjjubao.org/)\n* [家长监护](https://download.csdn.net/tutelage/home)\n* [网络110报警服务](https://cyberpolice.mps.gov.cn/)\n* [中国互联网举报中心](http://www.12377.cn/)\n* [Chrome商店下载](https://chrome.google.com/webstore/detail/csdn%E5%BC%80%E5%8F%91%E8%80%85%E5%8A%A9%E6%89%8B/kfkdboecolemdjodhmhmcibjocfopejo?hl=zh-CN)\n* [账号管理规范](https://blog.csdn.net/blogdevteam/article/details/126135357)\n* [版权与免责声明](https://www.csdn.net/company/index.html#statement)\n* [版权申诉](https://blog.csdn.net/blogdevteam/article/details/90369522)\n* [出版物许可证](https://img-home.csdnimg.cn/images/20250103023206.png)\n* [营业执照](https://img-home.csdnimg.cn/images/20250103023201.png)\n* ©1999-2026北京创新乐知网络技术有限公司\n\n登录后您可以享受以下权益：\n\n* 免费复制代码\n* 和博主大V互动\n* 下载海量资源\n* 发动态/写文章/加入社区\n\n×\n\n评论\xa02\n\n被折叠的\xa0\xa0条评论\n[为什么被折叠?](https://blogdev.blog.csdn.net/article/details/122245662)\n[到【灌水乐园】发言](https://bbs.csdn.net/forums/FreeZone)\n\n查看更多评论\n\n添加红包\n\n发出的红包\n\nJarodYv\n\n¥1\n¥2\n¥4\n¥6\n¥10\n¥20\n\n扫码支付：¥1\n\n您的余额不足，请更换扫码支付或[充值](https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip)\n\n打赏作者\n\n实付元\n\n扫码支付\n\n钱包余额\n0\n\n1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。  \n 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。\n\n[余额充值](https://i.csdn.net/#/wallet/balance/recharge)\n\n确定取消\n\n举报\n\n* 包含不实信息\n* 涉及个人隐私\n\n请选择具体原因（必选）\n\n* 侮辱谩骂\n* 诽谤\n\n请选择具体原因（必选）\n\n* 搬家样式\n* 博文样式\n\n[点击体验  \nDeepSeekR1满血版](https://ai.csdn.net/chat?utm_source=cknow_pc_blogdetail&spm=1001.2101.3001.10583) \n专业的中文 IT 技术社区，与千万技术人共成长\n客服\n返回顶部', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://blog.csdn.net/jarodyv/article/details/144699658', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99694854, 'save_path': None}}, {'paper_id': '', 'title': '[PDF] 人工智能的回顾与展望', 'authors': [], 'abstract': '第３期 中\u3000国\u3000科\u3000学\u3000基\u3000金 ２ ４ ３ \U00100170“ 双清论坛” 专题:人工智能基础理论及应用\U00100170 人工智能的回顾与展望 吴\u3000飞 １ ∗ 阳春华 ２ 兰旭光 ３ 丁进良 ４ 郑南宁 ３ 桂卫华 ２ 高\u3000文 ５ 柴天佑 ４ 钱\u3000锋 ６ 李德毅 ７ 潘云鹤 １ 韩军伟 ８ 付\u3000俊 ４ 刘\u3000克 ９ 宋\u3000苏 ９ 吴国政 ９ ( １ ．浙江大学人工智能研究所,杭州３ １ ０ ０ ２ ７ ; ２ ．中南大学信息科学与工程学院,长沙４ １ ０ ０ ８ ３ ; ３ ．西安交 通大学人工智能与机器人研究所,西安７ １ ０ ０ ４ ９ ; ４ ．东北大学流程工业综合自动化国家重点实验室,沈阳 １ １ ０ ８ １ ９ ; ５ ．北京大学数字视频编解码技术国家工程实验室,北京１ ０ ０ ８ ７ １ ; ６ ．华东理工大学化工过程先进 控制和优化技术教育部重点实验室, 上海２ ０ ０ ２ ３ ７ ; ７ ． 中国人民解放军军事科学院, 北京１ ０ ０ ８ ５ ０ ; ８ ． 西北工 业大学信息融合技术教育部重点实验室,西安７ １ ０ ０ ７ ２ ; ９ ．国家自然科学基金委员会信息科学部,北京 １ ０ ０ ８ ５ ) 收稿日期: ２ ０ １ ８ Ｇ ０ ３ Ｇ １ ６ ; 修回日期: ２ ０ １ ８ Ｇ ０ ４ Ｇ １ ２ ∗通信作者, E m a i l : w u f e i ＠ z j u ． e d u ． c n [ 摘\u3000要] 基于第１ ９ ４期“ 双清论坛” , 本文分析了我国人工智能发展和人工智能助力制造业优化 升级面临的挑战问题, 从脑启发计算、 人工智能基础前沿和流程制造业智能化三个方面总结了近５ 年主要研究进展, 探讨了未来５年前沿研究领域和科学基金重点资助方向.\n[ 关键词] 脑认知; 神经记忆; 非完全信息; 流程制造; 智能化 １ ９ ５ ５年美国M c C a r t h y等人在研究计划中提出 了人工智能( A r t i f i c i a l I n t e l l i g e n c e ,A I ) 的概念, 随 后１ ９ ５ ６年的达特蒙斯学院( D a r t m o u t h ) 暑期论坛上 首次提出[ １ ].经过６ ０多年的发展和积淀, 伴随着互 联网、 大数据、 云计算和新型传感等技术的发展, 人 工智能正引发可产生链式反应的科学突破, 催生一 批颠覆性技术、 培育经济发展新动能、 塑造新型产业 体系, 加速新一轮科技革命和产业变革.\n２ ０ １ ７年７月, 党中央、 国务院决定实施我国« 新 一代人工智能发展规划» , 十九大报告中也明确提出 推动互联网、 大数据、 人工智能和实体经济深度融 合, 人工智能已上升为国家战略.在此背景下, 国家 自然科学基金委员会( 以下简称基金委) 第１ ９ ４期 “ 双清论坛” 于２ ０ １ ７年１ ２月２ — ３日在湖南长沙召 开, 以“ 人工智能基础理论及应用” 为主题, 探索人工 智能基础前沿及人工智能助力制造业升级.来自北 京大学、 清华大学、 浙江大学、 德国汉堡大学、 中国科 学院和百度公司等３ ４所高校、 研究机构和大型企业 的５ ４位专家和２ ０余位青年学者, 以及基金委政策 局、 信息科学部、 数理科学部、 工程与材料科学部和 管理科学部的相关工作人员参加了此次论坛.与会 专家对脑科学和认知科学、 人工智能、 制造业优化升 级等多学科交叉发展现状与趋势、 未来主要研究方 向和科学问题进行了梳理, 并提出了主题相关领域 的国家自然科学基金资助战略.\n１ 人工智能基础理论与智能制造面临的机 遇与挑战 理解人类认知并建立可计算认知模型需要厘清 从行为到神经系统和回路再到细胞核分子不同层面 的因果关联, 因此理解人类认知的神经基础是促进 人工智能取得长足发展一个很有吸引力但遥远的目 标[ ２ ].从对大脑观测理解中, 抽取对人工智能有启 发性的内容, 为脑启发计算或生物计算带来启示, 是 目前脑科学与人工智能交叉一个活跃方向.除了借 鉴脑科学和神经科学所带来的启示, 国内外学者也 从统计学习、 概率建模和推理优化等角度来推动人 ２ ４ ４ 中\u3000国\u3000科\u3000学\u3000基\u3000金 ２ ０ １ ８年 工智能的发展.\n流程制造业( 主要指钢铁、 石化、 化工、 有色和建 材等原材料工业) 是我国经济社会发展的支柱产业, 作为我国实体经济的基石, 流程制造业的智能化是 提升我国自主创新能力的关键.因此, 推动人工智 能基础理论研究成果向制造业转化, 提升制造业水 平是实现场景人工智能需要发力关键.\n１ ． １ 脑科学给人工智能研究带来巨大启示 当前, 以深度学习为代表的人工智能在图像分 类、 语音识别、 视觉理解和机器翻译等领域取得惊人 的进步[ ３ , ４ ].但深度学习依赖于标注数据, 缺乏逻辑 推理和对因果关系的表达能力, 很难处理具有复杂时 空关联性的任务, 促使我们去寻求新的计算模式.\n人类大脑具有感知、 识别、 学习、 联想、 记忆和 推理等功能, 并非全部用符号计算形式来实现.这 些功能与大脑结构存在着对应关系, 并且大脑的神 经网络系统具有多层反馈机制, 如来自于高级“ 控 制” 脑区到初级视觉脑区的反馈信号, 形成了基于内 容和语义的视觉“ 选择性注意” 机制.类脑计算就是 受上述脑功能和脑神经网络连接机制启发的一种计 算架构, 它以神经形态计算的模式来部分模拟大脑 功能与其结构的对应关系和反馈连接, 增强人工智 能及其计算效率, 不完全依赖现有冯\U00100170诺依曼计算 结构, 也不是复制人类大脑或简单地建造一种模拟 神经元功能的芯片, 更不是去完全替代冯\U00100170诺依曼 计算结构.然而, 至今我们对人类认知功能如何从 复杂动态( 时空演变) 的大脑神经结构中产生, 依然 没有形成较为完整的认识.\n类脑计算最根本挑战是人类大脑信息处理和认 知功能深刻的复杂性.大脑复杂的网络连接、 信息传 输和组织方式在实现人类认知的过程中起着关键作 用.科学界已对大脑是由多个不同功能区域组织连 接而成的网络达成共识, 层次化、 多尺度、 高度连通、 多中央枢纽的网络拓扑结构决定着大脑任务相关以 及自发的活动.当前, 研究者正通过发掘大脑结构连 接、 功能连接和有效连接的聚合和分离( 敛散性) 来洞 察大脑认知机理.在这其中, 大脑结构连接相对静 态, 而功能连接和有效连接具有时空动态演化特性, 如连接强度变化及神经脉冲信号时序关系[ ５ ].\n记忆是生物神经系统一个重要功能.对大脑记 忆机制和模型的研究, 既可以增进人们理解大脑工 作机理, 又能推进类脑( 受脑启发的) 计算发展, 具有 重要的工程应用价值.神经记忆的特征主要表现在 如下四个方面: 分布式表达和存储、 输入信息与被检 索记忆信息在内容上具有关联性、 对记忆信息的存 储和检索具有动态性、 记忆与信息处理过程紧密结 合[ ６ ].鉴于记忆在生物神经系统具有重要作用, 因 此大脑记忆机制研究对推动类脑计算具有重要指导 意义.\n１ ． ２ 人工智能正迈向新的发展阶段 当前, 人工智能具有如下五个重要特点, 推动人 工智能迈向新的发展阶段[ ７ , ８ ]: 从人工知识表达技术 到大数据驱动知识学习; 从处理类型单一的数据到跨 媒体认知、 学习和推理; 从追求“ 机器智能” 到迈向人 机混合的增强智能; 从聚焦研究“ 个体智能” 到基于互 联网络的群体智能; 从机器人到自主无人系统.\n目前, 通过深度学习来形成原始数据更好表达 这一研究已在自然语言理解、 语音识别、 图像分类、 视频检测和知识图谱构建等方面取得巨大成效.与 依赖于人工经验、 通过手工构建的特征不同, 深度学 习一般从标注数据出发, 通过误差后向传播进行参 数调整以实现端到端的区别性特征学习.深度学习 基本动机在于构建多层网络来学习隐含在数据内部 的模式, 从而从数据中可直接学习更具区别力、 更泛 化的特征而非手工定义.\n但是, 这一犹如“ 黑盒子” 式的学习模型存在过 度依赖于标注数据, 难以有效利用逻辑、 先验和知识 等信息, 适应环境变化能力不足、 在对抗环境下易于 被攻击、 结果可解释差等不足.为了弥补上述不足, 一些研究开始重视在深度学习过程中引入先验知识 或更加重视中间特征层, 以建立更具解释性的深度 学习模型.\n与A l p h a G o 在“ 集合封闭、 规则完备、 约束有 限” 场景下完成博弈这一情况不同, 现实社会中诸多 行为决策( 如新经济运行、 产业布局、 网络空间安全 等) 往往是非完全信息条件下博弈, 即在未能全面掌 握所有条件下进行的推理和决策.\n非完全信息条件下人工智能在德州扑克和星际 争霸等方面取得了较好进展, 如卡耐基梅隆大学研 制的无限注德州扑克人工智能程序L i b r a t u s利用纳 什均衡、 残局终结和能力自我提升等方法与人类玩 家博弈[ ９ ], 体现了“ 从经验中进行策略学习的人工智 能能力” .\n从完全信息条件下博弈到非完全信息条件下博 弈需对知识引导、 数据驱动和策略搜索等不同人工 智能方法进行有机整合, 既要对多源头、 多领域、 多 类型数据自底向上进行多层次的深度抽象和归纳, 也要有效管控不确定性的自顶向下演绎和推理[ １ ０ ], 第３期 吴飞等:人工智能的回顾与展望 ２ ４ ５ 以建立逻辑推理、 归纳推理和直觉顿悟相互协调补 充的新模型和方法.对传统人工智能推理进行适度 松绑和合理假设是当前人工智能所面临挑战.\n１ ． ３ 智能制造机遇与挑战 流程制造业是我国实体经济的基石, 也是我国 结构性改革和绿色发展的主战场.近年来流程工业 的工艺、 装备和自动化水平都得到大幅提升, 自主创 新能力持续增强, 产业结构调整取得重要进展.\n然而, 流程制造业面临资源、 能源、 环境日益严 重的制约.新一轮科技革命和产业变革与我国加快 转变经济发展方式形成历史性交汇, 为我们实施创 新驱动发展战略提供了难得的重大机遇.新一代人 工智能、 大数据、 物联网等现代信息技术和制造流程 的紧密结合, 为我国流程制造业的优化升级指明了 发展方向[ １ １ , １ ２ ].\n智能制造已成为提升制造业整体竞争力的核心 高技术, 新一代人工智能技术与先进制造技术深度 融合, 将重构制造流程的各环节, 形成从技术模式到 价值链的新一代智能制造体系.\n流程制造过程包含复杂的物理化学反应, 难以 进行数字化描述, 多生产工序间关联耦合, 许多控 制、 调度、 决策行为仍依赖知识型工作者完成, 严重 阻碍了流程工业向高效化、 绿色化方向发展.首先, 制造过程信息呈现出多维性与多层次性, 面对严苛 指标和复杂要求, 操作人员难以敏锐感知、 深刻认知 制造全局动态变化.其次, 随着数据种类和规模迅 速增加, 无法使用手工方法从大数据中自动高效获 取知识和有价值规律.第三, 生产系统单元间关联 耦合复杂, 人工操作不能实现全局动态优化.最后, 决策系统严重依赖具有局限性的管理层经验, 经常 出现决策失误.正如S c i e n c e 杂志论文指出的[ １ ３ ]: 人类行为已经成为制造流程发展的瓶颈.加快新一 代人工智能技术与先进流程制造技术深度融合, 实 现流程制造智能化已经成为当务之急和行业共识.\n应用人工智能技术来实现流程制造智能化存在 的主要挑战: ( １ )如何在开放、 受扰、 不确定性动态 生产环境中来感知和认知全局工况态势; ( ２ )如何 学习处理不完备小样本数据中所包含碎片化隐性知 识, 以解决难以表征生产情境、 难以计算生产、 控制 和决策中复杂信息的关键技术问题; ( ３ )如何通过 智能方法来精确控制存在关联耦合的多工序以及多 冲突目标协同优化; ( ４ )如何清晰给出多尺度决策 空间的各种要素表征.\n因此, 流程制造智能化必须融合人工智能方法、 流程制造工艺机理和控制理论方法与技术, 从流程 制造环境的智能感知、 流程制造大数据智能计算和 知识自动化、 人机物系统协同的自主控制以及流程 制造动态智能优化决策等方面迎接上述挑战.需要 进一步强调的是, 流程制造智能化不是简单的机器 替代人, 而是感知、 认知、 决策、 执行能力的全面提升 这也会推动人工智能面向重大工程问题的基础 研究.\n２ 人工智能基础理论与智能制造近年主要 进展 ２ ． １ 脑启发计算 / 生物计算进展 近２ ０来, 由于脑科学、 神经科学、 信息科学等学 科的进步, 科学家们已能在微观尺度上观测基因和 蛋白质结构、 在介观尺度上研究细胞、 神经环路和网 络结构、 在宏观尺度上研究脑区结构以及认知行为.\n在这样的背景下, 欧盟、 美国和日本等科技大国先后 发起各类“ 大脑研究计划” [ ２ , ３ ], 引起学术界和产业 界的广泛关注和研究的热情.\n( １ )理论研究.研究者发现在复杂网络的动态 演化和调控过程中, 描述大尺度时空结构的因果关 系网络的曲线图, 是一个具有显著聚类特征的幂函 数曲线, 与许多复杂网络( 如互联网、 社交网、 脑神经 网络等) 有高度相似性[ １ ４ ].该研究对于构建人工神 经网络来模拟大脑的设想提供了理论支持.\n( ２ )观测手段.新的测序、 成像技术和显微技 术已经彻底改变了我们观察大脑的能力( 采用不同 的观测技术可以在不同的空间和时间尺度记录大脑 活动信号) .随着脑科学与认知科学的研究发展, 人 们已经可以在微观水平观测到脑神经元的结构、 不 同脑区的形态, 以及神经元放电、 不同神经元如何构 成神经网络等信息处理过程.结合这些实验观察, 可以在计算机上部分模拟脑信息处理过程[ １ ５ ].\n( ３ )神经元精确调控.在神经元精确调控与观 测方面代表性的技术有光基因技术( O p t o g e n e t Ｇ i c s ) [ １ ６ ], 其基本原理是用光选择神经元的开或断两 种状态之一.通过把能够感受光刺激的离子通道蛋 白的基因转入神经细胞, 使神经细胞在它的细胞膜 上表达这种蛋白, 然后用光来控制这种蛋白的开放 或关闭, 从而控制神经细胞的兴奋或者抑制.通过 该方法来操作神经回路, 探查或顺序激活位于大脑 不同区域的神经元的活动, 观察对大脑的意识、 感觉 和行为的影响.另一项代表性技术是可植入的导电 聚合物网( 软性的大脑电子探针) , 如哈佛大学科学 ２ ４ ６ 中\u3000国\u3000科\u3000学\u3000基\u3000金 ２ ０ １ ８年 家使用该技术, 在老鼠的颅骨部钻孔, 用针头将该网 注射进老鼠大脑, 这个网格很快展开并填充到大脑 组织缝隙部分且与大脑组织交融.此时与外部电脑 连接的纳米导线可用来记录或者刺激单个神经元活 动.该研究小组计划将该技术使用到新生小鼠上, 长时间观察和记录大脑生长发展过程及与环境之间 交互, 从而探析动物大脑奥秘[ １ ７ ].\n( ４ )神经形态计算.\n２ ０ １ ４年８月I B M 在S c i Ｇ e n c e杂志上发表了神经形态计算研究成果—T r u e Ｇ N o r t h芯片[ １ ８ ].该芯片集成了５ ４亿个晶体管, 模拟 了１百万个神经元和２ \U001001b0 ５ ６亿个神经突触, 功耗却只 有６ ５毫瓦.\nI B M 还展示了基于T r u e N o r t h架构的 视觉分类、 运动识别等简单应用.该研究工作令人 印象深刻, 但其技术路线过分强调对生物学模拟, 如 使用“ s p i k i n g Ｇ i n t e g r a t e Ｇ a n d Ｇ f i r e ” 神经元模型.从计 算的复杂性和实现更大规模的网络计算架构角度来 看, 这一技术路线无法实现更有价值应用和构建实 际计算设备.\n欧盟脑计划( H B P ) 着眼于设计一种模拟神经元 功能芯片, 然后用其搭建超级计算机, 进而实现类似 人脑的智能.\n２ ０ １ ５年１ ０月, H B P项目在C e l l杂志 发表了关于重构幼鼠躯体感觉皮质微型数字化电路 的研究结果, 成功模拟了３万个神经元和３ ７ ０ ０万个 神经突触, 再现了脑科学研究中已观测的一些生理 实验结果[ １ ９ ].一些学者认为该成果是集２ ０年神经 生物学实验和１ ０年神经计算科学大成之作, 是迄今 在“ 模拟脑” 领域最全面一项工作.但生物学上可识 别的大脑状态并不等同于功能上可识别的大脑状 态.因此, 通过有限的神经生物学实验, 无法完整的 描述大脑认知过程的功能性概括.\n２ ． ２ 人工智能进展 现有人工智能中知识引导方法长于推理( 但是 其难以拓展) 、 数据驱动模型擅于预测识别( 但是其 过程难以理解) 、 策略学习手段能对未知空间进行探 索( 但其依赖于搜索策略) .因此, 需要有机协调知 识指导下演绎、 数据驱动中归纳、 行为强化内规划等 不同人工智能方法和手段, 建立知识、 数据和反馈于 一体的人工智能理论和模型.当前, 人工智能在大 数据驱动学习( 如深度学习等) 、 知识引导推理( 如知 识图谱生成) 和从经验中学习( 如强化学习等) 以及 自然语言、 视觉理解和语音识别等方面取得了可喜 进展.\n( １ )深度学习中记忆机制引入.在深度学习方 面, 由于“ 端到端” 深度学习在识别分类等任务中表 现了优异性能, 因此如何在深度学习模型中引入注 意力机制和外在记忆体结构, 从而更高效挖掘数据 中感兴趣信息和利用外来信息, 是当前人工智能研 究的热点.\n这一方面代表性工作是在针对序列数据学习的 循环神经网络( R e c u r r e n tN e u r a lN e t w o r k , R N N) 中引入“ 短时记忆” , 如L S TM 和G R U 等模型.其 思路在于当前时刻状态的输出会受到过往若干时刻 状态的影响, 这样学习模型具备了“ 注意力” 机制.\n注意力模型在机器翻译、 语音识别和图文生成等领 域取得了成功, 这一学习输入序列数据和输出序列 数据之中若干单元之间相互影响的注意力机制也被 称为“ 内在记忆” .但是, 人脑在理解当前场景和环 境时, 有效利用了与当前输入数据相关的信息, 这些 信息存储在外部记忆体中.神经图灵机( N e u r a l T u r i n gM a c h i n e , N TM) [ ２ ０ ]就是通过一个控制器来 对外部记忆中存储的知识进行读 / 写操作, 以有效利 用已有知识和先验信息, 其被称深度神经推理.在 端到端深度学习中引入注意力机制和外在记忆体结 构, 可有效利用当前输入数据数据之外的数据和知 识, 克服了仅依赖于输入数据进行驱动学习的不足, 在零样本学习等方面表现出一定的优势.\n( ２ )深度强化学习.强化学习具有探索式( 直 觉牵引) 、 自主式学习特点.深度强化学习是将深度 学习的感知能力和强化学习的决策能力相结合的方 法, 以D e e p m i n d研制的A l p h a G o为代表, 目前在对 弈游戏、 对话生成和机器人控制等方面取得了较好 效果.强化学习的思想形成于２ １世纪初, 其核心概 念由阿尔伯塔大学的R i c h a r dS ． S u t t o n整理完善, 其思想假设来自于心理学中的行为主义, 即通过试 错( t r i a l a n de r r o r ) 来进行学习[ ２ １ ].强化学习强调 如何基于环境而行动, 以取得最大化的预期利益.\n这种思想具有普适性, 因此在博弈论、 控制论、 运筹 学、 信息论、 模拟优化方法、 多A g e n t系统学习、 群体 智能、 统计学以及遗传算法等其他许多领域的理论 研究中都有应用.\n２ ０ １ ３年１ ２月, 在D e e p M i n d发表 深度强化学习文章( D e e p Q Ｇ N e t w o r k , D Q N) [ ２ ２ ]之 前, 强化学习研究已经进入了瓶颈, 主要原因是高维 状态带来了维度灾难.D Q N 基本思想是用深度神 经网络来计算Q 函数, 采用了基于价值( v a l u e Ｇ b a s e d ) 方法.在D Q N之前所有尝试用深度神经网络 进行Q函数学习方法都失败了, 主要原因是此类结构 不稳定, D Q N 采用了奖励截断、 经验重放、 固定目标 Q网络等技术手段实现了稳定的深度增强学习. 第３期 吴飞等:人工智能的回顾与展望 ２ ４ ７ A l p h a G o等深度强化学习算法的成功, 证明了其对复 杂交互环境中时序学习问题建模具有强大能力[ １ ３ ].\n( ３ )开放动态环境中智能学习.人工智能在处 理开放动态环境所显现鲁棒性不足之一问题受到了 国际同行重视.国际机器学习学会创始主席T． D i Ｇ e t t e r i c h在A A A I ２ ０ １ ６主席报告中对鲁棒人工智能 研究进行了总结和展望.针对开放动态环境的不同 特点, 近年已提出了一些应对方法, 例如通过“ 查询 扩展” 等方式获取先验偏移趋势、 增广类别学习方法 来刻画已知类别边界以识别未见类别、 通过共享属 性 / 共享子空间等方式进行属性迁移、 通过多目标优 化来同时考虑不同目标的需求以快速适配到指定需 求上.\n另外一个方面, 图灵奖获得者J u d e aP e a r l提出 的贝叶斯人工智能通过采用严谨概率统计理论刻画 环境或模型的不确定性, 能对不完全信息、 开放性环 境进行建模, 从而动态推理, 甚至在对抗环境下可做 出最优贝叶斯决策.近年来, 国内外在贝叶斯人工 智能以及贝叶斯与深度学习的融合方面进行了大量 的工作.清华大学课题组提出正则化贝叶斯理论, 为经典贝叶斯推理提供了一个额外维度, 并且研发 了珠算概率编程库[ ２ ３ ].国际上的典型进展包括深 度生成模型( 如对抗生成网络等) 及高效算法[ ２ ４ ].\n( ４ )自然语言理解进展.在自然语言处理方 面, 机器学习( 特别是深度学习) 技术促进了自然语 言处理的研究, 深度学习使得自然语言研究从离散 表示发展到连续表示, 提高了一系列自然语言处理 任务的准确率.计算语言学基础理论在词法、 句法、 语义、 篇章等层面取得了较大进展, 构建了相应的语 言资源和知识库.这些均为自然语言处理研究奠定 了坚实的理论基础, 凝练、 定义了自然语言处理研究 的科学问题, 构建了自然语言处理建模基础.\n自然语言处理模型和算法也取得很大进展, 特 别是深度学习模型和自然语言任务结合产生的编 码、 解码模型和算法, 大数据( 特别是来自产业的真 实自然语言大数据) 成为模型训练和解码的知识源.\n产业需求和落地使自然语言处理处于历史上最好的 发展时期, 极大促进了自然语言处理的研究.\n２ ． ３ 流程制造智能化进展 智能感知、 自主控制和优化决策是流程制造智 能化的核心内容.\n( １ )环境智能感知.S c i e n c e 杂志指出亟需提 高测量系统的性能和全生命周期数据的获取能力.\n在美国提出的“ 智能过程制造” 技术框架中主动感知 是重要研究目标之一, 可见智能感知是流程智能制 造的重要前提.流程制造过程中环境恶劣, 包含复 杂的物理化学变化, 其生产工况、 工艺参数的原位检 测和在线感知比较困难, 光学检测新方法、 新型传感 器、 机器视觉、 分布式传感技术等成为流程制造关键 参数检测的研究热点.在流程制造过程中, 检测信 号、 监测图像、 指令文本等数据具有多源异构、 多时 空尺度、 数据缺失和不完整性等特征, 对多源异构数 据运行工况动态感知正成为制造环境智能感知的研 究热点.\n( ２ )智能自主控制.流程制造智能自主控制是 在流程制造系统中引入人工智能学习与智能控制技 术, 使过程生产不依靠人的干预来实现制造生产的 自主运行.目前, 我国流程制造正朝着智能自主控 制发展.基于人工智能方法的专家控制、 学习控制、 模糊控制、 神经网络控制、 进化控制、 主动视觉控制、 仿人行为的智能控制和基于多模型切换的智能解耦 控制等已取得了一定的理论成果.随着大数据、 工 业互联网、 云计算等新的信息技术的工业应用,提 出了基于工业互联网和工业云的云网工业控制系 统.在云网智能控制技术中, 控制器可以分散在网 络中的不同地点, 过程控制不限网络有无和不限地 域, 任何地点和条件都可以实现数据的传输、 远程故 障预警、 故障诊断及自主自愈智能控制.\n( ３ )智能决策.流程制造智能决策是在外部市 场动态需求、 内部企业生产动态状况( 设备能力、 资 源消耗、 环保) 等约束条件下, 以质量、 效率、 成本、 消 耗、 安环等为目标, 采用虚拟仿真前馈、 工业大数据 反馈、 人机交互动态智能决策实现企业全局指标、 生 产流程指标和工艺过程指标的优化, 为流程制造自 主协同控制提供优化方向.随着决策环境日趋复 杂, 决策问题由结构化向半结构化和非结构化问题 领域拓展, 决策方式从最开始的单人决策逐步过渡 到群体决策, 决策目标从单目标决策转向多目标决 策, 决策过程从静态决策发展到动态决策, 决策环境 由确定型向不确定型转变, 使得决策系统呈现出多 元化结构发展态势.基于数据仓库、 辅助决策数据 分析、 数据挖掘和知识库系统的智能决策支持系统 已发展成为目前主流的决策系统.\n从流程制造智能化的发展阶段来看, 初级智能 系统主要依靠状态反馈实现自动决策, 主要解决参 数闭环反馈控制; 中级智能系统主要依靠状态反馈 结合程序预设实现自主决策, 主要解决恒定时不变 ２ ４ ８ 中\u3000国\u3000科\u3000学\u3000基\u3000金 ２ ０ １ ８年 系统的精准控制; 高级智能系统应当是依靠认知学 习实现复杂分析、 精确判断和创新决策, 具有不断自 我改善、 学习提升的能力, 主要解决时变—开放的复 杂动态决策问题.新一代智能制造主要特点在于其 学习能力, 使知识的产生、 获取、 应用和传承效率发 生革命性变化, 显著提高感知认知、 自主控制和创新 决策能力.\n３ 未来５年拟重点资助方向的建议 ( １ )大脑有效连接的动态因果机制与信息机 理.认知功能与大脑网络中不同分布区域的动态交 互机理; 大脑功能网络的形成和解散与大脑结构网 络的衔接和分离的内在机制; 在复杂的认知行为中, 大脑功能网络有效合作、 竞争以及协调工作模式; 不 同脑组织的功能角色以及角色间的基本数学原理, 包括知识的获取、 表示和存储; 大脑记忆强化内在机 理; 大脑用来处理外界激励的能量消耗模式.\n( ２ )大脑通讯编码形式.生物神经网络是一种 脉冲神经网络, 神经元接收到的输入脉冲引起细胞 体膜电位的升高, 当其超过一定阈值时, 将会发出一 个神经脉冲到轴突, 并通过突触与后续的神经元树 突进行神经递质的传输, 影响其膜电位.锋电位作 为神经元之间的传输信号, 研究和理解其信息编码 的方式( S p i k es i g n a l c o d i n g ) 将有助于我们更好的 理解大脑的工作方式以及发展人机交互技术.\n( ３ )构建大尺度的神经形态计算系统.神经形 态工程学的关键问题是理解单个神经元的形态、 神 经元环路以及整体架构, 创建和获得满足不同任务 需求所要的计算能力, 完成信息的表达形式、 学习以 及发展适应性的塑性变化及有利于进化的改变.\n( ４ )高性能\\低功耗的类脑计算芯片与平台.\n类脑计算需要完成高性能计算到高智能计算进阶及 高功耗到低功耗进阶.计算能力的度量由每秒完成 的浮点数操作( F L O P S ) 变化为每秒完成的突触操 作( s y n a p t i co p e r a t i o n sp e r s e c o n d , S O P S ) .人类大 脑约有１ ０ １ １的神经元, 其中每个神经元有约１ ０ ４的 突触连接, 如果以１ ０ H z的速度释放神经脉冲, 其计 算量约为１ ０ １ ６次S O P S .假设每次神经脉冲操作需 要１ ０ ２次数值计算, 则共需要具有１ ０ １ ８次运算能力 的高性能计算系统才能模拟整个大脑的计算能力.\n目前最快的高性能计算机天河— ２的计算能力为 ３ ３ ． ８ ６ ~ ５ ４ ． ９ ０ P F L O P S .\n( ５ )脑启发的视觉处理计算架构.借鉴视觉通 道特别是视网膜的信息处理能力, 以及大脑神经连 接的网络化结构, 设计和研究新型的视觉计算模型 和处理架构.这种架构的组成单元包括从帧驱动到 事件驱动的信息获取单元( 智能计算前移) 、 注意力 选择 / 事件驱动的信息获取方式、 时空动态的信息编 码、 网络化分布式的动态信息处理、 结合长时和短时 记忆功能的网络结构, 以及条件要素的约束和引导 的有效控制.实现大脑结构网络、 功能网络和有效 网络在视觉处理架构不同层次的映射.\n( ６ )自然语言理解.研究人类理解、 表示和认 知自然语言的机制; 研究服务于自然语言处理的知 识获取手段, 以获取世界知识、 领域知识和语言学知 识; 研究自然语言处理的计算机数学建模方法, 如建 模词法、 句法、 语义、 篇章等; 研究基于知识的自然语 言处理方法, 如篇章级自然语言深度理解、 问答和 对话.\n( ７ )神经网络的记忆可计算模型.研究网络记 忆的可计算模型, 发展网络记忆的吸引子理论, 构建 新型网络模型; 研究记忆学习与记忆提取的可计算模 型, 发展网络学习算法; 研究记忆对网络输出稳定性 的作用机理, 发展基于记忆的网络输出稳定性方法.\n( ８ )复杂场景自动理解.\n研究从属性、 物体到场景的跨层次关系发现与 相应视觉知识的表示和推理方法; 研究对场景的层 次化识别及与之相关的类别与属性自动发现方法; 研究具有触类旁通能力的识别与学习方法; 建立视 觉对象的时空特征与语言表达之间的对齐, 进而和 计算语言学相结合, 实现从感知到认知的无缝转换.\n( ９ )自然场景理解中的脑功能网络及其启发的 深度神经网络.多模态脑功能成像( 如功能磁共振 成像f MR I 、 脑电图E E G) 融合方法与技术, 实现脑 功能活动的高时空分辨观测; 自然场景理解过程中 脑功能网络的识别; 各子网络之间的增强与抑制、 因 果与调制关系; 以此为启发信息的大规模神经网络 的结构设计、 高效训练方法与实验验证.\n( １ ０ )智能测试机制.建立人机对话新计算理 论框架, 为计算机通过图灵测试提供理论依据.开 发符合人类对话原则( 如合作原则、 礼貌原则等) 的 对话系统, 借助于理论而非工程测试得到人机对话 的成功几率.\n( １ １ )量子机器学习.发展机器学习、 包括深度 学习、 对抗学习、 在线学习与增强学习的量子算法, 给出实质加速或指数加速, 给出概率意义下的收敛 性[ ２ ５ ].发展基于量子模型、 针对量子数据的量子机 器学习方法.针对机器学习需求, 发展高效量子算 第３期 吴飞等:人工智能的回顾与展望 ２ ４ ９ 法, 包括量子线性代数算法、 量子优化算法、 N P C 问 题的量子算法等.\n( １ ２ )统计机器学习的新理论及方法.贝叶斯 学习与贝叶斯决策的基础理论、 基于变分和蒙特卡 洛的高效贝叶斯推理算法、 贝叶斯与深度学习的有 机融合理论与算法、 面向大数据和贝叶斯深度学习 的概率编程库、 支持高效学习与决策的软硬件平台.\n( １ ３ )开放动态环境下的人工智能理论.对感 知与表示进行研究, 弥补感知渠道独立、 缺乏渠道协 作、 数据源孤立、 模型可理解性差、 语义层次低等缺 陷.对学习与推理进行研究, 有效处理环境开放动 态、 样本数量巨大、 标记稀缺低质等普遍特性, 增强 可理解性, 整合知识获取与知识推理能力.对决策 与控制技术进行研究, 克服专家知识依赖严重、 环境 适应能力差、 样本利用率低等不足.\n( １ ４ )跨媒体推理与知识获取.研究多源头、 跨 媒体、 双向交互的综合推理机制, 打通逻辑、 语言、 听 觉和视觉等之间的鸿沟, 拓展人工智能系统因果推 断能力, 建立逻辑推理、 归纳推理和直觉顿悟相互协 调补充的新模型和方法, 进而使得人工智能具备创 意创造思维的能力.\n( １ ５ )在线智慧教育平台.构建情境感知的泛 在化网络学习环境, 克服情境多变难感知与用户体 验难适配问题; 知识图谱与知识发现, 解决碎片化知 识的融合与组织问题; 研究智能导师手段, 改善认知 过载迷航、 师生时空分隔辅助难; 研究多维指标评教 与管理决策, 克服在线教学质量监督难不足, 丰富监 督与管理方法, 最终构建“ 沉浸式情景化学习环境— 碎片化知识融合—个性化导学与问答—科学评教与 决策” 的一体化运作机制, 为促进在线教育产业发展 和构建终身学习社会提供技术支撑.\n( １ ６ )不确定制造环境下的智能感知与动态认 知.复杂流程制造环境下物料成分、 特殊生产参数 快速原位检测; 机理与装置运行信息融合的工业过 程多尺度、 多维度智能建模; 基于泛在感知与物联网 的质能转化智能感知; 全生命周期安全环境足迹监 控与风险溯源分析; 大数据与机理分析相结合的制 造流程运行态势认知.\n( １ ７ )流程制造大数据智能计算与知识自动化.\n制造过程海量、 高维、 异构、 跨域信息的知识获取与 表示; 支持在线迭代学习和智能共享的边缘计算; 基 于大数据智能和跨媒体智能的认知、 学习与关联; 面 向制造C P S的知识发现、 知识处理与知识推理; 面 向智能制造的知识自动化方法与系统.\n( １ ８ )制造过程的自主协同控制.集监控、 诊 断、 优化、 自愈于一体的制造过程智能自主控制; 流 程制造多智能体系统分析与协同控制; 制造过程自 适应与工况迁移智能控制; 精细化智能控制与网络 化协同控制; 异常工况智能预测与过程自愈控制.\n( １ ９ )流程制造动态智能优化决策.不确定、 开 放环境下的人机合作决策与互学习; 多尺度、 多冲突 目标、 多 / 变约束等的智能优化决策与控制一体化; 不确定小样本条件下的优化决策; 工业生产过程风 险预警与异常溯源分析与决策.\n致谢\u3000感谢薛建儒、 杜文莉、 陈晓方、 谢永芳、 邓方、 赵春晖、 钟伟民、 袁小锋、 黄科科、 王海峰、 陈熙霖、 吴 枫、 黄铁军、 郑庆华、 邹北骥、 高小山、 李肯立、 俞杨、 章毅、 于剑、 张民、 朱军、 黄凯奇、 赵珺、 刘青山等专家 学者对本文的贡献.\n参 考 文 献 [ １ ] M c C a r t h yJ ,M i n s k yM L, S h a n n o nC, e t a l , R e s e a r c hP r o Ｇ j e c to nA r t i f i c i a l I n t e l l i g e n c e , D a r t m o u t h , A u g u s t ３ １ , １ ９ ５ ５ ． [ ２ ] B R A I N２ ０ ２ ５AS c i e n t i f i cV i s i o n , ２ ０ １ ４ ． [ ３ ] S i l v e rD,H u a n g A,M a d d i s o n C J ,e ta l ．M a s t e r i n gt h e g a m eo fG ow i t hd e e pn e u r a l n e t w o r k sa n dt r e es e a r c h , N a Ｇ t u r e , ２ ０ １ ６ , ５ ２ ９ ( ７ ５ ８ ７ ) : ４ ８ ４ — ４ ８ ９ ． [ ４ ] 郑南宁, 任鹏举, 陈霸东, 等．类脑计算的问题与视觉认知． 中国自动化学会通讯, ２ ０ １ ６ , ３ ７ ( ２ )． [ ５ ] B r a u nU, S c h ä f e rA,W a l t e rH, e t a l ． D y n a m i c r e c o n f i g u r a Ｇ t i o no f f r o n t a lb r a i nn e t w o r k sd u r i n ge x e c u t i v ec o g n i t i o ni n h u m a n s ． P r o c e e d i n g so f t h eN a t i o n a lA c a d e m yo fS c i e n c e s , ２ ０ １ ５ , １ １ ２ ( ３ ７ ) : １ １ ６ ７ ８ — １ １ ６ ８ ３ ． [ ６ ] 李耀勇, 联想记忆模型: H o p f i e l d神经网络与动态神经网络 [ D] ． 西安交通大学, １ ９ ９ ８ ． [ ７ ] P a nY．H e a d i n g t o w a r da r t i f i c i a l i n t e l l i g e n c e ２ ． ０ ． E n g i n e e r Ｇ i n g , ２ ０ １ ６ , ２ ( ４ ) : ４ ０ ９ — ４ １ ３ ． [ ８ ] P a n YH． ２ ０ １ ８s p e c i a l i s s u eo na r t i f i c i a l i n t e l l i g e n c e２ ． ０ : t h e o r i e s a n da p p l i c a t i o n s ． F r o n t i e r so f I n f o r m a t i o nT e c h n o l Ｇ o g y& E l e c t r o n i cE n g i n e e r i n g２ ０ １ ８ , １ ９ ( １ ) : １ — ２ ． [ ９ ] B r o w nN,S a n d h o l m T．S u p e r h u m a n A If o rh e a d s Ｇ u pn o Ｇ l i m i t p o k e r : L i b r a t u s b e a t s t o pp r o f e s s i o n a l s ． S c i e n c e , ２ ０ １ ７ : e a a o １ ７ ３ ３ ． [ １ ０ ] 潘云鹤, 综合推理的研究． 模式识别与人工智能, １ ９ ９ ６ , ９ ( ３ ) : ２ ０ １ — ２ ０ ８ [ １ １ ] 周济,智能制造—“ 中国制造２ ０ ２ ５ ”的主攻方向．中国机械 工程, ２ ０ １ ５ , ２ ６ ( １ ７ ) : ２ ２ ７ ３ — ２ ２ ８ ４ ． [ １ ２ ] 习近平总书记系列重要讲话读本( ２ ０ １ ６年版) ,北京: 学习出 版社、 人民出版社出版, ２ ０ １ ６ [ １ ３ ]G i lY, G r e a v e sM,H e n d l e r J , e t a l ．A m p l i f ys c i e n t i f i cd i s Ｇ c o v e r y w i t h a r t i f i c i a l i n t e l l i g e n c e ．S c i e n c e , ２ ０ １ ４ , ３ ４ ６ ( ６ ２ ０ ６ ) : １ ７ １ — １ ７ ２ ． ２ ５ ０ 中\u3000国\u3000科\u3000学\u3000基\u3000金 ２ ０ １ ８年 [ １ ４ ] K r i o u k o vD, K i t s a k M, S i n k o v i t sR S , e ta l ．N e t w o r kc o s Ｇ m o l o g y ． S c i e n t i f i cR e p o r t s , ２ ０ １ ２ , ２ ( ２ ０ ) : １ ０ ２ ７ ２ — １ ０ ２ ８ ４ ． [ １ ５ ]T h eH u m a nB r a i nP r o j e c t : A R e p o r t t ot h eE u r o p e a nC o m Ｇ m i s s i o n , ２ ０ １ ３ ． [ １ ６ ]L i uX, R a m i r e zS , P a n gP T, e t a l ． O p t o g e n e t i c s t i m u l a t i o n o f ah i p p o c a m p a l e n g r a ma c t i v a t e sf e a rm e m o r yr e c a l l ．N a Ｇ t u r e , ２ ０ １ ２ , ４ ８ ４ ( ７ ３ ９ ４ ) : ３ ８ １ — ３ ８ ５ [ １ ７ ]h t t p : / / w w w．s c i e n t i f i c a m e r i c a n ．c o m / r e p o r t / w o r l d Ｇ c h a n Ｇ g i n g Ｇ i d e a s Ｇ ２ ０ １ ５ １ ． [ １ ８ ] M e r o l l aP A,A r t h u rJ V,A l v a r e z Ｇ I c a z aR, e ta l ．A m i l l i o n s p i k i n g Ｇ n e u r o n i n t e g r a t e dc i r c u i tw i t has c a l a b l ec o mm u n i c a Ｇ t i o nn e t w o r k a n di n t e r f a c e ．S c i e n c e ,２ ０ １ ４ ,３ ４ ５( ６ １ ９ ７) : ６ ６ ８ — ６ ７ ３ ． [ １ ９ ] M a r k r a m H,M u l l e rE,R a m a s w a m yS , e ta l ．R e c o n s t r u c Ｇ t i o n a n d S i m u l a t i o n o f N e o c o r t i c a l M i c r o c i r c u i t r y ． C e l l , ２ ０ １ ５ , １ ６ ３ ( ２ ) : ４ ５ ６ — ４ ９ ２ ． [ ２ ０ ]G r a v e sA,W a y n eG, D a n i h e l k a I ． N e u r a l t u r i n gm a c h i n e s ． a r X i vp r e p r i n t a r X i v : １ ４ １ ０ ． ５ ４ ０ １ , ２ ０ １ ４ ． [ ２ １ ]S u t t o nR S ,B a r t o A G．R e i n f o r c e m e n tl e a r n i n g :A ni n t r o Ｇ d u c t i o n , T h eM I TP r e s s ． [ ２ ２ ] M n i hV, K a v u k c u o g l uK, S i l v e rD, e t a l ． H u m a n Ｇ l e v e l c o n Ｇ t r o l t h r o u g hd e e p r e i n f o r c e m e n t l e a r n i n g ． N a t u r e , ２ ０ １ ５ , ５ １ ８ ( ７ ５ ４ ０ ) : ５ ２ ９ — ５ ３ ３ [ ２ ３ ]Z h uJ , C h e nN, X i n gE． B a y e s i a nI n f e r e n c ew i t hP o s t e r i o r R e g u l a r i z a t i o na n d a p p l i c a t i o n st oI n f i n i t e L a t e n t S VM s ． J o u r n a l o f M a c h i n e L e a r n i n g R e s e a r c h , ２ ０ １ ４ , １ ５ : １ ７ ９ ９ — １ ８ ４ ７ ． [ ２ ４ ]G o o d f e l l o wI , P o u g e t Ｇ A b a d i eJ ,M i r z a M, e ta l ．G e n e r a t i v e a d v e r s a r i a l n e t w o r k s ． N I P S , ２ ０ １ ４ ． [ ２ ５ ]B i a m o n t e J ,W i t t e kP , P a n c o t t iN, e t a l ． Q u a n t u m m a c h i n e l e a r n i n g ． N a t u r e , ２ ０ １ ７ , ５ ４ ９ ( ７ ６ ７ １ ) : １ ９ ５ ． A r t i f i c i a l i n t e l l i g e n c e : r e v i e wa n d f u t u r e o p p o r t u n i t i e s W uF e i １ Y a n gC h u n h u a ２ L a nX u g u a n g ３ D i n gJ i n l i a n g ４ Z h e n gN a n n i n g ３ G u iW e i H u a ２ G a oW e n ５ C h a iT i a n y o u ４ Q i a nF e n g ６ L iD e y i ７ P a nY u n h e １ H a nJ u n w e i ８ F uJ u n ４ L i uK e ９ S o n gS u ９ W uG u o Z h e n g ９ ( １ ． I n s t i t u t e o fA r t i f i c i a l I n t e l l i g e n c e, Z h e j i a n gU n i v e r s i t y, H a n g z h o u３ １ ０ ０ ２ ７ ; ２ ． S c h o o l o fI n f o r m a t i o nS c i e n c e a n dE n g i n e e r i n g, C e n t r a l S o u t hU n i v e r s i t y, C h a n g s h a４ １ ０ ０ ８ ３ ; ３ ． I n s t i t u t e o fA r t i f i c i a l I n t e l l i g e n c ea n dR o b o t i c s, X i \U001001b3 a nJ i a o t o n gU n i v e r s i t y, X i \U001001b3 a n７ １ ０ ０ ４ ９ ; ４ ． S t a t e K e yL a b o r a t o r y o fS y n t h e t i c a lA u t o m a t i o nf o rP r o c e s s I n d u s t r i e s, N o r t h e a s t e r nU n i v e r s i t y, S h e n y a n g１ １ ０ ８ １ ９ ; ５ ． N a t i o n a l E n g i n e e r i n gL a b o Ｇ r a t o r yf o rV i d e oT e c h n o l o g y, P e k i n gU n i v e r s i t y, B e i j i n g１ ０ ０ ８ ７ １ ; ６ ． K e yL a b o r a t o r yo fA d v a n c e dC o n t r o l a n dO p t i m i z a t i o nf o rC h e m i c a l P r o c e s s e s, E a s t C h i n aU n i v e r s i t yo fS c i e n c ea n dT e c h n o l o g y, S h a n g h a i２ ０ ０ ２ ３ ７ ; ７ ． P L AA c a d e m yo f M i l i t a r yS c i e n c e, B e i j i n g１ ０ ０ ８ ５ ０ ; ８ ． K e yL a b o r a t o r yo fI n f o r m a t i o nF u s i o nT e c h n o l o g y, N o r t h w e s t e r nP o l y t e c h n i c a lU n i v e r s i t y, X i \U001001b3 a n７ １ ０ ０ ７ ２ ; ９ ． D e p a r t m e n t o fI n f o r m a t i o n S c i e n c e s, N a t i o n a lN a t u r a lS c i e n c eF o u n d a t i o no fC h i n a, B e i j i n g１ ０ ０ ８ ５ ) A b s t r a c t F o c u s i n go n t h eo u t p u t s o f t h e １ ９ ４ t hS h u a n g q i n gF o r u mo fN a t i o n a lN a t u r a l S c i e n c eF o u n d a t i o n o fC h i n a , t h i sp a p e ra n a l y s e st h er e c e n ta d v a n c e sa n dm a i ns c i e n t i f i cc h a l l e n g e i nt e r m so fb r a i n Ｇ i n s p i r e d c o m p u t i n g , t h e o r e t i c a lA I a n dP r o c e s sm a n u f a c t u r e v i aA I ． A t t h e s a m e t i m e , t h i s p a p e r g i v e s o u t t h ek e y r e s e a r c hd i r e c t i o n s f u n d e d i n t h e c o m i n g３ — ５y e a r s ． K e yw o r d s b r a i nr e c o g n i t i o n , n e u r a lm e m o r y , i m p e r f e c t Ｇ i n f o r m a t i o n , p r o c e s sm a n u f a c t u r e , i n t e l l i g e n c e', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.nsfc.gov.cn/csc/20345/20348/pdf/2018/201803243.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.89982784, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 13:08:19,357 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=5, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 13:08:19,357 - __main__ - INFO - handle_download: downloaded=5
2026-02-03 13:08:19,358 - __main__ - INFO - call_tool payload: source_tool=tavily_download, result_type=papers, count=5
2026-02-03 13:08:19,358 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=5
2026-02-03 13:08:19,358 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能的创新发展与社会影响 - 中国人大网', 'authors': [], 'abstract': '当前位置：[首页](../../../../)\xa0>\xa0 [常委会专题讲座](../../node_541.htm)\n\n## 十三届全国人大常委会专题讲座第七讲\n\n# 人工智能的创新发展与社会影响\n\n浏览字号： [大](#) [中](#) [小](#) 来源： 中国人大网 2018年10月29日 10:26:09\n\n1956年人工智能（Artificial Intelligence，简称AI）的概念被正式提出，标志着人工智能学科的诞生，其发展目标是赋予机器类人的感知、学习、思考、决策和行动等能力。经过60多年的发展，人工智能已取得突破性进展，在经济社会各领域开始得到广泛应用并形成引领新一轮产业变革之势，推动人类社会进入智能化时代。美国、日本、德国、英国、法国、俄罗斯等国家都制定了发展人工智能的国家战略，我国也于2017年发布了《新一代人工智能发展规划》，发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏等地政府也相继出台推动人工智能发展的相关政策文件，社会各界对人工智能的重大战略意义已形成广泛共识。\n\n总体上看，已过花甲之年的人工智能当前的发展具有“四新”特征：以深度学习为代表的人工智能核心技术取得新突破、“智能+”模式的普适应用为经济社会发展注入新动能、人工智能成为世界各国竞相战略布局的新高地、人工智能的广泛应用给人类社会带来法律法规、道德伦理、社会治理等方面一系列的新挑战。因此人工智能这个机遇与挑战并存的新课题引起了全球范围内的广泛关注和高度重视。虽然人工智能未来的创新发展还存在不确定性，但是大家普遍认可人工智能的蓬勃兴起将带来新的社会文明，将推动产业变革，将深刻改变人们的生产生活方式，将是一场影响深远的科技革命。\n\n为了客观认识人工智能的本质内涵和创新发展，本报告在简要介绍人工智能基本概念与发展历程的基础上，着重分析探讨人工智能的发展现状和未来趋势，试图揭示人工智能的真实面貌。很显然，在当下人工智能蓬勃发展的历史浪潮中如何选择中国路径特别值得我们深入思考和探讨。因此，本报告最后就我国人工智能发展态势、存在问题和对策建议也进行了阐述。\n\n二、人工智能的发展历程与启示\n\n1956年夏，麦卡锡（John McCarthy）、明斯基（Marvin Minsky）、罗切斯特（Nathaniel Rochester）和香农（Claude Shannon）等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能”这一概念，标志着人工智能学科的诞生。人工智能的目标是模拟、延伸和扩展人类智能，探寻智能本质，发展类人智能机器。人工智能充满未知的探索道路曲折起伏，如何描述1956年以来60余年的人工智能发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能60余年的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年-20世纪60年代初。人工智能概念在1956年首次被提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、LISP表处理语言等，掀起了人工智能发展的第一个高潮。\n\n二是反思发展期：60年代-70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入了低谷。\n\n三是应用发展期：70年代初-80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入了应用发展的新高潮。\n\n四是低迷发展期：80年代中-90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：90年代中-2010年。由于网络技术特别是互联网技术的发展，信息与数据的汇聚不断加速，互联网应用的不断普及加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年IBM深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念，这些都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年-至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器（Graphics Processing Unit，简称GPU）等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越科学与应用之间的“技术鸿沟”，图像分类、语音识别、知识问答、人机对弈、无人驾驶等具有广阔应用前景的人工智能技术突破了从“不能用、不好用”到“可以用”的技术瓶颈，人工智能发展进入爆发式增长的新高潮。\n\n通过总结人工智能发展历程中的经验和教训，我们可以得到以下启示：\n\n（一）尊重学科发展规律是推动学科健康发展的前提。科学技术的发展有其自身的规律，顺其者昌，违其者衰。人工智能学科发展需要基础理论、数据资源、计算平台、应用场景的协同驱动，当条件不具备时很难实现重大突破。\n\n（二）基础研究是学科可持续发展的基石。加拿大多伦多大学杰弗里·辛顿（Geoffrey Hinton）教授坚持研究深度神经网络30年，奠定人工智能蓬勃发展的重要理论基础。谷歌的DeepMind团队长期深入研究神经科学启发的人工智能等基础问题，取得了阿尔法狗等一系列重大成果。\n\n（三）应用需求是科技创新的不竭之源。引领学科发展的动力主要来自于科学和需求的双轮驱动。人工智能发展的驱动力除了知识与技术体系内在矛盾外，贴近应用、解决用户需求是创新的最大源泉与动力。比如专家系统人工智能实现了从理论研究走向实际应用的突破，近些年来安防监控、身份识别、无人驾驶、互联网和物联网大数据分析等实际应用需求带动了人工智能的技术突破。\n\n（四）学科交叉是创新突破的“捷径”。人工智能研究涉及信息科学、脑科学、心理科学等，上世纪50年代人工智能的出现本身就是学科交叉的结果。特别是脑认知科学与人工智能的成功结合，带来了人工智能神经网络几十年的持久发展。智能本源、意识本质等一些基本科学问题正在孕育重大突破，对人工智能学科发展具有重要促进作用。\n\n（五）宽容失败应是支持创新的题中应有之义。任何学科的发展都不可能一帆风顺，任何创新目标的实现都不会一蹴而就。人工智能60余载的发展生动地诠释了一门学科创新发展起伏曲折的历程。可以说没有过去发展历程中的“寒冬”就没有今天人工智能发展新的春天。\n\n（六）实事求是设定发展目标是制定学科发展规划的基本原则。达到全方位类人水平的机器智能是人工智能学科宏伟的终极目标，但是需要根据科技和经济社会发展水平来设定合理的阶段性研究目标，否则会有挫败感从而影响学科发展，人工智能发展过程中的几次低谷皆因不切实际的发展目标所致。\n\n三、人工智能的发展现状与影响\n\n人工智能经过60多年的发展，理论、技术和应用都取得了重要突破，已成为推动新一轮科技和产业革命的驱动力，深刻影响世界经济、政治、军事和社会发展，日益得到各国政府、产业界和学术界的高度关注。从技术维度来看，人工智能技术突破集中在专用智能，但是通用智能发展水平仍处于起步阶段；从产业维度来看，人工智能创新创业如火如荼，技术和商业生态已见雏形；从社会维度来看，世界主要国家纷纷将人工智能上升为国家战略，人工智能社会影响日益凸显。\n\n（一）专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定领域的人工智能技术（即专用人工智能）由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，因此形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域，统计学习是专用人工智能走向实用的理论基础。深度学习、强化学习、对抗学习等统计机器学习理论在计算机视觉、语音识别、自然语言理解、人机博弈等方面取得成功应用。例如，阿尔法狗在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，语音识别系统5.1%的错误率比肩专业速记员，人工智能系统诊断皮肤癌达到专业医生水平，等等。\n\n（二）通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。虽然包括图像识别、语音识别、自动驾驶等在内的专用人工智能领域已取得突破性进展，但是通用智能系统的研究与应用仍然是任重而道远，人工智能总体发展水平仍处于起步阶段。美国国防高级研究计划局（Defense Advanced Research Projects Agency，简称DARPA）把人工智能发展分为三个阶段：规则智能、统计智能和自主智能，认为当前国际主流人工智能水平仍然处于第二阶段，核心技术依赖于深度学习、强化学习、对抗学习等统计机器学习，AI系统在信息感知（Perceiving）、机器学习（Learning）等智能水平维度进步显著，但是在概念抽象（Abstracting）和推理决策（Reasoning）等方面能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n（三）人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，在其2017年的年度开发者大会上，谷歌明确提出发展战略从“Mobile First”（移动优先）转向“AI First”（AI优先）；微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿，麦肯锡报告2016年全球人工智能研发投入超300亿美元并处于高速增长，全球知名风投调研机构CB Insights报告显示2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n（四）创新生态布局成为人工智能产业发展的战略高地。信息技术（IT）和产业的发展史就是新老IT巨头抢滩布局IT创新生态的更替史。例如，传统信息产业IT（Information Technology）代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网IT（Internet Technology）代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等，目前智能科技IT（Intelligent Technology）的产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动AI技术生态的研发布局，全力抢占人工智能相关产业的制高点。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理GPU服务器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。在技术生态方面，人工智能算法、数据、图形处理器（Graphics Processing Unit，简称GPU）/张量处理器（Tensor Processing Unit，简称TPU）/神经网络处理器（Neural network Processing Unit，NPU）计算、运行/编译/管理等基础软件已有大量开源资源，例如谷歌的TensorFlow第二代人工智能学习系统、脸书的PyTorch深度学习框架、微软的DMTK分布式学习工具包、IBM的SystemML开源机器学习系统等；此外谷歌、IBM、英伟达、英特尔、苹果、华为、中国科学院等积极布局人工智能领域的计算芯片。在人工智能商业和应用生态布局方面，“智能+X”成为创新范式，例如“智能+制造”、“智能+医疗”、“智能+安防”等，人工智能技术向创新性的消费场景和不同行业快速渗透融合并重塑整个社会发展，这是人工智能作为第四次技术革命关键驱动力的最主要表现方式。人工智能商业生态竞争进入白热化，例如智能驾驶汽车领域的参与者既有通用、福特、奔驰、丰田等传统龙头车企，又有互联网造车者如谷歌、特斯拉、优步、苹果、百度等新贵。\n\n（五）人工智能上升为世界主要国家的重大发展战略。人工智能正在成为新一轮产业变革的引擎，必将深刻影响国际产业竞争格局和一个国家的国际竞争力。世界主要发达国家纷纷把发展人工智能作为提升国际竞争力、维护国家安全的重大战略，加紧积极谋划政策，围绕核心技术、顶尖人才、标准规范等强化部署，力图在新一轮国际科技竞争中掌握主导权。无论是德国的“工业4.0”、美国的“工业互联网”、日本的“超智能社会”、还是我国的“中国制造2025”等重大国家战略，人工智能都是其中的核心关键技术。2017年7月，国务院发布了《新一代人工智能发展规划》，开启了我国人工智能快速创新发展的新征程。\n\n（六）人工智能的社会影响日益凸显。人工智能的社会影响是多元的，既有拉动经济、服务民生、造福社会的正面效应，又可能出现安全失控、法律失准、道德失范、伦理失常、隐私失密等社会问题，以及利用人工智能热点进行投机炒作从而存在泡沫风险。首先，人工智能作为新一轮科技革命和产业变革的核心力量，促进社会生产力的整体跃升，推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域发展积极正面影响。与此同时，我们也要看到人工智能引发的法律、伦理等问题日益凸显，对当下的社会秩序及公共管理体制带来了前所未有的新挑战。例如，2016年欧盟委员会法律事务委员会提交一项将最先进的自动化机器人身份定位为“电子人（electronic persons）”的动议，2017年沙特阿拉伯授予机器人“索菲亚”公民身份，这些显然冲击了传统的民事主体制度。那么，是否应该赋予人工智能系统法律主体资格？另外在人工智能新时代，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题都需要我们从法律法规、道德伦理、社会管理等多个角度提供解决方案。\n\n由于人工智能与人类智能密切关联且应用前景广阔、专业性很强，容易造成人们的误解，也带来了不少炒作。例如，有些人错误地认为人工智能就是机器学习（深度学习），人工智能与人类智能是零和博弈，人工智能已经达到5岁小孩的水平，人工智能系统的智能水平即将全面超越人类水平，30年内机器人将统治世界，人类将成为人工智能的奴隶，等等。这些错误认识会给人工智能的发展带来不利影响。还有不少人对人工智能预期过高，以为通用智能很快就能实现，只要给机器人发指令就可以干任何事。另外，有意炒作并通过包装人工智能概念来谋取不当利益的现象时有发生。因此，我们有义务向社会大众普及人工智能知识，引导政府、企业和广大民众科学客观地认识和了解人工智能。\n\n四、人工智能的发展趋势与展望\n\n人工智能经过六十多年的发展突破了算法、算力和算料（数据）等“三算”方面的制约因素，拓展了互联网、物联网等广阔应用场景，开始进入蓬勃发展的黄金时期。从技术维度看，当前人工智能处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有数据、能耗、泛化、可解释性、可靠性、安全性等诸多瓶颈，创新发展空间巨大，从专用到通用智能，从机器智能到人机智能融合，从“人工+智能”到自主智能，后深度学习的新理论体系正在酝酿；从产业和社会发展维度看，人工智能通过对经济和社会各领域渗透融合实现生产力和生产关系的变革，带动人类社会迈向新的文明，人类命运共同体将形成保障人工智能技术安全、可控、可靠发展的理性机制。总体而言，人工智能的春天刚刚开始，创新空间巨大，应用前景广阔。\n\n（一）从专用智能到通用智能。如何实现从狭义或专用人工智能（也称弱人工智能，具备单一领域智能）向通用人工智能（也称强人工智能，具备多领域智能）的跨越式发展，既是下一代人工智能发展的必然趋势，也是国际研究与应用领域的挑战问题。2016年10月美国国家科学技术委员会发布了《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。DeepMind创始人戴密斯·哈萨比斯（Demis Hassabis）提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年7月成立了通用人工智能实验室，100多位感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n（二）从人工智能到人机混合智能。人工智能的一个重要研究方向就是借鉴脑科学和认知科学的研究成果，研究从智能产生机理和本质出发的新型智能计算模型与方法，实现具有脑神经信息处理机制和类人智能行为与智能水平的智能系统。在美国、欧盟、日本等国家和地区纷纷启动的脑计划中，类脑智能已成为核心目标之一。英国工程与自然科学研究理事会EPSRC发布并启动了类脑智能研究计划。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。人机混合智能得到了我国新一代人工智能规划、美国脑计划、脸书（脑机语音文本界面）、特斯拉汽车创始人埃隆·马斯克（人脑芯片嵌入和脑机接口）等的高度关注。\n\n（三）从“人工+智能”到自主智能系统。当前人工智能的研究集中在深度学习，但是深度学习的局限是需要大量人工干预：人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据（非常费时费力）、用户需要人工适配智能系统等。因此已有科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类AI”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低AI人员成本。\n\n（四）人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、材料等传统科学的发展。例如，2018年美国麻省理工学院启动的“智能探究计划”（MIT Intelligence Quest）就联合了五大学院进行协同攻关。\n\n（五）人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来十年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，在现有基础上能够提高劳动生产率40%；美、日、英、德、法等12个发达国家（现占全球经济总量的一半）到2035年，年经济增长率平均可以翻一番。2018年麦肯锡的研究报告表明到2030年人工智能新增经济规模将达到13万亿美元。\n\n（六）人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出未来五年人工智能提升各行业运转效率，其中教育业提升82%，零售业71%，制造业64%，金融业58%。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n（七）人工智能领域的国际竞争将日趋激烈。“未来谁率先掌握人工智能，谁就能称霸世界”。2018年4月，欧盟委员会计划2018-2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略》重点推动物联网建设和人工智能的应用。世界军事强国已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即提出谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n（八）人工智能的社会学将提上议程。水能载舟，亦能覆舟。任何高科技也都是一把双刃剑。随着人工智能的深入发展和应用的不断普及，其社会影响日益明显。人工智能应用得当、把握有度、管理规范，就能有效控制负面风险。为了确保人工智能的健康可持续发展并确保人工智能的发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，深入分析人工智能对未来经济社会发展的可能影响，制定完善的人工智能法律法规，规避可能风险，确保人工智能的正面效应。2017年9月，联合国犯罪和司法研究所(UNICRI)决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。2018年4月，欧洲25个国家签署了《人工智能合作宣言》，从国家战略合作层面来推动人工智能发展，确保欧洲人工智能研发的竞争力，共同面对人工智能在社会、经济、伦理及法律等方面的机遇和挑战。\n\n五、我国人工智能的发展态势与思考\n\n我国当前人工智能发展的总体态势良好。中国信通院联合高德纳咨询公司（Gartner）于2018年9月发布的《2018世界人工智能产业发展蓝皮书》报告统计，我国（不含港澳台地区）人工智能企业总数位列全球第二（1040家），仅次于美国（2039家）。在人工智能总体水平和应用方面，我国也处于国际前列，发展潜力巨大，有望率先突破成为全球领跑者。但是我们也要清醒地看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n一是高度重视。党和国家高度重视并大力发展人工智能。党的十八大以来，习近平总书记把创新摆在国家发展全局的核心位置，高度重视人工智能发展，多次谈及人工智能的重要性，为人工智能如何赋能新时代指明方向。2016年7月习总书记明确指出，人工智能技术的发展将深刻改变人类社会生活，改变世界，应抓住机遇，在这一高技术领域抢占先机。在党的十九大报告中，习总书记强调“要推动互联网、大数据、人工智能和实体经济深度融合”。在2018年两院院士大会上，习总书记再次强调要“推进互联网、大数据、人工智能同实体经济深度融合，做大做强数字经济”。在2017年和2018年的《政府工作报告》中，李克强总理都提到了要加强新一代人工智能发展。2017年7月，国务院发布了《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动，人工智能将成为今后一段时期的国家重大战略。发改委、工信部、科技部、教育部、中央网信办等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n二是态势喜人。根据2017年爱思唯尔（Elsevier）文献数据库SCOPUS统计结果，我国在人工智能领域发表的论文数量已居世界第一。从2012年开始，我国在人工智能领域新增专利数量已经开始超越美国。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成全球人工智能投融资规模最大国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。近两年，清华大学、北京大学、中国科学院大学、浙江大学、上海交通大学、南京大学等高校纷纷成立人工智能学院。2015年开始的中国人工智能大会（CCAI）已连续成功召开四届、规模不断扩大，人工智能领域的教育、科研与学术活动层出不穷。\n\n三是差距不小。我国人工智能在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在较大差距。英国牛津大学2018年的一项研究报告指出中国的人工智能发展能力大致为美国的一半水平。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，存在“头重脚轻”的不均衡现象。在Top700全球AI人才中，中国虽然名列第二，但入选人数远远低于占一半数量的美国。据领英《全球AI领域人才报告》统计，截至2017年一季度全球人工智能领域专业技术人才数量超过190万，其中美国超过85万，我国仅超过5万人，排名全球第7位。2018年市场研究顾问公司Compass Intelligence对全球100多家AI计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国制定完善人工智能相关法律法规的进程需要加快，对可能产生的社会影响还缺少深度分析。\n\n四是前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出到2030年，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n人类社会已开始迈入智能化时代，人工智能引领社会发展是大势所趋，不可逆转。经历六十余年积累后，人工智能开始进入爆发式增长的红利期。伴随着人工智能自身的创新发展和向经济社会的全面渗透，这个红利期将持续相当长的时期。现在是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧需要深入思考。\n\n（一）树立理性务实的发展理念。围棋人机大战中阿尔法狗战胜李世石后，社会大众误以为人工智能已经无所不能，一些地方政府、社会企业、风险资金因此不切实际一窝蜂发展人工智能产业，一些别有用心的机构则有意炒作并通过包装人工智能概念来谋取不当利益。这种“一拥而上、一哄而散”的跟风行为不利于人工智能的健康可持续发展。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。根据高德纳咨询公司发布的技术发展曲线，当前智能机器人、认知专家顾问、机器学习、自动驾驶等人工智能热门技术与领域正处于期望膨胀期，但是通用人工智能及人工智能的整体发展仍处于初步阶段，人工智能还有很多“不能”，实现机器在任意现实环境的自主智能和通用智能仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此发展人工智能不能以短期牟利为目的，要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，并务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n（二）加强基础扎实的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。在此发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。根据2017年爱思唯尔文献数据库SCOPUS统计结果，尽管我国在人工智能领域发表的论文数量已经排名世界第一，但加权引文影响力则只排名34位。为了客观评价我国在人工智能基础研究方面的整体实力，我们搜索了SCI期刊、神经信息处理系统大会（Conference on Neural Information Processing Systems，简称NIPS）等主流人工智能学术会议关于通用智能、深度学习、类脑智能、脑智融合、人机博弈等关键词的论文统计情况，可以清楚看到在人工智能前沿方向中国与美国相比基础实力存在巨大差距：在高质量论文数量方面（按中科院划定的SCI一区论文标准统计），美国是中国的5.34倍（1325:248）；在人才储备方面（SCI论文通讯作者），美国是中国的2.12倍（4804:2267）。\n\n我国应对标国际最高水平，建设面向未来的人工智能基础科学研究中心，重点发展原创性、基础性、前瞻性、突破性的人工智能科学。应该鼓励科研人员瞄准人工智能学科前沿方向开展引领性原创科学研究，通过人工智能与脑认知、神经科学、心理学等学科的交叉融合，重点聚焦人工智能领域的重大基础性科学问题，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n（三）构建自主可控的创新生态。美国谷歌、IBM、微软、脸书等企业在AI芯片、服务器、操作系统、开源算法、云服务、无人驾驶等方面积极构建创新生态、抢占创新高地，已经在国际人工智能产业格局中占据先机。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。美国对中兴通讯发禁令一事充分说明自主可控“核高基”技术的重要性，我国应该吸取在核心电子器件、高端通用芯片及基础软件方面依赖进口的教训，避免重蹈覆辙，着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如军民融合、产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。\n\n另外，我们需要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过标准实施加速人工智能驱动经济社会转型升级的进程。\n\n（四）建立协同高效的创新体系。我国经济社会转型升级对人工智能有重大需求，但是单一的创新主体很难实现政策、市场、技术、应用等方面的全面突破。目前我国学术界、产业界、行业部门在人工智能发展方面各自为政的倾向比较明显，数据资源开放共享不够，缺少对行业资源的有效整合。相比而言，美国已经形成了全社会、全场景、全生态协同互动的人工智能协同创新体系，军民融合和产学研结合都做得很好。我国应在体制机制方面进一步改革创新，建立“军、政、产、学、研、用”一体的人工智能协同创新体系。例如，国家进行顶层设计和战略规划，举全国优势力量设立军事智能的研发和应用平台，提供“人工智能+X”行业融合、打破行业壁垒和行政障碍的激励政策；科技龙头企业引领技术创新生态建设，突破人工智能的重大技术瓶颈；高校科研机构进行人才培养和原始创新，着力构建公共数据资源与技术平台，共同建设若干标杆性的应用创新场景，推动成熟人工智能技术在城市、医疗、金融、文化、农业、交通、能源、物流、制造、安全、服务、教育等领域的深度应用，建设低成本高效益广范围的普惠型智能社会。\n\n（五）加快创新人才的教育培养。发展人工智能关键在人才，中高端人才短缺已经成为我国人工智能做大做强的主要瓶颈。另外，我国社会大众的人工智能科技素养也需要进一步提升，每一个人都需要去适应人工智能时代的科技浪潮。在加强人工智能领军人才培养引进的同时，要面向技术创新和产业发展多层次培养人工智能创新创业人才。《新一代人工智能发展规划》提出逐步开展全民智能教育项目，在中小学阶段设置人工智能课程。目前人工智能科普活动受到各地学校的欢迎，但是缺少通俗易懂的高质量人工智能科普教材、寓教于乐的实验设备和器材、开放共享的教学互动资源平台。国家相关部门应高度重视人工智能教育领域的基础性工作，增加投入，组织优势力量，加强高水平人工智能教育内容和资源平台建设，加快人工智能专业的教学师资培训，从教材、教具、教师等多个环节全面保障我国人工智能教育工作的开展。\n\n（六）推动共担共享的全球治理。人工智能将重塑全球政治和经济格局，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能将进一步拉大发达国家和发展中国家的生产力发展水平差距。美国、日本、德国等通过人工智能和机器人的技术突破和广泛应用弥补他们的人力成本劣势，希望制造业从新兴国家回流发达国家。目前看，我国是发展中国家阵容中唯一有望成为全球人工智能竞争中的领跑者，应采取不同于一些国家的“经济垄断主义、技术保护主义、贸易霸凌主义”路线，尽快布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合国家“一带一路”战略，向亚洲、非洲、南美等经济欠发达地区输出高水平、低成本的“中国智造”成果、提供人工智能时代的中国方案，为让人工智能时代的“智能红利”普惠人类命运共同体做出中国贡献！\n\n（七）制定科学合理的法律法规。要想实实在在收获人工智能带来的红利，首先应保证其安全、可控、可靠发展。美国和欧洲等发达国家和地区十分重视人工智能领域的法律法规问题。美国白宫多次组织这方面的研讨会、咨询会；特斯拉等产业巨头牵头成立OpenAI等机构，旨在以有利于整个人类的方式促进和发展友好的人工智能；科研人员自发签署23条“阿西洛马人工智能原则”，意图在规范人工智能科研及应用等方面抢占先机。我国在人工智能领域的法律法规制定及风险管控方面相对滞后，这种滞后局面与我国现阶段人工智能发展的整体形势不相适应，并可能成为我国人工智能下一步创新发展的一大掣肘。因此，有必要大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法规环境。\n\n（八）加强和鼓励人工智能社会学研究。人工智能的社会影响将是深远的、全方位的。我们当未雨绸缪，从国家安全、社会治理、就业结构、伦理道德、隐私保护等多个维度系统深入研究人工智能可能的影响，制定合理可行的应对措施，确保人工智能的正面效应。应大力加强人工智能领域的科普工作，打造科技与伦理的高效对话机制和沟通平台，消除社会大众对人工智能的误解与恐慌，为人工智能的发展营造理性务实、积极健康的社会氛围。\n\n六、结束语\n\n人工智能经过60多年的发展，进入了创新突破的战略机遇期和产业应用的红利收获期，必将对生产力和产业结构以及国际格局产生革命性影响，并推动人类进入普惠型智能社会。但是，我们需要清醒看到通用人工智能及人工智能的整体发展仍处于初级阶段，人工智能不是万能，人工智能还有很多“不能”。我们应当采取理性务实的发展路径，扎实推进基础研究、技术生态、人才培养、法律规范等方面的工作，在开放中创新，在创新中发展，全速跑赢智能时代，着力建设人工智能科技强国！\n\n（主讲人系中国科学院院士）\n\n责任编辑： 王伟\n\n[<< 返回首页](../../../../)\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'http://www.npc.gov.cn/zgrdw/npc/xinwen/2018-10/29/content_2065419.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9990601, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_人工智能的创新发展与社会影响 - 中国人大网.md'}}
2026-02-03 13:24:08,602 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': '人工智能的发展历史？'}
2026-02-03 13:24:08,602 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=人工智能的发展历史？, search_type=None
2026-02-03 13:24:08,636 - __main__ - INFO - call_tool: name=tavily_search, args={'query': '人工智能的发展历史？'}
2026-02-03 13:24:08,636 - __main__ - INFO - handle_search: searcher=TavilySearch, query=人工智能的发展历史？, search_type=None
2026-02-03 13:24:08,675 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': '人工智能的发展历史？'}
2026-02-03 13:24:08,675 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=人工智能的发展历史？, search_type=None
2026-02-03 13:24:12,281 - __main__ - INFO - handle_search: returned=10
2026-02-03 13:24:12,281 - __main__ - INFO - call_tool payload: source_tool=exa_context_search, result_type=papers, count=10
2026-02-03 13:24:12,281 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-03 13:24:12,281 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能历史 - IBM', 'authors': [], 'abstract': '人工智能历史 | IBM\n[Artificial Intelligence] \n# AI 的历史![高耸入云的摩天大楼尖顶] \n## 作者[Tim Mucci] \nIBM Writer\nGather\n## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。\nGPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;\n## 20 世纪以前### 1726\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。\n学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;\n“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”\n- Jonathan Swift 的《格列佛游记》(1726)\nSwift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。\n## 1900–1950\n### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。\n### 1921\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。\n### 1939\n爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。\n虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。\n与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。\n### 1950\n英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;\n图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n## 1950–1980\n### 1951\nMarvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952\n数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n### 1955\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。\n### 1958\nJohn McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959\nArthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n### 1965\n哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。\n### 1966\nShakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969\nArthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。\nMarvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。\n### 1970\nTerry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。\n### 1973\nJames Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000\n### 1980\nWABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。\n### 1982\n日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。\n### 1986\nDavid Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。\n这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987\n在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\nRollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\nMarvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。\n### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。\n### 1993\n科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。\n这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n### 1995\nRichard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;', 'doi': '', 'published_date': '2026-02-03T13:24:12.280159', 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 13:24:15,220 - __main__ - INFO - handle_search: returned=3
2026-02-03 13:24:15,220 - __main__ - INFO - call_tool payload: source_tool=wikipedia_search, result_type=papers, count=3
2026-02-03 13:24:15,220 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=3
2026-02-03 13:24:15,221 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-03T13:24:15.219928', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-03 13:24:15', 'language': 'zh'}}
2026-02-03 13:24:17,282 - __main__ - INFO - handle_search: returned=10
2026-02-03 13:24:17,282 - __main__ - INFO - call_tool payload: source_tool=tavily_search, result_type=papers, count=10
2026-02-03 13:24:17,283 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-03 13:24:17,283 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': None}}
2026-02-03 13:24:41,733 - __main__ - INFO - call_tool: name=wikipedia_download, args={'papers': [{'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-03T13:24:15.219928', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-03 13:24:15', 'language': 'zh'}}, {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T13:24:15.219951', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 13:24:15', 'language': 'zh'}}, {'paper_id': '1468546', 'title': '通用人工智慧', 'authors': ['Wikipedia'], 'abstract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'doi': '', 'published_date': '2026-02-03T13:24:15.219959', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'pageid': 1468546, 'fetch_time': '2026-02-03 13:24:15', 'language': 'zh'}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 13:24:41,734 - __main__ - INFO - handle_download: searcher=WikipediaSearcher, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 13:24:41,735 - __main__ - INFO - handle_download: downloaded=3
2026-02-03 13:24:41,735 - __main__ - INFO - call_tool payload: source_tool=wikipedia_download, result_type=papers, count=3
2026-02-03 13:24:41,735 - __main__ - INFO - call_tool: name=wikipedia_download, result_type=papers, count=3
2026-02-03 13:24:41,736 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-03T13:24:15.219928', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-03 13:24:15', 'language': 'zh', 'saved_path': '/home/qinshan/widthresearch/data/downloads/wiki_1394764.md'}}
2026-02-03 13:24:41,754 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': '人工智能历史 - IBM', 'authors': [], 'abstract': '人工智能历史 | IBM\n[Artificial Intelligence] \n# AI 的历史![高耸入云的摩天大楼尖顶] \n## 作者[Tim Mucci] \nIBM Writer\nGather\n## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。\nGPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;\n## 20 世纪以前### 1726\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。\n学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;\n“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”\n- Jonathan Swift 的《格列佛游记》(1726)\nSwift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。\n## 1900–1950\n### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。\n### 1921\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。\n### 1939\n爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。\n虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。\n与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。\n### 1950\n英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;\n图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n## 1950–1980\n### 1951\nMarvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952\n数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n### 1955\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。\n### 1958\nJohn McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959\nArthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n### 1965\n哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。\n### 1966\nShakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969\nArthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。\nMarvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。\n### 1970\nTerry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。\n### 1973\nJames Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000\n### 1980\nWABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。\n### 1982\n日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。\n### 1986\nDavid Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。\n这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987\n在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\nRollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\nMarvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。\n### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。\n### 1993\n科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。\n这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n### 1995\nRichard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;', 'doi': '', 'published_date': '2026-02-03T13:24:12.280159', 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'loading... - AMiner', 'authors': [], 'abstract': '- Search\n- ChatPaper\n- AI Writing\n- Scientific Research\n\n- Tools of Scientific research\n\n\nChrome Extension\n\nWeChat Mini Program\n\nUse on ChatGLM\n\nVIPCreated with Sketch.\n\nLog in\n\n[Academic Profile] [User Profile] \n\n[My Following] [Paper Collections] [Browse History] \n\n# Artificial Intelligence History [![AI] 精彩视频展示] \n\n![Artificial Intelligence History] [Original Image] \n\n\\\\* If you want to use this picture, please cite the following paper :\n\nJie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. [ArnetMiner: Extraction and Mining of Academic Social Networks.] In Proceedings of the Fourteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (SIGKDD\'2008). pp.990-998. [\\[PDF\\]] [\\[Slides\\]] [\\[System\\]] [\\[API\\]] \n\n```\n@INPROCEEDINGS{Tang:08KDD,\n AUTHOR = "Jie Tang and Jing Zhang and Limin Yao and Juanzi Li and Li Zhang and Zhong Su",\n TITLE = "ArnetMiner: Extraction and Mining of Academic Social Networks",\n pages = "990-998",\n YEAR = {2008},\n BOOKTITLE = "KDD\'08",\n}\n\n```\n\nCopy to clipboard\n\n人工智能简史\n\n**人工智能发展简史**\n\n人工智能到底是什么？通常来说，人工智能（Artificial Intelligence）是研究、开发用于模拟、延伸和扩展人智能的理论、方法、技术及应用系统的一门新技术科学。人工智能领域的研究包括机器人、语言识别、图像识别、自然语言处理和专家系统等。\n\n但是事实上，给一门学科界定范围是很难的，尤其对于一门正在快速发展的学科更是难上加难。即使是数学这样成熟的学科，有时我们也很难梳理一个明确的边界。而像人工智能这样不断扩展边界的学科，更是很难做出一个相对准确的判断。对于人工智能的应用已经扩展到各个领域，机械、电子、经济甚至哲学，都有所设计。它的实用性极强，是一种极具代表性的多元跨专业学科。\n\n基于AMiner科技情报引擎的梳理描绘，以河流图的形式展示了人工智能在60多年中的发展历史中取得的标志性成果。本文以该河流图为基础，系统的梳理了人工智能的发展过程及其标志性成果，希望能将这段60多年几经沉浮的历史，以一个更加清晰的面貌呈现出来。\n\n## 第一章：起步期-20世纪50年代及以前\n\n人工智能的起源可以追溯到以及阿兰·图灵（Alan Turing）1936年发表的《论可计算数及其在判定问题中的应用》。后来随着克劳德·香农（Claude Shannon）在\n1950 年提出计算机博弈。以及艾伦·麦席森·图灵（Alan Mathison\xa0Turing）在\n1954 年提出“图灵测试”，让机器产生智能这一想法开始进入人们的视野。\n\n1956年达特茅斯学院召开了一个研讨会，John McCarthy, Marvin Minsky, Nathaniel Rochester, 以及Claude Shannon等人正式提出“人工智能”这一概念。算法方面，1957年，Rosenblatt Frank提出感知机算法Perceptron，这不仅开启了机器学习的浪潮，也成为后来神经网络的基础（当然追溯的话，神经网络研究得追溯到1943年神经生理学家麦卡洛克（W. S. McCulloch）和皮茨（W. Pitts）的神经元模型）。\n\n### 1.1 计算机象棋博弈（Programming a computer for playing chess）\n\n克劳德·艾尔伍德·香农（Claude Elwood Shannon，1916年4月30日—2001年2月24日）是[美国] 数学家、[信息论] 的创始人。\n\n香农是世界上首批提出“计算机能够和人类进行国际象棋对弈”的科学家之一。1950年，他为《科学美国人》撰写过一篇文章，阐述了“实现人机博弈的方法”；他设计的国际象棋程序，发表在同年《哲学杂志》上（计算机下棋程序\nProgramming a Computer for Playing Chess）。\n\n香农把棋盘定义为二维数组，每个棋子都有一个对应的子程序计算棋子所有可能的走法，最后有个评估函数（evaluation function）。传统的棋局都把下棋过程分为三个阶段，开局、中局和残局，不同阶段需要不同的技术手段。而此论文也引用了冯·诺依曼的《博弈论》和维纳的《控制论》。\n\n这篇论文开启了计算机下棋的理论研究，其主要思路在多年后的“深蓝”及AlphaGo中仍能看到。1956年，在洛斯阿拉莫斯的MANIAC计算机上，他又展示了国际象棋的下棋程序。\n\n### 1.2 图灵测试（Turing Test）\n\n艾伦·麦席森·图灵（英语：Alan Mathison Turing，1912年6月23日—1954年6月7日），英国数学家、逻辑学家，被称为计算机科学之父，人工智能之父。\n\n1954年，图灵测试（The Turing test）由图灵发明，指测试者与被测试者（一个人和一台机器）隔开的情况下，通过一些装置（如键盘）向被测试者随意提问。进行多次测试后，如果机器让平均每个参与者做出超过30%的误判，那么这台机器就通过了测试，并被认为具有人类智能。图灵测试一词来源于[计算机科学] 和[密码学] 的先驱艾伦·麦席森·图灵写于1950年的一篇论文《计算机器与智能》，其中30%是图灵对2000年时的机器思考能力的一个预测，目前我们已远远落后于这个预测。\n\n他实际提出了一种测试机器是不是具备人类智能的方法。即假设有一台电脑，其运算速度非常快、记忆容量和[逻辑单元] 的数目也超过了人脑，而且还为这台电脑编写了许多智能化的程序，并提供了合适种类的大量数据，那么，是否就能说这台机器具有思维能力？\n\n图灵肯定机器可以思维的，他还对智能问题从[行为主义] 的角度给出了定义，由此提出一假想：即一个人在不接触对方的情况下，通过一种特殊的方式，和对方进行一系列的问答，如果在相当长时间内，他无法根据这些问题判断对方是人还是计算机，那么，就可以认为这个计算机具有同人相当的智力，即这台计算机是能思维的。这就是著名的“图灵测试”（Turing Testing）。当时全世界只有几台电脑，其他几乎所有计算机根本无法通过这一测试。\n\n要分辨一个想法是“自创”的思想还是精心设计的“模仿”是非常难的，任何自创思想的证据都可以被否决。图灵试图解决长久以来关于如何定义思考的哲学争论，他提出一个虽然主观但可操作的标准：如果一台电脑表现（act）、反应（react）和互相作用（interact）都和有意识的个体一样，那么它就应该被认为是有意识的。\n\n为消除人类心中的偏见，图灵设计了一种“[模仿游戏] ”即图灵测试：远处的人类测试者在一段规定的时间内，根据两个实体对他提出的各种问题的反应来判断是人类还是电脑。通过一系列这样的测试，从电脑被误判断为人的几率就可以测出电脑智能的成功程度。\n\n图灵预言，在20世纪末，一定会有电脑通过“图灵测试”。2014年6月7日在英国皇家学会举行的“2014图灵测试”大会上，举办方英国雷丁大学发布新闻稿，宣称俄罗斯人弗拉基米尔·维西罗夫（Vladimir Veselov）创立的人工智能软件尤金·古斯特曼（Eugene Goostman）通过了图灵测试。虽然“尤金”软件还远不能“思考”，但也是人工智能乃至于计算机史上的一个标志性事件。\n\n![] \n\n### 1.3达特茅斯学院人工智能夏季研讨会（Dartmouth Summer Research Conference on Artificial Intelligence）\n\n1956年夏季，年轻的明斯基与数学家和计算机专家麦卡锡（John MeCarthy，1927—2011）等10人在达特茅斯学院（Dartmouth College办了一个长达2个月的人工智能夏季研讨会，认真热烈地讨论用机器模拟人类智能的问题。会上正式使用了人工智能（artificial intelligence，即 AI）这一术语。\n\n这是人类历史上第一次人工智能研讨，标志着人工智能学科的诞生，具有十分重要的历史意义，为国际人工智能的发展做出重要的开创性贡献。会议持续了一个月，基本上以大范围的集思广益为主。这催生了后来人所共知的人工智能革命。1956年也因此成为了人工智能元年。会议的主要议题包括自动计算机、如何为计算机编程使其能够使用语言、神经网络、计算规模理论、自我改造、抽象、随机性与创造性等。\n\n### 1.4感知机（Perceptrons）\n\n1957年,弗兰克·罗森布拉特（Frank Rosenblatt）在一台IBM-704计算机上模拟实现了一种他发明的叫做“感知机”（Perceptron）的神经网络模型。罗森布拉特1962年出了本书：《神经动力学原理：感知机和大脑机制的理论》（Principles of Neurodynamics: Perceptrons and the Theory of Brain\nMechanisms），基于MCP神经元提出了第一个感知器学习算法，同时它还提出了一个自学习算法，此算法可以通过对输入信号和输出信号的学习，自动获取到权重系数，通过输入信号与权重系数的乘积来判断神经元是否被激活（产生输出信号）。\n\n感知机需要几个二进制输入， X1，X2，…Xn X1，X2，…Xn ，并产生一个二进制输出：\n\n![] \n\n上图所示的 Perceptron Perceptron 有三个输入，但是实际的输入可能远多于三个或是少与三个。 Rosenblatt Rosenblatt 提出了一个简单的规则来计算输出，他首先引入了 weights weights（权重）概念， ω1，ω2,... ω1，ω2,...。以实数权重 ω ω表示输入到输出的重要性，神经元的输出 0 或 1 ，这取决于加权因子（即 weights weights）小于或大于某一阈值。就像权重，阈值为一个实数，是一个神经元的参数。\n\n公式表示为：\n\n![] \n\n这就是我们熟知的激活函数的最初形态， 0 0 状态代表抑制， 1 1 状态代表激活。这简单的数学公式帮助我们了解 perceptrons perceptrons 是如何工作的。姑且我们把它理解为：它是一种通过权衡输入信息的重要性来决定你的输出。\n\n## 第二章：第一次浪潮期-20 世纪 60 年代\n\n到了 20 世纪 60 年代，人工智能出现了第一次高潮，发展出了符号逻辑，解决了若干通用问题，初步萌芽了自然语言处理和人机对话技术。其中的代表性事件是丹尼尔·博布罗（Daniel Bobrow）在1964年发表了Natural Language Input for a Computer Problem Solving System，以及约瑟夫·维森鲍姆（Joseph Weizenbaum）在1966年发表了ELIZA—A Computer Program for the Study of Natural Language\nCommunication between Man and Machine。\n\n早期的人工智能更多的侧重描述逻辑和通用问题求解上，到了60年代末，爱德华·费根鲍姆（Edward Feigenbaum）提出首个专家系统DENDRAL，并对知识库给出了初步的定义，这也孕育了后来的第二次人工智能浪潮。当然这个时期更重要的情况是大家对人工智能的热情逐渐褪去，人工智能的发展也进入了一轮跨度将近十年的“寒冬”。\n\n### 2.1 模式识别（Pattern Recognition）\n\n1961年，Leonard Merrick Uhr 和\xa0Charles M Vossler发表了题目为A\xa0_Pattern Recognition Program That Generates, Evaluates and Adjusts_\n_its Own Operators_的模式识别论文，该文章描述了一种利用机器学习或自组织过程设计模式识别程序的尝试。程序启动时不仅不知道要输入的特定模式，而且没有任何处理输入的运算符。算符是由程序本身生成和提炼的，它是问题空间的函数，也是处理问题空间的成功和失败的函数。程序不仅学习有关不同模式的信息，而且至少在一定程度上，它还学习或构造适合于分析输入到它特定模式集的二级代码。这也是第一个机器学习程序。\n\n![] \n\n### 2.2人机对话（Human computer coversation）\n\n1966 年，麻省理工学院的计算机科学家Joseph Weizenbaum 在\nACM 上发表了题为《\nELIZA，一个研究人机自然语言交流的计算机程序》（ELIZA-a computer program for the study of natural language\ncommunication between man and machine）的文章。文章描述了这个叫作\nELIZA 的程序如何使人与计算机在一定程度上进行自然语言对话成为可能。Weizenbaum 开发了最早的聊天机器人\nELIZA，用于在临床治疗中模仿心理医生。\n\nELIZA 的实现技术是通过关键词匹配规则对输入进行分解，而后根据分解规则所对应的重组规则来生成回复。简而言之，就是将输入语句类型化，再翻译成合适的输出。虽然\nELIZA 很简单，但\nWeizenbaum 本人对\nELIZA 的表现感到吃惊，随后撰写了《计算机的能力和人类的推理》（Computer Power and Human Reason）这本书，表达他对人工智能的特殊情感。ELIZA 如此出名，以至于\nSiri 也说\nELIZA 是一位心理医生，是她的启蒙老师。\n\n### 2.3专家系统DENTRAL（Expert Systems）\n\n1968年，在美国国家航空航天局要求下，爱德华·费根鲍姆（Edward Feigenbaum）提出首个专家系统DENDRAL，并对知识库给出了初步的定义，这也孕育了后来的第二次人工智能浪潮。当然这个时期更重要的情况是大家对人工智能的热情逐渐褪去，人工智能的发展也进入了一轮跨度将近十年的“寒冬”。该系统具有非常丰富的化学知识，可根据质谱数据帮助化学家推断分子结构。这个系统的完成标志着专家系统的诞生。在此之后, 麻省理工学院开始研制MACSYMA系统，经过不断扩充, 它能求解600多种数学问题。\n\n现在，专家系统(Expert System,简称ES)是人工智能(Artificial Intelligence,简称AI)的一个重要分支,同自然语言理解,机器人学并列为AI的三大研究方向。\n\n## 第三章：第二次浪潮期-20世纪70年代末、80年代\n\n20世纪70年代末、80年代初，人工智能进入了第二次浪潮，其中代表性的工作是1976年兰德尔·戴维斯（Randall Davis）构建和维护的大规模的知识库，1980年德鲁·麦狄蒙（Drew McDermott）和乔恩·多伊尔（Jon Doyle）提出的非单调逻辑，以及后期出现的机器人系统。\n\n1980年，汉斯·贝利纳（Hans Berliner）打造的计算机战胜双陆棋世界冠军成为标志性事件。随后，基于行为的机器人学在罗德尼·布鲁克斯（Rodney Brooks）和萨顿（R. Sutton）等人的推动下快速发展，成为人工智能一个重要的发展分支。这其中格瑞·特索罗（Gerry Tesauro）等人打造的自我学习双陆棋程序又为后来的增强学习的发展奠定了基础。\n\n机器学习算法方面，这个时期可谓是百花齐放，百家争鸣。Geoffrey Hinton等人提出的多层感知机，解决了Perceptron存在的不能做非线性分类的问题；Judea Pearl倡导的概率方法和贝叶斯网络为后来的因果推断奠定基础；以及机器学习方法在机器视觉等方向取得快速发展。\n\n### 3.1知识表示（Knowledge Representation）\n\n1975年，马文·明斯基(Marvin Minsky)在论文《知识表示的框架》(A Framework for Representing Knowledge)中提出框架理论，用于人工智能中的“知识表示”。\n\n明斯基框架不是一种单纯的理论。除了数据结构上有单纯的一面外，在概念上是相当复杂的。针对的是人们在理解事物情景或某一事件时的心理学模型。它将框架看作是知识的基本单位，将一组有关的框架连接起来整合成框架系统。系统中不同框架可用有共同节点，系统的行为由系统的子框架的具体功能来实现。推理过程由子框架的协调来完成。框架理论类似于人工智能中的面向对象化程序设计。它的成功之处是它利用框架这种结构将知识有机的整合起来，使其有一种特定的结构约束。同时保持了结构的相对独立性、封闭性。\n\n明斯基的框架理论体现出来的模块化思想和基于事例的认知推理为其理论增添了永恒的魅力，这也是认知哲学家关注它的一个重要原因。作为认知可计算主义核心代表的明斯基将心智与计算机类比，把认知过程理解为信息加工过程，把一切智能系统理解为物理符号系统。虽然这样做使人们能从环境到心智，又从心智到到环境的信息流中来分析问题，使心智问题研究具有实验上的严格性。但是机械性的缺陷也非常明显。\n\n同时，框架跟软件工程领域面向对象语言中的“类”相似，只是两者的基本设计目标不同。\n\n### 3.2启发式搜索（Heristic Search）\n\nDouglas Lenat（道格拉斯·布鲁斯·勒纳特）（生于1950年）是德克萨斯州奥斯汀市Cycorp公司的首席执行官，一直是人工智能领域的杰出研究者。他从事过机器学习（与他的AM和Eurisko程序）、知识表示、黑板系统和“本体工程”（在MCC和Cycorp的Cyc程序）。他还从事军事模拟，并发表了一篇对传统随机突变达尔文学说的批判，这是基于他对尤里斯科的经验。列纳特是AAAI的最初成员之一。\n\n在宾夕法尼亚大学，勒纳特获得数学和物理学士学位，并于1972年获得应用数学硕士学位。1976年，他从斯坦福大学获得博士学位，并发表论文《数学中发现的人工智能方法——启发式搜索》。\n\n该文章描述了一个名为“AM”的程序，它模拟了初等数学研究的一个方面：在大量启发式规则的指导下开发新概念数学被认为是一种智能行为，而不是一种成品。本地启发式通过一个议程机制、系统要执行的任务的全局列表以及每个任务合理的原因进行通信。一个单独的任务可以指导AM定义一个新的概念，或者探索一个现有概念的某个方面，或者检查一些经验数据的规律性等。程序从议程中反复选择具有最佳支持理由的任务，然后执行它。每个概念都是一个活跃的、结构化的知识模块。最初提供了一百个非常不完整的模，每个模对应于一个基本的集合论概念（如并集）。这提供了一个明确但巨大的“空间”，AM开始探索。AM扩展了它的知识库，最终重新发现了数百个常见的概念和定理。\n\n### 3.3大规模知识库构建与维护（Large Scale Knowledge-Base Construction）（已修改）\n\n1976年，Randall Davis在斯坦福大学获得人工智能博士学位，并发表文章_Applications of Meta Level Knowledge to the Construction,_\n_Maintenance and Use of Large Knowledge Bases_，此文提出：使用集成的面向对象模型是提高知识库（KB）开发、维护和使用的完整性的解决方案。共享对象增加了模型之间的跟踪能力，增强了半自动开发和维护功能。而抽象模型是在知识库构造过程中创建的，推理则是在模型初始化过程中执行的。\n\nRandall Davis在基于知识的系统和人机交互领域做出了开创性的贡献，发表了大约100多篇文章，并在多个系统的开发中发挥了核心作用。他和他的研究小组通过创建能够理解用户图像、手势和交谈的软件，开发先进的工具，并与计算机进行自然的多模式交互。\n\n### 3.4计算机视觉（Computer Vision）\n\n视觉计算理论（computational theory of vision）是在20世纪70年代由马尔（David Marr）提出的概念，他在1982发表代表作《视觉计算理论》。他的工作同时对认知科学（CognitiveScience）也产生了很深远的影响。\n\nDavid Marr生于1945年1月19日，早年就读于剑桥大学三一学院，获得数学硕士、神经生理学博士学位，同时还受过神经解剖学、心理学、生物化学等方面的严格训练。他在英国曾从事新皮层、海马，特别是小脑方面的理论研究。\n\n1974年访问美国，并应M.Minsky教授之请，留在麻省理工学院开展知觉和记忆方面的研究工作。他从计算机科学的观点出发，集数学、心理物理学、神经生理学于一体，首创人的视觉计算理论，使视觉研究的面貌为之一新。\n\n他的理论由他创建的一个以博士研究生为主体的研究小组继承、丰富和发展，并由其学生归纳总结为一本计算机视觉领域著作： _Vision: A computational investigation into the human representation_\n_and processing of visual information_，于他后发表。\n\n计算机视觉是一门研究如何使机器“看”的科学，更进一步的说，就是指用摄影机和计算机代替人眼对目标进行识别、跟踪和测量等机器视觉，并进一步做图像处理，用计算机处理成更适合人眼观察或进行仪器检测的图像。学习和运算能让机器能够更好的理解图片环境，并且建立具有真正智能的视觉系统。当下环境中存在着大量的图片和视频内容，这些内容亟需学者们理解并在其中找出模式，来揭示那些我们以前不曾注意过的细节。\n\n### 3.5电脑击败世界双陆棋冠军（Computer beats world Backgammon champion）\n\n1979 年 7 月，一款名为\nBKG 9.8 的计算机程序在蒙特卡洛举行的世界西洋双陆棋锦标赛中夺得冠军。这款程序的发明者是匹兹堡卡内基梅隆大学的计算机科学教授\nHans Berliner(汉斯·柏林格)，它在卡内基梅隆的一台大型计算机上运行，并通过卫星连接到蒙特卡洛的一个机器人上。', 'doi': '', 'published_date': '2026-02-03T13:24:12.280279', 'pdf_url': '', 'url': 'https://www.aminer.cn/ai-history', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来_中央网络安全和信息化委员会办公室', 'authors': [], 'abstract': '人工智能的历史、现状和未来\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能的历史、现状和未来2019年02月16日 12:05来源：\n求是[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n2018年2月25日，在平昌冬奥会闭幕式“北京8分钟”表演中，由沈阳新松机器人自动化股份有限公司研发的智能移动机器人与轮滑演员进行表演。 新华社记者李钢/摄\n![] \n2018年5月3日，中国科学院发布国内首款云端人工智能芯片，理论峰值速度达每秒128万亿次定点运算，达到世界先进水平。 新华社记者金立旺/摄\n![] \n2017年10月，在沙特阿拉伯首都利雅得举行的“未来投资倡议”大会上，机器人索菲亚被授予沙特公民身份，她也因此成为全球首个获得公民身份的机器人。图为2018年7月10日，在香港会展中心，机器人索菲亚亮相主舞台。 ISAAC LAWRENCE/视觉中国\n![] \n2018年11月22日， 在“伟大的变革——庆祝改革开放40周年大型展览”上，第三代国产骨科手术机器人“天玑”正在模拟做手术，它是国际上首个适应症覆盖脊柱全节段和骨盆髋臼手术的骨科机器人，性能指标达到国际领先水平。 麦田/视觉中国\n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。**概念与历程**\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n**现状与影响**\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。**趋势与展望**\n经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n从专用智能向通用智能发展。如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n从人工智能向人机混合智能发展。借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。从“人工+智能”向自主智能系统发展。当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。\n人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。\n人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n人工智能领域的国际竞争将日益激烈。当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n人工智能的社会学将提上议程。为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。\n**态势与思考**\n当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。高度重视。党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n态势喜人。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。\n差距不小。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。树立理性务实的发展理念。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。重视固本强基的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。构建自主可控的创新生态。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。推动共担共享的全球治理。目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。（作者：谭铁牛，系中央人民政府驻香港特别行政区联络办公室副主任、中国科学院院士）关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:12:01', 'doi': '', 'published_date': '2019-02-17T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2019-02/16/c_1124122584.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '中国人工智能40年发展简史', 'authors': [], 'abstract': '- [新浪首页] \n- [新闻] \n- [体育] \n- [财经] \n- [娱乐] \n- [科技] \n- [博客] \n- [图片] \n- [专栏] \n- [更多] \n\n- [汽车] [教育] [时尚] [女性] [星座] [健康] \n- [房产] [历史] [视频] [收藏] [育儿] [读书] \n- [佛学] [游戏] [旅游] [邮箱] [导航] \n\n[移动客户端] \n\n- [新浪微博] \n- [新浪新闻] \n- [新浪财经] \n- [新浪体育] \n- [新浪众测] \n- [新浪博客] \n- [新浪视频] \n- [新浪游戏] \n- [天气通] \n\n[我的收藏] \n\n[注册] \n\n[登录] \n\n[滚动新闻] >正文\n\n行情股吧新闻外汇新三板\n\n# 中国人工智能40年发展简史\n\n中国人工智能40年发展简史\n\n2025年04月30日 17:06工信头条\n\n[新浪财经APP] [缩小字体] [放大字体] [收藏] [微博] [微信] [分享] \n\n[腾讯QQ] [QQ空间] \n\n智能机器是一种能够呈现出人类智能行为的机器。人工智能(ArtificialIntelligence，AI)是计算机科学或智能科学中涉及研究、设计和应用智能机器的一个分支。人工智能的近期主要目标在于研究用机器来模仿和执行人脑的某些智力功能，而远期目标是用自动机模仿人类的思维活动和智力功能。\n\n人工智能探索历史\n\n人类对人工智能和智能机器的梦想与追求，可以追溯到3000 多年前。中国也不乏这方面的故事与史料。\n\n近代科学技术的许多重大进展都是人类智慧、思维、梦想和奋斗的成果。人类历史上从来没有出现过像今天这样的思想大解放，关于宇宙、星球、生命、人类、时空、进化和智能等思想与作品，如雨后春笋破土而出，似百花争艳迎春怒放。其中，人工智能尤其引人注目。进入20世纪后，人工智能开始孕育于人类社会母胎。到20世纪30—40年代发生了两件极其重要的事件：数理逻辑的形式化和智能可计算(机器能思维)的思想，建立了计算与智能关系的概念。被称为“人工智能之父”(The father of AI)的图灵(Turing AM)，于1936年创立了自动机理论，提出一个理论计算机模型，奠定电子计算机设计基础，促进人工智能特别是思维机器的研究。1950 年图灵的论文“机器能思考吗?”，为即将问世的人工智能提供了科学性和开创性的构思。\n\n1956 年夏季由麦卡锡(McCarthyJ)、明斯基(Minsky ML)、罗彻斯特(Lochester N)和香农(Shannon CE)共同发起，并邀请其他6位年轻的科学家，在美国达特茅斯(Dartmouth)大学举办了一次长达两个月的十人研讨会，讨论用机器模拟人类智能问题，首次使用“人工智能”这一术语。这是人类历史上第一次人工智能研讨会，标志着国际人工智能学科的诞生，具有十分重要的历史意义。发起这次研讨会的人工智能学者麦卡锡和明斯基，则被誉为国际人工智能的“奠基者”或“创始人”(The founding father)，有时也称为“人工智能之父”。\n\n中国的人工智能经历了怎样的发展过程?取得哪些成绩?存在什么问题?面临何种机遇?有哪些解决方案?本文力图逐一探讨。\n\n一、发展过程\n\n与国际上人工智能的发展情况相比，国内的人工智能研究不仅起步较晚，而且发展道路曲折坎坷，历经了质疑、批评甚至打压的十分艰难的发展历程。\n\n01\n\n迷雾重重\n\n20世纪50—60年代，人工智能在西方国家得到重视和发展，而在苏联却受到批判，将其斥为“资产阶级的反动伪科学”。当时，受苏联批判人工智能和控制论(Cybernetics)的影响，中国在20世纪50年代几乎没有人工智能研究;20世纪60年代后期和70年代，虽然苏联解禁了控制论和人工智能的研究，但因中苏关系恶化，中国学术界将苏联的这种解禁斥之为“修正主义”，人工智能研究继续停滞。那时，人工智能在中国要么受到质疑，要么与“特异功能”一起受到批判，被认为是伪科学和修正主义。《摘译外国自然科学哲学》月刊1976年第3期刊文称：“在批判‘图像识别’和‘人工智能’研究领域各种反动思潮的斗争中，走自己的道路”。这足见中国人工智能研究迷雾重重的艰难处境。\n\n1978年3月，全国科学大会在北京召开。大会提出“向科学技术现代化进军”的战略决策，打开解放思想的先河，促进中国科学事业的发展，使中国科技事业迎来了科学的春天\\[9\\]。这是中国改革开放的先声，广大科技人员出现了思想大解放，人工智能也在酝酿着进一步的解禁。吴文俊提出的利用机器证明与发现几何定理的新方法——几何定理机器证明(图1)，获得1978年全国科学大会重大科技成果奖就是一个好的征兆。\n\n20世纪80年代初期，钱学森等主张开展人工智能研究，中国的人工智能研究进一步活跃起来。但是，由于当时社会上把“人工智能”与“特异功能”混为一谈，使中国人工智能走过一段很长的弯路。一方面，包括许多人工智能学者在内的研究者把人工智能与特异功能搅在一起“研究”;另一方面，社会上在批判“特异功能”时将“人工智能”一起进行批判，把两者一并斥之为“伪科学”。\n\n02\n\n艰难起步\n\n20世纪70年代末至80年代，知识工程和专家系统在欧美发达国家得到迅速发展，并取得重大的经济效益。当时中国相关研究处于艰难起步阶段，一些基础性的工作得以开展。\n\n1) 派遣留学生出国研究人工智能。\n\n改革开放后，自1980 年起中国大批派遣留学生赴西方发达国家研究现代科技，学习科技新成果，其中包括人工智能和模式识别等学科领域。这些人工智能“海归”专家，已成为中国人工智能研究与开发应用的学术带头人和中坚力量，为发展中国人工智能做出举足轻重的贡献。\n\n2) 成立中国人工智能学会。\n\n1981 年9 月，中国人工智能学会(CAAI)在长沙成立，秦元勋当选第一任理事长。于光远在大会期间主持了一次大型座谈会，讨论有关人工智能的一些认识问题。他指出：“人工智能是一门新兴的科学，我们应该积极支持;对所谓‘人体特异功能’的研究是一门伪科学，不但不应该支持，而且要坚决反对。”1982年，中国人工智能学会刊物《人工智能学报》在长沙创刊，成为国内首份人工智能学术刊物。\n\nCAAI首任理事长秦元勋也颇受争议。秦元勋获美国哈佛大学博士学位后于1948年回国，历任中国科学院数学研究所研究员、执行副所长，中国核学会计算物理学会理事长，中国人工智能学会首届理事长等职。他在常微分方程的定性理论、运动稳定性、近似解析、机器推理等方面的研究，在中国处于开创的地位。其中极限环的研究，具有国际先进水平。他曾负责完成了中国第一颗原子弹和氢弹的威力计算工作，是1982年国家自然科学奖一等奖的原子弹氢弹设计原理中的物理力学数学理论项目的主要工作者之一，并开辟了计算物理学这一新的学科分支。\n\n3) 开始人工智能的相关项目研究。\n\n20世纪70年代末至80年代前期，一些人工智能相关项目已被纳入国家科研计划。例如，在1978年召开的中国自动化学会年会上，报告了光学文字识别系统、手写体数字识别、生物控制论和模糊集合等研究成果，表明中国人工智能在生物控制和模式识别等方向的研究已开始起步。又如，1978年把“智能模拟”纳入国家研究计划。不过，当时还未能直接提到“人工智能”研究，说明中国的人工智能禁区有待进一步打开。\n\n03\n\n迎来曙光\n\n1984年召开了全国智能计算机及其系统学术讨论会，1985年又召开了全国首届第五代计算机学术研讨会。1986年起把智能计算机系统、智能[机器人] 和智能信息处理等重大项目列入国家高技术研究发展计划(863计划)。\n\n1986 年，清华大学校务委员会经过三次讨论后，决定同意在清华大学出版社出版《人工智能及其应用》著作。\n\n1987年7月《人工智能及其应用》在清华大学出版社公开出版，成为国内首部具有自主知识产权的人工智能专著。接着，中国首部人工智能、机器人学和智能控制著作分别于1987年、1988 年和1990 年问世。1988 年2月，主管国家科技工作的宋健亲笔致信蔡自兴(图2)，对《人工智能及其应用》的公开出版和人工智能学科给予高度评价，指出该人工智能著作的编著和出版“使这一前沿学科的最精彩的成就迅速与中国读者见面，这对人工智能在中国的传播和发展必定会起到重大的推动作用……我深信，以人工智能和模式识别为带头的这门新学科，将为人类迈进智能自动化时期做出奠基性贡献。”宋健对该书的高度评价，体现出他对发展中国人工智能的关注和对作者的鼓励，对中国人工智能的发展产生了重大和深远的影响。\n\n在这封信中宋健还提到：“十年前，当我们和钱先生修订工程控制论时，尚无系统参考书可言，只能断断续续介绍一些思路。现在钱先生看到此书，也一定会欣喜万分。”这体现了宋健的谦虚品德，也表现出钱学森当时对人工智能的热烈支持。\n\n1987年《模式识别与人工智能》杂志创刊。\n\n1989年首次召开了中国人工智能联合会议(CJCAI)，至2004年共召开了8次。此外，还曾经联合召开过6届中国机器人学联合会议。\n\n1993年起，把智能控制和智能自动化等项目列入国家科技攀登计划。\n\n1993年7月，宋健应邀为中国人工智能学会智能机器人分会成立题词“人智能则国智科技强则国强”，向成立大会表示祝贺。本题词很好地阐明了人工智能与提高民族素质、增强科技实力和建设现代化强国的辩证关系。\n\n04\n\n蓬勃发展\n\n进入21世纪后，更多的人工智能与智能系统研究课题获得国家自然科学基金重点和重大项目、国家高技术研究发展计划(863 计划)和国家重点基础研究发展计划(973计划)项目、科技部科技攻关项目、工信部重大项目等各种国家基金计划支持，并与中国国民经济和科技发展的重大需求相结合，力求为国家做出更大贡献。这方面的研究项目很多，代表性的研究有视觉与听觉的认知计算、面向Agent的智能计算机系统、中文智能搜索引擎关键技术、智能化农业专家系统、虹膜识别、语音识别、人工心理与人工情感、基于仿人机器人的人机交互与合作、工程建设中的智能辅助决策系统、未知环境中移动机器人导航与控制等。\n\n2006年8月，中国人工智能学会联合其他学会和有关部门，在北京举办了“庆祝人工智能学科诞生50周年”大型庆祝活动。除了人工智能国际会议外，纪念活动还包括由中国人工智能学会主办的首届中国象棋计算机博弈锦标赛暨首届中国象棋人机大战。东北大学的“棋天大圣”象棋软件获得机器博弈冠军;“浪潮天梭”超级计算机以11：9的成绩战胜了中国象棋大师。这些赛事的成功举办，彰显了中国人工智能科技的长足进步，也向广大公众进行了一次深刻的人工智能基本知识普及教育。主办者认为，这次中国象棋人机大战“无论赢家是人类大师或超级计算机，都是人类智慧的胜利”。\n\n同年，《智能系统学报》创刊(图3)，这是继《人工智能学报》和《模式识别与人工智能》之后国内第3份人工智能类期刊。他们为国内人工智能学者和高校师生提供了一个学术交流平台，对中国人工智能研究与应用起到促进作用。\n\n2009 年，中国人工智能学会牵头组织，向国家学位委员会和国家教育部提出设置“智能科学与技术”学位授权一级学科的建议。该建议指出：现在信息化向智能化迈进”的趋势已经显现;因此，今天培养的智能科学技术高级人才大军，正好赶上明天信息化向智能化大规模迈进的需要。为此，一个顺理而紧迫的建议就是：为了适应信息化向智能化迈进的大趋势，为了实现建设创新型国家的大目标，在中国学位体系中增设智能科学与技术博士和硕士学位授权一级学科。这个建议凝聚了中国广大人工智能教育工作者的心智心血和他们的远见卓识，对中国人工智能学科建设具有十分深远的意义。\n\n05\n\n国家战略\n\n近两年来，中国的人工智能已发展成为国家战略。\n\n2014年6月9日，中国科学院第十七次院士大会、中国工程院第十二次院士大会开幕式上发表重要讲话强调：“由于大数据、云计算、移动互联网等新一代信息技术同机器人技术相互融合步伐加快，3D打印、人工智能迅猛发展，制造机器人的软硬件技术日趋成熟，成本不断降低，性能不断提升，军用无人机、自动驾驶汽车、家政服务机器人已经成为现实，有的人工智能机器人已具有相当程度的自主思维和学习能力。……我们要审时度势、全盘考虑、抓紧谋划、扎实推进。”这是党和国家最高领导人首次对人工智能和相关智能技术的高度评价，是对开展人工智能和智能机器人技术开发的庄严号召和大力推动。\n\n2015年十二届全国人大三次会议上，提出：“人工智能技术将为基于互联网和移动互联网等领域的创新应用提供核心基础。未来人工智能技术将进一步推动关联技术和新兴科技、新兴产业的深度融合，推动新一轮的信息技术革命，势必将成为我国经济结构转型升级的新支点。”这是对人工智能技术的重要作用给予的充分肯定，是对人工智能的有力促进。\n\n这些战略任务，无论是提高创新能力、信息化与工业化深度融合、强化工业基础能力、加强质量品牌建设，或是推动重点领域突破发展、全面推行绿色制造、推进制造业结构调整、发展服务型制造和生产性服务业、提高制造业国际化发展水平，都离不开人工智能的参与，都与人工智能的发展密切相关。人工智能是智能制造不可或缺的核心技术。\n\n2016年4月，工业和信息化部、国家发展改革委、财政部等三部委联合印发了《机器人产业发展规划(2016—2020年)》，为“十三五”期间中国机器人产业发展描绘了清晰的蓝图。该发展规划提出的大部分任务，如智能生产、智能物流、智能工业机器人、人机协作机器人、消防救援机器人、手术机器人、智能型公共服务机器人、智能护理机器人等，都需要采用各种人工智能技术。人工智能也是智能机器人产业发展的关键核心技术。\n\n2016年5月，国家发改委和科技部等4部门联合印发《“互联网+”人工智能三年行动实施方案》，明确未来3年智能产业的发展重点与具体扶持项目，进一步体现出人工智能已被提升至国家战略高度。根据方案的内容，未来3年将在3个大方面、9个小项推进智能产业发展。\n\n《机器人产业发展规划(2016—2020 年)》和《“互联网+”人工智能三年行动实施方案》的发布与施行，体现了中国已把人工智能技术提升到国家发展战略的高度，为人工智能的发展创造了前所未有的优良环境，也赋予人工智能艰巨而光荣的历史使命。\n\n2015年7月在北京召开了“2015中国人工智能大会”。发表了《中国人工智能白皮书》，包括“中国智能机器人白皮书”、“中国自然语言理解白皮书”、“中国模式识别白皮书”、“中国智能驾驶白皮书”和“中国机器学习白皮书”，为中国人工智能相关行业的科技发展描绘一个轮廓，给产业界指引一个发展方向。\n\n2016年4月由中国人工智能学会发起，联合20余家国家一级学会，在北京举行“2016 全球人工智能技术大会暨人工智能60 周年纪念活动启动仪式”(图5)。这次活动恰逢国际人工智能诞辰60周年，谷歌AlphaGo与韩国围棋九段棋手李世石上演“世纪人机大战”(图6)，将人工智能的关注度推到了前所未有的高度。启动仪式共同庆祝国际人工智能诞辰60周年，传承和弘扬人工智能的科学精神，开启智能化时代的新征程。\n\n现在，人工智能已发展成为国家发展战略，中国已有数以10万计的科技人员和大学师生从事不同层次的人工智能相关领域研究、学习、开发与应用，人工智能研究与应用已在中国空前开展，硕果累累，必将为促进其他学科的发展和中国的现代化建设做出新的重大贡献。\n\n二、主要成就\n\n中国的人工智能研究开发、学科建设、产业应用和社会服务等方面，已经取得不俗的成就，主要可以从以下几点得到证实。\n\n01\n\n形成人工智能学科\n\n1981年9月建立了全国性的人工智能组织中国人工智能学会(CAAI)，标志着中国人工智能学科的诞生。1982年在长沙创办中国人工智能学会刊物《人工智能学报》，成为中国人工智能学科领域的第一份学术刊物。中国人工智能学会大会每两年举行一次，至目前已举办16届。中国人工智能学会成立后，又相继成立了中国人工智能学会智能机器人专业委员会、机器学习专业委员会、模式识别专业委员会、自然语言处理专业委员会和智能控制专业委员会、人工智能教育工作委员会等。\n\n此外，中国计算机学会的一些二级学会也开展人工智能相关学术活动，为中国人工智能的发展做出了应有贡献。例如，中国计算机学会成立了人工智能与模式识别专业委员会，中国自动化学会成立了模式识别与机器智能专业委员会以及智能自动化专业委员会等二级学会。有些省市也成立了地方人工智能学会。1989—2004 年，由中国人工智能学会、中国计算机学会等多个学会联合举办过7届中国人工智能联合会议(CJCAI)。\n\n与人工智能密切相关的机器学习、模式识别、智能机器人、自然语言处理、专家系统等领域的学术组织也先后成立，学术活动也十分热烈。例如，国内机器学习的重要学术活动包括每两年举行一次的中国机器学习会议和每年举行的中国机器学习及其应用研讨会。前者由中国计算机学会人工智能与模式识别专业委员会协办，目前已历经15届。后者每届会议包括特邀报告、大会交流及Top Conference Review等部分，迄今已历经13届。又如，中国人工智能学会智能机器人专业委员会自1993年成立以来，每两年举行一次全国智能机器人学术会议，已组织过11届，还与其他学会共同举办过6次中国机器人联合会议。在王湘浩倡导与组织下，全国高校人工智能研讨会研究班自1980年起每年举行一次，是国内最早的人工智能学术研讨活动。\n\n这些人工智能学术组织和会议开展广泛深入的国内外学术交流，对开展人工智能学术活动和组织科技交流起到积极的作用，有力推动了中国人工智能科技发展和学科建设。\n\n02\n\n科学研究成绩斐然\n\n国家已先后设立了各种与人工智能相关的研究课题，如国家自然科学基金重大专项、重点项目和面上项目，国家863计划项目，国家重大战略项目智能制造2025等。在这些科研基金的支持下，国内人工智能研究已取得许多突出成果。\n\n1)人工智能基础研究成果突出\n\n除了前面提到的几何定理证明的“吴氏方法”外，吴文俊还于2004 年发表了重要论文“计算机时代的脑力劳动机械化与科学技术现代化”，宣布他在几何定理证明“机械化”方面的系列成果，指出：“在几何定理机器证明取得成功之后的20多年来，笔者与许多志同道合的同志们在科技部、科学院、基金委等大力支持下，开展了一场可谓‘数学机械化’的‘运动’，在理论与应用诸多方面都已取得了若干成功。”\n\n国内学者在人工智能的诸多领域，如问题求解、不确定推理、泛逻辑理论、拓扑学、模式识别、图像处理、机器学习、专家系统、智能计算和智能控制等领域的基础研究也多有建树，取得一批具有国际先进水平的创造性成果。例如，在模式识别方面，对文字识别、语音识别(图7)、指纹识别、人脸识别、虹膜识别和步态识别等进行深入研究，涉及生物医学、卫星遥感、机器人视觉、货物检测、目标跟踪、自主导航、保安、银行、交通、军事、电子商务和多媒体网络通信等应用领域。\n\n又如，机器学习也是人工智能的核心研究领域之一。现在机器学习的大数据往往体现出多源异构、语义复杂、规模巨大、动态多变等特殊性质，为传统机器学习技术带来了新的挑战。为应对这一挑战，国内科技企业巨头华为、百度等与国外巨头谷歌、微软、亚马逊等展开竞争，纷纷成立以机器学习技术为核心的研究院，以充分挖掘大数据中蕴含的巨大商业与应用价值。深度学习是机器学习领域一个新兴的子领域与研究方向，它是一种通过多层表示来对数据之间的复杂关系进行建模的算法。深度学习模仿人脑结构，具有更强的建模和推理能力，能够更有效地解决多类复杂的智能问题。近年来，中国在深度学习研究方面也取得重要进展，一些研究成果接近或达到国际先进水平。\n\n中国学者在自动规划领域也取得开创性成果。1985年提出与发展了基于专家系统的机器人规划机理与方法，实现了人工智能专家系统与机器人技术的结合，为基于知识的自动规划和高层控制开辟了一条新途径，对提高生产的智能化水平具有重要意义，并推动国内外机器人规划研究的发展。该成果被广泛引用，并被收入清华大学吴麒等主编的全国高校规划教材《自动控制原理》。1999年以来，又在机器人进化规划方面取得创新性成果。\n\n国内在认知计算、情感计算、模式识别、神经网络、智能驾驶、水下机器人和其他智能机器人等领域也取得一批具有国际先进水平的研究成果，培养了一批优秀的学术带头人：郭爱克、任继福、李衍达、王守觉、焦李成、贺汉根、蔡鹤皋、徐玉如和黄心汉等。\n\n此外，有些人工智能基础研究获得国际奖励，如1990年张钹获得ICL欧洲人工智能奖，蔡自兴指导的王勇博士获得2015 IEEE计算智能学会优秀博士学位论文奖等。\n\n值得一提的是美籍华裔学者王浩对人工智能的杰出贡献。1958 年夏天，王浩在纽约州的IBM实验室的一台IBM704机器上用汇编语言编写了3个程序，证明了罗素和怀特海《数学原理》中的200多个定理。他关于数理逻辑的一个命题被国际上定为“ 王氏悖论”。1966年，他在哈佛大学指导的博士生Stephen Cook，因NP 完全性方面的开创性研究成果而获得1982年图灵奖。王浩还与吴文俊进行了合作研究。\n\n2)专用人工智能开发有所突破\n\n中国在专用人工智能领域取得了突破性的进展，已在自然语言处理和语音识别、图像识别、机器学习、虚拟现实、智能处理器、认知计算、智能驾驶和智能机器人等方面取得一大批具有国际先进水平的应用成果。\n\n互联网和大数据推动人工智能进入了新的发展阶段。中国的智能语音技术在移动互联网、呼叫中心、智能家居、汽车电子等领域的研究与应用逐步深入，带动智能语音产业规模持续快速增长。2013年[科大讯飞] 以54.2%的市场份额继续处于国内领先地位。智能语音正在成为主流的交互方式之一。\n\n近几年在多层神经网络基础上发展起来的深度学习和深度神经网络已在中国很多模式识别领域获得成功应用。其中，中国科学院自动化研究所谭铁牛团队在虹膜识别领域，坚持从虹膜图像信息获取的源头进行系统创新，全面突破虹膜识别领域的成像装置、图像处理、特征抽取、识别检索、安全防伪等一系列关键技术，建立了虹膜识别比较系统的计算理论和方法体系，还建成目前国际上最大规模的共享虹膜图像库，已大规模用于煤矿人员辨识和北京城铁监控等，并在70个国家和地区的3000 多个科研团队推广使用，有力推动了虹膜识别学科发展。\n\n在2010年举行的国际上难度最高、规模最大的虹膜识别专业测评竞赛中，谭铁牛团队提交的算法，从来自25个国家和地区的41支参赛团队里脱颖而出，以测试性能指标超过第2名41.3%的绝对优势蝉联虹膜识别算法赛事冠军(图8)。在2008年进行的上届国际虹膜识别算法竞赛上，谭铁牛团队战胜来自35个国家和地区的97支参赛队伍。这充分展示出中国在虹膜识别领域领先国际的整体实力。\n\n在模式识别领域，石青云领衔的北大高科指纹技术有限公司在指纹识别领域取得领先成果，成为国家科技强警的利剑。\n\n专家系统已在国内获得广泛应用，应用领域涉及工业、农业等行业，其经济效益相当可观。例如，在冶金专家系统的开发与应用方面，已把专家系统技术用于高炉建模、监控与诊断等，建立了基于多核学习的高炉自动化框架、', 'doi': '', 'published_date': '2025-04-30T00:00:00+00:00', 'pdf_url': '', 'url': 'https://finance.sina.com.cn/roll/2025-04-30/doc-ineuxwev4150658.shtml', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '中国人工智能40年（上）_腾讯新闻', 'authors': [], 'abstract': '中国人工智能40年（上）\\_腾讯新闻\n# 中国人工智能40年（上）\n![头像]![] \n[\n人机与认知实验室] \n2025-04-25 05:43科技领域创作者\n【作者单位：湖南省自兴人工智能研究院，中南大学智能系统与智能软件研究所】智能机器是一种能够呈现出人类智能行为的机器。人工智能（ArtificialIntelligence，AI）是计算机科学或智能科学中涉及研究、设计和应用智能机器的一个分支。人工智能的近期主要目标在于研究用机器来模仿和执行人脑的某些智力功能，而远期目标是用自动机模仿人类的思维活动和智力功能[1]。\n人类对人工智能和智能机器的梦想与追求，可以追溯到3000多年前。中国也不乏这方面的故事与史料[2]。\n近代科学技术的许多重大进展都是人类智慧、思维、梦想和奋斗的成果。人类历史上从来没有出现过像今天这样的思想大解放，关于宇宙、星球、生命、人类、时空、进化和智能等思想与作品，如雨后春笋破土而出，似百花争艳迎春怒放。其中，人工智能尤其引人注目。进入20世纪后，人工智能开始孕育于人类社会母胎。到20世纪30—40年代发生了两件极其重要的事件：数理逻辑的形式化和智能可计算（机器能思维）的思想，建立了计算与智能关系的概念。被称为“人工智能之父”（The father of AI）的图灵（Turing AM），于1936年创立了自动机理论，提出一个理论计算机模型，奠定电子计算机设计基础，促进人工智能特别是思维机器的研究。1950年图灵的论文“机器能思考吗？”，为即将问世的人工智能提供了科学性和开创性的构思。\n1956年夏季由麦卡锡（McCarthyJ）、明斯基（Minsky ML）、罗彻斯特（Lochester N）和香农（Shannon CE）共同发起，并邀请其他6位年轻的科学家，在美国达特茅斯（Dartmouth）大学举办了一次长达两个月的十人研讨会，讨论用机器模拟人类智能问题，首次使用“人工智能”这一术语。这是人类历史上第一次人工智能研讨会，标志着国际人工智能学科的诞生，具有十分重要的历史意义。发起这次研讨会的人工智能学者麦卡锡和明斯基，则被誉为国际人工智能的“奠基者”或“创始人”（The founding father），有时也称为“人工智能之父”[3]。\n中国的人工智能经历了怎样的发展过程，取得哪些成绩，存在什么问题，面临何种机遇，有哪些解决方案？本文力图逐一探讨。**1发展过程**\n与国际上人工智能的发展情况相比，国内的人工智能研究不仅起步较晚，而且发展道路曲折坎坷，历经了质疑、批评甚至打压的十分艰难的发展历程。直到改革开放之后，中国的人工智能才逐渐走上发展之路。**1.1迷雾重重**\n20世纪50—60年代，人工智能在西方国家得到重视和发展，而在苏联却受到批判，将其斥为“资产阶级的反动伪科学”。当时，受苏联批判人工智能和控制论（Cybernetics）的影响[4]，中国在20世纪50年代几乎没有人工智能研究；20世纪60年代后期和70年代，虽然苏联解禁了控制论和人工智能的研究，但因中苏关系恶化，中国学术界将苏联的这种解禁斥之为“修正主义”，人工智能研究继续停滞。那时，人工智能在中国要么受到质疑，要么与“特异功能”一起受到批判，被认为是伪科学和修正主义。《摘译外国自然科学哲学》月刊1976年第3期刊文称：“在批判‘图像识别’和‘人工智能’研究领域各种反动思潮的斗争中，走自己的道路”。这足见中国人工智能研究迷雾重重的艰难处境[5\\~8]。\n![图片] 1978年3月，全国科学大会在北京召开。在华国锋主持的大会开幕式上，邓小平发表了“科学技术是生产力”的重要讲话。大会提出“向科学技术现代化进军”的战略决策，打开解放思想的先河，促进中国科学事业的发展，使中国科技事业迎来了科学的春天[9]。这是中国改革开放的先声，广大科技人员出现了思想大解放，人工智能也在酝酿着进一步的解禁。吴文俊提出的利用机器证明与发现几何定理的新方法——几何定理机器证明（图1），获得1978年全国科学大会重大科技成果奖就是一个好的征兆[10,11]。\n20世纪80年代初期，钱学森等主张开展人工智能研究，中国的人工智能研究进一步活跃起来[12,13]。但是，由于当时社会上把“人工智能”与“特异功能”混为一谈，使中国人工智能走过一段很长的弯路。一方面，包括许多人工智能学者在内的研究者把人工智能与特异功能搅在一起“研究”；另一方面，社会上在批判“特异功能”时将“人工智能”一起进行批判，把两者一并斥之为“伪科学”。\n**1.2艰难起步**\n20世纪70年代末至80年代，知识工程和专家系统在欧美发达国家得到迅速发展，并取得重大的经济效益。当时中国相关研究处于艰难起步阶段，一些基础性的工作得以开展。\n1） 派遣留学生出国研究人工智能。改革开放后，自1980年起中国大批派遣留学生赴西方发达国家研究现代科技，学习科技新成果，其中包括人工智能和模式识别等学科领域。这些人工智能“海归”专家，已成为中国人工智能研究与开发应用的学术带头人和中坚力量，为发展中国人工智能做出举足轻重的贡献。\n2） 成立中国人工智能学会。1981年9月，中国人工智能学会（CAAI）在长沙成立，秦元勋当选第一任理事长[14]。于光远在大会期间主持了一次大型座谈会，讨论有关人工智能的一些认识问题。他指出：“人工智能是一门新兴的科学，我们应该积极支持；对所谓‘人体特异功能’的研究是一门伪科学，不但不应该支持，而且要坚决反对。”[15]1982年，中国人工智能学会刊物《人工智能学报》在长沙创刊，成为国内首份人工智能学术刊物。\nCAAI首任理事长秦元勋也颇受争议。秦元勋获美国哈佛大学博士学位后于1948年回国，历任中国科学院数学研究所研究员、执行副所长，中国核学会计算物理学会理事长，中国人工智能学会首届理事长等职。他在常微分方程的定性理论、运动稳定性、近似解析、机器推理等方面的研究，在中国处于开创的地位。其中极限环的研究，具有国际先进水平。他曾负责完成了中国第一颗原子弹和氢弹的威力计算工作，是1982年国家自然科学奖一等奖的原子弹氢弹设计原理中的物理力学数学理论项目的主要工作者之一，并开辟了计算物理学这一新的学科分支[16]。\n3） 开始人工智能的相关项目研究。20世纪70年代末至80年代前期，一些人工智能相关项目已被纳入国家科研计划。例如，在1978年召开的中国自动化学会年会上，报告了光学文字识别系统、手写体数字识别、生物控制论和模糊集合等研究成果，表明中国人工智能在生物控制和模式识别等方向的研究已开始起步[17]。又如，1978年把“智能模拟”纳入国家研究计划。不过，当时还未能直接提到“人工智能”研究，说明中国的人工智能禁区有待进一步打开。\n**1.3迎来曙光**\n1984年1月和2月，邓小平分别在深圳和上海观看儿童与计算机下棋时，指示“计算机普及要从娃娃抓起”[18]。此后，中国人工智能研究的境遇有所好转。例如，人民日报关于人工智能的报道也渐渐多了起来[19,20]。20世纪80年代中期，中国的人工智能迎来曙光，开始走上比较正常的发展道路。\n国防科工委于1984年召开了全国智能计算机及其系统学术讨论会，1985年又召开了全国首届第五代计算机学术研讨会。1986年起把智能计算机系统、智能机器人和智能信息处理等重大项目列入国家高技术研究发展计划（863计划）。\n1986年，清华大学校务委员会经过三次讨论后，决定同意在清华大学出版社出版《人工智能及其应用》著作。\n1987年7月《人工智能及其应用》在清华大学出版社公开出版，成为国内首部具有自主知识产权的人工智能专著[21]。接着，中国首部人工智能、机器人学和智能控制著作分别于1987年、1988年和1990年问世[22\\~24]。1988年2月，主管国家科技工作的国务委员兼国家科委主任宋健亲笔致信蔡自兴（图2），对《人工智能及其应用》的公开出版和人工智能学科给予高度评价，指出该人工智能著作的编著和出版“使这一前沿学科的最精彩的成就迅速与中国读者见面，这对人工智能在中国的传播和发展必定会起到重大的推动作用。……现在有了这本书，千千万万的青年科学家得以一览这门学科的系统的、精选的要义，是中国科学界的一件大事。……我深信，以人工智能和模式识别为带头的这门新学科，将为人类迈进智能自动化时期做出奠基性贡献。”[25\\~27]宋健对该书的高度评价，体现出他对发展中国人工智能的关注和对作者的鼓励，对中国人工智能的发展产生了重大和深远的影响。![图片] \n在这封信中宋健还提到：“十年前，当我们和钱先生修订工程控制论时[28]，尚无系统参考书可言，只能断断续续介绍一些思路。现在钱先生看到此书，也一定会欣喜万分。”这体现了宋健的谦虚品德，也表现出钱学森当时对人工智能的热烈支持[27]。\n1987年《模式识别与人工智能》杂志创刊。\n1989年首次召开了中国人工智能联合会议（CJCAI），至2004年共召开了8次。此外，还曾经联合召开过6届中国机器人学联合会议。\n1993年起，把智能控制和智能自动化等项目列入国家科技攀登计划。\n1993年7月，宋健应邀为中国人工智能学会智能机器人分会成立题词“人智能则国智科技强则国强”，向成立大会表示祝贺[29]。本题词很好地阐明了人工智能与提高民族素质、增强科技实力和建设现代化强国的辩证关系，也是国家科技领域领导人对中国人工智能事业的有力支持以及对全国人工智能工作者的殷切期望。\n**1.4蓬勃发展**\n进入21世纪后，更多的人工智能与智能系统研究课题获得国家自然科学基金重点和重大项目、国家高技术研究发展计划（863计划）和国家重点基础研究发展计划（973计划）项目、科技部科技攻关项目、工信部重大项目等各种国家基金计划支持，并与中国国民经济和科技发展的重大需求相结合，力求为国家做出更大贡献。这方面的研究项目很多，代表性的研究有视觉与听觉的认知计算、面向Agent的智能计算机系统、中文智能搜索引擎关键技术、智能化农业专家系统、虹膜识别、语音识别、人工心理与人工情感、基于仿人机器人的人机交互与合作、工程建设中的智能辅助决策系统、未知环境中移动机器人导航与控制等。\n2006年8月，中国人工智能学会联合其他学会和有关部门，在北京举办了“庆祝人工智能学科诞生50周年”大型庆祝活动[30]。除了人工智能国际会议外，纪念活动还包括由中国人工智能学会主办的首届中国象棋计算机博弈锦标赛暨首届中国象棋人机大战。东北大学的“棋天大圣”象棋软件获得机器博弈冠军；“浪潮天梭”超级计算机以11：9的成绩战胜了中国象棋大师。这些赛事的成功举办，彰显了中国人工智能科技的长足进步，也向广大公众进行了一次深刻的人工智能基本知识普及教育。主办者认为，这次中国象棋人机大战“无论赢家是人类大师或超级计算机，都是人类智慧的胜利”[31]。![图片] \n同年，《智能系统学报》创刊（图3），这是继《人工智能学报》和《模式识别与人工智能》之后国内第3份人工智能类期刊。他们为国内人工智能学者和高校师生提供了一个学术交流平台，对中国人工智能研究与应用起到促进作用。\n2009年，中国人工智能学会牵头组织，向国家学位委员会和国家教育部提出设置“智能科学与技术”学位授权一级学科的建议。该建议指出：现在信息化向智能化迈进”的趋势已经显现；因此，今天培养的智能科学技术高级人才大军，正好赶上明天信息化向智能化大规模迈进的需要。为此，一个顺理而紧迫的建议就是：为了适应信息化向智能化迈进的大趋势，为了实现建设创新型国家的大目标，在中国学位体系中增设智能科学与技术博士和硕士学位授权一级学科。这个建议凝聚了中国广大人工智能教育工作者的心智心血和他们的远见卓识，对中国人工智能学科建设具有十分深远的意义[32]。\n**1.5国家战略**\n近两年来，中国的人工智能已发展成为国家战略。国家最高领导人习近平、李克强发表重要讲话，对发展中国人工智能和机器人学给予高屋建瓴的指示与支持。2014年6月9日，习近平总书记在中国科学院第十七次院士大会、中国工程院第十二次院士大会开幕式上发表重要讲话强调：“由于大数据、云计算、移动互联网等新一代信息技术同机器人技术相互融合步伐加快，3D打印、人工智能迅猛发展，制造机器人的软硬件技术日趋成熟，成本不断降低，性能不断提升，军用无人机、自动驾驶汽车、家政服务机器人已经成为现实，有的人工智能机器人已具有相当程度的自主思维和学习能力。……我们要审时度势、全盘考虑、抓紧谋划、扎实推进。”[33]这是党和国家最高领导人首次对人工智能和相关智能技术的高度评价，是对开展人工智能和智能机器人技术开发的庄严号召和大力推动。\n2015年十二届全国人大三次会议上，李克强总理在政府工作报告中提出：“人工智能技术将为基于互联网和移动互联网等领域的创新应用提供核心基础。未来人工智能技术将进一步推动关联技术和新兴科技、新兴产业的深度融合，推动新一轮的信息技术革命，势必将成为我国经济结构转型升级的新支点。”[34]这是对人工智能技术的重要作用给予的充分肯定，是对人工智能的有力促进。\n2015年5月，国务院发布《中国制造2025》（图4），部署全面推进实施制造强国战略。这是中国实施制造强国战略第一个十年的行动纲领。围绕实现制造强国的战略目标，《中国制造2025》明确了9项战略任务和重点[35]。![图片] \n这些战略任务，无论是提高创新能力、信息化与工业化深度融合、强化工业基础能力、加强质量品牌建设，或是推动重点领域突破发展、全面推行绿色制造、推进制造业结构调整、发展服务型制造和生产性服务业、提高制造业国际化发展水平，都离不开人工智能的参与，都与人工智能的发展密切相关。人工智能是智能制造不可或缺的核心技术。2016年4月，工业和信息化部、国家发展改革委、财政部等三部委联合印发了《机器人产业发展规划（2016—2020年）》，为“十三五”期间中国机器人产业发展描绘了清晰的蓝图。该发展规划提出的大部分任务，如智能生产、智能物流、智能工业机器人、人机协作机器人、消防救援机器人、手术机器人、智能型公共服务机器人、智能护理机器人等，都需要采用各种人工智能技术。人工智能也是智能机器人产业发展的关键核心技术[36，37]。![图片] \n2016年5月，国家发改委和科技部等4部门联合印发《“互联网+”人工智能三年行动实施方案》，明确未来3年智能产业的发展重点与具体扶持项目，进一步体现出人工智能已被提升至国家战略高度。根据方案的内容，未来3年将在3个大方面、9个小项推进智能产业发展[38]。\n国家最高领导人对人工智能的高度评价和对发展我国人工智能的指示，《中国制造2025》、《机器人产业发展规划（2016—2020年）》和《“互联网+”人工智能三年行动实施方案》的发布与施行，体现了中国已把人工智能技术提升到国家发展战略的高度，为人工智能的发展创造了前所未有的优良环境，也赋予人工智能艰巨而光荣的历史使命。\n2015年7月在北京召开了“2015中国人工智能大会”。发表了《中国人工智能白皮书》，包括“中国智能机器人白皮书”、“中国自然语言理解白皮书”、“中国模式识别白皮书”、“中国智能驾驶白皮书”和“中国机器学习白皮书”，为中国人工智能相关行业的科技发展描绘一个轮廓，给产业界指引一个发展方向[39]。\n2016年4月由中国人工智能学会发起，联合20余家国家一级学会，在北京举行“2016全球人工智能技术大会暨人工智能60周年纪念活动启动仪式”（图5）[40]。这次活动恰逢国际人工智能诞辰60周年，谷歌AlphaGo与韩国围棋九段棋手李世石上演“世纪人机大战”（图6），将人工智能的关注度推到了前所未有的高度[41]。启动仪式共同庆祝国际人工智能诞辰60周年，传承和弘扬人工智能的科学精神，开启智能化时代的新征程。\n现在，人工智能已发展成为国家发展战略，中国已有数以10万计的科技人员和大学师生从事不同层次的人工智能相关领域研究、学习、开发与应用，人工智能研究与应用已在中国空前开展，硕果累累，必将为促进其他学科的发展和中国的现代化建设做出新的重大贡献。\n**2主要成就**\n中国的人工智能研究开发、学科建设、产业应用和社会服务等方面，已经取得不俗的成就，主要可以从以下几点得到证实。![图片] \n**2.1形成人工智能学科**\n1981年9月建立了全国性的人工智能组织中国人工智能学会（CAAI），标志着中国人工智能学科的诞生[14]。1982年在长沙创办中国人工智能学会刊物《人工智能学报》，成为中国人工智能学科领域的第一份学术刊物。中国人工智能学会大会每两年举行一次，至目前已举办16届。中国人工智能学会成立后，又相继成立了中国人工智能学会智能机器人专业委员会、机器学习专业委员会、模式识别专业委员会、自然语言处理专业委员会和智能控制专业委员会、人工智能教育工作委员会等。\n此外，中国计算机学会的一些二级学会也开展人工智能相关学术活动，为中国人工智能的发展做出了应有贡献。例如，中国计算机学会成立了人工智能与模式识别专业委员会，中国自动化学会成立了模式识别与机器智能专业委员会以及智能自动化专业委员会等二级学会。有些省市也成立了地方人工智能学会。1989—2004年，由中国人工智能学会、中国计算机学会等多个学会联合举办过7届中国人工智能联合会议（CJCAI）[42]。\n与人工智能密切相关的机器学习、模式识别、智能机器人、自然语言处理、专家系统等领域的学术组织也先后成立，学术活动也十分热烈。例如，国内机器学习的重要学术活动包括每两年举行一次的中国机器学习会议和每年举行的中国机器学习及其应用研讨会。前者由中国计算机学会人工智能与模式识别专业委员会协办，目前已历经15届。后者每届会议包括特邀报告、大会交流及Top Conference Review等部分，迄今已历经13届。又如，中国人工智能学会智能机器人专业委员会自1993年成立以来，每两年举行一次全国智能机器人学术会议，已组织过11届，还与其他学会共同举办过6次中国机器人联合会议。在王湘浩倡导与组织下，全国高校人工智能研讨会研究班自1980年起每年举行一次，是国内最早的人工智能学术研讨活动。\n这些人工智能学术组织和会议开展广泛深入的国内外学术交流，对开展人工智能学术活动和组织科技交流起到积极的作用，有力推动了中国人工智能科技发展和学科建设。**2.2科学研究成绩斐然**\n国家已先后设立了各种与人工智能相关的研究课题，如国家自然科学基金重大专项、重点项目和面上项目，国家863计划项目，国家重大战略项目智能制造2025等。在这些科研基金的支持下，国内人工智能研究已取得许多突出成果。\n1）人工智能基础研究成果突出。\n除了前面提到的几何定理证明的“吴氏方法”外[43]，吴文俊还于2004 年发表了重要论文“计算机时代的脑力劳动机械化与科学技术现代化”，宣布他在几何定理证明“机械化”方面的系列成果，指出：“在几何定理机器证明取得成功之后的20多年来，笔者与许多志同道合的同志们在科技部、科学院、基金委等大力支持下，开展了一场可谓‘数学机械化’的‘运动’，在理论与应用诸多方面都已取得了若干成功。”[44]\n国内学者在人工智能的诸多领域，如问题求解、不确定推理、泛逻辑理论、拓扑学、模式识别、图像处理、机器学习、专家系统、智能计算和智能控制等领域的基础研究也多有建树，取得一批具有国际先进水平的创造性成果。例如，在模式识别方面，对文字识别、语音识别（图7）、指纹识别、人脸识别、虹膜识别和步态识别等进行深入研究，涉及生物医学、卫星遥感、机器人视觉、货物检测、目标跟踪、自主导航、保安、银行、交通、军事、电子商务和多媒体网络通信等应用领域[45,46]。又如，机器学习也是人工智能的核心研究领域之一，现在机器学习的大数据往往体现出多源异构、语义复杂、规模巨大、动态多变等特殊性质，为传统机器学习技术带来了新的挑战。为应对这一挑战，国内科技企业巨头华为、百度等与国外巨头谷歌、微软、亚马逊等展开竞争，纷纷成立以机器学习技术为核心的研究院，以充分挖掘大数据中蕴含的巨大商业与应用价值[47,48]。深度学习是机器学习领域一个新兴的子领域与研究方向，它是一种通过多层表示来对数据之间的复杂关系进行建模的算法[49]。深度学习模仿人脑结构，具有更强的建模和推理能力，能够更有效地解决多类复杂的智能问题。近年来，中国在深度学习研究方面也取得重要进展，一些研究成果接近或达到国际先进水平[50,51]。\n中国学者在自动规划领域也取得开创性成果。1985年提出与发展了基于专家系统的机器人规划机理与方法，实现了人工智能专家系统与机器人技术的结合，为基于知识的自动规划和高层控制开辟了一条新途径，对提高生产的智能化水平具有重要意义，并推动国内外机器人规划研究的发展[52\\~54]。该成果被广泛引用，并被收入清华大学吴麒等主编的全国高校规划教材《自动控制原理》[55]。1999年以来，又在机器人进化规划方面取得创新性成果[56\\~58]。\n国内在认知计算、情感计算、模式识别、神经网络、智能驾驶、水下机器人和其他智能机器人等领域也取得一批具有国际先进水平的研究成果，培养了一批优秀的学术带头人：郭爱克、任继福、李衍达、王守觉、焦李成、贺汉根、蔡鹤皋、徐玉如和黄心汉等。此外，有些人工智能基础研究获得国际奖励，如1990年张钹获得ICL欧洲人工智能奖[59]，蔡自兴指导的王勇博士获得2015 IEEE 计算智能学会优秀博士学位论文奖等[60]。\n值得一提的是美籍华裔学者王浩对人工智能的杰出贡献。1958年夏天，王浩在纽约州的IBM实验室的一台IBM704机器上用汇编语言编写了3个程序，证明了罗素和怀特海《数学原理》中的200多个定理。他关于数理逻辑的一个命题被国际上定为“ 王氏悖论”。1966年，他在哈佛大学指导的博士生Stephen Cook，因NP完全性方面的开创性研究成果而获得1982年图灵奖[61,62]。王浩还与吴文俊进行了合作研究[43]。\n2）专用人工智能开发有所突破。\n中国在专用人工智能领域取得了突破性的进展，已在自然语言处理和语音识别、图像识别、机器学习、虚拟现实、智能处理器、认知计算、智能驾驶和智能机器人等方面取得一大批具有国际先进水平的应用成果。互联网和大数据推动人工智能进入了新的发展阶段。中国的智能语音技术在移动互联网、呼叫中心、智能家居、汽车电子等领域的研究与应用逐步深入，带动智能语音产业规模持续快速增长。2013年科大讯飞以54.2%的市场份额继续处于国内领先地位。智能语音正在成为主流的交互方式之一[63]。![图片] \n近几年在多层神经网络基础上发展起来的深度学习和深度神经网络已在中国很多模式识别领域获得成功应用。其中，中国科学院自动化研究所谭铁牛团队在虹膜识别领域，坚持从虹膜图像信息获取的源头进行系统创新，全面突破虹膜识别领域的成像装置、图像处理、特征抽取、识别检索、安全防伪等一系列关键技术，建立了虹膜识别比较系统的计算理论和方法体系，还建成目前国际上最大规模的共享虹膜图像库，已大规模用于煤矿人员辨识和北京城铁监控等，并在70个国家和地区的3000多个科研团队推广使用，有力推动了虹膜识别学科发展[64]。在2010年举行的国际上难度最高、规模最大的虹膜识别专业测评竞赛中，谭铁牛团队提交的算法，从来自25个国家和地区的41支参赛团队里脱颖而出，以测试性能指标超过第2名41.3%的绝对优势蝉联虹膜识别算法赛事冠军（图8）。在2008年进行的上届国际虹膜识别算法竞赛上，谭铁牛团队战胜来自35个国家和地区的97支参赛队伍。这充分展示出中国在虹膜识别领域领先国际的整体实力[65]。\n在模式识别领域，石青云领衔的北大高科指纹技术有限公司在指纹识别领域取得领先成果，成为国家科技强警的利剑[66]。\n专家系统已在国内获得广泛应用，应用领域涉及工业、农业等行业，其经济效益相当可观[67\\~69]。例如，在冶金专家系统的开发与应用方面，已把专家系统技术用于高炉建模、', 'doi': '', 'published_date': '2025-04-25T00:00:00+00:00', 'pdf_url': '', 'url': 'https://news.qq.com/rain/a/20250425A01A5Q00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来----中国科学院', 'authors': [], 'abstract': '人工智能的历史、现状和未来----中国科学院\n[PC] /[English] /[联系我们] /[网站地图] /[邮箱] /[无障碍] /[关怀版] \n[![]![]] \n![] \n[![]] [![]] [![]] [![]] [![]] \n* [首页] \n* [组织机构] [主要职责] [院况简介] [院领导集体] [机构设置] \n* [科学研究] [科技专项] [科技奖励] [科技期刊] [科研进展] \n* [成果转化] [知识产权与科技成果转化网] [工作动态] \n* [人才教育] [中国科学院教育简介] [中国科学技术大学] [中国科学院大学] [上海科技大学] [工作动态] \n* [学部与院士] \n* [科学普及] [科学与中国] [中国科普博览] [科普场馆] [工作动态] \n* [党建与科学文化] [工作动态] [反腐倡廉] [文明天地] \n* [信息公开] [信息公开规定] [信息公开指南] [信息公开目录] [信息公开申请] [信息公开联系方式] \n* [首页] \n* [组织机构] \n* [科学研究] \n* [成果转化] \n* [人才教育] \n* [学部与院士] \n* [科学普及] \n* [党建与科学文化] \n* [信息公开] \n主要职责中国科学院贯彻落实党中央关于科技创新的方针政策和决策部署，在履行职责过程中坚持党中央对科技工作的集中统一领导。主要职责是：一、开展使命导向的自然科学领域基础研究，承担国家重大基础研究、应用基础研究、前沿交叉共性技术研究和引领性颠覆性技术研究任务，打造原始创新策源地。[更多+] \n院况简介中国科学院是国家科学技术界最高学术机构、国家科学技术思想库，自然科学基础研究与高技术综合研究的国家战略科技力量。1949年，伴随着新中国的诞生，中国科学院成立。建院70余年来，中国科学院时刻牢记使命，与科学共进，与祖国同行，以国家富强、人民幸福为己任，人才辈出，硕果累累，为我国科技进步、经济社会发展和国家安全作出了不可替代的重要贡献。[更多+] \n院领导集体* [![] \n侯建国] \n* [![] \n吴朝晖] \n* [![] \n孙也刚] \n* [![] \n周\u3000琪] \n* [![] \n汪克强] \n* [![] \n丁赤飚] \n* [![] \n何宏平] \n* [![] \n孙晓明] \n* [![] \n王\u3000华] \n* [![] \n文\u3000亚] \n* [![] \n王大同] \n机构设置* ##### 院机关[办公厅] \n[科技创新发展局] \n[基础科学研究局] \n[战略高技术研究局] \n[重大专项研究局] \n[可持续发展科技研究局] \n[科技基础能力局] \n[学部工作局] \n[人才与人事局] \n[国际合作局] \n[财务与资产管理局] \n[审计与监督局（党组巡视工作领导小组办公室）] \n[机关党委] \n[老专家老干部服务局] \n* ##### 派驻机构[中央纪委国家监委驻中国科学院纪检监察组] \n* ##### 分院[沈阳分院] \n[上海分院] \n[武汉分院] \n[广州分院] \n[成都分院] \n[昆明分院] \n[西安分院] \n[兰州分院] \n[新疆分院] \n* ##### 院属机构[研究单位] \n[学校] \n[管理与公共支撑单位] \n[新闻出版单位] \n[其他单位] \n[共建单位] \n[院级非法人单元] \n[所级分支机构] \n[境外机构] \n[群团和其他组织] \n* [![]] \n* [![]] \n科技奖励![] \n[科技奖励] \n* [国家最高科学技术奖] \n* [国家自然科学奖] \n* [国家技术发明奖] \n* [国家科学技术进步奖\n] \n* [国家科学技术合作奖] \n* [中国科学院杰出科技成就奖] \n* [中国科学院国际科技合作奖] \n* [陈嘉庚科学奖] \n科技期刊![] \n[科技期刊] \n* [期刊导航] \n* [数字平台] \n* [期刊集群] \n* [期刊动态] \n科技专项为方便科研人员全面快捷了解院级科技专项信息并进行项目申报等相关操作，特搭建中国科学院院级科技专项信息管理服务平台。了解科技专项更多内容，请点击进入→[![]] \n科研进展[/更多] \n* [我国成功实现太空金属3D打印] \n* [研究人员在铁电材料中发现一维带电畴壁] \n* [科学家打造“AI科学家团队” 加速新材料创制] \n* [研究揭示高纬度和高海拔多年冻土区土壤碳分解温度敏感性的分异特征] \n* [兰属植物*ndh*基因普遍退化及其演化响应研究取得进展] \n* [研究揭示杜鹃花属物种形成过程中基因流异质性与基因组结构关系] \n[![]] \n工作动态[/更多] \n* [青海盐湖所在碱性溶液萃取提锂关键技术上取得突破] \n* [上海硅酸盐所3D打印硅基生物陶瓷口腔修复产品开发取得新进展] \n* [“制氢+硫磺”，新技术助力工业绿色低碳发展] \n* [亿方级甲烷-二氧化碳干重整示范装置通过72小时标定考核] \n* [国内首台套钢铁行业高炉煤气变压吸附碳捕集示范装置正式投运] \n* [工程热物理所自主研发的循环流化床生物质气化制绿色液体燃料原料气技术示范工程投产] \n* [大连化物所开发出100kWh级磷酸盐基钠离子电池储能系统并实现并网运行] \n* [昆明分院等举办2025腾冲科学家论坛·科技创新成果展示与转化应用对接活动] \n* [山西煤化所等共同建设的千吨级高性能碳纤维项目竣工投产] \n* [大连化物所“苯酚双氧水羟基化制苯二酚固定床新工艺”通过科技成果评价] \n* [低空智能交通技术及载运装备领域科技成果对接系列活动在穗举办] \n* [金属所举办“云南行”科技成果对接活动] \n* [![]] \n[中国科学技术大学（简称“中国科大”）于1958年由中国科学院创建于北京，1970年学校迁至安徽省合肥市。中国科大坚持“全院办校、所系结合”的办学方针，是一所以前沿科学和高新技术为主、兼有特色管理与人文学科的研究型大学。] \n* [![]] \n[中国科学院大学（简称“国科大”）始建于1978年，其前身为中国科学院研究生院，2012年经教育部批准更名为中国科学院大学。国科大实行“科教融合”的办学方针，与中国科学院直属研究机构（包括所、院、台、中心等），在管理体制、师资队伍、培养体系、科研工作等方面高度融合，是一所以研究生教育为主的独具特色的高等学校。] \n* [![]] \n[上海科技大学（简称“上科大”），由上海市人民政府与中国科学院共同举办、共同建设，由上海市人民政府主管，2013年经教育部正式批准。上科大致力于服务国家经济社会发展战略，培养科技创新创业人才，努力建设一所小规模、高水平、国际化的研究型、创新型大学。] \n工作动态[/更多] \n* [国科大举办2025拾光奉献纪念典礼] \n* [上海分院与上海交通大学签约开展战略合作] \n* [2025年中国科大科教融合单位研究生教育工作总结交流会举办] \n* [沈阳分院与大连理工大学举行工作交流] \n* [云南省热带亚洲榕-蜂群落构建与利用国际联合实验室培训班举办] \n* [成都山地所与西南交通大学签署战略合作协议] \n[![]] [![]] [![]] \n科普场馆[/更多] \n* [中国科学院国家授时中心时间科学馆] \n* [中国科学院昆明动物研究所昆明动物博物馆] \n* [中国科学院合肥物质科学研究院合肥现代科技馆] \n* [中国科学院动物研究所国家动物博物馆] \n* [中国科学院新疆生态与地理研究所生物标本馆] \n* [中国科学院新疆生态与地理研究所新疆自然博物馆] \n* [中国科学院南海海洋研究所南海海洋生物标本馆] [![]] \n工作动态[/更多] \n* [“科学与中国”西部行——“千名院士·千场科普”行动在云南举办] \n* [2025“科学与中国”院士专家巡讲团走进香港50所中小学校] \n* [2025年中国科学院科普讲解大赛举办] \n* [中国科学院举办2025年度科普工作骨干培训班] \n* [2025年中国科学院科普讲解大赛即将启幕] \n* [版纳植物园举办第十三届观鸟节] \n* [福建物构所举办科学节活动] [![]] \n工作动态[/更多] \n* [数学院田野院士成为《榜样10》党员先进典型] \n* [天津工生所召开党委理论学习中心组学习会] \n* [理化所召开党委理论学习中心组集体学习会] \n* [昆明分院分党组理论学习中心组召开学习扩大会] \n* [武汉岩土所召开2025年度党（总）支部书记述职考评会] \n* [宁波材料所召开党委理论学习中心组学习会] \n* [授时中心传达学习中国科学院党组冬季扩大会议精神] \n* [版纳植物园召开党委会] \n* [心理所召开2025年度全面从严治党暨党风廉政建设会议] \n[![]] [![]] \n反腐倡廉[/更多] \n* [沈阳分院召开2025年度第四次纪检组扩大会议] \n* [新疆分院纪检组召开2025年第四次纪监审工作会议] \n* [国科控股举办2025年纪检干部培训班] \n* [西安分院召开第四季度纪监审工作交流会] \n[违纪违法举报] \n文明天地[/更多] \n* [中国科学院合唱团举办“2026新年音乐会”] \n* [中国科学院合唱团参加“首都留学人员2026新年音乐会”] \n* [光电所举办“五十五载辉煌路·追光逐电启新程”职工运动会] \n* [计算机网络信息中心举办“榜样之声·初心映耀”身边榜样故事分享会] \n主动公开工作信息相关规定* [信息公开指南] \n* [主动公开事项目录] \n* [其他规定] \n组织机构* [工作机构] \n* [监督机构] \n中国科学院学部基本信息* [学部概况] \n* [院士大会] \n* [院士信息] \n规章制度* [院士章程] \n* [增选工作有关规定] \n* [其他工作规则与管理办法] \n工作进展* [院士增选] \n* [决策咨询] \n* [学术引领] \n* [科学普及] \n* [工作动态] \n学部出版物* [决策咨询系列] \n* [学术引领系列] \n* [科学文化系列] \n* [其他出版物] \n陈嘉庚科学奖* [机构概况] \n* [规章制度] \n* [通知公告] \n中国科学院院部机构设置* [基本情况] \n* [院领导集体] \n* [组织机构] \n规章制度* [综合性制度文件] \n* [政策解读] \n财务资产* [预算决算] \n* [公示公告] \n新闻动态* [重要新闻] \n* [工作动态] \n* [媒体报道] \n* [网站专题] \n* [通知公告] \n科学研究* [科研装备] \n* [科研进展] \n* [成果转化] \n* [科技奖励] \n* [科技期刊] \n人事人才* [人事任免] \n* [人才招聘] \n* [招生与培养] \n国际合作* [国际组织] \n* [政策法规] \n[首页] \\>[访谈·视点] \n## ## 谭铁牛：人工智能的历史、现状和未来## 2019-02-18求是\n【字体：大中小】![] \n语音播报![] \n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。**概念与历程**\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n**现状与影响**\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，', 'doi': '', 'published_date': '2019-02-18T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cas.cn/zjs/201902/t20190218_4679625.shtml', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '中国人工智能学会', 'authors': [], 'abstract': '中国人工智能学会\n[![办公系统] 办公系统] \n[会员登录] |[会员注册] |[联系我们] |[English] \n[![中国人工智能学会]] \n* [首页] \n* [关于CAAI] \n* [CAAI简介] \n* [学会章程] \n* [条例与法规] \n* [主要领导] \n* [组织机构] \n* [分支机构] \n* [地方学会] \n* [服务矩阵] \n* [新闻动态] \n* [时政要闻] \n* [科协头条] \n* [学会新闻] \n* [通知公告] \n* [活动预告] \n* [学术资源] \n* [学会通讯] \n* [智能系统学报] \n* [CAAI TRIT] \n* [CAAI AIR] \n* [学科皮书系列] \n* [年鉴及发展报告] \n* [数字图书馆] \n* [会议系统] \n* [会员专区] \n* [学会会士] \n* [杰出会员] \n* [高级会员] \n* [会员荣誉] \n* [单位会员] \n* [党建强会] \n* [学会党建小组] \n* [重要讲话] \n* [党建强会] \n* [主题教育] \n* [二十大精神] \n* [思想体系] \n* [伟大精神] \n* [党史百科] \n* [学习书库] \n[![]] \n* [首页] \n* [关于CAAI] \n* [CAAI简介] \n* [学会章程] \n* [条例与法规] \n* [主要领导] \n* [组织机构] \n* [分支机构] \n* [地方学会] \n* [服务矩阵] \n* [新闻动态] \n* [时政要闻] \n* [科协头条] \n* [学会新闻] \n* [通知公告] \n* [活动预告] \n* [学术资源] \n* [学会通讯] \n* [智能系统学报] \n* [CAAI TRIT] \n* [CAAI AIR] \n* [学科皮书系列] \n* [年鉴及发展报告] \n* [数字图书馆] \n* [会议系统] \n* [会员专区] \n* [学会会士] \n* [杰出会员] \n* [高级会员] \n* [会员荣誉] \n* [单位会员] \n* [党建强会] \n* [学会党建小组] \n* [重要讲话] \n* [党建强会] \n* [主题教育] \n* [二十大精神] \n* [思想体系] \n* [伟大精神] \n* [党史百科] \n* [学习书库] \n[![中央八项精神]] \n[![2025年，“十四五”规划收官之年]] \n展开### [新闻公告] \n### 学会新闻[更多![]] \n[\n![] \n##### CAAI自主无人系统专委会换届工作会议顺利召开\n2026年1月16日，中国人工智能学会（CAAI）自主无人系统专委会（以下简称专委会）第六届委员换届会议在北京顺利召开。CAAI组织工委会委员、浙江大学刘哲教授代表学会主持和督导换届会议。第五届专委会主任孙长银教授，副主任贺威教授、王雅琳教授、宋士吉教授、刘允刚教授、葛泉波教授，秘书长余瑶副教授等120余人参加了本次换届会议。会议现场第五届专委会秘书长余瑶副教授作工作汇报，报告从组织学术活动、开展\n] \n* [\n•智能传媒技术发展大会在京举办2026-01-16] \n* [\n•第十届全国智能交互论坛在北京举行2026-01-13] \n* [\n•中国人工智能学会推荐的9场学术会议入选中国科协《重要学术会议指南（2025）》\n2026-01-07] \n* [\n•智汇常州，能动未来2026全国智能体开发者大会在常州召开\n2026-01-05] \n* [\n•CAAI自主无人系统专委会学术年会在杭州举办\n2026-01-04] \n### 通知公告[更多![]] \n* [\n01-222026\n##### 2026 CAAI-腾讯犀牛鸟研究计划AI Lab专项征集正式启动\n] \n* [\n01-142026\n##### 2025年度吴文俊人工智能科学技术奖初评通过项目公示（公示已结束）\n] \n* [\n01-062026\n##### 2025年CAAI-联想蓝天科研基金入选名单公示\n] \n* [\n12-092025\n##### 2025年度吴文俊人工智能科学技术奖形式审查结果公示\n] \n* [\n11-262025\n##### 中国人工智能学会教育工作委员会征集委员通知] \n* [\n•2026 CAAI-腾讯犀牛鸟研究计划AI Lab专项征集正式启动\n2026-01-22] \n* [\n•2025年度吴文俊人工智能科学技术奖初评通过项目公示（公示已结束）\n2026-01-14] \n* [\n•2025年CAAI-联想蓝天科研基金入选名单公示\n2026-01-06] \n* [\n•2025年度吴文俊人工智能科学技术奖形式审查结果公示\n2025-12-09] \n* [\n•中国人工智能学会教育工作委员会征集委员通知2025-11-26] \n### [服务矩阵] \n#### 会员服务咨询电话：010-62283918\n[个人会员注册] [单位会员注册] [个人会籍查询] [单位会员名录] [个人会员缴费通知] [单位会员缴费通知] \n#### 成果奖励咨询电话：010-82158857，010-82158859\n[成果鉴定服务] [吴文俊奖提名] [激励计划提名] \n#### 学术基金咨询电话：010-82158821\n[CAAI-昇思学术基金] [CAAI-昇腾学术基金] [CAAI-蚂蚁科研基金] [CAAI-联想蓝天科研基金] [CAAI-波色量子创新基金] \n#### 学会出版物咨询电话：010-62283919\n[中国人工智能学会通讯] [CAAI Trans.on IT] [智能系统学报] [CAAl AI Research] [CAAI系列白皮书] \n#### 算力平台咨询电话：010-82158821\n[CAAI-华为算力平台] [CAAI-英博数科算力平台] \n### [学会活动] \n#### 重要活动[进入会议系统查看更多![]] \n* {{ formatDate(item.start\\_time) }}{{ formatYear(item.start\\_time) }}\n##### {{ item.fair\\_name }}\n地址：{{ item.city }}|时间：{{ formatDateRange(item.start\\_time, item.end\\_time) }}\n[![]] \n### [新闻动态] \n### 时政要闻[更多![]] \n[\n![习近平在省部级主要领导干部学习贯彻党的二十届四中全会精神专题研讨班开班式上发表重要讲话] \n##### 习近平在省部级主要领导干部学习贯彻党的二十届四中全会精神专题研讨班开班式上发表重要讲话省部级主要领导干部学习贯彻党的二十届四中全会精神专题研讨班20日上午在中央党校（国家行政学院）开班。中共中央总书记、国家主席、中央军委主席习近平在开班式上发表重要讲话强调，要把学习贯彻党的二十届四中全会精神不断引向深入，更好统一思想、凝心聚力，在党中央坚强领导下扎实做好各项工作，努力实现“十五五”良好开局。\n] \n* [\n•习近平会见加拿大总理卡尼2026-01-16] \n* [\n•《求是》杂志发表习近平总书记重要文章《在中央城市工作会议上的讲话》2026-01-15] \n* [\n•中国共产党第二十届中央纪律检查委员会第五次全体会议公报2026-01-14] \n* [\n•习近平在二十届中央纪委五次全会上发表重要讲话2026-01-13] \n### 科协头条[更多![]] \n[\n![拥抱大有作为的黄金时代——中国科学技术协会二〇二六年新年贺词] \n##### 拥抱大有作为的黄金时代——中国科学技术协会二〇二六年新年贺词拥抱大有作为的黄金时代——中国科学技术协会二〇二六年新年贺词] \n* [\n•贺军科在吉林调研科协工作2025-12-25] \n* [\n•中国科协党组理论学习中心组专题学习习近平外交思想2025-12-22] \n* [\n•中国科协党组传达学习中央经济工作会议精神2025-12-12] \n* [\n•中国科协党组理论中心组专题学习研讨党的二十届四中全会精神2025-11-29] \n### [党建强会] \n \n### 重要讲话[更多![]] \n[\n![习近平：推进党的自我革命要做到“五个进一步到位”] \n##### 习近平：推进党的自我革命要做到“五个进一步到位”推进党的自我革命要做到“五个进一步到位”习近平\u3000\u3000在“七一”即将到来之际，中央政治局以健全落实中央八项规定精神、纠治“四风”长效机制为主题进行集体学习，既是推进全党深入贯彻中央八项规定精神学习教育的一项工作安排，也是庆祝党的生日的一次重要活动。我代表党中央，向全国广大共产党员致以节日的问候！\u3000\u3000中央八项规定是党中央徙木立信之举，是新时代管党治党的标志性措施。党的十八大以来，党中央以八项规定开局破题] \n* [\n•习近平：健全网络生态治理长效机制持续营造风清气正的网络空间2025-11-29] \n* [\n•习近平：大力弘扬志愿精神传递真善美传播正能量为强国建设民族复兴伟业贡献志愿服务力量2025-11-28] \n* [\n•习近平：在纪念胡耀邦同志诞辰110周年座谈会上的讲话\n2025-11-20] \n* [\n•习近平：坚持党的领导人民当家作主依法治国有机统一合力开创法治中国建设新局面2025-11-18] \n### 党建强会[更多![]] \n[\n![习近平在中共中央政治局第二十三次集体学习时强调 健全网络生态治理长效机制持续营造风清气正的网络空间] \n##### 习近平在中共中央政治局第二十三次集体学习时强调健全网络生态治理长效机制持续营造风清气正的网络空间中共中央政治局11月28日下午就加强网络生态治理进行第二十三次集体学习。中共中央总书记习近平在主持学习时强调，网络生态治理是网络强国建设的重要任务，事关国家发展和安全，事关人民群众切身利益。要健全网络生态治理长效机制，着力提升治理的前瞻性、精准性、系统性、协同性，持续营造风清气正的网络空间。中国政法大学教授时建中同志就这个问题进行讲解，提出工作建议。中央政治局的同志认真听取讲解，并进行\n] \n* [\n•实现高水平科技自立自强是中国式现代化建设的关键2025-12-01] \n* [\n•因地制宜发展新质生产力，需把握这些基本要求2025-11-25] \n* [\n•以韧劲钻劲恒劲擦亮作风建设“金色名片”2025-11-24] \n* [\n•新质生产力“新”在何处？2025-11-20] \n### [学会出版物] \n[\n![学会通讯] \n学会通讯] \n[\n![智能系统学报] \n智能系统学报] \n[\n![CAAI TRIT] \nCAAI TRIT\n] \n[\n![CAAI AIR] \nCAAI AIR\n] \n[\n![学科皮书系列] \n学科皮书系列] \n[\n![年鉴及发展报告] \n年鉴及发展报告] \n[\n![数字图书馆] \n数字图书馆] \n党政机关科协* [中国政府网] \n* [民政部] \n* [工业和信息化部] \n* [科技部] \n* [国家发改委] \n* [农业农村部] \n* [人力资源部] \n* [中国科学院] \n* [中国科学技术协会] \n* [中国工程院] \n* [共产党员网] \n* [党史学习教育官网] \n地方学会* [安徽省人工智能学会] \n* [海南省人工智能学会] \n* [吉林省人工智能学会] \n* [广西人工智能学会] \n* [黑龙江省人工智能学会] \n* [江苏省人工智能学会] \n* [重庆市人工智能学会] \n* [福建省人工智能学会] \n* [河南省人工智能学会] \n* [湖北省人工智能学会] \n* [湖南省人工智能学会] \n* [山东省人工智能学会] \n* [天津市人工智能学会] \n* [浙江省人工智能学会] \n* [深圳市人工智能学会] \n* [日照市人工智能学会] \n* [香港人工智能与机器人学会] \n* [内蒙古自治区人工智能学会] \n兄弟学会* [中国机械工程学会] \n* [中国仪器仪表学会] \n* [中国汽车工程学会] \n* [中国电工技术学会] \n* [中国电子学会] \n* [中国自动化学会] \n* [中国农业机械学会] \n* [中国微米纳米技术学会] \n* [中国光学工程学会] \n* [中国纺织工程学会] \n* [中国宇航学会] \n* [中国造船工程学会] \n* [中国计量测试学会] \n国际组织* [ACM] \n* [IEEE] \n* [AAAI] \n* [IJCAI] \n常务理事单位* [安谋科技（中国）有限公司] \n* [百度公司] \n* [北京三快在线科技有限公司] \n* [河海大学] \n* [华为技术有限公司] \n* [科大讯飞股份有限公司] \n* [高新兴科技集团股份有限公司] \n* [南京金盾公共安全技术研究院有限公司] \n* [360政企安全集团] \n* [武汉华工智云科技有限公司] \n* [新浪网技术（中国）有限公司] \n* [中国第一汽车股份有限公司] \n* [中兴通讯股份有限公司] \n* [蚂蚁科技集团股份有限公司] \n* [武汉数字化设计与制造创新中心有限公司] \n理事单位* [海信集团有限公司] \n* [平安科技（深圳）有限公司] \n* [东声（苏州）智能科技有限公司] \n* [北京富通东方科技有限公司] \n* [联想（北京）有限公司] \n* [四川长虹电器股份有限公司] \n* [医渡云（北京）技术有限公司] \n* [北方华创科技集团股份有限公司] \n* [北京飞象星球科技有限公司] \n* [易显智能科技有限责任公司] \n* [联通（广东）产业互联网有限公司] \n会员服务* [学会智库] \n* [数字图书馆] \n* [会员注册] \n* [个人会员会费说明] \n* [单位会员会费说明] \n* [分支活动申请表] \n高校机构* [清华大学] \n* [北京大学] \n* [浙江大学] \n* [复旦大学] \n* [北京邮电大学] \n[联系我们] |[网站地图] |[站长统计] \n地址：北京市海淀区西土城路10号 邮编：100876\n[] \nCopyright ©2026 中国人工智能学会互联网ICP备案：[京ICP备06029423号-1]![] [京公网安备11010802045678号] \n技术支持：[中科服] 15701507260\n[![] 媒体平台\n![媒体平台-官微号]![媒体平台-抖音号]![媒体平台-头条号] \n] [![常见问题] 常见问题] [![] 返回顶部] \n### 你知道你的Internet Explorer是过时了吗?\n为了得到我们网站最好的体验效果,我们建议您升级到最新版本的Internet Explorer或选择另一个web浏览器.一个列表最流行的web浏览器在下面可以找到.\n[] [] [] [] []', 'doi': '', 'published_date': '2025-06-05T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.caai.cn/index.php?s=%2Fhome%2Farticle%2Fdetail%2Fid%2F1278.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '谭铁牛：人工智能的历史、现状和未来----中国科学院科技战略咨询研究院', 'authors': [], 'abstract': '现在位置： [首页] \xa0>\xa0[科学传播] \xa0>\xa0[人物风采] \n\n## 谭铁牛：人工智能的历史、现状和未来\n\n作者：谭铁牛2019-03-27 10:43来源：求是\n\n【放大缩小】\n\n\xa0\xa0\xa0 如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。\n\n**概念与历程**\n\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。\n\n人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n\n**现状与影响**\n\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n\n专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n\n通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n\n人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。\n\n**趋势与展望**\n\n经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n\n从专用智能向通用智能发展。如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n从人工智能向人机混合智能发展。借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。\n\n从“人工+智能”向自主智能系统发展。当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。\n\n人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。\n\n人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。\n\n人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n人工智能领域的国际竞争将日益激烈。当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n人工智能的社会学将提上议程。为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。\n\n**态势与思考**\n\n当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n高度重视。党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n态势喜人。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。\n\n差距不小。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n\n前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。\n\n树立理性务实的发展理念。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n重视固本强基的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n构建自主可控的创新生态。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。\n\n推动共担共享的全球治理。目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。\n\n（作者：中央人民政府驻香港特别行政区联络办公室副主任、中国科学院院士）', 'doi': '', 'published_date': '2019-03-27T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.casisd.cas.cn/kxcb/kpzs/201903/t20190327_5262266.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '002_具身人工智能的历史演进与关键里程碑：从理论构想到实际应用', 'authors': [], 'abstract': '002\\_具身人工智能的历史演进与关键里程碑：从理论构想到实际应用-腾讯云开发者社区-腾讯云\n[] \n[安全风信子] \n## 002\\_具身人工智能的历史演进与关键里程碑：从理论构想到实际应用\n**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布安全风信子**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;002\\_具身人工智能的历史演进与关键里程碑：从理论构想到实际应用\n# 002\\_具身人工智能的历史演进与关键里程碑：从理论构想到实际应用\n![作者头像] \n安全风信子**关注\n发布于2025-11-18 18:42:14\n发布于2025-11-18 18:42:14\n2930\n举报**文章被收录于专栏：[AI SPPECH] AI SPPECH\n#### 1. 具身AI的思想萌芽（1940s-1970s）\n具身人工智能的发展可以追溯到人工智能学科的早期阶段，尽管当时还没有明确提出&quot;具身&quot;的概念，但一些先驱者已经开始思考智能与物理实体的关系。\n##### 1.1 早期人工智能的局限性第一代人工智能（1940s-1970s）主要关注符号主义方法，试图通过形式逻辑和符号操作来模拟智能。这一时期的代表成果包括：\n1. **图灵测试**（1950年）：Alan Turing提出的判断机器是否具有智能的测试方法\n2. **通用问题求解器**（1957年）：Herbert Simon和Allen Newell开发的模拟人类问题解决能力的程序\n3. **专家系统**：基于规则的知识表示系统，如DENDRAL（1965年）\n然而，这些早期AI系统主要是纯软件程序，缺乏与物理世界的直接互动能力，因此在处理感知、行动和适应复杂环境等方面存在严重局限性。\n##### 1.2 机器人技术的早期发展与早期AI并行发展的是机器人技术，这为后来的具身AI奠定了物理基础：\n1. **Unimate工业机器人**（1959年）：George Devol和Joseph Engelberger开发的第一台工业机器人\n2. **Shakey机器人**（1966-1972年）：由斯坦福研究所开发，是第一个结合了感知、规划和行动能力的移动机器人\n3. **WABOT-1**（1973年）：日本早稻田大学开发的第一台人形机器人\nShakey机器人被认为是具身AI的早期尝试，它能够通过摄像头感知环境，使用简单的规划算法，然后通过电机驱动执行动作。尽管功能有限，但它展示了将AI能力嵌入物理实体的可能性。\n##### 1.3 控制论的影响控制论（Cybernetics）对具身AI的发展产生了深远影响：\n1. **诺伯特·维纳的控制论**（1948年）：提出了通过反馈机制控制系统的理论\n2. **自适应控制系统**：能够根据环境变化调整行为的控制系统\n3. **生物控制论**：研究生物系统中的控制和通信机制\n控制论强调系统与环境的互动以及反馈机制的重要性，这些思想后来成为具身AI的核心原则之一。\n代码语言：javascript\n复制```\n`timeline\ntitle 具身AI思想萌芽时期关键事件\n1943 : McCulloch和Pitts提出神经元模型\n1948 : 诺伯特·维纳发表《控制论》1950 : 图灵发表《计算机器与智能》1956 : 达特茅斯会议，AI正式诞生\n1959 : Unimate工业机器人诞生\n1966 : Shakey机器人项目启动\n1973 : WABOT-1人形机器人开发完成`\n```\n#### 2. 具身认知理论的兴起（1980s-1990s）\n1980年代，随着对早期AI局限性的认识加深，研究者开始从认知科学的角度重新思考智能的本质，具身认知理论逐渐兴起，为具身AI提供了重要的理论基础。\n##### 2.1 具身认知理论的核心观点具身认知理论挑战了传统的认知主义观点，认为：1. **身体在认知中的作用**：认知过程不仅仅发生在大脑中，而是与身体结构和感官体验密切相关\n2. **情境嵌入性**：认知活动嵌入在特定的环境和情境中\n3. **动态生成性**：认知是大脑、身体和环境互动的动态生成过程\n这一理论的代表人物包括：* **Andy Clark**：提出了&quot;延展心智&quot;（Extended Mind）理论\n* **Alva Noë**：强调感知是一种行动能力\n* **Merleau-Ponty**：现象学哲学家，其思想对具身认知产生了重要影响##### 2.2 从符号主义到具身智能1980年代，AI研究出现了范式转变，从传统的符号主义方法转向更注重感知和行动的具身方法：\n1. **Rodney Brooks的包容架构**（1986年）：提出了基于行为的机器人控制架构，强调直接的感知-行动连接\n2. **&quot;No Reason to Represent&quot;论文**（1991年）：Brooks质疑了传统AI中符号表示的必要性\n3. **行为主义机器人学**：强调通过简单行为的组合产生复杂行为\n这一时期的代表性机器人包括：* **Allen和Herbert**（1984年）：MIT开发的办公室递送机器人\n* **Genghis**（1989年）：Brooks开发的六足步行机器人\n* **COG**（1993年）：MIT的人形机器人项目，旨在研究具身智能##### 2.3 进化机器人学的诞生进化机器人学（Evolutionary Robotics）结合了进化计算和机器人学，为具身AI提供了新的研究方向：\n1. **Hod Lipson的可进化机器人**：能够通过进化过程自我设计和改进\n2. **人工生命研究**：模拟生命系统的自组织和适应能力\n3. **模拟到现实的迁移**：在虚拟环境中进化的控制器迁移到物理机器人\n进化机器人学强调适应性和自组织，这些特性对于具身AI系统在复杂环境中的生存和发展至关重要。\n![] \n#### 3. 计算智能与机器人技术的融合（2000s-2010s）\n2000年代至2010年代，随着计算能力的提升和机器学习技术的发展，具身AI进入了计算智能与机器人技术深度融合的阶段。\n##### 3.1 机器学习在具身AI中的应用\n机器学习技术，特别是强化学习，为具身AI提供了强大的学习能力：\n1. **强化学习在机器人控制中的应用**：通过与环境互动学习最优策略\n2. **模仿学习**：从人类示范中学习技能\n3. **多任务学习**：一个模型学习执行多种任务\n这一时期的代表性成果包括：* **OpenAI Gym**（2016年）：为强化学习研究提供标准化环境\n* **Google DeepMind的AlphaGo**（2016年）：展示了深度学习在复杂决策中的能力\n* **Boston Dynamics的Atlas机器人**（2013年）：具有高度动态平衡和操作能力##### 3.2 多模态感知系统的发展具身AI系统的感知能力在这一时期得到了显著提升：\n1. **计算机视觉的突破**：卷积神经网络（CNN）在物体识别、场景理解等任务中取得成功\n2. **多传感器融合技术**：结合视觉、激光雷达、超声波等多种传感器信息\n3. **三维重建技术**：构建环境的三维模型\n代表性技术包括：* **Kinect深度相机**（2010年）：提供实时三维感知能力\n* **SLAM技术**（同步定位与地图构建）：如ORB-SLAM（2015年）\n* **PointNet**（2017年）：处理点云数据的深度学习架构##### 3.3 人机交互技术的进步人机交互技术的进步使具身AI系统能够更好地与人类协作：\n1. **自然语言处理**：使机器人能够理解和生成自然语言\n2. **手势识别**：识别人类手势命令\n3. **情感计算**：识别和响应人类情感\n代表性系统包括：* **Siri**（2011年）：苹果的语音助手，展示了自然语言交互的潜力\n* **NAO机器人**（2006年）：能够与人类进行简单交互的人形机器人\n* **Jibo**（2014年）：社交机器人，强调与人类的情感连接\n代码语言：javascript\n复制```\n`# 强化学习在机器人控制中的应用示例import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport gym\nclass DQNAgent:\ndef \\_\\_init\\_\\_(self, state\\_size, action\\_size):\nself.state\\_size = state\\_size\nself.action\\_size = action\\_size\nself.memory = []\nself.gamma = 0.95 # 折扣因子self.epsilon = 1.0 # 探索率self.epsilon\\_min = 0.01\nself.epsilon\\_decay = 0.995\nself.learning\\_rate = 0.001\nself.model = self.\\_build\\_model()\nself.target\\_model = self.\\_build\\_model()\nself.update\\_target\\_model()\ndef \\_build\\_model(self):\n# 构建Q网络模型\nmodel = models.Sequential()\nmodel.add(layers.Dense(24, input\\_dim=self.state\\_size, activation=&#x27;&#x27;relu&#x27;&#x27;))\nmodel.add(layers.Dense(24, activation=&#x27;&#x27;relu&#x27;&#x27;))\nmodel.add(layers.Dense(self.action\\_size, activation=&#x27;&#x27;linear&#x27;&#x27;))\nmodel.compile(loss=&#x27;&#x27;mse&#x27;&#x27;, optimizer=tf.keras.optimizers.Adam(lr=self.learning\\_rate))\nreturn model\ndef update\\_target\\_model(self):\n# 更新目标网络self.target\\_model.set\\_weights(self.model.get\\_weights())\ndef remember(self, state, action, reward, next\\_state, done):\n# 存储经验self.memory.append((state, action, reward, next\\_state, done))\ndef act(self, state):\n# 选择动作（ε-贪婪策略）\nif np.random.rand() &lt;&lt;= self.epsilon:\nreturn random.randrange(self.action\\_size)\nact\\_values = self.model.predict(state)\nreturn np.argmax(act\\_values[0]) # 返回Q值最大的动作\ndef replay(self, batch\\_size):\n# 经验回放学习minibatch = random.sample(self.memory, batch\\_size)\nfor state, action, reward, next\\_state, done in minibatch:\ntarget = reward\nif not done:\n# 使用目标网络计算Q值\ntarget = reward + self.gamma \\* np.amax(self.target\\_model.predict(next\\_state)[0])\ntarget\\_f = self.model.predict(state)\ntarget\\_f[0][action] = target\n# 训练主网络self.model.fit(state, target\\_f, epochs=1, verbose=0)\nif self.epsilon &gt;&gt; self.epsilon\\_min:\nself.epsilon \\*= self.epsilon\\_decay\n# 主函数示例（以CartPole环境为例）\nimport random\ndef train\\_agent(episodes=1000, batch\\_size=32):\nenv = gym.make(&#x27;&#x27;CartPole-v1&#x27;&#x27;)\nstate\\_size = env.observation\\_space.shape[0]\naction\\_size = env.action\\_space.n\nagent = DQNAgent(state\\_size, action\\_size)\nfor e in range(episodes):\nstate = env.reset()\nstate = np.reshape(state, [1, state\\_size])\nfor time in range(500):\n# 选择动作action = agent.act(state)\n# 执行动作next\\_state, reward, done, \\_ = env.step(action)\nreward = reward if not done else -10 # 失败时给予惩罚next\\_state = np.reshape(next\\_state, [1, state\\_size])\n# 存储经验agent.remember(state, action, reward, next\\_state, done)\nstate = next\\_state\nif done:\nprint(f&quot;&quot;回合: {e}/{episodes}, 分数: {time}, 探索率: {agent.epsilon:.2}&quot;&quot;)\nbreak\n# 经验回放if len(agent.memory) &gt;&gt; batch\\_size:\nagent.replay(batch\\_size)\n# 每100回合更新目标网络\nif e % 100 == 0:\nagent.update\\_target\\_model()\n# 保存模型agent.model.save(&quot;&quot;dqn\\_cartpole\\_model.h5&quot;&quot;)\nreturn agent\n# 训练机器人控制策略def train\\_robot\\_control():\n# 在实际应用中，这里会替换为真实机器人的状态和动作空间# 例如，使用ROS接口与物理机器人交互\nprint(&quot;&quot;训练机器人控制策略...&quot;&quot;)\n# 以下为示例代码框架# 1. 初始化机器人接口# robot\\_interface = RobotInterface()\n# 2. 定义状态和动作空间# state\\_size = 机器人状态维度# action\\_size = 机器人动作维度# 3. 初始化DQN代理\n# agent = DQNAgent(state\\_size, action\\_size)\n# 4. 训练循环# for episode in range(num\\_episodes):\n# state = robot\\_interface.reset()\n# total\\_reward = 0\n# for step in range(max\\_steps):\n# action = agent.act(state)\n# next\\_state, reward, done = robot\\_interface.step(action)\n# agent.remember(state, action, reward, next\\_state, done)\n# state = next\\_state\n# total\\_reward += reward\n# if done:\n# break\n# if len(agent.memory) &gt;&gt; batch\\_size:\n# agent.replay(batch\\_size)\nprint(&quot;&quot;机器人控制策略训练框架示例&quot;&quot;)\nif \\_\\_name\\_\\_ == &quot;&quot;\\_\\_main\\_\\_&quot;&quot;:\n# 训练CartPole示例\n# agent = train\\_agent(episodes=1000, batch\\_size=32)\n# 展示机器人控制训练框架train\\_robot\\_control()`\n```\n#### 4. 深度学习时代的具身AI（2010s至今）\n2010年代以来，随着深度学习技术的突破，具身AI进入了快速发展阶段，在感知、决策和行动能力方面取得了显著进步。\n##### 4.1 深度学习对具身AI的推动\n深度学习技术为具身AI带来了革命性变化：\n1. **深度强化学习**：结合深度学习和强化学习，能够从高维原始数据中学习控制策略\n2. **迁移学习**：将在一个任务上学到的知识迁移到新任务\n3. **元学习**：学习如何学习，使系统能够快速适应新环境\n代表性成果包括：* **DQN算法**（2015年）：DeepMind的深度Q网络，将深度学习应用于强化学习\n* **AlphaGo Zero**（2017年）：完全通过自我对弈学习围棋\n* **OpenAI Five**（2018年）：能够在Dota 2游戏中击败职业选手的AI系统##### 4.2 感知能力的飞跃深度学习极大提升了具身AI的感知能力：\n1. **图像识别技术**：如ResNet（2015年）在图像分类任务中取得突破性进展\n2. **目标检测算法**：如YOLO系列（2016年起）提供实时目标检测能力\n3. **语义分割**：如U-Net（2015年）能够精确分割图像中的对象\n这些技术使具身AI系统能够更准确地理解周围环境，为决策和行动提供可靠的输入。\n##### 4.3 机器人操作与灵巧性的提升在机器人操作和灵巧性方面，具身AI也取得了显著进展：\n1. **抓取学习**：通过深度学习学习物体抓取策略\n2. **操作技能迁移**：将虚拟环境中学到的技能迁移到物理机器人\n3. **多模态操作**：结合视觉、触觉等多种感知模态进行操作\n代表性研究包括：* **Google的Robotics Transformer**（2022年）：结合Transformer架构和机器人控制\n* **OpenAI的Dactyl**（2018年）：能够灵巧操作物体的机器人手\n* **Boston Dynamics的Pick and Place系统**（2020年）：展示了高精度物体操作能力##### 4.4 多智能体系统与协作多智能体系统研究使多个具身AI能够协作完成复杂任务：\n1. **分布式感知与决策**：多个智能体共同感知环境并做出决策\n2. **协作任务分配**：合理分配任务以提高整体效率\n3. **社交智能**：智能体之间的有效沟通和协作\n代表性系统包括：* **Swarm Robotics**：模仿昆虫群体行为的机器人集群\n* **MIT的RACECAR平台**（2017年）：用于多智能体协同研究\n* **OpenAI的Coordinated Reinforcement Learning**（2019年）：多智能体强化学习研究\n![] \n#### 5. 2025年具身AI的前沿发展\n2025年，具身AI技术已经达到了新的高度，在多个前沿领域取得了突破性进展。\n##### 5.1 神经形态计算的应用神经形态计算技术为具身AI带来了能效和认知能力的双重提升：\n1. **低功耗边缘计算**：神经形态芯片如Intel Loihi 2提供极高的能效比\n2. **实时处理能力**：毫秒级响应时间，满足实时控制需求\n3. **自学习能力**：硬件层面支持在线学习和适应\n神经形态计算在具身AI中的应用案例：\n* **自适应机器人控制系统**：根据环境变化自动调整控制参数\n* **实时异常检测**：在边缘设备上实现高性能异常行为识别\n* **低功耗持久任务**：长续航的环境监测和巡逻任务##### 5.2 量子安全技术在具身AI中的应用\n量子安全技术为具身AI系统提供了更高级别的安全保障：\n1. **量子密钥分发**：确保通信安全，防止窃听\n2. **量子随机数生成**：提供真正的随机数，增强加密强度\n3. **后量子密码学**：抵抗量子计算攻击的加密算法\n这些技术在关键领域的具身AI系统中得到应用，如医疗机器人、自动驾驶汽车和工业控制系统。\n##### 5.3 可解释AI与安全验证\n2025年，具身AI系统在可解释性和安全验证方面取得了重要进展：\n1. **可解释AI技术**：使AI决策过程更加透明和可理解\n2. **形式化验证方法**：数学证明AI系统的安全属性\n3. **安全约束学习**：在学习过程中内置安全约束\n这些技术对于高风险应用场景中的具身AI系统至关重要，能够确保系统在各种情况下都能安全可靠地运行。\n##### 5.4 零信任安全架构在具身AI中的实施\n零信任安全架构已经成为具身AI系统的安全标准：\n1. **持续身份验证**：对所有访问请求进行持续验证\n2. **最小权限原则**：严格限制每个组件的权限范围\n3. **微分段**：网络微分段，限制横向移动\n4. **实时监控与响应**：持续监控系统行为，及时响应安全事件\n零信任架构特别适合具身AI系统的复杂网络环境，能够有效防御各种高级威胁。\n代码语言：javascript\n复制```\n`# 零信任安全架构在具身AI系统中的应用示例\nimport hashlib\nimport time\nimport json\nfrom cryptography.fernet import Fernet\nclass ZeroTrustSecurityManager:\ndef \\_\\_init\\_\\_(self):\n# 初始化安全管理器self.key = Fernet.generate\\_key()\nself.cipher = Fernet(self.key)\nself.access\\_control\\_policies = {}\nself.authentication\\_logs = []\nself.activity\\_monitor = {}\ndef register\\_component(self, component\\_id, component\\_type, required\\_privileges):\n&quot;&quot;&quot;&quot;&quot;&quot;注册具身AI系统组件&quot;&quot;&quot;&quot;', 'doi': '', 'published_date': '2026-02-03T13:24:12.280931', 'pdf_url': '', 'url': 'https://cloud.tencent.com.cn/developer/article/2590590', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能简史-腾讯云开发者社区-腾讯云', 'authors': [], 'abstract': '人工智能简史-腾讯云开发者社区-腾讯云\n[] \n[用户9624935] \n## 人工智能简史**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布用户9624935\n**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;人工智能简史\n# 人工智能简史![作者头像] \n用户9624935\n**关注\n发布于2022-04-02 14:58:47\n发布于2022-04-02 14:58:47\n2.2K0\n举报**文章被收录于专栏：[凯云实验室] 凯云实验室\n![] \nArtificial Intelligence (AI)，是在1956年的达特茅斯会议上提出来的，标志着人工智能这一学科的诞生。\n从1956年到2016年，刚好是60年。在过去的60年里，人工智能经历了三个阶段：\n* 二十世纪五十年代到七十年代：推理期，其出发点是，数学家真聪明。让计算机具有逻辑推理能力：为什么仅有逻辑推理能力不能实现人工智能？困难在哪里？* 二十世纪七十年代中期开始：知识期，其出发点是，知识就是力量。让计算机具有知识：由人把知识总结出来，再教给计算机——这是相当困难的。* 二十世纪九十年代到现在：学习期，其出发点是，让系统自己学。同时，也催生了人工智能的三大派别：* 符号主义：主要内容是关于符号计算、演算和逻辑推理，用演算和推理的办法来证明。比如说像机器证明就是符号主义。* 连接主义：目前非常流行的神经网络、神经元网络、深度学习，这些都是连接主义。* 行为主义：行为主义其实是从控制论衍生出来的，目前提及较少，但不能忽略。> 作者注：关于学派的分法，《终极算法》一书分为五类：符号学派，联结学派，进化学派，贝叶斯学派和类推学派。人工智能的三个派别和三个阶段并没有对应和界限，三个派别是在三个阶段的交织中发展起来的。著名信息论和人工智能专家钟义信在《弘扬Simon的源头创新精神，开拓AI的新理念新路径》报告中指出三大学派的的出现是一直以来还原论把复杂的系统分而治之研究的结果。因为整体上解决智能问题在物理和数学上都存在巨大的困难，所以在模仿大脑的功能研究上，出现了符号主义；在模仿大脑结构的研究上，出现了连接主义，在模仿人类行为的研究上（什么样的环境刺激会产生什么样的行为反应），出现了行为主义。\n> 作者注：看待人工智能的历史，要把人工智能的历史和神经网路的历史稍微区分一下，不能把神经网络的历史看作是人工智能的历史。所以本文不单独列举神经网络的发展历史和重大事件，留在下一篇文章中探讨。人工智能发展的过程中，经历了三次大事件，这些大事件导致了人工智能的发展进入三次低谷，被称为&quot;AI winter&quot;：\n* 1973年，英国发表了James Lighthill报告，批评人工智能研究进展令人失望，建议取消机器人的研究。为了回应批评和国会的压力，美国和英国政府停止了人工智能研究的资助。\n* 1992年，日本智能（第五代）计算机的研制宣告失败。这次失败有一个收获，是在潘云鹤《人工智能走向2.0》一文指出的，这次失败表明：驱动人工智能的发展主要靠创新的知识和软件，硬件的作用是支持其运行。\n* 在80年代，也诞生了cyc项目，一个包含所有人类常识的数据库。该项目随着互联网搜索引擎的崛起而衰败。潘云鹤在《人工智能走向2.0》指出：海量知识不能靠专家人工表达，要从环境中自动学习。也就是周志华指出的：由人把知识总结出来，再教给计算机——这是相当困难的。\n在过去的60年里，人工智能领域共有8位科学家成为图领奖得主：\n* 1969，Marvin Minsky：奖励他在创造，塑造，推动和加速人工智能这一领域的核心作用。\n* 1971，John McCarthy：麦卡锡的讲座《人工智能的研究现状》概括了他在人工智能领域的成就，也概括了值得奖励的原因。\n* 1975，Allen Newell and Herbert A. Simon：奖励他们在二十多年的联合科学工作中，最初与兰德公司的JC Shaw合作，随后与卡内基梅隆大学的众多教师和学生同事合作，对人工智能，人类认知心理学和列表处理方面做出的基础贡献。\n* 1994，Edward Feigenbaum and Raj Reddy：奖励他们在开创了大规模人工智能系统的设计和建造，展示了人工智能技术的实际重要性和潜在的商业影响。\n* 2010，Leslie G. Valiant：奖励他对于计算理论的变革性贡献，包括可能近似正确（PAC）学习的理论，枚举和代数计算的复杂性以及并行和分布式计算的理论。\n* 2011，Judea Pearl：奖励他对人工智能的基础贡献：概率和因果推理的微积分。\n上面这8位科学家，Marvin Minsky是MIT教授，最早提出连接主义，后来发表的《Perceptrons》一书指出感知机无法处理异或问题，导致连接主义长时间陷入低谷。不过著名信息论和人工智能专家钟义信说，另一个方面来看，马文·明斯基指出这个问题以后，经过人们的研究，提出了所谓的多层感知机，我们只要增加一个顶层就可以极大地提高神经网络表达的能力，可以逼近任意的问题。所以这个事情又从它的负面走向了正面，产生了积极的效果。\nJohn McCarthy，Allen Newell， Herbert A. Simon、Edward Feigenbaum几位都是非常典型的符号主义代表，他们最早推动了机器证明、人工智能、通用人工智能机、知识工程的进步。\n> 作者注：值得一提的是Herbert A. Simon是美国卡内基－梅隆大学心理学教授，1978年诺贝尔奖金获得者（经济学）。1968-1972年任美国总统科学顾问、行为科学和人工智能的创始人之一。西蒙教授为科学界的知名学者，在企业管理、计算机设计和决策理论方面有所创见。\nRaj Reddy主要是做语音识别的，李开复、沈向阳的老师。\nLeslie G. Valiant的贡献是机器学习理论，Judea Pearl的贡献是概率计算和因果推理，高文院士说，他们的工作是未来人工智能的重点走向。\n以上从分别从三个时期，三大学派，三次大事件以及8位图领奖得主的角度，总结了人工智能的简史。以下是我的一些不成熟思考：\n第一，计算的本质与智能的本质。《类脑智能研究的回顾和展望》指出，现有人工智能系统通用性较差与其计算理论基础和系统设计原理有密不可分的关系。计算机的计算本质和基础架构是图灵机模型和冯诺伊曼体系结构，其共同的缺点是缺乏自适应性。图灵计算的本质是使用预定义的规则对一组输入符号进行处理，规则是限定的，输入也受限于预定义的形式。图灵机模型取决于人对物理世界的认知程度，因此人限定了机器描述问题，解决问题的程度。而冯诺伊曼体系结构是存储程序式计算，程序也是预先设定好的，无法根据外界的变化和需求的变化进行自我演化。总结来看，计算的本质可以用一个数学公式f(x)=y来表达，是问题求解的范畴。\n那智能的本质是什么？如何表达？著名信息论和人工智能专家钟义信给了一个探讨性的定义：智能一定是在环境的作用下，人跟环境相互作用，不断的去学习，不断的去进化，在这个过程当中展开了智能的活动。反之，如果没有这种主体跟客体的相互作用，如果一切都是十全十美，如果不需要做出任何的改进，那就不需要思考、不需要学习，也就不需要智能。所以，一定要在主体跟客体相互作用过程当中来考察智能才有意义。李衍达院士在《沿Simon 开拓下去》的报告中探讨了智能的功能与智能的机理问题，指出基因的层次没有鸿沟，人和所有生物的机理是相同的，区别的是进化：自动适应外界变化而优化自身结构的功能。而且人脑在进化过程里面通过DNA的改变，改变了神经元的连接，这个连接既记录了学习的结果，又优化了学习算法。既简化了所需要的元件，又节省了能耗，非常巧妙。\n> 智能路径：感知反应-&gt;条件反射（存储，记忆）-&gt;决策（意志、欲望和目的）\n第二，关于程序员转型。和第一个问题有关，我们都是学习图灵机模型和冯诺伊曼架构长大的，思维方式相对固定。深度学习今年非常火爆，程序员又要开始转型。关于转型，我注意到几个论调：* 转型深度学习，数学是首要的基础；* 转型深度学习，开始大量学习TensorFlow框架；\n* 大二大三优秀学生学习起来很快，有经验的程序员学习来很苦；以上我都不太认同，人类是万物之灵，遇到新问题，学习新东西，再正常不过的事情，何来转型之说？如果非要说有什么需要转变，我觉得是到思维方式的转变：* 数学只是工具，TensorFlow只是封装的平台，而深度学习是有理论瓶颈的，工程界一直以来轻视学术的思维定势需要改变了。国内程序员同时是科学家的太少了，科学家有点高，做个学者吧。感觉要做一个好的科学家，不只是研究技术，而是在研究哲学，研究一些物质的本质、规律，研究一些最基础的东西。\n* 大多数程序员都是“程序员”思维，这是软件工业化的结果。重接口，重输入，重交付，这是一种软件外包的思维。输入是什么？输出是什么？程序如何实现？这些都造成了思维懒惰的一代程序员，从来不去问为什么程序这么做。而深度学习恰恰是讨论程序为什么这么实现的问题，其输出是模型，是算法。这是程序员需要改变的思维方式。* 人工智能更强调创新，特别是源头创新。在这个领域，有大量的问题都是崭新的，需要采用一些数学理论，结合实际需求来探索。我们在学习机器学习理论和算法的时候，需要有意识的突破已有的认知，特别是图灵机模型和冯诺伊曼体系结构。第三，脑复杂？还是环境复杂？傅小兰在《Simon与认知科学研究》报告中提到了《分布式认知》，指出认知现象在认知主体和环境间分布的本质：认知既分布于个体内与个体间，也分布于媒介、环境、文化、社会和时间等之中（Cole &amp; Engestrom, 1993）。Herbert A. Simon 也指出，一个人，若视作行为系统，是很简单的。他的行为随时间而表现出的表面复杂性主要是他所处环境的复杂性的反映。人——或至少人的智力要素——也许是比较简单的，人的行为的复杂性也许大半来自人的环境，来自人对优秀设计的搜索，因此，“在相当大的程度上，要研究人类便要研究设计科学。它不仅是技术教育的专业要素，也是每个知书识字人的核心学科”。第四，从上而下还是从下而上？人工智能从上而下研究的开创者和代表人物是Herbert A. Simon，他当时想到，人的大脑活动是分层次的，在底层的机理没有搞清楚时，他认为也不妨碍对于高层概念、推理、问题求解层次进行研究。符号学派就是自上而下的典型代表，但至今符号学派一直受到自下而上的连接主义压制。自下而上的代表是日本的第五代计算机计划，东京大学元岗达教授提出“第五代计算机的构想”，随后日本制定了研制五代机的十年计划，总预算达4.3亿美元。以渊一博为所长的“新一代计算机技术研究所”苦苦奋战了近十年，他们几乎没有回过家，近乎玩命式的拼搏；然而，由于没有突破关键性技术难题，无法实现自然语言人机对话，程序自动生成等目标，最终于1992年宣告失败！这或许也是图灵机模型和冯诺伊曼架构的失败。然而，峰回路转，得益于分布式计算和大数据时代，深度学习成为主流的自下而上方法。近五年来，深度学习在“视”、“听”、“说”等领域取得了的巨大成功，但这还不能表明自下而上的胜利或者神经网络模型的正确。神经网络只是从下而上对大脑的粗糙模拟和抽象，是否是正确的大脑学习隐喻还不得而知。但神经网络的成功又引发了一些自下而上的尝试，据称IBM有一个名为“突触”的项目，研究芯片级类脑计算设备，支持低频率，低功耗，和大量链接等神经网络功能。\n第五，鲁棒性？可解释性？魔术性？这几个问题是现在机器学习，特别是深度学习面临的主要问题。人类犯错：水平从九段降到八段，机器犯错：水平从九段降到业余，这就是鲁棒性。鲁棒性要求，“好的时候”要好，“坏的时候”不能太坏。在封闭静态环境中，重要因素大多是“定”的，而在开放动态环境中，一切都是变的，开放环境的鲁棒性，这也是自动驾驶面临的困难所在。关于可解释性，也被称为深度学习的黑箱模型。若学习器不能给出治疗理由，则难以说服患者接受昂贵的治疗方案。若学习器不能给出停机检测的理由，则难以判断停机检测的风险和代价。这些案例都需要机器学习的模型给出解释，否则难以应用到难以用于高风险应用。而机器学习魔术性是指即便相同数据，普通用户很难获得机器学习专家级性能。就是专家之间，是特别考验团队实力的，也有一点运气在里面。门派都一样，功力不一般。第六，目前的研究热点和我的方向。深度学习是很火的，不过周志华说的很中肯：“深度学习中间还有很多困难而又重要的问题值得深入研究，但这些真正值得研究的问题，就我看到的情况而言，好像做的人非常少。大多数人在干什么呢？拿它做做应用，调调参数，性能刷几个点，然后发几篇文章。这样虽然容易发表文章，但恐怕很难产生有影响的成果。”另外，周志华在引领集成学习的发展方向，CCAI17可以看到一些方向，中国香港科技大学计算机系主任杨强谈到的迁移学习，日本理化学研究所杉山将谈到的弱监督机器学习等。我的计划是，从历史中观其大略；感知机，神经网络，反向传播，深度学习是一条线，已经是必备的基础了；然后向增强学习发力；在技术上打通分布式系统，大数据和机器学习；在业务和需求上结合金融场景。\n![] \n第七，已知和未知。我们参考神经生理学，研制了神经网络和深度学习，并且取得了良好的效果。有人指出，大脑的生物物理结构，机制和功能只是大脑处理信息过程中的印记，其中很少一部分可用于有意识的思想（认知）。在学习未知的过程中，我们对学习到底了解了多少？在未知的区域里，既有要学习的对象，也有学习本身。参考文献：《人工智能走向2.0》 潘云鹤《类脑智能研究的回顾与展望》曾毅等《脑启发计算》苏中《机器学习》序言陆汝钤《机器学习：发展与未来》周志华《H. A. Simon学术生平》林建祥\n《Simon的认知科学思想》傅小兰\n《人工智能--螺旋上升的60年》高文院士\n《沿Simon 开拓下去》李衍达《塞蒙终生学术经历简介》林建祥《人工智能的历史》中国人工智能学会《司马贺的创新之路》史忠植《弘扬Simon学术思想 》钟义信《探寻大师足迹，一览马文•明斯基学术风采》史忠植《站在巨人的肩膀上，从人工智能与认知商务》苏中《弘扬Simon的源头创新精神开拓“AI”的新理念新路径》钟义信\n《独家| 周志华：深度学习很有用，但过度追捧就有危险了》AI科技大本营\n本文参与[腾讯云自媒体同步曝光计划] ，分享自微信公众号。\n原始发表：2017-08-06，如有侵权请联系[cloudcommunity@tencent.com] 删除\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n本文分享自补天遗石微信公众号，前往查看如有侵权，请联系[cloudcommunity@tencent.com] 删除。\n本文参与[腾讯云自媒体同步曝光计划] ，欢迎热爱写作的你一起参与！\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n评论登录后参与评论0条评论\n热度最新登录后参与评论推荐阅读相关产品与服务人工智能与机器学习提供全球领先的人脸识别、文字识别、图像识别、语音技术、NLP、人工智能服务平台等多项人工智能技术，共享 AI 领域应用场景和解决方案。[**产品介绍] \n[**AI驱动 智领未来] \n领券* ### 社区* [技术文章] \n* [技术问答] \n* [技术沙龙] \n* [技术视频] \n* [学习中心] \n* [技术百科] \n* [技术专区] \n* ### 活动* [自媒体同步曝光计划] \n* [邀请作者入驻] \n* [自荐上首页] \n* [技术竞赛] \n* ### 圈层* [腾讯云最具价值专家] \n* [腾讯云架构师技术同盟] \n* [腾讯云创作之星] \n* [腾讯云TDP] \n* ### 关于* [社区规范] \n* [免责声明] \n* [联系我们] \n* [友情链接] \n* [MCP广场开源版权声明] \n### 腾讯云开发者![扫码关注腾讯云开发者] \n扫码关注腾讯云开发者领取腾讯云代金券### 热门产品* [域名注册] \n* [云服务器] \n* [区块链服务] \n* [消息队列] \n* [网络加速] \n* [云数据库] \n* [域名解析] \n* [云存储] \n* [视频直播] \n### 热门推荐* [人脸识别] \n* [腾讯会议] \n* [企业云] \n* [CDN加速] \n* [视频通话] \n* [图像分析] \n* [MySQL 数据库] \n* [SSL 证书] \n* [语音识别] \n### 更多推荐* [数据安全] \n* [负载均衡] \n* [短信] \n* [文字识别] \n* [云点播] \n* [大数据] \n* [小程序开发] \n* [网站监控] \n* [数据迁移] \nCopyright ©2013 -2026Tencent Cloud. All Rights Reserved. 腾讯云版权所有[深圳市腾讯计算机系统有限公司] ICP备案/许可证号：[粤B2-20090059]![] [粤公网安备44030502008569号] \n[腾讯云计算（北京）有限责任公司] 京ICP证150476号 |[京ICP备11018762号] \n[问题归档] [专栏文章] [快讯文章归档] [关键词归档] [开发者手册归档] [开发者手册 Section 归档] \nCopyright ©2013 -2026Tencent Cloud.\nAll Rights Reserved. 腾讯云版权所有登录后参与评论**\n**\n**\n000\n推', 'doi': '', 'published_date': '2022-04-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://cloud.tencent.com.cn/developer/article/1971641', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 13:24:41,755 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 13:24:41,757 - __main__ - INFO - handle_download: downloaded=9
2026-02-03 13:24:41,757 - __main__ - INFO - call_tool payload: source_tool=exa_context_download, result_type=papers, count=9
2026-02-03 13:24:41,757 - __main__ - INFO - call_tool: name=exa_context_download, result_type=papers, count=9
2026-02-03 13:24:41,757 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能历史 - IBM', 'authors': [], 'abstract': '人工智能历史 | IBM\n[Artificial Intelligence] \n# AI 的历史![高耸入云的摩天大楼尖顶] \n## 作者[Tim Mucci] \nIBM Writer\nGather\n## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。\nGPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;\n## 20 世纪以前### 1726\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。\n学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;\n“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”\n- Jonathan Swift 的《格列佛游记》(1726)\nSwift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。\n## 1900–1950\n### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。\n### 1921\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。\n### 1939\n爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。\n虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。\n与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。\n### 1950\n英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;\n图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n## 1950–1980\n### 1951\nMarvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952\n数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n### 1955\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。\n### 1958\nJohn McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959\nArthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n### 1965\n哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。\n### 1966\nShakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969\nArthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。\nMarvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。\n### 1970\nTerry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。\n### 1973\nJames Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000\n### 1980\nWABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。\n### 1982\n日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。\n### 1986\nDavid Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。\n这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987\n在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\nRollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\nMarvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。\n### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。\n### 1993\n科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。\n这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n### 1995\nRichard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;', 'doi': '', 'published_date': '2026-02-03T13:24:12.280159', 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'save_path': '/home/qinshan/widthresearch/data/downloads/exa_人工智能历史 - I.md'}}
2026-02-03 13:24:41,760 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': None}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来', 'authors': [], 'abstract': '[求是网首页](//www.qstheory.cn) | [网站地图](//www.qstheory.cn/sitemap/)\n\n# 人工智能的历史、现状和未来\n\n 来源：《求是》2019/04   作者：谭铁牛   2019-02-16 09:00:00 \n\n2018年2月25日，在平昌冬奥会闭幕式“北京8分钟”表演中，由沈阳新松机器人自动化股份有限公司研发的智能移动机器人与轮滑演员进行表演。 新华社记者 李钢/摄\n\n\u3000\u30002018年5月3日，中国科学院发布国内首款云端人工智能芯片，理论峰值速度达每秒128万亿次定点运算，达到世界先进水平。 新华社记者 金立旺/摄\n\n\u3000\u30002017年10月，在沙特阿拉伯首都利雅得举行的“未来投资倡议”大会上，机器人索菲亚被授予沙特公民身份，她也因此成为全球首个获得公民身份的机器人。图为2018年7月10日，在香港会展中心，机器人索菲亚亮相主舞台。 ISAAC LAWRENCE/视觉中国\n\n\u3000\u30002018年11月22日， 在“伟大的变革——庆祝改革开放40周年大型展览”上，第三代国产骨科手术机器人“天玑”正在模拟做手术，它是国际上首个适应症覆盖脊柱全节段和骨盆髋臼手术的骨科机器人，性能指标达到国际领先水平。 麦田/视觉中国\n\n\u3000\u3000如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。\n\n**概念与历程**\n\n\u3000\u3000了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n\n\u3000\u3000人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。\n\n\u3000\u3000人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n\n\u3000\u3000一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n\n\u3000\u3000二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n\n\u3000\u3000三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n\n\u3000\u3000四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n\u3000\u3000五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n\n\u3000\u3000六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n\n**现状与影响**\n\n\u3000\u3000对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n\n**专用人工智能取得重要突破。**从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n\n**通用人工智能尚处于起步阶段。**人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n**人工智能创新创业如火如荼。**全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n**创新生态布局成为人工智能产业发展的战略高地。**信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n\n**人工智能的社会影响日益凸显。**一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。\n\n**趋势与展望**\n\n\u3000\u3000经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n\n**从专用智能向通用智能发展。**如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n**从人工智能向人机混合智能发展。**借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。\n\n**从“人工+智能”向自主智能系统发展。**当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。\n\n**人工智能将加速与其他学科领域交叉渗透。**人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。\n\n**人工智能产业将蓬勃发展。**随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。\n\n**人工智能将推动人类进入普惠型智能社会。**“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n**人工智能领域的国际竞争将日益激烈。**当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n**人工智能的社会学将提上议程。**为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。\n\n**态势与思考**\n\n\u3000\u3000当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n**高度重视。**党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n**态势喜人。**据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。\n\n**差距不小。**目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n\n**前景看好。**我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n\u3000\u3000当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。\n\n**树立理性务实的发展理念。**任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n**重视固本强基的原创研究。**人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n**构建自主可控的创新生态。**我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。\n\n**推动共担共享的全球治理。**目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。\n\n标签 -\n\n网站编辑 - 王慧\n\n[【网站声明】](//www.qstheory.cn/qssyggw/2014-08/12/c_1112042256.htm)[【纠错】](//www.qstheory.cn/qssyggw/2014-08/06/c_1111961674.htm)[【打印】](#)\n\n评论 登录新浪微博 [@求是](http://www.weibo.com/qstheory) 发表评论。请您文明上网、理性发言并遵守相关规定。', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.qstheory.cn/dukan/qs/2019-02/16/c_1124114625.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9992679, 'save_path': None}}, {'paper_id': '', 'title': '一文概览人工智能(AI)发展历程', 'authors': [], 'abstract': None, 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/375549477', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99827254, 'save_path': None}}, {'paper_id': '', 'title': '人工智能简史— 深入浅出PyTorch', 'authors': [], 'abstract': 'Theme by the [Executable Book Project](https://ebp.jupyterbook.org)\n\n* [repository](https://github.com/datawhalechina/thorough-pytorch "Source repository")\n* [open issue](https://github.com/datawhalechina/thorough-pytorch/issues/new?title=Issue%20on%20page%20%2F第零章/0.1 人工智能简史.html&body=Your%20issue%20content%20here. "Open an issue")\n* [suggest edit](https://github.com/datawhalechina/thorough-pytorch/edit/master/第零章/0.1 人工智能简史.md "Edit this page")\n\n* [.md](../_sources/第零章/0.1 人工智能简史.md.txt "Download source file")\n\nContents\n\n# 人工智能简史\n\n## Contents\n\n# 人工智能简史[#](#id1 "永久链接至标题")\n\n自从图灵在1950年第一次提出“机器智能（Machine Intelligence）”这个概念以来，人工智能已经经历了七十余年的发展。在这七十多年中，人工智能的发展先后经历了三次浪潮，每一次浪潮对人工智能的发展来说，都是具有里程碑意义的。接下来我们将以这三次浪潮为主线，为大家介绍人工智能的发展历程。除此之外，我们也将会给大家介绍现在常说的Deep learning，Machine Learning和AI之间的关系。\n\n[\\* ]通过本章学习，你将收获：\n\n* 了解人工智能的三次浪潮\n* 了解Deep learning，Machine learning和AI之间的关系\n\n## 1.1 人工智能的三次浪潮[#](#id2 "永久链接至标题")\n\n### 1.1.1 第一次浪潮[#](#id3 "永久链接至标题")\n\n1950年，阿兰·图灵发表著名论文《计算机器与智能》，在这篇论文中，他提出了机器思维的概念和图灵测试，标志着“机器的智能化”正式进入人类的科技树。在此之后的数年间，机器智能有了进一步的发展。两年后的1952年，计算机科学家阿瑟·萨缪尔开发出一款跳棋程序，并提出了“机器学习”这个概念。在此之后的4年里，机器智能化也取得了一定的进步，直到1956年的达特茅斯会议上，约翰·麦卡锡正式提出了“人工智能”这个词语，1956年，也就成为了实际意义上的人工智能元年。\n\n达特茅斯会议之后，人工智能进入了一个高速发展的时期，也就是所谓的“第一次浪潮”。这次浪潮一直持续到二十世纪六十年代中期。在这近10年的时间里，计算机本身的“智能”并没有得到发展，快速进步的是人工智能的一些理论与算法方面。很多对后来人工智能发展起到奠基作用的算法——如罗森布拉特在1957年发明感知机——就是在这个时间段诞生的。感知机是机器学习人工神经网络理论中神经元的最早模型，这一模型也使得人工神经网络理论得到了巨大的突破。除此之外，强化学习的雏形也是在那段时间提出的。彼时的科学界都弥漫着快乐的气氛，大家都认为，只要坚持走下去，人工智能就一定会得到跨越式的发展。但事与愿违，不久后人工智能的第一次寒冬（AI Winter）就到来了。\n\n1966年前后，AI遭遇了瓶颈。人们发现逻辑证明器、感知器、强化学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。研究者们很快就意识到，要求程序对这个世界具有儿童水平的认识这个要求都太高了——那时没人能够做出人工智能需要的巨大数据库，也没人知道一个程序怎样才能学到如此丰富的信息。另一方面，有很多计算复杂度以指数程度增加，这成为了不可能完成的计算任务。\n\n可以说，人工智能的第一次浪潮在发展到“非智能对话机器”的智能化初级阶段时，就因为当时的技术限制不得不停摆。人工智能的发展似乎陷入了一个无解的“死胡同”里，并被计算机科学家们逐渐冷落。\n\n### 1.1.2 第二次浪潮[#](#id4 "永久链接至标题")\n\n时间来到了20世纪80年代。经过了数十年的研究，科学家们逐渐放弃了初代的符号学派思路，改用统计学的思路来研究人工智能。研究思路的改变再加上硬件技术的升级，人工智能的发展又一次迎来的新的契机。在那个时代，基于人工智能的“专家系统”受到了绝对的热捧。特定领域的“专家系统”程序被更广泛的采纳，该系统能够根据领域内的专业知识，推理出专业问题的答案，人工智能也由此变得更加“实用”，专家系统所依赖的知识库系统和知识工程成为了当时主要的研究方向。\n\n但由于专家系统仅适用于某些特定场景，很快人们就对这一系统由狂热的追捧逐渐走向巨大的失望。与此同时，现代电子计算机的出现让“知识查询”的费用进一步降低，人们更加深刻的意识到专家系统是如此的古老陈旧。因此，政府部门下调了专家系统的研发资金。缺少了资金的支持，由专家系统再次兴起的人工智能研究又一次陷入了低谷之中。\n\n虽然第二次浪潮持续的时间比较短，但它在整个人工智能发展历史中仍然起到了举足轻重的作用。它彻底改变了人工智能研究的大思路，将统计学思想引入研究之中，为人工智能在未来几十年的发展打下了基础。除此之外，在这次浪潮中提出的BP神经网络，为之后机器感知、交互的能力奠定了基础。\n\n### 1.1.3 第三次浪潮[#](#id5 "永久链接至标题")\n\n1993年后，新的数学工具，理论和摩尔定律的出现，使得计算机的算力进一步提高，以深度学习为核心的机器学习算法获得发展，新的芯片和云计算的发展使得可用的计算能力获得飞跃式提高，大数据的发展使得海量数据的储存和分析成为可能。在这样的技术背景下，人工智能的第三次浪潮即将到来。\n\n人工智能的第三次浪潮有两个重要的时间节点：2006年和2016年。2006年是深度学习发展史的分水岭。杰弗里辛顿在这一年发表了《一种深度置信网络的快速学习算法》，其他重要的深度学习学术文章也在这一年被发布，在基本理论层面取得了若干重大突破。而2016年3月，谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭，“人工智能”一词正式进入普通民众的视野并被逐渐熟知。至此，人工智能正式迈向了从“科研领域的应用型工具”到“实用性，功能性工具”的转变，人工智能有了新的研究方向和研究模式，即从过去的学术主导型研究逐渐走向了商业主导型研究。随着人类社会对智能化工具的不断追求和探索，人工智能的发展迎来了全新的时代。\n\n### 1.1.4 总结[#](#id6 "永久链接至标题")\n\n上图是对人工智能发展中经历的三次浪潮和两次寒冬的形象总结。除此之外，有观点认为，深度学习算法带来的“技术红利”，将支撑我们再发展5~10年时间，随后就会遇到瓶颈。人工智能不是一个简单的从1到100进步的过程，它往往趋向于两个极端：要么90分以上，其它的都是10分以下。目前，人工智能急需寻找到一个“技术奇点”，让人工智能迅速发展到通用人工智能甚至是超级人工智能的水平。否则，在人工智能研究商业化的今天，无法从中获利的投资人们将快速撤资退场，人工智能或将进入下一个寒冬。\n\n## 1.2 DL,ML,AI三者之间的关系[#](#dl-ml-ai "永久链接至标题")\n\n大家对“人工智能”这个词，也就是我们所谓的“AI”（Artificial Intelligence）想必是非常熟悉，无论是近几年各行各业都喜欢用作营销噱头的“智能化”还是早期电影如《黑客帝国》、《终结者》等，都让AI这个概念深入人心。但近几年，另外两个词语也在逐步进入我们的生活，即就是“机器学习（Machine Learning，ML）”和“深度学习（Deep Learning，DL）”。在接下来的叙述中，我们就将了解DL和ML究竟是什么，以及它们和AI之间的关系。\n\n### 1.2.1 DL和ML是什么[#](#dlml "永久链接至标题")\n\nMachine Learning（机器学习）。它在1959年被机器学习的先驱者之一的阿瑟·塞缪尔定义为：一门研究领域，它赋予计算机无需明确编程就能学习的能力。也就是说，机器学习程序不同于传统编程那样，使用if-then语句那样明确地输入到计算机中以便它根据条件执行。在某种意义上，机器学习程序赋予机器根据所接触到的数据进行自我调整的能力。机器学习更像是一种优化算法，如果我们在事先就对它进行了正确的调整，那么它就会在一遍又一遍的尝试和猜测之中不断减少它的错误，以无限逼近于最终的正确结果。而机器学习的基本思路，也就是将现实问题抽象成为一个数学问题，机器通过训练，寻找到解决数学问题的方法，进而解决现实问题。\n\nDeep Learning（深度学习）。它在2006年被提出，并在近些年得到了迅速的发展。它通过建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据。李开复教授在《人工智能》一书中这样解释深度学习：“假设深度学习要处理的信息是“水流”，而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。网络的入口是若干管道开口，网络的出口也是若干管道开口。这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节阀的总数可以成千上万甚至更多。水管网络中，每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来，组成一个从前到后，逐层完全连通的水流系统。”\n\n### 1.2.2 它们和AI的关系[#](#ai "永久链接至标题")\n\n众所周知，人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。既然如此，那么计算器算是人工智能吗？严格地说是算的，因为它至少做了“模拟”人在计算方面的智能，并扩展了这个能力（比人算得更快）。我们通过代码驱动计算机去帮我们干活，这个算是人工智能吗？也算的。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，说白了，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。\n\n随着人对计算机的期望越来越高，要求它解决的问题越来越复杂，仅仅算的更快，看的更准已经远远不能满足人们的诉求了。要解决的问题域越来越复杂，即使是同一个问题，其面对的场景也越来越多。传统的思路就是查找问题的条件和解决方法，在计算机程序中再加入一个if-then。但这只是治标不治本。随着我们期待解决的问题越来越多，计算机程序将越来越复杂，越来越难以维护。那怎么办呢？于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n\n至此，“机器学习”的概念，正式诞生。机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器自行学会如何执行任务。说白了，机器学习只是人们实现让机器“模拟、延伸和扩展人的智能”的一种较为轻松的方法罢了。它的成功与否取决于我们喂给机器的数据集是否准确且有效。因此，机器学习是大数据技术领域内的一个应用，人们只是借用这个应用，来发展人工智能罢了。机器学习发展了几十年之后，再次遇到了瓶颈期。随着问题场景的更加复杂多变，需要进行判断的条件更加苛刻，人们不得不重新思考一种方式来优化机器学习。深度学习就是带着这个目的被提出的。\n\n机器学习中有一个概念叫“神经网络”，深度学习正是通过优化这个网络来更好的解决通过机器学习难以解决的问题。它的基本特点，就是试图模仿大脑的神经元之间传递，处理信息的模式，通过不同的“层”来拆分问题，每一层解决问题的一个部分。比如在利用深度学习解决智能驾驶问题中，第一层可能用于识别车辆与道路边缘的距离，第二层用于识别道路标线，第三层用于识别路上的其他车辆等等。\n\n通过以上几段话的简单描述，DL,ML和AI之间的关系也就明确了。它们三者的关系就像是俄罗斯套娃：AI最大，它的目的是通过让机器模仿人类进而超越人类；ML次之，它是AI的一个分支（也是最重要分支），是让机器模仿人类的一种方法；DL更次之，它是ML的一个分支，它的目的是让机器不借助人工标注，也能自主提取目标特征进而解决问题的一种方法。\n\n最后，借用一张经典的关系图作为结尾：\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E9%9B%B6%E7%AB%A0/0.1%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99711037, 'save_path': None}}, {'paper_id': '', 'title': 'AI 简史：从神经元到现代大模型 - CSDN博客', 'authors': [], 'abstract': '* [博客](https://blog.csdn.net/)\n* [下载](https://download.csdn.net/)\n* [社区](https://devpress.csdn.net/)\n* [GitCode](https://link.csdn.net?target=https%3A%2F%2Fgitcode.com%3Futm_source%3Dcsdn_toolbar)\n* [GPU算力](https://ai.csdn.net/)\n* 更多\n\n  [会议](https://www.bagevent.com/event/9117243 "会议")[学习](https://edu.csdn.net?utm_source=zhuzhantoolbar "高质量课程·大会云会员")[InsCode](https://inscode.net?utm_source=csdn_blog_top_bar "InsCode")\n\nAI 搜索\n\n# AI 简史：从神经元到现代大模型\n\n原创\n已于\xa02024-12-25 16:28:52\xa0修改\n·\n1.8w 阅读\n\n·\n\n49\n\n·\n89\n·\n\nCC 4.0 BY-SA版权\n\n版权声明：本文为博主原创文章，遵循 [CC 4.0 BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/) 版权协议，转载请附上原文出处链接和本声明。\n\n文章标签：\n\n[#深度学习](https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#人工智能](https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#ai](https://so.csdn.net/so/search/s.do?q=ai&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#神经网络](https://so.csdn.net/so/search/s.do?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#transformer](https://so.csdn.net/so/search/s.do?q=transformer&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#卷积神经网络](https://so.csdn.net/so/search/s.do?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#机器学习](https://so.csdn.net/so/search/s.do?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n\n于\xa02024-12-25 10:54:28\xa0首次发布\n\n[2048 AI社区 文章已被社区收录](javascript:; "2048 AI社区")\n\n[生成AI\n专栏收录该内容](https://blog.csdn.net/jarodyv/category_12199878.html "生成AI")\n\n45 篇文章\n\n该文章已生成可运行项目，\n\n## AI 简史：从神经元到现代大模型\n\n人工智能 (AI) 和深度学习 (DL) 在过去的几十年中飞速发展，推动了[计算机视觉](https://so.csdn.net/so/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&spm=1001.2101.3001.7020)、自然语言处理和机器人等领域的进步。今年的诺贝尔物理学奖更是颁给了美国科学家约翰·霍普菲尔德 (John Hopfield）和英国科学家杰弗里·辛顿（Geoffrey Hinton），表彰他们“在人工神经网络机器学习方面的基础性发现和发明”。本文将为大家概述 AI 的发展历程，梳理出从早期神经网络模型到现代大型语言模型发展过程中的重要里程碑。\n\n图 1. AI 发展全景图\n\n#### 文章目录\n\n* + [1. 人工智能诞生 (1956)](#1__1956_10)\n  + [2. AI 的演进：从基于规则的系统到深度神经网络](#2_AI__36)\n  + [3. 早期人工神经网络 (1940s – 1960s)](#3__1940s__1960s_49)\n  + - [3.1 McCulloch-Pitts 神经元 (1943)](#31_McCullochPitts__1943_51)\n    - [3.2 Rosenblatt 感知机模型 (1957)](#32_Rosenblatt__1957_62)\n    - [3.3 ADALINE (1959)](#33_ADALINE_1959_82)\n    - [3.4 异或（XOR）问题 (1969)](#34_XOR_1969_106)\n  + [4. 多层感知机 (1960)](#4__1960_124)\n  + - [4.1 隐藏层 (Hidden Layers)](#41__Hidden_Layers_133)\n    - [4.2 多层感知机的历史背景与挑战](#42__142)\n  + [5. 反向传播 (1970s – 1980s)](#5__1970s__1980s_151)\n  + - [5.1 早期发展 (1970 年代)](#51__1970__166)\n    - [5.2 强化与普及（1980 年代）](#52_1980__171)\n    - [5.3 通用逼近定理 (1989)](#53__1989_182)\n    - [5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)](#54__1980___1990__191)\n    - [5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)](#55__1990___2000__200)\n    - [深度学习的复兴 (2000 年代末 – 现在)](#_2000____215)\n  + [6. 卷积神经网络 (1980s – 2010s)](#6__1980s__2010s_226)\n  + - [6.1 早期发展 (1980 – 1998)](#61__1980__1998_242)\n    - [6.2 CNN 的崛起：AlexNet (2012)](#62_CNN_AlexNet_2012_258)\n    - [6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）](#63_AlexNet_2010__280)\n    - [6.4 后续架构改进](#64__289)\n    - [6.5 CNN 的应用](#65_CNN__314)\n  + [7. 循环神经网络 (1986 – 2017)](#7__1986__2017_324)\n  + - [7.1 早期发展 (1980s – 1990s)](#71__1980s__1990s_328)\n    - [7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)](#72_LSTM_GRU__Seq2Seq__1997__2014_344)\n    - [7.3 RNN 的应用](#73_RNN__362)\n    - [7.4 RNN 的挑战](#74_RNN__370)\n  + [8. Transformer (2017 – 现在)](#8_Transformer_2017___380)\n  + - [8.1 Transformer 简介](#81_Transformer__384)\n    - [8.2 Transformer 的衍生模型](#82_Transformer__405)\n    - [8.3 OpenAI GPT 的发展历程](#83_OpenAI_GPT__423)\n    - [8.4 其他知名大语言模型](#84__439)\n  + [9. 多模态模型 (2023 – 现在)](#9__2023___457)\n  + - [9.1 GPT-4V (2023) 和 GPT-4o (2024)](#91_GPT4V_2023__GPT4o_2024_459)\n    - [9.2 Google’s Gemini (2023 – 现在)](#92_Googles_Gemini_2023___465)\n    - [9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)](#93_Claude_30__Claude_35_2023___471)\n    - [9.4 LLaVA (2023)](#94_LLaVA_2023_477)\n  + [10. 扩散模型 (2015 – 现在)](#10__2015___488)\n  + - [10.1 扩散模型简介 (2015)](#101__2015_492)\n    - [10.2 扩散模型的发展 (2020 – 现在)](#102__2020___509)\n    - [10.3 文生图模型](#103__523)\n    - [10.4 文生视频模型](#104__533)\n  + [11. 尾声](#11__566)\n\n### 1. 人工智能诞生 (1956)\n\n人工智能（AI）的概念由来已久，但现代 AI 的雏形是在 20 世纪中期逐渐形成的。“人工智能”这个术语是由计算机科学家和认知科学家约翰·麦卡锡 (John McCarthy) 在 1956 年召开的达特茅斯人工智能夏季研讨项目上首次提出并被大家接受，AI 从此走上历史舞台。\n\n图 2.\n[A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence](http://www-formal.stanford.edu/jmc/history/dartmouth.pdf) (1955)\n\n达特茅斯会议通常被视为 AI 研究的发源地。这次会议汇聚了计算机科学家、数学家和认知科学家，共同探讨创造能够模拟人类智能的机器的可能性。与会者中大佬云集，包括：\n\n* **约翰·麦卡锡 (John McCarthy)** ：计算机科学家、Lisp 编程语言发明人之一。\n* **马文·明斯基 (Marvin Minsky)**：计算机科学家、框架理论的创立者。\n* **雷·索洛莫诺夫 (Ray Solomonoff)**：算法概率论创始人，通用概率分布之父，通用归纳推理理论的创建者。\n* **纳撒尼尔·罗切斯特 (Nathaniel Rochester)** ：IBM 701 的首席设计师，编写了世界上第一个汇编程序。\n* **克劳德·香农 (Claude Shannon)** ：数学家、发明家、密码学家，信息论创始人。\n* **奥利弗·塞弗里奇 (Oliver Selfridge)**：模式识别的奠基人、人工智能的先驱，被誉为“机器知觉之父”。\n\n图 3. 参加达特茅斯会议的部分重量级人物\n\n### 2. AI 的演进：从基于规则的系统到深度神经网络\n\n纵观整个 AI 的发展史，有一条清晰的发展脉络，那就是从基于规则的系统向深度神经网络的不断进化。\n\n人工智能 (AI) 的发展始于上个世纪 50 年代，那时人们开始开发用于国际象棋和问题求解的算法。第一个 AI 程序 Logical Theorist 于 1956 年诞生。到了 1960 和 1970 年代，基于规则的专家系统如 MYCIN 被引入，它们可以帮助进行复杂的决策。1980 年代，机器学习开始兴起，使 AI 系统能够从数据中学习并不断改进，为现代深度学习技术奠定了基础。\n\n今天，大多数最前沿的 AI 技术都由深度学习驱动，深刻改变了 AI 的发展格局。深度学习是机器学习的一个独立分支，它通过多层人工神经网络从原始数据中提取复杂特征。在本文中，我们将探讨 AI 的发展历史，并重点介绍深度学习在其中的关键作用。\n\n图 4. 人工智能、机器学习、神经网络、深度学习之间的关系\n\n### 3. 早期人工神经网络 (1940s – 1960s)\n\n#### 3.1 McCulloch-Pitts 神经元 (1943)\n\n神经网络的概念可以追溯到 1943 年，当时 Warren McCulloch 和 Walter Pitts 提出了第一个人工神经元模型。McCulloch-Pitts (MP) 神经元模型是对生物神经元的一种突破性简化。这个模型通过聚合二进制输入，并利用阈值激活函数来做出决策，从而为人工神经网络奠定了基础，输出结果为二进制 \n{\n0\n,\n1\n}\n\\{0, 1\\}\n{0,1}。\n\n图 5. 人工神经元的结构与原理\n\n#### 3.2 Rosenblatt 感知机模型 (1957)\n\nFrank Rosenblatt 在 1957 年引入了感知机，这是一种能够学习和识别模式的单层神经网络。感知机模型比 MP 神经元更为通用，设计用于处理实数值输入，并通过调整权重来最小化分类错误。\n\n图 6. 感知机模型\n\nRosenblatt 还为感知机开发了一种监督学习算法，使得网络能够直接从训练数据中进行学习。  \n \nL\n(\nW\n)\n=\n−\n∑\ni\n∈\nM\nW\nT\nX\ni\ny\ni\n\\mathcal{L}(W) = - \\sum\\_{i \\in M} W^T X\\_i y\\_i\nL(W)=−i∈M∑\u200bWTXi\u200byi\u200b\n\n图 7. Mark I 感知机，是一台实现了图像识别感知机算法的机器\n\nRosenblatt 的感知机展示出识别个人和在不同语言间翻译语音的潜力，这在当时引发了公众对 AI 的极大兴趣。感知机模型及其相关的学习算法成为神经网络发展历程中的重要里程碑。然而，很快就显现出一个关键限制：当训练数据是非线性可分时，感知机的学习规则无法收敛。\n\n#### 3.3 ADALINE (1959)\n\nWidrow 和 Hoff 在 1959 年引入了 ADALINE（自适应线性神经元，也称 Delta 学习规则），对感知机学习规则进行了改进。ADALINE 解决了二进制输出和噪声敏感性等限制，并能够学习并收敛非线性可分的数据，这是神经网络发展中的一大突破。\n\n图 8. ADALINE VS. 感知机\n\nADALINE 的主要特点包括：\n\n* **线性激活函数**：不同于感知器的阶跃函数，ADALINE 使用线性激活函数，因此适用于回归任务和连续输出。\n* **最小均方（LMS）算法**：ADALINE 采用 LMS 算法，该算法通过最小化预测输出与实际输出之间的均方误差，提供更高效和稳定的学习过程。\n* **自适应权重**：LMS 算法根据输出误差自适应调整权重，使 ADALINE 即使在有噪声的情况下也能有效地学习和收敛。\n\n**ADALINE 的引入标志着神经网络第一次黄金时代的开始**，它克服了 Rosenblatt 感知机学习的限制。这一突破实现了高效学习、连续输出和对噪声数据的适应能力，推动了该领域的创新和快速发展。\n\n图 9. ADALINE 开启了神经网络第一次黄金时代\n\n然而，与感知机类似，ADALINE 仍然无法解决线性可分的问题，无法应对更复杂的非线性任务。这一局限集中体现在异或（XOR）问题上，也促进了更高级神经网络架构的发展。\n\n#### 3.4 异或（XOR）问题 (1969)\n\n1969年，Marvin Minsky 和 Seymour Papert 在他们的著作《Perceptrons》中揭示了单层感知机的一个重要局限：由于其线性决策边界，感知机无法解决异或 (XOR) 问题，而这是一个简单的二元分类任务。异或问题不是线性可分的，也就是说，没有一个单一的线性边界能够正确地将所有的输入模式分类。\n\n图 10. Marvin Minsky 和 Seymour Papert 合著的《Perceptrons: An introduction to computational geometry》\n\n这一发现强调了需要开发更复杂的神经网络架构，以便能够学习非线性的决策边界。感知机的局限性被揭露后，人们对神经网络的信心减弱，转而研究符号人工智能方法，**这标志着从 20 世纪 70 年代初到 80 年代中期的“神经网络的第一次黑暗时代”的开始**。\n\n图 11. 异或问题将神经网络代入第一次黑暗时代\n\n### 4. 多层感知机 (1960)\n\n多层感知机 (MLP) 最早于 20 世纪 60 年代提出，作为对单层感知机的改进。MLP 由多个层次的相互连接的神经元组成，能够克服单层模型的局限性。苏联科学家 A. G. Ivakhnenko 和 V. Lapa 在感知机基础上进行研究，对多层感知机的发展中做出了重要贡献。\n\n图 12. 多层感知机模型\n\n#### 4.1 隐藏层 (Hidden Layers)\n\n增加隐藏层使得 MLP (多层感知器) 可以捕捉和表达数据中的复杂非线性关系。这些隐藏层极大地增强了网络的学习能力，使其能够解决诸如异或问题这样非线性可分的问题。\n\n图 13. 隐藏层解决异或问题\n\n#### 4.2 多层感知机的历史背景与挑战\n\nMLP 的出现标志着神经网络的研究向前迈出了重大一步，展示了[深度学习架构](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9E%B6%E6%9E%84&spm=1001.2101.3001.7020)在解决复杂问题方面的潜力。然而，在 1960 年代和 1970 年代，MLP 的发展面临若干挑战：\n\n* **缺乏训练算法**：早期的 MLP 模型缺乏高效的训练算法，无法有效地调整网络权重。此时反向传播算法还未诞生，训练多层深度网络非常困难。\n* **算力限制**：当时的算力不足以应对训练深度神经网络所需的复杂计算。这一限制拖慢了 MLP 的研究和发展进程。\n\n神经网络的第一个黑暗时代在 1986 年结束，**随着反向传播算法的诞生，开启了神经网络的第二个黄金时代**。\n\n### 5. 反向传播 (1970s – 1980s)\n\n1969 年，异或问题揭示了感知机（单层神经网络）的局限性。研究人员意识到，多层神经网络能够克服这些限制，但缺乏有效的训练算法。17年后，反向传播算法的开发使得神经网络在理论上可以逼近任何函数。值得注意的是，该算法实际上在发表之前就已被发明。如今，反向传播已成为深度学习的核心组件，自 20 世纪 60 年代和70 年代以来经历了显著的发展和完善。\n\n图 14. 反向传播原理示意图\n\n反向传播的关键特性：\n\n* **梯度下降**：反向传播与梯度下降联合使用以降低误差函数。该算法计算每个权重相对于误差的梯度，从而逐步调整权重以减少误差。\n* **链式法则**：反向传播算法的核心在于应用微积分的链式法则。此法则使得误差的梯度可以被分解为一系列偏导数，并通过网络的反向传递高效计算。\n* **分层计算**：反向传播逐层运作，从输出层向输入层反向传递。这种分层计算确保梯度在网络中正确传播，使得深度架构的训练成为可能。\n\n#### 5.1 早期发展 (1970 年代)\n\n* **Seppo Linnainmaa (1970)**: 提出了自动微分的概念，这是反向传播算法的重要组成部分。\n* **Paul Werbos (1974)**: 提议使用微积分的链式法则计算误差函数对网络权重的梯度，从而能够训练多层神经网络。\n\n#### 5.2 强化与普及（1980 年代）\n\n* **David Rumelhart, Geoffrey Hinton 和 Ronald Williams (1986)**: 将**反向传播**这一高效实用的方法，用于训练深度神经网络，并展示了其在多种问题中的应用。\n\n图 15. 反向传播算法的三位主要贡献者\n\n其中 Geoffrey Hinton 因其在人工神经网络和机器学习领域的贡献获得了 2018 年图灵奖和 2024 诺贝尔物理学奖，称为继 Herbert Simon 后第二位图灵奖-诺贝尔奖双料得主。\n\n#### 5.3 通用逼近定理 (1989)\n\nGeorge Cybenko 在 1989 年提出的通用逼近定理，为多层神经网络的功能提供了数学基础。该定理表明，只要神经元数量足够，并且使用非线性激活函数，具有单个隐藏层的前馈神经网络就能够以任意精度逼近任意连续函数。这个定理突显了神经网络的强大能力和灵活性，使其能够应用于各种领域。\n\n图 16. 具有单个隐藏层的神经网络可以将任意连续函数逼近到任意所需的精度，从而在各个领域解决复杂的问题\n\n#### 5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)\n\n\\*\\*反向传播算法的出现和通用逼近定理的提出，开启了神经网络研究的第二个黄金时代。\\*\\*反向传播提供了一种高效的多层神经网络训练方法，使研究人员能够构建更深层次和更复杂的模型。通用逼近定理则为使用多层神经网络提供了理论支持，并增强了人们对其解决复杂问题能力的信心。在 1980 年代末至 1990 年代初，这一时期见证了对神经网络领域的兴趣回升和显著的进步。\n\n图 17. 反向传播和通用逼近定理开启了神经网络研究的第二个黄金时代\n\n#### 5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)\n\n然而，由于一系列因素，神经网络领域在 1990 年代初至 2000 年代初经历了“第二个黑暗时代”：\n\n* **支持向量机 (SVM) 的兴起**：支持向量机为分类和回归任务提供了更优雅的数学方法。\n* **算力限制**：由于训练深度神经网络仍然耗时且对硬件要求高，计算能力受到限制。\n* **过拟合和泛化问题**：这两个问题导致早期神经网络在训练数据上表现良好，但在新数据上表现不佳，限制了其实用性。\n\n这些挑战使得许多研究人员转而关注其他领域，导致神经网络研究的停滞。\n\n图 18. 随着 SVM 的兴起，神经网络进入第二个黑暗时代\n\n#### 深度学习的复兴 (2000 年代末 – 现在)\n\n在 2000 年代末和 2010 年代初，神经网络领域经历了复兴，这得益于以下方面的进步：\n\n* **深度学习架构的发展**（如 CNNs、RNNs、Transformers、Diffusion Models）\n* **硬件的改进**（如 GPUs、TPUs、LPUs）\n* **大规模数据集的可用性**（如 ImageNet、COCO、OpenWebText、WikiText 等）\n* **训练算法的优化**（如 SGD、Adam、dropout）\n\n这些进展带来了计算机视觉、自然语言处理、语音识别和强化学习的重大突破。通用逼近定理与实际技术的进步相结合，为深度学习技术的广泛应用和成功奠定了基础。\n\n### 6. 卷积神经网络 (1980s – 2010s)\n\n卷积神经网络 (CNN) 在深度学习领域，尤其是计算机视觉和图像处理方面，带来了革命性的变化。从上个世纪 80 年代到本世纪最初的 10 年，CNN 在架构、训练技术和应用等方面取得了显著的进步。\n\n卷积神经网络由以下三个主要组件构成：\n\n* **卷积层 (Convolutional Layers)**：这些层通过一组可调整的滤波器，从输入图像中自动学习和提取特征的空间层次结构。\n* **池化层 (Pooling Layers)**：池化层通过缩小输入的空间尺寸，来提高对输入变化的适应性，并减少计算量。\n* **全连接层 (Fully Connected Layers)**：在卷积层和池化层之后，全连接层用于分类任务，负责整合之前层中提取的特征。\n\n卷积神经网络的主要特性\n\n* **局部感受野**：CNN 利用局部感受野来捕捉输入数据中的局部特征，使其在处理图像和其他视觉任务时表现出色。\n* **权重共享**：通过在卷积层中共享权重，CNN 能够减少网络中参数的数量，从而提高训练效率。\n* **平移不变性**：池化层赋予网络平移不变性，使其能够识别输入图像中不同位置的相同模式。\n\n#### 6.1 早期发展 (1980 – 1998)\n\n1980 年代，福岛邦彦 (Kunihiko Fukushima) 首次提出了 CNN 的概念，他设计了一种称为神经认知机 (Neocognitron) 的分层神经网络，这种网络模仿了人类视觉皮层的结构。这项开创性的研究为之后 CNN 的发展奠定了基础。\n\n图 19. 福岛邦彦与他的神经认知机\n\n到了 1980 年代末和 1990 年代初，Yann LeCun 和他的团队在此基础上进一步发展了 CNN，并推出了 LeNet-5 架构，该架构专为手写数字识别而设计。\n\n图 20. Yann LeCun 与他的 LeNet-5\n\n#### 6.2 CNN 的崛起：AlexNet (2012)\n\n2012 年，AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了重大胜利，这是 CNN 发展中的一个重要里程碑。这次胜利不仅以压倒性优势赢得了比赛，也在图像分类领域取得了重大突破。\n\n图 21. ILSVRC 历年冠军及其表现\n\nILSVRC 是一个年度图像识别基准测试，用于评估算法在一个包含 1000 万多张注释图像的数据集上的表现，这些图像被划分为 1000 个类别。AlexNet 的创新之处包括：\n\n* **ReLU 激活函数**：为解决传统激活函数的问题而引入，ReLU 提高了训练速度并改善了性能。\n* **Dropout 正则化**：这种技术通过在训练过程中随机丢弃神经元来减少过拟合现象。\n* **数据增强**：通过人为增加训练数据的多样性，增强了数据集的丰富性，从而改善了模型的泛化能力。\n\nAlexNet 的成功成为 CNN 发展中的一个转折点，为图像分类和物体检测的进一步发展奠定了基础。\n\n图 22. AlexNet 架构\n\n#### 6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）\n\n自 2010 年代直至今天，当前的科技发展黄金时代以深度学习、大数据和强大计算平台的结合为特征。在这一时期，图像识别、自然语言处理和机器人技术等领域取得了显著的突破。持续的研究不断推动着人工智能（AI）能力的边界。\n\n图 23. AlexNet 开启神经网络的第三次黄金时代\n\n#### 6.4 后续架构改进\n\n继 AlexNet 之后，又相继出现了几个有影响力的架构：\n\n* **VGGNet (2014)**：由牛津大学的视觉几何组开发，VGGNet 强调使用更深的网络架构，并采用较小的卷积滤波器 (\n  3\n  ×\n  3\n  3 \\times 3\n  3×3)，从而取得了显著的准确率。\n\n  图 24. 原始 VGGNet 架构\n* **GoogLeNet/Inception (2014)**：引入了 inception 模块，使得网络能够以更高效的方式捕捉不同尺度的特征。\n\n  图 25. GooLeNet 架构\n* **ResNet (2015)**：残差网络通过引入跳跃连接，使得训练非常深的网络成为可能，同时缓解了梯度消失问题。\n\n  图 26. ResNet 架构\n\n#### 6.5 CNN 的应用\n\nCNN 的进步已经在多个领域引发了变革：\n\n* **计算机视觉**：CNN 已成为现代计算机视觉的核心，实现了图像分类、物体检测和语义分割方面的突破。\n* **医学影像**：CNN 被用于疾病诊断、肿瘤检测和图像引导手术等任务，大大提高了诊断准确性。\n* **无人驾驶**：CNN 是无人驾驶感知系统的核心，使它们能够解释和响应周围环境。\n\nCNN 从其创立到目前作为深度学习基石的历程展示了其对 AI 的重大影响。CNN 的成功也为深度学习的进一步进步铺平了道路，并激发了其他专用神经网络架构的发展，如 RNN 和 Transformer。CNN 的理论基础和实际创新显著推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 7. 循环神经网络 (1986 – 2017)\n\n循环神经网络 (RNN) 是为了处理序列数据而设计的。与传统的前馈网络（MLP）不同，RNN 拥有一个内部的隐藏状态或“记忆”，使其能够捕捉序列元素之间的时间依赖性。因此，RNN 在语言建模、时间序列预测和语音识别等任务中尤为有效。\n\n#### 7.1 早期发展 (1980s – 1990s)\n\nRNN 的概念起源于 1980 年代，John Hopfield, Michael I. Jordan 和 Jeffrey L. Elman 等先驱为这些网络的发展做出了贡献。John Hopfield在 1982 年提出的 Hopfield 网络为理解神经网络中的循环连接奠定了基础。Jordan 网络和 Elman 网络分别在 1980 年代和 1990 年代提出，是早期捕捉序列数据中时间依赖性的尝试。\n\n图 27. RNN 架构\n\nRNN 使用历时反向传播 (BPTT) 进行训练，这是前馈网络标准反向传播算法的扩展。BPTT 需要将网络在时间上展开，将每个时间步视为一层。在前向传播时，输入序列被处理，并在输出层计算误差。然后，产生的梯度从最后一个时间步反向传播到第一个时间步，以更新 RNN 的参数。然而，由于梯度消失问题，RNN 在学习长时间依赖性时遇到困难，因为梯度会变得极小，导致无法学习。相反，梯度也可能变得过大，造成训练不稳定，这被称为梯度爆炸问题。\n\n图 28. 反向传播 (BPTT)\n\n#### 7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)\n\n图 29. RNN, LSTM, GRU 单元\n\n* **长短期记忆 (LSTM) 网络 (1997)**：Sepp Hochreiter 和 Jürgen Schmidhuber 提出了 LSTM 网络，以解决传统 RNN 中的梯度消失问题。LSTM 通过使用门控机制来控制信息流动，使其能够捕捉序列数据中的长期依赖关系。LSTM 包括单元状态（用于存储长期信息）、隐藏状态（携带当前时间步的短期输出），以及三个门（输入门、遗忘门和输出门）。在每一步中，LSTM 会根据多个数学运算和门来决定需要遗忘多少信息，向单元状态添加多少信息，以及为下一步输出多少信息。\n* **门控循环单元 (GRU) (2014)**：Kyunghyun Cho 等人提出了 GRU，这是一种简化版的 LSTM，也采用门控机制来调节信息流。与 LSTM 的三个门和两个状态不同，GRUs 只有两个门和一个状态。LSTM 的遗忘门和输入门被合并为一个更新门，用于决定保留多少过去的信息和整合多少新信息。此外，GRU 用重置门代替了 LSTM 的输出门，该门决定在整合新信息之前需要“重置”或忘记多少过去的信息。由于 GRU 的参数较少，通常训练速度更快。\n* **Seq2Seq 模型 (2014)**：Ilya Sutskever 和他的团队提出了 Seq2Seq 模型，这种模型使用编码器-解码器架构，将输入序列转换为输出序列。Seq2Seq 模型已被广泛应用于机器翻译、语音识别和文本摘要等任务。\n\n  图 30. 基于 LSTM 的 Seq2Seq 编码器-解码器架构\n\n#### 7.3 RNN 的应用\n\nRNN 在多个领域产生了重大影响，包括：\n\n* **自然语言处理**：RNN 在自然语言处理领域引发了革命性变化，使得语言建模、机器翻译、情感分析和文本生成等任务取得了显著进展。\n* **语音识别**：RNN 广泛用于语音识别系统中，它们通过建模口语的时间依赖性，将语音信号转换为文本。\n* **时间序列预测**：RNN 在时间序列预测中表现出色，它们通过建模顺序数据的时间依赖性，以预测未来值。\n\n#### 7.4 RNN 的挑战\n\n尽管 RNN 在许多方面取得了成功，但其仍面临若干挑战：\n\n* **梯度消失与梯度爆炸**：传统 RNN 在处理这些问题时表现不佳，尽管 LSTM 和 GRU 提供了一些解决方案。\n* **计算复杂性**：训练 RNN 可能需要大量资源，尤其是在处理大型数据集时。\n* **并行化**：RNN 的顺序特性使得并行训练和推理过程变得复杂。\n\nRNN 的成功为深度学习的进一步发展奠定了基础，并启发了其他专门化神经网络架构的发展，例如 Transformer，它们在各种序列数据任务中取得了最先进的性能。RNN 的理论基础和实际创新大大推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 8. Transformer (2017 – 现在)\n\nTransformer 以其卓越的序列数据处理能力，深刻地改变了深度学习的格局，并在自然语言处理 (NLP) 和计算机视觉等多个领域中发挥了重要作用。\n\n#### 8.1 Transformer 简介\n\nVaswani 等人于 2017 年发表了开创性论文“Attention is All You Need”，其中提出了 Transformer 模型。这个模型放弃了 RNN 的传统序列处理方式，转而采用自注意力机制，从而实现了并行处理，并能更好地处理长距离依赖关系。\n\n图 31. 自注意力机制\n\nTransformer 具有如下核心特性：\n\n* **自注意力机制**：允许序列中每个位置灵活地关注其他所有位置，从而比 RNN 或 LSTM 更有效地捕捉上下文。\n* **并行化**：通过同时处理所有输入数据，大大提高了训练速度，这与 RNN 的顺序处理方式形成鲜明对比。\n* **编码器-解码器结构**：编码器和解码器堆栈都使用自注意力和前馈神经网络层，并通过位置编码来保持序列的顺序。\n\n图 32. Transformer 架构\n\n关于 Transformer 和自注意力机制的详细介绍，请参考 [《深度解析 Transformer 和注意力机制（含完整代码实现）》](https://jarod.blog.csdn.net/article/details/130867562) 和 [《图解 NLP 模型发展：从 RNN 到 Transformer》](https://jarod.blog.csdn.net/article/details/129564388)。\n\n#### 8.2 Transformer 的衍生模型\n\n图 33. 基于 Transformer 的模型\n\nTransformer 有众多衍生模型，其中比较重要的有：\n\n* **BERT (2018)**: BERT 是一种仅使用编码器的双向编码器表示模型，通过掩码语言建模和下一句预测的预训练，彻底革新了 NLP。\n* **GPT (2018)**: GPT 旨在预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这一基础模型为生成式语言模型的后续发展奠定了基础，展示了从大型文本语料库中进行无监督学习的潜力。\n* **T5 (2019)**: T5 是一种编码器-解码器结构的文本到文本转换模型，将 NLP 任务转化为统一的文本到文本格式，简化了模型架构和训练过程。\n\n图 34. BERT vs. GTP vs. T5\n\n#### 8.3 OpenAI GPT 的发展历程\n\nOpenAI 的生成式预训练 Transformer (Generative Pre-trained Transformer, GPT) 系列模型自 2018 年问世以来，极大地推动了自然语言处理 (Natural Language Processing, NLP) 领域的发展。每一代模型都在前一代的基础上进行改进，引入了更大规模的模型和增强的功能。以下是每个版本的详细概述。\n\n图 35. GPT 的自回归语言模型架构旨在根据之前输入的 Token 预测序列中的下一个 Token\n\n* **GPT (2018)**: 原始的 GPT 模型于 2018 年推出，作为一个仅使用自回归解码器的变换器，拥有 1.17 亿个参数。它被设计用于预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这个基础模型为后续生成式语言模型的发展奠定了基础，展示了无监督学习从大型文本语料库中获取信息的潜力。\n* **GPT-2 (2019)**: 2019 年发布的 GPT-2 在模型规模和能力上实现了显著飞跃，参数数量扩大到 15 亿个。这个版本表现出一些新兴能力，如零样本任务执行，即可以在没有专门训练的情况下执行任务。然而，它生成连贯但有时误导性文本的能力引发了关于潜在滥用的道德担忧，特别是在生成假新闻或错误信息方面。\n* **GPT-3 (2020)**: GPT-3 于 2020 年推出，进一步将模型规模扩大到惊人的 1750 亿个参数。该模型在少样本学习方面表现出卓越的能力，即可以根据提示中提供的极少量示例适应各种任务。其生成类人文本的能力使其成为许多应用的多功能工具，包括内容创作、代码辅助和对话代理。GPT-3 的架构使其能够在无需大量微调的情况下执行广泛的 NLP 任务，巩固了其作为当时最强大语言模型之一的地位。\n* **ChatGPT (2022):** 这是一个经过微调的 GPT-3.5 模型，通过人类反馈强化学习 (Reinforcement Learning from Human Feedback, RLHF) 进行优化，擅长处理后续问题和维护上下文，通过指令调优和用户偏好数据使响应更符合用户意图。\n* **GPT-4 (2023)**: GPT-4 于 2023 年发布，继续在能力和参数数量上进行扩展，尽管其架构和参数数量的具体细节目前尚未完全公开。预计将在之前几代模型的表现上进一步提升，特别是在推理能力和理解复杂上下文的能力方面。\n* **GPT-o1 (2024)**：这一版本的 GPT 与之前所有版本有了本质区别，它开创性地引入了人类的慢思考+思维链模式，将大模型从越来越离谱的参数内卷中解救出来，开辟了AI发展的新方向。GPT-o1 显著提升了逻辑推理能力，使其在数学、科研、代码等领域的表现有了质的飞跃。在若干基准测试中，GPT-o1 展现出的能力已经与博士生相当。\n\n#### 8.4 其他知名大语言模型\n\n随着越来越多优秀的大型语言模型（LLM）的涌现，人工智能领域得到了极大的丰富。这些模型各具特色，为人工智能技术带来了新的进展。以下是一些知名大语言模型的概况：\n\n* **Anthropic 的 Claude (2022)**: 该模型注重 AI 输出的安全性和伦理问题，致力于与人类价值观保持一致。\n* **Meta 的 LLaMA (2023)**: 提供多种规模的模型，以满足不同的计算需求，在自然语言处理的基准测试中表现卓越。\n* **Mistral.AI 的 Mistral (2023)**: 兼顾高性能和资源效率，适合于实时应用，专注于开源 AI 解决方案。\n* **阿里巴巴的 Qwen (2023)**: 专为创建高质量的英中双语 AI 模型而设计，促进跨语言应用并推动创新。\n* **Microsoft 的 Phi (2023)**: 强调在各种应用中的多功能性和集成能力，采用先进的训练技术以提升上下文理解和用户交互。\n* **Google 的 Gemma 系列 (2024)**: 这些轻量级的开放模型应用于多种领域，包括文本生成、摘要和信息提取，注重性能和效率。\n\n更多大语言模型及其能力评估参加下图\n\n图 36. 开源模型和闭源模型的性能\n\n### 9. 多模态模型 (2023 – 现在)\n\n#### 9.1 GPT-4V (2023) 和 GPT-4o (2024)\n\n* **GPT-4V (2023)** 是 AI 发展中的重要一步，它将多模态功能集成到已经强大的文本模型中。它不仅能够处理和生成文本，还可以处理和生成图像内容，为更全面的 AI 交互奠定了基础。\n* **GPT-4o (2024)** 是从 GPT-4V 演变而来的，通过复杂的上下文理解来增强多模态集成。与其前身相比，它在不同媒体之间提供了更好的连贯性，能够从文本提示生成更高级的图像，并基于视觉输入进行更精细的推理。此外，GPT-4o 通过高级训练机制实现伦理对齐，确保其输出不仅准确，而且负责任，并与人类价值观保持一致。\n\n#### 9.2 Google’s Gemini (2023 – 现在)\n\n* **Gemini Pro (2023)**: Google 的 Gemini 推出了一系列为多模态任务设计的模型，集成了文本、图像、音频和视频处理。特别是，Gemini Pro 因其可扩展性和效率而脱颖而出，使高级 AI 能够应用于从实时分析到跨不同媒体格式的复杂内容生成等多个领域。\n* **Gemini Ultra 和 Nano (2023)**: Gemini 模型包括适用于不同规模应用的 Ultra 和 Nano 版本，能够执行需要跨多种数据类型理解的任务。它们在视频摘要、多模态翻译和互动学习环境等任务中表现出色，体现了 Google 在推动 AI 在多媒体环境中应用的决心。\n\n#### 9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)\n\n* **Claude 3.0 (2023)** 由 Anthropic 推出，该模型专注于提高 AI 响应的安全性和可靠性，在上下文理解和伦理考虑方面进行了改进。它被设计得更具对话性和辅助性，同时严格遵循避免有害或偏见输出的原则。\n* **Claude 3.5 (2024)** 进一步提升了 Claude 3.0 的能力，在复杂任务中的表现更佳，处理效率更高，并且在用户请求的细节处理上更加细致。这个版本还强调多模态交互，虽然它主要在文本和逻辑任务中表现突出，但在处理视觉或其他感官输入方面也展现出新兴能力，提供更为综合的用户体验。\n\n#### 9.4 LLaVA (2023)\n\n* **LLaVA (Large Language and Vision Assistant)** 是一种创新的多模态 AI (Multimodal AI) 方法，将语言理解与视觉处理结合在一起。LLaVA 于 2023 年开发，能够解读图像并将其与文本内容相联系，使其可以回答关于图像的问题、描述视觉内容，甚至根据视觉线索生成文本。其架构充分利用 Transformer 模型的优势，在需要同时具备视觉和语言理解的任务中实现了最先进的性能。这个模型因其开源特性而备受关注，鼓励在多模态 AI 应用领域进行更多的研究和开发。\n\n  图 37. LLaVA 架构\n\n  这些模型的出现标志着 AI 系统的转变，这些系统不仅能够理解和生成文本，还能解释和创造跨多种模态的内容，更加贴近人类的认知能力。这种 AI 模型的发展推动了更具互动性和直观性的应用程序，它们能够结合不同的感官输入来处理现实世界中的场景，从而拓宽了 AI 在日常生活、研究和工业应用中的可能性。\n\n### 10. 扩散模型 (2015 – 现在)\n\n扩散模型已经成为生成模型中一个重要的类别，它为从复杂数据分布中生成高保真样本提供了一种全新的方法。与传统模型如 GAN 和 VAE 不同，扩散模型采用渐进去噪技术，并在许多应用中表现出色。\n\n#### 10.1 扩散模型简介 (2015)\n\n扩散模型的基础由 Sohl-Dickstein 等人于 2015 年在他们的论文中奠定。他们提出了一种生成过程，即通过逆转逐步添加的噪声，可以将噪声还原为结构化数据。\n\n图 38. 扩散模型原理概要\n\n扩散模型的关键特性：\n\n* **去噪过程**: 这些模型通过逐步添加噪声（前向过程），并学习如何逆转该过程（反向过程），以有效去噪并生成样本。\n* **马尔可夫链**: 这两个过程都被构建为马尔可夫链，每个前向步骤添加高斯噪声，模型学习如何在反向过程中去除这些噪声。\n* **训练目标**: 目标是在每一步中最小化预测噪声与实际噪声之间的差异，优化一种证据下界（ELBO）的形式。\n* **稳定性和鲁棒性**: 它们比 GAN 提供更好的稳定性，避免了模式崩溃等问题，从而能够持续生成多样化的高质量输出。\n\n关于扩散模型的详细介绍，请参考[《Diffusion Model 深入剖析》](https://jarod.blog.csdn.net/article/details/130903760)。\n\n#### 10.2 扩散模型的发展 (2020 – 现在)\n\n* **去噪扩散概率模型 (Denoising Diffusion Probabilistic Models, DDPM) (2020)**: 改进了扩散过程，在图像合成领域设立了新的标杆。\n* **去噪扩散隐式模型 (Denoising Diffusion Implicit Models, DDIM) (2021)**: 通过非马尔可夫采样提高了效率，使生成过程更加灵活。\n* **基于分数的生成模型 (2021)**: 通过使用随机微分方程提高了样本生成的效率。\n* **潜在扩散模型 (Latent Diffusion Model) (2022)**: 成为流行的文本到图像生成系统（如 Stable Diffusion）的基础，显著推动了 AI 生成图像领域的进步，并为更易于访问和高效的生成式 AI 工具铺平了道路。关于潜在扩散模型和 Stable Diffusion 的详细介绍，请参见 [《Stable Diffusion 超详细讲解》](https://jarod.blog.csdn.net/article/details/131018599) 和 [《Stable Diffusion原理详解》](https://jarod.blog.csdn.net/article/details/129280836)。\n\n  图 39. 潜在扩散模型架构\n\n#### 10.3 文生图模型\n\n* **DreamBooth (2022)**: 允许在少量特定主题的图像上训练扩散模型，从而实现个性化的图像生成。\n* **LoRA (2022)**: 代表低秩适应，是一种通过添加少量参数来微调扩散模型的技术，使其更容易适应特定任务或数据集。\n* **ControlNet (2023)**: 通过添加如草图或深度图等输入来控制扩散模型，从而对生成图像提供更多的控制。\n* **FLUX.1 (2024)**: Black Forest Lab 推出了 FLUX.1，这是一种用于 AI 图像生成的先进扩散模型，具备卓越的速度、质量和响应提示的能力。FLUX.1 提供三个版本——Schnell、Dev 和 Pro，并采用了整流流变换器等创新技术，能够生成高度逼真的图像。FLUX.1 还可以生成文字并精准处理手指和脚趾等细节，是一个全面的图像生成器。\n* **Multi-SBoRA (2024)**: Multi-SBoRA 是一种为多个概念定制扩散模型的新方法。它使用正交标准基向量来构建低秩矩阵进行微调，允许区域性和非重叠的权重更新，从而减少跨概念的干扰。这种方法保留了预训练模型的知识，减少了计算开销，并提高了模型的灵活性。实验结果显示，Multi-SBoRA 在多概念定制中表现优异，保持了独立性，并减轻了串扰效应。\n\n#### 10.4 文生视频模型\n\n2024 年 2 月，OpenAI 发布了 [Sora](https://openai.com/sora) 文生视频模型。凭借惊艳的视频生成质量，Sora 一经发布就受到各行各业的追捧和关注。尽管在 Sora 之前已经有好几个文生视频模型，但 Sora 的发布被普遍认为拉开了文生视频的大幕。\n\nSora vs. Pika vs. RunwayML vs. Stable Video 生成视频效果对比\n\n很明显可以看出 Sora 无论从分辨率、时长、精细度和对真实世界的还原程度上都远远好于其他模型。下表给出了详细的对比。\n\n图 40. Sora vs. 早期文生视频模型\n\n然而，Sora 发布后迟迟没有正式上线。全网苦等10个月，Sora 终于在 2024 年 12 月 10 日正式上线。在这 10 个月期间，国产文生视频模型迅速崛起，其中 MiniMax 的海螺和快手的可灵的视频生成质量比肩甚至超越 Sora。\n\n| 名称 | 公司 | 单次生成秒数 | 是否免费 | 生成方式 | 最低月付费 |\n| --- | --- | --- | --- | --- | --- |\n| 可灵 | 快手 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 66元 |\n| 即梦 | 字节 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 69元 |\n| 海螺 | MiniMax | 6s | 限制免费使用次数 | 文生视频、图生视频 | 68元 |\n| Vidu | 生数科技 | 4s | 限制免费使用次数 | 文生视频、图生视频 | 9.9美元 |\n| 智谱清言 | 智谱科技 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| 通义万相 | 阿里 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| FilmAction | 瀚皓科技 | 5s | 限制免费使用次数 | 图生视频 | 50元300电影币 |\n| 白日梦 | 光魔科技 | 最长6分钟 | 限制免费使用次数 | 图生视频 | 29元 |\n| Sora | OpenAl | 5s、20s | 付费使用 | 文生视频、图生视频 | 20美元 |\n| Runway | Runway | 10s | 限制免费使用次数 | 文生视频、图生视频 | 15美元 |\n\n表 1. 主流文生视频模型一览表\n\n相信 2025 年文生视频将会是各大 AI 企业主要争夺的战场。\n\n### 11. 尾声\n\n至此，我们的 AI 简史之旅就要接近尾声了。通过对 AI 发展的回顾，我们可以发现人工智能 (AI) 和深度学习的发展历史充满了突破性的进步和变革性的创新。从早期的简单神经网络到复杂的网络架构，从卷积神经网络 (CNN)、递归神经网络 (RNN) 到现在流行的 Transformer 和扩散模型，这些技术已经彻底改变了许多领域。\n\n最近的技术进步催生了大型语言模型和多模态模型，例如 OpenAI 的 GPT-4o、Google 的 Gemini Pro、Antropic 的 Claude 3.5 Sonnet 和 Meta 的 LLaMA3.1 等，它们在自然语言处理和多模态能力方面表现出色。此外，生成式 AI (Generative AI) 的突破，包括文本到图像和文本到视频生成模型如 Midjourney、DALL-E 3、Stable Diffusion、FLUX.1 和 Sora，极大地拓展了 AI 的创造潜力。\n\n随着研究继续致力于开发更高效、可解释和功能强大的模型，AI 和深度学习对社会和技术的影响将不断加深。这些技术进步不仅推动了传统行业的创新，还为创造性表达、问题解决和人机协作开辟了新可能。\n\n然而，深度学习并不是实现 AI 的唯一途径或最佳途径。符号 AI、强化学习和神经符号 AI 各自具有独特优势，并能弥补深度学习在可解释性和计算资源需求方面的不足。对 AI 的全面理解应涵盖这些多样化的方法。\n\nAI 的未来在于多种方法的协同效应。随着研究的深入，构建多元化的 AI 技术生态系统将确保其平衡和有效的发展，从而造福社会和科技领域。\n\n本文章已经生成可运行项目\n\n确定要放弃本次机会？\n\n福利倒计时\n\n*:*\n*:*\n\n立减 ¥\n\n普通VIP年卡可用\n\n[立即使用](https://mall.csdn.net/vip)\n\n[JarodYv](https://jarod.blog.csdn.net)\n\n[关注](javascript:;)\n关注\n\n* 49\n\n  点赞\n* 踩\n* [89](javascript:;)\n\n  收藏\n\n  觉得还不错?\n  一键收藏\n* [2](#commentBox)\n\n  评论\n* [分享](javascript:;)\n\n  复制链接\n\n  分享到 QQ\n\n  分享到新浪微博\n\n  扫一扫\n* [打赏](javascript:;)\n\n  打赏\n* 打赏\n  举报\n\n  举报\n\n专栏目录\n\n[*人工智能*（*AI*）*简史*：推动新时代的科技力量](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[qq\\_17153885的博客](https://blog.csdn.net/qq_17153885)\n\n12-31\n\n1万+\n\n[*人工智能*（*AI*，Artificial Intelligence）是计算机科学的一个分支，旨在研究和开发可以模拟、扩展或增强人类智能的系统。它涉及多种技术和方法，包括*机器学习*、*深度学习*、自然语言处理（NLP）、计算机视觉、专家系统等。](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[最全*AI**简史*（下）：后*深度学习*时代（*大模型*时代）](https://blog.csdn.net/jpw41/article/details/141403498)\n\n[jpw41的博客](https://blog.csdn.net/jpw41)\n\n08-21\n\n2914\n\n[💡 铺垫这么多终于到*大模型*章节了，前面两篇文章分别就*人工智能*和*深度学习*的发展历史进行了介绍，大致可以理解为：20世纪的*人工智能*发展百花齐放、坎坷中前进，进入21世纪后*深度学习*很快成为*人工智能*中的显学，2020年后则以大语言模型为代表范式。这当然不是说一些逻辑规则的、概率统计*机器学习*的甚至是非*Transformer*的*深度学习*结构已经逐渐推出历史舞台，相反大家各自在自己的领域依然是SOTA，也与*大模型*有许多交汇的地方。](https://blog.csdn.net/jpw41/article/details/141403498)\n\n2\xa0条评论\n您还未登录，请先\n登录\n后发表或查看评论\n\n[*AI*进化史*:*从图灵测试到ChatGPT](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n1-30\n\n[*AI**发展史*是一部人类探索智能本质、拓展认知边界的壮丽史诗,而我们正身处其中最具变革性的章节。DeepSeek等新一代*AI*力量的加入,正在书写着这段历史的新篇章。](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n[*人工智能*(Artificial Intelligence, *AI*)\\_*ai**发展史* csdn](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n1-20\n\n[机器翻译领域出现“ALPAC报告”*:*1966年,美国政府因机器翻译进展缓慢(如“the spirit is willing but the flesh is weak”被译为“酒是好的,但肉已变质”),停止资助相关研究,引发第一次*AI*寒冬。 1970s*:*符号主义局限性显现(如无法处理模糊、非结构化问题),加上计算能力不足,科研 funding 锐减,进入第一次*AI*寒冬。](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[CSDN\\_430422的博客](https://blog.csdn.net/CSDN_430422)\n\n07-21\n\n4621\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[收藏级！史上最通俗的*AI*发展历程综述（附*大模型*学习指南）\n\n最新发布](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[大模型教程的博客](https://blog.csdn.net/Z987421)\n\n12-27\n\n556\n\n[规则式*AI*的死板问题，催生了"让机器自主学习规律"的需求——*机器学习*（ML）技术应运而生，标志着*AI*从"规则驱动"迈入"数据驱动"时代。机器从数据中总结出的规律，最终会形成一个"可复用的计算模型"——这就是*AI*模型（Model）。对程序员而言，可理解为"一个经过数据训练的函数，输入新数据就能输出判断结果"。*AI*模型三大核心要素： - 输入：新的待处理数据（如收到的新邮件）；- 处理：用学到的规律对数据进行分析；- 输出：明确的结果（如"垃圾邮件"或"正常邮件"）。](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[*人工智能*发展*简史*, 没想到17世纪*AI*就出现了!\\_17世纪中叶*人工智能*-CSDN...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n12-17\n\n[本文回顾了*人工智能*的发展历程,从17世纪笛卡尔的构想到20世纪中叶图灵测试的提出,再到达特茅斯会议的*人工智能*定义。文章详细介绍了*AI*在商业、游戏、自动驾驶等领域的应用,以及近年来*深度学习*和无监督学习的重大突破。 部署运行你感兴趣的模型镜像一键部署 *人工智能**发展史* ...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n[*人工智能**发展史*\\_*人工智能*的夏天](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n1-17\n\n[Judea Pearl发表于1988年的名著将概率论和决策理论引入*AI*。现已投入应用的新工具包括贝叶斯网络,隐马尔可夫模型,信息论,随机模型和经典优化理论。针对*神经网络*和进化算法等“计算智能”范式的精确数学描述也被发展出来。 大数据*:*2005 - 现在 从某种意义上讲,2005年是大数据元年,虽然大部分人感受不到数据带来的变化,但是...](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n[*Ai**发展史*(个人理解)梳理](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[记录 IT 领域经验与见解的博客](https://blog.csdn.net/q6115759)\n\n04-17\n\n2355\n\n[在21世纪初期，随着计算机硬件的不断提升和大规模数据的出现，*深度学习*成为*人工智能*领域的热门研究方向。总之，*人工智能*是一项非常重要的技术，将对我们的生活和工作产生深远的影响。随着*人工智能*应用场景的不断增多，*人工智能*将更加个性化和定制化，可以根据不同用户的需求提供不同的服务。4. *人工智能*将更加智能和自主。随着*人工智能*技术的不断进步，*人工智能*将更加智能和自主，可以自主学习和决策，提高*人工智能*的效率和智能性。随着*人工智能*应用场景的不断增多，*人工智能*将更加注重安全和隐私，保护用户的数据和信息安全。](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[*人工智能**发展史*](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[JIA\\_NG\\_FA\\_N的博客](https://blog.csdn.net/JIA_NG_FA_N)\n\n06-08\n\n7819\n\n[起步发展期：1943年—20世纪60年代反思发展期：20世纪70年代应用发展期：20世纪80年代平稳发展期：20世纪90年代—2010年蓬勃发展期：2011年至今。](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[最全科普｜万字长文论*人工智能*的前世今生（下篇）](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[GentelAi的博客](https://blog.csdn.net/GentelAi)\n\n03-12\n\n1306\n\n[到1976年，MYCIN的开发工作基本完成，其诊断准确率达到65%-70%，甚至超过了一些人类医生的表现，成为*人工智能*领域的里程碑。1980年，美国数字设备公司（DEC）开发了XCON（eXpert CONfigurer），这是一个用于配置计算机系统的专家系统，成功帮助公司自动化复杂的计算机配置流程，显著降低了配置错误和成本，成为专家系统商业化的成功案例。Word2Vec的提出不仅显著提升了自然语言处理（NLP）任务的性能，也为后续的语言模型（如BERT和GPT）奠定了基础，成为NLP领域的里程碑。](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[一文了解*大模型*：*AI*（*人工智能*）的发展历程](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[m0\\_56255097的博客](https://blog.csdn.net/m0_56255097)\n\n08-23\n\n4429\n\n[*AI**大模型*作为*人工智能*领域的重要技术突破，正成为推动各行各业创新和转型的关键力量。抓住*AI**大模型*的风口，掌握*AI**大模型*的知识和技能将变得越来越重要。学习*AI**大模型*是一个系统的过程，需要从基础开始，逐步深入到更高级的技术。这里给大家精心整理了一份全面的*AI**大模型*学习资源，包括：*AI**大模型*全套学习路线图（从入门到实战）、精品*AI**大模型*学习书籍手册、视频教程、实战学习、面试题等，资料免费分享！](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[看 *人工智能**简史*](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[我相信......](https://blog.csdn.net/wireless_com)\n\n02-25\n\n2819\n\n[这个春节有些心神不定，只得靠读书和学习平复心情。《*人工智能**简史*》去年很火，在京东的销售榜中也很考前，未能免俗，自己抽空读了一遍，随记随想。（图片来自百度百科）过去只是序幕。*人工智能*缘起达特茅斯会议，在...](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[*AI**发展史*：从图灵机到*AI*大时代](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[m0\\_59164304的博客](https://blog.csdn.net/m0_59164304)\n\n05-21\n\n5806\n\n[*AI*无疑是近年来最热门的话题了，它以一种前所末有的速度影响我们的生活。然而,*AI*的发展历程并非一蹴而就,它经历了漫长的探索和曲折。本期,我们将回顾*AI*的发展历程。](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[*人工智能*与*深度学习*发展*简史*：从感知器到多模态*大模型*的技术演进](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*（*AI*）与*深度学习*的*发展史*，是一部融合数学、计算机科学、神经科学、认知心理学与工程实践的宏大叙事，其演进不仅体现了人类对智能本质的持续追问，更深刻重塑了技术范式、产业格局与社会运行逻辑。...](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*发展*简史*：从1943年M-P模型到21世纪*深度学习*爆发](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[资源摘要信息*:**人工智能*发展*简史*1所涵盖的知识点，系统性地勾勒出*人工智能*学科从思想萌芽到学科正式确立的关键演进脉络，其核心在于揭示人类如何在数学、逻辑学、神经生理学、计算机科学与认知科学的交叉融合中，逐步...](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[*AI**发展史*：从*神经网络*到*大模型*的演进之路](https://wenku.csdn.net/doc/706v1gz262)\n\n[本文以“*AI* *简史*：从*神经元*到*现代**大模型*”为题，系统梳理了从早期人工*神经网络*到当前主流*深度学习*架构的关键节点，涵盖了从理论奠基到实际应用的完整脉络，并提供了可运行的源码示例，使得开发者不仅能理解原理，还...](https://wenku.csdn.net/doc/706v1gz262)\n\n[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https://wenku.csdn.net/column/2fcd64w82r)\n\n[[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https*:*//online.visual-paradigm.com/repository/images/06393536-dbad-4462-982f-7661c65029ea/timeline-diagram-design/.png) # 1. *人工智能*...](https://wenku.csdn.net/column/2fcd64w82r)\n\n[*人工智能*发展*简史*：从图灵机、达特茅斯会议到*神经网络*与控制论的演进](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[而麦克洛奇与皮茨于1943年提出的MP*神经元*模型，则是首次用数学微分方程与阈值逻辑模拟生物*神经元*电生理活动的开创性尝试，它虽高度简化，却构建起连接主义范式的原始框架，成为后世感知机、反向传播算法及深度神经...](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[赫布理论](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[qq\\_31374615的博客](https://blog.csdn.net/qq_31374615)\n\n09-21\n\n3958\n\n[赫布理论\n本词条缺少名片图，补充相关内容使词条更完整，还能快速升级，赶紧来编辑吧！\n赫布理论（英语：Hebbian theory）描述了突触可塑性的基本原理，即突触前*神经元*向突触后*神经元*的持续重复的刺激可以导致突触传递效能的增加。这一理论由唐纳德·赫布于1949年提出，又被称为赫布定律（Hebb\'s\nrule）、赫布假说（Hebb\'s postulate）、细胞结集理论（cel](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[*人工智能**简史*\\_*人工智能**简史*](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[科技博客的分析“工具人”](https://blog.csdn.net/cxq8989)\n\n07-10\n\n387\n\n[*人工智能**简史* 在*人工智能*的早期，计算机科学家试图在计算机中重建人类思维的各个方面。 这就是科幻小说中的智力类型，即或多或少像我们一样思考的机器。 毫无疑问，这种类型的智能称为可理解性。 具有可理解性的计算机可用于探索我们如何推理，学习，判断，感知和执行脑力活动。\n可懂度的早期研究集中于在计算机中对现实世界和思维（来自认知科学家的领域）的部分进行建模。 当您考虑到这些实验是在60年前进行的时...](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[*人工智能*（*AI*）的发展历程](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[juzhi14plus的博客](https://blog.csdn.net/juzhi14plus)\n\n08-30\n\n2797\n\n[综上所述，人类在创造*人工智能*这一新物种的过程中，必须从伦理道德、法律监管、技术创新、教育和培训等方面进行应对，以确保*人工智能*的发展符合人类的利益和价值观，为人类社会的发展带来更多的机遇和福祉。十年后的 1966 年，麻省理工学院的约瑟夫・魏泽鲍姆开发了一款名为 ELIZA 的聊天机器人，这款机器人能够与人类进行简单的对话，为以后突破人类与机器之间的沟通障碍迈出了重要一步。*人工智能*的发展给人类带来了巨大的机遇和挑战，人类在创造这一新物种的过程中，必须采取积极有效的措施进行应对。](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[四张图片道清*AI**大模型*的*发展史*(1943-2023)\n\n热门推荐](https://keziyi.blog.csdn.net/article/details/132310317)\n\n[weixin\\_47567401的博客](https://blog.csdn.net/weixin_47567401)\n\n08-16\n\n1万+\n\n[快速了解大规模语言模型的发展历程](https://keziyi.blog.csdn.net/article/details/132310317)\n\n* [关于我们](//www.csdn.net/company/index.html#about)\n* [招贤纳士](//www.csdn.net/company/index.html#recruit)\n* [商务合作](https://fsc-p05.txscrm.com/T8PN8SFII7W)\n* [寻求报道](//marketing.csdn.net/questions/Q2202181748074189855)\n* 400-660-0108\n* [kefu@csdn.net](mailto:webmaster@csdn.net)\n* [在线客服](https://csdn.s2.udesk.cn/im_client/?web_plugin_id=29181)\n* 工作时间\xa08:30-22:00\n\n* [公安备案号11010502030143](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502030143)\n* [京ICP备19004658号](http://beian.miit.gov.cn/publish/query/indexFirst.action)\n* [京网文〔2020〕1039-165号](https://csdnimg.cn/release/live_fe/culture_license.png)\n* [经营性网站备案信息](https://csdnimg.cn/cdn/content-toolbar/csdn-ICP.png)\n* [北京互联网违法和不良信息举报中心](http://www.bjjubao.org/)\n* [家长监护](https://download.csdn.net/tutelage/home)\n* [网络110报警服务](https://cyberpolice.mps.gov.cn/)\n* [中国互联网举报中心](http://www.12377.cn/)\n* [Chrome商店下载](https://chrome.google.com/webstore/detail/csdn%E5%BC%80%E5%8F%91%E8%80%85%E5%8A%A9%E6%89%8B/kfkdboecolemdjodhmhmcibjocfopejo?hl=zh-CN)\n* [账号管理规范](https://blog.csdn.net/blogdevteam/article/details/126135357)\n* [版权与免责声明](https://www.csdn.net/company/index.html#statement)\n* [版权申诉](https://blog.csdn.net/blogdevteam/article/details/90369522)\n* [出版物许可证](https://img-home.csdnimg.cn/images/20250103023206.png)\n* [营业执照](https://img-home.csdnimg.cn/images/20250103023201.png)\n* ©1999-2026北京创新乐知网络技术有限公司\n\n登录后您可以享受以下权益：\n\n* 免费复制代码\n* 和博主大V互动\n* 下载海量资源\n* 发动态/写文章/加入社区\n\n×\n\n评论\xa02\n\n被折叠的\xa0\xa0条评论\n[为什么被折叠?](https://blogdev.blog.csdn.net/article/details/122245662)\n[到【灌水乐园】发言](https://bbs.csdn.net/forums/FreeZone)\n\n查看更多评论\n\n添加红包\n\n发出的红包\n\nJarodYv\n\n¥1\n¥2\n¥4\n¥6\n¥10\n¥20\n\n扫码支付：¥1\n\n您的余额不足，请更换扫码支付或[充值](https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip)\n\n打赏作者\n\n实付元\n\n扫码支付\n\n钱包余额\n0\n\n1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。  \n 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。\n\n[余额充值](https://i.csdn.net/#/wallet/balance/recharge)\n\n确定取消\n\n举报\n\n* 包含不实信息\n* 涉及个人隐私\n\n请选择具体原因（必选）\n\n* 侮辱谩骂\n* 诽谤\n\n请选择具体原因（必选）\n\n* 搬家样式\n* 博文样式\n\n[点击体验  \nDeepSeekR1满血版](https://ai.csdn.net/chat?utm_source=cknow_pc_blogdetail&spm=1001.2101.3001.10583) \n专业的中文 IT 技术社区，与千万技术人共成长\n客服\n返回顶部', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://blog.csdn.net/jarodyv/article/details/144699658', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99694854, 'save_path': None}}, {'paper_id': '', 'title': '人工智能的起源、发展和未来 - SK hynix Newsroom', 'authors': [], 'abstract': None, 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://news.skhynix.com.cn/all-about-ai-the-origins-evolution-future-of-ai/', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99648935, 'save_path': None}}, {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '![](https://en.wikipedia.org/static/images/donate/donate.gif)\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n\n# 人工智能史\n\n**人工智能的历史**源远流长。在古代的[神话](/wiki/%E7%A5%9E%E8%A9%B1 "神话")[传说](/wiki/%E4%BC%A0%E8%AF%B4 "传说")中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](/wiki/%E9%9B%BB%E8%85%A6 "电脑")的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n\n1956年，[人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")的研究领域确立于在[达特茅斯学院](/wiki/%E8%BE%BE%E7%89%B9%E8%8C%85%E6%96%AF%E5%AD%A6%E9%99%A2 "达特茅斯学院")举行的[会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2]](#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")（也被称作AI之冬）。由于[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")爵士的批评和国会方面的压力，[美国](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3]](#cite_note-3)\n\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "强人工智慧")的机器至今仍未出现。[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4]](#cite_note-TuringQuote-4)\n\n在21世纪的第一个十年，[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n## 目录\n\n## 先驱\n\n奥特曼写道[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](/wiki/%E8%87%AA%E5%8B%95%E6%A9%9F "自动机")）的实践之中。[[5]](#cite_note-FOOTNOTEMcCorduck20045–35-5)\n\n### 神话，幻想和预言中的AI\n\n[希腊神话](/wiki/%E5%B8%8C%E8%85%8A%E7%A5%9E%E8%AF%9D "希腊神话")中已经出现了机械人和人造人，如[赫淮斯托斯](/wiki/%E8%B5%AB%E6%B7%AE%E6%96%AF%E6%89%98%E6%96%AF "赫淮斯托斯")的黄金机器人和[皮格马利翁](/wiki/%E7%9A%AE%E6%A0%BC%E9%A9%AC%E5%88%A9%E7%BF%81 "皮格马利翁")的[伽拉忒亚](/wiki/%E4%BC%BD%E6%8B%89%E5%BF%92%E4%BA%9A "伽拉忒亚")。[[6]](#cite_note-6)中世纪出现了使用巫术或[炼金术](/wiki/%E7%82%BC%E9%87%91%E6%9C%AF "炼金术")将意识赋予无生命物质的传说，如[贾比尔](/wiki/%E8%B4%BE%E6%AF%94%E5%B0%94 "贾比尔")的*Takwin*，[帕拉塞尔苏斯](/wiki/%E5%B8%95%E6%8B%89%E5%A1%9E%E5%B0%94%E8%8B%8F%E6%96%AF "帕拉塞尔苏斯")的[何蒙库鲁兹](/wiki/%E4%BD%95%E8%92%99%E5%BA%93%E9%B2%81%E5%85%B9 "何蒙库鲁兹")和Judah Loew的[魔像](/wiki/%E9%AD%94%E5%83%8F "魔像")。[[7]](#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](/wiki/%E7%8E%9B%E4%B8%BD%C2%B7%E9%9B%AA%E8%8E%B1 "玛丽·雪莱")的《[弗兰肯斯坦](/wiki/%E5%BC%97%E5%85%B0%E8%82%AF%E6%96%AF%E5%9D%A6 "弗兰肯斯坦")》和[卡雷尔·恰佩克](/wiki/%E5%8D%A1%E9%9B%B7%E5%B0%94%C2%B7%E6%81%B0%E4%BD%A9%E5%85%8B "卡雷尔·恰佩克")的《罗素姆的万能机器人》。[[8]](#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9]](#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。\n\n### 自动人偶\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)\n\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师](/wiki/%E5%81%83%E5%B8%88 "偃师")（中国西周）[[10]](#cite_note-10)，[希罗](/wiki/%E5%B8%8C%E7%BD%97 "希罗")（希腊）[[11]](#cite_note-11)，[加扎利](/wiki/%E5%8A%A0%E6%89%8E%E5%88%A9 "加扎利")[[12]](#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13]](#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](/wiki/%E5%8F%A4%E5%9F%83%E5%8F%8A "古埃及")和[古希腊](/wiki/%E5%8F%A4%E5%B8%8C%E8%85%8A "古希腊")的[圣像](/wiki/%E8%81%96%E5%83%8F "圣像")，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")（[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")）写道“当发现神的本性时，人就能够重现他”[[14]](#cite_note-14)[[15]](#cite_note-15)。\n\n### 形式推理\n\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](/wiki/%E4%BA%9A%E9%87%8C%E5%A3%AB%E5%A4%9A%E5%BE%B7 "亚里士多德")（对三段论逻辑进行了形式分析），[欧几里得](/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97 "欧几里得")（其著作《[几何原本](/wiki/%E5%87%A0%E4%BD%95%E5%8E%9F%E6%9C%AC "几何原本")》是形式推理的典范），[花剌子密](/wiki/%E8%8A%B1%E5%89%8C%E5%AD%90%E5%AF%86 "花剌子密")（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E7%9A%84%E5%A8%81%E5%BB%89 "奥卡姆的威廉")和[邓斯·司各脱](/wiki/%E9%82%93%E6%96%AF%C2%B7%E5%8F%B8%E5%90%84%E8%84%B1 "邓斯·司各脱")。[[16]](#cite_note-Berlinski_2000-16)\n\n[马略卡](/wiki/%E9%A9%AC%E7%95%A5%E5%8D%A1 "马略卡")哲学家[拉蒙·柳利](/wiki/%E6%8B%89%E8%92%99%C2%B7%E6%9F%B3%E5%88%A9 "拉蒙·柳利")（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17]](#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18]](#cite_note-18)Llull的工作对[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")产生了很大影响，后者进一步发展了他的思想。[[19]](#cite_note-19)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/250px-Gottfried_Wilhelm_von_Leibniz.jpg)\n\n在17世纪中，[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")，[托马斯·霍布斯](/wiki/%E6%89%98%E9%A9%AC%E6%96%AF%C2%B7%E9%9C%8D%E5%B8%83%E6%96%AF "托马斯·霍布斯")和[笛卡儿](/wiki/%E7%AC%9B%E5%8D%A1%E5%84%BF "笛卡儿")尝试将理性的思考系统化为代数学或几何学那样的体系。[[20]](#cite_note-20)霍布斯在其著作《[利维坦](/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF) "利维坦 (霍布斯)")》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21]](#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](/wiki/%E9%80%9A%E7%94%A8%E8%A1%A8%E6%84%8F%E6%96%87%E5%AD%97 "通用表意文字")），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22]](#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n\n在20世纪，[数理逻辑](/wiki/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91 "数理逻辑")研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](/wiki/%E4%B9%94%E6%B2%BB%C2%B7%E5%B8%83%E5%B0%94 "乔治·布尔")的《思维的定律》与[弗雷格](/wiki/%E6%88%88%E7%89%B9%E6%B4%9B%E5%B8%83%C2%B7%E5%BC%97%E9%9B%B7%E6%A0%BC "戈特洛布·弗雷格")的《[概念文字](/wiki/%E6%A6%82%E5%BF%B5%E6%96%87%E5%AD%97 "概念文字")》。基于弗雷格的系统，[罗素](/wiki/%E7%BD%97%E7%B4%A0 "罗素")和[怀特海](/wiki/%E6%80%80%E7%89%B9%E6%B5%B7 "怀特海")在他们于1913年出版的巨著《[数学原理](/wiki/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86 "数学原理")》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9 "希尔伯特")，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16]](#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")，[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")和[Alonzo Church](/wiki/Alonzo_Church "Alonzo Church")的[λ演算](/wiki/%CE%9B%E6%BC%94%E7%AE%97 "Λ演算")给出。[[16]](#cite_note-Berlinski_2000-16)[[23]](#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)\n\n[邱奇-图灵论题](/wiki/%E9%82%B1%E5%A5%87-%E5%9B%BE%E7%81%B5%E8%AE%BA%E9%A2%98 "邱奇-图灵论题")暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16]](#cite_note-Berlinski_2000-16)[[24]](#cite_note-24)\n\n### 计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](/wiki/%E6%9F%A5%E5%B0%94%E6%96%AF%C2%B7%E5%B7%B4%E8%B4%9D%E5%A5%87 "查尔斯·巴贝奇")设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](/wiki/%E6%84%9B%E9%81%94%C2%B7%E5%8B%92%E8%8A%99%E8%95%BE%E7%B5%B2 "爱达·勒芙蕾丝")预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25]](#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%95%B0 "伯努利数")的方法。）\n\n第一批现代计算机是[二战](/wiki/%E4%BA%8C%E6%88%98 "二战")期间建造的大型译码机（包括Z3，[ENIAC](/wiki/ENIAC "ENIAC")和Colossus等）。[[26]](#cite_note-26)后两个机器的理论基础是[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")和[约翰·冯·诺伊曼](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC "约翰·冯·诺伊曼")提出和发展的学说。[[27]](#cite_note-27)\n\n## 人工智能的诞生：1943 - 1956\n\n[[28]](#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n### 控制论与早期神经网络\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/250px-BRL61-IBM_702.jpg)\n\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](/wiki/%E8%AF%BA%E4%BC%AF%E7%89%B9%C2%B7%E7%BB%B4%E7%BA%B3 "诺伯特·维纳")的[控制论](/wiki/%E6%8E%A7%E5%88%B6%E8%AE%BA "控制论")描述了电子网络的控制和稳定性。[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")提出的[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")则描述了[数字信号](/wiki/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7 "数字信号")（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29]](#cite_note-29)\n\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30]](#cite_note-30)\n\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")”的学者。[[31]](#cite_note-31)[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](/w/index.php?title=SNARC&action=edit&redlink=1 "SNARC（页面不存在）")。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n### 游戏AI\n\n1951年，[克里斯托弗·斯特雷奇](/wiki/%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%BC%97%C2%B7%E6%96%AF%E7%89%B9%E9%9B%B7%E5%A5%87 "克里斯托弗·斯特雷奇")使用[曼彻斯特大学](/wiki/%E6%9B%BC%E5%BD%BB%E6%96%AF%E7%89%B9%E5%A4%A7%E5%AD%A6 "曼彻斯特大学")的Ferranti Mark 1机器写出了一个[西洋跳棋](/wiki/%E8%A5%BF%E6%B4%8B%E8%B7%B3%E6%A3%8B "西洋跳棋")（checkers）程序；[迪特里希·普林茨](/w/index.php?title=%E8%BF%AA%E7%89%B9%E9%87%8C%E5%B8%8C%C2%B7%E6%99%AE%E6%9E%97%E8%8C%A8&action=edit&redlink=1 "迪特里希·普林茨（页面不存在）")（Dietrich Prinz）则写出了一个[国际象棋](/wiki/%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B "国际象棋")程序。[[32]](#cite_note-32)[亚瑟·李·塞谬尔](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E6%9D%8E%C2%B7%E5%A1%9E%E8%AC%AC%E7%88%BE "亚瑟·李·塞谬尔")（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33]](#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。\n\n### 图灵测试\n\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34]](#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试")：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35]](#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。\n\n### 符号推理与“逻辑理论家”程序\n\n50年代中期，随着数位计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36]](#cite_note-36)\n\n1955年，[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和后来荣获诺贝尔奖的[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")在J. C. Shaw的协助下开发了“[逻辑理论家](/wiki/%E9%80%BB%E8%BE%91%E7%90%86%E8%AE%BA%E5%AE%B6 "逻辑理论家")（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37]](#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](/wiki/%E5%BF%83%E8%BA%AB%E4%BA%8C%E5%88%86%E6%B3%95 "心身二分法")，解释了物质构成的系统如何获得心灵的性质。”[[38]](#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92 "约翰·罗杰斯·希尔勒")称为“强人工智能”，即机器可以像人一样具有思想。）[[39]](#cite_note-39)\n\n### 1956年达特茅斯会议：AI的诞生\n\n1956年[达特矛斯会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")[[40]](#cite_note-40)的组织者是[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")，[约翰·麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")和另两位资深科学家[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](/wiki/IBM "IBM")。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41]](#cite_note-41)与会者包括[雷·索罗门诺夫](/w/index.php?title=%E9%9B%B7%C2%B7%E7%B4%A2%E7%BE%85%E9%96%80%E8%AB%BE%E5%A4%AB&action=edit&redlink=1 "雷·索罗门诺夫（页面不存在）")（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42]](#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")则说服与会者接受“人工智能”一词作为本领域的名称。[[43]](#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44]](#cite_note-44)\n\n## 第一波浪潮 - 黄金年代：1956 - 1974\n\n[达特矛斯](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45]](#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46]](#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47]](#cite_note-47) [DARPA](/wiki/DARPA "DARPA")（[国防高等研究计划署](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")）等政府机构向这一新兴领域投入了大笔资金。[[48]](#cite_note-48)\n\n### 研究工作\n\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n#### 搜索式推理\n\n许多AI程序使用相同的基本[算法](/wiki/%E7%AE%97%E6%B3%95 "算法")。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95 "回溯法")。这就是“搜索式推理”。[[49]](#cite_note-49)\n\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95 "启发式算法")去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50]](#cite_note-50)\n\n艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](/wiki/%E4%B8%80%E8%88%AC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%99%A8 "一般问题解决器")（General Problem Solver）”程序，将这一算法推广到一般情形。[[51]](#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52]](#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](/wiki/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6 "斯坦福大学")为控制机器人Shakey而开发的STRIPS系统。[[53]](#cite_note-53)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)\n\n#### 自然语言\n\nAI研究的一个重要目标是使计算机能够通过[自然语言](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理")（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54]](#cite_note-54)\n\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](/wiki/%E8%AF%AD%E4%B9%89%E7%BD%91 "语义网")（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55]](#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56]](#cite_note-56)\n\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57]](#cite_note-57)\n\n#### 微世界\n\n60年代后期，[麻省理工大学](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")AI实验室的马文·闵斯基和[西摩尔·派普特](/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9 "西摩尔·派普特")建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58]](#cite_note-58)\n\n在这一指导思想下，[杰拉德·杰伊·萨斯曼](/wiki/%E5%82%91%E6%8B%89%E5%BE%B7%C2%B7%E5%82%91%E4%BC%8A%C2%B7%E8%96%A9%E6%96%AF%E6%9B%BC "杰拉德·杰伊·萨斯曼")（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](/w/index.php?title=%E5%A4%A7%E8%A1%9B%C2%B7%E7%93%A6%E7%88%BE%E8%8C%B2&action=edit&redlink=1 "大卫·瓦尔兹（页面不存在）")（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](/wiki/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89 "机器视觉")领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](/wiki/SHRDLU "SHRDLU")，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59]](#cite_note-59)\n\n### 乐观思潮\n\n第一代AI研究者们曾作出了如下预言:\n\n### 经费\n\n1963年6月，[MIT](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64]](#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](/wiki/%E5%8D%A1%E5%86%85%E5%9F%BA%E6%A2%85%E9%9A%86%E5%A4%A7%E5%AD%A6 "卡内基梅隆大学")的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65]](#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](/wiki/%E7%88%B1%E4%B8%81%E5%A0%A1%E5%A4%A7%E5%AD%A6 "爱丁堡大学")建立。[[66]](#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67]](#cite_note-67)\n\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68]](#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](/wiki/Hacker "Hacker")文化的形成，[[69]](#cite_note-69)但是好景不长。\n\n## 第一次AI低谷：1974 - 1980\n\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70]](#cite_note-70)同时，由于马文·闵斯基对[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")的激烈批评，[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")（即[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")）销声匿迹了十年。[[71]](#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](/wiki/%E9%80%BB%E8%BE%91%E7%BC%96%E7%A8%8B "逻辑编程")，常识推理等一些领域还是有所进展。[[72]](#cite_note-72)\n\n### 问题\n\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73]](#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74]](#cite_note-74)\n\n### 停止拨款\n\n由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81]](#cite_note-81)1973年[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82]](#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83]](#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84]](#cite_note-84)到了1974年已经很难再找到对AI项目的资助。\n\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85]](#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86]](#cite_note-86)\n\n### 来自大学的批评\n\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")已经证明[形式系统](/wiki/%E5%BD%A2%E5%BC%8F%E7%B3%BB%E7%BB%9F "形式系统")（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87]](#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88]](#cite_note-88)[[89]](#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间")”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](/wiki/%E6%84%8F%E5%90%91%E6%80%A7 "意向性")（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90]](#cite_note-90)\n\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](/wiki/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7 "计算复杂性")和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91]](#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92]](#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93]](#cite_note-93)\n\n约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94]](#cite_note-94)\n\n### 感知器与联结主义遭到冷落\n\n[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")是[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71]](#cite_note-Perceptrons-71)\n\n### “简约派（the neats）”：逻辑，Prolog语言和专家系统\n\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95]](#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96]](#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](/wiki/Prolog "Prolog")。[[97]](#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](/w/index.php?title=%E7%94%9F%E7%94%A2%E8%A6%8F%E5%89%87&action=edit&redlink=1 "生产规则（页面不存在）")（英语：[Production\\_system\\_(computer\\_science)](https://en.wikipedia.org/wiki/Production_system_(computer_science) "en:Production system (computer science)")）”密切相关的“[霍恩子句](/wiki/%E9%9C%8D%E6%81%A9%E5%AD%90%E5%8F%A5 "霍恩子句")”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](/wiki/%E6%84%9B%E5%BE%B7%E8%8F%AF%C2%B7%E8%B2%BB%E6%A0%B9%E9%AE%91%E5%A7%86 "爱德华·费根鲍姆")的[专家系统](/wiki/%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1 "专家系统")以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")及[认知统一理论](/wiki/%E8%AA%8D%E7%9F%A5%E7%B5%B1%E4%B8%80%E7%90%86%E8%AB%96 "认知统一理论")。[[98]](#cite_note-98)\n\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](/wiki/%E9%98%BF%E6%91%A9%E5%8F%B8%C2%B7%E7%89%B9%E6%B2%83%E6%96%AF%E5%9F%BA "阿摩司·特沃斯基")，Daniel Kahneman等人的实验证明了这一点。[[99]](#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100]](#cite_note-100)\n\n### “芜杂派（the scruffies）”：框架和脚本\n\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101]](#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102]](#cite_note-102)\n\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103]](#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n## 第二波浪潮 - 繁荣：1980—1987\n\n在80年代，一类名为“[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n### 专家系统获得赏识\n\n[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104]](#cite_note-104)\n\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105]](#cite_note-105)\n\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106]](#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107]](#cite_note-107)\n\n### 知识革命\n\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108]](#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109]](#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110]](#cite_note-110)\n\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111]](#cite_note-111)\n\n### 重获拨款：第五代工程\n\n1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](/wiki/%E7%AC%AC%E4%BA%94%E4%BB%A3%E9%9B%BB%E8%85%A6 "第五代电脑")项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112]](#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](/wiki/Prolog "Prolog")作为该项目的主要编程语言。[[113]](#cite_note-113)\n\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114]](#cite_note-114)[[115]](#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116]](#cite_note-116)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/250px-Hopfield-net.png)\n\n### 联结主义的重生\n\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 "反向传播算法")，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115]](#cite_note-Norvig_25-115)[[117]](#cite_note-117)\n\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86 "分布式并行处理")”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115]](#cite_note-Norvig_25-115)[[118]](#cite_note-118)\n\n## 第二次AI低谷：1987—1993\n\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n### 人工智慧的低谷\n\n“[AI之冬](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119]](#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120]](#cite_note-120)\n\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")）））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121]](#cite_note-121)\n\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122]](#cite_note-122)\n\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123]](#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123]](#cite_note-FifthGenEnd-123)\n\n### 躯体的重要性：Nouvelle AI与嵌入式推理\n\n80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124]](#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](/wiki/%E8%8E%AB%E6%8B%89%E7%B6%AD%E5%85%8B%E6%82%96%E8%AB%96 "莫拉维克悖论")）。[[125]](#cite_note-125)他们号召“[自底向上](/wiki/%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%92%8C%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%A8%AD%E8%A8%88 "自上而下和自下而上设计")”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。\n\n另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126]](#cite_note-126)\n\n在发表于1990年的论文“大象不玩象棋（Elephants Don\'t Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](/wiki/%E7%89%A9%E7%90%86%E7%AC%A6%E8%99%9F%E7%B3%BB%E7%B5%B1 "物理符号系统")”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127]](#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](/wiki/%E9%AB%94%E5%8C%96%E8%AA%8D%E7%9F%A5 "体化认知")（embodied mind/reason/cognition）”论题。[[128]](#cite_note-128)\n\n## 第三波浪潮 - 大数据与机器学习：1993—2019\n\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129]](#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。\n\n### 里程碑和摩尔定律\n\n1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](/wiki/%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BE%85%E5%A4%AB "卡斯帕罗夫")的第一个计算机系统。[[130]](#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131]](#cite_note-131)2009年，[蓝脑计画](/wiki/%E8%97%8D%E8%85%A6%E8%A8%88%E7%95%AB "蓝脑计画")声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](/w/index.php?title=IBM_%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%A8%8B%E5%BA%8F)&action=edit&redlink=1 "IBM 沃森 (人工智慧程序)（页面不存在）")参加《[危险边缘](/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98 "危险边缘")》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](/wiki/AlphaGo "AlphaGo")击败[李世乭](/wiki/%E6%9D%8E%E4%B8%96%E4%B9%AD "李世乭")，成为第一个不让子而击败职业[围棋](/wiki/%E5%9C%8D%E6%A3%8B "围棋")棋士的[电脑围棋](/wiki/%E7%94%B5%E8%84%91%E5%9B%B4%E6%A3%8B "电脑围棋")程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](/wiki/%E4%B8%AD%E5%9B%BD%E4%B9%8C%E9%95%87%E5%9B%B4%E6%A3%8B%E5%B3%B0%E4%BC%9A "中国乌镇围棋峰会")的三局比赛中击败[[132]](#cite_note-wuzhensecond-132)当时世界排名第一[[133]](#cite_note-133)[[134]](#cite_note-134)的中国棋手[柯洁](/wiki/%E6%9F%AF%E6%B4%81 "柯洁")。\n\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135]](#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136]](#cite_note-136)这种剧烈增长可以用[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n### 智能代理\n\n90年代，被称为“[智能代理](/wiki/%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86 "智能代理")”的新范式被广泛接受。[[137]](#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138]](#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139]](#cite_note-R27-139)当经济学中的“[理性代理](/wiki/%E7%90%86%E6%80%A7%E4%B8%BB%E4%BD%93 "理性主体")（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140]](#cite_note-140)\n\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](/w/index.php?title=%E4%BB%A3%E7%90%86%E6%9E%B6%E6%9E%84&action=edit&redlink=1 "代理架构（页面不存在）")（英语：[Agent\\_architecture](https://en.wikipedia.org/wiki/Agent_architecture "en:Agent architecture")）（像Newell的[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139]](#cite_note-R27-139)[[141]](#cite_note-141)\n\n### “简约派”的胜利\n\n越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142]](#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143]](#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144]](#cite_note-RN25-144)[[145]](#cite_note-145)\n\nJudea Pearl发表于1988年的名著[[146]](#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C "贝叶斯网络")，[隐马尔可夫模型](/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B "隐马尔可夫模型")，[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144]](#cite_note-RN25-144)\n\n### 幕后的AI\n\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147]](#cite_note-147)这些解决方案在产业界起到了重要作用。[[148]](#cite_note-148)应用了AI技术的有[数据挖掘](/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98 "数据挖掘")，[工业机器人](/wiki/%E5%B7%A5%E4%B8%9A%E6%9C%BA%E5%99%A8%E4%BA%BA "工业机器人")，[物流](/wiki/%E7%89%A9%E6%B5%81 "物流")[[149]](#cite_note-149)，[语音识别](/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB "语音识别")[[150]](#cite_note-150)，银行业软件[[151]](#cite_note-CNN7242006-151)，医疗诊断[[151]](#cite_note-CNN7242006-151)和[Google](/wiki/Google "Google")搜索引擎等。[[152]](#cite_note-152)\n\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153]](#cite_note-153)[尼克·博斯特罗姆](/wiki/%E5%B0%BC%E5%85%8B%C2%B7%E5%8D%9A%E6%96%AF%E7%89%B9%E7%BD%97%E5%A7%86 "尼克·博斯特罗姆")解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154]](#cite_note-154)\n\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](/wiki/%E4%BF%A1%E6%81%AF%E5%AD%A6 "信息学")，[知识系统](/w/index.php?title=%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "知识系统（页面不存在）")，[认知系统](/w/index.php?title=%E8%AE%A4%E7%9F%A5%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "认知系统（页面不存在）")或[计算智能](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD&action=edit&redlink=1 "计算智能（页面不存在）")。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155]](#cite_note-155)[[156]](#cite_note-156)[[157]](#cite_note-157)\n\n### HAL 9000在哪里?\n\n1968年[亚瑟·克拉克](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E5%85%8B%E6%8B%89%E5%85%8B "亚瑟·克拉克")和[史丹利·库柏力克](/wiki/%E5%8F%B2%E4%B8%B9%E5%88%A9%C2%B7%E5%BA%AB%E6%9F%8F%E5%8A%9B%E5%85%8B "史丹利·库柏力克")创作的《“[2001太空漫游](/wiki/2001%E5%A4%AA%E7%A9%BA%E6%BC%AB%E6%B8%B8 "2001太空漫游")”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158]](#cite_note-158)\n\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159]](#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")））。[[160]](#cite_note-160)[雷蒙德·库茨魏尔](/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94 "雷蒙德·库茨魏尔")相信问题在于计算机性能，根据[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")，他预测具有人类智能水平的机器将在2029年出现。[[161]](#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162]](#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n### 深度学习，大数据和通用人工智能：2011至2019\n\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n#### 深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](/wiki/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86 "MNIST数据集")（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n#### 大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n## 第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n### 大型语言模型\n\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](/wiki/ChatGPT "ChatGPT")基于[GPT-3.5](/wiki/GPT-3 "GPT-3")架构的[大型语言模型](/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B "大型语言模型")并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，[GPT-4](/wiki/GPT-4 "GPT-4")正式推出，进一步加强大型语言模型的推理能力。2023年8月，中国百度公司向公众开放使用[文心一言](/wiki/%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80 "文心一言")，让中国内地民众都可以使用内地版的大型语言模型。2025年1月，[深度求索](/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2 "深度求索")推出著名的[DeepSeek-R1](/wiki/DeepSeek-R1 "DeepSeek-R1") [开源](/wiki/%E9%96%8B%E6%BA%90 "开源")大型语言模型，并使用新的算法减低训练成本。\n\n### 机器人整合与人工智能的实际应用（2025年至今）\n\n先进的人工智能（AI）系统能够高精度理解和回应人类对话，已成熟到能够与机器人无缝整合，改变了制造业、医疗保健、公共服务和材料研究等行业。[[163]](#cite_note-163) 人工智能还通过高级数据分析和假设生成加速科学研究。[[164]](#cite_note-164) 包括中国、美国和日本在内的国家在政策和资金方面进行了大量投资，以部署人工智能驱动的机器人和人工智能的实际应用，解决劳动力短缺问题，促进创新并提高效率，同时实施监管框架以确保道德和安全发展。[[165]](#cite_note-165)\n\n#### 中国\n\n2025年被誉为“人工智能机器人年”，标志著人工智能（AI）与机器人无缝整合的关键时刻。在2025年，中国投资约7300亿元人民币（约1000亿美元）用于智能制造和医疗保健领域的人工智能和机器人技术发展。[[166]](#cite_note-166) [[167]](#cite_note-167) 第十四个五年规划（2021-2025年）优先发展服务机器人，人工智能系统使机器人能够执行复杂任务，例如协助手术或自动化工厂装配线。[[168]](#cite_note-168) 例如，中国医院中的人工智能人形机器人可以解读患者请求、运送物资并协助护士完成日常任务，显示现有的人工智能对话能力足以应用于实际的机器人应用。部分资金还支持国防应用，例如自主无人机。[[169]](#cite_note-169)[[170]](#cite_note-170) 自2025年9月起，中国要求对人工智能生成的内容进行标记，以确保技术的透明度和公众信任。[[171]](#cite_note-171)\n\n#### 美国\n\n2025年1月，人工智能基础设施投资取得重大进展，[星际之门计划](/wiki/%E6%98%9F%E9%99%85%E4%B9%8B%E9%97%A8%E8%AE%A1%E5%88%92 "星际之门计划") 成立。这家由 [OpenAI](/wiki/OpenAI "OpenAI")、[SoftBank Group](/wiki/SoftBank_Group "SoftBank Group")、[Oracle](/wiki/Oracle_Corporation "Oracle Corporation") 和 [MGX](/w/index.php?title=MGX_Fund_Management_Limited&action=edit&redlink=1 "MGX Fund Management Limited（页面不存在）") 组成的合资企业宣布计划到2029年在[美国](/wiki/%E7%BE%8E%E5%9C%8B "美国")投资5000亿美元用于人工智能基础设施，首期投资1000亿美元，以支持美国的再工业化并提供保护美国及其盟友国家安全的战略能力。[[172]](#cite_note-172) 该合资企业于2025年1月21日由美国总统唐纳德·特朗普正式宣布，SoftBank Group首席执行官 [孙正义](/wiki/%E5%AD%AB%E6%AD%A3%E7%BE%A9 "孙正义") 被任命为主席。[[173]](#cite_note-reuters-173)[[174]](#cite_note-174)\n\n美国政府拨款约20亿美元用于在制造业和物流业中整合人工智能和机器人技术，利用人工智能处理自然语言和执行用户指令的能力。[[175]](#cite_note-175) 各州政府补充资金支持服务机器人，例如部署在仓库中执行口头指令进行库存管理，或在养老院中回应居民的援助请求。[[176]](#cite_note-176) 这些应用表明，将已经熟练于人类交互的高级人工智能与机器人硬体结合是一项实际的前进步骤。\n\n2025年1月，第14179号行政命令确立了“人工智能行动计划”，以加速这些技术的创新和部署。[[177]](#cite_note-177)\n\n#### 影响\n\n2020年代各国政府和机构对AI的投资加速了人工智能的发展，推动了科学进步，提高了劳动效率，并通过自动化复杂任务改变了各行业。[[178]](#cite_note-178) 通过将成熟的人工智能系统整合到各行业的应用当中，这些发展有望彻底改变智能制造和服务行业，重塑人类的日常生活。\n\n## 注释\n\n## 参考文献\n\n`|date=`\n`|date=`\n`|date=`\n\n.\n\n![](https://zh.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=mobile&type=1x1&usesul3=1)\n\n#### 语言\n\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n\n* [![Wikimedia Foundation](/static/images/footer/wikimedia.svg)](https://www.wikimedia.org/)\n* [![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)](https://www.mediawiki.org/)\n\n![Wikimedia Foundation](/static/images/footer/wikimedia.svg)\n![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9957684, 'save_path': None}}, {'paper_id': '', 'title': '人工智能发展简史', 'authors': [], 'abstract': '[设为首页](###)[加入收藏](###)[手机版](//wap.cac.gov.cn/)[繁体](/###)\n\n* ### [首 页](//www.cac.gov.cn/index.htm)\n* ### [时政要闻](//www.cac.gov.cn/yaowen/szyw/A093601index_1.htm)\n* ### [网信政务](//www.cac.gov.cn/wxzw/A0937index_1.htm)\n* ### [互动服务](//www.cac.gov.cn/hdfw/A0938index_1.htm)\n* ### [热点专题](//www.cac.gov.cn/gzzt/ztzl/A092001index_1.htm)\n\n当前位置：[首页](/)>[正文](javascript:void(0);)\n\n* [首页](//wap.cac.gov.cn/phoneindex.htm)\n* [时政要闻](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=1)\n* [网信政务](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=2)\n* [互动服务](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=3)\n* [热点专题](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=4)\n\n# 人工智能发展简史\n\n2017年01月23日 11:10 来源： 网络传播杂志 \n\n[【打印】](javascript:window.print())【纠错】\n\n“人工智能之父” 艾伦·图灵。\n\n**1、 人工智能的诞生（20世纪40～50年代）**\n\n\u3000\u30001950年：图灵测试\n\n\u3000\u30001950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n\n\u3000\u30001954年：第一台可编程机器人诞生\n\n\u3000\u30001954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n\n\u3000\u30001956年：人工智能诞生\n\n\u3000\u30001956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n\n\u3000\u30001966年~1972年：首台人工智能机器人Shakey诞生\n\n\u3000\u30001966年~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n\n\u3000\u30001966年：世界上第一个聊天机器人ELIZA发布\n\n\u3000\u3000美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n\n\u3000\u30001968年：计算机鼠标发明\n\n\u3000\u30001968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n\n**3、 人工智能的低谷（20世纪70～80年代）**\n\n\u3000\u300020世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n\n\xa0\xa0\xa0\xa01997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n\n**4、 人工智能的繁荣期（1980年~1987年）**\n\n\u3000\u30001981年：日本研发人工智能计算机\n\n\u3000\u30001981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n\n\u3000\u30001984年：启动Cyc（大百科全书）项目\n\n\u3000\u3000在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n\n\u3000\u30001986年：3D打印机问世\n\n\u3000\u3000美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n\n**5、 人工智能的冬天（1987年~1993年）**\n\n\u3000\u3000“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n\n**6、 人工智能真正的春天（1993年至今）**\n\n\u3000\u30001997年：电脑深蓝战胜国际象棋世界冠军\n\n\u3000\u30001997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n\n\u3000\u30002011年：开发出使用自然语言回答问题的人工智能程序\n\n\u3000\u30002011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n\n\u3000\u30002012年：Spaun诞生\n\n\u3000\u3000加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n\n\u3000\u30002013年：深度学习算法被广泛运用在产品开发中\n\n\u3000\u3000Facebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n\n\u3000\u30002015年：人工智能突破之年\n\n\u3000\u3000Google开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n\n\u3000\u30002016年：AlphaGo战胜围棋世界冠军李世石\n\n\u3000\u30002016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）\n\n\xa02016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n\n**大事记**\n\n\u3000\u3000① 1942年：“机器人三定律”提出\n\n\u3000\u3000美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。\n\n\u3000\u3000② 1956年：人工智能的诞生\n\n\u3000\u3000达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n\n\u3000\u3000③ 1959年：第一代机器人出现\n\n\u3000\u3000德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n\n\u3000\u3000④ 1965年：兴起研究“有感觉”的机器人\n\n\u3000\u3000约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n\n\u3000\u3000⑤ 1968年：世界第一台智能机器人诞生\n\n\u3000\u3000美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n\n\u3000\u3000⑥ 2002年：家用机器人诞生\n\n\u3000\u3000美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n\n\u3000\u3000⑦ 2014年：机器人首次通过图灵测试\n\n\u3000\u3000在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n\n\u3000\u3000⑧ 2016年：AlphaGo打败人类\n\n\u3000\u30002016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。\n\n关闭\n\n中央网络安全和信息化委员会办公室 中华人民共和国国家互联网信息办公室 © 版权所有 [联系我们](//www.cac.gov.cn/hdfw/lxwm/A093812index_1.htm)\n\n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司\u3000[京ICP备14042428号](https://beian.miit.gov.cn/)\u3000[京公网安备11040102700108号](https://www.beian.gov.cn//www.cac.gov.cn/registerSystemInfo?recordcode=11040102700108)\n\n* ###### 学习强国\n\n  *◆* ◆\n* ###### 微信\n\n  *◆* ◆\n* ###### 返回顶部\n\n中华人民共和国国家互联网信息办公室 © 版权所有\n\nProduced By CMS 网站群内容管理系统 publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9931496, 'save_path': None}}, {'paper_id': '', 'title': '人工智能70年：科幻和現實的交融 - BBC', 'authors': [], 'abstract': '[BBC News, \n中文](/zhongwen/trad)\n\n**人類**\n**飛跑著**\n**進入**\n**人工智能（**\n**AI**\n**）**\n**時代。**\n**粗略估算現在人們日常生活中有20多種尋常的**\n**AI**\n**，從垃圾郵件過濾器到叫車軟件。**\n\nAI被分為兩類，這些執行具體任務的AI屬於「弱人工智能」；另一類「強人工智能」，又稱「通用人工智能」（AGI） ，能夠模仿人類思維、決策，有自我意識，自主行動。這一類目前主要出現在科幻作品中，還沒有成為科學現實。\n\n* [聊天機器人最難理解的十大詞匯](/ukchina/trad/vert-fut-46424329)\n* [假如人工智能（AI）有靈魂：這意味著什麼](/ukchina/trad/vert-fut-44641617)\n* [AI和媒體 機器與記者編輯的多重關係](/zhongwen/trad/science-45591003)\n* [人工智能面臨的最大挑戰不是技術？](/ukchina/trad/vert-fut-39433415)\n\n埃德利安·梅耶（Adrienne Mayor）在《諸神與機器人》（Gods and Robots）甚至把希臘古城亞歷山大港稱為最初的硅谷，因為那裏曾經是無數機器人的家園。\n\n[Skip 熱讀 and continue reading](#end-of-recommendations)\n\n**熱讀**\n\n* [美國愛潑斯坦性侵案：解密文件披露百多名政商名人](/zhongwen/trad/world-67890505)\n* [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](https://www.bbc.com/zhongwen/articles/cvgrmn683pro/trad)\n* [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](https://www.bbc.com/zhongwen/articles/cn0y72184yko/trad)\n* [為何中國如此迅速處決明氏家族11人？](https://www.bbc.com/zhongwen/articles/c5yvzn83ye1o/trad)\n\nEnd of 熱讀\n\n除了古希臘、羅馬，其他古文明也不乏人類對"複製自己"的探索。猶太人傳說中有生命的泥人，印度傳說中，守衛佛祖舍利子的機器人武士（模仿古希臘羅馬自動人形機的設計）；佛教傳入前日本的神照神社，中國的兵馬俑，後來又有了達芬奇的機器人武士、會下象棋的木頭人"土耳其"，等等。雖然跟現在一般理解的人工智能似乎風馬牛不相干，但這些嘗試都體現了人類複製、模擬自身的夢想。\n\n不過，法國索邦大學計算機學教授讓-加布裏埃爾·加納西亞（Jean-Gabriel Ganascia）認為，古代神話中人形物體被賦予生命，與今天人們想象和擔憂的「通用人工智能」，即具有超級智能的機器，都更多屬於想象而不是科學現實，至少目前如此。\n\n在開創人工智能學科的先驅者心目中，AI的初衷是用機器來模擬人類、動植物和物種種群的演變，這個學科立足於這樣一種猜想：所有認知功能都可以被精確描述，從而有可能在計算機上複製。\n\n作為現代科技學科的AI歷史很短，但不乏跌宕坎坷。\n\n* [「無頭屍」引發爭議：殺死機器人是否可能](/ukchina/trad/47655496)\n* [人工智能公司為什麼要不停的砸玻璃？](/ukchina/trad/vert-fut-38841260)\n* [「柔情」機器人：人類怎麼對機器人動了真感情](/ukchina/trad/vert-cap-44495182)\n\n## 1940年代——奠基\n\n1943年，美國神經科學家麥卡洛克（Warren McCulloch）和邏輯學家皮茨（Water Pitts）提出神經元的數學模型。後來有人說現代AI夢就誕生在那個時候。\n\n那個夢是一篇題目繞口的論文，《神經活動中內在思想的邏輯演算》（A Logical Calculus of Ideas Immanent in Nervous Activity）。這篇論文被視為人工智能學科的奠基石。現在大熱的「深度學習」，前身是人工神經網絡，而其基礎就是神經元的數學模型。\n\n這篇論文的發表也標誌著人工智能學科三大派之一的仿生學派誕生。這個學派從神經網絡的連接機制著手來發展人工智能，被稱為連接主義派，後來符號邏輯派佔上風幾十年，神經仿生派一直到二十世紀八、九十年代才翻身，以新連接主義面目復興。\n\nAI的另一塊基石是加拿大神經心理學家赫布（Donald Hebb）1949年提出「赫布規則」，簡單說就是兩個細胞如果總是同時被激活，那麼它們之間就有某種關聯，關聯度與同時激活概率成正比關係。這個規則今天用在機器自動學習算法中。\n\n* [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n\n## 1950年代——起步\n\n現在人們普遍把1956年叫做AI元年。人工智能作為一門學科，在這個時期起步並取得了早期成功。\n\n**圖靈和圖靈機**\n\n英國電腦奇才、密碼學家、邏輯學家、計算機與人工智能之父圖靈（Alan Turing）曾想，機器能不能模仿人類的認知、學習過程，用邏輯推理和已有的信息來解決問題，作出決定？他1936年提出圖靈機的設想，就是一種抽象計算模型，實質上是一種數學邏輯機。\n\n1950年，圖靈發表《計算機與智能》（Computing Machineray and Intelligence）論文，文中闡述了"模仿遊戲"的設想和測試方式，就是後來大家熟知的圖靈測試。這篇文章是對機器模仿人類智能的深度思考和系統論述。\n\n**達特茅斯人工智能夏季研討會**\n\n人工智能（artificial intelligence）這個詞1955年首次亮相。當時4位AI鼻祖寫了一份提案，申請開一個研討會研究人工智能。他們估計兩個月，10個人參加，就足以取得重大突破。他們是麥卡錫（John McCarthy）、明斯基（Marvin Minsky）、羅切斯特（Nathaniel Rochester）和香農（Claude Shannon）。\n\n申請獲准，暑期研討會於1956年8月31日在新罕布什爾州達特茅斯學院召開。\n\n研討會被普遍 視為人工智能作為一門學科的創立，所以這一年算AI元年。\n\n**早期**\n**成果**\n\nAI元年後，喜訊不斷。1957年，GPS（通用問題解決器）設想問世。這個設想的原理是任何形式化的符號問題都可以用這個電腦程序來解決。提出設想的是美國卡內基梅隆大學教授、認知心理學和計算機專家紐厄爾（Allen Newell）、西蒙（Herbert A. Simon）和肖。這個設想屬於邏輯、符號派。在短短60年時間裏也經歷了冷暖。\n\n1959年，麥卡錫提出世界上第一個完整的AI系統。那是他在《具備常識的程序》中提出的能像人類一樣學習的假想程序，"Advice Taker"。同年，他和明斯基牽頭在MIT成立了人工智能實驗室。\n\n也是在這一年，塞繆爾首創了機器學習這個概念。他1956年寫的跳棋程序具有自學能力，是世界第一個。\n\n* [人工智能：嚇壞創造者的「深度造假寫手」](/zhongwen/trad/science-47361632)\n* [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n* [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n\n## 1960年——伊莉莎\n\n1961年，世界第一款工業機器人Unimate在美國新澤西的通用電氣工廠上崗試用。1966年，第一台能移動的機器人Shakey問世，就是那個會抽煙的機器人。跟Shakey同年出生的還有伊莉莎。\n\n1966年問世的伊莉莎（Eliza）可以算作今天亞馬遜語音助手Alexa、谷歌助理和蘋果語音助手Siri們的祖母，可以跟人進行書面交流。\n\n「她」沒有人形，沒有聲音，就是一個簡單的機器人程序，通過人工編寫的DOCTOR腳本跟人類進行類似心理諮詢的交談。Eliza的「父親」，後來成為MIT教授的維森鮑姆（Joseph Weizenbaum）解釋說，用這個名字，是因為人們可以教這個程序學習掌握新的語言技能，談吐越來越優雅，就像《窈窕淑女》裏被調教得十分出色的賣花姑娘伊莉莎。\n\n伊莉莎問世時，機器解決問題和釋義語音語言的苗頭已經初露端倪。但是，抽象思維、自我認知和自然語言處理功能等人類智能對機器來說還遙不可及。\n\n半個多世紀後的今天，機器人索菲亞仍需依靠事先輸入的內容才能與人交流，但能說能笑能哭，而且是美女形象。\n\n**批評聲鵲起**\n\n這個時期出現了對人工智能的尖銳批評。\n\n《煉金術與人工智能》發表於1965年，作者德雷弗斯把這篇著名的檄文跟後來陸續寫的文章集成《計算機不能幹什麼》一書，後人凡批評AI必提此書。\n\n另一個刺耳的聲音來自古德（I. J. Good）。他1965年發表了一篇對人工智能未來可能對人類構成威脅的文章，可以算「AI威脅論」的先驅。他認為機器的超級智能和無法避免的智能爆炸最終將超出人類可控範疇。後來著名科學家霍金、發明家和實業家馬斯克對人工智能的恐怖預言跟古德半個世界前的警告遙相呼應。\n\n法國計算機學家加納西亞把這段時間稱為AI發展史上的"預言者時期"，因為學科初創並取得早期成果令人欣喜，難免說些頭腦發熱的話。\n\n流傳較廣的包括美國經濟學家西蒙（Herbert Simon司馬賀）1958年預言，再過10年機器就能問鼎國際象棋世界冠軍；結果是1997年才成真。另外，AI鼻祖明斯基在1968年《2001太空漫遊》記者會上說機器智能30年內可趕超人類 ，現在只是設想。\n\n1968年，科幻大片《2001太空漫遊》上映，導演庫布裏克對人類心靈深處那個古老的渴望做了太空時代的演繹。\n\n## 1970年代－機器人問診\n\n1970年，世界第一個擬人機器人WABOT-1在日本早稻田大學誕生。\n\n除此之外，這段時間AI領域基本上是埋頭科研，主要側重研究機器模擬記憶心理學和理解機制、知識和推理。因此，這個階段AI語義知識表示技術有長足進展，進而推動了專家系統的研發。\n\n專家系統利用一流專家的知識來再現他們的思維過程；從1980年代早期開始在醫療診斷和其他一些領域廣泛應用。\n\n1972年，針對細菌感染的醫療診斷系統MYCIN問世，凖確率69%，專科醫生是80%。1978年 ，用於電腦銷售過程中為顧客自動配置零部件的專家系統XCON誕生。XCON是第一個投入商用的AI專家，也是當時最成功的一款。\n\n1979年，斯坦福大學開始研發自動駕駛技術，但世界上第一次無人駕駛汽車完成首秀是在1986年；那是一輛奔馳麵包車，德國聯邦大學研製，車上有攝像機和感應裝置。它在無人的街道上行駛速度達55mph。\n\n## 1980年代——《終結者》\n\n數據和知識積累推動計算機學習算法發展，使機器能夠利用自己的經驗自動調整編程，AI的應用突飛猛進，如指紋、語音識別等。人工智能、計算機和人造生命開始和其他學科交融，生出混合系統。\n\n1984年，美國普林斯頓大學教授、物理學家、分子生物學家和神經學家霍普菲爾德用模擬集成電路實現了自己兩年前提出的神經網絡模型，這個模型帶動了神經網絡學派的復興。深度學習大熱並取得突破。\n\n同年，深度學習"三巨頭"辛頓（Geoffrey Hinton）、本吉奧（Yoshua Bengio）和楊立昆（Yann LeCun）發表反向傳播算法論文，開啟深度學習潮流。\n\n那年，卡梅隆大片《終結者》上映，作家布魯克斯（Rodney Allen Brooks）發表《大象不下棋》，提出更高層次的AI系統設想：在與環境互動的基礎上打造人工智能。\n\n人工智能三大源頭之一，哲學，又站到聚光燈下。1981年，美國哲學家、數學家與計算機科學家普特南（Hilary W. Putnam）發表《理性、真理與歷史》，提出著名的「缸中腦」假象試驗。\n\n這本身是一個哲學命題，缸中靠營養液存活、通過電腦接收各種刺激而產生感知的大腦，實際上就是虛擬現實。這個假想為人工智能提供了啟示，也引發了對人工智能的哲學思考，也催生了許多科幻作品，比如《盜夢空間》、《源代碼》和《阿凡達》。\n\n## AI的兩個冬季\n\n1974-1980年，1987-1993年，AI遭遇兩次寒冬。\n\n第一次是因為兩份學術報告發表，導致AI領域研究經費銳減。一份是1966年在美國自動語言處理顧問委員會（ALPAC）的《語言與機器：翻譯和語言學中的計算機》（Language and Machines: Computers in Translation and Linguistics），另一份是英國萊特希爾教授（Sir James Lighthill）1973年發表的《人工智能普查報告》。這兩份報告都表達了對先前的投資未能產生預期受益的失望，結論是不應該繼續往AI這個無底洞砸錢。\n\n不過，一線的科研仍在繼續，但直接說AI的少了，諸如機器學習、信息數學、基於知識的系統和模式識別之類新詞開始湧現。\n\n出現第二個冬季則是因為桌面電腦迅速普及，AI系統的金主，包括美國國防部，覺得投資AI性價比不高，興趣大減。但到20世紀末，AI領域再度春暖花開。標誌性事件是1997年IBM深藍大勝世界象棋冠軍卡斯帕洛夫。\n\n歷史上這兩次「錢荒」，跟AI研究資金來源較單一，主要來自政府給學術機構的科研撥款。隨著AI產業化加深，越來越多研發資金來自企業。但AI領域內部的混亂、門派紛爭、各自為政的問題依然存在。\n\n## 1990年代——聊天機器人\n\n1990年代後期，人工智能與機器人和人機界面結合，產生了具有情感和情緒的智能代理，情緒／情感計算（即評估情緒的變化然後在機器上再現）得以迅速發展，尤其是對話代理（聊天機器人）。\n\n1993年，維諾爾·溫奇發表《即將來臨的技術奇點》（The Coming Technological Singularity）一文，預言30年後人類將能夠創造具有超級智慧的機器，由此走上人類終結之路。這個時刻就是後來很多人說的「奇點」。數學家霍金和企業家馬斯克都是機器終結人類說法的信眾。\n\n但對於這個奇點究竟是否存在目前仍有不同看法。\n\n1997年，IBM的深藍超級電腦擊敗世界象棋冠軍卡斯帕洛夫，西蒙1958年的預言算是實現了，儘管晚了近40年。\n\n## 21世紀——深度學習\n\n進入21世紀，許多人工智能的能力已經超越人類，比如圍棋、德州撲克，比如證明數學定理，比如學習從海量數據中自動構建知識，識別語音、面孔、指紋，駕駛汽車，處理海量的文件、物流和製造業的自動化操作。\n\n機器人可以識別和模擬人類情緒，可以充當陪伴和護理員了。AI的應用也因此遍地開花，很快進入人類生活的各個領域。\n\n深度學習和強化學習成了時代強音。\n\n一個普遍認同的說法是，2012年的ImageNet年度挑戰開啟了這一輪AI復興浪潮，把深度學習和大數據推到前台，大量投資資金湧入。ImageNet是為視覺認知軟件研究而設計建立的大型視覺數據庫，由華裔AI科學家李飛飛2007年發起；她當時是普林斯頓大學教授。\n\nImageNet挑戰是每年一度的全行業比武，比誰家的電腦視覺算法最強。2012年奪冠的多倫多大學團隊的圖像識別軟件AlexNet錯誤率比第二名低10.8%。觀察人士總結秘密武器有3個：大數據、更強的電腦、更聰明的算法。\n\n李飛飛現為美國斯坦福大學教授、斯坦福大學人工智能實驗室與視覺實驗室負責人、谷歌雲人工智能和機器學習首席科學家，斯坦福以人為本人工智能研究院共同院長。\n\n另一個值得一提的名字是樊麾，生於中國，圍棋手，職業二段，現任法國圍棋隊總教練。他2015年10月與谷歌人工智能AlphaGO較量0:5敗於對方。他對BBC中文網表示，輸給機器的感覺終身難忘。\n\n過去10年中，人工智能開始寫新聞、搶獨家，經過海量數據訓練學會了識別貓，IBM超級電腦沃森戰勝了智力競賽兩任冠軍，谷歌阿爾法狗戰勝了圍棋世界冠軍，波士頓動力的機器人Atlas學會了三級障礙跳。沃森和阿爾法狗的秘訣都是強化學習。\n\n這個領域的鎮海寶典《深度學習》2015年發表，作者辛頓、本吉奧和楊立昆1980年代就合寫了同樣開行業先河的經典論文，闡述反向傳播算法，2019年獲圖靈獎。\n\n不得不提的是索菲亞。2017年這個擬人機器人亮相時艷驚天下，與人交談語言生動、深刻，沙特搶先給"她"發公民證，後來被楊立昆揭露是個騙局。\n\n因為，索菲亞雖然具備不少先進的技術，包括仿生材料做的皮膚和逼真的面部表情，與人互動時的共情反應，但她只會說事先輸入和設置的話，不具備人們以為她擁有的應用語言智能和思想意識。很快，索菲亞銷聲匿跡。\n\n現代科學誕生前，世界上有迷信，有工匠。然後科學和技術融合，科技和迷信並存；科技和迷信之間有一片寬闊地帶，繁茂地生長著科幻，小說、影視和藝術。\n\n深度學習似乎表明人類向複製自己的原始意願又邁進了一步；人工智能的發展將繼續跌宕起伏，而人與機器的關係、人工智能帶來的倫理挑戰日益成為AI領域的焦點話題。\n\n有人預言，幾百年後，世界上的智慧智能將由3部分組成：人類智能（AI）+人類可控的人工智能+人類不可控的機器智能。\n\n這一切又都離不開人類文明曙光初現時一個古老的夢想。\n\n想象和現實從來不可能一刀兩斷切割，科技和商業更是如影隨形，但區分人工智能（AI）和通用人工智能（AGI），或許有助於減緩第三次「AI寒冬」將至的擔憂和焦慮。\n\n**．**\n\n## 更多相關內容\n\n* ### [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* ### [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* ### [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n* ### [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n* ### [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* ### [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n\n## 頭條新聞\n\n* ### [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](/zhongwen/articles/cvgrmn683pro/trad)\n* ### [「代孕」引爆台灣社會爭論：誰的渴望，誰的風險？](/zhongwen/articles/clyz5pd20jvo/trad)\n* ### [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](/zhongwen/articles/cn0y72184yko/trad)\n\n## 特別推薦\n\n* ### [為什麼中國將英國首相施紀賢來訪視為更大局面的一部分？](/zhongwen/articles/c1m7y585x71o/trad)\n* ### [中國生育率破1新生數回到乾隆年間水平 預測失準後的斷崖式下跌](/zhongwen/articles/cr4kkydv75ro/trad)\n* ### [「時隔太久」：施紀賢習近平在北京「談及人權問題」](/zhongwen/articles/c368y7ex161o/trad)\n* ### [英國首相八年來首次訪華\u3000施紀賢亞洲行的時機和任務](/zhongwen/articles/cx2we08l9qpo/trad)\n* ### [中國調查解放軍最高級將領張又俠 官媒批其「造成極大破壞」](/zhongwen/articles/cx2k4pxdyyzo/trad)\n\n## 更多相關內容\n\n* ### [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* ### [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* ### [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n* ### [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n* ### [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* ### [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n\n## 頭條新聞\n\n* ### [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](/zhongwen/articles/cvgrmn683pro/trad)\n* ### [「代孕」引爆台灣社會爭論：誰的渴望，誰的風險？](/zhongwen/articles/clyz5pd20jvo/trad)\n* ### [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](/zhongwen/articles/cn0y72184yko/trad)\n\n## 特別推薦\n\n* ### [為什麼中國將英國首相施紀賢來訪視為更大局面的一部分？](/zhongwen/articles/c1m7y585x71o/trad)\n* ### [中國生育率破1新生數回到乾隆年間水平 預測失準後的斷崖式下跌](/zhongwen/articles/cr4kkydv75ro/trad)\n* ### [「時隔太久」：施紀賢習近平在北京「談及人權問題」](/zhongwen/articles/c368y7ex161o/trad)\n* ### [英國首相八年來首次訪華\u3000施紀賢亞洲行的時機和任務](/zhongwen/articles/cx2we08l9qpo/trad)\n* ### [中國調查解放軍最高級將領張又俠 官媒批其「造成極大破壞」](/zhongwen/articles/cx2k4pxdyyzo/trad)\n\n## 熱門內容\n\n1. 1\n\n   [美國愛潑斯坦性侵案：解密文件披露百多名政商名人](/zhongwen/trad/world-67890505)\n2. 2\n\n   [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](https://www.bbc.com/zhongwen/articles/cvgrmn683pro/trad)\n3. [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](https://www.bbc.com/zhongwen/articles/cn0y72184yko/trad)\n4. [為何中國如此迅速處決明氏家族11人？](https://www.bbc.com/zhongwen/articles/c5yvzn83ye1o/trad)\n\n7. [此前從未公開的愛潑斯坦島嶼新照片曝光](https://www.bbc.com/zhongwen/articles/cq60906prr3o/trad)\n9. [特權階層接連爆雷，中國網民震怒](https://www.bbc.com/zhongwen/articles/cdxl7w63p1po/trad)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.bbc.com/zhongwen/trad/science-48380424', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.96323055, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 13:24:41,761 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=9, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 13:24:41,764 - __main__ - INFO - handle_download: downloaded=7
2026-02-03 13:24:41,764 - __main__ - INFO - call_tool payload: source_tool=tavily_download, result_type=papers, count=7
2026-02-03 13:24:41,764 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=7
2026-02-03 13:24:41,765 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_[PDF] 人工智能.md'}}
2026-02-03 16:00:25,680 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': '人工智能的发展历史？'}
2026-02-03 16:00:25,681 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=人工智能的发展历史？, search_type=None
2026-02-03 16:00:25,716 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': '人工智能的发展历史？'}
2026-02-03 16:00:25,717 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=人工智能的发展历史？, search_type=None
2026-02-03 16:00:25,731 - __main__ - INFO - call_tool: name=tavily_search, args={'query': '人工智能的发展历史？'}
2026-02-03 16:00:25,732 - __main__ - INFO - handle_search: searcher=TavilySearch, query=人工智能的发展历史？, search_type=None
2026-02-03 16:00:29,783 - __main__ - INFO - handle_search: returned=10
2026-02-03 16:00:29,783 - __main__ - INFO - call_tool payload: source_tool=exa_context_search, result_type=papers, count=10
2026-02-03 16:00:29,783 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-03 16:00:29,784 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 16:00:32,771 - __main__ - INFO - handle_search: returned=3
2026-02-03 16:00:32,772 - __main__ - INFO - call_tool payload: source_tool=wikipedia_search, result_type=papers, count=3
2026-02-03 16:00:32,772 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=3
2026-02-03 16:00:32,772 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T16:00:32.771598', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 16:00:32', 'language': 'zh'}}
2026-02-03 16:00:34,620 - __main__ - INFO - handle_search: returned=10
2026-02-03 16:00:34,620 - __main__ - INFO - call_tool payload: source_tool=tavily_search, result_type=papers, count=10
2026-02-03 16:00:34,620 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-03 16:00:34,620 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': None}}
2026-02-03 16:00:59,699 - __main__ - INFO - call_tool: name=wikipedia_download, args={'papers': [{'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T16:00:32.771598', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 16:00:32', 'language': 'zh'}}, {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-03T16:00:32.771618', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-03 16:00:32', 'language': 'zh'}}, {'paper_id': '1468546', 'title': '通用人工智慧', 'authors': ['Wikipedia'], 'abstract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'doi': '', 'published_date': '2026-02-03T16:00:32.771625', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'pageid': 1468546, 'fetch_time': '2026-02-03 16:00:32', 'language': 'zh'}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 16:00:59,700 - __main__ - INFO - handle_download: searcher=WikipediaSearcher, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 16:00:59,700 - __main__ - INFO - handle_download: downloaded=3
2026-02-03 16:00:59,700 - __main__ - INFO - call_tool payload: source_tool=wikipedia_download, result_type=papers, count=3
2026-02-03 16:00:59,701 - __main__ - INFO - call_tool: name=wikipedia_download, result_type=papers, count=3
2026-02-03 16:00:59,701 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T16:00:32.771598', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 16:00:32', 'language': 'zh', 'saved_path': '/home/qinshan/widthresearch/data/downloads/wiki_317.md'}}
2026-02-03 16:00:59,710 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': None}}, {'paper_id': '', 'title': '谭铁牛：人工智能的历史、现状和未来 - 中国科学院', 'authors': [], 'abstract': '[PC](#) / [English](http://english.cas.cn) / [联系我们](//www.cas.cn/../../lx/) / [网站地图](//www.cas.cn/../../wz/) /[邮箱](//mail.cstnet.cn/) /[无障碍](javascript:void(0);) /[关怀版](javascript:EsdToolbarInit.elderly.open();)\n\n* [首页](//www.cas.cn/)\n* [组织机构](//www.cas.cn/../../zz/)\n\n  :   [主要职责](//www.cas.cn/../../zz/zyze/)\n  :   [院况简介](//www.cas.cn/../../zz/index.shtml#yk_scy)\n  :   [院领导集体](//www.cas.cn/../../zz/index.shtml#ha_zzjg)\n  :   [机构设置](//www.cas.cn/../../zz/index.shtml#hs_zzjg)\n* [科学研究](//www.cas.cn/../../kxyj/)\n\n  :   [科技专项](//www.cas.cn/../../kxyj/kjzx/)\n  :   [科技奖励](//www.cas.cn/../../kxyj/kj/)\n  :   [科技期刊](//www.cas.cn/../../kxyj/kjqk/)\n  :   [科研进展](//www.cas.cn/../../syky/)\n* [成果转化](//www.cas.cn/../../cg/)\n\n  :   [知识产权与科技成果转化网](http://www.casip.ac.cn/)\n  :   [工作动态](//www.cas.cn/../../cg/zh/)\n* [人才教育](//www.cas.cn/../../rcjy/)\n\n  :   [中国科学院教育简介](//www.cas.cn/../../rcjy/zkyjyjj/)\n  :   [中国科学技术大学](//www.cas.cn/../../rcjy/zkd/)\n  :   [中国科学院大学](//www.cas.cn/../../rcjy/gkd/)\n  :   [上海科技大学](//www.cas.cn/../../rcjy/skd/)\n  :   [工作动态](//www.cas.cn/../../rcjy/gz/)\n* [学部与院士](http://www.casad.cas.cn/)\n* [科学普及](//www.cas.cn/../../kx/)\n\n  :   [科学与中国](http://scicn.casad.cas.cn/)\n  :   [中国科普博览](http://www.kepu.cn/)\n  :   [科普场馆](//www.cas.cn/../../kx/kp/)\n  :   [工作动态](//www.cas.cn/../../kx/gz/)\n* [党建与科学文化](//www.cas.cn/../../djcx/)\n\n  :   [工作动态](//www.cas.cn/../../djcx/gz/)\n  :   [反腐倡廉](//www.cas.cn/../../djcx/ff/)\n  :   [文明天地](//www.cas.cn/../../djcx/wm/)\n* [信息公开](//www.cas.cn/../../xxgkml/)\n\n  :   [信息公开规定](//www.cas.cn/../../xxgkml/xxgkgzxx/xggd/qtgd/)\n  :   [信息公开指南](//www.cas.cn/../../xxgkml/xxgkgzxx/xggd/xxgkzn/)\n  :   [信息公开目录](//www.cas.cn/../../xxgkml/xxgkgzxx/xggd/xxgkml/)\n  :   [信息公开申请](//www.cas.cn/../../xxgkml/xxgksq/)\n  :   [信息公开联系方式](//www.cas.cn/../../xxgkml/xxgklxfs/)\n\n* [首页](//www.cas.cn/)\n* [组织机构](//www.cas.cn/../../zz/)\n* [科学研究](//www.cas.cn/../../kxyj/)\n* [成果转化](//www.cas.cn/../../cg/)\n* [人才教育](//www.cas.cn/../../rcjy/)\n* [学部与院士](http://www.casad.cas.cn/)\n* [科学普及](//www.cas.cn/../../kx/)\n* [党建与科学文化](//www.cas.cn/../../djcx/)\n* [信息公开](//www.cas.cn/../../xxgkml/)\n\n中国科学院贯彻落实党中央关于科技创新的方针政策和决策部署，在履行职责过程中坚持党中央对科技工作的集中统一领导。主要职责是：  \n\u3000\u3000一、开展使命导向的自然科学领域基础研究，承担国家重大基础研究、应用基础研究、前沿交叉共性技术研究和引领性颠覆性技术研究任务，打造原始创新策源地。 [更多+](//www.cas.cn/../../zz/zyze/202511/t20251114_5088877.shtml)\n\n中国科学院是国家科学技术界最高学术机构、国家科学技术思想库，自然科学基础研究与高技术综合研究的国家战略科技力量。  \n\u3000\u30001949年，伴随着新中国的诞生，中国科学院成立。建院70余年来，中国科学院时刻牢记使命，与科学共进，与祖国同行，以国家富强、人民幸福为己任，人才辈出，硕果累累，为我国科技进步、经济社会发展和国家安全作出了不可替代的重要贡献。 [更多+](//www.cas.cn/../../zz/yk/202511/t20251104_5087407.shtml)\n\n* [周\u3000琪](//www.cas.cn/zhouqi/)\n\n\n\n* [王\u3000华](//www.cas.cn/wanghua/)\n* [文\u3000亚](//www.cas.cn/wenya/)\n\n* ##### 院机关\n\n  [办公厅](https://go.cas.cn/)\n\n  [科技创新发展局](https://bdp.cas.cn/)\n\n  [基础科学研究局](https://bfse.cas.cn/)\n\n  [战略高技术研究局](https://bmrdp.cas.cn/)\n\n  [重大专项研究局](https://zdzx.cas.cn/)\n\n  [可持续发展科技研究局](https://sdr.cas.cn/)\n\n  [科技基础能力局](https://bsc.cas.cn/)\n\n  [学部工作局](https://casad.cas.cn/)\n\n  [人才与人事局](https://pe.cas.cn/)\n\n  [国际合作局](https://bic.cas.cn/)\n\n  [财务与资产管理局](https://bpf.cas.cn/)\n\n  [审计与监督局（党组巡视工作领导小组办公室）](https://jianshen.cas.cn/)\n\n  [机关党委](https://jgdw.cas.cn/)\n\n  [老专家老干部服务局](https://lt.cas.cn/)\n* ##### 派驻机构\n\n  [中央纪委国家监委驻中国科学院纪检监察组](https://jijianzu.cas.cn/)\n* ##### 分院\n\n  [沈阳分院](https://syb.cas.cn/)\n\n  [上海分院](https://shb.cas.cn/)\n\n  [武汉分院](https://whb.cas.cn)\n\n  [广州分院](https://gzb.cas.cn)\n\n  [成都分院](https://cdb.cas.cn)\n\n  [昆明分院](https://kmb.cas.cn)\n\n  [西安分院](https://xab.cas.cn)\n\n  [兰州分院](https://lzb.cas.cn)\n\n  [新疆分院](https://xjb.cas.cn)\n* ##### 院属机构\n\n  [研究单位](//www.cas.cn/../../zz/jg/ys/yj/)\n\n  [学校](//www.cas.cn/../../zz/jg/ys/xx/)\n\n  [管理与公共支撑单位](//www.cas.cn/../../zz/jg/ys/glzcdw/)\n\n  [新闻出版单位](//www.cas.cn/../../zz/jg/ys/xwdw/)\n\n  [其他单位](//www.cas.cn/../../zz/jg/ys/qt/)\n\n  [共建单位](//www.cas.cn/../../zz/jg/ys/gj/)\n\n  [院级非法人单元](//www.cas.cn/../../zz/jg/ys/ys/)\n\n  [所级分支机构](//www.cas.cn/../../zz/jg/ys/sjfzjg/)\n\n  [境外机构](//www.cas.cn/../../zz/jg/ys/jwjg/)\n\n  [群团和其他组织](//www.cas.cn/../../zz/jg/ys/xg/)\n\n科技奖励\n\n[科技奖励](//www.cas.cn/../../kxyj/kj/)\n\n* [国家最高科学技术奖](//www.cas.cn//kxyj/kj/zg/ "国家最高科学技术奖")\n* [国家自然科学奖](//www.cas.cn//kxyj/kj/zr/ "国家自然科学奖")\n* [国家技术发明奖](//www.cas.cn//kxyj/kj/js/ "国家技术发明奖")\n* [国家科学技术进步奖](//www.cas.cn//kxyj/kj/jb/ "国家科学技术进步奖<br/>")\n* [国家科学技术合作奖](//www.cas.cn//kxyj/kj/hz/ "国家科学技术合作奖")\n* [中国科学院杰出科技成就奖](//www.cas.cn//kxyj/kj/casjc/ "中国科学院杰出科技成就奖")\n* [中国科学院国际科技合作奖](//www.cas.cn//kxyj/kj/cashz/ "中国科学院国际科技合作奖")\n* [陈嘉庚科学奖](//www.cas.cn/http://www.tsaf.ac.cn/ "陈嘉庚科学奖")\n\n科技期刊\n\n[科技期刊](//www.cas.cn/../../kxyj/kjqk/)\n\n* [期刊导航](http://journals.cas.cn/pnav/ "期刊导航")\n* [数字平台](http://journals.cas.cn/platform/ "数字平台")\n* [期刊集群](http://journals.cas.cn/cluster/ "期刊集群")\n* [期刊动态](http://journals.cas.cn/notice/ "期刊动态")\n\n科技专项\n\n为方便科研人员全面快捷了解院级科技专项信息并进行项目申报等相关操作，特搭建中国科学院院级科技专项信息管理服务平台。了解科技专项更多内容，请点击进入→\n\n科研进展[/\xa0更多](//www.cas.cn/../../syky/)\n\n* [研究揭示心肌梗死过程中蛋白翻译调控心肌细胞铁死亡机制](//www.cas.cn/../../syky/202601/t20260127_5097313.shtml "研究揭示心肌梗死过程中蛋白翻译调控心肌细胞铁死亡机制")\n* [溶酶体酸性纳米层研究获进展](//www.cas.cn/../../syky/202601/t20260126_5097201.shtml "溶酶体酸性纳米层研究获进展")\n* [研究发现DNA糖苷酶TDG可作为p53缺失肿瘤的合成致死靶点](//www.cas.cn/../../syky/202601/t20260126_5097203.shtml "研究发现DNA糖苷酶TDG可作为p53缺失肿瘤的合成致死靶点")\n* [研究提出肝癌中胆汁酸代谢—免疫作用轴调控抗肿瘤免疫新机制](//www.cas.cn/../../syky/202601/t20260126_5097202.shtml "研究提出肝癌中胆汁酸代谢—免疫作用轴调控抗肿瘤免疫新机制")\n* [研究揭示信号受体途经高尔基体的短暂滞留机制](//www.cas.cn/../../syky/202601/t20260126_5097205.shtml "研究揭示信号受体途经高尔基体的短暂滞留机制")\n* [我国成功实现太空金属3D打印](//www.cas.cn/../../syky/202601/t20260123_5097065.shtml "我国成功实现太空金属3D打印")\n\n工作动态[/\xa0更多](//www.cas.cn/../../cg/zh/)\n\n* [青海盐湖所在碱性溶液萃取提锂关键技术上取得突破](//www.cas.cn/../../cg/zh/202601/t20260115_5096216.shtml "青海盐湖所在碱性溶液萃取提锂关键技术上取得突破")\n* [上海硅酸盐所3D打印硅基生物陶瓷口腔修复产品开发取得新进展](//www.cas.cn/../../cg/zh/202601/t20260112_5095833.shtml "上海硅酸盐所3D打印硅基生物陶瓷口腔修复产品开发取得新进展")\n* [“制氢+硫磺”，新技术助力工业绿色低碳发展](//www.cas.cn/../../cg/zh/202601/t20260107_5095421.shtml "“制氢+硫磺”，新技术助力工业绿色低碳发展")\n* [亿方级甲烷-二氧化碳干重整示范装置通过72小时标定考核](//www.cas.cn/../../cg/zh/202512/t20251226_5093799.shtml "亿方级甲烷-二氧化碳干重整示范装置通过72小时标定考核")\n* [国内首台套钢铁行业高炉煤气变压吸附碳捕集示范装置正式投运](//www.cas.cn/../../cg/zh/202512/t20251225_5093709.shtml "国内首台套钢铁行业高炉煤气变压吸附碳捕集示范装置正式投运")\n* [工程热物理所自主研发的循环流化床生物质气化制绿色液体燃料原料气技术示范工程投产](//www.cas.cn/../../cg/zh/202512/t20251218_5092810.shtml "工程热物理所自主研发的循环流化床生物质气化制绿色液体燃料原料气技术示范工程投产")\n\n* [大连化物所开发出100kWh级磷酸盐基钠离子电池储能系统并实现并网运行](//www.cas.cn/../../cg/zh/202512/t20251211_5092167.shtml "大连化物所开发出100kWh级磷酸盐基钠离子电池储能系统并实现并网运行")\n* [昆明分院等举办2025腾冲科学家论坛·科技创新成果展示与转化应用对接活动](//www.cas.cn/../../cg/zh/202512/t20251211_5092165.shtml "昆明分院等举办2025腾冲科学家论坛·科技创新成果展示与转化应用对接活动")\n* [山西煤化所等共同建设的千吨级高性能碳纤维项目竣工投产](//www.cas.cn/../../cg/zh/202512/t20251201_5090729.shtml "山西煤化所等共同建设的千吨级高性能碳纤维项目竣工投产")\n* [大连化物所“苯酚双氧水羟基化制苯二酚固定床新工艺”通过科技成果评价](//www.cas.cn/../../cg/zh/202511/t20251104_5087447.shtml "大连化物所“苯酚双氧水羟基化制苯二酚固定床新工艺”通过科技成果评价")\n* [低空智能交通技术及载运装备领域科技成果对接系列活动在穗举办](//www.cas.cn/../../cg/zh/202510/t20251030_5086716.shtml "低空智能交通技术及载运装备领域科技成果对接系列活动在穗举办")\n* [金属所举办“云南行”科技成果对接活动](//www.cas.cn/../../cg/zh/202510/t20251027_5086356.shtml "金属所举办“云南行”科技成果对接活动")\n\n* [中国科学技术大学（简称“中国科大”）于1958年由中国科学院创建于北京，1970年学校迁至安徽省合肥市。中国科大坚持“全院办校、所系结合”的办学方针，是一所以前沿科学和高新技术为主、兼有特色管理与人文学科的研究型大学。](//www.ustc.edu.cn/)\n* [中国科学院大学（简称“国科大”）始建于1978年，其前身为中国科学院研究生院，2012年经教育部批准更名为中国科学院大学。国科大实行“科教融合”的办学方针，与中国科学院直属研究机构（包括所、院、台、中心等），在管理体制、师资队伍、培养体系、科研工作等方面高度融合，是一所以研究生教育为主的独具特色的高等学校。](//www.ucas.ac.cn/)\n* [上海科技大学（简称“上科大”），由上海市人民政府与中国科学院共同举办、共同建设，由上海市人民政府主管，2013年经教育部正式批准。上科大致力于服务国家经济社会发展战略，培养科技创新创业人才，努力建设一所小规模、高水平、国际化的研究型、创新型大学。](//www.shanghaitech.edu.cn/)\n\n工作动态[/\xa0更多](//www.cas.cn/../../rcjy/gz/)\n\n* [国科大举办2025拾光奉献纪念典礼](//www.cas.cn/../../rcjy/gz/202601/t20260112_5095885.shtml "国科大举办2025拾光奉献纪念典礼")\n* [上海分院与上海交通大学签约开展战略合作](//www.cas.cn/../../rcjy/gz/202512/t20251230_5094552.shtml "上海分院与上海交通大学签约开展战略合作")\n* [2025年中国科大科教融合单位研究生教育工作总结交流会举办](//www.cas.cn/../../rcjy/gz/202512/t20251218_5092833.shtml "2025年中国科大科教融合单位研究生教育工作总结交流会举办")\n* [沈阳分院与大连理工大学举行工作交流](//www.cas.cn/../../rcjy/gz/202512/t20251218_5092832.shtml "沈阳分院与大连理工大学举行工作交流")\n* [云南省热带亚洲榕-蜂群落构建与利用国际联合实验室培训班举办](//www.cas.cn/../../rcjy/gz/202512/t20251201_5090728.shtml "云南省热带亚洲榕-蜂群落构建与利用国际联合实验室培训班举办")\n* [成都山地所与西南交通大学签署战略合作协议](//www.cas.cn/../../rcjy/gz/202511/t20251112_5088385.shtml "成都山地所与西南交通大学签署战略合作协议")\n\n科普场馆[/\xa0更多](//www.cas.cn/../../kx/kp/)\n\n* [中国科学院国家授时中心时间科学馆](//www.cas.cn/https://720yun.com/t/jlag4om4g7hndq89cy?pano_id=Nyj4UmWMfIAm5IsZ "中国科学院国家授时中心时间科学馆")\n* [中国科学院昆明动物研究所昆明动物博物馆](//www.cas.cn/http://museum.kiz.cas.cn/ "中国科学院昆明动物研究所昆明动物博物馆")\n* [中国科学院合肥物质科学研究院合肥现代科技馆](//www.cas.cn/http://kjg.hfcas.ac.cn/ "中国科学院合肥物质科学研究院合肥现代科技馆")\n* [中国科学院动物研究所国家动物博物馆](//www.cas.cn/http://www.kepu.net.cn/vmuseum/kpcg/bwg/bwg04.html "中国科学院动物研究所国家动物博物馆")\n* [中国科学院新疆生态与地理研究所生物标本馆](//www.cas.cn/http://www.kepu.net.cn/vmuseum/kpcg/bbg/bbg18.html "中国科学院新疆生态与地理研究所生物标本馆")\n* [中国科学院新疆生态与地理研究所新疆自然博物馆](//www.cas.cn/http://www.egi.cas.cn/yjpt/xjzrbwg/ "中国科学院新疆生态与地理研究所新疆自然博物馆")\n* [中国科学院南海海洋研究所南海海洋生物标本馆](//www.cas.cn/http://www.kepu.net.cn/vmuseum/kpcg/bbg/bbg17.html "中国科学院南海海洋研究所南海海洋生物标本馆")\n\n工作动态[/\xa0更多](//www.cas.cn/../../kx/gz/)\n\n* [“科学与中国”西部行——“千名院士·千场科普”行动在云南举办](//www.cas.cn/../../kx/gz/202512/t20251224_5093635.shtml "“科学与中国”西部行——“千名院士·千场科普”行动在云南举办")\n* [2025“科学与中国”院士专家巡讲团走进香港50所中小学校](//www.cas.cn/../../kx/gz/202512/t20251210_5092058.shtml "2025“科学与中国”院士专家巡讲团走进香港50所中小学校")\n* [2025年中国科学院科普讲解大赛举办](//www.cas.cn/../../kx/gz/202512/t20251201_5090915.shtml "2025年中国科学院科普讲解大赛举办")\n* [中国科学院举办2025年度科普工作骨干培训班](//www.cas.cn/../../kx/gz/202511/t20251128_5090611.shtml "中国科学院举办2025年度科普工作骨干培训班")\n* [2025年中国科学院科普讲解大赛即将启幕](//www.cas.cn/../../kx/gz/202511/t20251128_5090608.shtml "2025年中国科学院科普讲解大赛即将启幕")\n* [版纳植物园举办第十三届观鸟节](//www.cas.cn/../../kx/gz/202511/t20251127_5090275.shtml "版纳植物园举办第十三届观鸟节")\n* [福建物构所举办科学节活动](//www.cas.cn/../../kx/gz/202511/t20251125_5089867.shtml "福建物构所举办科学节活动")\n\n工作动态[/\xa0更多](//www.cas.cn/../../djcx/gz/)\n\n* [数学院田野院士成为《榜样10》党员先进典型](//www.cas.cn/../../djcx/gz/202601/t20260121_5096787.shtml "数学院田野院士成为《榜样10》党员先进典型")\n* [新疆分院分党组召开理论学习中心组学习会](//www.cas.cn/../../djcx/gz/202601/t20260127_5098680.shtml "新疆分院分党组召开理论学习中心组学习会")\n* [计算机网络信息中心党委理论学习中心组召开专题学习会](//www.cas.cn/../../djcx/gz/202601/t20260126_5097285.shtml "计算机网络信息中心党委理论学习中心组召开专题学习会")\n* [天津工生所召开党委理论学习中心组学习会](//www.cas.cn/../../djcx/gz/202601/t20260121_5096780.shtml "天津工生所召开党委理论学习中心组学习会")\n* [理化所召开党委理论学习中心组集体学习会](//www.cas.cn/../../djcx/gz/202601/t20260119_5096485.shtml "理化所召开党委理论学习中心组集体学习会")\n* [昆明分院分党组理论学习中心组召开学习扩大会](//www.cas.cn/../../djcx/gz/202601/t20260116_5096424.shtml "昆明分院分党组理论学习中心组召开学习扩大会")\n* [武汉岩土所召开2025年度党（总）支部书记述职考评会](//www.cas.cn/../../djcx/gz/202601/t20260115_5096342.shtml "武汉岩土所召开2025年度党（总）支部书记述职考评会")\n* [宁波材料所召开党委理论学习中心组学习会](//www.cas.cn/../../djcx/gz/202601/t20260113_5095893.shtml "宁波材料所召开党委理论学习中心组学习会")\n* [授时中心传达学习中国科学院党组冬季扩大会议精神](//www.cas.cn/../../djcx/gz/202601/t20260109_5095686.shtml "授时中心传达学习中国科学院党组冬季扩大会议精神")\n\n反腐倡廉[/\xa0更多](//www.cas.cn/../../djcx/ff/)\n\n* [沈阳分院召开2025年度第四次纪检组扩大会议](//www.cas.cn/../../djcx/ff/202512/t20251217_5092725.shtml "沈阳分院召开2025年度第四次纪检组扩大会议")\n* [新疆分院纪检组召开2025年第四次纪监审工作会议](//www.cas.cn/../../djcx/ff/202512/t20251201_5090930.shtml "新疆分院纪检组召开2025年第四次纪监审工作会议")\n* [国科控股举办2025年纪检干部培训班](//www.cas.cn/../../djcx/ff/202511/t20251125_5089920.shtml "国科控股举办2025年纪检干部培训班")\n* [西安分院召开第四季度纪监审工作交流会](//www.cas.cn/../../djcx/ff/202511/t20251104_5087359.shtml "西安分院召开第四季度纪监审工作交流会")\n\n[违纪违法举报](//www.cas.cn/../../jl/wf/)\n\n文明天地[/\xa0更多](//www.cas.cn/../../djcx/wm/)\n\n* [中国科学院合唱团举办“2026新年音乐会”](//www.cas.cn/../../djcx/wm/202601/t20260120_5096648.shtml "中国科学院合唱团举办“2026新年音乐会”")\n* [中国科学院合唱团参加“首都留学人员2026新年音乐会”](//www.cas.cn/../../djcx/wm/202512/t20251229_5094466.shtml "中国科学院合唱团参加“首都留学人员2026新年音乐会”")\n* [光电所举办“五十五载辉煌路·追光逐电启新程”职工运动会](//www.cas.cn/../../djcx/wm/202511/t20251117_5089033.shtml "光电所举办“五十五载辉煌路·追光逐电启新程”职工运动会")\n* [计算机网络信息中心举办“榜样之声·初心映耀”身边榜样故事分享会](//www.cas.cn/../../djcx/wm/202511/t20251111_5088215.shtml "计算机网络信息中心举办“榜样之声·初心映耀”身边榜样故事分享会")\n\n主动公开工作信息\n\n相关规定\n\n* [信息公开指南](//www.cas.cn/../../xxgkml/xxgkgzxx/xggd/xxgkzn/)\n* [主动公开事项目录](//www.cas.cn/../../xxgkml/xxgkgzxx/xggd/xxgkml/)\n* [其他规定](//www.cas.cn/../../xxgkml/xxgkgzxx/xggd/qtgd/)\n\n组织机构\n\n* [工作机构](//www.cas.cn/../../xxgkml/xxgkgzxx/zzjg/gzjg/)\n* [监督机构](//www.cas.cn/../../xxgkml/xxgkgzxx/zzjg/jdjg/)\n\n中国科学院学部\n\n基本信息\n\n* [学部概况](//www.cas.cn/../../xxgkml/zgkxyxb/jbxx/xbgk/)\n* [院士大会](//www.cas.cn/../../xxgkml/zgkxyxb/jbxx/ysdh/)\n* [院士信息](//www.cas.cn/../../xxgkml/zgkxyxb/jbxx/ysxx/)\n\n规章制度\n\n* [院士章程](//www.cas.cn/../../xxgkml/zgkxyxb/gzzd/yszc/)\n* [增选工作有关规定](//www.cas.cn/../../xxgkml/zgkxyxb/gzzd/zxgd/)\n* [其他工作规则与管理办法](//www.cas.cn/../../xxgkml/zgkxyxb/gzzd/qtgzbf/)\n\n工作进展\n\n* [院士增选](//www.cas.cn/../../xxgkml/zgkxyxb/gzjz/yszx/)\n* [决策咨询](//www.cas.cn/../../xxgkml/zgkxyxb/gzjz/zxpy/)\n* [学术引领](//www.cas.cn/../../xxgkml/zgkxyxb/gzjz/xsyl/)\n* [科学普及](//www.cas.cn/../../xxgkml/zgkxyxb/gzjz/xskp/)\n* [工作动态](//www.cas.cn/../../xxgkml/zgkxyxb/gzjz/gzdt/)\n\n学部出版物\n\n* [决策咨询系列](//www.cas.cn/../../xxgkml/zgkxyxb/xbcbw/zxjc/)\n* [学术引领系列](//www.cas.cn/../../xxgkml/zgkxyxb/xbcbw/xsyl/)\n* [科学文化系列](//www.cas.cn/../../xxgkml/zgkxyxb/xbcbw/kxwh/)\n* [其他出版物](//www.cas.cn/../../xxgkml/zgkxyxb/xbcbw/qtcbw/)\n\n陈嘉庚科学奖\n\n* [机构概况](//www.cas.cn/../../xxgkml/zgkxyxb/cjgkxj/jggk/)\n* [规章制度](//www.cas.cn/../../xxgkml/zgkxyxb/cjgkxj/gzzd/)\n* [通知公告](//www.cas.cn/../../xxgkml/zgkxyxb/cjgkxj/tzgg/)\n\n中国科学院院部\n\n机构设置\n\n* [基本情况](//www.cas.cn/../../zz/index.shtml#yk_scy)\n* [院领导集体](//www.cas.cn/../../zz/index.shtml#ha_zzjg)\n* [组织机构](//www.cas.cn/../../zz/)\n\n规章制度\n\n* [综合性制度文件](//www.cas.cn/../../xxgkml/zgkxyyb/gzzd/zd/)\n* [政策解读](//www.cas.cn/../../xxgkml/zgkxyyb/gzzd/jd/)\n\n财务资产\n\n* [预算决算](//www.cas.cn/../../xxgkml/zgkxyyb/czjf/ysjs/)\n* [公示公告](//www.cas.cn/../../xxgkml/zgkxyyb/czjf/gsgg/)\n\n新闻动态\n\n* [重要新闻](//www.cas.cn/../../xxgkml/zgkxyyb/xxgk/xw/)\n* [工作动态](//www.cas.cn/../../xxgkml/zgkxyyb/xxgk/dt/)\n* [媒体报道](//www.cas.cn/../../xxgkml/zgkxyyb/xxgk/bd/)\n* [网站专题](//www.cas.cn/../../xxgkml/zgkxyyb/xxgk/zt/)\n* [通知公告](//www.cas.cn/../../xxgkml/zgkxyyb/xxgk/tz/)\n\n科学研究\n\n* [科研装备](//www.cas.cn/../../xxgkml/zgkxyyb/kxyj/kyzb/)\n* [科研进展](//www.cas.cn/../../xxgkml/zgkxyyb/kxyj/kyjz/)\n* [成果转化](//www.cas.cn/../../xxgkml/zgkxyyb/kxyj/cgzh_/)\n* [科技奖励](//www.cas.cn/../../xxgkml/zgkxyyb/kxyj/kjjl/)\n* [科技期刊](//www.cas.cn/../../xxgkml/zgkxyyb/kxyj/qk/)\n\n人事人才\n\n* [人事任免](//www.cas.cn/../../xxgkml/zgkxyyb/rsrc/rsrm/)\n* [人才招聘](//www.cas.cn/../../xxgkml/zgkxyyb/rsrc/rczp/)\n* [招生与培养](//www.cas.cn/../../xxgkml/zgkxyyb/rsrc/zsypy/)\n\n国际合作\n\n* [国际组织](//www.cas.cn/../../xxgkml/zgkxyyb/gjhz/gjzz/)\n* [政策法规](//www.cas.cn/../../xxgkml/zgkxyyb/gjhz/zc/)\n\n[首页](../../ "首页")\xa0>\xa0[访谈·视点](../ "访谈·视点")\n\n## 谭铁牛：人工智能的历史、现状和未来\n\n2019-02-18 求是\n\n \n\n【字体：大 中 小】\n\n语音播报\n\n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。\n\n**概念与历程**\n\n\u3000\u3000了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n\n\u3000\u3000人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。\n\n\u3000\u3000人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n\n\u3000\u3000一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n\n\u3000\u3000二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n\n\u3000\u3000三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n\n\u3000\u3000四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n\u3000\u3000五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n\n\u3000\u3000六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n\n**现状与影响**\n\n\u3000\u3000对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n\n\u3000\u3000专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n\n\u3000\u3000通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n\u3000\u3000人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n\u3000\u3000创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n\n\u3000\u3000人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。\n\n**趋势与展望**\n\n\u3000\u3000经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n\n\u3000\u3000从专用智能向通用智能发展。如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n\u3000\u3000差距不小。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n\n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。  \n\u3000\u3000概念与历程  \n\u3000\u3000了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。  \n\u3000\u3000人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。  \n\u3000\u3000人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：  \n\u3000\u3000一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。  \n\u3000\u3000二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。  \n\u3000\u3000三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。  \n\u3000\u3000四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。  \n\u3000\u3000五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。  \n\u3000\u3000六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。  \n\u3000\u3000现状与影响  \n\u3000\u3000对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。  \n\u3000\u3000专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。  \n\u3000\u3000通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。  \n\u3000\u3000人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。  \n\u3000\u3000创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。  \n\u3000\u3000人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。  \n\u3000\u3000趋势与展望  \n\u3000\u3000经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？  \n\u3000\u3000从专用智能向通用智能发展。如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。  \n\u3000\u3000从人工智能向人机混合智能发展。借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。  \n\u3000\u3000从“人工+智能”向自主智能系统发展。当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。  \n\u3000\u3000人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。  \n\u3000\u3000人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。  \n\u3000\u3000人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。  \n\u3000\u3000人工智能领域的国际竞争将日益激烈。当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。  \n\u3000\u3000人工智能的社会学将提上议程。为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。  \n\u3000\u3000态势与思考  \n\u3000\u3000当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。  \n\u3000\u3000高度重视。党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。  \n\u3000\u3000态势喜人。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。  \n\u3000\u3000差距不小。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。  \n\u3000\u3000前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。  \n\u3000\u3000当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。  \n\u3000\u3000树立理性务实的发展理念。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。  \n\u3000\u3000重视固本强基的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。  \n\u3000\u3000构建自主可控的创新生态。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。  \n\u3000\u3000推动共担共享的全球治理。目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。  \n\u3000\u3000（作者：中央人民政府驻香港特别行政区联络办公室副主任、中国科学院院士）\n\n[打印](javascript:void(0);) 责任编辑：侯茜\n\n* 王小理 | [展望2050年国防生物科技创新前景](./t20190225_4680185.shtml)\n* 万劲波 | [更大力度推进基础研究](./t20190214_4679511.shtml)\n\n© 1996 - 中国科学院 版权所有\u3000[京ICP备05002857号-1](//beian.miit.gov.cn/)\u3000京公网安备110402500047号\u3000网站标识码bm48000002\n\n地址：北京市西城区三里河路52号 邮编：100864\n\n电话： 86 10 68597114（总机）\u300086 10 68597289（总值班室）\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.cas.cn/zjs/201902/t20190218_4679625.shtml', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9988927, 'save_path': None}}, {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '![](/static/images/icons/zhwiki-25.svg)\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n![自由的百科全书](/static/images/mobile/copyright/wikipedia-tagline-zh-25-hans.svg)\n\n## 目录\n\n# 人工智能史\n\n| [人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")系列内容 |\n| --- |\n|  |\n| 主要目标  * [知识表示](/wiki/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA "知识表示") * [自动规划](/w/index.php?title=%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92%E5%92%8C%E8%B0%83%E5%BA%A6&action=edit&redlink=1 "自动规划和调度（页面不存在）")（英语：[Automated planning and scheduling](https://en.wikipedia.org/wiki/Automated_planning_and_scheduling "en:Automated planning and scheduling")） * [机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习") * [语言处理](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理") * [电脑视觉](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89 "计算机视觉") * [机器人学](/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6 "机器人学") * [强人工智慧](/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "通用人工智慧") * [弱人工智慧](/wiki/%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "弱人工智慧") * [人工智能对齐](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%B9%E9%BD%90 "人工智能对齐") |\n| 实现方式  * [符号人工智能](/wiki/%E7%AC%A6%E8%99%9F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "符号人工智能") * [深度学习](/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0 "深度学习") * [贝氏网路](/wiki/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF "贝氏网路") * [进化算法](/wiki/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95 "进化算法") * [混合智能系统](/wiki/%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%B3%BB%E7%B5%B1 "混合智能系统")   + [混合专家模型](/wiki/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B "混合专家模型") * [生成式人工智慧](/wiki/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "生成式人工智慧") * [代理式人工智能](/w/index.php?title=%E4%BB%A3%E7%90%86%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "代理式人工智能（页面不存在）")（英语：[AI agent](https://en.wikipedia.org/wiki/AI_agent "en:AI agent")） |\n| [人工智能哲学](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%93%B2%E5%AD%B8 "人工智能哲学")  * [伦理](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BC%A6%E7%90%86&action=edit&redlink=1 "人工智能伦理（页面不存在）")（英语：[Ethics of artificial intelligence](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence "en:Ethics of artificial intelligence")） * [人工智能安全](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%89%E5%85%A8&action=edit&redlink=1 "人工智能安全（页面不存在）")（英语：[AI safety](https://en.wikipedia.org/wiki/AI_safety "en:AI safety")）   + [幻觉](/wiki/%E5%B9%BB%E8%A7%89_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD) "幻觉 (人工智能)")   + [存在风险](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%98%E5%9C%A8%E9%A3%8E%E9%99%A9&action=edit&redlink=1 "人工智能的存在风险（页面不存在）")（英语：[Existential risk from artificial general intelligence](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence "en:Existential risk from artificial general intelligence")） * [图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试") * [中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间") * [可解释人工智慧](/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "可解释人工智慧") * [友好的人工智能](/w/index.php?title=%E5%8F%8B%E5%A5%BD%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "友好的人工智能（页面不存在）")（英语：[Friendly artificial intelligence](https://en.wikipedia.org/wiki/Friendly_artificial_intelligence "en:Friendly artificial intelligence")） * [人工智能监管](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9B%91%E7%AE%A1&action=edit&redlink=1 "人工智能监管（页面不存在）")（英语：[Regulation of artificial intelligence](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence "en:Regulation of artificial intelligence")） |\n| 历史  * [时间轴](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E9%97%B4%E8%BD%B4&action=edit&redlink=1 "人工智能时间轴（页面不存在）")（英语：[Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence "en:Timeline of artificial intelligence")） * [发展](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95&action=edit&redlink=1 "人工智能发展（页面不存在）")（英语：[Progress in artificial intelligence](https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence "en:Progress in artificial intelligence")） * [专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统") * [人工智慧低谷](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷") * [人工智能热潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%83%AD%E6%BD%AE "人工智能热潮") * [人工智能法案](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B3%95%E6%A1%88 "人工智能法案") |\n| [人工智能的应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")  * [应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")   + [AlphaFold](/wiki/AlphaFold "AlphaFold")   + [深度伪造](/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%AA%E9%80%A0 "深度伪造")   + [AI艺术](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%97%9D%E8%A1%93 "人工智慧艺术")   + [音乐](/wiki/%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "音乐和人工智能")   + [医疗保健](/wiki/%E5%8C%BB%E7%96%97%E9%A2%86%E5%9F%9F%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "医疗领域的人工智能")   + [工业](/wiki/%E5%B7%A5%E4%B8%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "工业人工智能")   + [机器翻译](/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91 "机器翻译")   + [军事](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BB%8D%E5%82%99%E7%AB%B6%E8%B3%BD "人工智能军备竞赛") * [项目](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B9%E7%9B%AE%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能项目列表（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） * [编程语言](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能编程语言列表（页面不存在）")（英语：[List of programming languages for artificial intelligence](https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence "en:List of programming languages for artificial intelligence")） |\n| 主题与列表  * [主题](/wiki/Portal:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Portal:人工智能") * [术语表](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AF%E8%AF%AD%E8%A1%A8 "人工智能术语表") * [AI概述](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%BF%B0 "人工智能概述") * [AI公司列表](/w/index.php?title=List_of_artificial_intelligence_companies&action=edit&redlink=1 "List of artificial intelligence companies（页面不存在）")（英语：[List of artificial intelligence companies](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies "en:List of artificial intelligence companies")） * [AI项目列表](/w/index.php?title=List_of_artificial_intelligence_projects&action=edit&redlink=1 "List of artificial intelligence projects（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） |\n| * [查](/wiki/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template:人工智能") * [论](/wiki/Template_talk:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template talk:人工智能") * [编](/wiki/Special:EditPage/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Special:EditPage/Template:人工智能") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png/250px-Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png)\n\n**人工智能的历史**源远流长。在古代的[神话](/wiki/%E7%A5%9E%E8%A9%B1 "神话")[传说](/wiki/%E4%BC%A0%E8%AF%B4 "传说")中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](/wiki/%E9%9B%BB%E8%85%A6 "电脑")的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n\n1956年，[人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")的研究领域确立于在[达特茅斯学院](/wiki/%E8%BE%BE%E7%89%B9%E8%8C%85%E6%96%AF%E5%AD%A6%E9%99%A2 "达特茅斯学院")举行的[会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2]](#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")（也被称作AI之冬）。由于[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")爵士的批评和国会方面的压力，[美国](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3]](#cite_note-3)\n\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "强人工智慧")的机器至今仍未出现。[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4]](#cite_note-TuringQuote-4)\n\n在21世纪的第一个十年，[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n| [计算历史](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） |\n| --- |\n| [硬件](/wiki/%E7%A1%AC%E4%BB%B6 "硬件") |\n| * [1960年代之前](/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2 "计算机硬体历史") * [1960年代至今](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2_(1960%E5%B9%B4%E4%BB%A3%E8%87%B3%E4%BB%8A)&action=edit&redlink=1 "计算机硬体历史 (1960年代至今)（页面不存在）")（英语：[History of computing hardware (1960s–present)](https://en.wikipedia.org/wiki/History_of_computing_hardware_(1960s%E2%80%93present) "en:History of computing hardware (1960s–present)")） |\n| [软件](/wiki/%E8%BD%AF%E4%BB%B6 "软件") |\n| * [软体](/w/index.php?title=%E8%BB%9F%E9%AB%94%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体历史（页面不存在）")（英语：[History of software](https://en.wikipedia.org/wiki/History_of_software "en:History of software")） * [Unix](/w/index.php?title=Unix%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Unix历史（页面不存在）")（英语：[History of Unix](https://en.wikipedia.org/wiki/History_of_Unix "en:History of Unix")） * [自由和开源软件](/w/index.php?title=%E8%87%AA%E7%94%B1%E5%92%8C%E9%96%8B%E6%BA%90%E8%BB%9F%E4%BB%B6%E7%9A%84%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "自由和开源软件的历史（页面不存在）")（英语：[History of free and open-source software](https://en.wikipedia.org/wiki/History_of_free_and_open-source_software "en:History of free and open-source software")） |\n| [计算机科学](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6 "计算机科学") |\n| * 人工智能 * [编译器构造](/w/index.php?title=%E7%BC%96%E8%AF%91%E5%99%A8%E6%9E%84%E9%80%A0%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "编译器构造历史（页面不存在）")（英语：[History of compiler construction](https://en.wikipedia.org/wiki/History_of_compiler_construction "en:History of compiler construction")） * [计算机科学](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算机科学历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） * [操作系统](/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%86%E5%8F%B2 "操作系统历史") * [程式语言](/wiki/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80%E6%AD%B7%E5%8F%B2 "程式语言历史") * [杰出先驱者](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%85%88%E9%A9%B1%E8%80%85%E5%88%97%E8%A1%A8&action=edit&redlink=1 "计算机科学先驱者列表（页面不存在）")（英语：[List of pioneers in computer science](https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science "en:List of pioneers in computer science")） * [软体工程](/w/index.php?title=%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体工程历史（页面不存在）")（英语：[History of software engineering](https://en.wikipedia.org/wiki/History_of_software_engineering "en:History of software engineering")） |\n| 现代概念 |\n| * [通用CPU](/w/index.php?title=%E9%80%9A%E7%94%A8%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "通用中央处理器历史（页面不存在）")（英语：[History of general-purpose CPUs](https://en.wikipedia.org/wiki/History_of_general-purpose_CPUs "en:History of general-purpose CPUs")） * [图形用户界面](/wiki/%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2 "图形用户界面") * [互联网](/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%8E%86%E5%8F%B2 "互联网历史") * [个人电脑](/w/index.php?title=%E5%80%8B%E4%BA%BA%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "个人电脑历史（页面不存在）")（英语：[History of personal computers](https://en.wikipedia.org/wiki/History_of_personal_computers "en:History of personal computers")） * [笔记型电脑](/w/index.php?title=%E7%AD%86%E8%A8%98%E5%9E%8B%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "笔记型电脑历史（页面不存在）")（英语：[History of laptops](https://en.wikipedia.org/wiki/History_of_laptops "en:History of laptops")） * [电子游戏](/wiki/%E9%9B%BB%E5%AD%90%E9%81%8A%E6%88%B2%E5%8F%B2 "电子游戏史") * [全球资讯网](/w/index.php?title=%E5%85%A8%E7%90%83%E8%B3%87%E8%A8%8A%E7%B6%B2%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "全球资讯网历史（页面不存在）")（英语：[History of the World Wide Web](https://en.wikipedia.org/wiki/History_of_the_World_Wide_Web "en:History of the World Wide Web")） |\n| 按国家 |\n| * [保加利亚](/w/index.php?title=%E4%BF%9D%E5%8A%A0%E5%88%A9%E4%BA%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "保加利亚计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Bulgaria](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Bulgaria "en:History of computer hardware in Bulgaria")） * [波兰](/w/index.php?title=%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "波兰计算历史（页面不存在）")（英语：[History of computing in Poland](https://en.wikipedia.org/wiki/History_of_computing_in_Poland "en:History of computing in Poland")） * [罗马尼亚](/w/index.php?title=%E7%BD%97%E9%A9%AC%E5%B0%BC%E4%BA%9A%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "罗马尼亚计算历史（页面不存在）")（英语：[History of computing in Romania](https://en.wikipedia.org/wiki/History_of_computing_in_Romania "en:History of computing in Romania")） * [苏联集团国家](/w/index.php?title=%E8%8B%8F%E8%81%94%E9%9B%86%E5%9B%A2%E5%9B%BD%E5%AE%B6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联集团国家计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Soviet Bloc countries](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Soviet_Bloc_countries "en:History of computer hardware in Soviet Bloc countries")） * [苏联](/w/index.php?title=%E8%8B%8F%E8%81%94%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联计算历史（页面不存在）")（英语：[History of computing in the Soviet Union](https://en.wikipedia.org/wiki/History_of_computing_in_the_Soviet_Union "en:History of computing in the Soviet Union")） * [南斯拉夫](/w/index.php?title=%E5%8D%97%E6%96%AF%E6%8B%89%E5%A4%AB%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "南斯拉夫计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Yugoslavia](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Yugoslavia "en:History of computer hardware in Yugoslavia")） |\n| [计算年表](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "计算年表（页面不存在）")（英语：[Timeline of computing](https://en.wikipedia.org/wiki/Timeline_of_computing "en:Timeline of computing")） |\n| * [1950年之前](/w/index.php?title=1950%E5%B9%B4%E4%B9%8B%E5%89%8D%E7%9A%84%E8%AE%A1%E7%AE%97%E7%A1%AC%E4%BB%B6%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "1950年之前的计算硬件年表（页面不存在）")（英语：[Timeline of computing hardware before 1950](https://en.wikipedia.org/wiki/Timeline_of_computing_hardware_before_1950 "en:Timeline of computing hardware before 1950")） * [1950–1979](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1950%E2%80%931979)&action=edit&redlink=1 "计算年表 (1950–1979)（页面不存在）")（英语：[Timeline of computing 1950–1979](https://en.wikipedia.org/wiki/Timeline_of_computing_1950%E2%80%931979 "en:Timeline of computing 1950–1979")） * [1980–1989](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1980%E2%80%931989)&action=edit&redlink=1 "计算年表 (1980–1989)（页面不存在）")（英语：[Timeline of computing 1980–1989](https://en.wikipedia.org/wiki/Timeline_of_computing_1980%E2%80%931989 "en:Timeline of computing 1980–1989")） * [1990–1999](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1990%E2%80%931999)&action=edit&redlink=1 "计算年表 (1990–1999)（页面不存在）")（英语：[Timeline of computing 1990–1999](https://en.wikipedia.org/wiki/Timeline_of_computing_1990%E2%80%931999 "en:Timeline of computing 1990–1999")） * [2000–2009](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2000%E2%80%932009)&action=edit&redlink=1 "计算年表 (2000–2009)（页面不存在）")（英语：[Timeline of computing 2000–2009](https://en.wikipedia.org/wiki/Timeline_of_computing_2000%E2%80%932009 "en:Timeline of computing 2000–2009")） * [2010–2019](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2010%E2%80%932019)&action=edit&redlink=1 "计算年表 (2010–2019)（页面不存在）")（英语：[Timeline of computing 2010–2019](https://en.wikipedia.org/wiki/Timeline_of_computing_2010%E2%80%932019 "en:Timeline of computing 2010–2019")） * [更多年表……](/wiki/Category:%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8 "Category:计算年表") |\n| [计算机科学词汇](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E8%AF%8D%E6%B1%87&action=edit&redlink=1 "计算机科学词汇（页面不存在）")（英语：[Glossary of computer science](https://en.wikipedia.org/wiki/Glossary_of_computer_science "en:Glossary of computer science")） |\n| * [分类](/wiki/Category:%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B2 "Category:计算机历史") |\n| * [查](/wiki/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Template:计算历史") * [论](/w/index.php?title=Template_talk:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Template talk:计算历史（页面不存在）") * [编](/wiki/Special:EditPage/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Special:EditPage/Template:计算历史") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)\n\n## 先驱\n\n奥特曼写道[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](/wiki/%E8%87%AA%E5%8B%95%E6%A9%9F "自动机")）的实践之中。[[5]](#cite_note-FOOTNOTEMcCorduck20045–35-5)\n\n### 神话，幻想和预言中的AI\n\n[希腊神话](/wiki/%E5%B8%8C%E8%85%8A%E7%A5%9E%E8%AF%9D "希腊神话")中已经出现了机械人和人造人，如[赫淮斯托斯](/wiki/%E8%B5%AB%E6%B7%AE%E6%96%AF%E6%89%98%E6%96%AF "赫淮斯托斯")的黄金机器人和[皮格马利翁](/wiki/%E7%9A%AE%E6%A0%BC%E9%A9%AC%E5%88%A9%E7%BF%81 "皮格马利翁")的[伽拉忒亚](/wiki/%E4%BC%BD%E6%8B%89%E5%BF%92%E4%BA%9A "伽拉忒亚")。[[6]](#cite_note-6)中世纪出现了使用巫术或[炼金术](/wiki/%E7%82%BC%E9%87%91%E6%9C%AF "炼金术")将意识赋予无生命物质的传说，如[贾比尔](/wiki/%E8%B4%BE%E6%AF%94%E5%B0%94 "贾比尔")的*Takwin*，[帕拉塞尔苏斯](/wiki/%E5%B8%95%E6%8B%89%E5%A1%9E%E5%B0%94%E8%8B%8F%E6%96%AF "帕拉塞尔苏斯")的[何蒙库鲁兹](/wiki/%E4%BD%95%E8%92%99%E5%BA%93%E9%B2%81%E5%85%B9 "何蒙库鲁兹")和Judah Loew的[魔像](/wiki/%E9%AD%94%E5%83%8F "魔像")。[[7]](#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](/wiki/%E7%8E%9B%E4%B8%BD%C2%B7%E9%9B%AA%E8%8E%B1 "玛丽·雪莱")的《[弗兰肯斯坦](/wiki/%E5%BC%97%E5%85%B0%E8%82%AF%E6%96%AF%E5%9D%A6 "弗兰肯斯坦")》和[卡雷尔·恰佩克](/wiki/%E5%8D%A1%E9%9B%B7%E5%B0%94%C2%B7%E6%81%B0%E4%BD%A9%E5%85%8B "卡雷尔·恰佩克")的《罗素姆的万能机器人》。[[8]](#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9]](#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。\n\n### 自动人偶\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)\n\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师](/wiki/%E5%81%83%E5%B8%88 "偃师")（中国西周）[[10]](#cite_note-10)，[希罗](/wiki/%E5%B8%8C%E7%BD%97 "希罗")（希腊）[[11]](#cite_note-11)，[加扎利](/wiki/%E5%8A%A0%E6%89%8E%E5%88%A9 "加扎利")[[12]](#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13]](#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](/wiki/%E5%8F%A4%E5%9F%83%E5%8F%8A "古埃及")和[古希腊](/wiki/%E5%8F%A4%E5%B8%8C%E8%85%8A "古希腊")的[圣像](/wiki/%E8%81%96%E5%83%8F "圣像")，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")（[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")）写道“当发现神的本性时，人就能够重现他”[[14]](#cite_note-14)[[15]](#cite_note-15)。\n\n### 形式推理\n\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](/wiki/%E4%BA%9A%E9%87%8C%E5%A3%AB%E5%A4%9A%E5%BE%B7 "亚里士多德")（对三段论逻辑进行了形式分析），[欧几里得](/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97 "欧几里得")（其著作《[几何原本](/wiki/%E5%87%A0%E4%BD%95%E5%8E%9F%E6%9C%AC "几何原本")》是形式推理的典范），[花剌子密](/wiki/%E8%8A%B1%E5%89%8C%E5%AD%90%E5%AF%86 "花剌子密")（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E7%9A%84%E5%A8%81%E5%BB%89 "奥卡姆的威廉")和[邓斯·司各脱](/wiki/%E9%82%93%E6%96%AF%C2%B7%E5%8F%B8%E5%90%84%E8%84%B1 "邓斯·司各脱")。[[16]](#cite_note-Berlinski_2000-16)\n\n[马略卡](/wiki/%E9%A9%AC%E7%95%A5%E5%8D%A1 "马略卡")哲学家[拉蒙·柳利](/wiki/%E6%8B%89%E8%92%99%C2%B7%E6%9F%B3%E5%88%A9 "拉蒙·柳利")（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17]](#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18]](#cite_note-18)Llull的工作对[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")产生了很大影响，后者进一步发展了他的思想。[[19]](#cite_note-19)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/250px-Gottfried_Wilhelm_von_Leibniz.jpg)\n\n在17世纪中，[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")，[托马斯·霍布斯](/wiki/%E6%89%98%E9%A9%AC%E6%96%AF%C2%B7%E9%9C%8D%E5%B8%83%E6%96%AF "托马斯·霍布斯")和[笛卡儿](/wiki/%E7%AC%9B%E5%8D%A1%E5%84%BF "笛卡儿")尝试将理性的思考系统化为代数学或几何学那样的体系。[[20]](#cite_note-20)霍布斯在其著作《[利维坦](/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF) "利维坦 (霍布斯)")》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21]](#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](/wiki/%E9%80%9A%E7%94%A8%E8%A1%A8%E6%84%8F%E6%96%87%E5%AD%97 "通用表意文字")），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22]](#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n\n在20世纪，[数理逻辑](/wiki/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91 "数理逻辑")研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](/wiki/%E4%B9%94%E6%B2%BB%C2%B7%E5%B8%83%E5%B0%94 "乔治·布尔")的《思维的定律》与[弗雷格](/wiki/%E6%88%88%E7%89%B9%E6%B4%9B%E5%B8%83%C2%B7%E5%BC%97%E9%9B%B7%E6%A0%BC "戈特洛布·弗雷格")的《[概念文字](/wiki/%E6%A6%82%E5%BF%B5%E6%96%87%E5%AD%97 "概念文字")》。基于弗雷格的系统，[罗素](/wiki/%E7%BD%97%E7%B4%A0 "罗素")和[怀特海](/wiki/%E6%80%80%E7%89%B9%E6%B5%B7 "怀特海")在他们于1913年出版的巨著《[数学原理](/wiki/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86 "数学原理")》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9 "希尔伯特")，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16]](#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")，[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")和[Alonzo Church](/wiki/Alonzo_Church "Alonzo Church")的[λ演算](/wiki/%CE%9B%E6%BC%94%E7%AE%97 "Λ演算")给出。[[16]](#cite_note-Berlinski_2000-16)[[23]](#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)\n\n[邱奇-图灵论题](/wiki/%E9%82%B1%E5%A5%87-%E5%9B%BE%E7%81%B5%E8%AE%BA%E9%A2%98 "邱奇-图灵论题")暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16]](#cite_note-Berlinski_2000-16)[[24]](#cite_note-24)\n\n### 计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](/wiki/%E6%9F%A5%E5%B0%94%E6%96%AF%C2%B7%E5%B7%B4%E8%B4%9D%E5%A5%87 "查尔斯·巴贝奇")设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](/wiki/%E6%84%9B%E9%81%94%C2%B7%E5%8B%92%E8%8A%99%E8%95%BE%E7%B5%B2 "爱达·勒芙蕾丝")预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25]](#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%95%B0 "伯努利数")的方法。）\n\n第一批现代计算机是[二战](/wiki/%E4%BA%8C%E6%88%98 "二战")期间建造的大型译码机（包括Z3，[ENIAC](/wiki/ENIAC "ENIAC")和Colossus等）。[[26]](#cite_note-26)后两个机器的理论基础是[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")和[约翰·冯·诺伊曼](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC "约翰·冯·诺伊曼")提出和发展的学说。[[27]](#cite_note-27)\n\n## 人工智能的诞生：1943 - 1956\n\n[[28]](#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n### 控制论与早期神经网络\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/250px-BRL61-IBM_702.jpg)\n\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](/wiki/%E8%AF%BA%E4%BC%AF%E7%89%B9%C2%B7%E7%BB%B4%E7%BA%B3 "诺伯特·维纳")的[控制论](/wiki/%E6%8E%A7%E5%88%B6%E8%AE%BA "控制论")描述了电子网络的控制和稳定性。[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")提出的[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")则描述了[数字信号](/wiki/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7 "数字信号")（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29]](#cite_note-29)\n\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30]](#cite_note-30)\n\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")”的学者。[[31]](#cite_note-31)[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](/w/index.php?title=SNARC&action=edit&redlink=1 "SNARC（页面不存在）")。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n### 游戏AI\n\n1951年，[克里斯托弗·斯特雷奇](/wiki/%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%BC%97%C2%B7%E6%96%AF%E7%89%B9%E9%9B%B7%E5%A5%87 "克里斯托弗·斯特雷奇")使用[曼彻斯特大学](/wiki/%E6%9B%BC%E5%BD%BB%E6%96%AF%E7%89%B9%E5%A4%A7%E5%AD%A6 "曼彻斯特大学")的Ferranti Mark 1机器写出了一个[西洋跳棋](/wiki/%E8%A5%BF%E6%B4%8B%E8%B7%B3%E6%A3%8B "西洋跳棋")（checkers）程序；[迪特里希·普林茨](/w/index.php?title=%E8%BF%AA%E7%89%B9%E9%87%8C%E5%B8%8C%C2%B7%E6%99%AE%E6%9E%97%E8%8C%A8&action=edit&redlink=1 "迪特里希·普林茨（页面不存在）")（Dietrich Prinz）则写出了一个[国际象棋](/wiki/%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B "国际象棋")程序。[[32]](#cite_note-32)[亚瑟·李·塞谬尔](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E6%9D%8E%C2%B7%E5%A1%9E%E8%AC%AC%E7%88%BE "亚瑟·李·塞谬尔")（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33]](#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。\n\n### 图灵测试\n\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34]](#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试")：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35]](#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。\n\n### 符号推理与“逻辑理论家”程序\n\n50年代中期，随着数位计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36]](#cite_note-36)\n\n1955年，[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和后来荣获诺贝尔奖的[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")在J. C. Shaw的协助下开发了“[逻辑理论家](/wiki/%E9%80%BB%E8%BE%91%E7%90%86%E8%AE%BA%E5%AE%B6 "逻辑理论家")（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37]](#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](/wiki/%E5%BF%83%E8%BA%AB%E4%BA%8C%E5%88%86%E6%B3%95 "心身二分法")，解释了物质构成的系统如何获得心灵的性质。”[[38]](#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92 "约翰·罗杰斯·希尔勒")称为“强人工智能”，即机器可以像人一样具有思想。）[[39]](#cite_note-39)\n\n### 1956年达特茅斯会议：AI的诞生\n\n1956年[达特矛斯会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")[[40]](#cite_note-40)的组织者是[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")，[约翰·麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")和另两位资深科学家[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](/wiki/IBM "IBM")。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41]](#cite_note-41)与会者包括[雷·索罗门诺夫](/w/index.php?title=%E9%9B%B7%C2%B7%E7%B4%A2%E7%BE%85%E9%96%80%E8%AB%BE%E5%A4%AB&action=edit&redlink=1 "雷·索罗门诺夫（页面不存在）")（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42]](#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")则说服与会者接受“人工智能”一词作为本领域的名称。[[43]](#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44]](#cite_note-44)\n\n## 第一波浪潮 - 黄金年代：1956 - 1974\n\n[达特矛斯](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45]](#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46]](#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47]](#cite_note-47) [DARPA](/wiki/DARPA "DARPA")（[国防高等研究计划署](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")）等政府机构向这一新兴领域投入了大笔资金。[[48]](#cite_note-48)\n\n### 研究工作\n\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n#### 搜索式推理\n\n许多AI程序使用相同的基本[算法](/wiki/%E7%AE%97%E6%B3%95 "算法")。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95 "回溯法")。这就是“搜索式推理”。[[49]](#cite_note-49)\n\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95 "启发式算法")去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50]](#cite_note-50)\n\n艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](/wiki/%E4%B8%80%E8%88%AC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%99%A8 "一般问题解决器")（General Problem Solver）”程序，将这一算法推广到一般情形。[[51]](#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52]](#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](/wiki/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6 "斯坦福大学")为控制机器人Shakey而开发的STRIPS系统。[[53]](#cite_note-53)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)\n\n#### 自然语言\n\nAI研究的一个重要目标是使计算机能够通过[自然语言](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理")（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54]](#cite_note-54)\n\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](/wiki/%E8%AF%AD%E4%B9%89%E7%BD%91 "语义网")（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55]](#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56]](#cite_note-56)\n\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57]](#cite_note-57)\n\n#### 微世界\n\n60年代后期，[麻省理工大学](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")AI实验室的马文·闵斯基和[西摩尔·派普特](/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9 "西摩尔·派普特")建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58]](#cite_note-58)\n\n在这一指导思想下，[杰拉德·杰伊·萨斯曼](/wiki/%E5%82%91%E6%8B%89%E5%BE%B7%C2%B7%E5%82%91%E4%BC%8A%C2%B7%E8%96%A9%E6%96%AF%E6%9B%BC "杰拉德·杰伊·萨斯曼")（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](/w/index.php?title=%E5%A4%A7%E8%A1%9B%C2%B7%E7%93%A6%E7%88%BE%E8%8C%B2&action=edit&redlink=1 "大卫·瓦尔兹（页面不存在）")（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](/wiki/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89 "机器视觉")领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](/wiki/SHRDLU "SHRDLU")，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59]](#cite_note-59)\n\n### 乐观思潮\n\n第一代AI研究者们曾作出了如下预言:\n\n### 经费\n\n1963年6月，[MIT](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64]](#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](/wiki/%E5%8D%A1%E5%86%85%E5%9F%BA%E6%A2%85%E9%9A%86%E5%A4%A7%E5%AD%A6 "卡内基梅隆大学")的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65]](#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](/wiki/%E7%88%B1%E4%B8%81%E5%A0%A1%E5%A4%A7%E5%AD%A6 "爱丁堡大学")建立。[[66]](#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67]](#cite_note-67)\n\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68]](#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](/wiki/Hacker "Hacker")文化的形成，[[69]](#cite_note-69)但是好景不长。\n\n## 第一次AI低谷：1974 - 1980\n\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70]](#cite_note-70)同时，由于马文·闵斯基对[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")的激烈批评，[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")（即[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")）销声匿迹了十年。[[71]](#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](/wiki/%E9%80%BB%E8%BE%91%E7%BC%96%E7%A8%8B "逻辑编程")，常识推理等一些领域还是有所进展。[[72]](#cite_note-72)\n\n### 问题\n\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73]](#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74]](#cite_note-74)\n\n### 停止拨款\n\n由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81]](#cite_note-81)1973年[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82]](#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83]](#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84]](#cite_note-84)到了1974年已经很难再找到对AI项目的资助。\n\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85]](#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86]](#cite_note-86)\n\n### 来自大学的批评\n\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")已经证明[形式系统](/wiki/%E5%BD%A2%E5%BC%8F%E7%B3%BB%E7%BB%9F "形式系统")（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87]](#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88]](#cite_note-88)[[89]](#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间")”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](/wiki/%E6%84%8F%E5%90%91%E6%80%A7 "意向性")（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90]](#cite_note-90)\n\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](/wiki/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7 "计算复杂性")和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91]](#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92]](#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93]](#cite_note-93)\n\n约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94]](#cite_note-94)\n\n### 感知器与联结主义遭到冷落\n\n[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")是[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71]](#cite_note-Perceptrons-71)\n\n### “简约派（the neats）”：逻辑，Prolog语言和专家系统\n\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95]](#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96]](#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](/wiki/Prolog "Prolog")。[[97]](#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](/w/index.php?title=%E7%94%9F%E7%94%A2%E8%A6%8F%E5%89%87&action=edit&redlink=1 "生产规则（页面不存在）")（英语：[Production\\_system\\_(computer\\_science)](https://en.wikipedia.org/wiki/Production_system_(computer_science) "en:Production system (computer science)")）”密切相关的“[霍恩子句](/wiki/%E9%9C%8D%E6%81%A9%E5%AD%90%E5%8F%A5 "霍恩子句")”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](/wiki/%E6%84%9B%E5%BE%B7%E8%8F%AF%C2%B7%E8%B2%BB%E6%A0%B9%E9%AE%91%E5%A7%86 "爱德华·费根鲍姆")的[专家系统](/wiki/%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1 "专家系统")以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")及[认知统一理论](/wiki/%E8%AA%8D%E7%9F%A5%E7%B5%B1%E4%B8%80%E7%90%86%E8%AB%96 "认知统一理论")。[[98]](#cite_note-98)\n\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](/wiki/%E9%98%BF%E6%91%A9%E5%8F%B8%C2%B7%E7%89%B9%E6%B2%83%E6%96%AF%E5%9F%BA "阿摩司·特沃斯基")，Daniel Kahneman等人的实验证明了这一点。[[99]](#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100]](#cite_note-100)\n\n### “芜杂派（the scruffies）”：框架和脚本\n\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101]](#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102]](#cite_note-102)\n\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103]](#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n## 第二波浪潮 - 繁荣：1980—1987\n\n在80年代，一类名为“[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n### 专家系统获得赏识\n\n[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104]](#cite_note-104)\n\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105]](#cite_note-105)\n\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106]](#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107]](#cite_note-107)\n\n### 知识革命\n\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108]](#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109]](#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110]](#cite_note-110)\n\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111]](#cite_note-111)\n\n### 重获拨款：第五代工程\n\n1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](/wiki/%E7%AC%AC%E4%BA%94%E4%BB%A3%E9%9B%BB%E8%85%A6 "第五代电脑")项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112]](#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](/wiki/Prolog "Prolog")作为该项目的主要编程语言。[[113]](#cite_note-113)\n\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114]](#cite_note-114)[[115]](#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116]](#cite_note-116)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/250px-Hopfield-net.png)\n\n### 联结主义的重生\n\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 "反向传播算法")，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115]](#cite_note-Norvig_25-115)[[117]](#cite_note-117)\n\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86 "分布式并行处理")”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115]](#cite_note-Norvig_25-115)[[118]](#cite_note-118)\n\n## 第二次AI低谷：1987—1993\n\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n### 人工智慧的低谷\n\n“[AI之冬](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119]](#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120]](#cite_note-120)\n\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")）））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121]](#cite_note-121)\n\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122]](#cite_note-122)\n\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123]](#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123]](#cite_note-FifthGenEnd-123)\n\n### 躯体的重要性：Nouvelle AI与嵌入式推理\n\n80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124]](#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](/wiki/%E8%8E%AB%E6%8B%89%E7%B6%AD%E5%85%8B%E6%82%96%E8%AB%96 "莫拉维克悖论")）。[[125]](#cite_note-125)他们号召“[自底向上](/wiki/%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%92%8C%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%A8%AD%E8%A8%88 "自上而下和自下而上设计")”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。\n\n另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126]](#cite_note-126)\n\n在发表于1990年的论文“大象不玩象棋（Elephants Don\'t Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](/wiki/%E7%89%A9%E7%90%86%E7%AC%A6%E8%99%9F%E7%B3%BB%E7%B5%B1 "物理符号系统")”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127]](#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](/wiki/%E9%AB%94%E5%8C%96%E8%AA%8D%E7%9F%A5 "体化认知")（embodied mind/reason/cognition）”论题。[[128]](#cite_note-128)\n\n## 第三波浪潮 - 大数据与机器学习：1993—2019\n\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129]](#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。\n\n### 里程碑和摩尔定律\n\n1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](/wiki/%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BE%85%E5%A4%AB "卡斯帕罗夫")的第一个计算机系统。[[130]](#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131]](#cite_note-131)2009年，[蓝脑计画](/wiki/%E8%97%8D%E8%85%A6%E8%A8%88%E7%95%AB "蓝脑计画")声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](/w/index.php?title=IBM_%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%A8%8B%E5%BA%8F)&action=edit&redlink=1 "IBM 沃森 (人工智慧程序)（页面不存在）")参加《[危险边缘](/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98 "危险边缘")》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](/wiki/AlphaGo "AlphaGo")击败[李世乭](/wiki/%E6%9D%8E%E4%B8%96%E4%B9%AD "李世乭")，成为第一个不让子而击败职业[围棋](/wiki/%E5%9C%8D%E6%A3%8B "围棋")棋士的[电脑围棋](/wiki/%E7%94%B5%E8%84%91%E5%9B%B4%E6%A3%8B "电脑围棋")程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](/wiki/%E4%B8%AD%E5%9B%BD%E4%B9%8C%E9%95%87%E5%9B%B4%E6%A3%8B%E5%B3%B0%E4%BC%9A "中国乌镇围棋峰会")的三局比赛中击败[[132]](#cite_note-wuzhensecond-132)当时世界排名第一[[133]](#cite_note-133)[[134]](#cite_note-134)的中国棋手[柯洁](/wiki/%E6%9F%AF%E6%B4%81 "柯洁")。\n\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135]](#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136]](#cite_note-136)这种剧烈增长可以用[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n### 智能代理\n\n90年代，被称为“[智能代理](/wiki/%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86 "智能代理")”的新范式被广泛接受。[[137]](#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138]](#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139]](#cite_note-R27-139)当经济学中的“[理性代理](/wiki/%E7%90%86%E6%80%A7%E4%B8%BB%E4%BD%93 "理性主体")（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140]](#cite_note-140)\n\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](/w/index.php?title=%E4%BB%A3%E7%90%86%E6%9E%B6%E6%9E%84&action=edit&redlink=1 "代理架构（页面不存在）")（英语：[Agent\\_architecture](https://en.wikipedia.org/wiki/Agent_architecture "en:Agent architecture")）（像Newell的[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139]](#cite_note-R27-139)[[141]](#cite_note-141)\n\n### “简约派”的胜利\n\n越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142]](#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143]](#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144]](#cite_note-RN25-144)[[145]](#cite_note-145)\n\nJudea Pearl发表于1988年的名著[[146]](#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C "贝叶斯网络")，[隐马尔可夫模型](/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B "隐马尔可夫模型")，[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144]](#cite_note-RN25-144)\n\n### 幕后的AI\n\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147]](#cite_note-147)这些解决方案在产业界起到了重要作用。[[148]](#cite_note-148)应用了AI技术的有[数据挖掘](/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98 "数据挖掘")，[工业机器人](/wiki/%E5%B7%A5%E4%B8%9A%E6%9C%BA%E5%99%A8%E4%BA%BA "工业机器人")，[物流](/wiki/%E7%89%A9%E6%B5%81 "物流")[[149]](#cite_note-149)，[语音识别](/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB "语音识别")[[150]](#cite_note-150)，银行业软件[[151]](#cite_note-CNN7242006-151)，医疗诊断[[151]](#cite_note-CNN7242006-151)和[Google](/wiki/Google "Google")搜索引擎等。[[152]](#cite_note-152)\n\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153]](#cite_note-153)[尼克·博斯特罗姆](/wiki/%E5%B0%BC%E5%85%8B%C2%B7%E5%8D%9A%E6%96%AF%E7%89%B9%E7%BD%97%E5%A7%86 "尼克·博斯特罗姆")解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154]](#cite_note-154)\n\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](/wiki/%E4%BF%A1%E6%81%AF%E5%AD%A6 "信息学")，[知识系统](/w/index.php?title=%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "知识系统（页面不存在）")，[认知系统](/w/index.php?title=%E8%AE%A4%E7%9F%A5%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "认知系统（页面不存在）")或[计算智能](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD&action=edit&redlink=1 "计算智能（页面不存在）")。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155]](#cite_note-155)[[156]](#cite_note-156)[[157]](#cite_note-157)\n\n### HAL 9000在哪里?\n\n1968年[亚瑟·克拉克](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E5%85%8B%E6%8B%89%E5%85%8B "亚瑟·克拉克")和[史丹利·库柏力克](/wiki/%E5%8F%B2%E4%B8%B9%E5%88%A9%C2%B7%E5%BA%AB%E6%9F%8F%E5%8A%9B%E5%85%8B "史丹利·库柏力克")创作的《“[2001太空漫游](/wiki/2001%E5%A4%AA%E7%A9%BA%E6%BC%AB%E6%B8%B8 "2001太空漫游")”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158]](#cite_note-158)\n\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159]](#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")））。[[160]](#cite_note-160)[雷蒙德·库茨魏尔](/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94 "雷蒙德·库茨魏尔")相信问题在于计算机性能，根据[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")，他预测具有人类智能水平的机器将在2029年出现。[[161]](#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162]](#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n### 深度学习，大数据和通用人工智能：2011至2019\n\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n#### 深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](/wiki/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86 "MNIST数据集")（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n#### 大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n## 第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n### 大型语言模型\n\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](/wiki/ChatGPT "ChatGPT")基于[GPT-3.5](/wiki/GPT-3 "GPT-3")架构的[大型语言模型](/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B "大型语言模型")并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，[GPT-4](/wiki/GPT-4 "GPT-4")正式推出，进一步加强大型语言模型的推理能力。2023年8月，中国百度公司向公众开放使用[文心一言](/wiki/%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80 "文心一言")，让中国内地民众都可以使用内地版的大型语言模型。2025年1月，[深度求索](/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2 "深度求索")推出著名的[DeepSeek-R1](/wiki/DeepSeek-R1 "DeepSeek-R1") [开源](/wiki/%E9%96%8B%E6%BA%90 "开源")大型语言模型，并使用新的算法减低训练成本。\n\n### 机器人整合与人工智能的实际应用（2025年至今）\n\n先进的人工智能（AI）系统能够高精度理解和回应人类对话，已成熟到能够与机器人无缝整合，改变了制造业、医疗保健、公共服务和材料研究等行业。[[163]](#cite_note-163) 人工智能还通过高级数据分析和假设生成加速科学研究。[[164]](#cite_note-164) 包括中国、美国和日本在内的国家在政策和资金方面进行了大量投资，以部署人工智能驱动的机器人和人工智能的实际应用，解决劳动力短缺问题，促进创新并提高效率，同时实施监管框架以确保道德和安全发展。[[165]](#cite_note-165)\n\n#### 中国\n\n2025年被誉为“人工智能机器人年”，标志著人工智能（AI）与机器人无缝整合的关键时刻。在2025年，中国投资约7300亿元人民币（约1000亿美元）用于智能制造和医疗保健领域的人工智能和机器人技术发展。[[166]](#cite_note-166) [[167]](#cite_note-167) 第十四个五年规划（2021-2025年）优先发展服务机器人，人工智能系统使机器人能够执行复杂任务，例如协助手术或自动化工厂装配线。[[168]](#cite_note-168) 例如，中国医院中的人工智能人形机器人可以解读患者请求、运送物资并协助护士完成日常任务，显示现有的人工智能对话能力足以应用于实际的机器人应用。部分资金还支持国防应用，例如自主无人机。[[169]](#cite_note-169)[[170]](#cite_note-170) 自2025年9月起，中国要求对人工智能生成的内容进行标记，以确保技术的透明度和公众信任。[[171]](#cite_note-171)\n\n#### 美国\n\n2025年1月，人工智能基础设施投资取得重大进展，[星际之门计划](/wiki/%E6%98%9F%E9%99%85%E4%B9%8B%E9%97%A8%E8%AE%A1%E5%88%92 "星际之门计划") 成立。这家由 [OpenAI](/wiki/OpenAI "OpenAI")、[SoftBank Group](/wiki/SoftBank_Group "SoftBank Group")、[Oracle](/wiki/Oracle_Corporation "Oracle Corporation") 和 [MGX](/w/index.php?title=MGX_Fund_Management_Limited&action=edit&redlink=1 "MGX Fund Management Limited（页面不存在）") 组成的合资企业宣布计划到2029年在[美国](/wiki/%E7%BE%8E%E5%9C%8B "美国")投资5000亿美元用于人工智能基础设施，首期投资1000亿美元，以支持美国的再工业化并提供保护美国及其盟友国家安全的战略能力。[[172]](#cite_note-172) 该合资企业于2025年1月21日由美国总统唐纳德·特朗普正式宣布，SoftBank Group首席执行官 [孙正义](/wiki/%E5%AD%AB%E6%AD%A3%E7%BE%A9 "孙正义") 被任命为主席。[[173]](#cite_note-reuters-173)[[174]](#cite_note-174)\n\n美国政府拨款约20亿美元用于在制造业和物流业中整合人工智能和机器人技术，利用人工智能处理自然语言和执行用户指令的能力。[[175]](#cite_note-175) 各州政府补充资金支持服务机器人，例如部署在仓库中执行口头指令进行库存管理，或在养老院中回应居民的援助请求。[[176]](#cite_note-176) 这些应用表明，将已经熟练于人类交互的高级人工智能与机器人硬体结合是一项实际的前进步骤。\n\n2025年1月，第14179号行政命令确立了“人工智能行动计划”，以加速这些技术的创新和部署。[[177]](#cite_note-177)\n\n#### 影响\n\n2020年代各国政府和机构对AI的投资加速了人工智能的发展，推动了科学进步，提高了劳动效率，并通过自动化复杂任务改变了各行业。[[178]](#cite_note-178) 通过将成熟的人工智能系统整合到各行业的应用当中，这些发展有望彻底改变智能制造和服务行业，重塑人类的日常生活。\n\n## 注释\n\n## 参考文献\n\n`|date=`\n`|date=`\n`|date=`\n\n.\n\n![](https://zh.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&type=1x1&usesul3=1)\n![Wikimedia Foundation](/static/images/footer/wikimedia.svg)\n![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99847525, 'save_path': None}}, {'paper_id': '', 'title': '一文概览人工智能(AI)发展历程 - 知乎专栏', 'authors': [], 'abstract': None, 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/375549477', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99828595, 'save_path': None}}, {'paper_id': '', 'title': '人工智能简史— 深入浅出PyTorch', 'authors': [], 'abstract': 'Theme by the [Executable Book Project](https://ebp.jupyterbook.org)\n\n* [repository](https://github.com/datawhalechina/thorough-pytorch "Source repository")\n* [open issue](https://github.com/datawhalechina/thorough-pytorch/issues/new?title=Issue%20on%20page%20%2F第零章/0.1 人工智能简史.html&body=Your%20issue%20content%20here. "Open an issue")\n* [suggest edit](https://github.com/datawhalechina/thorough-pytorch/edit/master/第零章/0.1 人工智能简史.md "Edit this page")\n\n* [.md](../_sources/第零章/0.1 人工智能简史.md.txt "Download source file")\n\nContents\n\n# 人工智能简史\n\n## Contents\n\n# 人工智能简史[#](#id1 "永久链接至标题")\n\n自从图灵在1950年第一次提出“机器智能（Machine Intelligence）”这个概念以来，人工智能已经经历了七十余年的发展。在这七十多年中，人工智能的发展先后经历了三次浪潮，每一次浪潮对人工智能的发展来说，都是具有里程碑意义的。接下来我们将以这三次浪潮为主线，为大家介绍人工智能的发展历程。除此之外，我们也将会给大家介绍现在常说的Deep learning，Machine Learning和AI之间的关系。\n\n[\\* ]通过本章学习，你将收获：\n\n* 了解人工智能的三次浪潮\n* 了解Deep learning，Machine learning和AI之间的关系\n\n## 1.1 人工智能的三次浪潮[#](#id2 "永久链接至标题")\n\n### 1.1.1 第一次浪潮[#](#id3 "永久链接至标题")\n\n1950年，阿兰·图灵发表著名论文《计算机器与智能》，在这篇论文中，他提出了机器思维的概念和图灵测试，标志着“机器的智能化”正式进入人类的科技树。在此之后的数年间，机器智能有了进一步的发展。两年后的1952年，计算机科学家阿瑟·萨缪尔开发出一款跳棋程序，并提出了“机器学习”这个概念。在此之后的4年里，机器智能化也取得了一定的进步，直到1956年的达特茅斯会议上，约翰·麦卡锡正式提出了“人工智能”这个词语，1956年，也就成为了实际意义上的人工智能元年。\n\n达特茅斯会议之后，人工智能进入了一个高速发展的时期，也就是所谓的“第一次浪潮”。这次浪潮一直持续到二十世纪六十年代中期。在这近10年的时间里，计算机本身的“智能”并没有得到发展，快速进步的是人工智能的一些理论与算法方面。很多对后来人工智能发展起到奠基作用的算法——如罗森布拉特在1957年发明感知机——就是在这个时间段诞生的。感知机是机器学习人工神经网络理论中神经元的最早模型，这一模型也使得人工神经网络理论得到了巨大的突破。除此之外，强化学习的雏形也是在那段时间提出的。彼时的科学界都弥漫着快乐的气氛，大家都认为，只要坚持走下去，人工智能就一定会得到跨越式的发展。但事与愿违，不久后人工智能的第一次寒冬（AI Winter）就到来了。\n\n1966年前后，AI遭遇了瓶颈。人们发现逻辑证明器、感知器、强化学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。研究者们很快就意识到，要求程序对这个世界具有儿童水平的认识这个要求都太高了——那时没人能够做出人工智能需要的巨大数据库，也没人知道一个程序怎样才能学到如此丰富的信息。另一方面，有很多计算复杂度以指数程度增加，这成为了不可能完成的计算任务。\n\n可以说，人工智能的第一次浪潮在发展到“非智能对话机器”的智能化初级阶段时，就因为当时的技术限制不得不停摆。人工智能的发展似乎陷入了一个无解的“死胡同”里，并被计算机科学家们逐渐冷落。\n\n### 1.1.2 第二次浪潮[#](#id4 "永久链接至标题")\n\n时间来到了20世纪80年代。经过了数十年的研究，科学家们逐渐放弃了初代的符号学派思路，改用统计学的思路来研究人工智能。研究思路的改变再加上硬件技术的升级，人工智能的发展又一次迎来的新的契机。在那个时代，基于人工智能的“专家系统”受到了绝对的热捧。特定领域的“专家系统”程序被更广泛的采纳，该系统能够根据领域内的专业知识，推理出专业问题的答案，人工智能也由此变得更加“实用”，专家系统所依赖的知识库系统和知识工程成为了当时主要的研究方向。\n\n但由于专家系统仅适用于某些特定场景，很快人们就对这一系统由狂热的追捧逐渐走向巨大的失望。与此同时，现代电子计算机的出现让“知识查询”的费用进一步降低，人们更加深刻的意识到专家系统是如此的古老陈旧。因此，政府部门下调了专家系统的研发资金。缺少了资金的支持，由专家系统再次兴起的人工智能研究又一次陷入了低谷之中。\n\n虽然第二次浪潮持续的时间比较短，但它在整个人工智能发展历史中仍然起到了举足轻重的作用。它彻底改变了人工智能研究的大思路，将统计学思想引入研究之中，为人工智能在未来几十年的发展打下了基础。除此之外，在这次浪潮中提出的BP神经网络，为之后机器感知、交互的能力奠定了基础。\n\n### 1.1.3 第三次浪潮[#](#id5 "永久链接至标题")\n\n1993年后，新的数学工具，理论和摩尔定律的出现，使得计算机的算力进一步提高，以深度学习为核心的机器学习算法获得发展，新的芯片和云计算的发展使得可用的计算能力获得飞跃式提高，大数据的发展使得海量数据的储存和分析成为可能。在这样的技术背景下，人工智能的第三次浪潮即将到来。\n\n人工智能的第三次浪潮有两个重要的时间节点：2006年和2016年。2006年是深度学习发展史的分水岭。杰弗里辛顿在这一年发表了《一种深度置信网络的快速学习算法》，其他重要的深度学习学术文章也在这一年被发布，在基本理论层面取得了若干重大突破。而2016年3月，谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭，“人工智能”一词正式进入普通民众的视野并被逐渐熟知。至此，人工智能正式迈向了从“科研领域的应用型工具”到“实用性，功能性工具”的转变，人工智能有了新的研究方向和研究模式，即从过去的学术主导型研究逐渐走向了商业主导型研究。随着人类社会对智能化工具的不断追求和探索，人工智能的发展迎来了全新的时代。\n\n### 1.1.4 总结[#](#id6 "永久链接至标题")\n\n上图是对人工智能发展中经历的三次浪潮和两次寒冬的形象总结。除此之外，有观点认为，深度学习算法带来的“技术红利”，将支撑我们再发展5~10年时间，随后就会遇到瓶颈。人工智能不是一个简单的从1到100进步的过程，它往往趋向于两个极端：要么90分以上，其它的都是10分以下。目前，人工智能急需寻找到一个“技术奇点”，让人工智能迅速发展到通用人工智能甚至是超级人工智能的水平。否则，在人工智能研究商业化的今天，无法从中获利的投资人们将快速撤资退场，人工智能或将进入下一个寒冬。\n\n## 1.2 DL,ML,AI三者之间的关系[#](#dl-ml-ai "永久链接至标题")\n\n大家对“人工智能”这个词，也就是我们所谓的“AI”（Artificial Intelligence）想必是非常熟悉，无论是近几年各行各业都喜欢用作营销噱头的“智能化”还是早期电影如《黑客帝国》、《终结者》等，都让AI这个概念深入人心。但近几年，另外两个词语也在逐步进入我们的生活，即就是“机器学习（Machine Learning，ML）”和“深度学习（Deep Learning，DL）”。在接下来的叙述中，我们就将了解DL和ML究竟是什么，以及它们和AI之间的关系。\n\n### 1.2.1 DL和ML是什么[#](#dlml "永久链接至标题")\n\nMachine Learning（机器学习）。它在1959年被机器学习的先驱者之一的阿瑟·塞缪尔定义为：一门研究领域，它赋予计算机无需明确编程就能学习的能力。也就是说，机器学习程序不同于传统编程那样，使用if-then语句那样明确地输入到计算机中以便它根据条件执行。在某种意义上，机器学习程序赋予机器根据所接触到的数据进行自我调整的能力。机器学习更像是一种优化算法，如果我们在事先就对它进行了正确的调整，那么它就会在一遍又一遍的尝试和猜测之中不断减少它的错误，以无限逼近于最终的正确结果。而机器学习的基本思路，也就是将现实问题抽象成为一个数学问题，机器通过训练，寻找到解决数学问题的方法，进而解决现实问题。\n\nDeep Learning（深度学习）。它在2006年被提出，并在近些年得到了迅速的发展。它通过建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据。李开复教授在《人工智能》一书中这样解释深度学习：“假设深度学习要处理的信息是“水流”，而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。网络的入口是若干管道开口，网络的出口也是若干管道开口。这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节阀的总数可以成千上万甚至更多。水管网络中，每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来，组成一个从前到后，逐层完全连通的水流系统。”\n\n### 1.2.2 它们和AI的关系[#](#ai "永久链接至标题")\n\n众所周知，人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。既然如此，那么计算器算是人工智能吗？严格地说是算的，因为它至少做了“模拟”人在计算方面的智能，并扩展了这个能力（比人算得更快）。我们通过代码驱动计算机去帮我们干活，这个算是人工智能吗？也算的。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，说白了，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。\n\n随着人对计算机的期望越来越高，要求它解决的问题越来越复杂，仅仅算的更快，看的更准已经远远不能满足人们的诉求了。要解决的问题域越来越复杂，即使是同一个问题，其面对的场景也越来越多。传统的思路就是查找问题的条件和解决方法，在计算机程序中再加入一个if-then。但这只是治标不治本。随着我们期待解决的问题越来越多，计算机程序将越来越复杂，越来越难以维护。那怎么办呢？于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n\n至此，“机器学习”的概念，正式诞生。机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器自行学会如何执行任务。说白了，机器学习只是人们实现让机器“模拟、延伸和扩展人的智能”的一种较为轻松的方法罢了。它的成功与否取决于我们喂给机器的数据集是否准确且有效。因此，机器学习是大数据技术领域内的一个应用，人们只是借用这个应用，来发展人工智能罢了。机器学习发展了几十年之后，再次遇到了瓶颈期。随着问题场景的更加复杂多变，需要进行判断的条件更加苛刻，人们不得不重新思考一种方式来优化机器学习。深度学习就是带着这个目的被提出的。\n\n机器学习中有一个概念叫“神经网络”，深度学习正是通过优化这个网络来更好的解决通过机器学习难以解决的问题。它的基本特点，就是试图模仿大脑的神经元之间传递，处理信息的模式，通过不同的“层”来拆分问题，每一层解决问题的一个部分。比如在利用深度学习解决智能驾驶问题中，第一层可能用于识别车辆与道路边缘的距离，第二层用于识别道路标线，第三层用于识别路上的其他车辆等等。\n\n通过以上几段话的简单描述，DL,ML和AI之间的关系也就明确了。它们三者的关系就像是俄罗斯套娃：AI最大，它的目的是通过让机器模仿人类进而超越人类；ML次之，它是AI的一个分支（也是最重要分支），是让机器模仿人类的一种方法；DL更次之，它是ML的一个分支，它的目的是让机器不借助人工标注，也能自主提取目标特征进而解决问题的一种方法。\n\n最后，借用一张经典的关系图作为结尾：\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E9%9B%B6%E7%AB%A0/0.1%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99711037, 'save_path': None}}, {'paper_id': '', 'title': 'AI 简史：从神经元到现代大模型 - CSDN博客', 'authors': [], 'abstract': '* [博客](https://blog.csdn.net/)\n* [下载](https://download.csdn.net/)\n* [社区](https://devpress.csdn.net/)\n* [GitCode](https://link.csdn.net?target=https%3A%2F%2Fgitcode.com%3Futm_source%3Dcsdn_toolbar)\n* [GPU算力](https://ai.csdn.net/)\n* 更多\n\n  [会议](https://www.bagevent.com/event/9117243 "会议")[学习](https://edu.csdn.net?utm_source=zhuzhantoolbar "高质量课程·大会云会员")[InsCode](https://inscode.net?utm_source=csdn_blog_top_bar "InsCode")\n\nAI 搜索\n\n# AI 简史：从神经元到现代大模型\n\n原创\n已于\xa02024-12-25 16:28:52\xa0修改\n·\n1.8w 阅读\n\n·\n\n49\n\n·\n89\n·\n\nCC 4.0 BY-SA版权\n\n版权声明：本文为博主原创文章，遵循 [CC 4.0 BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/) 版权协议，转载请附上原文出处链接和本声明。\n\n文章标签：\n\n[#深度学习](https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#人工智能](https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#ai](https://so.csdn.net/so/search/s.do?q=ai&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#神经网络](https://so.csdn.net/so/search/s.do?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#transformer](https://so.csdn.net/so/search/s.do?q=transformer&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#卷积神经网络](https://so.csdn.net/so/search/s.do?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#机器学习](https://so.csdn.net/so/search/s.do?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n\n于\xa02024-12-25 10:54:28\xa0首次发布\n\n[2048 AI社区 文章已被社区收录](javascript:; "2048 AI社区")\n\n[生成AI\n专栏收录该内容](https://blog.csdn.net/jarodyv/category_12199878.html "生成AI")\n\n45 篇文章\n\n该文章已生成可运行项目，\n\n## AI 简史：从神经元到现代大模型\n\n人工智能 (AI) 和深度学习 (DL) 在过去的几十年中飞速发展，推动了[计算机视觉](https://so.csdn.net/so/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&spm=1001.2101.3001.7020)、自然语言处理和机器人等领域的进步。今年的诺贝尔物理学奖更是颁给了美国科学家约翰·霍普菲尔德 (John Hopfield）和英国科学家杰弗里·辛顿（Geoffrey Hinton），表彰他们“在人工神经网络机器学习方面的基础性发现和发明”。本文将为大家概述 AI 的发展历程，梳理出从早期神经网络模型到现代大型语言模型发展过程中的重要里程碑。\n\n图 1. AI 发展全景图\n\n#### 文章目录\n\n* + [1. 人工智能诞生 (1956)](#1__1956_10)\n  + [2. AI 的演进：从基于规则的系统到深度神经网络](#2_AI__36)\n  + [3. 早期人工神经网络 (1940s – 1960s)](#3__1940s__1960s_49)\n  + - [3.1 McCulloch-Pitts 神经元 (1943)](#31_McCullochPitts__1943_51)\n    - [3.2 Rosenblatt 感知机模型 (1957)](#32_Rosenblatt__1957_62)\n    - [3.3 ADALINE (1959)](#33_ADALINE_1959_82)\n    - [3.4 异或（XOR）问题 (1969)](#34_XOR_1969_106)\n  + [4. 多层感知机 (1960)](#4__1960_124)\n  + - [4.1 隐藏层 (Hidden Layers)](#41__Hidden_Layers_133)\n    - [4.2 多层感知机的历史背景与挑战](#42__142)\n  + [5. 反向传播 (1970s – 1980s)](#5__1970s__1980s_151)\n  + - [5.1 早期发展 (1970 年代)](#51__1970__166)\n    - [5.2 强化与普及（1980 年代）](#52_1980__171)\n    - [5.3 通用逼近定理 (1989)](#53__1989_182)\n    - [5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)](#54__1980___1990__191)\n    - [5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)](#55__1990___2000__200)\n    - [深度学习的复兴 (2000 年代末 – 现在)](#_2000____215)\n  + [6. 卷积神经网络 (1980s – 2010s)](#6__1980s__2010s_226)\n  + - [6.1 早期发展 (1980 – 1998)](#61__1980__1998_242)\n    - [6.2 CNN 的崛起：AlexNet (2012)](#62_CNN_AlexNet_2012_258)\n    - [6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）](#63_AlexNet_2010__280)\n    - [6.4 后续架构改进](#64__289)\n    - [6.5 CNN 的应用](#65_CNN__314)\n  + [7. 循环神经网络 (1986 – 2017)](#7__1986__2017_324)\n  + - [7.1 早期发展 (1980s – 1990s)](#71__1980s__1990s_328)\n    - [7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)](#72_LSTM_GRU__Seq2Seq__1997__2014_344)\n    - [7.3 RNN 的应用](#73_RNN__362)\n    - [7.4 RNN 的挑战](#74_RNN__370)\n  + [8. Transformer (2017 – 现在)](#8_Transformer_2017___380)\n  + - [8.1 Transformer 简介](#81_Transformer__384)\n    - [8.2 Transformer 的衍生模型](#82_Transformer__405)\n    - [8.3 OpenAI GPT 的发展历程](#83_OpenAI_GPT__423)\n    - [8.4 其他知名大语言模型](#84__439)\n  + [9. 多模态模型 (2023 – 现在)](#9__2023___457)\n  + - [9.1 GPT-4V (2023) 和 GPT-4o (2024)](#91_GPT4V_2023__GPT4o_2024_459)\n    - [9.2 Google’s Gemini (2023 – 现在)](#92_Googles_Gemini_2023___465)\n    - [9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)](#93_Claude_30__Claude_35_2023___471)\n    - [9.4 LLaVA (2023)](#94_LLaVA_2023_477)\n  + [10. 扩散模型 (2015 – 现在)](#10__2015___488)\n  + - [10.1 扩散模型简介 (2015)](#101__2015_492)\n    - [10.2 扩散模型的发展 (2020 – 现在)](#102__2020___509)\n    - [10.3 文生图模型](#103__523)\n    - [10.4 文生视频模型](#104__533)\n  + [11. 尾声](#11__566)\n\n### 1. 人工智能诞生 (1956)\n\n人工智能（AI）的概念由来已久，但现代 AI 的雏形是在 20 世纪中期逐渐形成的。“人工智能”这个术语是由计算机科学家和认知科学家约翰·麦卡锡 (John McCarthy) 在 1956 年召开的达特茅斯人工智能夏季研讨项目上首次提出并被大家接受，AI 从此走上历史舞台。\n\n图 2.\n[A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence](http://www-formal.stanford.edu/jmc/history/dartmouth.pdf) (1955)\n\n达特茅斯会议通常被视为 AI 研究的发源地。这次会议汇聚了计算机科学家、数学家和认知科学家，共同探讨创造能够模拟人类智能的机器的可能性。与会者中大佬云集，包括：\n\n* **约翰·麦卡锡 (John McCarthy)** ：计算机科学家、Lisp 编程语言发明人之一。\n* **马文·明斯基 (Marvin Minsky)**：计算机科学家、框架理论的创立者。\n* **雷·索洛莫诺夫 (Ray Solomonoff)**：算法概率论创始人，通用概率分布之父，通用归纳推理理论的创建者。\n* **纳撒尼尔·罗切斯特 (Nathaniel Rochester)** ：IBM 701 的首席设计师，编写了世界上第一个汇编程序。\n* **克劳德·香农 (Claude Shannon)** ：数学家、发明家、密码学家，信息论创始人。\n* **奥利弗·塞弗里奇 (Oliver Selfridge)**：模式识别的奠基人、人工智能的先驱，被誉为“机器知觉之父”。\n\n图 3. 参加达特茅斯会议的部分重量级人物\n\n### 2. AI 的演进：从基于规则的系统到深度神经网络\n\n纵观整个 AI 的发展史，有一条清晰的发展脉络，那就是从基于规则的系统向深度神经网络的不断进化。\n\n人工智能 (AI) 的发展始于上个世纪 50 年代，那时人们开始开发用于国际象棋和问题求解的算法。第一个 AI 程序 Logical Theorist 于 1956 年诞生。到了 1960 和 1970 年代，基于规则的专家系统如 MYCIN 被引入，它们可以帮助进行复杂的决策。1980 年代，机器学习开始兴起，使 AI 系统能够从数据中学习并不断改进，为现代深度学习技术奠定了基础。\n\n今天，大多数最前沿的 AI 技术都由深度学习驱动，深刻改变了 AI 的发展格局。深度学习是机器学习的一个独立分支，它通过多层人工神经网络从原始数据中提取复杂特征。在本文中，我们将探讨 AI 的发展历史，并重点介绍深度学习在其中的关键作用。\n\n图 4. 人工智能、机器学习、神经网络、深度学习之间的关系\n\n### 3. 早期人工神经网络 (1940s – 1960s)\n\n#### 3.1 McCulloch-Pitts 神经元 (1943)\n\n神经网络的概念可以追溯到 1943 年，当时 Warren McCulloch 和 Walter Pitts 提出了第一个人工神经元模型。McCulloch-Pitts (MP) 神经元模型是对生物神经元的一种突破性简化。这个模型通过聚合二进制输入，并利用阈值激活函数来做出决策，从而为人工神经网络奠定了基础，输出结果为二进制 \n{\n0\n,\n1\n}\n\\{0, 1\\}\n{0,1}。\n\n图 5. 人工神经元的结构与原理\n\n#### 3.2 Rosenblatt 感知机模型 (1957)\n\nFrank Rosenblatt 在 1957 年引入了感知机，这是一种能够学习和识别模式的单层神经网络。感知机模型比 MP 神经元更为通用，设计用于处理实数值输入，并通过调整权重来最小化分类错误。\n\n图 6. 感知机模型\n\nRosenblatt 还为感知机开发了一种监督学习算法，使得网络能够直接从训练数据中进行学习。  \n \nL\n(\nW\n)\n=\n−\n∑\ni\n∈\nM\nW\nT\nX\ni\ny\ni\n\\mathcal{L}(W) = - \\sum\\_{i \\in M} W^T X\\_i y\\_i\nL(W)=−i∈M∑\u200bWTXi\u200byi\u200b\n\n图 7. Mark I 感知机，是一台实现了图像识别感知机算法的机器\n\nRosenblatt 的感知机展示出识别个人和在不同语言间翻译语音的潜力，这在当时引发了公众对 AI 的极大兴趣。感知机模型及其相关的学习算法成为神经网络发展历程中的重要里程碑。然而，很快就显现出一个关键限制：当训练数据是非线性可分时，感知机的学习规则无法收敛。\n\n#### 3.3 ADALINE (1959)\n\nWidrow 和 Hoff 在 1959 年引入了 ADALINE（自适应线性神经元，也称 Delta 学习规则），对感知机学习规则进行了改进。ADALINE 解决了二进制输出和噪声敏感性等限制，并能够学习并收敛非线性可分的数据，这是神经网络发展中的一大突破。\n\n图 8. ADALINE VS. 感知机\n\nADALINE 的主要特点包括：\n\n* **线性激活函数**：不同于感知器的阶跃函数，ADALINE 使用线性激活函数，因此适用于回归任务和连续输出。\n* **最小均方（LMS）算法**：ADALINE 采用 LMS 算法，该算法通过最小化预测输出与实际输出之间的均方误差，提供更高效和稳定的学习过程。\n* **自适应权重**：LMS 算法根据输出误差自适应调整权重，使 ADALINE 即使在有噪声的情况下也能有效地学习和收敛。\n\n**ADALINE 的引入标志着神经网络第一次黄金时代的开始**，它克服了 Rosenblatt 感知机学习的限制。这一突破实现了高效学习、连续输出和对噪声数据的适应能力，推动了该领域的创新和快速发展。\n\n图 9. ADALINE 开启了神经网络第一次黄金时代\n\n然而，与感知机类似，ADALINE 仍然无法解决线性可分的问题，无法应对更复杂的非线性任务。这一局限集中体现在异或（XOR）问题上，也促进了更高级神经网络架构的发展。\n\n#### 3.4 异或（XOR）问题 (1969)\n\n1969年，Marvin Minsky 和 Seymour Papert 在他们的著作《Perceptrons》中揭示了单层感知机的一个重要局限：由于其线性决策边界，感知机无法解决异或 (XOR) 问题，而这是一个简单的二元分类任务。异或问题不是线性可分的，也就是说，没有一个单一的线性边界能够正确地将所有的输入模式分类。\n\n图 10. Marvin Minsky 和 Seymour Papert 合著的《Perceptrons: An introduction to computational geometry》\n\n这一发现强调了需要开发更复杂的神经网络架构，以便能够学习非线性的决策边界。感知机的局限性被揭露后，人们对神经网络的信心减弱，转而研究符号人工智能方法，**这标志着从 20 世纪 70 年代初到 80 年代中期的“神经网络的第一次黑暗时代”的开始**。\n\n图 11. 异或问题将神经网络代入第一次黑暗时代\n\n### 4. 多层感知机 (1960)\n\n多层感知机 (MLP) 最早于 20 世纪 60 年代提出，作为对单层感知机的改进。MLP 由多个层次的相互连接的神经元组成，能够克服单层模型的局限性。苏联科学家 A. G. Ivakhnenko 和 V. Lapa 在感知机基础上进行研究，对多层感知机的发展中做出了重要贡献。\n\n图 12. 多层感知机模型\n\n#### 4.1 隐藏层 (Hidden Layers)\n\n增加隐藏层使得 MLP (多层感知器) 可以捕捉和表达数据中的复杂非线性关系。这些隐藏层极大地增强了网络的学习能力，使其能够解决诸如异或问题这样非线性可分的问题。\n\n图 13. 隐藏层解决异或问题\n\n#### 4.2 多层感知机的历史背景与挑战\n\nMLP 的出现标志着神经网络的研究向前迈出了重大一步，展示了[深度学习架构](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9E%B6%E6%9E%84&spm=1001.2101.3001.7020)在解决复杂问题方面的潜力。然而，在 1960 年代和 1970 年代，MLP 的发展面临若干挑战：\n\n* **缺乏训练算法**：早期的 MLP 模型缺乏高效的训练算法，无法有效地调整网络权重。此时反向传播算法还未诞生，训练多层深度网络非常困难。\n* **算力限制**：当时的算力不足以应对训练深度神经网络所需的复杂计算。这一限制拖慢了 MLP 的研究和发展进程。\n\n神经网络的第一个黑暗时代在 1986 年结束，**随着反向传播算法的诞生，开启了神经网络的第二个黄金时代**。\n\n### 5. 反向传播 (1970s – 1980s)\n\n1969 年，异或问题揭示了感知机（单层神经网络）的局限性。研究人员意识到，多层神经网络能够克服这些限制，但缺乏有效的训练算法。17年后，反向传播算法的开发使得神经网络在理论上可以逼近任何函数。值得注意的是，该算法实际上在发表之前就已被发明。如今，反向传播已成为深度学习的核心组件，自 20 世纪 60 年代和70 年代以来经历了显著的发展和完善。\n\n图 14. 反向传播原理示意图\n\n反向传播的关键特性：\n\n* **梯度下降**：反向传播与梯度下降联合使用以降低误差函数。该算法计算每个权重相对于误差的梯度，从而逐步调整权重以减少误差。\n* **链式法则**：反向传播算法的核心在于应用微积分的链式法则。此法则使得误差的梯度可以被分解为一系列偏导数，并通过网络的反向传递高效计算。\n* **分层计算**：反向传播逐层运作，从输出层向输入层反向传递。这种分层计算确保梯度在网络中正确传播，使得深度架构的训练成为可能。\n\n#### 5.1 早期发展 (1970 年代)\n\n* **Seppo Linnainmaa (1970)**: 提出了自动微分的概念，这是反向传播算法的重要组成部分。\n* **Paul Werbos (1974)**: 提议使用微积分的链式法则计算误差函数对网络权重的梯度，从而能够训练多层神经网络。\n\n#### 5.2 强化与普及（1980 年代）\n\n* **David Rumelhart, Geoffrey Hinton 和 Ronald Williams (1986)**: 将**反向传播**这一高效实用的方法，用于训练深度神经网络，并展示了其在多种问题中的应用。\n\n图 15. 反向传播算法的三位主要贡献者\n\n其中 Geoffrey Hinton 因其在人工神经网络和机器学习领域的贡献获得了 2018 年图灵奖和 2024 诺贝尔物理学奖，称为继 Herbert Simon 后第二位图灵奖-诺贝尔奖双料得主。\n\n#### 5.3 通用逼近定理 (1989)\n\nGeorge Cybenko 在 1989 年提出的通用逼近定理，为多层神经网络的功能提供了数学基础。该定理表明，只要神经元数量足够，并且使用非线性激活函数，具有单个隐藏层的前馈神经网络就能够以任意精度逼近任意连续函数。这个定理突显了神经网络的强大能力和灵活性，使其能够应用于各种领域。\n\n图 16. 具有单个隐藏层的神经网络可以将任意连续函数逼近到任意所需的精度，从而在各个领域解决复杂的问题\n\n#### 5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)\n\n\\*\\*反向传播算法的出现和通用逼近定理的提出，开启了神经网络研究的第二个黄金时代。\\*\\*反向传播提供了一种高效的多层神经网络训练方法，使研究人员能够构建更深层次和更复杂的模型。通用逼近定理则为使用多层神经网络提供了理论支持，并增强了人们对其解决复杂问题能力的信心。在 1980 年代末至 1990 年代初，这一时期见证了对神经网络领域的兴趣回升和显著的进步。\n\n图 17. 反向传播和通用逼近定理开启了神经网络研究的第二个黄金时代\n\n#### 5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)\n\n然而，由于一系列因素，神经网络领域在 1990 年代初至 2000 年代初经历了“第二个黑暗时代”：\n\n* **支持向量机 (SVM) 的兴起**：支持向量机为分类和回归任务提供了更优雅的数学方法。\n* **算力限制**：由于训练深度神经网络仍然耗时且对硬件要求高，计算能力受到限制。\n* **过拟合和泛化问题**：这两个问题导致早期神经网络在训练数据上表现良好，但在新数据上表现不佳，限制了其实用性。\n\n这些挑战使得许多研究人员转而关注其他领域，导致神经网络研究的停滞。\n\n图 18. 随着 SVM 的兴起，神经网络进入第二个黑暗时代\n\n#### 深度学习的复兴 (2000 年代末 – 现在)\n\n在 2000 年代末和 2010 年代初，神经网络领域经历了复兴，这得益于以下方面的进步：\n\n* **深度学习架构的发展**（如 CNNs、RNNs、Transformers、Diffusion Models）\n* **硬件的改进**（如 GPUs、TPUs、LPUs）\n* **大规模数据集的可用性**（如 ImageNet、COCO、OpenWebText、WikiText 等）\n* **训练算法的优化**（如 SGD、Adam、dropout）\n\n这些进展带来了计算机视觉、自然语言处理、语音识别和强化学习的重大突破。通用逼近定理与实际技术的进步相结合，为深度学习技术的广泛应用和成功奠定了基础。\n\n### 6. 卷积神经网络 (1980s – 2010s)\n\n卷积神经网络 (CNN) 在深度学习领域，尤其是计算机视觉和图像处理方面，带来了革命性的变化。从上个世纪 80 年代到本世纪最初的 10 年，CNN 在架构、训练技术和应用等方面取得了显著的进步。\n\n卷积神经网络由以下三个主要组件构成：\n\n* **卷积层 (Convolutional Layers)**：这些层通过一组可调整的滤波器，从输入图像中自动学习和提取特征的空间层次结构。\n* **池化层 (Pooling Layers)**：池化层通过缩小输入的空间尺寸，来提高对输入变化的适应性，并减少计算量。\n* **全连接层 (Fully Connected Layers)**：在卷积层和池化层之后，全连接层用于分类任务，负责整合之前层中提取的特征。\n\n卷积神经网络的主要特性\n\n* **局部感受野**：CNN 利用局部感受野来捕捉输入数据中的局部特征，使其在处理图像和其他视觉任务时表现出色。\n* **权重共享**：通过在卷积层中共享权重，CNN 能够减少网络中参数的数量，从而提高训练效率。\n* **平移不变性**：池化层赋予网络平移不变性，使其能够识别输入图像中不同位置的相同模式。\n\n#### 6.1 早期发展 (1980 – 1998)\n\n1980 年代，福岛邦彦 (Kunihiko Fukushima) 首次提出了 CNN 的概念，他设计了一种称为神经认知机 (Neocognitron) 的分层神经网络，这种网络模仿了人类视觉皮层的结构。这项开创性的研究为之后 CNN 的发展奠定了基础。\n\n图 19. 福岛邦彦与他的神经认知机\n\n到了 1980 年代末和 1990 年代初，Yann LeCun 和他的团队在此基础上进一步发展了 CNN，并推出了 LeNet-5 架构，该架构专为手写数字识别而设计。\n\n图 20. Yann LeCun 与他的 LeNet-5\n\n#### 6.2 CNN 的崛起：AlexNet (2012)\n\n2012 年，AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了重大胜利，这是 CNN 发展中的一个重要里程碑。这次胜利不仅以压倒性优势赢得了比赛，也在图像分类领域取得了重大突破。\n\n图 21. ILSVRC 历年冠军及其表现\n\nILSVRC 是一个年度图像识别基准测试，用于评估算法在一个包含 1000 万多张注释图像的数据集上的表现，这些图像被划分为 1000 个类别。AlexNet 的创新之处包括：\n\n* **ReLU 激活函数**：为解决传统激活函数的问题而引入，ReLU 提高了训练速度并改善了性能。\n* **Dropout 正则化**：这种技术通过在训练过程中随机丢弃神经元来减少过拟合现象。\n* **数据增强**：通过人为增加训练数据的多样性，增强了数据集的丰富性，从而改善了模型的泛化能力。\n\nAlexNet 的成功成为 CNN 发展中的一个转折点，为图像分类和物体检测的进一步发展奠定了基础。\n\n图 22. AlexNet 架构\n\n#### 6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）\n\n自 2010 年代直至今天，当前的科技发展黄金时代以深度学习、大数据和强大计算平台的结合为特征。在这一时期，图像识别、自然语言处理和机器人技术等领域取得了显著的突破。持续的研究不断推动着人工智能（AI）能力的边界。\n\n图 23. AlexNet 开启神经网络的第三次黄金时代\n\n#### 6.4 后续架构改进\n\n继 AlexNet 之后，又相继出现了几个有影响力的架构：\n\n* **VGGNet (2014)**：由牛津大学的视觉几何组开发，VGGNet 强调使用更深的网络架构，并采用较小的卷积滤波器 (\n  3\n  ×\n  3\n  3 \\times 3\n  3×3)，从而取得了显著的准确率。\n\n  图 24. 原始 VGGNet 架构\n* **GoogLeNet/Inception (2014)**：引入了 inception 模块，使得网络能够以更高效的方式捕捉不同尺度的特征。\n\n  图 25. GooLeNet 架构\n* **ResNet (2015)**：残差网络通过引入跳跃连接，使得训练非常深的网络成为可能，同时缓解了梯度消失问题。\n\n  图 26. ResNet 架构\n\n#### 6.5 CNN 的应用\n\nCNN 的进步已经在多个领域引发了变革：\n\n* **计算机视觉**：CNN 已成为现代计算机视觉的核心，实现了图像分类、物体检测和语义分割方面的突破。\n* **医学影像**：CNN 被用于疾病诊断、肿瘤检测和图像引导手术等任务，大大提高了诊断准确性。\n* **无人驾驶**：CNN 是无人驾驶感知系统的核心，使它们能够解释和响应周围环境。\n\nCNN 从其创立到目前作为深度学习基石的历程展示了其对 AI 的重大影响。CNN 的成功也为深度学习的进一步进步铺平了道路，并激发了其他专用神经网络架构的发展，如 RNN 和 Transformer。CNN 的理论基础和实际创新显著推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 7. 循环神经网络 (1986 – 2017)\n\n循环神经网络 (RNN) 是为了处理序列数据而设计的。与传统的前馈网络（MLP）不同，RNN 拥有一个内部的隐藏状态或“记忆”，使其能够捕捉序列元素之间的时间依赖性。因此，RNN 在语言建模、时间序列预测和语音识别等任务中尤为有效。\n\n#### 7.1 早期发展 (1980s – 1990s)\n\nRNN 的概念起源于 1980 年代，John Hopfield, Michael I. Jordan 和 Jeffrey L. Elman 等先驱为这些网络的发展做出了贡献。John Hopfield在 1982 年提出的 Hopfield 网络为理解神经网络中的循环连接奠定了基础。Jordan 网络和 Elman 网络分别在 1980 年代和 1990 年代提出，是早期捕捉序列数据中时间依赖性的尝试。\n\n图 27. RNN 架构\n\nRNN 使用历时反向传播 (BPTT) 进行训练，这是前馈网络标准反向传播算法的扩展。BPTT 需要将网络在时间上展开，将每个时间步视为一层。在前向传播时，输入序列被处理，并在输出层计算误差。然后，产生的梯度从最后一个时间步反向传播到第一个时间步，以更新 RNN 的参数。然而，由于梯度消失问题，RNN 在学习长时间依赖性时遇到困难，因为梯度会变得极小，导致无法学习。相反，梯度也可能变得过大，造成训练不稳定，这被称为梯度爆炸问题。\n\n图 28. 反向传播 (BPTT)\n\n#### 7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)\n\n图 29. RNN, LSTM, GRU 单元\n\n* **长短期记忆 (LSTM) 网络 (1997)**：Sepp Hochreiter 和 Jürgen Schmidhuber 提出了 LSTM 网络，以解决传统 RNN 中的梯度消失问题。LSTM 通过使用门控机制来控制信息流动，使其能够捕捉序列数据中的长期依赖关系。LSTM 包括单元状态（用于存储长期信息）、隐藏状态（携带当前时间步的短期输出），以及三个门（输入门、遗忘门和输出门）。在每一步中，LSTM 会根据多个数学运算和门来决定需要遗忘多少信息，向单元状态添加多少信息，以及为下一步输出多少信息。\n* **门控循环单元 (GRU) (2014)**：Kyunghyun Cho 等人提出了 GRU，这是一种简化版的 LSTM，也采用门控机制来调节信息流。与 LSTM 的三个门和两个状态不同，GRUs 只有两个门和一个状态。LSTM 的遗忘门和输入门被合并为一个更新门，用于决定保留多少过去的信息和整合多少新信息。此外，GRU 用重置门代替了 LSTM 的输出门，该门决定在整合新信息之前需要“重置”或忘记多少过去的信息。由于 GRU 的参数较少，通常训练速度更快。\n* **Seq2Seq 模型 (2014)**：Ilya Sutskever 和他的团队提出了 Seq2Seq 模型，这种模型使用编码器-解码器架构，将输入序列转换为输出序列。Seq2Seq 模型已被广泛应用于机器翻译、语音识别和文本摘要等任务。\n\n  图 30. 基于 LSTM 的 Seq2Seq 编码器-解码器架构\n\n#### 7.3 RNN 的应用\n\nRNN 在多个领域产生了重大影响，包括：\n\n* **自然语言处理**：RNN 在自然语言处理领域引发了革命性变化，使得语言建模、机器翻译、情感分析和文本生成等任务取得了显著进展。\n* **语音识别**：RNN 广泛用于语音识别系统中，它们通过建模口语的时间依赖性，将语音信号转换为文本。\n* **时间序列预测**：RNN 在时间序列预测中表现出色，它们通过建模顺序数据的时间依赖性，以预测未来值。\n\n#### 7.4 RNN 的挑战\n\n尽管 RNN 在许多方面取得了成功，但其仍面临若干挑战：\n\n* **梯度消失与梯度爆炸**：传统 RNN 在处理这些问题时表现不佳，尽管 LSTM 和 GRU 提供了一些解决方案。\n* **计算复杂性**：训练 RNN 可能需要大量资源，尤其是在处理大型数据集时。\n* **并行化**：RNN 的顺序特性使得并行训练和推理过程变得复杂。\n\nRNN 的成功为深度学习的进一步发展奠定了基础，并启发了其他专门化神经网络架构的发展，例如 Transformer，它们在各种序列数据任务中取得了最先进的性能。RNN 的理论基础和实际创新大大推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 8. Transformer (2017 – 现在)\n\nTransformer 以其卓越的序列数据处理能力，深刻地改变了深度学习的格局，并在自然语言处理 (NLP) 和计算机视觉等多个领域中发挥了重要作用。\n\n#### 8.1 Transformer 简介\n\nVaswani 等人于 2017 年发表了开创性论文“Attention is All You Need”，其中提出了 Transformer 模型。这个模型放弃了 RNN 的传统序列处理方式，转而采用自注意力机制，从而实现了并行处理，并能更好地处理长距离依赖关系。\n\n图 31. 自注意力机制\n\nTransformer 具有如下核心特性：\n\n* **自注意力机制**：允许序列中每个位置灵活地关注其他所有位置，从而比 RNN 或 LSTM 更有效地捕捉上下文。\n* **并行化**：通过同时处理所有输入数据，大大提高了训练速度，这与 RNN 的顺序处理方式形成鲜明对比。\n* **编码器-解码器结构**：编码器和解码器堆栈都使用自注意力和前馈神经网络层，并通过位置编码来保持序列的顺序。\n\n图 32. Transformer 架构\n\n关于 Transformer 和自注意力机制的详细介绍，请参考 [《深度解析 Transformer 和注意力机制（含完整代码实现）》](https://jarod.blog.csdn.net/article/details/130867562) 和 [《图解 NLP 模型发展：从 RNN 到 Transformer》](https://jarod.blog.csdn.net/article/details/129564388)。\n\n#### 8.2 Transformer 的衍生模型\n\n图 33. 基于 Transformer 的模型\n\nTransformer 有众多衍生模型，其中比较重要的有：\n\n* **BERT (2018)**: BERT 是一种仅使用编码器的双向编码器表示模型，通过掩码语言建模和下一句预测的预训练，彻底革新了 NLP。\n* **GPT (2018)**: GPT 旨在预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这一基础模型为生成式语言模型的后续发展奠定了基础，展示了从大型文本语料库中进行无监督学习的潜力。\n* **T5 (2019)**: T5 是一种编码器-解码器结构的文本到文本转换模型，将 NLP 任务转化为统一的文本到文本格式，简化了模型架构和训练过程。\n\n图 34. BERT vs. GTP vs. T5\n\n#### 8.3 OpenAI GPT 的发展历程\n\nOpenAI 的生成式预训练 Transformer (Generative Pre-trained Transformer, GPT) 系列模型自 2018 年问世以来，极大地推动了自然语言处理 (Natural Language Processing, NLP) 领域的发展。每一代模型都在前一代的基础上进行改进，引入了更大规模的模型和增强的功能。以下是每个版本的详细概述。\n\n图 35. GPT 的自回归语言模型架构旨在根据之前输入的 Token 预测序列中的下一个 Token\n\n* **GPT (2018)**: 原始的 GPT 模型于 2018 年推出，作为一个仅使用自回归解码器的变换器，拥有 1.17 亿个参数。它被设计用于预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这个基础模型为后续生成式语言模型的发展奠定了基础，展示了无监督学习从大型文本语料库中获取信息的潜力。\n* **GPT-2 (2019)**: 2019 年发布的 GPT-2 在模型规模和能力上实现了显著飞跃，参数数量扩大到 15 亿个。这个版本表现出一些新兴能力，如零样本任务执行，即可以在没有专门训练的情况下执行任务。然而，它生成连贯但有时误导性文本的能力引发了关于潜在滥用的道德担忧，特别是在生成假新闻或错误信息方面。\n* **GPT-3 (2020)**: GPT-3 于 2020 年推出，进一步将模型规模扩大到惊人的 1750 亿个参数。该模型在少样本学习方面表现出卓越的能力，即可以根据提示中提供的极少量示例适应各种任务。其生成类人文本的能力使其成为许多应用的多功能工具，包括内容创作、代码辅助和对话代理。GPT-3 的架构使其能够在无需大量微调的情况下执行广泛的 NLP 任务，巩固了其作为当时最强大语言模型之一的地位。\n* **ChatGPT (2022):** 这是一个经过微调的 GPT-3.5 模型，通过人类反馈强化学习 (Reinforcement Learning from Human Feedback, RLHF) 进行优化，擅长处理后续问题和维护上下文，通过指令调优和用户偏好数据使响应更符合用户意图。\n* **GPT-4 (2023)**: GPT-4 于 2023 年发布，继续在能力和参数数量上进行扩展，尽管其架构和参数数量的具体细节目前尚未完全公开。预计将在之前几代模型的表现上进一步提升，特别是在推理能力和理解复杂上下文的能力方面。\n* **GPT-o1 (2024)**：这一版本的 GPT 与之前所有版本有了本质区别，它开创性地引入了人类的慢思考+思维链模式，将大模型从越来越离谱的参数内卷中解救出来，开辟了AI发展的新方向。GPT-o1 显著提升了逻辑推理能力，使其在数学、科研、代码等领域的表现有了质的飞跃。在若干基准测试中，GPT-o1 展现出的能力已经与博士生相当。\n\n#### 8.4 其他知名大语言模型\n\n随着越来越多优秀的大型语言模型（LLM）的涌现，人工智能领域得到了极大的丰富。这些模型各具特色，为人工智能技术带来了新的进展。以下是一些知名大语言模型的概况：\n\n* **Anthropic 的 Claude (2022)**: 该模型注重 AI 输出的安全性和伦理问题，致力于与人类价值观保持一致。\n* **Meta 的 LLaMA (2023)**: 提供多种规模的模型，以满足不同的计算需求，在自然语言处理的基准测试中表现卓越。\n* **Mistral.AI 的 Mistral (2023)**: 兼顾高性能和资源效率，适合于实时应用，专注于开源 AI 解决方案。\n* **阿里巴巴的 Qwen (2023)**: 专为创建高质量的英中双语 AI 模型而设计，促进跨语言应用并推动创新。\n* **Microsoft 的 Phi (2023)**: 强调在各种应用中的多功能性和集成能力，采用先进的训练技术以提升上下文理解和用户交互。\n* **Google 的 Gemma 系列 (2024)**: 这些轻量级的开放模型应用于多种领域，包括文本生成、摘要和信息提取，注重性能和效率。\n\n更多大语言模型及其能力评估参加下图\n\n图 36. 开源模型和闭源模型的性能\n\n### 9. 多模态模型 (2023 – 现在)\n\n#### 9.1 GPT-4V (2023) 和 GPT-4o (2024)\n\n* **GPT-4V (2023)** 是 AI 发展中的重要一步，它将多模态功能集成到已经强大的文本模型中。它不仅能够处理和生成文本，还可以处理和生成图像内容，为更全面的 AI 交互奠定了基础。\n* **GPT-4o (2024)** 是从 GPT-4V 演变而来的，通过复杂的上下文理解来增强多模态集成。与其前身相比，它在不同媒体之间提供了更好的连贯性，能够从文本提示生成更高级的图像，并基于视觉输入进行更精细的推理。此外，GPT-4o 通过高级训练机制实现伦理对齐，确保其输出不仅准确，而且负责任，并与人类价值观保持一致。\n\n#### 9.2 Google’s Gemini (2023 – 现在)\n\n* **Gemini Pro (2023)**: Google 的 Gemini 推出了一系列为多模态任务设计的模型，集成了文本、图像、音频和视频处理。特别是，Gemini Pro 因其可扩展性和效率而脱颖而出，使高级 AI 能够应用于从实时分析到跨不同媒体格式的复杂内容生成等多个领域。\n* **Gemini Ultra 和 Nano (2023)**: Gemini 模型包括适用于不同规模应用的 Ultra 和 Nano 版本，能够执行需要跨多种数据类型理解的任务。它们在视频摘要、多模态翻译和互动学习环境等任务中表现出色，体现了 Google 在推动 AI 在多媒体环境中应用的决心。\n\n#### 9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)\n\n* **Claude 3.0 (2023)** 由 Anthropic 推出，该模型专注于提高 AI 响应的安全性和可靠性，在上下文理解和伦理考虑方面进行了改进。它被设计得更具对话性和辅助性，同时严格遵循避免有害或偏见输出的原则。\n* **Claude 3.5 (2024)** 进一步提升了 Claude 3.0 的能力，在复杂任务中的表现更佳，处理效率更高，并且在用户请求的细节处理上更加细致。这个版本还强调多模态交互，虽然它主要在文本和逻辑任务中表现突出，但在处理视觉或其他感官输入方面也展现出新兴能力，提供更为综合的用户体验。\n\n#### 9.4 LLaVA (2023)\n\n* **LLaVA (Large Language and Vision Assistant)** 是一种创新的多模态 AI (Multimodal AI) 方法，将语言理解与视觉处理结合在一起。LLaVA 于 2023 年开发，能够解读图像并将其与文本内容相联系，使其可以回答关于图像的问题、描述视觉内容，甚至根据视觉线索生成文本。其架构充分利用 Transformer 模型的优势，在需要同时具备视觉和语言理解的任务中实现了最先进的性能。这个模型因其开源特性而备受关注，鼓励在多模态 AI 应用领域进行更多的研究和开发。\n\n  图 37. LLaVA 架构\n\n  这些模型的出现标志着 AI 系统的转变，这些系统不仅能够理解和生成文本，还能解释和创造跨多种模态的内容，更加贴近人类的认知能力。这种 AI 模型的发展推动了更具互动性和直观性的应用程序，它们能够结合不同的感官输入来处理现实世界中的场景，从而拓宽了 AI 在日常生活、研究和工业应用中的可能性。\n\n### 10. 扩散模型 (2015 – 现在)\n\n扩散模型已经成为生成模型中一个重要的类别，它为从复杂数据分布中生成高保真样本提供了一种全新的方法。与传统模型如 GAN 和 VAE 不同，扩散模型采用渐进去噪技术，并在许多应用中表现出色。\n\n#### 10.1 扩散模型简介 (2015)\n\n扩散模型的基础由 Sohl-Dickstein 等人于 2015 年在他们的论文中奠定。他们提出了一种生成过程，即通过逆转逐步添加的噪声，可以将噪声还原为结构化数据。\n\n图 38. 扩散模型原理概要\n\n扩散模型的关键特性：\n\n* **去噪过程**: 这些模型通过逐步添加噪声（前向过程），并学习如何逆转该过程（反向过程），以有效去噪并生成样本。\n* **马尔可夫链**: 这两个过程都被构建为马尔可夫链，每个前向步骤添加高斯噪声，模型学习如何在反向过程中去除这些噪声。\n* **训练目标**: 目标是在每一步中最小化预测噪声与实际噪声之间的差异，优化一种证据下界（ELBO）的形式。\n* **稳定性和鲁棒性**: 它们比 GAN 提供更好的稳定性，避免了模式崩溃等问题，从而能够持续生成多样化的高质量输出。\n\n关于扩散模型的详细介绍，请参考[《Diffusion Model 深入剖析》](https://jarod.blog.csdn.net/article/details/130903760)。\n\n#### 10.2 扩散模型的发展 (2020 – 现在)\n\n* **去噪扩散概率模型 (Denoising Diffusion Probabilistic Models, DDPM) (2020)**: 改进了扩散过程，在图像合成领域设立了新的标杆。\n* **去噪扩散隐式模型 (Denoising Diffusion Implicit Models, DDIM) (2021)**: 通过非马尔可夫采样提高了效率，使生成过程更加灵活。\n* **基于分数的生成模型 (2021)**: 通过使用随机微分方程提高了样本生成的效率。\n* **潜在扩散模型 (Latent Diffusion Model) (2022)**: 成为流行的文本到图像生成系统（如 Stable Diffusion）的基础，显著推动了 AI 生成图像领域的进步，并为更易于访问和高效的生成式 AI 工具铺平了道路。关于潜在扩散模型和 Stable Diffusion 的详细介绍，请参见 [《Stable Diffusion 超详细讲解》](https://jarod.blog.csdn.net/article/details/131018599) 和 [《Stable Diffusion原理详解》](https://jarod.blog.csdn.net/article/details/129280836)。\n\n  图 39. 潜在扩散模型架构\n\n#### 10.3 文生图模型\n\n* **DreamBooth (2022)**: 允许在少量特定主题的图像上训练扩散模型，从而实现个性化的图像生成。\n* **LoRA (2022)**: 代表低秩适应，是一种通过添加少量参数来微调扩散模型的技术，使其更容易适应特定任务或数据集。\n* **ControlNet (2023)**: 通过添加如草图或深度图等输入来控制扩散模型，从而对生成图像提供更多的控制。\n* **FLUX.1 (2024)**: Black Forest Lab 推出了 FLUX.1，这是一种用于 AI 图像生成的先进扩散模型，具备卓越的速度、质量和响应提示的能力。FLUX.1 提供三个版本——Schnell、Dev 和 Pro，并采用了整流流变换器等创新技术，能够生成高度逼真的图像。FLUX.1 还可以生成文字并精准处理手指和脚趾等细节，是一个全面的图像生成器。\n* **Multi-SBoRA (2024)**: Multi-SBoRA 是一种为多个概念定制扩散模型的新方法。它使用正交标准基向量来构建低秩矩阵进行微调，允许区域性和非重叠的权重更新，从而减少跨概念的干扰。这种方法保留了预训练模型的知识，减少了计算开销，并提高了模型的灵活性。实验结果显示，Multi-SBoRA 在多概念定制中表现优异，保持了独立性，并减轻了串扰效应。\n\n#### 10.4 文生视频模型\n\n2024 年 2 月，OpenAI 发布了 [Sora](https://openai.com/sora) 文生视频模型。凭借惊艳的视频生成质量，Sora 一经发布就受到各行各业的追捧和关注。尽管在 Sora 之前已经有好几个文生视频模型，但 Sora 的发布被普遍认为拉开了文生视频的大幕。\n\nSora vs. Pika vs. RunwayML vs. Stable Video 生成视频效果对比\n\n很明显可以看出 Sora 无论从分辨率、时长、精细度和对真实世界的还原程度上都远远好于其他模型。下表给出了详细的对比。\n\n图 40. Sora vs. 早期文生视频模型\n\n然而，Sora 发布后迟迟没有正式上线。全网苦等10个月，Sora 终于在 2024 年 12 月 10 日正式上线。在这 10 个月期间，国产文生视频模型迅速崛起，其中 MiniMax 的海螺和快手的可灵的视频生成质量比肩甚至超越 Sora。\n\n| 名称 | 公司 | 单次生成秒数 | 是否免费 | 生成方式 | 最低月付费 |\n| --- | --- | --- | --- | --- | --- |\n| 可灵 | 快手 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 66元 |\n| 即梦 | 字节 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 69元 |\n| 海螺 | MiniMax | 6s | 限制免费使用次数 | 文生视频、图生视频 | 68元 |\n| Vidu | 生数科技 | 4s | 限制免费使用次数 | 文生视频、图生视频 | 9.9美元 |\n| 智谱清言 | 智谱科技 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| 通义万相 | 阿里 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| FilmAction | 瀚皓科技 | 5s | 限制免费使用次数 | 图生视频 | 50元300电影币 |\n| 白日梦 | 光魔科技 | 最长6分钟 | 限制免费使用次数 | 图生视频 | 29元 |\n| Sora | OpenAl | 5s、20s | 付费使用 | 文生视频、图生视频 | 20美元 |\n| Runway | Runway | 10s | 限制免费使用次数 | 文生视频、图生视频 | 15美元 |\n\n表 1. 主流文生视频模型一览表\n\n相信 2025 年文生视频将会是各大 AI 企业主要争夺的战场。\n\n### 11. 尾声\n\n至此，我们的 AI 简史之旅就要接近尾声了。通过对 AI 发展的回顾，我们可以发现人工智能 (AI) 和深度学习的发展历史充满了突破性的进步和变革性的创新。从早期的简单神经网络到复杂的网络架构，从卷积神经网络 (CNN)、递归神经网络 (RNN) 到现在流行的 Transformer 和扩散模型，这些技术已经彻底改变了许多领域。\n\n最近的技术进步催生了大型语言模型和多模态模型，例如 OpenAI 的 GPT-4o、Google 的 Gemini Pro、Antropic 的 Claude 3.5 Sonnet 和 Meta 的 LLaMA3.1 等，它们在自然语言处理和多模态能力方面表现出色。此外，生成式 AI (Generative AI) 的突破，包括文本到图像和文本到视频生成模型如 Midjourney、DALL-E 3、Stable Diffusion、FLUX.1 和 Sora，极大地拓展了 AI 的创造潜力。\n\n随着研究继续致力于开发更高效、可解释和功能强大的模型，AI 和深度学习对社会和技术的影响将不断加深。这些技术进步不仅推动了传统行业的创新，还为创造性表达、问题解决和人机协作开辟了新可能。\n\n然而，深度学习并不是实现 AI 的唯一途径或最佳途径。符号 AI、强化学习和神经符号 AI 各自具有独特优势，并能弥补深度学习在可解释性和计算资源需求方面的不足。对 AI 的全面理解应涵盖这些多样化的方法。\n\nAI 的未来在于多种方法的协同效应。随着研究的深入，构建多元化的 AI 技术生态系统将确保其平衡和有效的发展，从而造福社会和科技领域。\n\n本文章已经生成可运行项目\n\n确定要放弃本次机会？\n\n福利倒计时\n\n*:*\n*:*\n\n立减 ¥\n\n普通VIP年卡可用\n\n[立即使用](https://mall.csdn.net/vip)\n\n[JarodYv](https://jarod.blog.csdn.net)\n\n[关注](javascript:;)\n关注\n\n* 49\n\n  点赞\n* 踩\n* [89](javascript:;)\n\n  收藏\n\n  觉得还不错?\n  一键收藏\n* [2](#commentBox)\n\n  评论\n* [分享](javascript:;)\n\n  复制链接\n\n  分享到 QQ\n\n  分享到新浪微博\n\n  扫一扫\n* [打赏](javascript:;)\n\n  打赏\n* 打赏\n  举报\n\n  举报\n\n专栏目录\n\n[*人工智能*（*AI*）*简史*：推动新时代的科技力量](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[qq\\_17153885的博客](https://blog.csdn.net/qq_17153885)\n\n12-31\n\n1万+\n\n[*人工智能*（*AI*，Artificial Intelligence）是计算机科学的一个分支，旨在研究和开发可以模拟、扩展或增强人类智能的系统。它涉及多种技术和方法，包括*机器学习*、*深度学习*、自然语言处理（NLP）、计算机视觉、专家系统等。](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[最全*AI**简史*（下）：后*深度学习*时代（*大模型*时代）](https://blog.csdn.net/jpw41/article/details/141403498)\n\n[jpw41的博客](https://blog.csdn.net/jpw41)\n\n08-21\n\n2914\n\n[💡 铺垫这么多终于到*大模型*章节了，前面两篇文章分别就*人工智能*和*深度学习*的发展历史进行了介绍，大致可以理解为：20世纪的*人工智能*发展百花齐放、坎坷中前进，进入21世纪后*深度学习*很快成为*人工智能*中的显学，2020年后则以大语言模型为代表范式。这当然不是说一些逻辑规则的、概率统计*机器学习*的甚至是非*Transformer*的*深度学习*结构已经逐渐推出历史舞台，相反大家各自在自己的领域依然是SOTA，也与*大模型*有许多交汇的地方。](https://blog.csdn.net/jpw41/article/details/141403498)\n\n2\xa0条评论\n您还未登录，请先\n登录\n后发表或查看评论\n\n[*AI*进化史*:*从图灵测试到ChatGPT](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n1-30\n\n[*AI**发展史*是一部人类探索智能本质、拓展认知边界的壮丽史诗,而我们正身处其中最具变革性的章节。DeepSeek等新一代*AI*力量的加入,正在书写着这段历史的新篇章。](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n[*人工智能*(Artificial Intelligence, *AI*)\\_*ai**发展史* csdn](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n1-20\n\n[机器翻译领域出现“ALPAC报告”*:*1966年,美国政府因机器翻译进展缓慢(如“the spirit is willing but the flesh is weak”被译为“酒是好的,但肉已变质”),停止资助相关研究,引发第一次*AI*寒冬。 1970s*:*符号主义局限性显现(如无法处理模糊、非结构化问题),加上计算能力不足,科研 funding 锐减,进入第一次*AI*寒冬。](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[CSDN\\_430422的博客](https://blog.csdn.net/CSDN_430422)\n\n07-21\n\n4621\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[收藏级！史上最通俗的*AI*发展历程综述（附*大模型*学习指南）\n\n最新发布](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[大模型教程的博客](https://blog.csdn.net/Z987421)\n\n12-27\n\n556\n\n[规则式*AI*的死板问题，催生了"让机器自主学习规律"的需求——*机器学习*（ML）技术应运而生，标志着*AI*从"规则驱动"迈入"数据驱动"时代。机器从数据中总结出的规律，最终会形成一个"可复用的计算模型"——这就是*AI*模型（Model）。对程序员而言，可理解为"一个经过数据训练的函数，输入新数据就能输出判断结果"。*AI*模型三大核心要素： - 输入：新的待处理数据（如收到的新邮件）；- 处理：用学到的规律对数据进行分析；- 输出：明确的结果（如"垃圾邮件"或"正常邮件"）。](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[*人工智能*发展*简史*, 没想到17世纪*AI*就出现了!\\_17世纪中叶*人工智能*-CSDN...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n12-17\n\n[本文回顾了*人工智能*的发展历程,从17世纪笛卡尔的构想到20世纪中叶图灵测试的提出,再到达特茅斯会议的*人工智能*定义。文章详细介绍了*AI*在商业、游戏、自动驾驶等领域的应用,以及近年来*深度学习*和无监督学习的重大突破。 部署运行你感兴趣的模型镜像一键部署 *人工智能**发展史* ...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n[*人工智能**发展史*\\_*人工智能*的夏天](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n1-17\n\n[Judea Pearl发表于1988年的名著将概率论和决策理论引入*AI*。现已投入应用的新工具包括贝叶斯网络,隐马尔可夫模型,信息论,随机模型和经典优化理论。针对*神经网络*和进化算法等“计算智能”范式的精确数学描述也被发展出来。 大数据*:*2005 - 现在 从某种意义上讲,2005年是大数据元年,虽然大部分人感受不到数据带来的变化,但是...](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n[*Ai**发展史*(个人理解)梳理](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[记录 IT 领域经验与见解的博客](https://blog.csdn.net/q6115759)\n\n04-17\n\n2355\n\n[在21世纪初期，随着计算机硬件的不断提升和大规模数据的出现，*深度学习*成为*人工智能*领域的热门研究方向。总之，*人工智能*是一项非常重要的技术，将对我们的生活和工作产生深远的影响。随着*人工智能*应用场景的不断增多，*人工智能*将更加个性化和定制化，可以根据不同用户的需求提供不同的服务。4. *人工智能*将更加智能和自主。随着*人工智能*技术的不断进步，*人工智能*将更加智能和自主，可以自主学习和决策，提高*人工智能*的效率和智能性。随着*人工智能*应用场景的不断增多，*人工智能*将更加注重安全和隐私，保护用户的数据和信息安全。](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[*人工智能**发展史*](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[JIA\\_NG\\_FA\\_N的博客](https://blog.csdn.net/JIA_NG_FA_N)\n\n06-08\n\n7819\n\n[起步发展期：1943年—20世纪60年代反思发展期：20世纪70年代应用发展期：20世纪80年代平稳发展期：20世纪90年代—2010年蓬勃发展期：2011年至今。](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[最全科普｜万字长文论*人工智能*的前世今生（下篇）](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[GentelAi的博客](https://blog.csdn.net/GentelAi)\n\n03-12\n\n1306\n\n[到1976年，MYCIN的开发工作基本完成，其诊断准确率达到65%-70%，甚至超过了一些人类医生的表现，成为*人工智能*领域的里程碑。1980年，美国数字设备公司（DEC）开发了XCON（eXpert CONfigurer），这是一个用于配置计算机系统的专家系统，成功帮助公司自动化复杂的计算机配置流程，显著降低了配置错误和成本，成为专家系统商业化的成功案例。Word2Vec的提出不仅显著提升了自然语言处理（NLP）任务的性能，也为后续的语言模型（如BERT和GPT）奠定了基础，成为NLP领域的里程碑。](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[一文了解*大模型*：*AI*（*人工智能*）的发展历程](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[m0\\_56255097的博客](https://blog.csdn.net/m0_56255097)\n\n08-23\n\n4429\n\n[*AI**大模型*作为*人工智能*领域的重要技术突破，正成为推动各行各业创新和转型的关键力量。抓住*AI**大模型*的风口，掌握*AI**大模型*的知识和技能将变得越来越重要。学习*AI**大模型*是一个系统的过程，需要从基础开始，逐步深入到更高级的技术。这里给大家精心整理了一份全面的*AI**大模型*学习资源，包括：*AI**大模型*全套学习路线图（从入门到实战）、精品*AI**大模型*学习书籍手册、视频教程、实战学习、面试题等，资料免费分享！](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[看 *人工智能**简史*](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[我相信......](https://blog.csdn.net/wireless_com)\n\n02-25\n\n2819\n\n[这个春节有些心神不定，只得靠读书和学习平复心情。《*人工智能**简史*》去年很火，在京东的销售榜中也很考前，未能免俗，自己抽空读了一遍，随记随想。（图片来自百度百科）过去只是序幕。*人工智能*缘起达特茅斯会议，在...](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[*AI**发展史*：从图灵机到*AI*大时代](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[m0\\_59164304的博客](https://blog.csdn.net/m0_59164304)\n\n05-21\n\n5806\n\n[*AI*无疑是近年来最热门的话题了，它以一种前所末有的速度影响我们的生活。然而,*AI*的发展历程并非一蹴而就,它经历了漫长的探索和曲折。本期,我们将回顾*AI*的发展历程。](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[*人工智能*与*深度学习*发展*简史*：从感知器到多模态*大模型*的技术演进](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*（*AI*）与*深度学习*的*发展史*，是一部融合数学、计算机科学、神经科学、认知心理学与工程实践的宏大叙事，其演进不仅体现了人类对智能本质的持续追问，更深刻重塑了技术范式、产业格局与社会运行逻辑。...](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*发展*简史*：从1943年M-P模型到21世纪*深度学习*爆发](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[资源摘要信息*:**人工智能*发展*简史*1所涵盖的知识点，系统性地勾勒出*人工智能*学科从思想萌芽到学科正式确立的关键演进脉络，其核心在于揭示人类如何在数学、逻辑学、神经生理学、计算机科学与认知科学的交叉融合中，逐步...](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[*AI**发展史*：从*神经网络*到*大模型*的演进之路](https://wenku.csdn.net/doc/706v1gz262)\n\n[本文以“*AI* *简史*：从*神经元*到*现代**大模型*”为题，系统梳理了从早期人工*神经网络*到当前主流*深度学习*架构的关键节点，涵盖了从理论奠基到实际应用的完整脉络，并提供了可运行的源码示例，使得开发者不仅能理解原理，还...](https://wenku.csdn.net/doc/706v1gz262)\n\n[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https://wenku.csdn.net/column/2fcd64w82r)\n\n[[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https*:*//online.visual-paradigm.com/repository/images/06393536-dbad-4462-982f-7661c65029ea/timeline-diagram-design/.png) # 1. *人工智能*...](https://wenku.csdn.net/column/2fcd64w82r)\n\n[*人工智能*发展*简史*：从图灵机、达特茅斯会议到*神经网络*与控制论的演进](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[而麦克洛奇与皮茨于1943年提出的MP*神经元*模型，则是首次用数学微分方程与阈值逻辑模拟生物*神经元*电生理活动的开创性尝试，它虽高度简化，却构建起连接主义范式的原始框架，成为后世感知机、反向传播算法及深度神经...](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[赫布理论](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[qq\\_31374615的博客](https://blog.csdn.net/qq_31374615)\n\n09-21\n\n3958\n\n[赫布理论\n本词条缺少名片图，补充相关内容使词条更完整，还能快速升级，赶紧来编辑吧！\n赫布理论（英语：Hebbian theory）描述了突触可塑性的基本原理，即突触前*神经元*向突触后*神经元*的持续重复的刺激可以导致突触传递效能的增加。这一理论由唐纳德·赫布于1949年提出，又被称为赫布定律（Hebb\'s\nrule）、赫布假说（Hebb\'s postulate）、细胞结集理论（cel](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[*人工智能**简史*\\_*人工智能**简史*](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[科技博客的分析“工具人”](https://blog.csdn.net/cxq8989)\n\n07-10\n\n387\n\n[*人工智能**简史* 在*人工智能*的早期，计算机科学家试图在计算机中重建人类思维的各个方面。 这就是科幻小说中的智力类型，即或多或少像我们一样思考的机器。 毫无疑问，这种类型的智能称为可理解性。 具有可理解性的计算机可用于探索我们如何推理，学习，判断，感知和执行脑力活动。\n可懂度的早期研究集中于在计算机中对现实世界和思维（来自认知科学家的领域）的部分进行建模。 当您考虑到这些实验是在60年前进行的时...](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[*人工智能*（*AI*）的发展历程](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[juzhi14plus的博客](https://blog.csdn.net/juzhi14plus)\n\n08-30\n\n2797\n\n[综上所述，人类在创造*人工智能*这一新物种的过程中，必须从伦理道德、法律监管、技术创新、教育和培训等方面进行应对，以确保*人工智能*的发展符合人类的利益和价值观，为人类社会的发展带来更多的机遇和福祉。十年后的 1966 年，麻省理工学院的约瑟夫・魏泽鲍姆开发了一款名为 ELIZA 的聊天机器人，这款机器人能够与人类进行简单的对话，为以后突破人类与机器之间的沟通障碍迈出了重要一步。*人工智能*的发展给人类带来了巨大的机遇和挑战，人类在创造这一新物种的过程中，必须采取积极有效的措施进行应对。](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[四张图片道清*AI**大模型*的*发展史*(1943-2023)\n\n热门推荐](https://keziyi.blog.csdn.net/article/details/132310317)\n\n[weixin\\_47567401的博客](https://blog.csdn.net/weixin_47567401)\n\n08-16\n\n1万+\n\n[快速了解大规模语言模型的发展历程](https://keziyi.blog.csdn.net/article/details/132310317)\n\n* [关于我们](//www.csdn.net/company/index.html#about)\n* [招贤纳士](//www.csdn.net/company/index.html#recruit)\n* [商务合作](https://fsc-p05.txscrm.com/T8PN8SFII7W)\n* [寻求报道](//marketing.csdn.net/questions/Q2202181748074189855)\n* 400-660-0108\n* [kefu@csdn.net](mailto:webmaster@csdn.net)\n* [在线客服](https://csdn.s2.udesk.cn/im_client/?web_plugin_id=29181)\n* 工作时间\xa08:30-22:00\n\n* [公安备案号11010502030143](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502030143)\n* [京ICP备19004658号](http://beian.miit.gov.cn/publish/query/indexFirst.action)\n* [京网文〔2020〕1039-165号](https://csdnimg.cn/release/live_fe/culture_license.png)\n* [经营性网站备案信息](https://csdnimg.cn/cdn/content-toolbar/csdn-ICP.png)\n* [北京互联网违法和不良信息举报中心](http://www.bjjubao.org/)\n* [家长监护](https://download.csdn.net/tutelage/home)\n* [网络110报警服务](https://cyberpolice.mps.gov.cn/)\n* [中国互联网举报中心](http://www.12377.cn/)\n* [Chrome商店下载](https://chrome.google.com/webstore/detail/csdn%E5%BC%80%E5%8F%91%E8%80%85%E5%8A%A9%E6%89%8B/kfkdboecolemdjodhmhmcibjocfopejo?hl=zh-CN)\n* [账号管理规范](https://blog.csdn.net/blogdevteam/article/details/126135357)\n* [版权与免责声明](https://www.csdn.net/company/index.html#statement)\n* [版权申诉](https://blog.csdn.net/blogdevteam/article/details/90369522)\n* [出版物许可证](https://img-home.csdnimg.cn/images/20250103023206.png)\n* [营业执照](https://img-home.csdnimg.cn/images/20250103023201.png)\n* ©1999-2026北京创新乐知网络技术有限公司\n\n登录后您可以享受以下权益：\n\n* 免费复制代码\n* 和博主大V互动\n* 下载海量资源\n* 发动态/写文章/加入社区\n\n×\n\n评论\xa02\n\n被折叠的\xa0\xa0条评论\n[为什么被折叠?](https://blogdev.blog.csdn.net/article/details/122245662)\n[到【灌水乐园】发言](https://bbs.csdn.net/forums/FreeZone)\n\n查看更多评论\n\n添加红包\n\n发出的红包\n\nJarodYv\n\n¥1\n¥2\n¥4\n¥6\n¥10\n¥20\n\n扫码支付：¥1\n\n您的余额不足，请更换扫码支付或[充值](https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip)\n\n打赏作者\n\n实付元\n\n扫码支付\n\n钱包余额\n0\n\n1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。  \n 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。\n\n[余额充值](https://i.csdn.net/#/wallet/balance/recharge)\n\n确定取消\n\n举报\n\n* 包含不实信息\n* 涉及个人隐私\n\n请选择具体原因（必选）\n\n* 侮辱谩骂\n* 诽谤\n\n请选择具体原因（必选）\n\n* 搬家样式\n* 博文样式\n\n[点击体验  \nDeepSeekR1满血版](https://ai.csdn.net/chat?utm_source=cknow_pc_blogdetail&spm=1001.2101.3001.10583) \n专业的中文 IT 技术社区，与千万技术人共成长\n客服\n返回顶部', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://blog.csdn.net/jarodyv/article/details/144699658', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99694854, 'save_path': None}}, {'paper_id': '', 'title': '人工智能70年：科幻和現實的交融 - BBC', 'authors': [], 'abstract': '[BBC News, \n中文](/zhongwen/trad)\n\n**人類**\n**飛跑著**\n**進入**\n**人工智能（**\n**AI**\n**）**\n**時代。**\n**粗略估算現在人們日常生活中有20多種尋常的**\n**AI**\n**，從垃圾郵件過濾器到叫車軟件。**\n\nAI被分為兩類，這些執行具體任務的AI屬於「弱人工智能」；另一類「強人工智能」，又稱「通用人工智能」（AGI） ，能夠模仿人類思維、決策，有自我意識，自主行動。這一類目前主要出現在科幻作品中，還沒有成為科學現實。\n\n* [聊天機器人最難理解的十大詞匯](/ukchina/trad/vert-fut-46424329)\n* [假如人工智能（AI）有靈魂：這意味著什麼](/ukchina/trad/vert-fut-44641617)\n* [AI和媒體 機器與記者編輯的多重關係](/zhongwen/trad/science-45591003)\n* [人工智能面臨的最大挑戰不是技術？](/ukchina/trad/vert-fut-39433415)\n\n埃德利安·梅耶（Adrienne Mayor）在《諸神與機器人》（Gods and Robots）甚至把希臘古城亞歷山大港稱為最初的硅谷，因為那裏曾經是無數機器人的家園。\n\n[Skip 熱讀 and continue reading](#end-of-recommendations)\n\n**熱讀**\n\n* [美國愛潑斯坦性侵案：解密文件披露百多名政商名人](/zhongwen/trad/world-67890505)\n* [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](https://www.bbc.com/zhongwen/articles/cvgrmn683pro/trad)\n* [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](https://www.bbc.com/zhongwen/articles/cn0y72184yko/trad)\n* [為何中國如此迅速處決明氏家族11人？](https://www.bbc.com/zhongwen/articles/c5yvzn83ye1o/trad)\n\nEnd of 熱讀\n\n除了古希臘、羅馬，其他古文明也不乏人類對"複製自己"的探索。猶太人傳說中有生命的泥人，印度傳說中，守衛佛祖舍利子的機器人武士（模仿古希臘羅馬自動人形機的設計）；佛教傳入前日本的神照神社，中國的兵馬俑，後來又有了達芬奇的機器人武士、會下象棋的木頭人"土耳其"，等等。雖然跟現在一般理解的人工智能似乎風馬牛不相干，但這些嘗試都體現了人類複製、模擬自身的夢想。\n\n不過，法國索邦大學計算機學教授讓-加布裏埃爾·加納西亞（Jean-Gabriel Ganascia）認為，古代神話中人形物體被賦予生命，與今天人們想象和擔憂的「通用人工智能」，即具有超級智能的機器，都更多屬於想象而不是科學現實，至少目前如此。\n\n在開創人工智能學科的先驅者心目中，AI的初衷是用機器來模擬人類、動植物和物種種群的演變，這個學科立足於這樣一種猜想：所有認知功能都可以被精確描述，從而有可能在計算機上複製。\n\n作為現代科技學科的AI歷史很短，但不乏跌宕坎坷。\n\n* [「無頭屍」引發爭議：殺死機器人是否可能](/ukchina/trad/47655496)\n* [人工智能公司為什麼要不停的砸玻璃？](/ukchina/trad/vert-fut-38841260)\n* [「柔情」機器人：人類怎麼對機器人動了真感情](/ukchina/trad/vert-cap-44495182)\n\n## 1940年代——奠基\n\n1943年，美國神經科學家麥卡洛克（Warren McCulloch）和邏輯學家皮茨（Water Pitts）提出神經元的數學模型。後來有人說現代AI夢就誕生在那個時候。\n\n那個夢是一篇題目繞口的論文，《神經活動中內在思想的邏輯演算》（A Logical Calculus of Ideas Immanent in Nervous Activity）。這篇論文被視為人工智能學科的奠基石。現在大熱的「深度學習」，前身是人工神經網絡，而其基礎就是神經元的數學模型。\n\n這篇論文的發表也標誌著人工智能學科三大派之一的仿生學派誕生。這個學派從神經網絡的連接機制著手來發展人工智能，被稱為連接主義派，後來符號邏輯派佔上風幾十年，神經仿生派一直到二十世紀八、九十年代才翻身，以新連接主義面目復興。\n\nAI的另一塊基石是加拿大神經心理學家赫布（Donald Hebb）1949年提出「赫布規則」，簡單說就是兩個細胞如果總是同時被激活，那麼它們之間就有某種關聯，關聯度與同時激活概率成正比關係。這個規則今天用在機器自動學習算法中。\n\n* [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n\n## 1950年代——起步\n\n現在人們普遍把1956年叫做AI元年。人工智能作為一門學科，在這個時期起步並取得了早期成功。\n\n**圖靈和圖靈機**\n\n英國電腦奇才、密碼學家、邏輯學家、計算機與人工智能之父圖靈（Alan Turing）曾想，機器能不能模仿人類的認知、學習過程，用邏輯推理和已有的信息來解決問題，作出決定？他1936年提出圖靈機的設想，就是一種抽象計算模型，實質上是一種數學邏輯機。\n\n1950年，圖靈發表《計算機與智能》（Computing Machineray and Intelligence）論文，文中闡述了"模仿遊戲"的設想和測試方式，就是後來大家熟知的圖靈測試。這篇文章是對機器模仿人類智能的深度思考和系統論述。\n\n**達特茅斯人工智能夏季研討會**\n\n人工智能（artificial intelligence）這個詞1955年首次亮相。當時4位AI鼻祖寫了一份提案，申請開一個研討會研究人工智能。他們估計兩個月，10個人參加，就足以取得重大突破。他們是麥卡錫（John McCarthy）、明斯基（Marvin Minsky）、羅切斯特（Nathaniel Rochester）和香農（Claude Shannon）。\n\n申請獲准，暑期研討會於1956年8月31日在新罕布什爾州達特茅斯學院召開。\n\n研討會被普遍 視為人工智能作為一門學科的創立，所以這一年算AI元年。\n\n**早期**\n**成果**\n\nAI元年後，喜訊不斷。1957年，GPS（通用問題解決器）設想問世。這個設想的原理是任何形式化的符號問題都可以用這個電腦程序來解決。提出設想的是美國卡內基梅隆大學教授、認知心理學和計算機專家紐厄爾（Allen Newell）、西蒙（Herbert A. Simon）和肖。這個設想屬於邏輯、符號派。在短短60年時間裏也經歷了冷暖。\n\n1959年，麥卡錫提出世界上第一個完整的AI系統。那是他在《具備常識的程序》中提出的能像人類一樣學習的假想程序，"Advice Taker"。同年，他和明斯基牽頭在MIT成立了人工智能實驗室。\n\n也是在這一年，塞繆爾首創了機器學習這個概念。他1956年寫的跳棋程序具有自學能力，是世界第一個。\n\n* [人工智能：嚇壞創造者的「深度造假寫手」](/zhongwen/trad/science-47361632)\n* [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n* [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n\n## 1960年——伊莉莎\n\n1961年，世界第一款工業機器人Unimate在美國新澤西的通用電氣工廠上崗試用。1966年，第一台能移動的機器人Shakey問世，就是那個會抽煙的機器人。跟Shakey同年出生的還有伊莉莎。\n\n1966年問世的伊莉莎（Eliza）可以算作今天亞馬遜語音助手Alexa、谷歌助理和蘋果語音助手Siri們的祖母，可以跟人進行書面交流。\n\n「她」沒有人形，沒有聲音，就是一個簡單的機器人程序，通過人工編寫的DOCTOR腳本跟人類進行類似心理諮詢的交談。Eliza的「父親」，後來成為MIT教授的維森鮑姆（Joseph Weizenbaum）解釋說，用這個名字，是因為人們可以教這個程序學習掌握新的語言技能，談吐越來越優雅，就像《窈窕淑女》裏被調教得十分出色的賣花姑娘伊莉莎。\n\n伊莉莎問世時，機器解決問題和釋義語音語言的苗頭已經初露端倪。但是，抽象思維、自我認知和自然語言處理功能等人類智能對機器來說還遙不可及。\n\n半個多世紀後的今天，機器人索菲亞仍需依靠事先輸入的內容才能與人交流，但能說能笑能哭，而且是美女形象。\n\n**批評聲鵲起**\n\n這個時期出現了對人工智能的尖銳批評。\n\n《煉金術與人工智能》發表於1965年，作者德雷弗斯把這篇著名的檄文跟後來陸續寫的文章集成《計算機不能幹什麼》一書，後人凡批評AI必提此書。\n\n另一個刺耳的聲音來自古德（I. J. Good）。他1965年發表了一篇對人工智能未來可能對人類構成威脅的文章，可以算「AI威脅論」的先驅。他認為機器的超級智能和無法避免的智能爆炸最終將超出人類可控範疇。後來著名科學家霍金、發明家和實業家馬斯克對人工智能的恐怖預言跟古德半個世界前的警告遙相呼應。\n\n法國計算機學家加納西亞把這段時間稱為AI發展史上的"預言者時期"，因為學科初創並取得早期成果令人欣喜，難免說些頭腦發熱的話。\n\n流傳較廣的包括美國經濟學家西蒙（Herbert Simon司馬賀）1958年預言，再過10年機器就能問鼎國際象棋世界冠軍；結果是1997年才成真。另外，AI鼻祖明斯基在1968年《2001太空漫遊》記者會上說機器智能30年內可趕超人類 ，現在只是設想。\n\n1968年，科幻大片《2001太空漫遊》上映，導演庫布裏克對人類心靈深處那個古老的渴望做了太空時代的演繹。\n\n## 1970年代－機器人問診\n\n1970年，世界第一個擬人機器人WABOT-1在日本早稻田大學誕生。\n\n除此之外，這段時間AI領域基本上是埋頭科研，主要側重研究機器模擬記憶心理學和理解機制、知識和推理。因此，這個階段AI語義知識表示技術有長足進展，進而推動了專家系統的研發。\n\n專家系統利用一流專家的知識來再現他們的思維過程；從1980年代早期開始在醫療診斷和其他一些領域廣泛應用。\n\n1972年，針對細菌感染的醫療診斷系統MYCIN問世，凖確率69%，專科醫生是80%。1978年 ，用於電腦銷售過程中為顧客自動配置零部件的專家系統XCON誕生。XCON是第一個投入商用的AI專家，也是當時最成功的一款。\n\n1979年，斯坦福大學開始研發自動駕駛技術，但世界上第一次無人駕駛汽車完成首秀是在1986年；那是一輛奔馳麵包車，德國聯邦大學研製，車上有攝像機和感應裝置。它在無人的街道上行駛速度達55mph。\n\n## 1980年代——《終結者》\n\n數據和知識積累推動計算機學習算法發展，使機器能夠利用自己的經驗自動調整編程，AI的應用突飛猛進，如指紋、語音識別等。人工智能、計算機和人造生命開始和其他學科交融，生出混合系統。\n\n1984年，美國普林斯頓大學教授、物理學家、分子生物學家和神經學家霍普菲爾德用模擬集成電路實現了自己兩年前提出的神經網絡模型，這個模型帶動了神經網絡學派的復興。深度學習大熱並取得突破。\n\n同年，深度學習"三巨頭"辛頓（Geoffrey Hinton）、本吉奧（Yoshua Bengio）和楊立昆（Yann LeCun）發表反向傳播算法論文，開啟深度學習潮流。\n\n那年，卡梅隆大片《終結者》上映，作家布魯克斯（Rodney Allen Brooks）發表《大象不下棋》，提出更高層次的AI系統設想：在與環境互動的基礎上打造人工智能。\n\n人工智能三大源頭之一，哲學，又站到聚光燈下。1981年，美國哲學家、數學家與計算機科學家普特南（Hilary W. Putnam）發表《理性、真理與歷史》，提出著名的「缸中腦」假象試驗。\n\n這本身是一個哲學命題，缸中靠營養液存活、通過電腦接收各種刺激而產生感知的大腦，實際上就是虛擬現實。這個假想為人工智能提供了啟示，也引發了對人工智能的哲學思考，也催生了許多科幻作品，比如《盜夢空間》、《源代碼》和《阿凡達》。\n\n## AI的兩個冬季\n\n1974-1980年，1987-1993年，AI遭遇兩次寒冬。\n\n第一次是因為兩份學術報告發表，導致AI領域研究經費銳減。一份是1966年在美國自動語言處理顧問委員會（ALPAC）的《語言與機器：翻譯和語言學中的計算機》（Language and Machines: Computers in Translation and Linguistics），另一份是英國萊特希爾教授（Sir James Lighthill）1973年發表的《人工智能普查報告》。這兩份報告都表達了對先前的投資未能產生預期受益的失望，結論是不應該繼續往AI這個無底洞砸錢。\n\n不過，一線的科研仍在繼續，但直接說AI的少了，諸如機器學習、信息數學、基於知識的系統和模式識別之類新詞開始湧現。\n\n出現第二個冬季則是因為桌面電腦迅速普及，AI系統的金主，包括美國國防部，覺得投資AI性價比不高，興趣大減。但到20世紀末，AI領域再度春暖花開。標誌性事件是1997年IBM深藍大勝世界象棋冠軍卡斯帕洛夫。\n\n歷史上這兩次「錢荒」，跟AI研究資金來源較單一，主要來自政府給學術機構的科研撥款。隨著AI產業化加深，越來越多研發資金來自企業。但AI領域內部的混亂、門派紛爭、各自為政的問題依然存在。\n\n## 1990年代——聊天機器人\n\n1990年代後期，人工智能與機器人和人機界面結合，產生了具有情感和情緒的智能代理，情緒／情感計算（即評估情緒的變化然後在機器上再現）得以迅速發展，尤其是對話代理（聊天機器人）。\n\n1993年，維諾爾·溫奇發表《即將來臨的技術奇點》（The Coming Technological Singularity）一文，預言30年後人類將能夠創造具有超級智慧的機器，由此走上人類終結之路。這個時刻就是後來很多人說的「奇點」。數學家霍金和企業家馬斯克都是機器終結人類說法的信眾。\n\n但對於這個奇點究竟是否存在目前仍有不同看法。\n\n1997年，IBM的深藍超級電腦擊敗世界象棋冠軍卡斯帕洛夫，西蒙1958年的預言算是實現了，儘管晚了近40年。\n\n## 21世紀——深度學習\n\n進入21世紀，許多人工智能的能力已經超越人類，比如圍棋、德州撲克，比如證明數學定理，比如學習從海量數據中自動構建知識，識別語音、面孔、指紋，駕駛汽車，處理海量的文件、物流和製造業的自動化操作。\n\n機器人可以識別和模擬人類情緒，可以充當陪伴和護理員了。AI的應用也因此遍地開花，很快進入人類生活的各個領域。\n\n深度學習和強化學習成了時代強音。\n\n一個普遍認同的說法是，2012年的ImageNet年度挑戰開啟了這一輪AI復興浪潮，把深度學習和大數據推到前台，大量投資資金湧入。ImageNet是為視覺認知軟件研究而設計建立的大型視覺數據庫，由華裔AI科學家李飛飛2007年發起；她當時是普林斯頓大學教授。\n\nImageNet挑戰是每年一度的全行業比武，比誰家的電腦視覺算法最強。2012年奪冠的多倫多大學團隊的圖像識別軟件AlexNet錯誤率比第二名低10.8%。觀察人士總結秘密武器有3個：大數據、更強的電腦、更聰明的算法。\n\n李飛飛現為美國斯坦福大學教授、斯坦福大學人工智能實驗室與視覺實驗室負責人、谷歌雲人工智能和機器學習首席科學家，斯坦福以人為本人工智能研究院共同院長。\n\n另一個值得一提的名字是樊麾，生於中國，圍棋手，職業二段，現任法國圍棋隊總教練。他2015年10月與谷歌人工智能AlphaGO較量0:5敗於對方。他對BBC中文網表示，輸給機器的感覺終身難忘。\n\n過去10年中，人工智能開始寫新聞、搶獨家，經過海量數據訓練學會了識別貓，IBM超級電腦沃森戰勝了智力競賽兩任冠軍，谷歌阿爾法狗戰勝了圍棋世界冠軍，波士頓動力的機器人Atlas學會了三級障礙跳。沃森和阿爾法狗的秘訣都是強化學習。\n\n這個領域的鎮海寶典《深度學習》2015年發表，作者辛頓、本吉奧和楊立昆1980年代就合寫了同樣開行業先河的經典論文，闡述反向傳播算法，2019年獲圖靈獎。\n\n不得不提的是索菲亞。2017年這個擬人機器人亮相時艷驚天下，與人交談語言生動、深刻，沙特搶先給"她"發公民證，後來被楊立昆揭露是個騙局。\n\n因為，索菲亞雖然具備不少先進的技術，包括仿生材料做的皮膚和逼真的面部表情，與人互動時的共情反應，但她只會說事先輸入和設置的話，不具備人們以為她擁有的應用語言智能和思想意識。很快，索菲亞銷聲匿跡。\n\n現代科學誕生前，世界上有迷信，有工匠。然後科學和技術融合，科技和迷信並存；科技和迷信之間有一片寬闊地帶，繁茂地生長著科幻，小說、影視和藝術。\n\n深度學習似乎表明人類向複製自己的原始意願又邁進了一步；人工智能的發展將繼續跌宕起伏，而人與機器的關係、人工智能帶來的倫理挑戰日益成為AI領域的焦點話題。\n\n有人預言，幾百年後，世界上的智慧智能將由3部分組成：人類智能（AI）+人類可控的人工智能+人類不可控的機器智能。\n\n這一切又都離不開人類文明曙光初現時一個古老的夢想。\n\n想象和現實從來不可能一刀兩斷切割，科技和商業更是如影隨形，但區分人工智能（AI）和通用人工智能（AGI），或許有助於減緩第三次「AI寒冬」將至的擔憂和焦慮。\n\n**．**\n\n## 更多相關內容\n\n* ### [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* ### [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* ### [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n* ### [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n* ### [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* ### [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n\n## 頭條新聞\n\n* ### [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](/zhongwen/articles/cvgrmn683pro/trad)\n* ### [「代孕」引爆台灣社會爭論：誰的渴望，誰的風險？](/zhongwen/articles/clyz5pd20jvo/trad)\n* ### [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](/zhongwen/articles/cn0y72184yko/trad)\n\n## 特別推薦\n\n* ### [為什麼中國將英國首相施紀賢來訪視為更大局面的一部分？](/zhongwen/articles/c1m7y585x71o/trad)\n* ### [中國生育率破1新生數回到乾隆年間水平 預測失準後的斷崖式下跌](/zhongwen/articles/cr4kkydv75ro/trad)\n* ### [「時隔太久」：施紀賢習近平在北京「談及人權問題」](/zhongwen/articles/c368y7ex161o/trad)\n* ### [英國首相八年來首次訪華\u3000施紀賢亞洲行的時機和任務](/zhongwen/articles/cx2we08l9qpo/trad)\n* ### [中國調查解放軍最高級將領張又俠 官媒批其「造成極大破壞」](/zhongwen/articles/cx2k4pxdyyzo/trad)\n\n## 更多相關內容\n\n* ### [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* ### [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* ### [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n* ### [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n* ### [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* ### [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n\n## 頭條新聞\n\n* ### [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](/zhongwen/articles/cvgrmn683pro/trad)\n* ### [「代孕」引爆台灣社會爭論：誰的渴望，誰的風險？](/zhongwen/articles/clyz5pd20jvo/trad)\n* ### [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](/zhongwen/articles/cn0y72184yko/trad)\n\n## 特別推薦\n\n* ### [為什麼中國將英國首相施紀賢來訪視為更大局面的一部分？](/zhongwen/articles/c1m7y585x71o/trad)\n* ### [中國生育率破1新生數回到乾隆年間水平 預測失準後的斷崖式下跌](/zhongwen/articles/cr4kkydv75ro/trad)\n* ### [「時隔太久」：施紀賢習近平在北京「談及人權問題」](/zhongwen/articles/c368y7ex161o/trad)\n* ### [英國首相八年來首次訪華\u3000施紀賢亞洲行的時機和任務](/zhongwen/articles/cx2we08l9qpo/trad)\n* ### [中國調查解放軍最高級將領張又俠 官媒批其「造成極大破壞」](/zhongwen/articles/cx2k4pxdyyzo/trad)\n\n## 熱門內容\n\n1. 1\n\n   [美國愛潑斯坦性侵案：解密文件披露百多名政商名人](/zhongwen/trad/world-67890505)\n2. 2\n\n   [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](https://www.bbc.com/zhongwen/articles/cvgrmn683pro/trad)\n3. [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](https://www.bbc.com/zhongwen/articles/cn0y72184yko/trad)\n4. [為何中國如此迅速處決明氏家族11人？](https://www.bbc.com/zhongwen/articles/c5yvzn83ye1o/trad)\n\n7. [此前從未公開的愛潑斯坦島嶼新照片曝光](https://www.bbc.com/zhongwen/articles/cq60906prr3o/trad)\n9. [特權階層接連爆雷，中國網民震怒](https://www.bbc.com/zhongwen/articles/cdxl7w63p1po/trad)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.bbc.com/zhongwen/trad/science-48380424', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.96323055, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 16:00:59,713 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=7, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 16:00:59,713 - __main__ - INFO - handle_download: downloaded=7
2026-02-03 16:00:59,713 - __main__ - INFO - call_tool payload: source_tool=tavily_download, result_type=papers, count=7
2026-02-03 16:00:59,714 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=7
2026-02-03 16:00:59,714 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_[PDF] 人工智能.md'}}
2026-02-03 16:00:59,726 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的80年进化编年史：从想象到现实', 'authors': [], 'abstract': '人工智能的80年进化编年史：从想象到现实\\_腾讯新闻\n# 人工智能的80年进化编年史：从想象到现实\n![头像]![] \n[\nWeb3天空之城\n] \n2023-03-01 20:44发布于浙江科技领域创作者\nAGI是Artificial General Intelligence的缩写，即通用人工智能。\nAGI的目标是实现人类般的通用智能，这意味着AI可以像人类一样理解任意通用任务, 并以人类的智力水平执行完成。基本上, 除了&quot;自我意识&quot;的生成，AGI就是人类对人工智能的终极梦想了。\n无论是近一年来火爆的AI绘画，还是当红炸子鸡ChatGPT，AI研究应用的终极目标, 都是向着AGI通用人工智能的大一统目标在迈进。\n读者是否有同感,\xa0这几年各种AI大模型的发展和突破, 着实有让人眼花缭乱之感?\n本文主要把现代到当下一些AI的重要节点做了时间线梳理和简单分析，或有助于大家来理清楚这些年AI发展的关键脉络。\n1942年\n时间回到80年前, 科幻泰斗阿西莫夫提出了著名的&quot;机器人三定律”：\n机器人不得伤害人类，或坐视人类受到伤害；除非违背第一定律，否则机器人必须服从人类命令；除非违背第一或第二定律，否则机器人必须保护自己。这三个定律是人工智能和机器人技术的哲学基础，是对如何设计人工智能系统的基本原则的阐述，至今都有着重要的参考意义。1950年\n计算机科学之父艾伦·图灵（Alan Turing）发表了具有里程碑意义的论文《Computing Machinery and Intelligence（计算机器与智能）》。论文预言了创造出具有真正智能的机器的可能性，第一次提出图灵测试（The Turing test）的概念：\n如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。1956年\nAI概念诞生。\n美国的达特茅斯学院举行了一次具有传奇色彩的学术会议（Dartmouth Conference）， 探讨用机器模拟人类智能的问题。计算机专家约翰·麦卡锡提出了AI&quot;人工智能”一词。这被广泛认为是人工智能正式诞生的日子。参与会议的学者们是最早的AI研究先驱。\n从1956年到现代，这几十年来AI研究的起伏，有兴趣的读者可以参考本号另一篇文章从爆火的chatGPT讲起: 自然语言生成式AI的前世今生, 你想了解的一切&gt;\n当今大众关于AI的记忆，或许是从1997年开始的：\n1997年\n5月11日, IBM公司的电脑&quot;深蓝”战胜了国际象棋世界冠军卡斯帕罗夫，成为首个击败国际象棋世界冠军的AI系统。\n1998年\n现代卷积神经网络CNN诞生。\n1980年，日本学者福岛邦彦（Kunihiko Fukushima）模仿生物的视觉皮层（visual cortex），设计了人工神经网络&quot;neocognitron”，这是现代卷积神经网络的雏形。\n经过多年前赴后继的研究，1998年杨立昆（Yann LeCun，现任Meta首席人工智能科学家）基于前人基础，构建了更加完备的卷积神经网络LeNet-5，在手写数字的识别问题中取得了成功。LeNet-5被认为是现代卷积神经网络的基本结构。\n卷积神经网络CNN是当今&quot;深度学习&quot;AI模型的计算基础架构。一直到2017年Transformer架构横空出世后，CNN才被取代。\n2003年\nYoshua Bengio在2003年发表了《A Neural Probabilistic Language Model》，这是第一篇基于人工神经网络打造自然语言模型的论文，提出了具有奠基意义的NNLM&quot;神经网络语言模型&quot;。它在得到语言模型的同时也产生了副产品&quot;词向量&quot;。\n2006年\n杰弗里·辛顿（Geoffrey Hinton）在science期刊上发表了重要的论文《Reducing the dimensionality of data with neural networks》，提出深度信念网络（Deep Belief Networks，DBNs），&quot;深度学习&quot;正式诞生。\n2009年\n李飞飞主导的Image Net正式发布，有超过1000万数据，两万多个类别。为全世界的AI学者提供了开放的标注图像大数据集。\n2010年开始，Image Net大规模视觉识别挑战赛（ILSVCR）开始举办，全世界图像领域深度学习的专家们同台竞技和交流，从此拉开了计算机视觉的新篇章。\n2012年\nGoogle的吴恩达和Jef Dean使用1.6万个CPU（那时的GPU生态还在婴幼儿阶段）训练了一个当时世界上最大的人工神经网络，用来教AI绘制猫脸图片。训练数据是来自youtube的1000万个猫脸图片，1.6万个CPU整整训练了3天。\n对于计算机AI领域，这是一次具有突破性意义的尝试。AI第一次&quot;生成&quot;了一个图像内容：一张模糊的猫脸\n![图片] \n2013年\nGoogle的托马斯·米科洛夫（Tomas Mikolov）带领研究团队发表了论文《Efficient Estimation of Word Representations inVector Space》，提出了Word2Vec。\nWord2Vec可以根据给定的语料库，通过优化后的训练模型可以快速有效地将一个词语表达成高维空间里的词向量形式，为自然语言处理领域的应用研究提供了新的工具。\n2014年1月\n谷歌斥资400亿美元收购了位于伦敦的明星人工智能企业DeepMind。\n2014年12月\nGAN（对抗式生成网络）诞生。\n2014 年，Lan Goodfellow从博弈论中的&quot;二人零和博弈&quot;得到启发 ，创造性的提出了生成对抗网络（GAN，Generative Adversarial Networks），他在2014年的NIPS会议上首次发表了相关论文，用两个神经网络即生成器（Generator）和判别器（Discriminator）进行对抗。在两个神经网络的对抗和自我迭代中，GAN会逐渐演化出强大的能力。\n作者在最早的文章里形象的把GAN比喻为伪造者和警察：伪造者总想造出以假乱真的钞票，而警察则努力用更先进的技术去鉴别真伪。在博弈过程中，双方都不断提升了自己的技术水平。\nGAN号称21世纪最强大的算法模型之一，&quot;Gan之父&quot;Ian Goodfellow也一跃成为AI领域的顶级专家。\n2015年12月\nOpenAI公司于美国旧金山成立。\nOpenAI诞生的原因是很有趣的：DeepMind被Google收购的消息震动了硅谷，如果发展下去，DeepMind很有可能成为最早实现AGI通用人工智能的公司。为了打破GoogleAI技术的垄断，在一次私人聚会后，大佬们一拍即合成立了OpenAI。\n其中包括，钢铁侠Elon Musk，当时已是著名创业孵化器 Y Combinator 的负责人现在成为OpenAI CEO的Sam Altman，以及著名天使投资人 Peter Thiel等硅谷大佬。\nOpenAI作为一个非营利性组织运营，并立志要做DeepMind和Google无法做到的事情：开放和共享AI技术。\n从今天的眼光看，尽管OpenAI后来的商业模式有所变化，但绝对实现了它诞生的最大愿景之一：狙击Google和DeepMind。\nChatGPT的推出加上微软Bing的推波助澜搞得Google实在是狼狈不堪。\n2015年\n11月， Google开源了重要的深度学习框架Tensor Flow；\n同年，还是Google，开源了用来分类和整理图像的 AI 程序Inceptionism，并命名为 DeepDream。尽管还很初级，但DeepDream被认为是第一个现代的AI绘画应用。\n2016年\n3月，Google的AlphaGo战胜围棋世界冠军李世石;\n4月，Google深度学习框架TensorFlow发布分布式版本;\n9月，Google上线基于深度学习的机器翻译;\n2015到2016年，Google的AI能力可谓是风头一时无两。\n2017年1月\nFacebook人工智能研究院（FAIR）开源了PyTorch。PyTorch和tensorFlow从此成为了当今两大主流深度学习框架。\n2017年7月\nFacebook联合罗格斯大学和查尔斯顿学院艺术史系三方合作得到新AI绘画模型，号称创造性对抗网络（CAN，Creative Adversarial Networks），\nCAN在测试中，有53%的观众认为AI作品出自人类之手，这是类似的图灵测试历史上首次突破半数，这是AI绘画模型小小而扎实的一步。\nFacebook在AI领域其实耕耘了很久，做过很多贡献，可惜后面搞Metaverse连公司名字都改成Meta了， 差点错过了当下这波AI的浪潮。\n不过最近小札醒悟过来，终于官宣要All in AI。Meta还是很有实力的，奋起直追应为时未晚。\n2017年12月\n颠覆性的Tranformer架构出世了!\nGoogl机器翻译团队在年底的顶级会议NIPS上发表了里程碑式的论文《Attention is all you need》，提出只使用自注意力（Self Attention）机制来训练自然语言模型，并给这种架构起了个霸气的名字：Transformer。\n所谓&quot;自我注意力&quot;机制，简单说就是只关心输入信息之间的关系，而不再关注输入和对应输出的关系。和之前大模型训练需要匹配的输入输出标注数据相比，这是一个革命性的变化。\nTransformer彻底抛弃了传统的CNN和RNN等神经网络结构。在这篇论文发布之前，主流AI模型都基于CNN卷积神经网络和RNN循环神经网络（recurrent neural network）; 而之后，便是Transformer一统天下。\nTransformer架构的详细描述不在本文范围，读者只需要知道它具有两点无敌的优势：\n自我注意力机制，让模型训练只需使用未经标注的原始数据，而无需再进行昂贵的的人工标注（标注输入和对应输出）。并行效率是之前的AI模型结构被一直诟病的地方。抛弃了传统CNN/RNN架构后，基于Transformer架构的大模型训练可以实现高度并行化，这大大提高了模型训练的效率;\n从此，大模型大数据大算力，大力出奇迹，成为了AI领域的标配。\n感慨一下，Google首先发明了划时代的Transformer架构，但在5年后的今天，却被OpenAI打得喘不过气。这是命运的偶然吗？\n2018年6月\nOpenAI发布了第一版的GPT（Generative Pre-training Transformers）系列模型 GPT-1。\n同时，OpenAI发表了论文《Improving Language Understanding by Generative Pre-training》\n从论文里可以了解到，GPT-1具有1.17个参数，采用了12层的Transformer 解码器结构，使用5GB的无标注文本数据，在8个GPU上训练了一个月，然后再进行人工监督的微调。\n不过，GPT-1并不是当年的明星，因为同年，Google的BERT大模型也发布了（当时的Google就是强啊）。\n2018年10月\n谷歌发布3亿参数的BERT（Bidirectional Encoder Representation from Transformers），意思即&quot;来自Transformers的双向编码表示”模型。\nGPT和BERT的诞生意味着预训练大模型（Pre-trained Models）成为了自然语言处理领域的主流。\n和GPT相比，BERT最大的区别就是使用文本的上下文来训练模型，而专注于&quot;文本生成&quot;的GPT-1，使用的是上文。\n基于&quot;双向编码&quot;的能力让BERT的性能在当时明显优异于第一代的GPT-1。\n幸好，Open AI 并没有那么容易放弃，一直坚持只用上文训练的&quot;单向编码&quot;纯生成模式。直到GPT-3，神功初成。\n2018年底\n在共同创立公司三年后，钢铁侠马斯克辞去了Open AI董事会职务，原因是&quot;为了消除潜在的未来冲突&quot;。\n实际情况是，2017年6月，马斯克挖走了OpenAI的核心人员Andrej Karpathy，担任Tesla的AI部门主管并直接向自己汇报，负责构建特斯拉的自动驾驶系统。\n所以，确实是存在人才竞争&quot;潜在冲突&quot;的。\n有趣的是，根据前不久的最新消息，ChatGPT大火之后，Andrej Karpathy同学又离开了Tesla回到了OpenAI。这是所谓&quot;鸟择良木而栖&quot;：）\n而马斯克放出了声音，要打造OpenAI的竞争者。不知首富同学是否遗憾当年不得不放走了OpenAI。\n2019年2月\nOpenAI发布了GPT-2。\nGPT-2有48层Transformer结构，使用40GB文本数据训练，参数量突破到了15亿。\n在同时发布的论文《Language Models are Unsupervised Multitask Learners》 中，OpenAI描述了GPT2在经过大量无标注数据生成式训练后，展示出来的零样本（zero-shot）多任务能力。\n所谓零样本学习就是用很大的通用语料去训练模型，然后不再需要做特定任务的训练，大模型就可以直接完成一些具体任务。一个典型例子是翻译。GPT-2具备了良好的语言翻译能力; 而有趣的是，专门做翻译的模型通常使用标注好的语料（即两个不同语言的匹配数据）来训练。但GPT-2并没有使用这类数据，翻译效果还超过了很多专职翻译的小模型。\nGPT-2揭示了一个有趣的现象，仅作为生成式任务来训练打造的大模型，开始具备了多种通用任务能力，比如GPT-2所具备的阅读理解和翻译等等。\n2019年3-7月\n3月份，OpenAI正式宣布重组，成为一家&quot;利润上限（caped-profit）&quot;的公司，规定了投资收益的上限。这是一个很特别的架构。\n而近期披露的OpenAI最新投资架构也再次揭示了这个公司股权结构的与众不同。简单的说，OpenAI把自己租借给了微软，赚到1500亿美金后，将重新变为非营利性组织 -- 至少说是这么说的。5月，Sam Altman辞去了 YC总裁的工作，开始担任新 OpenAI 的CEO。\n7月，重组后的OpenAI拿到了微软包括Azure云计算资源在内的10亿美金投资， 微软将作为&quot;首选合作伙伴”，今后可获得OpenAI 技术成果的独家授权。自此，OpenAI后续技术成果不再承诺开源。\n2020年5月\nOpenAI发布了GPT-3。\nGPT-3的初始版本在内部代号为&quot;davinci&quot;，使用45TB文本数据训练，有1750亿参数。根据公开信息，模型的训练费用是1200万美金。因为太贵，只训练了一次。\n随后，OpenAI发表了近70页的论文《Language Models are Few-Shot Learner》。这篇论文阐述了大模型的各种新能力，而最重要的就是标题所指出的小样本（few-shot）学习能力。\n&quot;few-shot&quot;是一个专业术语，理解起来也简单，就是通过少量的几个例子就能学习一个新的任务。人们发现，GPT-3开始具有类似人类的能力，只要在提示里展示特定任务的几个示例，GPT-3就能完成新示例的输出。而无需进行针对性的额外微调训练。这也被称之为&quot;上下文学习&quot;（in context learning）\n2020年6月\n对AI绘画有重要意义的论文 《Denoising Diffusion Probabilistic Models》发表， 引入了DDPM模型。 作为领域的奠基之作，这篇论文第一次把2015年诞生的Diffusion&quot;扩散模型&quot;用在了图像生成上。\n用扩散模型生成图像的过程，简单理解，就是我们熟知的图片&quot;降噪&quot;：把一幅全部是噪点的随机图像通过AI算法反复&quot;降噪&quot;到最清晰，一个图像便生成了。\nDDPM的出现把Diffusion扩散模型带到了一个新的高度。在不久之后，DDPM以及后续的Diffusion扩散模型就全面取代了GAN（生成式对抗网络），成为了AI绘画大模型当仁不让的主流技术。\n2020年12月\n由于不再认同转型后的公司文化和战略，OpenAI的部分核心团队出走。\n12月31日，OpenAI发布新闻稿，宣布其研究副总裁Dario Amodei在OpenAI工作了近五年后离开了OpenAI。\nOpenAI正是5年前成立的，这位研究副总看来是妥妥的创始核心。\nDario Amodei带着一些OpenAI的早期核心员工随后创办了Anthropic，推出了ChatGPT的直接竞品Claude。\n被ChatGPT逼急了的Google最近刚给Anthropic紧急投资了3亿美金，以获得其10%的股份，并绑定了其云计算提供商的身份。\n这里说个小知识，加州没有竞业协议，真的是创业者的天堂!\n2021年1月\n1月11日，Google发表论文《Switch Transformers：Scaling to Trillion Parameter Models with Simple and Efficient Sparsity》，提出了最新语言模型—Switch Transformer。\n这个Switch Transformer 模型以高达1.6 万亿的参数量打破了GPT-3 作为最大AI 模型的统治地位，成为史上首个万亿级语言模型。然而，时间会证明一切。2年后的今天，这个万亿参数的Switch大模型在当下似乎没产生任何水花，而千亿参数级别的GPT-3.5系列依然风生水起。这是不是说明一个问题：突破千亿阈值后，参数多少并不代表一切。\n2021年2月\nOpen AI开源了新的深度学习模型 CLIP（Contrastive Language-Image Pre-Training）。\nCLIP是一个多模态模型，用来判断文字和图像两个不同&quot;模态&quot;信息的关联匹配程度。\n在CLIP之前，也有人尝试过这个方向，但OpenAI最大的创意是直接使用全互联网上已经标记过的图像数据，巧妙的避免了海量数据标注的昂贵费用。最后以接近40亿的互联网&quot;文本-图像&quot;训练数据打造了CLIP。\n这次重要的开源直接推动了各大AI绘画模型的迅猛发展。CLIP的多模态能力正是各AI绘画大模型从文字到画面想象力的核心基础。\n同时，OpenAI还发布了自己基于CLIP的 AI绘画DALL-E 模型。这或许是大众听说的第一个&quot;文本生成图像&quot;的AI绘画模型了。\n从CLIP到DALL-E，显然OpenAI走在了AI绘画大模型潮流的最前端。\n只是，OpenAI在AI绘画模型的商业决策上出现了失误：因为没有开放使用DALL-E以及后续DALL-E2，而又开源了关键的CLIP模型，导致目前AI绘画模型的光芒完全被其开源继承者Stable Diffusion，还有付费的Midjourney服务掩盖了。\n正是在AI绘画模型上有苦说不出的经历，直接影响了后来OpenAI管理层的决策：决定在第一时间面向公众抢先推出 ChatGPT聊天机器人。\n2021年4月\n华为的盘古NLP大模型发布，号称是中国第一个千亿参数语言大模型。\n2021年6月\n6 月30 日，OpenAI 和GitHub 联合发布了AI 代码补全工具GitHub Copilot，这个工具可以在 VS Code 编辑器中自动完成代码片段，也是OpenAI 拿了微软10 亿美元之后的第一个重大成果。而Copilot 的AI技术核心正是OpenAI的新模型CodeX。这个模型在随后的8月份也对外发布了。\n根据相关论文《Evaluating Large Language Models Trained on Code》，OpenAI基于GPT-3，使用大量公开代码数据训练出了Codex模型。\nCodex拥有120亿参数，使用了159G代码数据进行训练，模型可以将自然语言描述转换为代码。而效果吗，看看码农们对Copilot的赞不绝口就知道了。\nAI生成代码的时代终于到来了。\n据称，Codex的训练数据来自于公共数据源的数十亿行源代码，而其中最重要的来源，无疑正是微软所买下的GitHub 这个世界上最大的开源代码平台。使用GitHub代码训练模型这个事情还引起了一些程序员关于代码版权的热烈讨论。\n不过，正如画师们对砸了自己饭碗的AI绘画大模型怨声载道而然并卵。。。能力突破的AI对人类初级技能的全面覆盖，恐怕是一个不得不接受的事实。\n从商业角度上看，CodeX的诞生和Copilot的成功证明了OpenAI和微软的商业合作确实是一个双赢。\n2021年10月\n第一个开源的AI绘画大模型Disco-Diffusion诞生!\n发布在Github上的Disco-Diffusion是整个2022年AI绘画旋风的起点。从Disco-Diffusion开始，AI绘画大模型突飞猛进的发展让所有人目不暇接，揭开了AI的新时代。\n2021年12月\n百度第三代文心语言大模型，2600亿参数的ERNIE3.0 Titan发布。\n百度文心和华为盘古都是GPT-3量级的模型，关于国产大模型的具体判断，读者有兴趣可以参考本号国产ChatGPT们的真相&gt;一文\n2022 年3 月OpenAI发布InstructGPT， 同时发表论文《Training language models to follow instructions with human feedback》。\n根据论文，InstructGPT基于GPT-3模型做了进一步微调，并且在模型训练中加入了人类的反馈评价数据。\n这里出现的RLHF &quot;从人类反馈中强化学习&quot;，正是后面ChatGPT所依赖的一个关键技术。\n2022年4月\nOpenAI发布了AI绘画大模型DALL-E 2。\n同一时间，面向公众的付费AI绘画服务Midjourney也发布了。\n和开局王炸，第一年就赚取了大把真金白银的MidJourney相比，使用受限的DALL-E 2并没有在大众人群里产生多少影响力。\n如之前所说，OpenAI在绘画大模型的开放上过于保守了，也许还有优先和微软技术合作的考量在内...\n总之，非常遗憾，绘画模型的风头完全被付费的Midjourney和随后的Stable diffusion抢走。\n2022年5月\nOpenAI发布代号为text-davinci-002的新版大模型，GPT系列正式迈入3.5时代。\n有趣的是，按照OpenAI官方文档说法：\nis a base model，so good for pure code-completion tasks\nis an InstructGPT model based on\n就是说，代号为code的002号模型是3.5系列的基础模型，而代号为text的002号模型是基于code 002模型用指令微调技术得到的 （insturctGPT）\n如果，OpenAI没有在模型名字上混淆视听，一个有趣而合理的推断是：GPT-3.5系列的基础核心模型首先是依赖于代码（Code）大数据训练，而不是普通文本（Text）训练的\n如果这个推断差不太多，那么众多ChatGPT的追随者们，如希望自家能力真正比肩基于GPT-3.5的ChatGPT， 那必须要补的一课，就是代码数据的训练了。2022年6月\n6月15日，谷歌研究院联合DeepMind和斯坦福大学等在arxiv上发表了一篇论文：《Emergent Abilities of Large Language', 'doi': '', 'published_date': '2023-03-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://view.inews.qq.com/a/20230301A08BTW00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '万字长文解读AI发展史，看人工智能将如何改变下个时代_腾讯新闻', 'authors': [], 'abstract': '万字长文解读AI发展史，看人工智能将如何改变下个时代\\_腾讯新闻\n# 万字长文解读AI发展史，看人工智能将如何改变下个时代\n![头像]![] \n[\nINDIGO的数字镜像\n] \n2022-11-15 09:06发布于中国香港科技领域创作者\n就在过去几个月里，因为美联储的加息，科技公司的资本狂欢宣告结束，美国上市的SaaS 公司股价基本都跌去了70%，裁员与紧缩是必要选项。但正当市场一片哀嚎的时候，Dall-E 2 发布了，紧接着就是一大批炫酷的AI 公司登场。这些事件在风投界引发了一股风潮，我们看到那些兜售着基于生成式AI（Generative AI）产品的公司，估值达到了数十亿美元，虽然收入还不到百万美元，也没有经过验证的商业模式。不久前，同样的故事在 Web 3 上也发生过！感觉我们又将进入一个全新的繁荣时代，但人工智能这次真的能带动科技产业复苏么？划重点本文将带你领略一次人工智能领域波澜壮阔的发展史，从关键人物推动的学术进展、算法和理念的涌现、公司和产品的进步、还有脑科学对神经网络的迭代影响，这四个维度来深刻理解“机器之心的进化”。先忘掉那些花里胡哨的图片生产应用，我们一起来学点接近AI 本质的东西。文章较长，累计22800 字，请留出一小时左右的阅读时间，欢迎先收藏再阅读！文中每一个链接和引用都是有价值的，特别作为衍生阅读推荐给大家。阅读之前先插播一段Elon Musk 和Jack Ma 在WAIC 2019 关于人工智能的对谈的经典老视频，全程注意Elon Ma 的表情大家觉得机器智能能否超过人类么？带着这个问题来阅读，相信看完就会有系统性的答案！本文在无特别指明的情况下，为了书写简洁，在同一个段落中重复词汇大量出现时，会用AI（Artifical Intelligence）来代表 人工智能，用ML（Machine Learning）来代表机器学习，DL（Deep Learning）来代表深度学习，以及各种英文缩写来优先表达。\n01\nAI 进化史对于机器是否真能&quot;知道&quot;、&quot;思考 &quot;等问题，我们很难严谨地定义这些。我们对人类心理过程的理解，或许只比鱼对游泳的理解更好一点。\n- John McCarthy\n早在1945 年，Alan Turing 就已经在考虑如何用计算机来模拟人脑了。他设计了ACE（Automatic Computing Engine - 自动计算引擎）来模拟大脑工作。在给一位同事的信中写道：&quot;与计算的实际应用相比，我对制作大脑运作的模型可能更感兴趣 ...... 尽管大脑运作机制是通过轴突和树突的生长来计算的复杂神经元回路，但我们还是可以在ACE 中制作一个模型，允许这种可能性的存在，ACE 的实际构造并没有改变，它只是记住了数据......&quot; 这就是机器智能的起源，至少那时在英国都这样定义。1.1 前神经网络时代神经网络是以模仿人脑中的神经元的运作为模型的计算机系统。AI 是伴随着神经网络的发展而出现的。1956年，美国心理学家 Frank Rosenblatt 实现了一个早期的神经网络演示- 感知器模型（Perceptron Model），该网络通过监督 Learning的方法将简单的图像分类，如三角形和正方形。这是一台只有八个模拟神经元的计算机，这些神经元由马达和转盘制成，与 400 个光探测器连接。![图片] 配图01：Frank Rosenblatt &amp; Perceptron Model\nIBM 的Georgetown 实验室在这些研究的基础上，实现了最早的机器语言翻译系统，可以在英语和俄语之间互译。1956年的夏天，在 Dartmouth College 的一次会议上，AI被定义为计算机科学的一个研究领域，Marvin Minsky（明斯基）, John McCarthy（麦卡锡）, Claude Shannon（香农）, 还有Nathaniel Rochester（罗切斯特）组织了这次会议，他们后来被称为 AI 的&quot;奠基人&quot;。\n![图片] 配图02：Participants of the 1956 Dartmouth Summer Research Project on AI\nDARPA 在这个“黄金”时期，将大部分资金投入AI 领域，就在十年后他们还发明了ARPANET（互联网的前身）。早期的 AI 先驱们试图教计算机做模仿人类的复杂心理任务，他们将其分成五个子领域：推理、知识表述、规划、自然语言处理（NLP）和感知，这些听起来很笼统的术语一直沿用至今。\n从专家系统到机器学习1966年，Marvin Minsky 和Seymour Papert 在《感知器：计算几何学导论》一书中阐述了因为硬件的限制，只有几层的神经网络仅能执行最基本的计算，一下子浇灭了这条路线上研发的热情，AI 领域迎来了第一次泡沫破灭。这些先驱们怎么也没想到，计算机的速度能够在随后的几十年里指数级增长，提升了上亿倍。在上世纪八十年代，随着电脑性能的提升，新计算机语言Prolog &amp; Lisp 的流行，可以用复杂的程序结构，例如条件循环来实现逻辑，这时的人工智能就是专家系统（Expert System），iRobot 公司绝对是那个时代明星；但短暂的繁荣之后，硬件存储空间的限制，还有专家系统无法解决具体的、难以计算的逻辑问题，人工智能再一次陷入窘境。我怀疑任何非常类似于形式逻辑的东西能否成为人类推理的良好模型。- Marvin Minsky\n直到IBM 深蓝在1997年战胜了国际象棋冠军卡斯帕罗夫后，新的基于概率推论（Probabilistic Reasoning）思路开始被广泛应用在 AI 领域，随后IBM Watson 的项目使用这种方法在电视游戏节目《Jeopardy》中经常击败参赛的人类。\n概率推论就是典型的机器学习（Machine Learning）。今天的大多数 AI 系统都是由ML 驱动的，其中预测模型是根据历史数据训练的，并用于对未来的预测。这是AI 领域的第一次范式转变，算法不指定如何解决一个任务，而是根据数据来诱导它，动态地达成目标。因为有了ML，才有了大数据（Big Data）这个概念。\n1.2 Machine Learning 的跃迁Machine Learning 算法一般通过分析数据和推断模型来建立参数，或者通过与环境互动，获得反馈来学习。人类可以注释这些数据，也可以不注释，环境可以是模拟的，也可以是真实世界。Deep Learning\nDeep Learning 是一种Machine Learning算法，它使用多层神经网络和反向传播（Backpropagation）技术来训练神经网络。该领域是几乎是由 Geoffrey Hinton 开创的，早在1986年，Hinton 与他的同事一起发表了关于深度神经网络（DNNs - Deep Neural Networks）的开创性论文，这篇文章引入了反向传播的概念，这是一种调整权重的算法，每当你改变权重时，神经网络就会比以前更快接近正确的输出，可以轻松的实现多层的神经网络，突破了 1966 年Minsky 写的感知器局限的魔咒。![图片] 配图03：Geoffrey Hinton &amp; Deep Neural Networks\nDeep Learning 在2012 年才真正兴起，当时Hinton 和他在多伦多的两个学生表明，使用反向传播训练的深度神经网络在图像识别方面击败了最先进的系统，几乎将以前的错误率减半。由于他的工作和对该领域的贡献，Hinton 的名字几乎成为Deep Learning 的代名词。数据是新的石油Deep Learning 是一个革命性的领域，但为了让它按预期工作，需要数据。而最重要的数据集之一，就是由李飞飞创建的ImageNet。曾任斯坦福大学人工智能实验室主任，同时也是谷歌云 AI/ML 首席科学家的李飞飞，早在2009 年就看出数据对Machine Learning 算法的发展至关重要，同年在计算机视觉和模式识别（CVPR）上发表了相关论文。\n![图片] 配图04：FeiFei Li &amp; ImageNet\n该数据集对研究人员非常有用，正因为如此，它变得越来越有名，为最重要的年度DL 竞赛提供了基准。仅仅七年时间，ImageNet 让获胜算法对图像中的物体进行分类的准确率从72% 提高到了98%，超过了人类的平均能力。\nImageNet 成为DL 革命的首选数据集，更确切地说，是由Hinton 领导的AlexNet 卷积神经网络（CNN - Convolution Neural Networks）的数据集。ImageNet 不仅引领了DL 的革命，也为其他数据集开创了先例。自其创建以来，数十种新的数据集被引入，数据更丰富，分类更精确。神经网络大爆发在Deep Learning 理论和数据集的加持下，2012年以来深度神经网络算法开始大爆发，卷积神经网络（CNN）、递归神经网络（RNN - Recurrent Neural Network）和长短期记忆网络（LSTM - Long Short-Term Memory）等等，每一种都有不同的特性。例如，递归神经网络是较高层的神经元直接连接到较低层的神经元。\n来自日本的计算机研究员福岛邦彦（Kunihiko Fukushima）根据人脑中视觉的运作方式，创建了一个人工神经网络模型。该架构是基于人脑中两种类型的神经元细胞，称为简单细胞和复杂细胞。它们存在于初级视觉皮层中，是大脑中处理视觉信息的部分。简单细胞负责检测局部特征，如边缘；复杂细胞汇集了简单细胞在一个区域内产生的结果。例如，一个简单细胞可能检测到一个椅子的边缘，复杂细胞汇总信息产生结果，通知下一个更高层次的简单细胞，这样逐级识别得到完整结果。\n![图片] 配图05：深度神经网络如何识别物体（TensorFlow）\nCNN 的结构是基于这两类细胞的级联模型，主要用于模式识别任务。它在计算上比大多数其他架构更有效、更快速，在许多应用中，包括自然语言处理和图像识别，已经被用来击败大多数其他算法。我们每次对大脑的工作机制的认知多一点，神经网络的算法和模型也会前进一步！1.3 开启潘多拉的魔盒从2012 到现在，深度神经网络的使用呈爆炸式增长，进展惊人。现在Machine Learning 领域的大部分研究都集中在Deep Learning 方面，就像进入了潘多拉的魔盒被开启了的时代。![图片] 配图06：AI 进化史GAN\n生成对抗网络（GAN - Generative Adversarial Network） 是Deep Learning 领域里面另一个重要的里程碑，诞生于2014 年，它可以帮助神经网络用更少的数据进行学习，生成更多的合成图像，然后用来识别和创建更好的神经网络。GANs 的创造者Ian Goodfellow 是在蒙特利尔的一个酒吧里想出这个主意的，它由两个神经网络玩着猫捉老鼠的游戏，一个创造出看起来像真实图像的假图像，而另一个则决定它们是否是真的。![图片] 配图07：GANs 模拟生产人像的进化GANs 将有助于创建图像，还可以创建现实世界的软件模拟，Nvidia 就大量采用这种技术来增强他的现实模拟系统，开发人员可以在那里训练和测试其他类型的软件。你可以用一个神经网络来“压缩”图像，另一个神经网络来生成原始视频或图像，而不是直接压缩数据，Demis Hassabis 在他的一篇论文中就提到了人类大脑“海马体”的记忆回放也是类似的机制。大规模神经网络大脑的工作方式肯定不是靠某人用规则来编程。- Geoffrey Hinton\n大规模神经网络的竞赛从成立于2011 年的Google Brain 开始，现在属于Google Research。他们推动了 TensorFlow 语言的开发，提出了万能模型Transformer 的技术方案并在其基础上开发了BERT，我们在第四章中将详细讨论这些。\nDeepMind 是这个时代的传奇之一，在2014年被 Google 以5.25 亿美元收购的。它专注游戏算法，其使命是&quot;解决智能问题&quot;，然后用这种智能来 &quot;解决其他一切问题&quot;！DeepMind 的团队开发了一种新的算法Deep Q-Network (DQN)，它可以从经验中学习。2015 年10 月AlphaGo 项目首次在围棋中击败人类冠军李世石；之后的AlphaGo Zero 用新的可以自我博弈的改进算法让人类在围棋领域再也无法翻盘。另一个传奇OpenAI，它是一个由Elon Musk, Sam Altman, Peter Thiel, 还有Reid Hoffman 在2015年共同出资十亿美金创立的科研机构，其主要的竞争对手就是 DeepMind。OpenAI 的使命是通用人工智能（AGI –Artificial General Intelligence），即一种高度自主且在大多数具有经济价值的工作上超越人类的系统。2020年推出的 GPT-3 是目前最好的自然语言生成工具（NLP - Natural Language Processing）之一，通过它的 API 可以实现自然语言同步翻译、对话、撰写文案，甚至是代码（Codex），以及现在最流行的生成图像（DALL·E）。\nGartner AI HypeCycle\nGartner 的技术炒作周期（HypeCycle）很值得一看，这是他们 2022 年最新的关于AI 领域下各个技术发展的成熟度预估，可以快速了解AI 进化史这一章中不同技术的发展阶段。![图片] 配图08：Gartner AI HypeCycle 2022\n神经网络，这个在上世纪60 年代碰到的挫折，然后在2012 年之后却迎来了新生。反向传播花了这么长时间才被开发出来的原因之一就是该功能需要计算机进行乘法矩阵运算。在上世纪70 年代末，世界上最强的的超级电脑之一Cray-1，每秒浮点运算速度 50 MFLOP，现在衡量 GPU 算力的单位是TFLOP（Trillion FLOPs），Nvidia 用于数据中心的最新GPU Nvidia Volta 的性能可以达到125 TFLOP，单枚芯片的速度就比五十年前世界上最快的电脑强大 250 万倍。技术的进步是多维度的，一些生不逢时的理论或者方法，在另一些技术条件达成时，就能融合出巨大的能量。02\n软件2.0 的崛起未来的计算机语言将更多得关注目标，而不是由程序员来考虑实现的过程。- Marvin Minsky\nSoftware 2.0 概念的最早提出人是Andrej Karpathy，这位从小随家庭从捷克移民来加拿大的天才少年在多伦多大学师从 Geoffrey Hinton，然后在斯坦福李飞飞团队获得博士学位，主要研究 NLP 和计算机视觉，同时作为创始团队成员加入了OpenAI，Deep Learning 的关键人物和历史节点都被他点亮。在2017 年被Elon Musk 挖墙脚到了Tesla 负责自动驾驶研发，然后就有了重构的FSD（Full Self-Driving）。\n按照Andrej Karpathy 的定义- “软件2.0 使用更抽象、对人类不友好的语言生成，比如神经网络的权重。没人参与编写这些代码，一个典型的神经网络可能有数百万个权重，用权重直接编码比较困难”。Andrej 说他以前试过，这几乎不是人类能干的事儿。。![图片] 配图09：Andrej Karpathy 和神经网络权重2.1 范式转移在创建深度神经网络时，程序员只写几行代码，让神经网络自己学习，计算权重，形成网络连接，而不是手写代码。这种软件开发的新范式始于第一个Machine Learning 语言TensorFlow，我们也把这种新的编码方式被称为软件 2.0。在 Deep Learning 兴起之前，大多数人工智能程序是用Python 和JavaScript 等编程语言手写的。人类编写了每一行代码，也决定了程序的所有规则。![图片] 配图10：How does Machine Learning work？（TensorFlow）\n相比之下，随着Deep Learning 技术的出现，程序员利用这些新方式，给程序指定目标。如赢得围棋比赛，或通过提供适当输入和输出的数据，如向算法提供具有&quot;SPAM” 特征的邮件和其他没有&quot;SPAM” 特征的邮件。编写一个粗略的代码骨架（一个神经网络架构），确定一个程序空间的可搜索子集，并使用我们所能提供的算力在这个空间中搜索，形成一个有效的程序路径。在神经网络里，我们一步步地限制搜索范围到连续的子集上，搜索过程通过反向传播和随机梯度下降（Stochastic Gradient Descent）而变得十分高效。\n神经网络不仅仅是另一个分类器，它代表着我们开发软件的范式开始转移，它是软件2.0。\n软件1.0 人们编写代码，编译后生成可以执行的二进制文件；但在软件2.0 中人们提供数据和神经网络框架，通过训练将数据编译成二进制的神经网络。在当今大多数实际应用中，神经网络结构和训练系统日益标准化为一种商品，因此大多数软件2.0 的开发都由模型设计实施和数据清理标记两部分组成。这从根本上改变了我们在软件开发迭代上的范式，团队也会因此分成了两个部分:2.0 程序员负责模型和数据，而那些1.0 程序员则负责维护和迭代运转模型和数据的基础设施、分析工具以及可视化界面。Marc Andreessen 的经典文章标题《Why Software Is Eating the World》现在可以改成这样：“软件（1.0）正在吞噬世界，而现在人工智能（2.0）正在吞噬软件！\n2.2 软件的演化软件从1.0 发展到软件2.0，经过了一个叫做“数据产品”的中间态。当顶级软件公司在了解大数据的商业潜力后，并开始使用 Machine Learning 构建数据产品时，这种状态就出现了。下图来自Ahmad Mustapha 的一篇文章《The Rise of Software 2.0》很好地呈现了这个过渡。\n![图片] 配图11：软件产品演化的三种状态\n这个中间态也叫大数据和算法推荐。在现实生活中，这样的产品可以是Amazon 的商品推荐，它们可以预测客户会感兴趣什么，可以是Facebook 好友推荐，还可以是Netflix 电影推荐或Tiktok 的短视频推荐。还有呢？Waze 的路由算法、Airbnb 背后的排名算法等等，总之琳琅满目。数据产品有几个重要特点：1、它们都不是软件的主要功能，通常是为了增加体验，达成更好的用户活跃以及销售目标；2、能够随着数据的增加而进化；3、大部分都是基于传统 ML 实现的，最重要的一点数据产品是可解释的。但有些行业正在改变，Machine Learning 是主体。当我们放弃通过编写明确的代码来解决复杂问题时，这个到2.0 技术栈的转变就发生了，在过去几年中，很多领域都在突飞猛进。语音识别曾经涉及大量的预处理、高斯混合模型和隐式Markov 模型，但今天几乎完全被神经网络替代了。早在1985 年，知名信息论和语言识别专家Fred Jelinek 就有一句经常被引用的段子：“每当我解雇一个语言学家，我们的语音识别系统的性能就会得到提高”。![图片] 配图12：图解软件 2.0 的代表应用除了大家熟悉的图像语音识别、语音合成、机器翻译、游戏挑战之外，AI 在很多传统系统也看到了早期的转型迹象。例如The Case for Learned Index Structures 用神经网络取代了数据管理系统的核心组件，在速度上比B-Trees 缓存优化快70%，同时节省了一个数量级的内存。\n所以，软件2.0 的范式具备了这几个新特征：1、Deep Learning 是主体，所有的功能都是围绕神经网络的输入输出构建的，例如语音识别、自动驾驶；2、可解释性并不重要，一个好的大数据推荐广告可以告诉客户用户看到这条广告的理由，但你没法从神经网络中找到规则，至少目前不行；3、高研发投入与低开发投入，现在大量的成功都来自大学和科技公司的研究部门，论文绝对比应用多。。\n2.3 软件2.0 的优势为什么我们应该倾向于将复杂的程序移植到软件2.0 中？Andrej Karpathy 在《Software 2.0》中给出了一个简单的答案：它们在实践中表现得更好！\n容易被写入芯片由于神经网络的指令集相对较小，主要是矩阵乘法（Matrix Multiplication）和阈值判断（Thresholding at Zero），因此把它们写入芯片要容易得多，例如使用定制的 ASIC、神经形态芯片等等（Alan Turing 在设计ACE 时就这样考虑了）。例如，小而廉价的芯片可以带有一个预先训练好的卷积网络，它们可以识别语音、合成音频、处理视觉信号。当我们周围充斥着低能耗的智能时，世界将会因此而大不同（好坏皆可）。非常敏捷敏捷开发意味着灵活高效。如果你有一段C++ 代码，有人希望你把它的速度提高一倍，那么你需要系统性地调优甚至是重写。然而，在软件2.0 中，我们在网络中删除一半的通道，重新训练，然后就可以了。。它的运行速度正好提升两倍，只是输出更差一些，这就像魔法。相反，如果你有更多的数据或算力，通过添加更多的通道和再次训练，你的程序就能工作得更好。模块可以融合成一个最佳的整体做过软件开发的同学都知道，程序模块通常利用公共函数、API 或远程调用来通讯。然而，如果让两个原本分开训练的软件2.0 模块进行互动，我们可以很容易地通过整体进行反向传播来实现。想象一下，如果你的浏览器能够自动整合改进低层次的系统指令，来提升网页加载效率，这将是一件令人惊奇的事情。但在软件2.0 中，这是默认行为。它做得比你好最后，也是最重要的一点，神经网络比你能想到的任何有价值的垂直领域的代码都要好，目前至少在图像、视频、声音、语音相关的任何东西上，比你写的代码要好。2.4 Bug 2.0\n对于传统软件，即软件1.0，大多数程序都通过源代码保存，这些代码可能少至数千行，多至上亿行。据说，谷歌的整个代码库大约有 20 亿行代码。无论代码有多少，传统的软件工程实践表明，使用封装和模块化设计，有助于创建可维护的代码，很容易隔离Bug 来进行修改。但在新的范式中，程序被存储在内存中，作为神经网络架构的权重，程序员编写的代码很少。软件2.0 带来了两个新问题：不可解释和数据污染。因为训练完成的神经网络权重，工程师无法理解（不过现在对理解神经网络的研究有了很多进展，第六章会讲到），所以我们无法知道正确的执行是为什么？错误又是因为什么？这个和大数据算法有很大的不同，虽然大多数的应用只关心结果，无需解释；但对于一些安全敏感的领域，比如自动驾驶和医疗应用，这确实很重要。在2.0 的堆栈中，数据决定了神经网络的连接，所以不正确的数据集和标签，都会混淆神经网络。错误的数据可能来自失误、也可能是人为设计，或者是有针对性地投喂混淆数据（这也是人工智能领域中新的程序道德规范问题）。例如iOS 系统的自动拼写功能被意外的数据训练污染了，我们在输入某些字符的时候就永远得不到正确的结果。训练模型会认为污染数据是一个重要的修正，一旦完成训练部署，这个错误就像病毒一样传播，到达了数百万部iPhone 手机。所以在这种2.0 版的Bug 中，需要对数据以及程序结果进行良好的测试，确保这些边缘案例不会使程序失败。在短期内，软件2.0 将变得越来越普遍，那些没法通过清晰算法和软件逻辑化表述的问题，都会转入2.0 的新范式，现实世界并不适合整齐地封装。', 'doi': '', 'published_date': '2022-11-15T09:06:40+00:00', 'pdf_url': '', 'url': 'https://news.qq.com/rain/a/20221112A04S4N00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '智能时代的蜕变：人工智能发展历程-百度开发者中心', 'authors': [], 'abstract': '[推荐] \n\n[数据库] \n\n[文心快码 Baidu Comate] \n\n[飞桨PaddlePaddle] \n\n[人工智能] \n\n[云原生] \n\n[超级链] \n\n[百度安全] \n\n[物联网] \n\n[开源技术] \n\n[云计算] \n\n[大数据] \n\n[开发者] \n\n[企业服务] \n\n[更多内容] \n\n[千帆大模型平台] \n\n# 智能时代的蜕变：人工智能发展历程\n\n作者： [谁偷走了我的奶酪] 2024.01.18 13:57浏览量：3\n\n_简介：_ 人工智能经历了从概念提出到实际应用的漫长历程，本文将带您了解人工智能的发展脉络和重要阶段。\n\n在过去的几十年里，人工智能已经从科幻概念逐渐成为我们日常生活的一部分。它的起源可以追溯到20世纪50年代，当时科学家们开始探索让计算机具备人类智能的可能性。人工智能的发展经历了多个阶段，每个阶段都有其独特的贡献和里程碑。第一阶段：人工智能的起源（1950-1974）人工智能的起源可以追溯到1950年，当时计算机科学家阿兰·图灵提出了著名的图灵测试。该测试旨在判断一台机器是否具备智能，通过让人类与机器对话，如果人类不能区分与机器对话的是人类还是机器，则认为这台机器具有智能。这一想法为人工智能的发展奠定了基础。第二阶段：专家系统与商业化（1980-1987）到了20世纪80年代，人工智能开始进入商业化应用阶段。专家系统是这一时期的代表，它们是包含专门领域知识的计算机系统，能够提供专业意见和建议。专家系统的流行使得人工智能开始在医疗、金融等领域得到应用。第三阶段： [神经网络] 的兴起（1987-1994）神经网络是模拟人类大脑神经元网络的 [机器学习] 算法。在20世纪80年代末和90年代初，神经网络成为人工智能领域的研究热点。然而，由于计算能力的限制和训练数据不足，神经网络的应用受到限制。第四阶段：支持向量机与核方法的兴起（1995-2008）随着计算机技术的进步，支持向量机和核方法在人工智能领域的应用逐渐普及。支持向量机是一种分类算法，核方法则用于解决非线性问题。这些方法在 [语音识别] 、图像处理等领域取得了显著成果。第五阶段： [深度学习] 的崛起（2008至今）深度学习是人工智能领域的一种重要技术，它通过构建深度神经网络来模拟人类大脑的行为。自2008年以来，随着计算能力的提升和大数据的涌现，深度学习在语音识别、 [图像识别] 、 [自然语言处理] 等领域取得了重大突破。如今，人工智能已经渗透到我们生活的方方面面，从智能手机、智能家居到自动驾驶汽车和机器人，人工智能的应用场景不断拓展。未来，随着技术的不断进步，人工智能将在更多领域发挥巨大潜力，推动人类社会的发展进步。然而，人工智能的发展也面临着一些挑战和问题。如何确保人工智能的道德和法律合规性、如何解决数据隐私和 [安全] 问题、如何提高人工智能的可解释性和透明度等都是亟待解决的问题。因此，在推动人工智能发展的同时，我们也需要关注其带来的挑战和问题，并寻求解决方案，以实现人工智能的可持续发展。总结起来，人工智能的发展历程是一个不断探索和创新的过程。通过了解人工智能的发展历程，我们可以更好地认识这一领域的现状和未来趋势。同时，我们也应该意识到人工智能的潜力和挑战，共同努力推动其健康、可持续发展。\n\n### 相关文章推荐\n\n- [**文心一言接入指南：通过百度智能云千帆大模型平台API调用** \\\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。] \n\n[十万个为什么] 2023.10.20 16:56236691199\n\n- [**从 MLOps 到 LMOps 的关键技术嬗变** \\\n本文整理自 QCon 全球软件开发大会 -从 MLOps 到 LMOps 分论坛的同名主题演讲] \n\n[百度智能云开发者中心] 2023.11.15 18:031939694\n\n- [**Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然** \\\nSugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n\n[百度智能云开发者中心] 2023.03.21 10:561652421\n\n- [**更轻量的百度百舸，CCE Stack 智算版发布** \\\n百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的 AI 工程能力面向市场推出的解决方案。] \n\n[百度智能云开发者中心] 2023.03.02 12:171187101\n\n- [**打造合规数据闭环，加速自动驾驶技术研发** \\\n今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n\n[百度智能云开发者中心] 2023.03.02 15:001377901\n\n- [**LMOps 工具链与千帆大模型平台** \\\nLMOps 相关的概念以及关键技术] \n\n[百度智能云开发者中心] 2023.11.17 15:491157113\n\n\n### 发表评论\n\n登录后可评论，请前往\xa0[登录] \xa0或\xa0[注册] \n\n评 论\n\n### 开发者关注产品榜\n\n- [_1_\\\n\\\n**千帆大模型服务与开发平台ModelBuilder** \\\n\\\n企业级一站式大模型开发及服务平台\\\n\\\n模型训练限时免费] \n- [_2_\\\n\\\n**千帆大模型应用开发平台AppBuilder** \\\n\\\n企业级大模型应用开发平台\\\n\\\n平台体验全免费] \n- [_3_\\\n\\\n**秒哒-生成式应用开发平台** \\\n\\\n不用写代码，就能实现任意想法\\\n\\\n全功能免费体验] \n- [_4_\\\n\\\n**百度智能云客悦智能客服平台** \\\n\\\n大模型重塑营销与客服体验\\\n\\\n0元试用一个月] \n\n### 最热文章\n\n- [秒哒，全面开放！] \n- [两连发！文心大模型4.5及X1，上线千帆！] \n- [即刻体验！文心大模型X1现面向企业用户全面开放！] \n- [百度智能云千帆全面支持DeepSeek-R1/V3调用，价格超低] \n- [0 Token 间间隔 100% GPU 利用率，百度百舸 AIAK 大模型推理引擎极限优化 TPS] \n- [文心快码问答智能体现场演示，重塑问题解决的体验感！] \n\n### 关于作者\n\n- 被阅读数\n- 被赞数\n- 被收藏数\n\n关 注', 'doi': '', 'published_date': '2024-01-18T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2842433', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '图说人工智能简史，每一张图片都是一个里程碑', 'authors': [], 'abstract': '图说人工智能简史，每一张图片都是一个里程碑-腾讯云开发者社区-腾讯云\n[] \n[AI大眼萌\n] \n## 图说人工智能简史，每一张图片都是一个里程碑原创**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布AI大眼萌\n**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;图说人工智能简史，每一张图片都是一个里程碑\n# 图说人工智能简史，每一张图片都是一个里程碑原创![作者头像] \nAI大眼萌\n**关注\n修改于2025-02-11 08:16:03\n修改于2025-02-11 08:16:03\n18.9K1\n举报在人类文明的漫长历程中，对于智慧的追求从未停歇。自古代哲学家对逻辑和推理的探索，到20世纪计算机科学的诞生，我们见证了人工智能（Artificial Intelligence, AI）从概念的萌芽到技术的蓬勃发展。人工智能，作为计算机科学的一个分支，其核心目标是模拟人类思维，赋予机器学习、推理乃至创造的能力。AI大眼萌将带大家回顾人工智能发展的各个阶段。\n人工智能(Artificial Intelligence，AI) 是计算机科学的一个分支领域，致力于让机器模拟人类思维，执行学习、推理等工作。人工智能的发展经历了以下六个阶段。* **前导：**萌芽阶段\n* **第一阶段-AI兴起**：人工智能的诞生（1941- 1956）\n* **第二阶段-AI早期成功**：AI黄金发展时代（1956-1974）\n* **第三阶段-AI第一次寒冬**：神经网络遇冷，研究经费减少（1974\\~1980）\n* **第四阶段-AI复兴**：第二次AI黄金发展时代，专家系统流行并商用（1980\\~1987）\n* **第五阶段-AI第二次寒冬**：专家系统溃败，研究经费大减（1987\\~1993）\n* **第六阶段-AI崛起**：深度学习理论和工程突破（1993至今）\n![图片] \n图片**00**\n**前导：萌芽阶段**\n人工智能是建立在人类思维过程可以机械化的假设之上的。中国、印度和希腊的哲学家都在公元前一千年发展出了形式演绎的结构化方法。几个世纪以来，亚里士多德Aristotle（他对三段论*Syllogism*进行形式分析）、欧几里得Euclid（他的*《几何原本》*是形式推理的一个模型）、阿尔·花拉子模al-Khwārizmī（他发展了代数，并以自己的名字命名了“*算法”*一词）等都发展了他们的思想。从古代到现在对逻辑和形式推理的研究直接导致了20世纪40年代可编程数字计算机的发明，这是一种基于抽象数学推理的机器。这个装置及其背后的想法激发了科学家们开始讨论建造电子大脑的可能性。\n![图片] \n图片Al-Jazari&#x27;s programmable automata (1206 CE)\n**01**\n**第一阶段-AI兴起：人工智能的诞生（1941- 1956）**\n* 1943**人工神经元模型Artificial\\_neuron**\n自1943年起，**沃尔特·皮茨Walter Pitts**和**沃伦·麦卡洛克Warren McCulloch**携手提出了**人工神经元模型Artificial\\_neuron**，即阈值逻辑单元（TLU），为神经网络研究奠定了基石。有趣的是，这两位大师相差25岁，却意外地在同一年离世。皮茨更是个极其低调的人，即便有人出钱，也不愿透露自己的姓名。\n![图片] \n图片![图片] \n图片* **1945年**，艾伦·图灵Alan Turing就已经在考虑如何用计算机来模拟人脑了。他设计了 ACE（Automatic Computing Engine- 自动计算引擎）来模拟大脑工作。在给一位同事的信中写道：&quot;与计算的实际应用相比，我对制作大脑运作的模型可能更感兴趣 ...... 尽管大脑运作机制是通过轴突和树突的生长来计算的复杂神经元回路，但我们还是可以在ACE 中制作一个模型，允许这种可能性的存在，ACE 的实际构造并没有改变，它只是记住了数据......&quot; 这就是机器智能的起源![图片] \n图片* **1950年**，艾伦·图灵Alan Turing发表了《计算机器与智能》，提出了著名的“图灵测试”，标志着**人工智能**概念的初步形成。\n![图片] \n图片![图片] \n图片* **1951**年，Marvin Lee Minsky 与Dean Edmonds 一道建造了第一台神经网络机，称为SNARC\n![图片] \n图片* **1956年**夏天，在美国新罕布什尔州汉诺斯小镇的达特茅斯学院，一群科学家聚集在一起，讨论了关于设计智能机器的可能性。约翰·麦卡锡、马文·明斯基等人首次提出了“人工智能”这一术语，此次达特茅斯会议Dartmouth被视为**人工智能学科**的正式诞生。会议上最引人瞩目的成果，是赫伯特·西蒙Herbert Simon和艾伦·纽厄尔Alan Newell介绍的一个程序“逻辑理论家”Logic Theorist，这个程序可以证明伯特兰·罗素Bertrand Russell和艾尔弗雷德·诺思·怀特海Alfred North Whitehead合著的《数学原理》中命题逻辑部分的一个很大子集，“逻辑理论家”程序被许多人认为是第一款可工作的人工智能程序。\n![图片] \n图片![图片] \n图片1956年8月从左至右：Oliver Selfridge, Nathaniel Rochester, Ray Solomonoff, Marvin Minsky, Trenchard More, John McCarthy, Claude Shannon.。\n![图片] \n图片![图片] \n图片* **人工智能三大学派**\n在人工智能的热潮中，涌现了从不同的学科背景出发的三大学派：![图片] \n图片* **连接主义connectionism**：又称为仿生学派或生理学派，包含感知器，人工神经网络，深度学习等技术。代表人物有**罗森布莱特**（Frank Rosenblatt）等。\n* 主张智能可以通过模拟大脑神经元网络来实现。* 强调使用神经网络和学习算法来处理信息。* 深度学习、卷积神经网络（CNN）和循环神经网络（RNN）是这一流派的现代发展。\n![图片] \n图片连接主义的代表：多层神经网络* **符号主义symbolism**：又称为逻辑主义、心理学派或计算机学派。包含决策树，专家系统等技术。代表人物有西蒙和纽厄尔、马文·明斯基等。各类决策树相关的算法，均受益于符号主义流派。\n* 主张智能可以通过符号操作来实现。* 强调使用逻辑、规则和符号来模拟人类思维过程。* 知识图谱是大数据时代的知识工程集大成者，是符号主义与连接主义相结合的产物，是实现认知智能的基石。![图片] \n图片* **行为主义**：又称为进化主义或控制论学派，包含控制论、马尔科夫决策过程、遗传算法、强化学习和某些类型的机器人技术等技术。代表人物有萨顿（Richard Sutton）等。\n* 也称为进化主义或控制论，主张智能行为可以通过与环境的交互来学习。* 强调通过试错和自然选择来优化行为。* 行为主义在后来的机器人学、自动化控制、游戏AI、自动驾驶汽车等领域有着重要应用\n![图片] \n图片麻省理工学院制造的六足机器人Genghis（成吉思汗）\n**02**\n**第二阶段-AI**\n**早期成功：AI黄金发展时代（1956-1974年）**\n* **1957 年**，美国心理学家弗兰克·罗森布拉特Frank Rosenblatt在康奈尔航空实验室发明了一个**早期的神经网络early neural networks- 感知器模型（Perceptron Model）**，感知器的设计包含三个部分：输入层、隐藏层和输出层。输入层由400个光敏元件组成，用于模拟视网膜的功能；隐藏层包含512个步进电动机，模拟神经元的兴奋和抑制过程；输出层则连接了8个执行器单元。通过“反向传播误差校正”原理，感知器可以不断调整自身的参数以提高分类准确率，从而在处理线性可分的分类问题上表现出良好的学习能力。\n![图片] \n图片感知机模型：![图片] \n图片![图片] \n图片打个比方：![图片] \n图片1958年，纽约时报记者对人工智能未来的畅想。\n![图片] \n图片* **1959年**，亚瑟·塞缪尔Arthur Samuel开发了首个自学习程序——西洋跳棋程序，并引入了“**机器学习Machine Learning”**这一概念。\n![图片] \n图片* **1960年**，Frank Rosenblatt 获得了美国海军研究办公室信息系统分支和罗马航空发展中心的资助，建造了一台定制的计算机Mark I感知器。\n![图片] \n图片![图片] \n图片* **1966年**，约瑟夫·魏岑鲍姆开发了 ELIZA，这是一个早期的**自然语言Natural language**处理程序。最著名的脚本DOCTOR模拟了Rogerian学派的心理治疗师（治疗师经常将患者的话反映给患者）,并使用脚本中规定的规则，对用户输入的非方向性问题做出回应。因此，ELIZA是第一个聊天机器人（现代的“聊天机器人”）和第一个能够尝试图灵测试的程序之一，展示了机器与人类进行自然语言交流的可能性。ELIZA可以说是现在Siri、小爱同学等问答交互工具的鼻祖。\n![图片] \n图片* **1969年**，马文·明斯基Marvin Minsky和西摩·帕珀特Seymour Papert出版的《感知器：计算几何学导论》一书，对罗森布莱特的感知器提出了质疑。书中指出：单层感知器本质上是一个线性分类器，无法求解非线性分类问题，甚至连简单的异或（XOR）问题都无法求解。人们通常错误地认为，他们也证明了类似的结果适用于多层感知器网络。然而，这是不正确的，因为Minsky和Papert已经知道多层感知器能够产生XOR函数。经常被错误引用的Minsky和Papert文本导致神经网络研究的兴趣和资金大幅下降，导致**神经网络研究**一度陷入低谷。这些先驱们怎么也没想到，计算机的速度能够在随后的几十年里指数级增长，提升了上亿倍。\n![图片] \n图片单层感知机：无法将蓝、红两类点用一条直线分开在两边。![图片] \n图片* **1970年**，第一个拟人机器人WABOT-1在日本早稻田大学建成。它由一个肢体控制系统、一个视觉系统和一个对话系统组成。\n![图片] \n图片**03**\n**第三阶段-AI第一次寒冬：神经网络遇冷，研究经费减少（1974\\~1980）**\n在20 世纪70 年代，人工智能受到批评和财务挫折。人工智能研究人员未能意识到他们所面临问题的难度。他们的巨大乐观情绪提高了公众的期望，而当承诺的结果未能实现时，针对人工智能的资金就被严重减少。1973年英国科学研究委员会消减对AI研究的资助。1973\\~1974 年，美国DARPA 大幅削减对AI研究的资助，到1974年，已经很难再找到对AI项目的资助了。\n![图片] \n图片* **1974 年**，哈佛大学沃伯斯（Paul Werbos）博士论文里，首次提出了通过误差的反向传播（BP）来训练人工神经网络，但在该时期未引起重视。\n![图片] \n图片* 在20 世纪七八十年代的“寒冬”里，仍有一些人执着于神经网络研究，科学界把他们视为狂热的疯子。比如，芬兰人戴沃·科霍宁（Teuvo Kohonen），他研究的是一个与神经网络比较接近的课题—联想记忆。再比如，还有一群日本人，与西方不同，日本的工程科学生态系统比较孤立，其中包括数学家甘利俊一Shun-Ichi Amari和一位名为福岛邦彦Kunihiko Fukushima的业内人士，后者发布了一个被他称为**认知机****Congitron**的机器，这一命名来自术语**感知机****Perceptron**。福岛邦彦前后一共发布了这个机器的两个版本，分别是 20 世纪70 年代的认知机和**1979年**发布的**神经认知机****Neocognitron**，它是一种分层、多层人工神经网络，通过无监督学习，用于日语手写字符识别和其他模式识别任务，并成为卷积神经网络的灵感来源。\n![图片] \n图片**04**\n**第四阶段-AI复兴：第二次AI黄金发展时代，专家系统流行并商用（1980\\~1987）**\n* 专家系统的兴起:AI的第一次寒冬，让研究者们的研究热点，转向了专家系统。专家系统，是模仿人类专家决策能力的计算机系统。依据一组从专门知识中推演出的逻辑规则，来回答特定领域中的问题。专家系统包含若干子系统：知识库，推理引擎，用户界面。\n![图片] \n图片知识库系统和知识工程成为80年代AI研究的主要方向，出现了许多有名的专家系统。\n* MYCIN：识别可能导致急性感染的各种细菌，根据患者的体重推荐药物。\n* DENDRAL：用于化学分析，可预测分子结构。\n* PXDES：用于预测肺癌程度和类型。\n* XCON：1980年由CMU为DEC设计，1986年之前每年为DEC省下四千万美金。\n专家系统具有明显的一些优势：* 设计简单，且能够容易地编程实现或修改* 实践证明了专家系统的实用性和经济价值* 高效、准确、迅速和不知疲倦地进行工作* 使领域专家的经验不受时间和空间的限制专家系统的这一系列优势，吸引了新一轮的政府资助。1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目，目标是造出能与人对话，翻译语言，解释图像，并像人一样推理的机器，英国开始了耗资三亿五千万英镑的Alvey工程。DARPA成立战略计算促进会，1988年向AI的投资是1984年的三倍。\n* **1982 年**，物理学家约翰·霍普菲尔德John Hopfield证明了一种神经网络（现在称为“**霍普菲尔德网络Hopfield net**&quot;”）可以学习和处理信息，并在任何固定条件下经过足够的时间后可证明收敛，因为之前人们认为非线性网络通常会混乱地演化。1986年，David Rumelhart和杰弗里·辛顿Geoffrey Hinton推广了一种适用于多层感知器（MLP）的算法，称为“**反向传播算法Backpropagation**”的神经网络训练方法，推动了多层神经网络的发展。这两项进展重新点燃了**神经网络研究**的热潮。\n![图片] \n图片多层感知器multilayer perceptron (MLP）\n![图片] \n图片![图片] \n图片* **1985 年**，朱迪亚·珀尔Judea Pearl提出贝叶斯网络，以倡导人工智能的概率方法和发展贝叶斯网络而闻名，还因发展了一种基于结构模型的因果和反事实推理理论而受到赞誉。\n![图片] \n图片![图片] \n图片* **1985年**，杰弗里·辛顿Geoffrey Hinton提出**受限玻尔兹曼机Restricted Boltzmann machine**。受限玻尔兹曼机是一种二分图结构，包含可见单元和隐藏单元。其训练算法是基于梯度的对比分歧算法，可以用于降维、分类、回归和特征学习等任务。\n![图片] \n图片**05**\n**第五阶段-AI第二次寒冬：专家系统溃败，研究经费大减（1987\\~1993）**\n在专家系统快速发展的过程中，其劣势也逐渐显露出来。专家系统的劣势有：* 知识采集和获取的难度很大，系统建立和维护费用高。* 专家系统仅限应用于某些特定情景，不具备通用性。* 使用者需要花很长时间来熟悉系统的使用“AI 之冬”一词由经历过1974 年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。**专家系统的这些劣势，使得商业化面临重重困境，从而直接引发了AI的第二次寒冬**\n* 变天的最早征兆是1987 年AI 硬件市场需求的突然下跌。Apple 和IBM 生产的台式机性能不断提升，到1987 年时其性能已经超过了Symbolics 和其他厂家生产的昂贵的Lisp 机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解* 80年代晚期，战略计算促进会大幅削减对AI的资助。\n* DARPA认为AI并非“下一个浪潮”，拨款倾向于更容易出成果的项目。\n* 1991年，日本的“第五代计算机项目”的目标未能实现，事实上其中一些目标，比如“与人展开交谈”，直到 2010 年也没有实现。与其他AI 项目一样，期望比真正可能实现的要高得多。* **1989年**，AT＆T贝尔实验室的**杨立昆Yann Lecun**和团队使用**卷积神经网络convolutional neural networks CNN**技术，实现了人工智能识别手写的邮政编码数字图像，成为深度学习在实践中的早期成功案例。\n![图片] \n图片1980年代是人工智能研究方向发生重大转折的时期。机器学习和神经网络（联结主义）加速崛起，逐渐取代专家系统（符号主义），成为人工智能的主要研究方向。我们也可以理解为，人工智能原本由知识驱动的方式，逐渐变成了由数据驱动。\n![图片] \n图片* **1991年**，互联网的出现使在线连接和数据共享成为可能，无论你是谁，无论你在哪里。由于数据是人工智能的燃料，这在以后将被理解为人工智能的一个关键时刻。\n![图片] \n图片**06**\n**第六阶段-AI崛起：深度学习理论和工程突破（1993至今）**\n![图片] \n图片* **深度学习三巨头**\n少数AI研究者在AI寒冬期以众人皆醉我独醒的态度，十年如一日地坚持坐冷板凳，开展神经网络方向的研究。其中代表人物是深度学习三巨头。**他们在2018年因在深度学习方面的卓越贡献，一同被授予了图灵奖**。\n* 杰弗里·辛顿Jeoffrey Hinton：发明了受限玻尔兹曼机，首先将反向传播算法应用于多层神经网络。培养了杨立昆Yann Lecun等一众大牛级学生。推动谷歌的图像和音频识别性能大幅提升。\n![图片] \n图片我一直以来都确信，实现人工智能的唯一方式，就是按人类大脑的方式去进行计算。——杰弗里·辛顿* 杨立昆Yann Lecun：1989年使用反向传播和神经网络识别手写数字，用来读取银行支票上的手写数字，首次实现神经网络商业化，1998 ，提出LeNet5卷积神经网络，Facebook人工智能实验室负责人。\n![图片] \n图片我们之所以为人，是因为我们具有智能，而人工智能是这一能力的扩展。——杨立昆* 约书亚·本吉奥Yoshua Bengio：推动了循环神经网络的发展，带领开发出Theano框架，启发了Tensorflow等众多后续框架的发展，创办AI顶会ICLR，开创了基于神经网络的语言模型。他也是权威教材《深度学习》一书的合著者。\n![图片] \n图片我一直认为“创造性”可通过计算的方式来实现。我们理解计算背后的原理。所以，只需找到更智能的神经网络或模型即可。——约书亚·本吉奥* **1995 年**，克里娜·柯尔特斯Corinna Cortes和弗拉基米尔·万普尼克Vladimir Vapnik提出联结主义经典的支持向量机（Support Vector Machine ,SVM），可以视为在感知机基础上的改进，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中\n![图片] \n图片* **1997 年**，IBM 深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。![图片] \n图片* **2000年**，麻省理工学院的辛西娅-布雷泽尔开发了Kismet，一种能够识别和模拟情绪的机器人。\n![图片] \n图片* **2003 年**，Google 公布3 篇大数据奠基性论文，为大数据存储及分布式处理的核心问题提供了思路：非结构化文件分布式存储（GFS）、分布式计算（MapReduce）及结构化数据存储（BigTable），奠定了现代大数据技术的理论基础。\n![图片] \n图片* **2006年**，杰弗里·辛顿等人发表了重要的论文《Reducing the dimensionality of data with neural networks（用神经网络降低数据维数）》, 提出了**深度信念网络Deep Belief Network(DBN)**，用于无监督特征学习，为深度学习的发展奠定了基础，**2006 年也被称为深度学习元年**。\n![图片] \n图片* **2006年**，英伟达（NVIDIA）推出CUDA （统一计算架构），GPU开始用于解决商业、工业以及科学方面的复杂计算，GPU与深度学习结合，模型的训练速度有了数量级的提升。\n![图片] \n图片* **2012年**，在杰弗里·辛顿的指导下，伊利亚·苏茨克沃Ilya Sutskever和亚历克斯·克里切夫斯基Alex Krizhevsky开发出 AlexNet 模型，推动了**深度卷积神经网络CNN**的发展。AlexNet在ImageNet挑战赛上取得了突破性的成果，从而引发了深度学习Deep Learning的热潮。值得一提的是，他们三人用于训练模型的，只是2张英伟达GTX 580显卡。GPU在深度神经网络训练上表现出的惊人能力，不仅让他们自己吓了一跳，也让黄仁勋和英伟达公司吓了一跳。\n![图片] \n图片作为对比，2012年的早些时候，谷歌“Google Brain”项目的研究人员吴恩达（华裔美国人，1976年生于伦敦）、杰夫·迪恩Jeff Dean等人，也捣鼓了一个神经网络（10亿参数），用来训练对猫的识别。他们的训练数据是来自youtube的1000万个猫脸图片，用了1.6万个CPU，整整训练了3天。\n![图片] \n图片深度学习Deep Learning是一Machine Learning 的一个重要分支,更准确来说，机器学习底下有一条“神经网络”路线，而深度学习，是加强版的“神经网络”学习, 它使用多层神经网络和反向传播Backpropagation技术来训练神经网络。经典机器学习算法使用的神经网络，具有输入层、一个或两个“隐藏”层和一个输出层。数据需要由人类专家进行结构化或标记（监督学习），以便算法能够从数据中提取特征。', 'doi': '', 'published_date': '2026-02-03T16:00:29.783108', 'pdf_url': '', 'url': 'https://cloud.tencent.com/developer/article/2491938', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能发展简史 - 中央网信办', 'authors': [], 'abstract': '人工智能发展简史\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能发展简史2017年01月23日 11:10来源：\n网络传播杂志[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n“人工智能之父”艾伦·图灵。**1、 人工智能的诞生（20世纪40～50年代）**\n1950年：图灵测试\n1950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n1954年：第一台可编程机器人诞生\n1954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n1956年：人工智能诞生\n1956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n1966年\\~1972年：首台人工智能机器人Shakey诞生\n1966年\\~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n1966年：世界上第一个聊天机器人ELIZA发布\n美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n1968年：计算机鼠标发明\n1968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n**3、 人工智能的低谷（20世纪70～80年代）**\n20世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n![] \n1997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n**4、 人工智能的繁荣期（1980年\\~1987年）**\n1981年：日本研发人工智能计算机\n1981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n1984年：启动Cyc（大百科全书）项目\n在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n1986年：3D打印机问世\n美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n**5、 人工智能的冬天（1987年\\~1993年）**\n“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n**6、 人工智能真正的春天（1993年至今）**\n1997年：电脑深蓝战胜国际象棋世界冠军\n1997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n2011年：开发出使用自然语言回答问题的人工智能程序\n2011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n2012年：Spaun诞生\n加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n2013年：深度学习算法被广泛运用在产品开发中\nFacebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n2015年：人工智能突破之年\nGoogle开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n2016年：AlphaGo战胜围棋世界冠军李世石\n2016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）![] \n2016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n**大事记**\n①1942年：“机器人三定律”提出\n美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。②1956年：人工智能的诞生\n达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n③1959年：第一代机器人出现\n德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n④1965年：兴起研究“有感觉”的机器人\n约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n⑤1968年：世界第一台智能机器人诞生\n美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n⑥2002年：家用机器人诞生\n美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n⑦2014年：机器人首次通过图灵测试\n在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n⑧2016年：AlphaGo打败人类\n2016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': '2017-01-23T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来- 求是网', 'authors': [], 'abstract': '# 人工智能的历史、现状和未来\n\n来源：《求是》2019/04\n作者：谭铁牛\n2019-02-16 09:00:00\n\n2018年2月25日，在平昌冬奥会闭幕式“北京8分钟”表演中，由沈阳新松机器人自动化股份有限公司研发的智能移动机器人与轮滑演员进行表演。 新华社记者 李钢/摄\n\n2018年5月3日，中国科学院发布国内首款云端人工智能芯片，理论峰值速度达每秒128万亿次定点运算，达到世界先进水平。 新华社记者 金立旺/摄\n\n2017年10月，在沙特阿拉伯首都利雅得举行的“未来投资倡议”大会上，机器人索菲亚被授予沙特公民身份，她也因此成为全球首个获得公民身份的机器人。图为2018年7月10日，在香港会展中心，机器人索菲亚亮相主舞台。 ISAAC LAWRENCE/视觉中国\n\n2018年11月22日， 在“伟大的变革——庆祝改革开放40周年大型展览”上，第三代国产骨科手术机器人“天玑”正在模拟做手术，它是国际上首个适应症覆盖脊柱全节段和骨盆髋臼手术的骨科机器人，性能指标达到国际领先水平。 麦田/视觉中国\n\n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。\n\n**概念与历程**\n\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。\n\n人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n\n**现状与影响**\n\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n\n**专用人工智能取得重要突破。** 从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n\n**通用人工智能尚处于起步阶段。** 人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n**人工智能创新创业如火如荼。** 全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n**创新生态布局成为人工智能产业发展的战略高地。** 信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n\n**人工智能的社会影响日益凸显。** 一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。\n\n**趋势与展望**\n\n经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n\n**从专用智能向通用智能发展。** 如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n**从人工智能向人机混合智能发展。** 借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。\n\n**从“人工+智能”向自主智能系统发展。** 当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。\n\n**人工智能将加速与其他学科领域交叉渗透。** 人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。\n\n**人工智能产业将蓬勃发展。** 随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。\n\n**人工智能将推动人类进入普惠型智能社会。**“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n**人工智能领域的国际竞争将日益激烈。** 当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n**人工智能的社会学将提上议程。** 为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。\n\n**态势与思考**\n\n当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n**高度重视。** 党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n**态势喜人。** 据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。\n\n**差距不小。** 目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n\n**前景看好。** 我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。\n\n**树立理性务实的发展理念。** 任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n**重视固本强基的原创研究。** 人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n**构建自主可控的创新生态。** 我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。\n\n**推动共担共享的全球治理。** 目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。\n\n作者：中央人民政府驻香港特别行政区联络办公室副主任、中国科学院院士\n\n扫描二维码分享到手机\n\n标签 -\n\n网站编辑 \\- 王慧\n\n[【网站声明】] [【纠错】] [【打印】] \n\n评论登录新浪微博 [@求是] 发表评论。请您文明上网、理性发言并遵守相关规定。', 'doi': '', 'published_date': '2019-02-16T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.qstheory.cn/dukan/qs/2019-02/16/c_1124114625.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能历史 - IBM', 'authors': [], 'abstract': '人工智能历史 | IBM\n[Artificial Intelligence] \n# AI 的历史![高耸入云的摩天大楼尖顶] \n## 作者[Tim Mucci] \nIBM Writer\nGather\n## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。\nGPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;\n## 20 世纪以前### 1726\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。\n学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;\n“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”\n- Jonathan Swift 的《格列佛游记》(1726)\nSwift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。\n## 1900–1950\n### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。\n### 1921\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。\n### 1939\n爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。\n虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。\n与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。\n### 1950\n英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;\n图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n## 1950–1980\n### 1951\nMarvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952\n数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n### 1955\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。\n### 1958\nJohn McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959\nArthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n### 1965\n哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。\n### 1966\nShakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969\nArthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。\nMarvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。\n### 1970\nTerry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。\n### 1973\nJames Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000\n### 1980\nWABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。\n### 1982\n日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。\n### 1986\nDavid Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。\n这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987\n在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\nRollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\nMarvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。\n### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。\n### 1993\n科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。\n这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n### 1995\nRichard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;', 'doi': '', 'published_date': '2026-02-03T16:00:29.783300', 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI 有着怎样的发展历程？ - Cloudflare', 'authors': [], 'abstract': 'AI 有着怎样的发展历程？| Cloudflare\n[注册] \n语言* [English] \n* [English (United Kingdom)] \n* [Deutsch] \n* [Español (Latinoamérica)] \n* [Español (España)] \n* [Français] \n* [Italiano] \n* [日本語] \n* [한국어] \n* [Polski] \n* [Português (Brasil)] \n* [Русский] \n* [繁體中文] \n* [简体中文] \n# AI 有着怎样的发展历程？当今最先进的AI 模型建立在几十年前的发现基础之上。AI 的历史可以追溯到第一台数字计算机诞生之前。#### 学习目标阅读本文后，您将能够：* 识别AI 发展的关键进展* 了解Alan Turing、Frank Rosenblatt 和Geoffrey Hinton 等发明家和创新者多年来对AI 发展做出的贡献* 列举促成当今AI 热潮的发展相关内容[\n什么是代理式AI？\n] [\n什么是生成式AI？\n] [\n预测式AI\n] [\n神经网络] [\n什么是人工智能(AI)？\n] \n复制文章链接## AI 有着怎样的发展历程？[人工智能 (AI)] 是指机器（通常特指计算机）模仿人类认知过程、解决问题的能力以及行动能力。如今，AI 涵盖了一系列能力，从[预测式 AI] 和[自然语言处理] ，到[大型语言模型 (LLM)] 和[代理式 AI] 。\n从古代世界的自动机到最早的计算机，这些都是AI 的前身。当今最先进的模型，其基础是几十年前发展起来的理论和算法。## AI 历史上的重大事件：时间线虽然“人工智能”一词最早出现在1955 年，但对AI 发展至关重要的事件却可以追溯到几个世纪以前。#### 20 世纪之前* **大约公元前 400 年：**根据一些古希腊文献记载，阿尔希塔斯 (Archytas of Tarentum) 制作了一只能够拍打翅膀并飞翔的木鸽。* **大约 1495 年：**莱昂纳多•达•芬奇 (Leonardo da Vinci) 绘制了一幅外形类似德国骑士的自动机详细图纸，并且可能已经制造了一台（即便确实如此，这台自动机也无法流传至今）。* **大约 1560 年：**西班牙国王费利佩二世 (Phillip II) 委托钟表匠Juanelo Turriano 模仿方济各会修士Diego de Alcalá（后来被封为圣徒 St. Diego）制作一台自动机。这种自动机由发条驱动，可以模仿人类的基本动作和姿势。\n* **1764 - 1770 年：**名为*Canard Digérateur*（或“消化鸭”）以及 Automaton Chess Player（或“自动行棋的傀儡”）的自动机令公众欣喜。虽然两者后来都被证明是骗局，但它们拓展了人们对自动化可能性的普遍理解。\n* **1822 年：**查尔斯•巴贝奇 (Charles Babbage) 完成了“差分引擎”的研制，这是一种机械计算装置，它是计算机的早期前身。#### 1900 - 1973 年* **1914年：**数学家兼发明家 Leonardo Torres y Quevedo 首次推出了"El Ajedrecista"，这是一款能够自动进行国际象棋对局并在特定情况下击败人类棋手的自动机。\n* **1943 年：**神经生理学家 Warren McCulloch 和数学家Walter Pitts 共同发表了题为《神经活动内在概念的逻辑演算》(A Logical Calculus of the Ideas Imminent in Nervous Activity) 的论文，文中介绍了神经元的数学描述。这篇论文成为了构建[人工神经网络] 的关键一步。\n* **1945 年：**第一台数字计算机 ENIAC 诞生。* **1949 年：**心理专家唐纳德•赫布 (Donald Hebb) 出版了*《行为的组织》*，这本书对神经网络的发展产生了深远的影响。\n* **1950 年：**颇具影响力的数学家和计算机科学家 Alan Turing 发表了《计算机器与智能》(Computing Machinery and Intelligence)，这篇论文探讨了“机器能否思考”的问题。论文描述了著名的“图灵测试”，用于判断计算机智能是否已变得与人类智能无法区分。\n* **1951 年：**Dean Edmunds 和Marvin Minsky 一起建造了随机神经模拟强化计算器(SNARC)，这是世界上第一台神经网络计算机。它只有 40 个神经元。* **1955 年：**在计算机科学家约翰•麦卡锡 (John McCarthy) 主持的一次研讨会上，“人工智能”一词首次出现。* **1957 年：**心理学家兼计算机科学家弗兰克•罗森布拉特 (Frank Rosenblatt) 创建了感知器，这是一种早期的人工神经网络。* **1959 年：**斯坦福大学研究员 Bernard Widrow 和Marcian Hoff 开发了出现实世界中使用的第一个神经网络模型：多自适应线性元素(Madaline)，用于消除电话线路回声。\n* **1966 年：**计算机科学家 Joseph Weizenbaum 发布了ELIZA 程序，这被认为是第一个[聊天机器人] （尽管按照如今的标准，其底层模式匹配算法相当简单）。\n* **1969 年：**Marvin Minsky 和Seymour Papert 出版了*《感知器：计算几何学导论》*(Perceptrons: An Introduction to Computational Geometry)，这本书对感知器提出了质疑（最初由 Frank Rosenblatt 提出）。引人争议的是，书中还论述了感知器的一些局限性，某些研究员后来认为这些局限性削弱了对AI 研究的资助热情。#### AI 的寒冬与复苏：1973 - 2000 年* **1973 年：**第一个“AI 寒冬”开始，英国科学研究委员会的一份报告指出，这一领域的工作未能兑现其承诺，英国削减了对AI 研究的资助。在七十年代这十年的剩余时间里，AI 研究速度放缓。* **1980 年：**人工智能促进协会 (AAAI) 召开了第一次会议。对AI 研究的兴趣开始复苏。* **1982 年：**加州理工学院的 John Hopfield 向美国国家研究院提交了一篇关于在人工神经元之间使用双向连接的论文（以前一直都只使用了单向连接）。此外，日本启动了该国的第五代计算机系统项目(FGCS)，为 AI 研究提供了更多资金。* **1987 年：**第二个 AI 寒冬开始，在此期间，由于研究进展停滞不前，AI 研究的投资极少。* **1995 年：**Richard Wallace 开发了聊天机器人A.L.I.C.E.，它以 20 世纪60 年代的聊天机器人ELIZA 为基础。* **1997 年：**IBM 的超级计算机“深蓝”(Deep Blue) 在六局棋国际象棋比赛中击败了国际象棋大师加里•卡斯帕罗夫(Garry Kasparov)。#### 21 世纪：AI 热潮* **2002 年：**Roomba 机器人发布，这是最早具备完全自主功能的消费产品之一。* **2007 年：**计算机科学家 Geoffrey Hinton 发表了题为“Learning Multiple Layers of Representation”的论文，这是一篇在[深度学习] 方面具有重大意义的论文。\n* **2009 年：**研究员 Rajat Raina、Anand Madhavan 和Andrew Ng 共同发表了题为“Large-scale Deep Unsupervised Learning using Graphics Processors”的论文，文中指出 GPU 在机器学习方面优于CPU。未来几年，向 GPU 转变将会催生出比以往任何时候都更加强大的AI 模型。* **2011 年：**IBM 的自然语言处理器Watson 参加了美国智力竞猜电视节目*《危险边缘》(Jeopardy!)*并获胜。同一年，Apple 推出了首个广受欢迎的虚拟助手Siri。\n* **2012 年：**Google 研究员Jeff Dean 和Andrew Ng 训练一个神经网络，使其能够仅使用未标记的图像识别猫。大约在这个时候，“AI 热潮”开始了。* **2016 年：**Google 计算机程序AlphaGo 在围棋比赛中击败了围棋世界冠军李世石。* **2017 年：**Google 提出了Transformer 神经网络框架，这种架构为[大型语言模型 (LLM)] 的开发铺平了道路。\n* **2020 年：**OpenAI 发布了GPT-3，这是首批 LLM 之一。* **2021 年：**Google 发布了多任务统一模型(MUM)，这是一种由 AI 驱动的搜索算法，能够理解并生成语言。* **2022 年：**ChatGPT 4.0 版本正式发布可供大众使用，彻底改变了人们对AI 能力的理解。其他LLM，例如 Bard、Llama、Bing Chat 和Copilot，也相继发布。## 什么是AI 的“第三次浪潮”？凭借一系列硬件突破和进步，AI 在经历了数十年的缓慢发展和寒冬之后，近几年迎来了加速发展。行业观察人士认为，在这一轮AI 发展热潮中，三种类型的AI[浪潮] 相继快速成为主流，它们分别是：[预测式 AI] 、[生成式 AI] （例如 LLM），以及[代理式 AI] 。\n代理式AI 可以创建计算机程序，即使没有明确的指令，也能够自主执行任务，而且也无需基于提示的特定上下文。AI 代理可以自行决策，从过去的经验中学习，并相应地调整行动。因此，它们可以独立运行，或者只需极少的人工干预就能运行。## 未来AI 将会如何发展？近年来，新的发现和更强大的硬件帮助AI 获得了前所未有的能力。AI 的历史将会继续延续，未来或许会有更多激动人心的发展。Cloudflare 赋能开发人员，让其能够为AI 的发展史贡献自己的力量。凭借遍布全球的分布式无服务器AI 基础设施、免费的训练数据出口、分布式[矢量数据库] 和其他关键的 AI 构建块，Cloudflare 平台让开发人员能够利用最先进的AI 技术进行构建。[立即为 AI 发展史贡献自己的力量] 。\n*来源：*\n* *https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html*\n* *https://www.history.com/articles/7-early-robots-and-automatons*\n* *https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(07)00217-3*\n* *https://www.historyofinformation.com/detail.php?entryid=782*\n* *https://www.historyofinformation.com/detail.php?id=4137*\n* *https://www.techtarget.com/searchenterpriseai/definition/AI-winter*\n* *https://aaai.org/conference/aaai/aaai80/*\n* *https://blog.google/products/search/introducing-mum/*\n* *https://news.harvard.edu/gazette/story/2012/09/alan-turing-at-100/*\n开始使用* [Free 计划] \n* [小型企业计划] \n* [企业级服务] \n* [获得推荐] \n* [请求演示] \n* [联系销售] \n人工智能* [什么是人工智能 (AI)？] \n* [人工智能推理与训练] \n* [AI 发展史] \n机器学习* [什么是机器学习？] \n* [什么是深度学习？] \n* [什么是大型语言模型(LLM)？] \n* [低秩自适应 (LoRA)] \n* [AI 图像生成] \n大数据* [什么是嵌入？] \n* [什么是大数据？] \n* [如何构建 RAG 管道] \n词汇* [什么是 AI 安全？] \n* [向量数据库] \n* [预测式 AI] \n* [ChatGPT 插件] \n* [神经网络] \n* [什么是生成式 AI？] \n* [什么是自然语言处理 (NLP)？] \n* [AI 幻觉] \n* [AI 量化] \n* [OWASP Top 10 for LLM] \n* [AI 数据投毒] \n* [检索增强生成 (RAG)] \n* [什么是代理式 AI？] \n* [AI 的第三次浪潮] \n* [什么是氛围编码？] \n* [模型上下文协议 (MCP)] \n* [AI 在网络安全领域的应用] \n* [如何开始氛围编码] \n* [如何管理 AI 智能体] \n* [如何阻止 AI 爬网程序] \n* [如何防止抓取] \n* [如何保护 AI 系统] \n* [如何保护 AI 训练数据安全] \n学习中心* [安全性学习中心] \n* [CDN 学习中心] \n* [DDoS 学习中心] \n* [DNS 学习中心] \n* [性能学习中心] \n* [无服务器学习中心] \n* [SSL 学习中心] \n* [机器人学习中心] \n* [云学习中心] \n* [访问管理学习中心] \n* [网络层学习中心] \n* [隐私学习中心] \n* [视频流式传输学习中心] \n* [电子邮件安全性学习中心] \n* [学习中心主页] \n[] [] [] [] [] \n©2026Cloudflare 公司[隐私政策] [使用条款] [报告安全问题] [信任与安全]![privacy options] Cookie 首选项[商标]', 'doi': '', 'published_date': '2026-02-03T16:00:29.783309', 'pdf_url': '', 'url': 'https://www.cloudflare.com/zh-cn/learning/ai/history-of-ai/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的起源、发展和未来 - SK hynix Newsroom', 'authors': [], 'abstract': '人工智能的起源、发展和未来\n[![SK hynix Newsroom]] \n选择页面[] [] \n* [English] \n* [Chinese(中文)] \n* [Korean(한국어)] \n[] \n[![sk하이닉스 뉴스룸홈]] \n[] \n* [ENG] \n* [中文] \n* [KOR] \n[![sk하이닉스 뉴스룸홈]] \n[] \n[] \n[#CXL] [#DRAM] [#eSSD] [#HBM3E] [#HBM4] [#NAND] [#面向AI的存储器] \n[技术] [사용안함] \n# 人工智能的起源、发展和未来2024年10月14日\n分享[![닫기 버튼]] \n* [] \n* [] \n* [] \n![] \n能够像人类一样行走、说话和思考的人工智能机器人，过去常常是科幻漫画和电影中的热门题材。曾经只存在于人类想象中的人工智能和机器人，如今已不再是梦想，因为它正在走进现实并且改变着人们的日常生活。那么，人工智能始于何时，经历了怎样的演变，又会创造怎样的未来呢？### “人工智能”的起源与发展![人工智能发展的历史演变进程] \n人工智能发展的历史演变进程人工智能的起源可以追溯到20世纪50年代。1950年，英国数学家艾伦·图灵（Alan Turing）声称机器能够思考，并设计了“图灵测试（The Turing Test）”作为验证方法以佐证这个观点，这被认为是首次提出人工智能概念的研究。1956年，达特茅斯会议（Dartmouth Conference）召开，向世界介绍了人工智能的概念。会议讨论了机器能否像人类一样学习和发展，并首次使用了“人工智能”这一术语。\n在这一时期，人们对人工神经网络（Artificial Neural Network）模型的研究也很活跃。1957年，弗兰克·罗森布拉特（Frank Rosenblatt）用他的 &#8220;感知器（Perceptron）&#8221;模型实证了计算机可以识别和学习模式的概念，这是对&#8221;神经网络&#8221;理论的一次实践检验。“神经网络”理论是由神经生理学家沃伦·斯特吉斯·麦卡洛克（Warren Sturgis McCulloch）和沃尔特·皮茨（Walter Pitts）于1943年提出的，他们根据神经细胞的相互作用原理组建了一个简单的计算模型。尽管这些早期的研究成果引发了公众的期待，但由于计算能力、逻辑和数据缺乏等方面的限制，人工智能的研究很快就停滞不前。\n20世纪80年代出现了 &#8220;专家系统（Expert System）&#8221;，它可以根据人类输入的规则自动做出决策。“专家系统”在医学、法律和零售业等实用领域发挥的诊断、分类和分析等功能，暂时性地再度引起了人们对人工智能的关注。然而，该系统的局限性在于仅依赖人工设定的规则运行，缺乏理解现实世界的复杂性的能力，因此发展受到了限制。\n20世纪90年代，过去只能听从人类指令的人工智能，利用“机器学习（Machine Learning）”算法开始自主发现规则进行学习，这得益于数码技术及互联网的出现。有了来自网络的大量数据，人工智能可以自主学习规则，甚至发现人类无法发现的规则。基于“机器学习”的人工智能研究开始重新产出成果。\n### 人工智能的核心技术，&#8221;深度学习&#8221;的发展\n![人工神经网络和深度学习发展的时间线] \n人工神经网络和深度学习发展的时间线人工神经网络的早期研究在1969年进入了长期停滞期，因为人们发现先前提出的感知器模型无法有效解决非线性问题1。此后，重新将这一研究推向前沿的正是被誉为&#8221;深度学习之父&#8221;的杰弗里·辛顿（Geoffrey Hinton）。\n1986年，辛顿将反向传播算法2应用到由多层人工神经网络构成的多层感知器（Multi-Layer Perceptrons）理论中，证明其可以解决感知器存在的现有问题。这一举措重燃了人工神经网络研究的热情。然而，随着神经网络深度的增加，出现了学习过程和结果异常的问题。\n2006年，辛顿发表了题为《深度信念网络的快速学习算法（A Fast Learning Algorithm for Deep Belief Nets）》的论文，确立了深度学习的基本概念，并介绍了深度信念网络（DBN，Deep Belief Network），这种生成式模型可大幅提升多层感知器的性能。深度信念网络通过无监督学习3对每一层进行预训练，然后对整个网络进行微调，显著地提高了神经网络的学习速度和效率, 这一进展为未来深度学习的发展铺平了道路。1早期感知器模型为单层感知器（Single-layer Perceptron），不能处理XOR等非线性问题，处理这类问题时，在两个输入值相同时需输出0，而不同时则需输出1。\n2**反向传播（Backpropagation）**：神经网络中的一种算法，用于计算输出值与真实值之间的差值，并从输出值开始按相反顺序调整权重，以减少误差。\n3**无监督学习（Unsupervised Learning）**：机器学习中的一种学习理论，不给出输入数据的正确答案，而是让其发现和理解隐藏结构或模式的学习方法。\n![Kien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页] \nKien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页2012年，发生了一件历史性事件，证明了深度学习的卓越性能。由辛顿率领的AlexNet在图像识别挑战赛（ILSVRC, ImageNet Large Scale Visual Recognition Challenge）中夺得冠军。基于深度学习的AlexNet模型实现了84.7%的图像识别率，远超其他模型，值得一提的是，它将上一年冠军的错误率从25.8%降至16.4%。\n自2010年以来，深度学习已成为人工智能研究的主流，其迅速发展的背后有两个主要原因。首先是包括图形处理器（GPU ，Graphics Processing Unit）在内的计算机系统的进步。GPU最初是为处理计算机图形而创建的，与中央处理器（CPU ，Central Processing Unit）相比，GPU并行处理类似的重复运算速度更快。2010年，GPU通用计算（GPGPU ，General-Purpose computing on GPU）技术的出现，使GPU取代了CPU的角色。GPU的应用领域愈发广泛，特别是在训练人工神经网络方面，极大地加快了深度学习的发展。深度学习需要对海量训练数据进行分析以提取特征，并且需要进行迭代计算，而GPU具备的并行计算结构则非常适合这一需求。\n其次是由于数据量的增加，因为训练人工神经网络需要大量数据。过去，数据仅限于输入计算机的信息，但自20世纪90年代以来，随着互联网的普及和搜索引擎的发展，可处理的数据范围呈指数级增长。2000年以来，智能手机和物联网（IoT, Internet of Things）得到发展，催生了大数据（Big Data）的概念，现实世界到处都能实时收集数不清的数据。深度学习算法经过更多数据的训练后变得更加精细化，数据模式的转变无疑为深度学习技术奠定了基础。\n2016年，深度学习再次改变了世界。谷歌DeepMind开发的人工智能AlphaGo以4胜1负的比分战胜了围棋大师李世石九段，这一壮举让全世界都铭记人工智能的存在。AlphaGo是通过融合深度学习算法、强化学习（Reinforcement Learning）4和蒙特卡洛树搜索（MCTS，Monte Carlo Tree Search）5算法而创建的。借助此种方式，它能够进行数万次的自我对弈、自主学习，并模仿人类直觉以预测数值，甚至是制定战略。“战胜人类的AI”问世，标志着人工智能时代正式到来。\n4**强化学习（Reinforcement Learning）**：人工智能学习行为的方法之一，以奖励的形式告知行动结果，并且可以在特定情况下选择最佳行动的策略。\n5**蒙特卡洛树搜索（Monte Carlo tree search）**：一种通过反复生成一系列随机数来处理近似函数值的概率算法。 其功能是将目前情况下可选择的行为结构化为探索树，并通过随机模拟推论各行为的得失来决定最佳行为。### “生成式人工智能”热潮始于ChatGPT\n![生成式人工智能概念图] \n生成式人工智能概念图2022年末，人类迎来了人工智能技术的巨大变革。OpenAI推出了ChatGPT，由大语言模型（LLM，Large Language Model）6GPT（Generative Pre-trained Transformer）3.5驱动，标志着生成式人工智能时代的开启。生成式人工智能渗透到了曾被视为人类独有的“创作”领域，能够生成各种格式的高质量内容。它超越了基于数据进行预测或分类的深度学习层面，可根据用户需求，使用LLM或各种图像生成模型（如 VAE、GAN、扩散模型等），自行生成结果。\n6**大语言模型（Large Language Model）**：以海量数据基础，进行多种自然语言处理任务的深度学习算法。\n生成式人工智能的诞生可以追溯到2014年，当时伊恩·古德费洛（Ian Goodfellow）发布了生成对抗网络（GANs，Generative Adversarial Networks）模型，该模型由两个神经网络相互竞争学习的结构而组成。一个神经网络生成与真实数据无异的新数据，另一个神经网络将其与真实数据进行比较，并做出判断，随着这一竞争和判断的过程不断重复，生成的数据也越来越精细。随着时间推移，GANs模型不断得到修改和完善，目前已被广泛应用于图像生成和转换等多个领域中。\n2017年，名为Transformer的自然语言处理（NLP，Natural Language Processing）模型问世。Transformer将数据间的关系视为重要变量，通过对特定信息给予更多&#8221;关注&#8221;，它可以学习数据之间的复杂关系和模式，捕捉更多重要信息，从而产生更高质量的输出结果。Transformer模型为语言理解、机器翻译和交互系统等自然语言处理任务带来了革命性变化，尤其是它对前文提到的GPT等LLM的出现产生了重大影响。\nGPT于2018年首次发布，由于每年都会使用更多的参数和训练数据，其性能一直在飞速提升。2022年，搭载GPT 3.5的交互式人工智能系统ChatGPT发布，彻底改变了人工智能的模式。ChatGPT能通过理解用户对话的上下文来提供适当的回复，并回答各种问题。ChatGPT推出一周内，用户数量就突破了100万，两个月内活跃用户数量就超过了1亿，在全球范围内引发了爆炸性的关注。\n2023年，Open AI推出了GPT-4，再次实现技术飞跃。GPT-4使用的数据集约为GPT-3.5的500倍，已进化为大型多模态模型（LMM，Large Multimodal Model）7，可同时处理文本之外的图像、音频和视频等各种输入数据，并生成各种数据格式。随着ChatGPT引发的生成式人工智能热潮，各企业纷纷推出了多种生成式人工智能服务。其中，谷歌推出的可同时识别并理解文本、图像和音频的Gemini、Meta推出的能准确识别并分离出图像中特定对象的SAM，和Open AI推出的可根据文本提示制作视频的Sora等均为具有代表性的生成式人工智能。\n7**大型多模式模型（Large Multimodal Model）**：一种深度学习算法，除文本外，还可处理多种不同类型的数据，包括图像、音频等。\n生成式人工智能市场才刚刚起步。根据全球市场调研公司IDC（International Data Corporation）的报告，2024年生成式人工智能市场规模有望达到401亿美元，是上一年的2.7倍。同时，该报告还预测，该市场增长速度将逐年加快，到2027年有望达到1511亿美元。展望未来，生成式人工智能将超越软件，并转向硬件和互联网服务及其他领域。其性能和便利性也将不断提升，让更多人轻松使用。\n### 改变日常生活的人工智能，未来走向会如何？就如同2000年的谷歌搜索和2010年的移动社交媒体一样，人工智能正在成为焦点，成为整个社会新变化和新机遇的驱动力。其技术进步的速度前所未有，而在此过程中，人类面临的挑战和担忧也与日俱增。\n那么，“下一代生成式人工智能技术”将是什么呢？当前最受瞩目的未来人工智能技术无疑是“端侧AI（On-Device AI）”。通常情况下，人工智能服务需要与大型云服务器进行通信，将数据传输到边缘设备。然而，端侧AI往往可以通过在手机、个人电脑或其他电子设备上安装人工智能芯片组和小型LLM （sLLM, Smaller LLM）自主运行人工智能服务。这种替代方案不仅可以解决与运行人工智能相关的安全和资源问题，同时还可以提供更加个性化的人工智能服务。\n![云侧人工智能和端侧人工智能的架构比较] \n云侧人工智能和端侧人工智能的架构比较与端侧AI一样，未来人工智能也将搭载在更多的设备上，其形式也将不断进化。市场上已经出现了一些我们只在电影中见过的创新产品。美国人工智能初创公司Humane于2023年推出的AI Pin是一款可穿戴的人工智能设备，搭载激光墨水显示屏，可以将菜单投射到用户的手掌上。2024年，在CES上引起关注的Rabbit R1和Brilliant Labs推出的Frame，同样是具有创新性的人工智能可穿戴设备。此外，如苹果公司的Vision Pro和Meta公司的Quest等采用了人工智能技术的混合现实（MR, Mixed Reality）头戴式设备，正在开辟一个超越传统虚拟现实（VR，Virtual Reality）和元宇宙的新市场。\n科技的迅猛发展为人类创造了新的机遇，但同时也带来了一系列社会问题。人工智能技术的快速发展引起了人们的担忧，担心社会无法跟上这些技术进展的步伐。同时，在现实世界中出现了不少滥用人工智能的案例，制造精巧虚假内容导致大量假新闻的产生，加剧了社会混乱。最近，围绕着美国等多个面临大型选举的国家，人们对虚假视频和图片等&#8220;深度伪造（Deepfake）&#8221;内容泛滥的情况表示深切担忧。\n![生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱] \n生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱\n人工智能在开发和使用过程中可能存在一些风险因素。由于生成式人工智能会从网络上抓取并重新组合可公开获得的资料进行预训练，许多创作作品可能会成为抄袭对象。此外，人们还担心用相同的生成式人工智能程序并用相似的提示语所生成的内容可能会产生版权纠纷。人工智能不仅可以帮助人们完成工作、提高生产率，还有可能取代一些工作岗位，对劳动力市场结构带来改变，这种前景显然并不受欢迎。人工智能创造的世界已经超出了人类的想象。一个我们从未经历过的世界正在快速逼近。面对这突如其来的未来变革，我们该如何应对？为了做出正确的回应，我们需要深入理解和分析人工智能，并进行更具体的关注和社会讨论。TAG(#)\n[#AI] [#人工智能] [#机器学习] [#生成式人工智能] [#深度学习] \n分享* [] \n* [] \n* [![link]] \n## 相关帖子[![]] \n商业사용안함## [SK海力士都承勇副社长荣获铜塔产业勋章：“以基于AI/DT的智能工厂，提升HBM等制造技术的竞争力”] \n2025年5月2日\n[![]] \n技术## [[Rulebreakers’ Revolutions]SK海力士的SOM如何引领AI时代的下一代存储器发展] \n2025年4月1日\n[![]] \n新闻稿사용안함## [SK海力士将在GTC 2025上展示业界顶级存储器技术实力] \n2025年3月18日\n[![]] \n技术사용안함## [[Rulebreakers’ Revolutions] CXL技术如何在人工智能时代扩展数据中心存储容量的极限] \n2025年1月24日\n[![]] \n商业사용안함## [[CES 2025视频] 与SK海力士携手掀起人工智能浪潮] \n2025年1月10日\n[![]] \n商业사용안함## [SK海力士在CES 2025展示人工智能驱动的创新成果，助力可持续未来] \n2025年1月7日\n[] \n分享* [] \n* [] \n* [![link]] \n搜索', 'doi': '', 'published_date': '2024-10-14T00:00:00+00:00', 'pdf_url': '', 'url': 'https://news.skhynix.com.cn/all-about-ai-the-origins-evolution-future-of-ai/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 16:00:59,729 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 16:00:59,731 - __main__ - INFO - handle_download: downloaded=8
2026-02-03 16:00:59,731 - __main__ - INFO - call_tool payload: source_tool=exa_context_download, result_type=papers, count=8
2026-02-03 16:00:59,732 - __main__ - INFO - call_tool: name=exa_context_download, result_type=papers, count=8
2026-02-03 16:00:59,732 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'save_path': '/home/qinshan/widthresearch/data/downloads/exa_人工智能六十年技术革.md'}}
2026-02-03 16:14:05,993 - __main__ - INFO - call_tool: name=tavily_search, args={'query': '人工智能的发展历史？'}
2026-02-03 16:14:05,994 - __main__ - INFO - handle_search: searcher=TavilySearch, query=人工智能的发展历史？, search_type=None
2026-02-03 16:14:06,033 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': '人工智能的发展历史？'}
2026-02-03 16:14:06,034 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=人工智能的发展历史？, search_type=None
2026-02-03 16:14:06,044 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': '人工智能的发展历史？'}
2026-02-03 16:14:06,044 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=人工智能的发展历史？, search_type=None
2026-02-03 16:14:09,859 - __main__ - INFO - handle_search: returned=10
2026-02-03 16:14:09,859 - __main__ - INFO - call_tool payload: source_tool=tavily_search, result_type=papers, count=10
2026-02-03 16:14:09,859 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-03 16:14:09,860 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': None}}
2026-02-03 16:14:10,287 - __main__ - INFO - handle_search: returned=10
2026-02-03 16:14:10,287 - __main__ - INFO - call_tool payload: source_tool=exa_context_search, result_type=papers, count=10
2026-02-03 16:14:10,287 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-03 16:14:10,288 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能的发展时间轴：从过去到未来-百度开发者中心', 'authors': [], 'abstract': '人工智能的发展时间轴：从过去到未来-百度开发者中心\n[![logo]] \n* [登录] \n* |\n* [注册] \n### 开发者热搜* [人工智能] \n* [云原生] \n* [AI应用] \n[推荐] \n[云原生] \n[文心快码 Baidu Comate] \n[飞桨PaddlePaddle] \n[人工智能] \n[超级链] \n[数据库] \n[百度安全] \n[物联网] \n[开源技术] \n[云计算] \n[大数据] \n[开发者] \n[企业服务] \n[更多内容] \n[千帆大模型平台] \n[客悦智能客服] \n# 人工智能的发展时间轴：从过去到未来作者：[谁偷走了我的奶酪] 2024.01.08 08:38浏览量：33\n*简介：*本文将带你了解人工智能的发展历程，从早期的思想萌芽到现代的应用普及，我们将通过时间轴的方式揭示人工智能的冷知识和发展趋势。\n人工智能（AI）的发展历程可以追溯到上个世纪。在这个漫长的时间里，AI经历了多次高潮和低谷，不断推动着科技的进步。下面让我们一起沿着时间轴，了解AI的成长历程和未来展望。\n1943年，美国神经科学家Warren McCulloch和数学家Walter Pitts提出了[神经网络] 的初步概念，他们认为神经元的工作原理与逻辑门相似。这一思想成为人工智能发展的重要起点。\n1956年，美国达特茅斯学院的一次研讨会上，正式提出了“人工智能”这一概念。这次会议标志着AI作为一个独立的学术领域正式诞生。\n1957年，加拿大心理学家Frank Rosenblatt开发了感知机模型，这是一种基于神经网络的[机器学习] 模型。然而，由于当时计算机性能的限制，这一模型并未得到广泛应用。\n1966年，美国科学家Joseph Weizenbaum开发了名为Eliza的自然语言对话程序，这是最早的聊天机器人之一。Eliza能够通过简单的文本对话模拟人类对话，引起了人们对AI的关注。\n1970年，日本ATR实验室开发了名为Shakey的机器人，它是世界上最早的移动机器人之一。Shakey能够自主导航、识别物体并执行任务。\n1981年，日本科学家Satoshi Sekiguchi提出了基于规则的专家系统，这是一种基于知识的计算机系统，用于提供专业领域的建议和决策。\n1988年，美国斯坦福大学教授Fei-Fei Li和她的团队开发了用于[图像识别] 的卷积神经网络LeNet-5。虽然当时的技术有限，但这一研究为现代计算机视觉领域奠定了基础。\n1997年，IBM的超级计算机“深蓝”战胜了国际象棋世界冠军Garry Kasparov，这是计算机首次在传统智力[游戏] 中击败人类。\n2006年，加拿大多伦多大学教授Geoffrey Hinton提出了[深度学习] 的概念，这是一种模拟人脑神经网络的机器学习方法。深度学习在[语音识别] 、图像识别等领域取得了巨大成功。\n2011年，苹果公司发布Siri语音助手，成为首个在消费市场上广泛应用的智能助手。Siri能够理解语音指令并回答问题，为用户提供便利的信息和服务。\n2016年，谷歌DeepMind开发的AlphaGo战胜了围棋世界冠军李世石，这是计算机在围棋领域首次击败人类。AlphaGo使用深度学习和蒙特卡洛树搜索算法，展现了AI在复杂决策问题上的强大能力。\n2020年，Open[AI开发] 的GPT-3语言模型引发了AI文本生成的热潮。GPT-3能够生成连贯、有逻辑的文本内容，被广泛应用于[自然语言处理] 和对话系统等领域。\n未来展望：随着技术的不断进步，AI将在更多领域发挥重要作用。例如，自动驾驶、医疗诊断、金融投资等领域都将受益于AI的发展。同时，我们也需要关注AI带来的伦理和隐私问题，确保技术的可持续发展。\n### 相关文章推荐* [### 文心一言接入指南：通过百度智能云千帆大模型平台API调用\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。\n] \n[十万个为什么] 2023.10.20 16:562564931910\n* [### 从MLOps 到LMOps 的关键技术嬗变本文整理自QCon 全球软件开发大会-从 MLOps 到LMOps 分论坛的同名主题演讲] \n[百度智能云开发者中心] 2023.11.15 18:033441095\n* [### Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n[百度智能云开发者中心] 2023.03.21 10:563032831\n* [### 更轻量的百度百舸，CCE Stack 智算版发布百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的AI 工程能力面向市场推出的解决方案。] \n[百度智能云开发者中心] 2023.03.02 12:172626811\n* [### 打造合规数据闭环，加速自动驾驶技术研发今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n[百度智能云开发者中心] 2023.03.02 15:002767501\n* [### LMOps 工具链与千帆大模型平台LMOps 相关的概念以及关键技术] \n[百度智能云开发者中心] 2023.11.17 15:492395533\n### 发表评论登录后可评论，请前往[登录] 或[注册] \n评论### 开发者关注产品榜* [\n*1*\n### 百度千帆·大模型服务及Agent开发平台\n企业级一站式大模型开发及服务平台模型训练限时免费] \n* [\n*2*\n### 百度千帆·数据智能平台一站式多模态数据管理、加工和分析应用平台平台体验全免费] \n* [\n*3*\n### 秒哒-生成式应用开发平台\n不用写代码，就能实现任意想法全功能免费体验] \n* [\n*4*\n### 百度智能云客悦智能客服平台大模型重塑营销与客服体验0元试用一个月\n] \n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践] \n### 关于作者[![] ### ] \n* 被阅读数* 被赞数* 被收藏数关注活动[\n咨询]', 'doi': '', 'published_date': '2024-01-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2733815', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 16:14:13,073 - __main__ - INFO - handle_search: returned=3
2026-02-03 16:14:13,073 - __main__ - INFO - call_tool payload: source_tool=wikipedia_search, result_type=papers, count=3
2026-02-03 16:14:13,073 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=3
2026-02-03 16:14:13,074 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T16:14:13.072842', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 16:14:13', 'language': 'zh'}}
2026-02-03 16:14:38,096 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': None}}, {'paper_id': '', 'title': '人工智能的起源、发展和未来 - SK hynix Newsroom', 'authors': [], 'abstract': '![SK hynix Newsroom](https://d36ae2cxtn9mcr.cloudfront.net/wp-content/uploads/2024/12/09053016/logo.png)\n![sk하이닉스 뉴스룸 홈](https://d36ae2cxtn9mcr.cloudfront.net/wp-content/uploads/2024/12/11060634/logo_black.png)\n![sk하이닉스 뉴스룸 홈](https://d36ae2cxtn9mcr.cloudfront.net/wp-content/uploads/2024/12/11060634/logo_black.png)\n\n# 人工智能的起源、发展和未来\n\n![닫기 버튼](/wp-content/uploads/2025/01/close_white.svg)\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/10003024/SK-hynix_All-About-AI_Thumbnail.png)\n\n能够像人类一样行走、说话和思考的人工智能机器人，过去常常是科幻漫画和电影中的热门题材。曾经只存在于人类想象中的人工智能和机器人，如今已不再是梦想，因为它正在走进现实并且改变着人们的日常生活。那么，人工智能始于何时，经历了怎样的演变，又会创造怎样的未来呢？\n\n### “人工智能”的起源与发展\n\n![人工智能发展的历史演变进程](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055755/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_01.png "人工智能发展的历史演变进程")\n\n![人工智能发展的历史演变进程](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055755/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_01.png "人工智能发展的历史演变进程")\n\n人工智能发展的历史演变进程\n\n人工智能的起源可以追溯到20世纪50年代。1950年，英国数学家艾伦·图灵（Alan Turing）声称机器能够思考，并设计了“图灵测试（The Turing Test）”作为验证方法以佐证这个观点，这被认为是首次提出人工智能概念的研究。1956年，达特茅斯会议（Dartmouth Conference）召开，向世界介绍了人工智能的概念。会议讨论了机器能否像人类一样学习和发展，并首次使用了“人工智能”这一术语。\n\n在这一时期，人们对人工神经网络（Artificial Neural Network）模型的研究也很活跃。1957年，弗兰克·罗森布拉特（Frank Rosenblatt）用他的 “感知器（Perceptron）”模型实证了计算机可以识别和学习模式的概念，这是对”神经网络”理论的一次实践检验。“神经网络”理论是由神经生理学家沃伦·斯特吉斯·麦卡洛克（Warren Sturgis McCulloch）和沃尔特·皮茨（Walter Pitts）于1943年提出的，他们根据神经细胞的相互作用原理组建了一个简单的计算模型。尽管这些早期的研究成果引发了公众的期待，但由于计算能力、逻辑和数据缺乏等方面的限制，人工智能的研究很快就停滞不前。\n\n20世纪80年代出现了 “专家系统（Expert System）”，它可以根据人类输入的规则自动做出决策。“专家系统”在医学、法律和零售业等实用领域发挥的诊断、分类和分析等功能，暂时性地再度引起了人们对人工智能的关注。然而，该系统的局限性在于仅依赖人工设定的规则运行，缺乏理解现实世界的复杂性的能力，因此发展受到了限制。\n\n20世纪90年代，过去只能听从人类指令的人工智能，利用“机器学习（Machine Learning）”算法开始自主发现规则进行学习，这得益于数码技术及互联网的出现。有了来自网络的大量数据，人工智能可以自主学习规则，甚至发现人类无法发现的规则。基于“机器学习”的人工智能研究开始重新产出成果。\n\n### 人工智能的核心技术，”深度学习”的发展\n\n![人工神经网络和深度学习发展的时间线](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055758/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_02.png "人工神经网络和深度学习发展的时间线")\n\n![人工神经网络和深度学习发展的时间线](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055758/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_02.png "人工神经网络和深度学习发展的时间线")\n\n人工神经网络和深度学习发展的时间线\n\n人工神经网络的早期研究在1969年进入了长期停滞期，因为人们发现先前提出的感知器模型无法有效解决非线性问题1。此后，重新将这一研究推向前沿的正是被誉为”深度学习之父”的杰弗里·辛顿（Geoffrey Hinton）。\n\n1986年，辛顿将反向传播算法2应用到由多层人工神经网络构成的多层感知器（Multi-Layer Perceptrons）理论中，证明其可以解决感知器存在的现有问题。这一举措重燃了人工神经网络研究的热情。然而，随着神经网络深度的增加，出现了学习过程和结果异常的问题。\n\n2006年，辛顿发表了题为《深度信念网络的快速学习算法（A Fast Learning Algorithm for Deep Belief Nets）》的论文，确立了深度学习的基本概念，并介绍了深度信念网络（DBN，Deep Belief Network），这种生成式模型可大幅提升多层感知器的性能。深度信念网络通过无监督学习3对每一层进行预训练，然后对整个网络进行微调，显著地提高了神经网络的学习速度和效率, 这一进展为未来深度学习的发展铺平了道路。\n\n1早期感知器模型为单层感知器（Single-layer Perceptron），不能处理XOR等非线性问题，处理这类问题时，在两个输入值相同时需输出0，而不同时则需输出1。  \n2**反向传播（Backpropagation）**：神经网络中的一种算法，用于计算输出值与真实值之间的差值，并从输出值开始按相反顺序调整权重，以减少误差。  \n3**无监督学习（Unsupervised Learning）**：机器学习中的一种学习理论，不给出输入数据的正确答案，而是让其发现和理解隐藏结构或模式的学习方法。\n\n![Kien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055802/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_03.png "Kien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页")\n\n![Kien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055802/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_03.png "Kien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页")\n\nKien Nguyen, Arun Ross，《基于现有CNN特征的虹膜识别：深度学习视角》，IEEE ACCESS SEPT（2017），第 3 页\n\n2012年，发生了一件历史性事件，证明了深度学习的卓越性能。由辛顿率领的AlexNet在图像识别挑战赛（ILSVRC, ImageNet Large Scale Visual Recognition Challenge）中夺得冠军。基于深度学习的AlexNet模型实现了84.7%的图像识别率，远超其他模型，值得一提的是，它将上一年冠军的错误率从25.8%降至16.4%。\n\n自2010年以来，深度学习已成为人工智能研究的主流，其迅速发展的背后有两个主要原因。首先是包括图形处理器（GPU ，Graphics Processing Unit）在内的计算机系统的进步。GPU最初是为处理计算机图形而创建的，与中央处理器（CPU ，Central Processing Unit）相比，GPU并行处理类似的重复运算速度更快。2010年，GPU通用计算（GPGPU ，General-Purpose computing on GPU）技术的出现，使GPU取代了CPU的角色。GPU的应用领域愈发广泛，特别是在训练人工神经网络方面，极大地加快了深度学习的发展。深度学习需要对海量训练数据进行分析以提取特征，并且需要进行迭代计算，而GPU具备的并行计算结构则非常适合这一需求。\n\n其次是由于数据量的增加，因为训练人工神经网络需要大量数据。过去，数据仅限于输入计算机的信息，但自20世纪90年代以来，随着互联网的普及和搜索引擎的发展，可处理的数据范围呈指数级增长。2000年以来，智能手机和物联网（IoT, Internet of Things）得到发展，催生了大数据（Big Data）的概念，现实世界到处都能实时收集数不清的数据。深度学习算法经过更多数据的训练后变得更加精细化，数据模式的转变无疑为深度学习技术奠定了基础。\n\n2016年，深度学习再次改变了世界。谷歌DeepMind开发的人工智能AlphaGo以4胜1负的比分战胜了围棋大师李世石九段，这一壮举让全世界都铭记人工智能的存在。AlphaGo是通过融合深度学习算法、强化学习（Reinforcement Learning）4和蒙特卡洛树搜索（MCTS，Monte Carlo Tree Search）5算法而创建的。借助此种方式，它能够进行数万次的自我对弈、自主学习，并模仿人类直觉以预测数值，甚至是制定战略。“战胜人类的AI”问世，标志着人工智能时代正式到来。\n\n4**强化学习（Reinforcement Learning）**：人工智能学习行为的方法之一，以奖励的形式告知行动结果，并且可以在特定情况下选择最佳行动的策略。  \n5**蒙特卡洛树搜索（Monte Carlo tree search）**：一种通过反复生成一系列随机数来处理近似函数值的概率算法。 其功能是将目前情况下可选择的行为结构化为探索树，并通过随机模拟推论各行为的得失来决定最佳行为。\n\n### “生成式人工智能”热潮始于ChatGPT\n\n![生成式人工智能概念图](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055806/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_04.png "生成式人工智能概念图")\n\n![生成式人工智能概念图](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055806/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_04.png "生成式人工智能概念图")\n\n生成式人工智能概念图\n\n2022年末，人类迎来了人工智能技术的巨大变革。OpenAI推出了ChatGPT，由大语言模型（LLM，Large Language Model）6GPT（Generative Pre-trained Transformer）3.5驱动，标志着生成式人工智能时代的开启。生成式人工智能渗透到了曾被视为人类独有的“创作”领域，能够生成各种格式的高质量内容。它超越了基于数据进行预测或分类的深度学习层面，可根据用户需求，使用LLM或各种图像生成模型（如 VAE、GAN、扩散模型等），自行生成结果。\n\n6**大语言模型（Large Language Model）**：以海量数据基础，进行多种自然语言处理任务的深度学习算法。\n\n生成式人工智能的诞生可以追溯到2014年，当时伊恩·古德费洛（Ian Goodfellow）发布了生成对抗网络（GANs，Generative Adversarial Networks）模型，该模型由两个神经网络相互竞争学习的结构而组成。一个神经网络生成与真实数据无异的新数据，另一个神经网络将其与真实数据进行比较，并做出判断，随着这一竞争和判断的过程不断重复，生成的数据也越来越精细。随着时间推移，GANs模型不断得到修改和完善，目前已被广泛应用于图像生成和转换等多个领域中。\n\n2017年，名为Transformer的自然语言处理（NLP，Natural Language Processing）模型问世。Transformer将数据间的关系视为重要变量，通过对特定信息给予更多”关注”，它可以学习数据之间的复杂关系和模式，捕捉更多重要信息，从而产生更高质量的输出结果。Transformer模型为语言理解、机器翻译和交互系统等自然语言处理任务带来了革命性变化，尤其是它对前文提到的GPT等LLM的出现产生了重大影响。\n\nGPT于2018年首次发布，由于每年都会使用更多的参数和训练数据，其性能一直在飞速提升。2022年，搭载GPT 3.5的交互式人工智能系统ChatGPT发布，彻底改变了人工智能的模式。ChatGPT能通过理解用户对话的上下文来提供适当的回复，并回答各种问题。ChatGPT推出一周内，用户数量就突破了100万，两个月内活跃用户数量就超过了1亿，在全球范围内引发了爆炸性的关注。\n\n2023年，Open AI推出了GPT-4，再次实现技术飞跃。GPT-4使用的数据集约为GPT-3.5的500倍，已进化为大型多模态模型（LMM，Large Multimodal Model）7，可同时处理文本之外的图像、音频和视频等各种输入数据，并生成各种数据格式。随着ChatGPT引发的生成式人工智能热潮，各企业纷纷推出了多种生成式人工智能服务。其中，谷歌推出的可同时识别并理解文本、图像和音频的Gemini、Meta推出的能准确识别并分离出图像中特定对象的SAM，和Open AI推出的可根据文本提示制作视频的Sora等均为具有代表性的生成式人工智能。\n\n7**大型多模式模型（Large Multimodal Model）**：一种深度学习算法，除文本外，还可处理多种不同类型的数据，包括图像、音频等。\n\n生成式人工智能市场才刚刚起步。根据全球市场调研公司IDC（International Data Corporation）的报告，2024年生成式人工智能市场规模有望达到401亿美元，是上一年的2.7倍。同时，该报告还预测，该市场增长速度将逐年加快，到2027年有望达到1511亿美元。展望未来，生成式人工智能将超越软件，并转向硬件和互联网服务及其他领域。其性能和便利性也将不断提升，让更多人轻松使用。\n\n### 改变日常生活的人工智能，未来走向会如何？\n\n就如同2000年的谷歌搜索和2010年的移动社交媒体一样，人工智能正在成为焦点，成为整个社会新变化和新机遇的驱动力。其技术进步的速度前所未有，而在此过程中，人类面临的挑战和担忧也与日俱增。\n\n那么，“下一代生成式人工智能技术”将是什么呢？当前最受瞩目的未来人工智能技术无疑是“端侧AI（On-Device AI）”。通常情况下，人工智能服务需要与大型云服务器进行通信，将数据传输到边缘设备。然而，端侧AI往往可以通过在手机、个人电脑或其他电子设备上安装人工智能芯片组和小型LLM （sLLM, Smaller LLM）自主运行人工智能服务。这种替代方案不仅可以解决与运行人工智能相关的安全和资源问题，同时还可以提供更加个性化的人工智能服务。\n\n![云侧人工智能和端侧人工智能的架构比较](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055809/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_05.png "云侧人工智能和端侧人工智能的架构比较")\n\n![云侧人工智能和端侧人工智能的架构比较](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055809/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_05.png "云侧人工智能和端侧人工智能的架构比较")\n\n云侧人工智能和端侧人工智能的架构比较\n\n与端侧AI一样，未来人工智能也将搭载在更多的设备上，其形式也将不断进化。市场上已经出现了一些我们只在电影中见过的创新产品。美国人工智能初创公司Humane于2023年推出的AI Pin是一款可穿戴的人工智能设备，搭载激光墨水显示屏，可以将菜单投射到用户的手掌上。2024年，在CES上引起关注的Rabbit R1和Brilliant Labs推出的Frame，同样是具有创新性的人工智能可穿戴设备。此外，如苹果公司的Vision Pro和Meta公司的Quest等采用了人工智能技术的混合现实（MR, Mixed Reality）头戴式设备，正在开辟一个超越传统虚拟现实（VR，Virtual Reality）和元宇宙的新市场。\n\n科技的迅猛发展为人类创造了新的机遇，但同时也带来了一系列社会问题。人工智能技术的快速发展引起了人们的担忧，担心社会无法跟上这些技术进展的步伐。同时，在现实世界中出现了不少滥用人工智能的案例，制造精巧虚假内容导致大量假新闻的产生，加剧了社会混乱。最近，围绕着美国等多个面临大型选举的国家，人们对虚假视频和图片等 “深度伪造（Deepfake）”内容泛滥的情况表示深切担忧。\n\n![生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055816/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_06.png "生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱")\n\n![生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2024/10/07055816/SK-hynix_All-About-AI_The-Origins-Evolution-Future-of-AI_06.png "生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱")\n\n生成式人工智能（DALL·E）描述的深度伪造技术引起的社会焦虑和混乱\n\n人工智能在开发和使用过程中可能存在一些风险因素。由于生成式人工智能会从网络上抓取并重新组合可公开获得的资料进行预训练，许多创作作品可能会成为抄袭对象。此外，人们还担心用相同的生成式人工智能程序并用相似的提示语所生成的内容可能会产生版权纠纷。人工智能不仅可以帮助人们完成工作、提高生产率，还有可能取代一些工作岗位，对劳动力市场结构带来改变，这种前景显然并不受欢迎。\n\n人工智能创造的世界已经超出了人类的想象。一个我们从未经历过的世界正在快速逼近。面对这突如其来的未来变革，我们该如何应对？为了做出正确的回应，我们需要深入理解和分析人工智能，并进行更具体的关注和社会讨论。\n\nTAG(#)\n\n分享\n\n![link](/wp-content/uploads/2025/01/link_black2.svg)\n\n## 相关帖子\n\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2025/04/30054942/SK-hynix_VP-Seungyong-Doh-Awarded-Bronze-Tower-Order-of-Industrial-Service-Merit_Thumbnail_CN.png)\n\n## [SK海力士都承勇副社长荣获铜塔产业勋章：“以基于AI/DT的智能工厂，提升HBM等制造技术的竞争力”](https://news.skhynix.com.cn/sk-hynix-vp-seungyong-doh-awarded-bronze-tower-order-of-industrial-service-merit/)\n\n2025年5月2日\n\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2025/03/31022846/SK-hynix_Rulebreaker-8_SOM_thumb.png)\n\n## [[Rulebreakers’ Revolutions]SK海力士的SOM如何引领AI时代的下一代存储器发展](https://news.skhynix.com.cn/rulebreakers-revolutions-how-sk-hynix-som-paves-the-way-for-next-gen-memory-in-the-ai-era/)\n\n2025年4月1日\n\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2025/03/21064348/SK-hynix_NVIDIA-GTC-2025-Press-Release_Thumb.png)\n\n## [SK海力士将在GTC 2025上展示业界顶级存储器技术实力](https://news.skhynix.com.cn/sk-hynix-showcases-industry-leading-memory-technology-at-gtc-2025/)\n\n2025年3月18日\n\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2025/02/06062623/SK-hynix_Rulebreaker-7_CXL_CN_Thumbnail.png)\n\n## [[Rulebreakers’ Revolutions] CXL技术如何在人工智能时代扩展数据中心存储容量的极限](https://news.skhynix.com.cn/rulebreakers-revolutions-how-cxl-tech-expands-data-center-memory-scaling-boundaries-in-the-ai-era/)\n\n2025年1月24日\n\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2025/02/06051208/SK-hynix_CES-2025-video_thumb.png)\n\n## [[CES 2025视频] 与SK海力士携手掀起人工智能浪潮](https://news.skhynix.com.cn/ces-2025-video-ride-the-ai-wave-with-sk-hynix/)\n\n2025年1月10日\n\n![](https://dfovt2pachtw4.cloudfront.net/wp-content/uploads/2025/02/06035825/Sk-hynix_Business_CES-2025_thumb.png)\n\n## [SK海力士在CES 2025展示人工智能驱动的创新成果，助力可持续未来](https://news.skhynix.com.cn/sk-hynix-showcases-ai-driven-innovations-for-a-sustainable-tomorrow-at-ces-2025/)\n\n2025年1月7日\n\n分享\n\n![link](/wp-content/uploads/2025/01/link_white2.svg)\n\n#### 欢迎订阅SK海力士的最新消息！\n\n[申请订阅](/newsroom-subscribe/)\n\n![sk하이닉스 뉴스룸](https://d36ae2cxtn9mcr.cloudfront.net/wp-content/uploads/2024/12/13084420/footer_logo.png)\n![linkdin](/wp-content/uploads/2025/01/linkedin_white.svg)\n![wechat](/wp-content/uploads/2025/01/wechat_ico.svg)\n![wechat_qr](/wp-content/uploads/2025/02/SKhynix_QRcode-ordinary.jpg)\n![RSS](/wp-content/uploads/2025/01/rss_white.svg)\n\n版权所有 (C) SK HYNIX INC. 保留所有权利.\nSK海力士 ∣ 京畿道利川市夫鉢邑京忠大路2091 ∣ +82.31.8093.4790', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://news.skhynix.com.cn/all-about-ai-the-origins-evolution-future-of-ai/', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99929583, 'save_path': None}}, {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '![](/static/images/icons/zhwiki-25.svg)\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n![自由的百科全书](/static/images/mobile/copyright/wikipedia-tagline-zh-25-hans.svg)\n\n## 目录\n\n# 人工智能史\n\n| [人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")系列内容 |\n| --- |\n|  |\n| 主要目标  * [知识表示](/wiki/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA "知识表示") * [自动规划](/w/index.php?title=%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92%E5%92%8C%E8%B0%83%E5%BA%A6&action=edit&redlink=1 "自动规划和调度（页面不存在）")（英语：[Automated planning and scheduling](https://en.wikipedia.org/wiki/Automated_planning_and_scheduling "en:Automated planning and scheduling")） * [机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习") * [语言处理](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理") * [电脑视觉](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89 "计算机视觉") * [机器人学](/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6 "机器人学") * [强人工智慧](/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "通用人工智慧") * [弱人工智慧](/wiki/%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "弱人工智慧") * [人工智能对齐](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%B9%E9%BD%90 "人工智能对齐") |\n| 实现方式  * [符号人工智能](/wiki/%E7%AC%A6%E8%99%9F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "符号人工智能") * [深度学习](/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0 "深度学习") * [贝氏网路](/wiki/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF "贝氏网路") * [进化算法](/wiki/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95 "进化算法") * [混合智能系统](/wiki/%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%B3%BB%E7%B5%B1 "混合智能系统")   + [混合专家模型](/wiki/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B "混合专家模型") * [生成式人工智慧](/wiki/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "生成式人工智慧") * [代理式人工智能](/w/index.php?title=%E4%BB%A3%E7%90%86%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "代理式人工智能（页面不存在）")（英语：[AI agent](https://en.wikipedia.org/wiki/AI_agent "en:AI agent")） |\n| [人工智能哲学](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%93%B2%E5%AD%B8 "人工智能哲学")  * [伦理](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BC%A6%E7%90%86&action=edit&redlink=1 "人工智能伦理（页面不存在）")（英语：[Ethics of artificial intelligence](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence "en:Ethics of artificial intelligence")） * [人工智能安全](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%89%E5%85%A8&action=edit&redlink=1 "人工智能安全（页面不存在）")（英语：[AI safety](https://en.wikipedia.org/wiki/AI_safety "en:AI safety")）   + [幻觉](/wiki/%E5%B9%BB%E8%A7%89_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD) "幻觉 (人工智能)")   + [存在风险](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%98%E5%9C%A8%E9%A3%8E%E9%99%A9&action=edit&redlink=1 "人工智能的存在风险（页面不存在）")（英语：[Existential risk from artificial general intelligence](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence "en:Existential risk from artificial general intelligence")） * [图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试") * [中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间") * [可解释人工智慧](/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "可解释人工智慧") * [友好的人工智能](/w/index.php?title=%E5%8F%8B%E5%A5%BD%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "友好的人工智能（页面不存在）")（英语：[Friendly artificial intelligence](https://en.wikipedia.org/wiki/Friendly_artificial_intelligence "en:Friendly artificial intelligence")） * [人工智能监管](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9B%91%E7%AE%A1&action=edit&redlink=1 "人工智能监管（页面不存在）")（英语：[Regulation of artificial intelligence](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence "en:Regulation of artificial intelligence")） |\n| 历史  * [时间轴](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E9%97%B4%E8%BD%B4&action=edit&redlink=1 "人工智能时间轴（页面不存在）")（英语：[Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence "en:Timeline of artificial intelligence")） * [发展](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95&action=edit&redlink=1 "人工智能发展（页面不存在）")（英语：[Progress in artificial intelligence](https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence "en:Progress in artificial intelligence")） * [专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统") * [人工智慧低谷](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷") * [人工智能热潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%83%AD%E6%BD%AE "人工智能热潮") * [人工智能法案](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B3%95%E6%A1%88 "人工智能法案") |\n| [人工智能的应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")  * [应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")   + [AlphaFold](/wiki/AlphaFold "AlphaFold")   + [深度伪造](/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%AA%E9%80%A0 "深度伪造")   + [AI艺术](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%97%9D%E8%A1%93 "人工智慧艺术")   + [音乐](/wiki/%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "音乐和人工智能")   + [医疗保健](/wiki/%E5%8C%BB%E7%96%97%E9%A2%86%E5%9F%9F%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "医疗领域的人工智能")   + [工业](/wiki/%E5%B7%A5%E4%B8%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "工业人工智能")   + [机器翻译](/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91 "机器翻译")   + [军事](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BB%8D%E5%82%99%E7%AB%B6%E8%B3%BD "人工智能军备竞赛") * [项目](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B9%E7%9B%AE%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能项目列表（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） * [编程语言](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能编程语言列表（页面不存在）")（英语：[List of programming languages for artificial intelligence](https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence "en:List of programming languages for artificial intelligence")） |\n| 主题与列表  * [主题](/wiki/Portal:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Portal:人工智能") * [术语表](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AF%E8%AF%AD%E8%A1%A8 "人工智能术语表") * [AI概述](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%BF%B0 "人工智能概述") * [AI公司列表](/w/index.php?title=List_of_artificial_intelligence_companies&action=edit&redlink=1 "List of artificial intelligence companies（页面不存在）")（英语：[List of artificial intelligence companies](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies "en:List of artificial intelligence companies")） * [AI项目列表](/w/index.php?title=List_of_artificial_intelligence_projects&action=edit&redlink=1 "List of artificial intelligence projects（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） |\n| * [查](/wiki/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template:人工智能") * [论](/wiki/Template_talk:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template talk:人工智能") * [编](/wiki/Special:EditPage/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Special:EditPage/Template:人工智能") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png/250px-Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png)\n\n**人工智能的历史**源远流长。在古代的[神话](/wiki/%E7%A5%9E%E8%A9%B1 "神话")[传说](/wiki/%E4%BC%A0%E8%AF%B4 "传说")中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](/wiki/%E9%9B%BB%E8%85%A6 "电脑")的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n\n1956年，[人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")的研究领域确立于在[达特茅斯学院](/wiki/%E8%BE%BE%E7%89%B9%E8%8C%85%E6%96%AF%E5%AD%A6%E9%99%A2 "达特茅斯学院")举行的[会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2]](#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")（也被称作AI之冬）。由于[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")爵士的批评和国会方面的压力，[美国](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3]](#cite_note-3)\n\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "强人工智慧")的机器至今仍未出现。[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4]](#cite_note-TuringQuote-4)\n\n在21世纪的第一个十年，[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n| [计算历史](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） |\n| --- |\n| [硬件](/wiki/%E7%A1%AC%E4%BB%B6 "硬件") |\n| * [1960年代之前](/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2 "计算机硬体历史") * [1960年代至今](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2_(1960%E5%B9%B4%E4%BB%A3%E8%87%B3%E4%BB%8A)&action=edit&redlink=1 "计算机硬体历史 (1960年代至今)（页面不存在）")（英语：[History of computing hardware (1960s–present)](https://en.wikipedia.org/wiki/History_of_computing_hardware_(1960s%E2%80%93present) "en:History of computing hardware (1960s–present)")） |\n| [软件](/wiki/%E8%BD%AF%E4%BB%B6 "软件") |\n| * [软体](/w/index.php?title=%E8%BB%9F%E9%AB%94%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体历史（页面不存在）")（英语：[History of software](https://en.wikipedia.org/wiki/History_of_software "en:History of software")） * [Unix](/w/index.php?title=Unix%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Unix历史（页面不存在）")（英语：[History of Unix](https://en.wikipedia.org/wiki/History_of_Unix "en:History of Unix")） * [自由和开源软件](/w/index.php?title=%E8%87%AA%E7%94%B1%E5%92%8C%E9%96%8B%E6%BA%90%E8%BB%9F%E4%BB%B6%E7%9A%84%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "自由和开源软件的历史（页面不存在）")（英语：[History of free and open-source software](https://en.wikipedia.org/wiki/History_of_free_and_open-source_software "en:History of free and open-source software")） |\n| [计算机科学](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6 "计算机科学") |\n| * 人工智能 * [编译器构造](/w/index.php?title=%E7%BC%96%E8%AF%91%E5%99%A8%E6%9E%84%E9%80%A0%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "编译器构造历史（页面不存在）")（英语：[History of compiler construction](https://en.wikipedia.org/wiki/History_of_compiler_construction "en:History of compiler construction")） * [计算机科学](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算机科学历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） * [操作系统](/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%86%E5%8F%B2 "操作系统历史") * [程式语言](/wiki/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80%E6%AD%B7%E5%8F%B2 "程式语言历史") * [杰出先驱者](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%85%88%E9%A9%B1%E8%80%85%E5%88%97%E8%A1%A8&action=edit&redlink=1 "计算机科学先驱者列表（页面不存在）")（英语：[List of pioneers in computer science](https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science "en:List of pioneers in computer science")） * [软体工程](/w/index.php?title=%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体工程历史（页面不存在）")（英语：[History of software engineering](https://en.wikipedia.org/wiki/History_of_software_engineering "en:History of software engineering")） |\n| 现代概念 |\n| * [通用CPU](/w/index.php?title=%E9%80%9A%E7%94%A8%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "通用中央处理器历史（页面不存在）")（英语：[History of general-purpose CPUs](https://en.wikipedia.org/wiki/History_of_general-purpose_CPUs "en:History of general-purpose CPUs")） * [图形用户界面](/wiki/%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2 "图形用户界面") * [互联网](/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%8E%86%E5%8F%B2 "互联网历史") * [个人电脑](/w/index.php?title=%E5%80%8B%E4%BA%BA%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "个人电脑历史（页面不存在）")（英语：[History of personal computers](https://en.wikipedia.org/wiki/History_of_personal_computers "en:History of personal computers")） * [笔记型电脑](/w/index.php?title=%E7%AD%86%E8%A8%98%E5%9E%8B%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "笔记型电脑历史（页面不存在）")（英语：[History of laptops](https://en.wikipedia.org/wiki/History_of_laptops "en:History of laptops")） * [电子游戏](/wiki/%E9%9B%BB%E5%AD%90%E9%81%8A%E6%88%B2%E5%8F%B2 "电子游戏史") * [全球资讯网](/w/index.php?title=%E5%85%A8%E7%90%83%E8%B3%87%E8%A8%8A%E7%B6%B2%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "全球资讯网历史（页面不存在）")（英语：[History of the World Wide Web](https://en.wikipedia.org/wiki/History_of_the_World_Wide_Web "en:History of the World Wide Web")） |\n| 按国家 |\n| * [保加利亚](/w/index.php?title=%E4%BF%9D%E5%8A%A0%E5%88%A9%E4%BA%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "保加利亚计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Bulgaria](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Bulgaria "en:History of computer hardware in Bulgaria")） * [波兰](/w/index.php?title=%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "波兰计算历史（页面不存在）")（英语：[History of computing in Poland](https://en.wikipedia.org/wiki/History_of_computing_in_Poland "en:History of computing in Poland")） * [罗马尼亚](/w/index.php?title=%E7%BD%97%E9%A9%AC%E5%B0%BC%E4%BA%9A%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "罗马尼亚计算历史（页面不存在）")（英语：[History of computing in Romania](https://en.wikipedia.org/wiki/History_of_computing_in_Romania "en:History of computing in Romania")） * [苏联集团国家](/w/index.php?title=%E8%8B%8F%E8%81%94%E9%9B%86%E5%9B%A2%E5%9B%BD%E5%AE%B6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联集团国家计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Soviet Bloc countries](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Soviet_Bloc_countries "en:History of computer hardware in Soviet Bloc countries")） * [苏联](/w/index.php?title=%E8%8B%8F%E8%81%94%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联计算历史（页面不存在）")（英语：[History of computing in the Soviet Union](https://en.wikipedia.org/wiki/History_of_computing_in_the_Soviet_Union "en:History of computing in the Soviet Union")） * [南斯拉夫](/w/index.php?title=%E5%8D%97%E6%96%AF%E6%8B%89%E5%A4%AB%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "南斯拉夫计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Yugoslavia](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Yugoslavia "en:History of computer hardware in Yugoslavia")） |\n| [计算年表](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "计算年表（页面不存在）")（英语：[Timeline of computing](https://en.wikipedia.org/wiki/Timeline_of_computing "en:Timeline of computing")） |\n| * [1950年之前](/w/index.php?title=1950%E5%B9%B4%E4%B9%8B%E5%89%8D%E7%9A%84%E8%AE%A1%E7%AE%97%E7%A1%AC%E4%BB%B6%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "1950年之前的计算硬件年表（页面不存在）")（英语：[Timeline of computing hardware before 1950](https://en.wikipedia.org/wiki/Timeline_of_computing_hardware_before_1950 "en:Timeline of computing hardware before 1950")） * [1950–1979](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1950%E2%80%931979)&action=edit&redlink=1 "计算年表 (1950–1979)（页面不存在）")（英语：[Timeline of computing 1950–1979](https://en.wikipedia.org/wiki/Timeline_of_computing_1950%E2%80%931979 "en:Timeline of computing 1950–1979")） * [1980–1989](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1980%E2%80%931989)&action=edit&redlink=1 "计算年表 (1980–1989)（页面不存在）")（英语：[Timeline of computing 1980–1989](https://en.wikipedia.org/wiki/Timeline_of_computing_1980%E2%80%931989 "en:Timeline of computing 1980–1989")） * [1990–1999](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1990%E2%80%931999)&action=edit&redlink=1 "计算年表 (1990–1999)（页面不存在）")（英语：[Timeline of computing 1990–1999](https://en.wikipedia.org/wiki/Timeline_of_computing_1990%E2%80%931999 "en:Timeline of computing 1990–1999")） * [2000–2009](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2000%E2%80%932009)&action=edit&redlink=1 "计算年表 (2000–2009)（页面不存在）")（英语：[Timeline of computing 2000–2009](https://en.wikipedia.org/wiki/Timeline_of_computing_2000%E2%80%932009 "en:Timeline of computing 2000–2009")） * [2010–2019](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2010%E2%80%932019)&action=edit&redlink=1 "计算年表 (2010–2019)（页面不存在）")（英语：[Timeline of computing 2010–2019](https://en.wikipedia.org/wiki/Timeline_of_computing_2010%E2%80%932019 "en:Timeline of computing 2010–2019")） * [更多年表……](/wiki/Category:%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8 "Category:计算年表") |\n| [计算机科学词汇](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E8%AF%8D%E6%B1%87&action=edit&redlink=1 "计算机科学词汇（页面不存在）")（英语：[Glossary of computer science](https://en.wikipedia.org/wiki/Glossary_of_computer_science "en:Glossary of computer science")） |\n| * [分类](/wiki/Category:%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B2 "Category:计算机历史") |\n| * [查](/wiki/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Template:计算历史") * [论](/w/index.php?title=Template_talk:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Template talk:计算历史（页面不存在）") * [编](/wiki/Special:EditPage/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Special:EditPage/Template:计算历史") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)\n\n## 先驱\n\n奥特曼写道[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](/wiki/%E8%87%AA%E5%8B%95%E6%A9%9F "自动机")）的实践之中。[[5]](#cite_note-FOOTNOTEMcCorduck20045–35-5)\n\n### 神话，幻想和预言中的AI\n\n[希腊神话](/wiki/%E5%B8%8C%E8%85%8A%E7%A5%9E%E8%AF%9D "希腊神话")中已经出现了机械人和人造人，如[赫淮斯托斯](/wiki/%E8%B5%AB%E6%B7%AE%E6%96%AF%E6%89%98%E6%96%AF "赫淮斯托斯")的黄金机器人和[皮格马利翁](/wiki/%E7%9A%AE%E6%A0%BC%E9%A9%AC%E5%88%A9%E7%BF%81 "皮格马利翁")的[伽拉忒亚](/wiki/%E4%BC%BD%E6%8B%89%E5%BF%92%E4%BA%9A "伽拉忒亚")。[[6]](#cite_note-6)中世纪出现了使用巫术或[炼金术](/wiki/%E7%82%BC%E9%87%91%E6%9C%AF "炼金术")将意识赋予无生命物质的传说，如[贾比尔](/wiki/%E8%B4%BE%E6%AF%94%E5%B0%94 "贾比尔")的*Takwin*，[帕拉塞尔苏斯](/wiki/%E5%B8%95%E6%8B%89%E5%A1%9E%E5%B0%94%E8%8B%8F%E6%96%AF "帕拉塞尔苏斯")的[何蒙库鲁兹](/wiki/%E4%BD%95%E8%92%99%E5%BA%93%E9%B2%81%E5%85%B9 "何蒙库鲁兹")和Judah Loew的[魔像](/wiki/%E9%AD%94%E5%83%8F "魔像")。[[7]](#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](/wiki/%E7%8E%9B%E4%B8%BD%C2%B7%E9%9B%AA%E8%8E%B1 "玛丽·雪莱")的《[弗兰肯斯坦](/wiki/%E5%BC%97%E5%85%B0%E8%82%AF%E6%96%AF%E5%9D%A6 "弗兰肯斯坦")》和[卡雷尔·恰佩克](/wiki/%E5%8D%A1%E9%9B%B7%E5%B0%94%C2%B7%E6%81%B0%E4%BD%A9%E5%85%8B "卡雷尔·恰佩克")的《罗素姆的万能机器人》。[[8]](#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9]](#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。\n\n### 自动人偶\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)\n\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师](/wiki/%E5%81%83%E5%B8%88 "偃师")（中国西周）[[10]](#cite_note-10)，[希罗](/wiki/%E5%B8%8C%E7%BD%97 "希罗")（希腊）[[11]](#cite_note-11)，[加扎利](/wiki/%E5%8A%A0%E6%89%8E%E5%88%A9 "加扎利")[[12]](#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13]](#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](/wiki/%E5%8F%A4%E5%9F%83%E5%8F%8A "古埃及")和[古希腊](/wiki/%E5%8F%A4%E5%B8%8C%E8%85%8A "古希腊")的[圣像](/wiki/%E8%81%96%E5%83%8F "圣像")，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")（[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")）写道“当发现神的本性时，人就能够重现他”[[14]](#cite_note-14)[[15]](#cite_note-15)。\n\n### 形式推理\n\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](/wiki/%E4%BA%9A%E9%87%8C%E5%A3%AB%E5%A4%9A%E5%BE%B7 "亚里士多德")（对三段论逻辑进行了形式分析），[欧几里得](/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97 "欧几里得")（其著作《[几何原本](/wiki/%E5%87%A0%E4%BD%95%E5%8E%9F%E6%9C%AC "几何原本")》是形式推理的典范），[花剌子密](/wiki/%E8%8A%B1%E5%89%8C%E5%AD%90%E5%AF%86 "花剌子密")（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E7%9A%84%E5%A8%81%E5%BB%89 "奥卡姆的威廉")和[邓斯·司各脱](/wiki/%E9%82%93%E6%96%AF%C2%B7%E5%8F%B8%E5%90%84%E8%84%B1 "邓斯·司各脱")。[[16]](#cite_note-Berlinski_2000-16)\n\n[马略卡](/wiki/%E9%A9%AC%E7%95%A5%E5%8D%A1 "马略卡")哲学家[拉蒙·柳利](/wiki/%E6%8B%89%E8%92%99%C2%B7%E6%9F%B3%E5%88%A9 "拉蒙·柳利")（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17]](#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18]](#cite_note-18)Llull的工作对[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")产生了很大影响，后者进一步发展了他的思想。[[19]](#cite_note-19)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/250px-Gottfried_Wilhelm_von_Leibniz.jpg)\n\n在17世纪中，[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")，[托马斯·霍布斯](/wiki/%E6%89%98%E9%A9%AC%E6%96%AF%C2%B7%E9%9C%8D%E5%B8%83%E6%96%AF "托马斯·霍布斯")和[笛卡儿](/wiki/%E7%AC%9B%E5%8D%A1%E5%84%BF "笛卡儿")尝试将理性的思考系统化为代数学或几何学那样的体系。[[20]](#cite_note-20)霍布斯在其著作《[利维坦](/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF) "利维坦 (霍布斯)")》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21]](#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](/wiki/%E9%80%9A%E7%94%A8%E8%A1%A8%E6%84%8F%E6%96%87%E5%AD%97 "通用表意文字")），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22]](#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n\n在20世纪，[数理逻辑](/wiki/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91 "数理逻辑")研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](/wiki/%E4%B9%94%E6%B2%BB%C2%B7%E5%B8%83%E5%B0%94 "乔治·布尔")的《思维的定律》与[弗雷格](/wiki/%E6%88%88%E7%89%B9%E6%B4%9B%E5%B8%83%C2%B7%E5%BC%97%E9%9B%B7%E6%A0%BC "戈特洛布·弗雷格")的《[概念文字](/wiki/%E6%A6%82%E5%BF%B5%E6%96%87%E5%AD%97 "概念文字")》。基于弗雷格的系统，[罗素](/wiki/%E7%BD%97%E7%B4%A0 "罗素")和[怀特海](/wiki/%E6%80%80%E7%89%B9%E6%B5%B7 "怀特海")在他们于1913年出版的巨著《[数学原理](/wiki/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86 "数学原理")》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9 "希尔伯特")，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16]](#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")，[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")和[Alonzo Church](/wiki/Alonzo_Church "Alonzo Church")的[λ演算](/wiki/%CE%9B%E6%BC%94%E7%AE%97 "Λ演算")给出。[[16]](#cite_note-Berlinski_2000-16)[[23]](#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)\n\n[邱奇-图灵论题](/wiki/%E9%82%B1%E5%A5%87-%E5%9B%BE%E7%81%B5%E8%AE%BA%E9%A2%98 "邱奇-图灵论题")暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16]](#cite_note-Berlinski_2000-16)[[24]](#cite_note-24)\n\n### 计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](/wiki/%E6%9F%A5%E5%B0%94%E6%96%AF%C2%B7%E5%B7%B4%E8%B4%9D%E5%A5%87 "查尔斯·巴贝奇")设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](/wiki/%E6%84%9B%E9%81%94%C2%B7%E5%8B%92%E8%8A%99%E8%95%BE%E7%B5%B2 "爱达·勒芙蕾丝")预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25]](#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%95%B0 "伯努利数")的方法。）\n\n第一批现代计算机是[二战](/wiki/%E4%BA%8C%E6%88%98 "二战")期间建造的大型译码机（包括Z3，[ENIAC](/wiki/ENIAC "ENIAC")和Colossus等）。[[26]](#cite_note-26)后两个机器的理论基础是[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")和[约翰·冯·诺伊曼](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC "约翰·冯·诺伊曼")提出和发展的学说。[[27]](#cite_note-27)\n\n## 人工智能的诞生：1943 - 1956\n\n[[28]](#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n### 控制论与早期神经网络\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/250px-BRL61-IBM_702.jpg)\n\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](/wiki/%E8%AF%BA%E4%BC%AF%E7%89%B9%C2%B7%E7%BB%B4%E7%BA%B3 "诺伯特·维纳")的[控制论](/wiki/%E6%8E%A7%E5%88%B6%E8%AE%BA "控制论")描述了电子网络的控制和稳定性。[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")提出的[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")则描述了[数字信号](/wiki/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7 "数字信号")（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29]](#cite_note-29)\n\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30]](#cite_note-30)\n\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")”的学者。[[31]](#cite_note-31)[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](/w/index.php?title=SNARC&action=edit&redlink=1 "SNARC（页面不存在）")。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n### 游戏AI\n\n1951年，[克里斯托弗·斯特雷奇](/wiki/%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%BC%97%C2%B7%E6%96%AF%E7%89%B9%E9%9B%B7%E5%A5%87 "克里斯托弗·斯特雷奇")使用[曼彻斯特大学](/wiki/%E6%9B%BC%E5%BD%BB%E6%96%AF%E7%89%B9%E5%A4%A7%E5%AD%A6 "曼彻斯特大学")的Ferranti Mark 1机器写出了一个[西洋跳棋](/wiki/%E8%A5%BF%E6%B4%8B%E8%B7%B3%E6%A3%8B "西洋跳棋")（checkers）程序；[迪特里希·普林茨](/w/index.php?title=%E8%BF%AA%E7%89%B9%E9%87%8C%E5%B8%8C%C2%B7%E6%99%AE%E6%9E%97%E8%8C%A8&action=edit&redlink=1 "迪特里希·普林茨（页面不存在）")（Dietrich Prinz）则写出了一个[国际象棋](/wiki/%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B "国际象棋")程序。[[32]](#cite_note-32)[亚瑟·李·塞谬尔](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E6%9D%8E%C2%B7%E5%A1%9E%E8%AC%AC%E7%88%BE "亚瑟·李·塞谬尔")（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33]](#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。\n\n### 图灵测试\n\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34]](#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试")：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35]](#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。\n\n### 符号推理与“逻辑理论家”程序\n\n50年代中期，随着数位计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36]](#cite_note-36)\n\n1955年，[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和后来荣获诺贝尔奖的[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")在J. C. Shaw的协助下开发了“[逻辑理论家](/wiki/%E9%80%BB%E8%BE%91%E7%90%86%E8%AE%BA%E5%AE%B6 "逻辑理论家")（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37]](#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](/wiki/%E5%BF%83%E8%BA%AB%E4%BA%8C%E5%88%86%E6%B3%95 "心身二分法")，解释了物质构成的系统如何获得心灵的性质。”[[38]](#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92 "约翰·罗杰斯·希尔勒")称为“强人工智能”，即机器可以像人一样具有思想。）[[39]](#cite_note-39)\n\n### 1956年达特茅斯会议：AI的诞生\n\n1956年[达特矛斯会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")[[40]](#cite_note-40)的组织者是[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")，[约翰·麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")和另两位资深科学家[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](/wiki/IBM "IBM")。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41]](#cite_note-41)与会者包括[雷·索罗门诺夫](/w/index.php?title=%E9%9B%B7%C2%B7%E7%B4%A2%E7%BE%85%E9%96%80%E8%AB%BE%E5%A4%AB&action=edit&redlink=1 "雷·索罗门诺夫（页面不存在）")（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42]](#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")则说服与会者接受“人工智能”一词作为本领域的名称。[[43]](#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44]](#cite_note-44)\n\n## 第一波浪潮 - 黄金年代：1956 - 1974\n\n[达特矛斯](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45]](#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46]](#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47]](#cite_note-47) [DARPA](/wiki/DARPA "DARPA")（[国防高等研究计划署](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")）等政府机构向这一新兴领域投入了大笔资金。[[48]](#cite_note-48)\n\n### 研究工作\n\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n#### 搜索式推理\n\n许多AI程序使用相同的基本[算法](/wiki/%E7%AE%97%E6%B3%95 "算法")。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95 "回溯法")。这就是“搜索式推理”。[[49]](#cite_note-49)\n\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95 "启发式算法")去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50]](#cite_note-50)\n\n艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](/wiki/%E4%B8%80%E8%88%AC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%99%A8 "一般问题解决器")（General Problem Solver）”程序，将这一算法推广到一般情形。[[51]](#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52]](#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](/wiki/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6 "斯坦福大学")为控制机器人Shakey而开发的STRIPS系统。[[53]](#cite_note-53)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)\n\n#### 自然语言\n\nAI研究的一个重要目标是使计算机能够通过[自然语言](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理")（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54]](#cite_note-54)\n\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](/wiki/%E8%AF%AD%E4%B9%89%E7%BD%91 "语义网")（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55]](#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56]](#cite_note-56)\n\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57]](#cite_note-57)\n\n#### 微世界\n\n60年代后期，[麻省理工大学](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")AI实验室的马文·闵斯基和[西摩尔·派普特](/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9 "西摩尔·派普特")建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58]](#cite_note-58)\n\n在这一指导思想下，[杰拉德·杰伊·萨斯曼](/wiki/%E5%82%91%E6%8B%89%E5%BE%B7%C2%B7%E5%82%91%E4%BC%8A%C2%B7%E8%96%A9%E6%96%AF%E6%9B%BC "杰拉德·杰伊·萨斯曼")（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](/w/index.php?title=%E5%A4%A7%E8%A1%9B%C2%B7%E7%93%A6%E7%88%BE%E8%8C%B2&action=edit&redlink=1 "大卫·瓦尔兹（页面不存在）")（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](/wiki/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89 "机器视觉")领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](/wiki/SHRDLU "SHRDLU")，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59]](#cite_note-59)\n\n### 乐观思潮\n\n第一代AI研究者们曾作出了如下预言:\n\n### 经费\n\n1963年6月，[MIT](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64]](#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](/wiki/%E5%8D%A1%E5%86%85%E5%9F%BA%E6%A2%85%E9%9A%86%E5%A4%A7%E5%AD%A6 "卡内基梅隆大学")的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65]](#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](/wiki/%E7%88%B1%E4%B8%81%E5%A0%A1%E5%A4%A7%E5%AD%A6 "爱丁堡大学")建立。[[66]](#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67]](#cite_note-67)\n\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68]](#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](/wiki/Hacker "Hacker")文化的形成，[[69]](#cite_note-69)但是好景不长。\n\n## 第一次AI低谷：1974 - 1980\n\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70]](#cite_note-70)同时，由于马文·闵斯基对[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")的激烈批评，[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")（即[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")）销声匿迹了十年。[[71]](#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](/wiki/%E9%80%BB%E8%BE%91%E7%BC%96%E7%A8%8B "逻辑编程")，常识推理等一些领域还是有所进展。[[72]](#cite_note-72)\n\n### 问题\n\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73]](#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74]](#cite_note-74)\n\n### 停止拨款\n\n由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81]](#cite_note-81)1973年[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82]](#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83]](#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84]](#cite_note-84)到了1974年已经很难再找到对AI项目的资助。\n\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85]](#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86]](#cite_note-86)\n\n### 来自大学的批评\n\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")已经证明[形式系统](/wiki/%E5%BD%A2%E5%BC%8F%E7%B3%BB%E7%BB%9F "形式系统")（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87]](#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88]](#cite_note-88)[[89]](#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间")”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](/wiki/%E6%84%8F%E5%90%91%E6%80%A7 "意向性")（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90]](#cite_note-90)\n\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](/wiki/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7 "计算复杂性")和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91]](#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92]](#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93]](#cite_note-93)\n\n约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94]](#cite_note-94)\n\n### 感知器与联结主义遭到冷落\n\n[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")是[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71]](#cite_note-Perceptrons-71)\n\n### “简约派（the neats）”：逻辑，Prolog语言和专家系统\n\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95]](#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96]](#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](/wiki/Prolog "Prolog")。[[97]](#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](/w/index.php?title=%E7%94%9F%E7%94%A2%E8%A6%8F%E5%89%87&action=edit&redlink=1 "生产规则（页面不存在）")（英语：[Production\\_system\\_(computer\\_science)](https://en.wikipedia.org/wiki/Production_system_(computer_science) "en:Production system (computer science)")）”密切相关的“[霍恩子句](/wiki/%E9%9C%8D%E6%81%A9%E5%AD%90%E5%8F%A5 "霍恩子句")”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](/wiki/%E6%84%9B%E5%BE%B7%E8%8F%AF%C2%B7%E8%B2%BB%E6%A0%B9%E9%AE%91%E5%A7%86 "爱德华·费根鲍姆")的[专家系统](/wiki/%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1 "专家系统")以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")及[认知统一理论](/wiki/%E8%AA%8D%E7%9F%A5%E7%B5%B1%E4%B8%80%E7%90%86%E8%AB%96 "认知统一理论")。[[98]](#cite_note-98)\n\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](/wiki/%E9%98%BF%E6%91%A9%E5%8F%B8%C2%B7%E7%89%B9%E6%B2%83%E6%96%AF%E5%9F%BA "阿摩司·特沃斯基")，Daniel Kahneman等人的实验证明了这一点。[[99]](#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100]](#cite_note-100)\n\n### “芜杂派（the scruffies）”：框架和脚本\n\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101]](#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102]](#cite_note-102)\n\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103]](#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n## 第二波浪潮 - 繁荣：1980—1987\n\n在80年代，一类名为“[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n### 专家系统获得赏识\n\n[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104]](#cite_note-104)\n\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105]](#cite_note-105)\n\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106]](#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107]](#cite_note-107)\n\n### 知识革命\n\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108]](#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109]](#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110]](#cite_note-110)\n\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111]](#cite_note-111)\n\n### 重获拨款：第五代工程\n\n1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](/wiki/%E7%AC%AC%E4%BA%94%E4%BB%A3%E9%9B%BB%E8%85%A6 "第五代电脑")项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112]](#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](/wiki/Prolog "Prolog")作为该项目的主要编程语言。[[113]](#cite_note-113)\n\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114]](#cite_note-114)[[115]](#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116]](#cite_note-116)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/250px-Hopfield-net.png)\n\n### 联结主义的重生\n\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 "反向传播算法")，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115]](#cite_note-Norvig_25-115)[[117]](#cite_note-117)\n\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86 "分布式并行处理")”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115]](#cite_note-Norvig_25-115)[[118]](#cite_note-118)\n\n## 第二次AI低谷：1987—1993\n\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n### 人工智慧的低谷\n\n“[AI之冬](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119]](#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120]](#cite_note-120)\n\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")）））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121]](#cite_note-121)\n\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122]](#cite_note-122)\n\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123]](#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123]](#cite_note-FifthGenEnd-123)\n\n### 躯体的重要性：Nouvelle AI与嵌入式推理\n\n80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124]](#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](/wiki/%E8%8E%AB%E6%8B%89%E7%B6%AD%E5%85%8B%E6%82%96%E8%AB%96 "莫拉维克悖论")）。[[125]](#cite_note-125)他们号召“[自底向上](/wiki/%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%92%8C%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%A8%AD%E8%A8%88 "自上而下和自下而上设计")”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。\n\n另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126]](#cite_note-126)\n\n在发表于1990年的论文“大象不玩象棋（Elephants Don\'t Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](/wiki/%E7%89%A9%E7%90%86%E7%AC%A6%E8%99%9F%E7%B3%BB%E7%B5%B1 "物理符号系统")”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127]](#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](/wiki/%E9%AB%94%E5%8C%96%E8%AA%8D%E7%9F%A5 "体化认知")（embodied mind/reason/cognition）”论题。[[128]](#cite_note-128)\n\n## 第三波浪潮 - 大数据与机器学习：1993—2019\n\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129]](#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。\n\n### 里程碑和摩尔定律\n\n1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](/wiki/%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BE%85%E5%A4%AB "卡斯帕罗夫")的第一个计算机系统。[[130]](#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131]](#cite_note-131)2009年，[蓝脑计画](/wiki/%E8%97%8D%E8%85%A6%E8%A8%88%E7%95%AB "蓝脑计画")声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](/w/index.php?title=IBM_%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%A8%8B%E5%BA%8F)&action=edit&redlink=1 "IBM 沃森 (人工智慧程序)（页面不存在）")参加《[危险边缘](/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98 "危险边缘")》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](/wiki/AlphaGo "AlphaGo")击败[李世乭](/wiki/%E6%9D%8E%E4%B8%96%E4%B9%AD "李世乭")，成为第一个不让子而击败职业[围棋](/wiki/%E5%9C%8D%E6%A3%8B "围棋")棋士的[电脑围棋](/wiki/%E7%94%B5%E8%84%91%E5%9B%B4%E6%A3%8B "电脑围棋")程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](/wiki/%E4%B8%AD%E5%9B%BD%E4%B9%8C%E9%95%87%E5%9B%B4%E6%A3%8B%E5%B3%B0%E4%BC%9A "中国乌镇围棋峰会")的三局比赛中击败[[132]](#cite_note-wuzhensecond-132)当时世界排名第一[[133]](#cite_note-133)[[134]](#cite_note-134)的中国棋手[柯洁](/wiki/%E6%9F%AF%E6%B4%81 "柯洁")。\n\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135]](#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136]](#cite_note-136)这种剧烈增长可以用[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n### 智能代理\n\n90年代，被称为“[智能代理](/wiki/%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86 "智能代理")”的新范式被广泛接受。[[137]](#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138]](#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139]](#cite_note-R27-139)当经济学中的“[理性代理](/wiki/%E7%90%86%E6%80%A7%E4%B8%BB%E4%BD%93 "理性主体")（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140]](#cite_note-140)\n\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](/w/index.php?title=%E4%BB%A3%E7%90%86%E6%9E%B6%E6%9E%84&action=edit&redlink=1 "代理架构（页面不存在）")（英语：[Agent\\_architecture](https://en.wikipedia.org/wiki/Agent_architecture "en:Agent architecture")）（像Newell的[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139]](#cite_note-R27-139)[[141]](#cite_note-141)\n\n### “简约派”的胜利\n\n越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142]](#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143]](#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144]](#cite_note-RN25-144)[[145]](#cite_note-145)\n\nJudea Pearl发表于1988年的名著[[146]](#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C "贝叶斯网络")，[隐马尔可夫模型](/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B "隐马尔可夫模型")，[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144]](#cite_note-RN25-144)\n\n### 幕后的AI\n\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147]](#cite_note-147)这些解决方案在产业界起到了重要作用。[[148]](#cite_note-148)应用了AI技术的有[数据挖掘](/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98 "数据挖掘")，[工业机器人](/wiki/%E5%B7%A5%E4%B8%9A%E6%9C%BA%E5%99%A8%E4%BA%BA "工业机器人")，[物流](/wiki/%E7%89%A9%E6%B5%81 "物流")[[149]](#cite_note-149)，[语音识别](/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB "语音识别")[[150]](#cite_note-150)，银行业软件[[151]](#cite_note-CNN7242006-151)，医疗诊断[[151]](#cite_note-CNN7242006-151)和[Google](/wiki/Google "Google")搜索引擎等。[[152]](#cite_note-152)\n\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153]](#cite_note-153)[尼克·博斯特罗姆](/wiki/%E5%B0%BC%E5%85%8B%C2%B7%E5%8D%9A%E6%96%AF%E7%89%B9%E7%BD%97%E5%A7%86 "尼克·博斯特罗姆")解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154]](#cite_note-154)\n\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](/wiki/%E4%BF%A1%E6%81%AF%E5%AD%A6 "信息学")，[知识系统](/w/index.php?title=%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "知识系统（页面不存在）")，[认知系统](/w/index.php?title=%E8%AE%A4%E7%9F%A5%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "认知系统（页面不存在）")或[计算智能](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD&action=edit&redlink=1 "计算智能（页面不存在）")。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155]](#cite_note-155)[[156]](#cite_note-156)[[157]](#cite_note-157)\n\n### HAL 9000在哪里?\n\n1968年[亚瑟·克拉克](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E5%85%8B%E6%8B%89%E5%85%8B "亚瑟·克拉克")和[史丹利·库柏力克](/wiki/%E5%8F%B2%E4%B8%B9%E5%88%A9%C2%B7%E5%BA%AB%E6%9F%8F%E5%8A%9B%E5%85%8B "史丹利·库柏力克")创作的《“[2001太空漫游](/wiki/2001%E5%A4%AA%E7%A9%BA%E6%BC%AB%E6%B8%B8 "2001太空漫游")”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158]](#cite_note-158)\n\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159]](#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")））。[[160]](#cite_note-160)[雷蒙德·库茨魏尔](/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94 "雷蒙德·库茨魏尔")相信问题在于计算机性能，根据[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")，他预测具有人类智能水平的机器将在2029年出现。[[161]](#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162]](#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n### 深度学习，大数据和通用人工智能：2011至2019\n\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n#### 深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](/wiki/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86 "MNIST数据集")（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n#### 大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n## 第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n### 大型语言模型\n\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](/wiki/ChatGPT "ChatGPT")基于[GPT-3.5](/wiki/GPT-3 "GPT-3")架构的[大型语言模型](/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B "大型语言模型")并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，[GPT-4](/wiki/GPT-4 "GPT-4")正式推出，进一步加强大型语言模型的推理能力。2023年8月，中国百度公司向公众开放使用[文心一言](/wiki/%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80 "文心一言")，让中国内地民众都可以使用内地版的大型语言模型。2025年1月，[深度求索](/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2 "深度求索")推出著名的[DeepSeek-R1](/wiki/DeepSeek-R1 "DeepSeek-R1") [开源](/wiki/%E9%96%8B%E6%BA%90 "开源")大型语言模型，并使用新的算法减低训练成本。\n\n### 机器人整合与人工智能的实际应用（2025年至今）\n\n先进的人工智能（AI）系统能够高精度理解和回应人类对话，已成熟到能够与机器人无缝整合，改变了制造业、医疗保健、公共服务和材料研究等行业。[[163]](#cite_note-163) 人工智能还通过高级数据分析和假设生成加速科学研究。[[164]](#cite_note-164) 包括中国、美国和日本在内的国家在政策和资金方面进行了大量投资，以部署人工智能驱动的机器人和人工智能的实际应用，解决劳动力短缺问题，促进创新并提高效率，同时实施监管框架以确保道德和安全发展。[[165]](#cite_note-165)\n\n#### 中国\n\n2025年被誉为“人工智能机器人年”，标志著人工智能（AI）与机器人无缝整合的关键时刻。在2025年，中国投资约7300亿元人民币（约1000亿美元）用于智能制造和医疗保健领域的人工智能和机器人技术发展。[[166]](#cite_note-166) [[167]](#cite_note-167) 第十四个五年规划（2021-2025年）优先发展服务机器人，人工智能系统使机器人能够执行复杂任务，例如协助手术或自动化工厂装配线。[[168]](#cite_note-168) 例如，中国医院中的人工智能人形机器人可以解读患者请求、运送物资并协助护士完成日常任务，显示现有的人工智能对话能力足以应用于实际的机器人应用。部分资金还支持国防应用，例如自主无人机。[[169]](#cite_note-169)[[170]](#cite_note-170) 自2025年9月起，中国要求对人工智能生成的内容进行标记，以确保技术的透明度和公众信任。[[171]](#cite_note-171)\n\n#### 美国\n\n2025年1月，人工智能基础设施投资取得重大进展，[星际之门计划](/wiki/%E6%98%9F%E9%99%85%E4%B9%8B%E9%97%A8%E8%AE%A1%E5%88%92 "星际之门计划") 成立。这家由 [OpenAI](/wiki/OpenAI "OpenAI")、[SoftBank Group](/wiki/SoftBank_Group "SoftBank Group")、[Oracle](/wiki/Oracle_Corporation "Oracle Corporation") 和 [MGX](/w/index.php?title=MGX_Fund_Management_Limited&action=edit&redlink=1 "MGX Fund Management Limited（页面不存在）") 组成的合资企业宣布计划到2029年在[美国](/wiki/%E7%BE%8E%E5%9C%8B "美国")投资5000亿美元用于人工智能基础设施，首期投资1000亿美元，以支持美国的再工业化并提供保护美国及其盟友国家安全的战略能力。[[172]](#cite_note-172) 该合资企业于2025年1月21日由美国总统唐纳德·特朗普正式宣布，SoftBank Group首席执行官 [孙正义](/wiki/%E5%AD%AB%E6%AD%A3%E7%BE%A9 "孙正义") 被任命为主席。[[173]](#cite_note-reuters-173)[[174]](#cite_note-174)\n\n美国政府拨款约20亿美元用于在制造业和物流业中整合人工智能和机器人技术，利用人工智能处理自然语言和执行用户指令的能力。[[175]](#cite_note-175) 各州政府补充资金支持服务机器人，例如部署在仓库中执行口头指令进行库存管理，或在养老院中回应居民的援助请求。[[176]](#cite_note-176) 这些应用表明，将已经熟练于人类交互的高级人工智能与机器人硬体结合是一项实际的前进步骤。\n\n2025年1月，第14179号行政命令确立了“人工智能行动计划”，以加速这些技术的创新和部署。[[177]](#cite_note-177)\n\n#### 影响\n\n2020年代各国政府和机构对AI的投资加速了人工智能的发展，推动了科学进步，提高了劳动效率，并通过自动化复杂任务改变了各行业。[[178]](#cite_note-178) 通过将成熟的人工智能系统整合到各行业的应用当中，这些发展有望彻底改变智能制造和服务行业，重塑人类的日常生活。\n\n## 注释\n\n## 参考文献\n\n`|date=`\n`|date=`\n`|date=`\n\n.\n\n![](https://zh.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&type=1x1&usesul3=1)\n![Wikimedia Foundation](/static/images/footer/wikimedia.svg)\n![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99847525, 'save_path': None}}, {'paper_id': '', 'title': '一文概览人工智能(AI)发展历程 - 知乎专栏', 'authors': [], 'abstract': None, 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/375549477', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99828595, 'save_path': None}}, {'paper_id': '', 'title': '人工智能简史— 深入浅出PyTorch', 'authors': [], 'abstract': 'Theme by the [Executable Book Project](https://ebp.jupyterbook.org)\n\n* [repository](https://github.com/datawhalechina/thorough-pytorch "Source repository")\n* [open issue](https://github.com/datawhalechina/thorough-pytorch/issues/new?title=Issue%20on%20page%20%2F第零章/0.1 人工智能简史.html&body=Your%20issue%20content%20here. "Open an issue")\n* [suggest edit](https://github.com/datawhalechina/thorough-pytorch/edit/master/第零章/0.1 人工智能简史.md "Edit this page")\n\n* [.md](../_sources/第零章/0.1 人工智能简史.md.txt "Download source file")\n\nContents\n\n# 人工智能简史\n\n## Contents\n\n# 人工智能简史[#](#id1 "永久链接至标题")\n\n自从图灵在1950年第一次提出“机器智能（Machine Intelligence）”这个概念以来，人工智能已经经历了七十余年的发展。在这七十多年中，人工智能的发展先后经历了三次浪潮，每一次浪潮对人工智能的发展来说，都是具有里程碑意义的。接下来我们将以这三次浪潮为主线，为大家介绍人工智能的发展历程。除此之外，我们也将会给大家介绍现在常说的Deep learning，Machine Learning和AI之间的关系。\n\n[\\* ]通过本章学习，你将收获：\n\n* 了解人工智能的三次浪潮\n* 了解Deep learning，Machine learning和AI之间的关系\n\n## 1.1 人工智能的三次浪潮[#](#id2 "永久链接至标题")\n\n### 1.1.1 第一次浪潮[#](#id3 "永久链接至标题")\n\n1950年，阿兰·图灵发表著名论文《计算机器与智能》，在这篇论文中，他提出了机器思维的概念和图灵测试，标志着“机器的智能化”正式进入人类的科技树。在此之后的数年间，机器智能有了进一步的发展。两年后的1952年，计算机科学家阿瑟·萨缪尔开发出一款跳棋程序，并提出了“机器学习”这个概念。在此之后的4年里，机器智能化也取得了一定的进步，直到1956年的达特茅斯会议上，约翰·麦卡锡正式提出了“人工智能”这个词语，1956年，也就成为了实际意义上的人工智能元年。\n\n达特茅斯会议之后，人工智能进入了一个高速发展的时期，也就是所谓的“第一次浪潮”。这次浪潮一直持续到二十世纪六十年代中期。在这近10年的时间里，计算机本身的“智能”并没有得到发展，快速进步的是人工智能的一些理论与算法方面。很多对后来人工智能发展起到奠基作用的算法——如罗森布拉特在1957年发明感知机——就是在这个时间段诞生的。感知机是机器学习人工神经网络理论中神经元的最早模型，这一模型也使得人工神经网络理论得到了巨大的突破。除此之外，强化学习的雏形也是在那段时间提出的。彼时的科学界都弥漫着快乐的气氛，大家都认为，只要坚持走下去，人工智能就一定会得到跨越式的发展。但事与愿违，不久后人工智能的第一次寒冬（AI Winter）就到来了。\n\n1966年前后，AI遭遇了瓶颈。人们发现逻辑证明器、感知器、强化学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。研究者们很快就意识到，要求程序对这个世界具有儿童水平的认识这个要求都太高了——那时没人能够做出人工智能需要的巨大数据库，也没人知道一个程序怎样才能学到如此丰富的信息。另一方面，有很多计算复杂度以指数程度增加，这成为了不可能完成的计算任务。\n\n可以说，人工智能的第一次浪潮在发展到“非智能对话机器”的智能化初级阶段时，就因为当时的技术限制不得不停摆。人工智能的发展似乎陷入了一个无解的“死胡同”里，并被计算机科学家们逐渐冷落。\n\n### 1.1.2 第二次浪潮[#](#id4 "永久链接至标题")\n\n时间来到了20世纪80年代。经过了数十年的研究，科学家们逐渐放弃了初代的符号学派思路，改用统计学的思路来研究人工智能。研究思路的改变再加上硬件技术的升级，人工智能的发展又一次迎来的新的契机。在那个时代，基于人工智能的“专家系统”受到了绝对的热捧。特定领域的“专家系统”程序被更广泛的采纳，该系统能够根据领域内的专业知识，推理出专业问题的答案，人工智能也由此变得更加“实用”，专家系统所依赖的知识库系统和知识工程成为了当时主要的研究方向。\n\n但由于专家系统仅适用于某些特定场景，很快人们就对这一系统由狂热的追捧逐渐走向巨大的失望。与此同时，现代电子计算机的出现让“知识查询”的费用进一步降低，人们更加深刻的意识到专家系统是如此的古老陈旧。因此，政府部门下调了专家系统的研发资金。缺少了资金的支持，由专家系统再次兴起的人工智能研究又一次陷入了低谷之中。\n\n虽然第二次浪潮持续的时间比较短，但它在整个人工智能发展历史中仍然起到了举足轻重的作用。它彻底改变了人工智能研究的大思路，将统计学思想引入研究之中，为人工智能在未来几十年的发展打下了基础。除此之外，在这次浪潮中提出的BP神经网络，为之后机器感知、交互的能力奠定了基础。\n\n### 1.1.3 第三次浪潮[#](#id5 "永久链接至标题")\n\n1993年后，新的数学工具，理论和摩尔定律的出现，使得计算机的算力进一步提高，以深度学习为核心的机器学习算法获得发展，新的芯片和云计算的发展使得可用的计算能力获得飞跃式提高，大数据的发展使得海量数据的储存和分析成为可能。在这样的技术背景下，人工智能的第三次浪潮即将到来。\n\n人工智能的第三次浪潮有两个重要的时间节点：2006年和2016年。2006年是深度学习发展史的分水岭。杰弗里辛顿在这一年发表了《一种深度置信网络的快速学习算法》，其他重要的深度学习学术文章也在这一年被发布，在基本理论层面取得了若干重大突破。而2016年3月，谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭，“人工智能”一词正式进入普通民众的视野并被逐渐熟知。至此，人工智能正式迈向了从“科研领域的应用型工具”到“实用性，功能性工具”的转变，人工智能有了新的研究方向和研究模式，即从过去的学术主导型研究逐渐走向了商业主导型研究。随着人类社会对智能化工具的不断追求和探索，人工智能的发展迎来了全新的时代。\n\n### 1.1.4 总结[#](#id6 "永久链接至标题")\n\n上图是对人工智能发展中经历的三次浪潮和两次寒冬的形象总结。除此之外，有观点认为，深度学习算法带来的“技术红利”，将支撑我们再发展5~10年时间，随后就会遇到瓶颈。人工智能不是一个简单的从1到100进步的过程，它往往趋向于两个极端：要么90分以上，其它的都是10分以下。目前，人工智能急需寻找到一个“技术奇点”，让人工智能迅速发展到通用人工智能甚至是超级人工智能的水平。否则，在人工智能研究商业化的今天，无法从中获利的投资人们将快速撤资退场，人工智能或将进入下一个寒冬。\n\n## 1.2 DL,ML,AI三者之间的关系[#](#dl-ml-ai "永久链接至标题")\n\n大家对“人工智能”这个词，也就是我们所谓的“AI”（Artificial Intelligence）想必是非常熟悉，无论是近几年各行各业都喜欢用作营销噱头的“智能化”还是早期电影如《黑客帝国》、《终结者》等，都让AI这个概念深入人心。但近几年，另外两个词语也在逐步进入我们的生活，即就是“机器学习（Machine Learning，ML）”和“深度学习（Deep Learning，DL）”。在接下来的叙述中，我们就将了解DL和ML究竟是什么，以及它们和AI之间的关系。\n\n### 1.2.1 DL和ML是什么[#](#dlml "永久链接至标题")\n\nMachine Learning（机器学习）。它在1959年被机器学习的先驱者之一的阿瑟·塞缪尔定义为：一门研究领域，它赋予计算机无需明确编程就能学习的能力。也就是说，机器学习程序不同于传统编程那样，使用if-then语句那样明确地输入到计算机中以便它根据条件执行。在某种意义上，机器学习程序赋予机器根据所接触到的数据进行自我调整的能力。机器学习更像是一种优化算法，如果我们在事先就对它进行了正确的调整，那么它就会在一遍又一遍的尝试和猜测之中不断减少它的错误，以无限逼近于最终的正确结果。而机器学习的基本思路，也就是将现实问题抽象成为一个数学问题，机器通过训练，寻找到解决数学问题的方法，进而解决现实问题。\n\nDeep Learning（深度学习）。它在2006年被提出，并在近些年得到了迅速的发展。它通过建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据。李开复教授在《人工智能》一书中这样解释深度学习：“假设深度学习要处理的信息是“水流”，而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。网络的入口是若干管道开口，网络的出口也是若干管道开口。这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节阀的总数可以成千上万甚至更多。水管网络中，每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来，组成一个从前到后，逐层完全连通的水流系统。”\n\n### 1.2.2 它们和AI的关系[#](#ai "永久链接至标题")\n\n众所周知，人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。既然如此，那么计算器算是人工智能吗？严格地说是算的，因为它至少做了“模拟”人在计算方面的智能，并扩展了这个能力（比人算得更快）。我们通过代码驱动计算机去帮我们干活，这个算是人工智能吗？也算的。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，说白了，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。\n\n随着人对计算机的期望越来越高，要求它解决的问题越来越复杂，仅仅算的更快，看的更准已经远远不能满足人们的诉求了。要解决的问题域越来越复杂，即使是同一个问题，其面对的场景也越来越多。传统的思路就是查找问题的条件和解决方法，在计算机程序中再加入一个if-then。但这只是治标不治本。随着我们期待解决的问题越来越多，计算机程序将越来越复杂，越来越难以维护。那怎么办呢？于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n\n至此，“机器学习”的概念，正式诞生。机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器自行学会如何执行任务。说白了，机器学习只是人们实现让机器“模拟、延伸和扩展人的智能”的一种较为轻松的方法罢了。它的成功与否取决于我们喂给机器的数据集是否准确且有效。因此，机器学习是大数据技术领域内的一个应用，人们只是借用这个应用，来发展人工智能罢了。机器学习发展了几十年之后，再次遇到了瓶颈期。随着问题场景的更加复杂多变，需要进行判断的条件更加苛刻，人们不得不重新思考一种方式来优化机器学习。深度学习就是带着这个目的被提出的。\n\n机器学习中有一个概念叫“神经网络”，深度学习正是通过优化这个网络来更好的解决通过机器学习难以解决的问题。它的基本特点，就是试图模仿大脑的神经元之间传递，处理信息的模式，通过不同的“层”来拆分问题，每一层解决问题的一个部分。比如在利用深度学习解决智能驾驶问题中，第一层可能用于识别车辆与道路边缘的距离，第二层用于识别道路标线，第三层用于识别路上的其他车辆等等。\n\n通过以上几段话的简单描述，DL,ML和AI之间的关系也就明确了。它们三者的关系就像是俄罗斯套娃：AI最大，它的目的是通过让机器模仿人类进而超越人类；ML次之，它是AI的一个分支（也是最重要分支），是让机器模仿人类的一种方法；DL更次之，它是ML的一个分支，它的目的是让机器不借助人工标注，也能自主提取目标特征进而解决问题的一种方法。\n\n最后，借用一张经典的关系图作为结尾：\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E9%9B%B6%E7%AB%A0/0.1%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99711037, 'save_path': None}}, {'paper_id': '', 'title': 'AI 简史：从神经元到现代大模型 - CSDN博客', 'authors': [], 'abstract': '* [博客](https://blog.csdn.net/)\n* [下载](https://download.csdn.net/)\n* [社区](https://devpress.csdn.net/)\n* [GitCode](https://link.csdn.net?target=https%3A%2F%2Fgitcode.com%3Futm_source%3Dcsdn_toolbar)\n* [GPU算力](https://ai.csdn.net/)\n* 更多\n\n  [会议](https://www.bagevent.com/event/9117243 "会议")[学习](https://edu.csdn.net?utm_source=zhuzhantoolbar "高质量课程·大会云会员")[InsCode](https://inscode.net?utm_source=csdn_blog_top_bar "InsCode")\n\nAI 搜索\n\n# AI 简史：从神经元到现代大模型\n\n原创\n已于\xa02024-12-25 16:28:52\xa0修改\n·\n1.8w 阅读\n\n·\n\n49\n\n·\n89\n·\n\nCC 4.0 BY-SA版权\n\n版权声明：本文为博主原创文章，遵循 [CC 4.0 BY-NC-SA](http://creativecommons.org/licenses/by-nc-sa/4.0/) 版权协议，转载请附上原文出处链接和本声明。\n\n文章标签：\n\n[#深度学习](https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#人工智能](https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#ai](https://so.csdn.net/so/search/s.do?q=ai&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#神经网络](https://so.csdn.net/so/search/s.do?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#transformer](https://so.csdn.net/so/search/s.do?q=transformer&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#卷积神经网络](https://so.csdn.net/so/search/s.do?q=%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n[#机器学习](https://so.csdn.net/so/search/s.do?q=%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0&t=all&o=vip&s=&l=&f=&viparticle=&from_tracking_code=tag_word&from_code=app_blog_art)\n\n于\xa02024-12-25 10:54:28\xa0首次发布\n\n[2048 AI社区 文章已被社区收录](javascript:; "2048 AI社区")\n\n[生成AI\n专栏收录该内容](https://blog.csdn.net/jarodyv/category_12199878.html "生成AI")\n\n45 篇文章\n\n该文章已生成可运行项目，\n\n## AI 简史：从神经元到现代大模型\n\n人工智能 (AI) 和深度学习 (DL) 在过去的几十年中飞速发展，推动了[计算机视觉](https://so.csdn.net/so/search?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&spm=1001.2101.3001.7020)、自然语言处理和机器人等领域的进步。今年的诺贝尔物理学奖更是颁给了美国科学家约翰·霍普菲尔德 (John Hopfield）和英国科学家杰弗里·辛顿（Geoffrey Hinton），表彰他们“在人工神经网络机器学习方面的基础性发现和发明”。本文将为大家概述 AI 的发展历程，梳理出从早期神经网络模型到现代大型语言模型发展过程中的重要里程碑。\n\n图 1. AI 发展全景图\n\n#### 文章目录\n\n* + [1. 人工智能诞生 (1956)](#1__1956_10)\n  + [2. AI 的演进：从基于规则的系统到深度神经网络](#2_AI__36)\n  + [3. 早期人工神经网络 (1940s – 1960s)](#3__1940s__1960s_49)\n  + - [3.1 McCulloch-Pitts 神经元 (1943)](#31_McCullochPitts__1943_51)\n    - [3.2 Rosenblatt 感知机模型 (1957)](#32_Rosenblatt__1957_62)\n    - [3.3 ADALINE (1959)](#33_ADALINE_1959_82)\n    - [3.4 异或（XOR）问题 (1969)](#34_XOR_1969_106)\n  + [4. 多层感知机 (1960)](#4__1960_124)\n  + - [4.1 隐藏层 (Hidden Layers)](#41__Hidden_Layers_133)\n    - [4.2 多层感知机的历史背景与挑战](#42__142)\n  + [5. 反向传播 (1970s – 1980s)](#5__1970s__1980s_151)\n  + - [5.1 早期发展 (1970 年代)](#51__1970__166)\n    - [5.2 强化与普及（1980 年代）](#52_1980__171)\n    - [5.3 通用逼近定理 (1989)](#53__1989_182)\n    - [5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)](#54__1980___1990__191)\n    - [5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)](#55__1990___2000__200)\n    - [深度学习的复兴 (2000 年代末 – 现在)](#_2000____215)\n  + [6. 卷积神经网络 (1980s – 2010s)](#6__1980s__2010s_226)\n  + - [6.1 早期发展 (1980 – 1998)](#61__1980__1998_242)\n    - [6.2 CNN 的崛起：AlexNet (2012)](#62_CNN_AlexNet_2012_258)\n    - [6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）](#63_AlexNet_2010__280)\n    - [6.4 后续架构改进](#64__289)\n    - [6.5 CNN 的应用](#65_CNN__314)\n  + [7. 循环神经网络 (1986 – 2017)](#7__1986__2017_324)\n  + - [7.1 早期发展 (1980s – 1990s)](#71__1980s__1990s_328)\n    - [7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)](#72_LSTM_GRU__Seq2Seq__1997__2014_344)\n    - [7.3 RNN 的应用](#73_RNN__362)\n    - [7.4 RNN 的挑战](#74_RNN__370)\n  + [8. Transformer (2017 – 现在)](#8_Transformer_2017___380)\n  + - [8.1 Transformer 简介](#81_Transformer__384)\n    - [8.2 Transformer 的衍生模型](#82_Transformer__405)\n    - [8.3 OpenAI GPT 的发展历程](#83_OpenAI_GPT__423)\n    - [8.4 其他知名大语言模型](#84__439)\n  + [9. 多模态模型 (2023 – 现在)](#9__2023___457)\n  + - [9.1 GPT-4V (2023) 和 GPT-4o (2024)](#91_GPT4V_2023__GPT4o_2024_459)\n    - [9.2 Google’s Gemini (2023 – 现在)](#92_Googles_Gemini_2023___465)\n    - [9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)](#93_Claude_30__Claude_35_2023___471)\n    - [9.4 LLaVA (2023)](#94_LLaVA_2023_477)\n  + [10. 扩散模型 (2015 – 现在)](#10__2015___488)\n  + - [10.1 扩散模型简介 (2015)](#101__2015_492)\n    - [10.2 扩散模型的发展 (2020 – 现在)](#102__2020___509)\n    - [10.3 文生图模型](#103__523)\n    - [10.4 文生视频模型](#104__533)\n  + [11. 尾声](#11__566)\n\n### 1. 人工智能诞生 (1956)\n\n人工智能（AI）的概念由来已久，但现代 AI 的雏形是在 20 世纪中期逐渐形成的。“人工智能”这个术语是由计算机科学家和认知科学家约翰·麦卡锡 (John McCarthy) 在 1956 年召开的达特茅斯人工智能夏季研讨项目上首次提出并被大家接受，AI 从此走上历史舞台。\n\n图 2.\n[A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence](http://www-formal.stanford.edu/jmc/history/dartmouth.pdf) (1955)\n\n达特茅斯会议通常被视为 AI 研究的发源地。这次会议汇聚了计算机科学家、数学家和认知科学家，共同探讨创造能够模拟人类智能的机器的可能性。与会者中大佬云集，包括：\n\n* **约翰·麦卡锡 (John McCarthy)** ：计算机科学家、Lisp 编程语言发明人之一。\n* **马文·明斯基 (Marvin Minsky)**：计算机科学家、框架理论的创立者。\n* **雷·索洛莫诺夫 (Ray Solomonoff)**：算法概率论创始人，通用概率分布之父，通用归纳推理理论的创建者。\n* **纳撒尼尔·罗切斯特 (Nathaniel Rochester)** ：IBM 701 的首席设计师，编写了世界上第一个汇编程序。\n* **克劳德·香农 (Claude Shannon)** ：数学家、发明家、密码学家，信息论创始人。\n* **奥利弗·塞弗里奇 (Oliver Selfridge)**：模式识别的奠基人、人工智能的先驱，被誉为“机器知觉之父”。\n\n图 3. 参加达特茅斯会议的部分重量级人物\n\n### 2. AI 的演进：从基于规则的系统到深度神经网络\n\n纵观整个 AI 的发展史，有一条清晰的发展脉络，那就是从基于规则的系统向深度神经网络的不断进化。\n\n人工智能 (AI) 的发展始于上个世纪 50 年代，那时人们开始开发用于国际象棋和问题求解的算法。第一个 AI 程序 Logical Theorist 于 1956 年诞生。到了 1960 和 1970 年代，基于规则的专家系统如 MYCIN 被引入，它们可以帮助进行复杂的决策。1980 年代，机器学习开始兴起，使 AI 系统能够从数据中学习并不断改进，为现代深度学习技术奠定了基础。\n\n今天，大多数最前沿的 AI 技术都由深度学习驱动，深刻改变了 AI 的发展格局。深度学习是机器学习的一个独立分支，它通过多层人工神经网络从原始数据中提取复杂特征。在本文中，我们将探讨 AI 的发展历史，并重点介绍深度学习在其中的关键作用。\n\n图 4. 人工智能、机器学习、神经网络、深度学习之间的关系\n\n### 3. 早期人工神经网络 (1940s – 1960s)\n\n#### 3.1 McCulloch-Pitts 神经元 (1943)\n\n神经网络的概念可以追溯到 1943 年，当时 Warren McCulloch 和 Walter Pitts 提出了第一个人工神经元模型。McCulloch-Pitts (MP) 神经元模型是对生物神经元的一种突破性简化。这个模型通过聚合二进制输入，并利用阈值激活函数来做出决策，从而为人工神经网络奠定了基础，输出结果为二进制 \n{\n0\n,\n1\n}\n\\{0, 1\\}\n{0,1}。\n\n图 5. 人工神经元的结构与原理\n\n#### 3.2 Rosenblatt 感知机模型 (1957)\n\nFrank Rosenblatt 在 1957 年引入了感知机，这是一种能够学习和识别模式的单层神经网络。感知机模型比 MP 神经元更为通用，设计用于处理实数值输入，并通过调整权重来最小化分类错误。\n\n图 6. 感知机模型\n\nRosenblatt 还为感知机开发了一种监督学习算法，使得网络能够直接从训练数据中进行学习。  \n \nL\n(\nW\n)\n=\n−\n∑\ni\n∈\nM\nW\nT\nX\ni\ny\ni\n\\mathcal{L}(W) = - \\sum\\_{i \\in M} W^T X\\_i y\\_i\nL(W)=−i∈M∑\u200bWTXi\u200byi\u200b\n\n图 7. Mark I 感知机，是一台实现了图像识别感知机算法的机器\n\nRosenblatt 的感知机展示出识别个人和在不同语言间翻译语音的潜力，这在当时引发了公众对 AI 的极大兴趣。感知机模型及其相关的学习算法成为神经网络发展历程中的重要里程碑。然而，很快就显现出一个关键限制：当训练数据是非线性可分时，感知机的学习规则无法收敛。\n\n#### 3.3 ADALINE (1959)\n\nWidrow 和 Hoff 在 1959 年引入了 ADALINE（自适应线性神经元，也称 Delta 学习规则），对感知机学习规则进行了改进。ADALINE 解决了二进制输出和噪声敏感性等限制，并能够学习并收敛非线性可分的数据，这是神经网络发展中的一大突破。\n\n图 8. ADALINE VS. 感知机\n\nADALINE 的主要特点包括：\n\n* **线性激活函数**：不同于感知器的阶跃函数，ADALINE 使用线性激活函数，因此适用于回归任务和连续输出。\n* **最小均方（LMS）算法**：ADALINE 采用 LMS 算法，该算法通过最小化预测输出与实际输出之间的均方误差，提供更高效和稳定的学习过程。\n* **自适应权重**：LMS 算法根据输出误差自适应调整权重，使 ADALINE 即使在有噪声的情况下也能有效地学习和收敛。\n\n**ADALINE 的引入标志着神经网络第一次黄金时代的开始**，它克服了 Rosenblatt 感知机学习的限制。这一突破实现了高效学习、连续输出和对噪声数据的适应能力，推动了该领域的创新和快速发展。\n\n图 9. ADALINE 开启了神经网络第一次黄金时代\n\n然而，与感知机类似，ADALINE 仍然无法解决线性可分的问题，无法应对更复杂的非线性任务。这一局限集中体现在异或（XOR）问题上，也促进了更高级神经网络架构的发展。\n\n#### 3.4 异或（XOR）问题 (1969)\n\n1969年，Marvin Minsky 和 Seymour Papert 在他们的著作《Perceptrons》中揭示了单层感知机的一个重要局限：由于其线性决策边界，感知机无法解决异或 (XOR) 问题，而这是一个简单的二元分类任务。异或问题不是线性可分的，也就是说，没有一个单一的线性边界能够正确地将所有的输入模式分类。\n\n图 10. Marvin Minsky 和 Seymour Papert 合著的《Perceptrons: An introduction to computational geometry》\n\n这一发现强调了需要开发更复杂的神经网络架构，以便能够学习非线性的决策边界。感知机的局限性被揭露后，人们对神经网络的信心减弱，转而研究符号人工智能方法，**这标志着从 20 世纪 70 年代初到 80 年代中期的“神经网络的第一次黑暗时代”的开始**。\n\n图 11. 异或问题将神经网络代入第一次黑暗时代\n\n### 4. 多层感知机 (1960)\n\n多层感知机 (MLP) 最早于 20 世纪 60 年代提出，作为对单层感知机的改进。MLP 由多个层次的相互连接的神经元组成，能够克服单层模型的局限性。苏联科学家 A. G. Ivakhnenko 和 V. Lapa 在感知机基础上进行研究，对多层感知机的发展中做出了重要贡献。\n\n图 12. 多层感知机模型\n\n#### 4.1 隐藏层 (Hidden Layers)\n\n增加隐藏层使得 MLP (多层感知器) 可以捕捉和表达数据中的复杂非线性关系。这些隐藏层极大地增强了网络的学习能力，使其能够解决诸如异或问题这样非线性可分的问题。\n\n图 13. 隐藏层解决异或问题\n\n#### 4.2 多层感知机的历史背景与挑战\n\nMLP 的出现标志着神经网络的研究向前迈出了重大一步，展示了[深度学习架构](https://so.csdn.net/so/search?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9E%B6%E6%9E%84&spm=1001.2101.3001.7020)在解决复杂问题方面的潜力。然而，在 1960 年代和 1970 年代，MLP 的发展面临若干挑战：\n\n* **缺乏训练算法**：早期的 MLP 模型缺乏高效的训练算法，无法有效地调整网络权重。此时反向传播算法还未诞生，训练多层深度网络非常困难。\n* **算力限制**：当时的算力不足以应对训练深度神经网络所需的复杂计算。这一限制拖慢了 MLP 的研究和发展进程。\n\n神经网络的第一个黑暗时代在 1986 年结束，**随着反向传播算法的诞生，开启了神经网络的第二个黄金时代**。\n\n### 5. 反向传播 (1970s – 1980s)\n\n1969 年，异或问题揭示了感知机（单层神经网络）的局限性。研究人员意识到，多层神经网络能够克服这些限制，但缺乏有效的训练算法。17年后，反向传播算法的开发使得神经网络在理论上可以逼近任何函数。值得注意的是，该算法实际上在发表之前就已被发明。如今，反向传播已成为深度学习的核心组件，自 20 世纪 60 年代和70 年代以来经历了显著的发展和完善。\n\n图 14. 反向传播原理示意图\n\n反向传播的关键特性：\n\n* **梯度下降**：反向传播与梯度下降联合使用以降低误差函数。该算法计算每个权重相对于误差的梯度，从而逐步调整权重以减少误差。\n* **链式法则**：反向传播算法的核心在于应用微积分的链式法则。此法则使得误差的梯度可以被分解为一系列偏导数，并通过网络的反向传递高效计算。\n* **分层计算**：反向传播逐层运作，从输出层向输入层反向传递。这种分层计算确保梯度在网络中正确传播，使得深度架构的训练成为可能。\n\n#### 5.1 早期发展 (1970 年代)\n\n* **Seppo Linnainmaa (1970)**: 提出了自动微分的概念，这是反向传播算法的重要组成部分。\n* **Paul Werbos (1974)**: 提议使用微积分的链式法则计算误差函数对网络权重的梯度，从而能够训练多层神经网络。\n\n#### 5.2 强化与普及（1980 年代）\n\n* **David Rumelhart, Geoffrey Hinton 和 Ronald Williams (1986)**: 将**反向传播**这一高效实用的方法，用于训练深度神经网络，并展示了其在多种问题中的应用。\n\n图 15. 反向传播算法的三位主要贡献者\n\n其中 Geoffrey Hinton 因其在人工神经网络和机器学习领域的贡献获得了 2018 年图灵奖和 2024 诺贝尔物理学奖，称为继 Herbert Simon 后第二位图灵奖-诺贝尔奖双料得主。\n\n#### 5.3 通用逼近定理 (1989)\n\nGeorge Cybenko 在 1989 年提出的通用逼近定理，为多层神经网络的功能提供了数学基础。该定理表明，只要神经元数量足够，并且使用非线性激活函数，具有单个隐藏层的前馈神经网络就能够以任意精度逼近任意连续函数。这个定理突显了神经网络的强大能力和灵活性，使其能够应用于各种领域。\n\n图 16. 具有单个隐藏层的神经网络可以将任意连续函数逼近到任意所需的精度，从而在各个领域解决复杂的问题\n\n#### 5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)\n\n\\*\\*反向传播算法的出现和通用逼近定理的提出，开启了神经网络研究的第二个黄金时代。\\*\\*反向传播提供了一种高效的多层神经网络训练方法，使研究人员能够构建更深层次和更复杂的模型。通用逼近定理则为使用多层神经网络提供了理论支持，并增强了人们对其解决复杂问题能力的信心。在 1980 年代末至 1990 年代初，这一时期见证了对神经网络领域的兴趣回升和显著的进步。\n\n图 17. 反向传播和通用逼近定理开启了神经网络研究的第二个黄金时代\n\n#### 5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)\n\n然而，由于一系列因素，神经网络领域在 1990 年代初至 2000 年代初经历了“第二个黑暗时代”：\n\n* **支持向量机 (SVM) 的兴起**：支持向量机为分类和回归任务提供了更优雅的数学方法。\n* **算力限制**：由于训练深度神经网络仍然耗时且对硬件要求高，计算能力受到限制。\n* **过拟合和泛化问题**：这两个问题导致早期神经网络在训练数据上表现良好，但在新数据上表现不佳，限制了其实用性。\n\n这些挑战使得许多研究人员转而关注其他领域，导致神经网络研究的停滞。\n\n图 18. 随着 SVM 的兴起，神经网络进入第二个黑暗时代\n\n#### 深度学习的复兴 (2000 年代末 – 现在)\n\n在 2000 年代末和 2010 年代初，神经网络领域经历了复兴，这得益于以下方面的进步：\n\n* **深度学习架构的发展**（如 CNNs、RNNs、Transformers、Diffusion Models）\n* **硬件的改进**（如 GPUs、TPUs、LPUs）\n* **大规模数据集的可用性**（如 ImageNet、COCO、OpenWebText、WikiText 等）\n* **训练算法的优化**（如 SGD、Adam、dropout）\n\n这些进展带来了计算机视觉、自然语言处理、语音识别和强化学习的重大突破。通用逼近定理与实际技术的进步相结合，为深度学习技术的广泛应用和成功奠定了基础。\n\n### 6. 卷积神经网络 (1980s – 2010s)\n\n卷积神经网络 (CNN) 在深度学习领域，尤其是计算机视觉和图像处理方面，带来了革命性的变化。从上个世纪 80 年代到本世纪最初的 10 年，CNN 在架构、训练技术和应用等方面取得了显著的进步。\n\n卷积神经网络由以下三个主要组件构成：\n\n* **卷积层 (Convolutional Layers)**：这些层通过一组可调整的滤波器，从输入图像中自动学习和提取特征的空间层次结构。\n* **池化层 (Pooling Layers)**：池化层通过缩小输入的空间尺寸，来提高对输入变化的适应性，并减少计算量。\n* **全连接层 (Fully Connected Layers)**：在卷积层和池化层之后，全连接层用于分类任务，负责整合之前层中提取的特征。\n\n卷积神经网络的主要特性\n\n* **局部感受野**：CNN 利用局部感受野来捕捉输入数据中的局部特征，使其在处理图像和其他视觉任务时表现出色。\n* **权重共享**：通过在卷积层中共享权重，CNN 能够减少网络中参数的数量，从而提高训练效率。\n* **平移不变性**：池化层赋予网络平移不变性，使其能够识别输入图像中不同位置的相同模式。\n\n#### 6.1 早期发展 (1980 – 1998)\n\n1980 年代，福岛邦彦 (Kunihiko Fukushima) 首次提出了 CNN 的概念，他设计了一种称为神经认知机 (Neocognitron) 的分层神经网络，这种网络模仿了人类视觉皮层的结构。这项开创性的研究为之后 CNN 的发展奠定了基础。\n\n图 19. 福岛邦彦与他的神经认知机\n\n到了 1980 年代末和 1990 年代初，Yann LeCun 和他的团队在此基础上进一步发展了 CNN，并推出了 LeNet-5 架构，该架构专为手写数字识别而设计。\n\n图 20. Yann LeCun 与他的 LeNet-5\n\n#### 6.2 CNN 的崛起：AlexNet (2012)\n\n2012 年，AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了重大胜利，这是 CNN 发展中的一个重要里程碑。这次胜利不仅以压倒性优势赢得了比赛，也在图像分类领域取得了重大突破。\n\n图 21. ILSVRC 历年冠军及其表现\n\nILSVRC 是一个年度图像识别基准测试，用于评估算法在一个包含 1000 万多张注释图像的数据集上的表现，这些图像被划分为 1000 个类别。AlexNet 的创新之处包括：\n\n* **ReLU 激活函数**：为解决传统激活函数的问题而引入，ReLU 提高了训练速度并改善了性能。\n* **Dropout 正则化**：这种技术通过在训练过程中随机丢弃神经元来减少过拟合现象。\n* **数据增强**：通过人为增加训练数据的多样性，增强了数据集的丰富性，从而改善了模型的泛化能力。\n\nAlexNet 的成功成为 CNN 发展中的一个转折点，为图像分类和物体检测的进一步发展奠定了基础。\n\n图 22. AlexNet 架构\n\n#### 6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）\n\n自 2010 年代直至今天，当前的科技发展黄金时代以深度学习、大数据和强大计算平台的结合为特征。在这一时期，图像识别、自然语言处理和机器人技术等领域取得了显著的突破。持续的研究不断推动着人工智能（AI）能力的边界。\n\n图 23. AlexNet 开启神经网络的第三次黄金时代\n\n#### 6.4 后续架构改进\n\n继 AlexNet 之后，又相继出现了几个有影响力的架构：\n\n* **VGGNet (2014)**：由牛津大学的视觉几何组开发，VGGNet 强调使用更深的网络架构，并采用较小的卷积滤波器 (\n  3\n  ×\n  3\n  3 \\times 3\n  3×3)，从而取得了显著的准确率。\n\n  图 24. 原始 VGGNet 架构\n* **GoogLeNet/Inception (2014)**：引入了 inception 模块，使得网络能够以更高效的方式捕捉不同尺度的特征。\n\n  图 25. GooLeNet 架构\n* **ResNet (2015)**：残差网络通过引入跳跃连接，使得训练非常深的网络成为可能，同时缓解了梯度消失问题。\n\n  图 26. ResNet 架构\n\n#### 6.5 CNN 的应用\n\nCNN 的进步已经在多个领域引发了变革：\n\n* **计算机视觉**：CNN 已成为现代计算机视觉的核心，实现了图像分类、物体检测和语义分割方面的突破。\n* **医学影像**：CNN 被用于疾病诊断、肿瘤检测和图像引导手术等任务，大大提高了诊断准确性。\n* **无人驾驶**：CNN 是无人驾驶感知系统的核心，使它们能够解释和响应周围环境。\n\nCNN 从其创立到目前作为深度学习基石的历程展示了其对 AI 的重大影响。CNN 的成功也为深度学习的进一步进步铺平了道路，并激发了其他专用神经网络架构的发展，如 RNN 和 Transformer。CNN 的理论基础和实际创新显著推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 7. 循环神经网络 (1986 – 2017)\n\n循环神经网络 (RNN) 是为了处理序列数据而设计的。与传统的前馈网络（MLP）不同，RNN 拥有一个内部的隐藏状态或“记忆”，使其能够捕捉序列元素之间的时间依赖性。因此，RNN 在语言建模、时间序列预测和语音识别等任务中尤为有效。\n\n#### 7.1 早期发展 (1980s – 1990s)\n\nRNN 的概念起源于 1980 年代，John Hopfield, Michael I. Jordan 和 Jeffrey L. Elman 等先驱为这些网络的发展做出了贡献。John Hopfield在 1982 年提出的 Hopfield 网络为理解神经网络中的循环连接奠定了基础。Jordan 网络和 Elman 网络分别在 1980 年代和 1990 年代提出，是早期捕捉序列数据中时间依赖性的尝试。\n\n图 27. RNN 架构\n\nRNN 使用历时反向传播 (BPTT) 进行训练，这是前馈网络标准反向传播算法的扩展。BPTT 需要将网络在时间上展开，将每个时间步视为一层。在前向传播时，输入序列被处理，并在输出层计算误差。然后，产生的梯度从最后一个时间步反向传播到第一个时间步，以更新 RNN 的参数。然而，由于梯度消失问题，RNN 在学习长时间依赖性时遇到困难，因为梯度会变得极小，导致无法学习。相反，梯度也可能变得过大，造成训练不稳定，这被称为梯度爆炸问题。\n\n图 28. 反向传播 (BPTT)\n\n#### 7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)\n\n图 29. RNN, LSTM, GRU 单元\n\n* **长短期记忆 (LSTM) 网络 (1997)**：Sepp Hochreiter 和 Jürgen Schmidhuber 提出了 LSTM 网络，以解决传统 RNN 中的梯度消失问题。LSTM 通过使用门控机制来控制信息流动，使其能够捕捉序列数据中的长期依赖关系。LSTM 包括单元状态（用于存储长期信息）、隐藏状态（携带当前时间步的短期输出），以及三个门（输入门、遗忘门和输出门）。在每一步中，LSTM 会根据多个数学运算和门来决定需要遗忘多少信息，向单元状态添加多少信息，以及为下一步输出多少信息。\n* **门控循环单元 (GRU) (2014)**：Kyunghyun Cho 等人提出了 GRU，这是一种简化版的 LSTM，也采用门控机制来调节信息流。与 LSTM 的三个门和两个状态不同，GRUs 只有两个门和一个状态。LSTM 的遗忘门和输入门被合并为一个更新门，用于决定保留多少过去的信息和整合多少新信息。此外，GRU 用重置门代替了 LSTM 的输出门，该门决定在整合新信息之前需要“重置”或忘记多少过去的信息。由于 GRU 的参数较少，通常训练速度更快。\n* **Seq2Seq 模型 (2014)**：Ilya Sutskever 和他的团队提出了 Seq2Seq 模型，这种模型使用编码器-解码器架构，将输入序列转换为输出序列。Seq2Seq 模型已被广泛应用于机器翻译、语音识别和文本摘要等任务。\n\n  图 30. 基于 LSTM 的 Seq2Seq 编码器-解码器架构\n\n#### 7.3 RNN 的应用\n\nRNN 在多个领域产生了重大影响，包括：\n\n* **自然语言处理**：RNN 在自然语言处理领域引发了革命性变化，使得语言建模、机器翻译、情感分析和文本生成等任务取得了显著进展。\n* **语音识别**：RNN 广泛用于语音识别系统中，它们通过建模口语的时间依赖性，将语音信号转换为文本。\n* **时间序列预测**：RNN 在时间序列预测中表现出色，它们通过建模顺序数据的时间依赖性，以预测未来值。\n\n#### 7.4 RNN 的挑战\n\n尽管 RNN 在许多方面取得了成功，但其仍面临若干挑战：\n\n* **梯度消失与梯度爆炸**：传统 RNN 在处理这些问题时表现不佳，尽管 LSTM 和 GRU 提供了一些解决方案。\n* **计算复杂性**：训练 RNN 可能需要大量资源，尤其是在处理大型数据集时。\n* **并行化**：RNN 的顺序特性使得并行训练和推理过程变得复杂。\n\nRNN 的成功为深度学习的进一步发展奠定了基础，并启发了其他专门化神经网络架构的发展，例如 Transformer，它们在各种序列数据任务中取得了最先进的性能。RNN 的理论基础和实际创新大大推动了深度学习技术在各个领域的广泛应用和成功。\n\n### 8. Transformer (2017 – 现在)\n\nTransformer 以其卓越的序列数据处理能力，深刻地改变了深度学习的格局，并在自然语言处理 (NLP) 和计算机视觉等多个领域中发挥了重要作用。\n\n#### 8.1 Transformer 简介\n\nVaswani 等人于 2017 年发表了开创性论文“Attention is All You Need”，其中提出了 Transformer 模型。这个模型放弃了 RNN 的传统序列处理方式，转而采用自注意力机制，从而实现了并行处理，并能更好地处理长距离依赖关系。\n\n图 31. 自注意力机制\n\nTransformer 具有如下核心特性：\n\n* **自注意力机制**：允许序列中每个位置灵活地关注其他所有位置，从而比 RNN 或 LSTM 更有效地捕捉上下文。\n* **并行化**：通过同时处理所有输入数据，大大提高了训练速度，这与 RNN 的顺序处理方式形成鲜明对比。\n* **编码器-解码器结构**：编码器和解码器堆栈都使用自注意力和前馈神经网络层，并通过位置编码来保持序列的顺序。\n\n图 32. Transformer 架构\n\n关于 Transformer 和自注意力机制的详细介绍，请参考 [《深度解析 Transformer 和注意力机制（含完整代码实现）》](https://jarod.blog.csdn.net/article/details/130867562) 和 [《图解 NLP 模型发展：从 RNN 到 Transformer》](https://jarod.blog.csdn.net/article/details/129564388)。\n\n#### 8.2 Transformer 的衍生模型\n\n图 33. 基于 Transformer 的模型\n\nTransformer 有众多衍生模型，其中比较重要的有：\n\n* **BERT (2018)**: BERT 是一种仅使用编码器的双向编码器表示模型，通过掩码语言建模和下一句预测的预训练，彻底革新了 NLP。\n* **GPT (2018)**: GPT 旨在预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这一基础模型为生成式语言模型的后续发展奠定了基础，展示了从大型文本语料库中进行无监督学习的潜力。\n* **T5 (2019)**: T5 是一种编码器-解码器结构的文本到文本转换模型，将 NLP 任务转化为统一的文本到文本格式，简化了模型架构和训练过程。\n\n图 34. BERT vs. GTP vs. T5\n\n#### 8.3 OpenAI GPT 的发展历程\n\nOpenAI 的生成式预训练 Transformer (Generative Pre-trained Transformer, GPT) 系列模型自 2018 年问世以来，极大地推动了自然语言处理 (Natural Language Processing, NLP) 领域的发展。每一代模型都在前一代的基础上进行改进，引入了更大规模的模型和增强的功能。以下是每个版本的详细概述。\n\n图 35. GPT 的自回归语言模型架构旨在根据之前输入的 Token 预测序列中的下一个 Token\n\n* **GPT (2018)**: 原始的 GPT 模型于 2018 年推出，作为一个仅使用自回归解码器的变换器，拥有 1.17 亿个参数。它被设计用于预测序列中的下一个 Token（词），展示了在理解和生成类人文本方面的强大能力。这个基础模型为后续生成式语言模型的发展奠定了基础，展示了无监督学习从大型文本语料库中获取信息的潜力。\n* **GPT-2 (2019)**: 2019 年发布的 GPT-2 在模型规模和能力上实现了显著飞跃，参数数量扩大到 15 亿个。这个版本表现出一些新兴能力，如零样本任务执行，即可以在没有专门训练的情况下执行任务。然而，它生成连贯但有时误导性文本的能力引发了关于潜在滥用的道德担忧，特别是在生成假新闻或错误信息方面。\n* **GPT-3 (2020)**: GPT-3 于 2020 年推出，进一步将模型规模扩大到惊人的 1750 亿个参数。该模型在少样本学习方面表现出卓越的能力，即可以根据提示中提供的极少量示例适应各种任务。其生成类人文本的能力使其成为许多应用的多功能工具，包括内容创作、代码辅助和对话代理。GPT-3 的架构使其能够在无需大量微调的情况下执行广泛的 NLP 任务，巩固了其作为当时最强大语言模型之一的地位。\n* **ChatGPT (2022):** 这是一个经过微调的 GPT-3.5 模型，通过人类反馈强化学习 (Reinforcement Learning from Human Feedback, RLHF) 进行优化，擅长处理后续问题和维护上下文，通过指令调优和用户偏好数据使响应更符合用户意图。\n* **GPT-4 (2023)**: GPT-4 于 2023 年发布，继续在能力和参数数量上进行扩展，尽管其架构和参数数量的具体细节目前尚未完全公开。预计将在之前几代模型的表现上进一步提升，特别是在推理能力和理解复杂上下文的能力方面。\n* **GPT-o1 (2024)**：这一版本的 GPT 与之前所有版本有了本质区别，它开创性地引入了人类的慢思考+思维链模式，将大模型从越来越离谱的参数内卷中解救出来，开辟了AI发展的新方向。GPT-o1 显著提升了逻辑推理能力，使其在数学、科研、代码等领域的表现有了质的飞跃。在若干基准测试中，GPT-o1 展现出的能力已经与博士生相当。\n\n#### 8.4 其他知名大语言模型\n\n随着越来越多优秀的大型语言模型（LLM）的涌现，人工智能领域得到了极大的丰富。这些模型各具特色，为人工智能技术带来了新的进展。以下是一些知名大语言模型的概况：\n\n* **Anthropic 的 Claude (2022)**: 该模型注重 AI 输出的安全性和伦理问题，致力于与人类价值观保持一致。\n* **Meta 的 LLaMA (2023)**: 提供多种规模的模型，以满足不同的计算需求，在自然语言处理的基准测试中表现卓越。\n* **Mistral.AI 的 Mistral (2023)**: 兼顾高性能和资源效率，适合于实时应用，专注于开源 AI 解决方案。\n* **阿里巴巴的 Qwen (2023)**: 专为创建高质量的英中双语 AI 模型而设计，促进跨语言应用并推动创新。\n* **Microsoft 的 Phi (2023)**: 强调在各种应用中的多功能性和集成能力，采用先进的训练技术以提升上下文理解和用户交互。\n* **Google 的 Gemma 系列 (2024)**: 这些轻量级的开放模型应用于多种领域，包括文本生成、摘要和信息提取，注重性能和效率。\n\n更多大语言模型及其能力评估参加下图\n\n图 36. 开源模型和闭源模型的性能\n\n### 9. 多模态模型 (2023 – 现在)\n\n#### 9.1 GPT-4V (2023) 和 GPT-4o (2024)\n\n* **GPT-4V (2023)** 是 AI 发展中的重要一步，它将多模态功能集成到已经强大的文本模型中。它不仅能够处理和生成文本，还可以处理和生成图像内容，为更全面的 AI 交互奠定了基础。\n* **GPT-4o (2024)** 是从 GPT-4V 演变而来的，通过复杂的上下文理解来增强多模态集成。与其前身相比，它在不同媒体之间提供了更好的连贯性，能够从文本提示生成更高级的图像，并基于视觉输入进行更精细的推理。此外，GPT-4o 通过高级训练机制实现伦理对齐，确保其输出不仅准确，而且负责任，并与人类价值观保持一致。\n\n#### 9.2 Google’s Gemini (2023 – 现在)\n\n* **Gemini Pro (2023)**: Google 的 Gemini 推出了一系列为多模态任务设计的模型，集成了文本、图像、音频和视频处理。特别是，Gemini Pro 因其可扩展性和效率而脱颖而出，使高级 AI 能够应用于从实时分析到跨不同媒体格式的复杂内容生成等多个领域。\n* **Gemini Ultra 和 Nano (2023)**: Gemini 模型包括适用于不同规模应用的 Ultra 和 Nano 版本，能够执行需要跨多种数据类型理解的任务。它们在视频摘要、多模态翻译和互动学习环境等任务中表现出色，体现了 Google 在推动 AI 在多媒体环境中应用的决心。\n\n#### 9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)\n\n* **Claude 3.0 (2023)** 由 Anthropic 推出，该模型专注于提高 AI 响应的安全性和可靠性，在上下文理解和伦理考虑方面进行了改进。它被设计得更具对话性和辅助性，同时严格遵循避免有害或偏见输出的原则。\n* **Claude 3.5 (2024)** 进一步提升了 Claude 3.0 的能力，在复杂任务中的表现更佳，处理效率更高，并且在用户请求的细节处理上更加细致。这个版本还强调多模态交互，虽然它主要在文本和逻辑任务中表现突出，但在处理视觉或其他感官输入方面也展现出新兴能力，提供更为综合的用户体验。\n\n#### 9.4 LLaVA (2023)\n\n* **LLaVA (Large Language and Vision Assistant)** 是一种创新的多模态 AI (Multimodal AI) 方法，将语言理解与视觉处理结合在一起。LLaVA 于 2023 年开发，能够解读图像并将其与文本内容相联系，使其可以回答关于图像的问题、描述视觉内容，甚至根据视觉线索生成文本。其架构充分利用 Transformer 模型的优势，在需要同时具备视觉和语言理解的任务中实现了最先进的性能。这个模型因其开源特性而备受关注，鼓励在多模态 AI 应用领域进行更多的研究和开发。\n\n  图 37. LLaVA 架构\n\n  这些模型的出现标志着 AI 系统的转变，这些系统不仅能够理解和生成文本，还能解释和创造跨多种模态的内容，更加贴近人类的认知能力。这种 AI 模型的发展推动了更具互动性和直观性的应用程序，它们能够结合不同的感官输入来处理现实世界中的场景，从而拓宽了 AI 在日常生活、研究和工业应用中的可能性。\n\n### 10. 扩散模型 (2015 – 现在)\n\n扩散模型已经成为生成模型中一个重要的类别，它为从复杂数据分布中生成高保真样本提供了一种全新的方法。与传统模型如 GAN 和 VAE 不同，扩散模型采用渐进去噪技术，并在许多应用中表现出色。\n\n#### 10.1 扩散模型简介 (2015)\n\n扩散模型的基础由 Sohl-Dickstein 等人于 2015 年在他们的论文中奠定。他们提出了一种生成过程，即通过逆转逐步添加的噪声，可以将噪声还原为结构化数据。\n\n图 38. 扩散模型原理概要\n\n扩散模型的关键特性：\n\n* **去噪过程**: 这些模型通过逐步添加噪声（前向过程），并学习如何逆转该过程（反向过程），以有效去噪并生成样本。\n* **马尔可夫链**: 这两个过程都被构建为马尔可夫链，每个前向步骤添加高斯噪声，模型学习如何在反向过程中去除这些噪声。\n* **训练目标**: 目标是在每一步中最小化预测噪声与实际噪声之间的差异，优化一种证据下界（ELBO）的形式。\n* **稳定性和鲁棒性**: 它们比 GAN 提供更好的稳定性，避免了模式崩溃等问题，从而能够持续生成多样化的高质量输出。\n\n关于扩散模型的详细介绍，请参考[《Diffusion Model 深入剖析》](https://jarod.blog.csdn.net/article/details/130903760)。\n\n#### 10.2 扩散模型的发展 (2020 – 现在)\n\n* **去噪扩散概率模型 (Denoising Diffusion Probabilistic Models, DDPM) (2020)**: 改进了扩散过程，在图像合成领域设立了新的标杆。\n* **去噪扩散隐式模型 (Denoising Diffusion Implicit Models, DDIM) (2021)**: 通过非马尔可夫采样提高了效率，使生成过程更加灵活。\n* **基于分数的生成模型 (2021)**: 通过使用随机微分方程提高了样本生成的效率。\n* **潜在扩散模型 (Latent Diffusion Model) (2022)**: 成为流行的文本到图像生成系统（如 Stable Diffusion）的基础，显著推动了 AI 生成图像领域的进步，并为更易于访问和高效的生成式 AI 工具铺平了道路。关于潜在扩散模型和 Stable Diffusion 的详细介绍，请参见 [《Stable Diffusion 超详细讲解》](https://jarod.blog.csdn.net/article/details/131018599) 和 [《Stable Diffusion原理详解》](https://jarod.blog.csdn.net/article/details/129280836)。\n\n  图 39. 潜在扩散模型架构\n\n#### 10.3 文生图模型\n\n* **DreamBooth (2022)**: 允许在少量特定主题的图像上训练扩散模型，从而实现个性化的图像生成。\n* **LoRA (2022)**: 代表低秩适应，是一种通过添加少量参数来微调扩散模型的技术，使其更容易适应特定任务或数据集。\n* **ControlNet (2023)**: 通过添加如草图或深度图等输入来控制扩散模型，从而对生成图像提供更多的控制。\n* **FLUX.1 (2024)**: Black Forest Lab 推出了 FLUX.1，这是一种用于 AI 图像生成的先进扩散模型，具备卓越的速度、质量和响应提示的能力。FLUX.1 提供三个版本——Schnell、Dev 和 Pro，并采用了整流流变换器等创新技术，能够生成高度逼真的图像。FLUX.1 还可以生成文字并精准处理手指和脚趾等细节，是一个全面的图像生成器。\n* **Multi-SBoRA (2024)**: Multi-SBoRA 是一种为多个概念定制扩散模型的新方法。它使用正交标准基向量来构建低秩矩阵进行微调，允许区域性和非重叠的权重更新，从而减少跨概念的干扰。这种方法保留了预训练模型的知识，减少了计算开销，并提高了模型的灵活性。实验结果显示，Multi-SBoRA 在多概念定制中表现优异，保持了独立性，并减轻了串扰效应。\n\n#### 10.4 文生视频模型\n\n2024 年 2 月，OpenAI 发布了 [Sora](https://openai.com/sora) 文生视频模型。凭借惊艳的视频生成质量，Sora 一经发布就受到各行各业的追捧和关注。尽管在 Sora 之前已经有好几个文生视频模型，但 Sora 的发布被普遍认为拉开了文生视频的大幕。\n\nSora vs. Pika vs. RunwayML vs. Stable Video 生成视频效果对比\n\n很明显可以看出 Sora 无论从分辨率、时长、精细度和对真实世界的还原程度上都远远好于其他模型。下表给出了详细的对比。\n\n图 40. Sora vs. 早期文生视频模型\n\n然而，Sora 发布后迟迟没有正式上线。全网苦等10个月，Sora 终于在 2024 年 12 月 10 日正式上线。在这 10 个月期间，国产文生视频模型迅速崛起，其中 MiniMax 的海螺和快手的可灵的视频生成质量比肩甚至超越 Sora。\n\n| 名称 | 公司 | 单次生成秒数 | 是否免费 | 生成方式 | 最低月付费 |\n| --- | --- | --- | --- | --- | --- |\n| 可灵 | 快手 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 66元 |\n| 即梦 | 字节 | 5s | 限制免费使用次数 | 文生视频、图生视频 | 69元 |\n| 海螺 | MiniMax | 6s | 限制免费使用次数 | 文生视频、图生视频 | 68元 |\n| Vidu | 生数科技 | 4s | 限制免费使用次数 | 文生视频、图生视频 | 9.9美元 |\n| 智谱清言 | 智谱科技 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| 通义万相 | 阿里 | 6s | 没有限制 | 文生视频、图生视频 | 免费 |\n| FilmAction | 瀚皓科技 | 5s | 限制免费使用次数 | 图生视频 | 50元300电影币 |\n| 白日梦 | 光魔科技 | 最长6分钟 | 限制免费使用次数 | 图生视频 | 29元 |\n| Sora | OpenAl | 5s、20s | 付费使用 | 文生视频、图生视频 | 20美元 |\n| Runway | Runway | 10s | 限制免费使用次数 | 文生视频、图生视频 | 15美元 |\n\n表 1. 主流文生视频模型一览表\n\n相信 2025 年文生视频将会是各大 AI 企业主要争夺的战场。\n\n### 11. 尾声\n\n至此，我们的 AI 简史之旅就要接近尾声了。通过对 AI 发展的回顾，我们可以发现人工智能 (AI) 和深度学习的发展历史充满了突破性的进步和变革性的创新。从早期的简单神经网络到复杂的网络架构，从卷积神经网络 (CNN)、递归神经网络 (RNN) 到现在流行的 Transformer 和扩散模型，这些技术已经彻底改变了许多领域。\n\n最近的技术进步催生了大型语言模型和多模态模型，例如 OpenAI 的 GPT-4o、Google 的 Gemini Pro、Antropic 的 Claude 3.5 Sonnet 和 Meta 的 LLaMA3.1 等，它们在自然语言处理和多模态能力方面表现出色。此外，生成式 AI (Generative AI) 的突破，包括文本到图像和文本到视频生成模型如 Midjourney、DALL-E 3、Stable Diffusion、FLUX.1 和 Sora，极大地拓展了 AI 的创造潜力。\n\n随着研究继续致力于开发更高效、可解释和功能强大的模型，AI 和深度学习对社会和技术的影响将不断加深。这些技术进步不仅推动了传统行业的创新，还为创造性表达、问题解决和人机协作开辟了新可能。\n\n然而，深度学习并不是实现 AI 的唯一途径或最佳途径。符号 AI、强化学习和神经符号 AI 各自具有独特优势，并能弥补深度学习在可解释性和计算资源需求方面的不足。对 AI 的全面理解应涵盖这些多样化的方法。\n\nAI 的未来在于多种方法的协同效应。随着研究的深入，构建多元化的 AI 技术生态系统将确保其平衡和有效的发展，从而造福社会和科技领域。\n\n本文章已经生成可运行项目\n\n确定要放弃本次机会？\n\n福利倒计时\n\n*:*\n*:*\n\n立减 ¥\n\n普通VIP年卡可用\n\n[立即使用](https://mall.csdn.net/vip)\n\n[JarodYv](https://jarod.blog.csdn.net)\n\n[关注](javascript:;)\n关注\n\n* 49\n\n  点赞\n* 踩\n* [89](javascript:;)\n\n  收藏\n\n  觉得还不错?\n  一键收藏\n* [2](#commentBox)\n\n  评论\n* [分享](javascript:;)\n\n  复制链接\n\n  分享到 QQ\n\n  分享到新浪微博\n\n  扫一扫\n* [打赏](javascript:;)\n\n  打赏\n* 打赏\n  举报\n\n  举报\n\n专栏目录\n\n[*人工智能*（*AI*）*简史*：推动新时代的科技力量](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[qq\\_17153885的博客](https://blog.csdn.net/qq_17153885)\n\n12-31\n\n1万+\n\n[*人工智能*（*AI*，Artificial Intelligence）是计算机科学的一个分支，旨在研究和开发可以模拟、扩展或增强人类智能的系统。它涉及多种技术和方法，包括*机器学习*、*深度学习*、自然语言处理（NLP）、计算机视觉、专家系统等。](https://blog.csdn.net/qq_17153885/article/details/144838030)\n\n[最全*AI**简史*（下）：后*深度学习*时代（*大模型*时代）](https://blog.csdn.net/jpw41/article/details/141403498)\n\n[jpw41的博客](https://blog.csdn.net/jpw41)\n\n08-21\n\n2914\n\n[💡 铺垫这么多终于到*大模型*章节了，前面两篇文章分别就*人工智能*和*深度学习*的发展历史进行了介绍，大致可以理解为：20世纪的*人工智能*发展百花齐放、坎坷中前进，进入21世纪后*深度学习*很快成为*人工智能*中的显学，2020年后则以大语言模型为代表范式。这当然不是说一些逻辑规则的、概率统计*机器学习*的甚至是非*Transformer*的*深度学习*结构已经逐渐推出历史舞台，相反大家各自在自己的领域依然是SOTA，也与*大模型*有许多交汇的地方。](https://blog.csdn.net/jpw41/article/details/141403498)\n\n2\xa0条评论\n您还未登录，请先\n登录\n后发表或查看评论\n\n[*AI*进化史*:*从图灵测试到ChatGPT](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n1-30\n\n[*AI**发展史*是一部人类探索智能本质、拓展认知边界的壮丽史诗,而我们正身处其中最具变革性的章节。DeepSeek等新一代*AI*力量的加入,正在书写着这段历史的新篇章。](https://blog.csdn.net/qq_38145499/article/details/155749946)\n\n[*人工智能*(Artificial Intelligence, *AI*)\\_*ai**发展史* csdn](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n1-20\n\n[机器翻译领域出现“ALPAC报告”*:*1966年,美国政府因机器翻译进展缓慢(如“the spirit is willing but the flesh is weak”被译为“酒是好的,但肉已变质”),停止资助相关研究,引发第一次*AI*寒冬。 1970s*:*符号主义局限性显现(如无法处理模糊、非结构化问题),加上计算能力不足,科研 funding 锐减,进入第一次*AI*寒冬。](https://blog.csdn.net/m0_68935893/article/details/150590727)\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[CSDN\\_430422的博客](https://blog.csdn.net/CSDN_430422)\n\n07-21\n\n4621\n\n[万字长文详解 *AI* *大模型**发展史*：从萌芽到爆发，史上最全整理](https://devpress.csdn.net/v1/article/detail/149507169)\n\n[收藏级！史上最通俗的*AI*发展历程综述（附*大模型*学习指南）\n\n最新发布](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[大模型教程的博客](https://blog.csdn.net/Z987421)\n\n12-27\n\n556\n\n[规则式*AI*的死板问题，催生了"让机器自主学习规律"的需求——*机器学习*（ML）技术应运而生，标志着*AI*从"规则驱动"迈入"数据驱动"时代。机器从数据中总结出的规律，最终会形成一个"可复用的计算模型"——这就是*AI*模型（Model）。对程序员而言，可理解为"一个经过数据训练的函数，输入新数据就能输出判断结果"。*AI*模型三大核心要素： - 输入：新的待处理数据（如收到的新邮件）；- 处理：用学到的规律对数据进行分析；- 输出：明确的结果（如"垃圾邮件"或"正常邮件"）。](https://devpress.csdn.net/v1/article/detail/156328628)\n\n[*人工智能*发展*简史*, 没想到17世纪*AI*就出现了!\\_17世纪中叶*人工智能*-CSDN...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n12-17\n\n[本文回顾了*人工智能*的发展历程,从17世纪笛卡尔的构想到20世纪中叶图灵测试的提出,再到达特茅斯会议的*人工智能*定义。文章详细介绍了*AI*在商业、游戏、自动驾驶等领域的应用,以及近年来*深度学习*和无监督学习的重大突破。 部署运行你感兴趣的模型镜像一键部署 *人工智能**发展史* ...](https://blog.csdn.net/gravitylink/article/details/86089639)\n\n[*人工智能**发展史*\\_*人工智能*的夏天](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n1-17\n\n[Judea Pearl发表于1988年的名著将概率论和决策理论引入*AI*。现已投入应用的新工具包括贝叶斯网络,隐马尔可夫模型,信息论,随机模型和经典优化理论。针对*神经网络*和进化算法等“计算智能”范式的精确数学描述也被发展出来。 大数据*:*2005 - 现在 从某种意义上讲,2005年是大数据元年,虽然大部分人感受不到数据带来的变化,但是...](https://blog.csdn.net/carolynlmk/article/details/75043875)\n\n[*Ai**发展史*(个人理解)梳理](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[记录 IT 领域经验与见解的博客](https://blog.csdn.net/q6115759)\n\n04-17\n\n2355\n\n[在21世纪初期，随着计算机硬件的不断提升和大规模数据的出现，*深度学习*成为*人工智能*领域的热门研究方向。总之，*人工智能*是一项非常重要的技术，将对我们的生活和工作产生深远的影响。随着*人工智能*应用场景的不断增多，*人工智能*将更加个性化和定制化，可以根据不同用户的需求提供不同的服务。4. *人工智能*将更加智能和自主。随着*人工智能*技术的不断进步，*人工智能*将更加智能和自主，可以自主学习和决策，提高*人工智能*的效率和智能性。随着*人工智能*应用场景的不断增多，*人工智能*将更加注重安全和隐私，保护用户的数据和信息安全。](https://blog.csdn.net/q6115759/article/details/130200753)\n\n[*人工智能**发展史*](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[JIA\\_NG\\_FA\\_N的博客](https://blog.csdn.net/JIA_NG_FA_N)\n\n06-08\n\n7819\n\n[起步发展期：1943年—20世纪60年代反思发展期：20世纪70年代应用发展期：20世纪80年代平稳发展期：20世纪90年代—2010年蓬勃发展期：2011年至今。](https://blog.csdn.net/JIA_NG_FA_N/article/details/139538850)\n\n[最全科普｜万字长文论*人工智能*的前世今生（下篇）](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[GentelAi的博客](https://blog.csdn.net/GentelAi)\n\n03-12\n\n1306\n\n[到1976年，MYCIN的开发工作基本完成，其诊断准确率达到65%-70%，甚至超过了一些人类医生的表现，成为*人工智能*领域的里程碑。1980年，美国数字设备公司（DEC）开发了XCON（eXpert CONfigurer），这是一个用于配置计算机系统的专家系统，成功帮助公司自动化复杂的计算机配置流程，显著降低了配置错误和成本，成为专家系统商业化的成功案例。Word2Vec的提出不仅显著提升了自然语言处理（NLP）任务的性能，也为后续的语言模型（如BERT和GPT）奠定了基础，成为NLP领域的里程碑。](https://blog.csdn.net/GentelAi/article/details/146201083)\n\n[一文了解*大模型*：*AI*（*人工智能*）的发展历程](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[m0\\_56255097的博客](https://blog.csdn.net/m0_56255097)\n\n08-23\n\n4429\n\n[*AI**大模型*作为*人工智能*领域的重要技术突破，正成为推动各行各业创新和转型的关键力量。抓住*AI**大模型*的风口，掌握*AI**大模型*的知识和技能将变得越来越重要。学习*AI**大模型*是一个系统的过程，需要从基础开始，逐步深入到更高级的技术。这里给大家精心整理了一份全面的*AI**大模型*学习资源，包括：*AI**大模型*全套学习路线图（从入门到实战）、精品*AI**大模型*学习书籍手册、视频教程、实战学习、面试题等，资料免费分享！](https://devpress.csdn.net/v1/article/detail/141417916)\n\n[看 *人工智能**简史*](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[我相信......](https://blog.csdn.net/wireless_com)\n\n02-25\n\n2819\n\n[这个春节有些心神不定，只得靠读书和学习平复心情。《*人工智能**简史*》去年很火，在京东的销售榜中也很考前，未能免俗，自己抽空读了一遍，随记随想。（图片来自百度百科）过去只是序幕。*人工智能*缘起达特茅斯会议，在...](https://devpress.csdn.net/v1/article/detail/79386740)\n\n[*AI**发展史*：从图灵机到*AI*大时代](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[m0\\_59164304的博客](https://blog.csdn.net/m0_59164304)\n\n05-21\n\n5806\n\n[*AI*无疑是近年来最热门的话题了，它以一种前所末有的速度影响我们的生活。然而,*AI*的发展历程并非一蹴而就,它经历了漫长的探索和曲折。本期,我们将回顾*AI*的发展历程。](https://devpress.csdn.net/v1/article/detail/139102029)\n\n[*人工智能*与*深度学习*发展*简史*：从感知器到多模态*大模型*的技术演进](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*（*AI*）与*深度学习*的*发展史*，是一部融合数学、计算机科学、神经科学、认知心理学与工程实践的宏大叙事，其演进不仅体现了人类对智能本质的持续追问，更深刻重塑了技术范式、产业格局与社会运行逻辑。...](https://wenku.csdn.net/doc/68jgfmwztf)\n\n[*人工智能*发展*简史*：从1943年M-P模型到21世纪*深度学习*爆发](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[资源摘要信息*:**人工智能*发展*简史*1所涵盖的知识点，系统性地勾勒出*人工智能*学科从思想萌芽到学科正式确立的关键演进脉络，其核心在于揭示人类如何在数学、逻辑学、神经生理学、计算机科学与认知科学的交叉融合中，逐步...](https://wenku.csdn.net/doc/7utf0qazuj)\n\n[*AI**发展史*：从*神经网络*到*大模型*的演进之路](https://wenku.csdn.net/doc/706v1gz262)\n\n[本文以“*AI* *简史*：从*神经元*到*现代**大模型*”为题，系统梳理了从早期人工*神经网络*到当前主流*深度学习*架构的关键节点，涵盖了从理论奠基到实际应用的完整脉络，并提供了可运行的源码示例，使得开发者不仅能理解原理，还...](https://wenku.csdn.net/doc/706v1gz262)\n\n[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https://wenku.csdn.net/column/2fcd64w82r)\n\n[[【引言与*神经网络*基础】*人工智能**简史*：从逻辑机器到*深度学习*的演变](https*:*//online.visual-paradigm.com/repository/images/06393536-dbad-4462-982f-7661c65029ea/timeline-diagram-design/.png) # 1. *人工智能*...](https://wenku.csdn.net/column/2fcd64w82r)\n\n[*人工智能*发展*简史*：从图灵机、达特茅斯会议到*神经网络*与控制论的演进](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[而麦克洛奇与皮茨于1943年提出的MP*神经元*模型，则是首次用数学微分方程与阈值逻辑模拟生物*神经元*电生理活动的开创性尝试，它虽高度简化，却构建起连接主义范式的原始框架，成为后世感知机、反向传播算法及深度神经...](https://wenku.csdn.net/doc/2qeezgdjyz)\n\n[赫布理论](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[qq\\_31374615的博客](https://blog.csdn.net/qq_31374615)\n\n09-21\n\n3958\n\n[赫布理论\n本词条缺少名片图，补充相关内容使词条更完整，还能快速升级，赶紧来编辑吧！\n赫布理论（英语：Hebbian theory）描述了突触可塑性的基本原理，即突触前*神经元*向突触后*神经元*的持续重复的刺激可以导致突触传递效能的增加。这一理论由唐纳德·赫布于1949年提出，又被称为赫布定律（Hebb\'s\nrule）、赫布假说（Hebb\'s postulate）、细胞结集理论（cel](https://blog.csdn.net/qq_31374615/article/details/48623221)\n\n[*人工智能**简史*\\_*人工智能**简史*](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[科技博客的分析“工具人”](https://blog.csdn.net/cxq8989)\n\n07-10\n\n387\n\n[*人工智能**简史* 在*人工智能*的早期，计算机科学家试图在计算机中重建人类思维的各个方面。 这就是科幻小说中的智力类型，即或多或少像我们一样思考的机器。 毫无疑问，这种类型的智能称为可理解性。 具有可理解性的计算机可用于探索我们如何推理，学习，判断，感知和执行脑力活动。\n可懂度的早期研究集中于在计算机中对现实世界和思维（来自认知科学家的领域）的部分进行建模。 当您考虑到这些实验是在60年前进行的时...](https://devpress.csdn.net/v1/article/detail/107257372)\n\n[*人工智能*（*AI*）的发展历程](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[juzhi14plus的博客](https://blog.csdn.net/juzhi14plus)\n\n08-30\n\n2797\n\n[综上所述，人类在创造*人工智能*这一新物种的过程中，必须从伦理道德、法律监管、技术创新、教育和培训等方面进行应对，以确保*人工智能*的发展符合人类的利益和价值观，为人类社会的发展带来更多的机遇和福祉。十年后的 1966 年，麻省理工学院的约瑟夫・魏泽鲍姆开发了一款名为 ELIZA 的聊天机器人，这款机器人能够与人类进行简单的对话，为以后突破人类与机器之间的沟通障碍迈出了重要一步。*人工智能*的发展给人类带来了巨大的机遇和挑战，人类在创造这一新物种的过程中，必须采取积极有效的措施进行应对。](https://devpress.csdn.net/v1/article/detail/141714348)\n\n[四张图片道清*AI**大模型*的*发展史*(1943-2023)\n\n热门推荐](https://keziyi.blog.csdn.net/article/details/132310317)\n\n[weixin\\_47567401的博客](https://blog.csdn.net/weixin_47567401)\n\n08-16\n\n1万+\n\n[快速了解大规模语言模型的发展历程](https://keziyi.blog.csdn.net/article/details/132310317)\n\n* [关于我们](//www.csdn.net/company/index.html#about)\n* [招贤纳士](//www.csdn.net/company/index.html#recruit)\n* [商务合作](https://fsc-p05.txscrm.com/T8PN8SFII7W)\n* [寻求报道](//marketing.csdn.net/questions/Q2202181748074189855)\n* 400-660-0108\n* [kefu@csdn.net](mailto:webmaster@csdn.net)\n* [在线客服](https://csdn.s2.udesk.cn/im_client/?web_plugin_id=29181)\n* 工作时间\xa08:30-22:00\n\n* [公安备案号11010502030143](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11010502030143)\n* [京ICP备19004658号](http://beian.miit.gov.cn/publish/query/indexFirst.action)\n* [京网文〔2020〕1039-165号](https://csdnimg.cn/release/live_fe/culture_license.png)\n* [经营性网站备案信息](https://csdnimg.cn/cdn/content-toolbar/csdn-ICP.png)\n* [北京互联网违法和不良信息举报中心](http://www.bjjubao.org/)\n* [家长监护](https://download.csdn.net/tutelage/home)\n* [网络110报警服务](https://cyberpolice.mps.gov.cn/)\n* [中国互联网举报中心](http://www.12377.cn/)\n* [Chrome商店下载](https://chrome.google.com/webstore/detail/csdn%E5%BC%80%E5%8F%91%E8%80%85%E5%8A%A9%E6%89%8B/kfkdboecolemdjodhmhmcibjocfopejo?hl=zh-CN)\n* [账号管理规范](https://blog.csdn.net/blogdevteam/article/details/126135357)\n* [版权与免责声明](https://www.csdn.net/company/index.html#statement)\n* [版权申诉](https://blog.csdn.net/blogdevteam/article/details/90369522)\n* [出版物许可证](https://img-home.csdnimg.cn/images/20250103023206.png)\n* [营业执照](https://img-home.csdnimg.cn/images/20250103023201.png)\n* ©1999-2026北京创新乐知网络技术有限公司\n\n登录后您可以享受以下权益：\n\n* 免费复制代码\n* 和博主大V互动\n* 下载海量资源\n* 发动态/写文章/加入社区\n\n×\n\n评论\xa02\n\n被折叠的\xa0\xa0条评论\n[为什么被折叠?](https://blogdev.blog.csdn.net/article/details/122245662)\n[到【灌水乐园】发言](https://bbs.csdn.net/forums/FreeZone)\n\n查看更多评论\n\n添加红包\n\n发出的红包\n\nJarodYv\n\n¥1\n¥2\n¥4\n¥6\n¥10\n¥20\n\n扫码支付：¥1\n\n您的余额不足，请更换扫码支付或[充值](https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip)\n\n打赏作者\n\n实付元\n\n扫码支付\n\n钱包余额\n0\n\n1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。  \n 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。\n\n[余额充值](https://i.csdn.net/#/wallet/balance/recharge)\n\n确定取消\n\n举报\n\n* 包含不实信息\n* 涉及个人隐私\n\n请选择具体原因（必选）\n\n* 侮辱谩骂\n* 诽谤\n\n请选择具体原因（必选）\n\n* 搬家样式\n* 博文样式\n\n[点击体验  \nDeepSeekR1满血版](https://ai.csdn.net/chat?utm_source=cknow_pc_blogdetail&spm=1001.2101.3001.10583) \n专业的中文 IT 技术社区，与千万技术人共成长\n客服\n返回顶部', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://blog.csdn.net/jarodyv/article/details/144699658', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99694854, 'save_path': None}}, {'paper_id': '', 'title': '人工智能历史 - IBM', 'authors': [], 'abstract': '[Artificial Intelligence](https://www.ibm.com/cn-zh/think/artificial-intelligence)\n\n# AI 的历史\n\n## 作者\n\n[Tim Mucci](https://www.ibm.com/think/author/tim-mucci.html) \n\nIBM Writer\n\n人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志，而虚构的故事充满了智能机器的可能性，设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的 [GPT](https://www.ibm.com/cn-zh/think/topics/gpt)（Generative Pretrained Transformer，生成式预训练转换器）时，迅速获得了广泛关注，标志着向实现这一古老梦想迈出了重要一步。\n\nGPT-3 是 [AI](https://www.ibm.com/cn-zh/topics/artificial-intelligence) 领域具有里程碑意义的时刻，因为它具有前所未有的规模，具有 1,750 亿个参数，这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练，使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习，显著提高了其泛用性，并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。\n\n如今，AI 正逐渐融入日常生活的方方面面，从社交媒体到工作流程，随着技术的不断进步，其影响力也将持续增长。要了解这项技术的发展方向，首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史：\n\n## 20 世纪以前\n\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念，这是一个大型机械装置，用于帮助学者产生新的想法、句子和书籍。\n\n- Jonathan Swift 的《格列佛游记》(1726)\n\nSwift 的讽刺作品预示了算法文本生成的概念，而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起，从而生成连贯的文本，这与斯威夫特虚构的“引擎”所要做的事情类似。\n\n### 1914 年\n\n西班牙工程师 Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机 *El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista* 自动下了一个简单的国际象棋残局，即王、车对王。机器一旦设置好就不需要人工干预，它会自主进行符合规则的国际象棋移动，如果人类对手下出了不合规则的招法，机器会发出信号指示错误。如果机器被置于获胜位置，它就能够可靠地将死人类对手。\n\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由 Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中，“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后，“机器人”一词迅速获得国际认可，并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的，但该词却与机械、人形机器联系在一起，被设计用来从事单调、无技能的劳动。\n\n爱荷华州立大学物理和数学教授 John Vincent Atanasoff 和他的研究生 Clifford Berry 在爱荷华州立大学依靠 650 美元的资助，创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一，也是美国计算机科学领域的里程碑。\n\n虽然 ABC 从未充分运行或广泛使用，但它引入的几个关键概念将成为现代计算发展的基础。\n\n与以前依赖十进制的计算设备不同，ABC 使用二进制（1 和 0）来表示数据，二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一，因此计算得更快、更可靠。ABC 将数据存储（内存）与处理单元（逻辑运算）分开，现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据，可处理多达 30 个联立方程。\n\nABC 采用大约 300 个真空电子管进行逻辑运行，使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障，但它们是电子计算领域的一项关键发展。ABC 重量超过 700 磅，可以求解多达 29 个联立线性方程。\n\n### 1943 年\n\nWarren S. McCulloch 和 Walter Pitts 在 *Bulletin of Mathematical Biophysics* 上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础，并引入了人工神经网络的概念，而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统，特别是通过[神经网络](https://www.ibm.com/cn-zh/topics/neural-networks)和[深度学习](https://www.ibm.com/cn-zh/topics/deep-learning)来模拟类似大脑的功能和过程。\n\n### 1950\n\n英国数学家 Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在 *Mind* 上。2这篇论文是 AI 领域的奠基性文章，探讨了“机器能思考吗？”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”（即现在的图灵测试）来衡量其智能确立了基础。Turing 引入了一个思想实验，以避免直接回答“机器会思考吗？”；他是将这个问题重新表述为更具体、更可操作的形式：机器能否表现出与人类无异的智能行为？\n\n图灵测试已成为 AI 的核心概念，这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n\n## 1950–1980\n\n### 1951\n\nMarvin Minsky 和 Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器 (SNARC) 是模拟人脑学习过程的早期尝试，特别是通过[强化学习](https://www.ibm.com/cn-zh/topics/reinforcement-learning)。\n\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式，即随时间推移根据反馈调整自己的行为。它是一台模拟计算机，使用 3,000 个真空电子管组成的网络和突触权重来模拟 40 个类似神经元的单元。\n\n### 1952\n\n数学家兼计算机科学家 Allen Newell 和政治学家 Herbert A. Simon 开发出了 Logic Theorist 和 General Problem Solve 等具有影响力的程序，这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n\n### 1955\n\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中，由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的 Nathaniel Rochest 以及贝尔电话实验室的 Claude Shannon 共同提交。\n\n一年后，即 1956 年 7 月和 8 月举行的这次研讨会被普遍认为是新兴 AI 领域的正式诞生之时。\n\n### 1957 年\n\nFrank Rosenblatt 是一位心理学家兼计算机科学家，他开发了 Perceptron，这是一种早期的人工神经网络，可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念，二元分类器可通过学习[算法](https://www.ibm.com/cn-zh/topics/machine-learning-algorithms)调整其输入的权重，从而从数据中学习。虽然仅限于解决线性可分离问题，但它为未来神经网络和[机器学习](https://www.ibm.com/cn-zh/topics/machine-learning)的发展奠定了基础。\n\n### 1958\n\nJohn McCarthy 开发了编程语言 Lisp4，Lisp 是 LISt Processing 的缩写。Lisp 的诞生源于 McCarthy 在形式化算法和数理逻辑方面的工作，特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为 AI 研究中最流行的编程语言。\n\n### 1959\n\nArthur Samuel 率先提出了机器学习的概念，他开发了一个计算机程序，随着时间的推移，该程序在跳棋方面的性能不断提高。Samuel 证明，可以对计算机进行编程，使其遵循预定义的规则，并从经验中“学习”，最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步，并在此过程中创造了“机器学习”这一术语。\n\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统，在该系统中，各种“恶魔”（处理单元）共同识别模式。恶魔们竞相识别未经预编程的数据中的特征，模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献，影响了机器视觉和 AI 的未来发展。\n\nJohn McCarthy 在他的论文《具有常识的程序》中提出了"建议接受者"的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题，为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令，利用常识性知识进行推理，并从经验中学习，其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n\n### 1965\n\n哲学家 Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7，文章认为人类大脑的运作方式与计算机有着根本的不同。他预测，由于复制人类直觉和理解力方面的挑战，AI 的进步会受到限制。他的批评在引发关于 AI 的哲学和实践极限的辩论方面具有影响力。\n\nI.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8，其中有一个著名的断言：一旦创造了一台超智能机器，它就可以设计出更智能的系统，使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。\n\nJoseph Weizenbaum 开发了 ELIZA9，这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化，但他感到惊讶的是，有很多用户认为该程序有类似人类的情绪，这引发了有关 AI 和人类互动的伦理问题。\n\n斯坦福大学的 Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和 Carl Djerassi 开发了 DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着 AI 的进步，展示了系统如何执行专业任务，甚至比人类专家更好。\n\n### 1966\n\nShakey 于 20 世纪 60 年代末在 SRI 研发，是第一个能够对自己的行动进行推理的移动机器人，集感知、规划和解决问题于一身。11Marvin Minsky 在 1970 年《生活》杂志的一篇文章中预测，AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和 AI 领域的一个里程碑，尽管 Minsky 雄心勃勃的时间表被证明过于乐观。\n\n### 1969\n\nArthur Bryson 和 Yu-Chi Ho 介绍了一种优化多级动态系统的方法 - [反向传播](https://www.ibm.com/cn-zh/think/topics/backpropagation)。虽然该算法最初是为控制系统开发的，但在训练多层神经网络时却变得至关重要。。随着计算能力的进步，反向传播在 2000 和 2010 年代才开始崭露头角，从而促成了深度学习的兴起。\n\nMarvin Minsky 和 Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》，*12*，该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中，他们认为，尽管到 20 世纪 60 年代中期，对感知机进行了大量实验，但由于缺乏理论理解，相关进展已经停滞。\n\n### 1970\n\nTerry Winograd 创建了 SHRDLU，这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互，操作虚拟积木世界中的对象，这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理](https://www.ibm.com/cn-zh/topics/natural-language-processing)领域的一项早期成果，但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的 AI 语言理解的前景和挑战。\n\n### 1972 年\n\nMYCIN 由斯坦福大学开发，是最早创建的专家系统之一，用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程，并为医疗 AI 系统的开发创建了一个平台。然而，由于伦理和法律问题，它从未在临床实践中实施。\n\n### 1973\n\nJames Lighthill 向英国科学研究理事会提交了一份关于 AI 研究进展的关键报告，并得出 AI 未能兑现其早期承诺的结论。15 他认为，该领域尚未产生重大突破，导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个 AI 寒冬的爆发16，此时期人们对 AI 研究的兴趣和投资消减了。\n\n## 1980–2000\n\n### 1980\n\nWABOT-217 是日本早稻田大学开发的仿人机器人，于 1980 年开始制造，1984 年左右完成。它是继 1973 年制造的 WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流，而 WABOT-2 则更为专业，专门设计为音乐家机器人。它可以用摄像"眼睛"阅读乐谱，与人类交谈，用电子风琴演奏音乐，甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步，仿人机器人和 AI 能够执行复杂的、类似人类的任务，如艺术表达。\n\n### 1982\n\n日本启动了第五代计算机系统项目 (FGCS)，旨在开发能够进行逻辑推理和解决问题的计算机，推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于 1992 年停止，但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。\n\n### 1984 年\n\n在人工智能发展协会 (AAAI) 年会上，Roger Schank 和 Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测，对 AI 的过高期望很快就会导致投资和研究的崩溃，就像 20 世纪 70 年代中期资金减少一样。他们的预言在三年内变成现实，人们对 AI 的兴趣因未兑现承诺而减弱，导致资助减少，进展放缓。这一时期被称为第二次 AI 寒冬。\n\nSchank 和 Minsky 的警告凸显了 AI 热潮的周期性质，当技术未能满足投资者和公众的预期时，迸发的乐观情绪之后是幻灭的寒冬。\n\n### 1986\n\nDavid Rumelhart、Geoffrey Hinton 和 Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》，他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重，提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础，重新激发了人们对神经网络的兴趣，并克服了早期 AI 研究中凸显的一些局限性。这一发现以 Arthur Bryson 和 Yu-Chi Ho 1969 年的研究成果为基础，将反向传播算法专门应用于神经网络，克服了以往多层网络训练中的一些局限性。\n\n这一突破使人工神经网络的实际应用变得可行，并为 21 世纪前十年和 21 世纪 10 年代的深度学习革命打开了大门。\n\n### 1987\n\n在教育大会的主题演讲中，苹果公司 CEO John Sculley 展示了 Knowledge Navigator 视频，想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景，这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素，如 AI 助手、网络知识数据库和我们互联的数字世界。\n\n### 1988\n\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》，彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络，一种表示复杂概率模型的形式主义，以及在其中执行推理的算法。Pearl 的方法使 AI 系统能够在不确定的环境中做出合理的决策，影响到 AI 以外的领域，包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可，该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\n\nRollo Carpenter 开发了 Jbberwacky22，这是一个早期的[聊天机器人](https://www.ibm.com/cn-zh/topics/chatbots)，旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同，Jbberwacky 从人类交互中学习以生成更自然的对话，为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批 AI 尝试之一。\n\nIBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》，标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的 Candide 项目为例 24，使用了 220 万个英法句子对，主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习，而不是试图理解或“懂得”语言，这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\n\nMarvin Minsky 和 Seymour Papert 发布了他们 1969 年出版的《*Perceptrons*》一书的扩展版，这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中，他们反思了 AI 领域的缓慢进展，并指出由于不熟悉早期的挑战，许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求，这在早期的神经网络研究中是缺乏的。他们强调了最初的批评，同时认可了后来导致现代深度学习进步的新兴方法。\n\n### 1989 年\n\nYann LeCun 和 AT&T 贝尔实验室的研究团队取得了突破性进展，成功地将反向传播算法应用于多层神经网络，以识别手写邮政编码图像。24这是利用[卷积神经网络](https://www.ibm.com/cn-zh/topics/convolutional-neural-networks)进行深度学习的首批实际应用之一。尽管当时的硬件条件有限，但神经网络的培训大约需要三天时间，与之前的尝试相比有了显著改进。该系统在手写数字识别（邮政服务自动化的一项关键任务）方面的成功，展示了神经网络在图像识别任务方面的潜力，并为深度学习在随后几十年的爆炸式增长奠定了基础。\n\n### 1993\n\n科幻小说作家兼数学家 Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章，其中他预测超人的智慧将在未来30 年内诞生，从而从根本上改变人类文明。25Vinge 认为，技术进步，特别是 AI，将导致智能爆炸，机器将超越人类智能，并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用，并引发了 AI、伦理和未来主义社区的讨论。\n\n这一预测持续影响着有关 AI 和超级智能潜在影响的讨论，特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n\n### 1995\n\nRichard Wallace 在 Joseph Weizenbaum 的 ELIZA 计划基础上开发了聊天机器人 A.L.I.C.E.26（人工语言互联网计算机实体）。ELIZA 依靠脚本回复来模拟对话，与之不同的是，A.L.I.C.E. 利用新兴的万维网来收集和处理大量自然语言数据，使其能够进行更复杂、更流畅的对话。A.L.I.C.E. 使用一种名为 AIML（人工智能标记语言）的模式匹配技术来解析和生成回复，这使它比其前辈更具适应性和可扩展性。Wallace 的工作为会话式 AI 的进一步发展奠定了基础，对现代虚拟助手和聊天机器人产生了影响。\n\n### 1997\n\nSepp Hochreiter 和 Jürgen Schmidhuber 推出了[长短期记忆](https://video.ibm.com/recorded/131507960) (LSTM)，这种[循环神经网络](https://www.ibm.com/cn-zh/topics/recurrent-neural-networks) (RNN) 旨在克服传统 RNN 的局限性，尤其是它们无法有效捕获数据中的长期依赖关系。LSTM 网络广泛用于手写识别、语音识别、自然语言处理和时间序列预测等应用。\n\nIBM 的 Deep Blue 在六局制比赛中击败了卫冕的国际象棋世界冠军 Garry Kasparov，创造了历史。27这是计算机国际象棋程序首次在标准国际象棋比赛时间控制下击败世界冠军。Deep Blue 的胜利表明，计算机可以在高度战略性的游戏中胜过人类，长期以来，这被认为是人类智能的标志。这台机器每秒计算数百万步的能力，再加上博弈论和启发式的进步，使其能够战胜 Kasparov，巩固了 Deep Blue 在 AI 历史上的地位。\n\n该事件还引发了关于人类认知与 AI 未来关系的讨论，影响了后续在自然语言处理、自主系统等其他领域的 AI 研究。\n\n### 1998\n\nDave Hampton 和 Caleb Chung 创造了 Furby，这是第一款广受欢迎的家用机器人宠物。28Furby 可以响应触摸、声音和光，并随着时间的推移“学习”语言，从它的语言 Furbish 开始，但随着它与用户的互动，逐渐“说”更多的英语。它首次在消费产品中将机器人技术与娱乐相结合，而其模仿学习和与用户互动的能力使其成为更复杂的社交机器人的先驱。\n\nYann LeCun、Yoshua Bengio 和他们的合作者发表了关于神经网络在手写识别中应用的有影响力的论文。29他们的工作重点是使用卷积神经网络来优化反向传播算法，使其更有效地训练深度网络。通过改进反向传播过程并展示 CNN 在图像和模式识别方面的强大功能，LeCun 和 Bengio 的研究为当今广泛 AI 应用中使用的现代深度学习技术奠定了基础。\n\n## 2000–2020\n\n### 2000\n\n麻省理工学院的 Cynthia Breazeal 开发了 Kismet，这是一款旨在通过情感和社交提示与人类互动的机器人。30Kismet 配备了摄像头、麦克风和富有表现力的面部特征，能够感知和响应人类的情绪，如快乐、悲伤和惊讶。这一发展标志着社交机器人技术的一大进步，探索了机器人如何更自然地与人类互动。\n\n### 2006\n\nGeoffrey Hinton 出版了《Learning Multiple Layers of Representation》一书，其中总结了深度学习的关键突破，并概述了如何更有效地训练多层神经网络。31Hinton 的工作重点是训练具有分级连接的网络，以生成感知数据，而不是简单地对其进行分类。这种方法代表从传统神经网络向我们现在所说的深度学习的转变，使机器能够学习数据的复杂分层表示。\n\n### 2007\n\nFei-Fei Li 和她的团队在普林斯顿大学启动了 ImageNet 项目，创建了最大、最全面的注释图像数据库之一。32ImageNet 旨在通过提供涵盖数千个类别的数百万张标记图像来支持视觉对象识别软件的开发。该数据集的规模和质量推动了计算机视觉研究的进步，特别是在训练深度学习模型以识别和分类图像中的对象方面。\n\n### 2009\n\nRajat Raina、Anand Madhavan 和 Andrew Ng 发表了"使用图形处理器的大规模深度无监督学习"一文，认为图形处理器 (GPU) 在深度学习任务中的性能远远超过传统的多核 CPU。33他们证明，GPU 的超强计算能力可以彻底改变深度无监督学习方法的适用性，使研究人员能够更高效地训练更广泛、更复杂的模型。这项工作对加速 GPU 在深度学习中的应用起到了重要作用，从而在 2010 年代取得了突破性进展，为计算机视觉和自然语言处理等领域的现代 AI 应用提供了动力。\n\n西北大学智能信息实验室的计算机科学家开发了 Stats Monkey，该程序能在无需人工干预的情况下自动生成体育新闻报道。34利用比赛统计数据，Stats Monkey 可以制作关于棒球比赛的连贯叙述，包括回顾、球员表现和分析。\n\n### 2011 年\n\nIBM 的 Watson 是一款先进的自然语言问答计算机，因为参加游戏节目《Jeopardy！》，对阵该节目中最成功的两位冠军 Ken Jennings 和 Brad Rutter，并击败了他们成为头条新闻。35Watson 处理和解释自然语言的能力及其庞大的知识库使其能够快速准确地回答复杂的问题。这场胜利凸显了 AI 在复杂层面上理解人类语言和与人互动能力的进步。\n\nApple 推出集成到 iOS 操作系统中的虚拟助理 Siri。Siri 提供自然语言用户界面，允许用户通过语音命令与其设备交互。Siri 可以利用机器学习执行发送消息、设置提醒、提供建议和回答问题等任务，以适应每个用户的偏好和语音模式。这种个性化自适应的[语音识别](https://www.ibm.com/cn-zh/topics/speech-recognition)系统可为用户提供个性化体验，对于日常消费者来说，标志着人工智能驱动助手的可用性和可访问性方面实现了飞跃。\n\n### 2012\n\nJeff Dean 和 Andrew Ng 利用大型神经网络以及源自 YouTube 视频的 1,000 万张未标记图像进行了一项实验。36在实验期间，神经网络在没有事先标记的情况下学习识别数据中的模式，其间“令我们感到有趣的是”，一个神经元变得对猫的图像特别敏感。这一发现是无监督学习的证明，展示了深度神经网络如何从海量数据中自主学习特征。\n\n多伦多大学的研究人员在 Geoffrey Hinton 的带领下，设计了一种卷积神经网络，在 ImageNet 大规模视觉识别挑战赛中取得了突破性的结果。37他们的卷积神经网络（即 AlexNet）实现了 16% 的错误率，比前一年 25% 的最佳结果有了大幅提升。这一成果标志着计算机视觉领域深度学习的转折点，证明在大型数据集上进行训练时，卷积神经网络可以超越传统的图像分类方法。\n\n### 2016 年\n\nGoogle DeepMind 的 AlphaGo 击败了世界顶级围棋选手之一李世石。围棋是一种复杂的棋盘游戏，其可能的招法比宇宙中的原子还多；长期以来，围棋一直被认为是对 AI 的一个挑战。38AlphaGo 4–1 战胜李世石是 AI 领域的一个开创性时刻，展示了深度学习技术的强大，足以处理以前超出 AI 能力的高度复杂的战略任务。\n\nHanson Robotics 推出了一款非常先进的仿人机器人 -Sophia。39Sophia 可以通过图像识别和自然语言处理相结合的方式识别人脸、进行眼神交流并进行对话。\n\n### 2017\n\nFacebook 人工智能研究 (FAIR) 实验室的研究人员训练两个聊天机器人相互谈判。虽然聊天机器人被编程为用英语进行交流，但在它们的对话过程中，它们开始摆脱结构化的人类语言，创建了自己的速记语言，以便更有效地进行交流。40这种发展出乎意料，因为机器人可以在没有人工干预的情况下优化交流。为了让机器人使用人类能理解的语言，实验曾暂停，但这一事件凸显了 AI 系统自主和不可预测地演化的潜力。\n\n### 2020\n\nOpenAI 推出 GPT-3，这是一种拥有 1,750 亿个参数的语言模型，使其成为迄今为止最大、最复杂的 AI 模型之一。GPT-3 展示了生成类似人类撰写文本、进行对话、编写代码、翻译语言和基于自然语言提示进行创意写作的能力。作为[大型语言模型](https://www.ibm.com/cn-zh/topics/large-language-models) (LLM) 最早的范例之一，GPT 庞大的尺寸和规模使其能够执行各种语言任务，几乎不需要进行特定任务的训练。此示例展示了 AI 在理解和生成高度连贯语言方面的潜力。\n\nDeepMind 的 AlphaFold 2 通过氨基酸序列准确预测了蛋白质的三维结构，在生物学领域取得了突破性进展。这一成果解决了困扰科学家数十年的难题，即了解蛋白质如何折叠成其独特的三维形状。AlphaFold 2 在蛋白质结构预测方面的高准确性对疾病研究和药物开发具有重要意义，为了解疾病背后的分子机制和更有效地设计新型疗法提供了新途径。\n\n## 2021-至今\n\n### 2021\n\nMUM（多任务统一模型）是由 Google 开发的一种强大的 AI 模型，旨在通过理解和生成 75 种语言来改善搜索体验。MUM 可以执行多项任务，同时分析文本、图像和视频，从而处理更复杂、更细致的搜索查询。41与传统模型不同，MUM 可以处理多模态输入，并为涉及多个信息源的复杂问题提供全面、上下文丰富的答案。\n\nTesla 推出全自动驾驶 (FSD) Beta 版，这是一种旨在实现完全自动驾驶的高级驾驶辅助系统。FSD Beta 利用深度学习和神经网络实现复杂驾驶场景的导航，例如实时城市街道、高速公路和十字路口。它允许 Tesla 车辆在特定条件下自动转向、加速和制动，同时需要驾驶员的监督。Tesla 的 FSD Beta 版标志着该公司朝着全自动驾驶汽车的目标迈出了一步，尽管在实现自动驾驶技术广泛部署的路途上仍存在监管挑战和安全问题。\n\n### 2021–2023\n\nOpenAI 推出 DAL-E，随后推出 DAL-E 2 和 DAL-E 3，此系列[生成式 AI](https://www.ibm.com/cn-zh/topics/generative-ai) 模型能够从文本描述生成非常详细的图像。这些模型使用先进的深度学习和转换器架构，根据用户输入创建复杂、逼真和艺术化的图像。DAL-E 2 和 3 扩展了 AI 在视觉内容创建中的使用，允许用户在没有传统图形设计技能的情况下将想法转化为图像。\n\n### 2024\n\n2 月\n\nGoogle 推出有限 beta 版的 Gemini 1.5，这是一种高级语言模型，能够处理长达 1 百万个词元的上下文长度。42该模型可以处理和理解单次提示中的大量信息，提高了在复杂对话和任务中针对较长文本维护上下文的能力。Gemini 1.5 针对长输入提供了增强的记忆功能和上下文理解，代表了自然语言处理领域的显著飞跃。\n\nOpenAI 公开发布 Sora，这是一种文本转视频模型，能够根据文本描述生成长达一分钟的视频。43这项创新将 AI 生成内容的用途扩展到静态图像之外，使用户能够根据提示创建详细的动态视频片段。Sora 有望为视频内容创作开辟新的可能性。\n\nStabilityAI 宣布推出最新的文本转图像模型 Stable Diffusion 3。与 Sora 一样，Stable Diffusion 3 使用类似的架构，从文本提示生成详细的创意内容。44\n\n5 月\n\nGoogle DeepMind 推出 AlphaFold 的新扩展，有助于识别癌症和遗传病，为遗传诊断和个性化医疗提供了强大的工具。45\n\nIBM 推出 [Granite](https://www.ibm.com/cn-zh/granite) 系列生成式 AI 模型，作为其 [watsonx](https://www.ibm.com/cn-zh/watsonx) 平台的一部分。Granite 模型包含 30 亿至 340 亿个参数，专为代码生成、时间序列预测和文档处理等任务而设计。这些模型是开源的，可在 Apache 2.0 许可证下使用，属于轻量级模型，经济高效且可定制，是各种业务应用程序的理想选择。\n\n6 月\n\nApple 宣布推出 Apple Intelligence，它可将 ChatGPT 整合至全新 iPhone 和 Siri。46这种整合使 Siri 能够执行更复杂的任务，进行更自然的对话，更好地理解和执行精细的命令。\n\n9 月\n\nNotebookLM 引入了 DeepDive，这是一种新型多模态 AI，能够将源资料转换为播客结构的引人入胜的音频演示。47DeepDive 能够分析和汇总来自不同格式（包括网页、文本、音频和视频）的信息，从而为跨各种平台创建个性化和自动化内容开辟了新的机会。此功能使其成为媒体制作和教育的全能工具。\n\n[当前的 AI 趋势](https://www.ibm.com/cn-zh/think/insights/artificial-intelligence-trends)表明，生成式 AI 将会以更小、更高效的基础模型为基础，并会出现代理式 AI，其中特定 AI 模型协同工作以更快地完成用户请求。[更远的未来](https://www.ibm.com/cn-zh/think/insights/artificial-intelligence-future)，自动驾驶汽车将在高速公路上行驶，多模态 AI 将在单一平台上创建音频、视频、文本和图像，AI 助手将帮助用户规划个人生活和职业生涯。\n\n1. [A logical calculus of the ideas immanent in nervous activity](https://link.springer.com/article/10.1007/BF02478259)，springer.com，1943 年 12 月\n2. [Computing machinery and intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238)，*Mind*，1950 年 10 月\n3. [A proposal for the Dartmouth summer research project on artificial intelligence](https://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html)，Stanford.edu，1955 年 8 月 31 日\n4. [Lisp (progamming language)](https://en.wikipedia.org/wiki/Lisp_(programming_language))，wikipedia.org\n5. [Pandemonium: a paradigm for learning](https://aitopics.org/download/classics:504E1BAC)，aitopics.org\n6. [Programs with common sense](https://www-formal.stanford.edu/jmc/mcc59.pdf)，stanford.edu\n7. [Alchemy and artifical intelligence](https://www.rand.org/content/dam/rand/pubs/papers/2006/P3244.pdf)，rand.org，1965 年 12 月\n8. [Speculations concerning the first ultraintelligent machine](https://www.sciencedirect.com/science/article/abs/pii/S0065245808604180)，sciencedirect.com\n9. [ELIZA](https://en.wikipedia.org/wiki/ELIZA)，wikipedia.org\n10. [Dendral](https://en.wikipedia.org/wiki/Dendral)，wikipedia.org\n11. [Shakey the robot](https://www.sri.com/hoi/shakey-the-robot/)，sri.com\n12. [Perceptrons: an introduction to computational geometry](https://direct.mit.edu/books/monograph/3132/PerceptronsAn-Introduction-to-Computational)，MIT.edu\n13. [SHRDLU](https://hci.stanford.edu/winograd/shrdlu/)，stanford.edu\n14. [MYCIN: a knowledge-based program for infectious disease diagnosis](https://www.sciencedirect.com/science/article/abs/pii/S0020737378800492)，science.direct.com\n15. [Artificial Intelligence: a general survey](https://www.chilton-computing.org.uk/inf/literature/reports/lighthill_report/p001.htm)，chilton-computing.org.uk，1972 年 7 月\n16. [AI winter](https://en.wikipedia.org/wiki/AI_winter)，wikipedia.org\n17. [WABOT](https://www.humanoid.waseda.ac.jp/booklet/kato_2.html)，humanoid.waseda.ac.jp\n18. [Learning representations by back-propagating errors](https://www.nature.com/articles/323533a0)，nature.com，1986 年 10 月 9 日\n19. [Knowledge navigator](https://www.youtube.com/watch?v=QRH8eimU_20)，youtube.com，2008 年 4 月 29 日\n20. [Probabilistic reasoning in intelligent systems: networks of plausible inference](https://www.sciencedirect.com/book/9780080514895/probabilistic-reasoning-in-intelligent-systems)，sciencedirect.com，1988 年\n21. [Judea Pearl Turing Award](https://amturing.acm.org/award_winners/pearl_2658896.cfm)，amturing.amc.org\n22. [Jabberwacky](https://en.wikipedia.org/wiki/Jabberwacky)，wikipedia.org\n23. [A statistical approach to language translation](https://dl.acm.org/doi/10.3115/991635.991651)，acm.org，1988 年 8 月 22 日\n24. [Candide: a statistical machine translation system](https://aclanthology.org/H94-1100.pdf)，aclanthology.org\n25. [The coming technological singularity: how to survive in the post-human era](https://edoras.sdsu.edu/~vinge/misc/singularity.html)，edoras.sdsu.edu，1993\n26. [A.L.I.C.E. (Artificial Linguistic Internet Computer Entity)](https://en.wikipedia.org/wiki/Artificial_Linguistic_Internet_Computer_Entity)，wikipedia.org\n27. [Deep blue (chess computer)](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer))，wikipedia.org\n28. [Furby](https://en.wikipedia.org/wiki/Furby)，wikipedia.org\n29. [Gradient-based learning applied to document recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)，Stanford.edu，1998 年 11 月\n30. [Kismet](https://web.media.mit.edu/~cynthiab/research/robots/kismet/overview/overview.html)，mit.edu\n31. [Learning multiple layers of representation](https://www.cs.toronto.edu/~hinton/absps/tics.pdf)，toronto.edu\n32. [ImageNet](https://en.wikipedia.org/wiki/ImageNet)，wikipedia.org\n33. [Large-scale deep unsupervised learning using graphic processors](https://robotics.stanford.edu/~ang/papers/icml09-LargeScaleUnsupervisedDeepLearningGPU.pdf)，stanford.edu\n34. [The robots are coming! Oh, they\'re here](https://archive.nytimes.com/mediadecoder.blogs.nytimes.com/2009/10/19/the-robots-are-coming-oh-theyre-here/?_r=0)，nytimes.com，2009 年 10 月 19 日\n35. [Watson IBM invitational](https://www.jeopardy.com/jbuzz/news-events/watson-ibm-invitational)，jeopardy.com，2015 年 6 月 22 日\n36. [Using large-scale brain simulations for machine learning and A.I.，](https://blog.google/technology/ai/using-large-scale-brain-simulations-for/)blog.google，2012 年 6 月 26 日\n37. [ImageNet large scale visual recognition challenge 2012](https://image-net.org/challenges/LSVRC/2012/)，image-net.org\n38. [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo)，wikipedia.org\n39. [We talked to Sophia](https://www.youtube.com/watch?v=78-1MlkxyqI)，youtube.com，2017 年 12 月 28 日\n40. [Facebook\'s artificial intelligence robots shut down after they start talking to each other in their own language](https://www.independent.co.uk/life-style/facebook-artificial-intelligence-ai-chatbot-new-language-research-openai-google-a7869706.html)，independent.co.uk，2017 年 7 月 31 日\n41. [How will Google MUM affect your search ranking in 2024?](https://learn.g2.com/google-mum)，learn.g2.com，2023 年 8 月 7 日\n42. [Our next-generation model: Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)，blog.google，2024 年 2 月 15 日\n43. [Sora](https://openai.com/index/sora/)，openai.com\n44. [Stable diffusion 3](https://stability.ai/news/stable-diffusion-3)，stability.ai，2024 年 2 月 22 日\n45. [AlphaFold 3 predicts the structure and interactions of all of life’s molecules](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/)，blog.google，2024 年 5 月 8 日\n46. [Apple intelligence](https://www.apple.com/newsroom/2024/06/introducing-apple-intelligence-for-iphone-ipad-and-mac/)，apple.com，2024 年 6 月 10 日\n47. [NotebookLM now lets you listen to a conversation about your sources](https://blog.google/technology/ai/notebooklm-audio-overviews/)，blog.google，2024 年 9 月 11 日\n\n[博客   AI 的未来：塑造未来 10 年的趋势 \n\n深入了解 AI 的未来，到 2034 年，创新将如何重塑行业。深入了解 AI 在社会中不断演变的角色、其技术进步以及将影响其对决策和自动化的影响的道德考虑。](https://www.ibm.com/cn-zh/think/insights/artificial-intelligence-future)\n\n## Think 时事通讯\n\n来自 Think 的最新 AI 和技术洞察\n\n [立即注册](https://www.ibm.com/cn-zh/forms/news-mkt-52954)\n\n相关解决方案    [watsonx.ai 中的基础模型 \n\n深入了解 watsonx 组合中基础模型库，从容自信地为您的业务扩展生成式 AI\n\n 深入了解 watsonx.ai](https://www.ibm.com/cn-zh/products/watsonx-ai/foundation-models)   [IBM Maximo Visual Inspection \n\nIBM Maximo Visual Inspection 是一个无代码计算机视觉平台，旨在实现视觉检查流程自动化。深入了解资源、自助演示、产品导览和解决方案简介。\n\n 了解 IBM Maximo Visual Inspection](https://www.ibm.com/cn-zh/products/maximo/visual-inspection)   [人工智能 (AI) 咨询服务 \n\nIBM® Consulting 正在与全球客户和合作伙伴展开合作，共同开创 AI 的未来。我们由 20,000 多名 AI 专家组成的多元化全球团队可帮助您在整个企业中快速、从容地设计并扩展尖端的 AI 解决方案和自动化功能。\u200b\n\n 深入了解 IBM AI 咨询服务](https://www.ibm.com/cn-zh/consulting/artificial-intelligence)\n\n## 资源\n\n  \n\nIBM AI Academy\n\nAI 教育\n\n \n\n \n\n\n如何使用预处理来优化 Watson Visual Recognition 结果\n\n \n\n\nAI 的未来是开放的\n\n博客\n\n使用面向 AI 构建器的新一代企业级开发平台 IBM watsonx.ai，可以训练、验证、调整和部署生成式 AI、基础模型和机器学习功能。使用一小部分数据，即可在很短的时间内构建 AI 应用程序。\n\n    [深入了解 watsonx.ai](https://www.ibm.com/cn-zh/products/watsonx-ai)   [预约实时演示](https://www.ibm.com/cn-zh/forms/mkt-demo-dataaiwatsonxai)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99486035, 'save_path': None}}, {'paper_id': '', 'title': '人工智能发展简史 - 中央网信办', 'authors': [], 'abstract': '[设为首页](###)[加入收藏](###)[手机版](//wap.cac.gov.cn/)[繁体](/###)\n\n* ### [首 页](//www.cac.gov.cn/index.htm)\n* ### [时政要闻](//www.cac.gov.cn/yaowen/szyw/A093601index_1.htm)\n* ### [网信政务](//www.cac.gov.cn/wxzw/A0937index_1.htm)\n* ### [互动服务](//www.cac.gov.cn/hdfw/A0938index_1.htm)\n* ### [热点专题](//www.cac.gov.cn/gzzt/ztzl/A092001index_1.htm)\n\n当前位置：[首页](/)>[正文](javascript:void(0);)\n\n* [首页](//wap.cac.gov.cn/phoneindex.htm)\n* [时政要闻](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=1)\n* [网信政务](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=2)\n* [互动服务](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=3)\n* [热点专题](//wap.cac.gov.cn/phoneindex.htm?defaultIndex=4)\n\n# 人工智能发展简史\n\n2017年01月23日 11:10 来源： 网络传播杂志 \n\n[【打印】](javascript:window.print())【纠错】\n\n“人工智能之父” 艾伦·图灵。\n\n**1、 人工智能的诞生（20世纪40～50年代）**\n\n\u3000\u30001950年：图灵测试\n\n\u3000\u30001950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n\n\u3000\u30001954年：第一台可编程机器人诞生\n\n\u3000\u30001954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n\n\u3000\u30001956年：人工智能诞生\n\n\u3000\u30001956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n\n\u3000\u30001966年~1972年：首台人工智能机器人Shakey诞生\n\n\u3000\u30001966年~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n\n\u3000\u30001966年：世界上第一个聊天机器人ELIZA发布\n\n\u3000\u3000美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n\n\u3000\u30001968年：计算机鼠标发明\n\n\u3000\u30001968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n\n**3、 人工智能的低谷（20世纪70～80年代）**\n\n\u3000\u300020世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n\n\xa0\xa0\xa0\xa01997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n\n**4、 人工智能的繁荣期（1980年~1987年）**\n\n\u3000\u30001981年：日本研发人工智能计算机\n\n\u3000\u30001981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n\n\u3000\u30001984年：启动Cyc（大百科全书）项目\n\n\u3000\u3000在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n\n\u3000\u30001986年：3D打印机问世\n\n\u3000\u3000美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n\n**5、 人工智能的冬天（1987年~1993年）**\n\n\u3000\u3000“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n\n**6、 人工智能真正的春天（1993年至今）**\n\n\u3000\u30001997年：电脑深蓝战胜国际象棋世界冠军\n\n\u3000\u30001997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n\n\u3000\u30002011年：开发出使用自然语言回答问题的人工智能程序\n\n\u3000\u30002011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n\n\u3000\u30002012年：Spaun诞生\n\n\u3000\u3000加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n\n\u3000\u30002013年：深度学习算法被广泛运用在产品开发中\n\n\u3000\u3000Facebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n\n\u3000\u30002015年：人工智能突破之年\n\n\u3000\u3000Google开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n\n\u3000\u30002016年：AlphaGo战胜围棋世界冠军李世石\n\n\u3000\u30002016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）\n\n\xa02016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n\n**大事记**\n\n\u3000\u3000① 1942年：“机器人三定律”提出\n\n\u3000\u3000美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。\n\n\u3000\u3000② 1956年：人工智能的诞生\n\n\u3000\u3000达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n\n\u3000\u3000③ 1959年：第一代机器人出现\n\n\u3000\u3000德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n\n\u3000\u3000④ 1965年：兴起研究“有感觉”的机器人\n\n\u3000\u3000约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n\n\u3000\u3000⑤ 1968年：世界第一台智能机器人诞生\n\n\u3000\u3000美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n\n\u3000\u3000⑥ 2002年：家用机器人诞生\n\n\u3000\u3000美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n\n\u3000\u3000⑦ 2014年：机器人首次通过图灵测试\n\n\u3000\u3000在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n\n\u3000\u3000⑧ 2016年：AlphaGo打败人类\n\n\u3000\u30002016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。\n\n关闭\n\n中央网络安全和信息化委员会办公室 中华人民共和国国家互联网信息办公室 © 版权所有 [联系我们](//www.cac.gov.cn/hdfw/lxwm/A093812index_1.htm)\n\n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司\u3000[京ICP备14042428号](https://beian.miit.gov.cn/)\u3000[京公网安备11040102700108号](https://www.beian.gov.cn//www.cac.gov.cn/registerSystemInfo?recordcode=11040102700108)\n\n* ###### 学习强国\n\n  *◆* ◆\n* ###### 微信\n\n  *◆* ◆\n* ###### 返回顶部\n\n中华人民共和国国家互联网信息办公室 © 版权所有\n\nProduced By CMS 网站群内容管理系统 publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9943141, 'save_path': None}}, {'paper_id': '', 'title': '人工智能70年：科幻和現實的交融 - BBC', 'authors': [], 'abstract': '[BBC News, \n中文](/zhongwen/trad)\n\n**人類**\n**飛跑著**\n**進入**\n**人工智能（**\n**AI**\n**）**\n**時代。**\n**粗略估算現在人們日常生活中有20多種尋常的**\n**AI**\n**，從垃圾郵件過濾器到叫車軟件。**\n\nAI被分為兩類，這些執行具體任務的AI屬於「弱人工智能」；另一類「強人工智能」，又稱「通用人工智能」（AGI） ，能夠模仿人類思維、決策，有自我意識，自主行動。這一類目前主要出現在科幻作品中，還沒有成為科學現實。\n\n* [聊天機器人最難理解的十大詞匯](/ukchina/trad/vert-fut-46424329)\n* [假如人工智能（AI）有靈魂：這意味著什麼](/ukchina/trad/vert-fut-44641617)\n* [AI和媒體 機器與記者編輯的多重關係](/zhongwen/trad/science-45591003)\n* [人工智能面臨的最大挑戰不是技術？](/ukchina/trad/vert-fut-39433415)\n\n埃德利安·梅耶（Adrienne Mayor）在《諸神與機器人》（Gods and Robots）甚至把希臘古城亞歷山大港稱為最初的硅谷，因為那裏曾經是無數機器人的家園。\n\n[Skip 熱讀 and continue reading](#end-of-recommendations)\n\n**熱讀**\n\n* [美國愛潑斯坦性侵案：解密文件披露百多名政商名人](/zhongwen/trad/world-67890505)\n* [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](https://www.bbc.com/zhongwen/articles/cvgrmn683pro/trad)\n* [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](https://www.bbc.com/zhongwen/articles/cn0y72184yko/trad)\n* [為何中國如此迅速處決明氏家族11人？](https://www.bbc.com/zhongwen/articles/c5yvzn83ye1o/trad)\n\nEnd of 熱讀\n\n除了古希臘、羅馬，其他古文明也不乏人類對"複製自己"的探索。猶太人傳說中有生命的泥人，印度傳說中，守衛佛祖舍利子的機器人武士（模仿古希臘羅馬自動人形機的設計）；佛教傳入前日本的神照神社，中國的兵馬俑，後來又有了達芬奇的機器人武士、會下象棋的木頭人"土耳其"，等等。雖然跟現在一般理解的人工智能似乎風馬牛不相干，但這些嘗試都體現了人類複製、模擬自身的夢想。\n\n不過，法國索邦大學計算機學教授讓-加布裏埃爾·加納西亞（Jean-Gabriel Ganascia）認為，古代神話中人形物體被賦予生命，與今天人們想象和擔憂的「通用人工智能」，即具有超級智能的機器，都更多屬於想象而不是科學現實，至少目前如此。\n\n在開創人工智能學科的先驅者心目中，AI的初衷是用機器來模擬人類、動植物和物種種群的演變，這個學科立足於這樣一種猜想：所有認知功能都可以被精確描述，從而有可能在計算機上複製。\n\n作為現代科技學科的AI歷史很短，但不乏跌宕坎坷。\n\n* [「無頭屍」引發爭議：殺死機器人是否可能](/ukchina/trad/47655496)\n* [人工智能公司為什麼要不停的砸玻璃？](/ukchina/trad/vert-fut-38841260)\n* [「柔情」機器人：人類怎麼對機器人動了真感情](/ukchina/trad/vert-cap-44495182)\n\n## 1940年代——奠基\n\n1943年，美國神經科學家麥卡洛克（Warren McCulloch）和邏輯學家皮茨（Water Pitts）提出神經元的數學模型。後來有人說現代AI夢就誕生在那個時候。\n\n那個夢是一篇題目繞口的論文，《神經活動中內在思想的邏輯演算》（A Logical Calculus of Ideas Immanent in Nervous Activity）。這篇論文被視為人工智能學科的奠基石。現在大熱的「深度學習」，前身是人工神經網絡，而其基礎就是神經元的數學模型。\n\n這篇論文的發表也標誌著人工智能學科三大派之一的仿生學派誕生。這個學派從神經網絡的連接機制著手來發展人工智能，被稱為連接主義派，後來符號邏輯派佔上風幾十年，神經仿生派一直到二十世紀八、九十年代才翻身，以新連接主義面目復興。\n\nAI的另一塊基石是加拿大神經心理學家赫布（Donald Hebb）1949年提出「赫布規則」，簡單說就是兩個細胞如果總是同時被激活，那麼它們之間就有某種關聯，關聯度與同時激活概率成正比關係。這個規則今天用在機器自動學習算法中。\n\n* [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n\n## 1950年代——起步\n\n現在人們普遍把1956年叫做AI元年。人工智能作為一門學科，在這個時期起步並取得了早期成功。\n\n**圖靈和圖靈機**\n\n英國電腦奇才、密碼學家、邏輯學家、計算機與人工智能之父圖靈（Alan Turing）曾想，機器能不能模仿人類的認知、學習過程，用邏輯推理和已有的信息來解決問題，作出決定？他1936年提出圖靈機的設想，就是一種抽象計算模型，實質上是一種數學邏輯機。\n\n1950年，圖靈發表《計算機與智能》（Computing Machineray and Intelligence）論文，文中闡述了"模仿遊戲"的設想和測試方式，就是後來大家熟知的圖靈測試。這篇文章是對機器模仿人類智能的深度思考和系統論述。\n\n**達特茅斯人工智能夏季研討會**\n\n人工智能（artificial intelligence）這個詞1955年首次亮相。當時4位AI鼻祖寫了一份提案，申請開一個研討會研究人工智能。他們估計兩個月，10個人參加，就足以取得重大突破。他們是麥卡錫（John McCarthy）、明斯基（Marvin Minsky）、羅切斯特（Nathaniel Rochester）和香農（Claude Shannon）。\n\n申請獲准，暑期研討會於1956年8月31日在新罕布什爾州達特茅斯學院召開。\n\n研討會被普遍 視為人工智能作為一門學科的創立，所以這一年算AI元年。\n\n**早期**\n**成果**\n\nAI元年後，喜訊不斷。1957年，GPS（通用問題解決器）設想問世。這個設想的原理是任何形式化的符號問題都可以用這個電腦程序來解決。提出設想的是美國卡內基梅隆大學教授、認知心理學和計算機專家紐厄爾（Allen Newell）、西蒙（Herbert A. Simon）和肖。這個設想屬於邏輯、符號派。在短短60年時間裏也經歷了冷暖。\n\n1959年，麥卡錫提出世界上第一個完整的AI系統。那是他在《具備常識的程序》中提出的能像人類一樣學習的假想程序，"Advice Taker"。同年，他和明斯基牽頭在MIT成立了人工智能實驗室。\n\n也是在這一年，塞繆爾首創了機器學習這個概念。他1956年寫的跳棋程序具有自學能力，是世界第一個。\n\n* [人工智能：嚇壞創造者的「深度造假寫手」](/zhongwen/trad/science-47361632)\n* [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n* [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n\n## 1960年——伊莉莎\n\n1961年，世界第一款工業機器人Unimate在美國新澤西的通用電氣工廠上崗試用。1966年，第一台能移動的機器人Shakey問世，就是那個會抽煙的機器人。跟Shakey同年出生的還有伊莉莎。\n\n1966年問世的伊莉莎（Eliza）可以算作今天亞馬遜語音助手Alexa、谷歌助理和蘋果語音助手Siri們的祖母，可以跟人進行書面交流。\n\n「她」沒有人形，沒有聲音，就是一個簡單的機器人程序，通過人工編寫的DOCTOR腳本跟人類進行類似心理諮詢的交談。Eliza的「父親」，後來成為MIT教授的維森鮑姆（Joseph Weizenbaum）解釋說，用這個名字，是因為人們可以教這個程序學習掌握新的語言技能，談吐越來越優雅，就像《窈窕淑女》裏被調教得十分出色的賣花姑娘伊莉莎。\n\n伊莉莎問世時，機器解決問題和釋義語音語言的苗頭已經初露端倪。但是，抽象思維、自我認知和自然語言處理功能等人類智能對機器來說還遙不可及。\n\n半個多世紀後的今天，機器人索菲亞仍需依靠事先輸入的內容才能與人交流，但能說能笑能哭，而且是美女形象。\n\n**批評聲鵲起**\n\n這個時期出現了對人工智能的尖銳批評。\n\n《煉金術與人工智能》發表於1965年，作者德雷弗斯把這篇著名的檄文跟後來陸續寫的文章集成《計算機不能幹什麼》一書，後人凡批評AI必提此書。\n\n另一個刺耳的聲音來自古德（I. J. Good）。他1965年發表了一篇對人工智能未來可能對人類構成威脅的文章，可以算「AI威脅論」的先驅。他認為機器的超級智能和無法避免的智能爆炸最終將超出人類可控範疇。後來著名科學家霍金、發明家和實業家馬斯克對人工智能的恐怖預言跟古德半個世界前的警告遙相呼應。\n\n法國計算機學家加納西亞把這段時間稱為AI發展史上的"預言者時期"，因為學科初創並取得早期成果令人欣喜，難免說些頭腦發熱的話。\n\n流傳較廣的包括美國經濟學家西蒙（Herbert Simon司馬賀）1958年預言，再過10年機器就能問鼎國際象棋世界冠軍；結果是1997年才成真。另外，AI鼻祖明斯基在1968年《2001太空漫遊》記者會上說機器智能30年內可趕超人類 ，現在只是設想。\n\n1968年，科幻大片《2001太空漫遊》上映，導演庫布裏克對人類心靈深處那個古老的渴望做了太空時代的演繹。\n\n## 1970年代－機器人問診\n\n1970年，世界第一個擬人機器人WABOT-1在日本早稻田大學誕生。\n\n除此之外，這段時間AI領域基本上是埋頭科研，主要側重研究機器模擬記憶心理學和理解機制、知識和推理。因此，這個階段AI語義知識表示技術有長足進展，進而推動了專家系統的研發。\n\n專家系統利用一流專家的知識來再現他們的思維過程；從1980年代早期開始在醫療診斷和其他一些領域廣泛應用。\n\n1972年，針對細菌感染的醫療診斷系統MYCIN問世，凖確率69%，專科醫生是80%。1978年 ，用於電腦銷售過程中為顧客自動配置零部件的專家系統XCON誕生。XCON是第一個投入商用的AI專家，也是當時最成功的一款。\n\n1979年，斯坦福大學開始研發自動駕駛技術，但世界上第一次無人駕駛汽車完成首秀是在1986年；那是一輛奔馳麵包車，德國聯邦大學研製，車上有攝像機和感應裝置。它在無人的街道上行駛速度達55mph。\n\n## 1980年代——《終結者》\n\n數據和知識積累推動計算機學習算法發展，使機器能夠利用自己的經驗自動調整編程，AI的應用突飛猛進，如指紋、語音識別等。人工智能、計算機和人造生命開始和其他學科交融，生出混合系統。\n\n1984年，美國普林斯頓大學教授、物理學家、分子生物學家和神經學家霍普菲爾德用模擬集成電路實現了自己兩年前提出的神經網絡模型，這個模型帶動了神經網絡學派的復興。深度學習大熱並取得突破。\n\n同年，深度學習"三巨頭"辛頓（Geoffrey Hinton）、本吉奧（Yoshua Bengio）和楊立昆（Yann LeCun）發表反向傳播算法論文，開啟深度學習潮流。\n\n那年，卡梅隆大片《終結者》上映，作家布魯克斯（Rodney Allen Brooks）發表《大象不下棋》，提出更高層次的AI系統設想：在與環境互動的基礎上打造人工智能。\n\n人工智能三大源頭之一，哲學，又站到聚光燈下。1981年，美國哲學家、數學家與計算機科學家普特南（Hilary W. Putnam）發表《理性、真理與歷史》，提出著名的「缸中腦」假象試驗。\n\n這本身是一個哲學命題，缸中靠營養液存活、通過電腦接收各種刺激而產生感知的大腦，實際上就是虛擬現實。這個假想為人工智能提供了啟示，也引發了對人工智能的哲學思考，也催生了許多科幻作品，比如《盜夢空間》、《源代碼》和《阿凡達》。\n\n## AI的兩個冬季\n\n1974-1980年，1987-1993年，AI遭遇兩次寒冬。\n\n第一次是因為兩份學術報告發表，導致AI領域研究經費銳減。一份是1966年在美國自動語言處理顧問委員會（ALPAC）的《語言與機器：翻譯和語言學中的計算機》（Language and Machines: Computers in Translation and Linguistics），另一份是英國萊特希爾教授（Sir James Lighthill）1973年發表的《人工智能普查報告》。這兩份報告都表達了對先前的投資未能產生預期受益的失望，結論是不應該繼續往AI這個無底洞砸錢。\n\n不過，一線的科研仍在繼續，但直接說AI的少了，諸如機器學習、信息數學、基於知識的系統和模式識別之類新詞開始湧現。\n\n出現第二個冬季則是因為桌面電腦迅速普及，AI系統的金主，包括美國國防部，覺得投資AI性價比不高，興趣大減。但到20世紀末，AI領域再度春暖花開。標誌性事件是1997年IBM深藍大勝世界象棋冠軍卡斯帕洛夫。\n\n歷史上這兩次「錢荒」，跟AI研究資金來源較單一，主要來自政府給學術機構的科研撥款。隨著AI產業化加深，越來越多研發資金來自企業。但AI領域內部的混亂、門派紛爭、各自為政的問題依然存在。\n\n## 1990年代——聊天機器人\n\n1990年代後期，人工智能與機器人和人機界面結合，產生了具有情感和情緒的智能代理，情緒／情感計算（即評估情緒的變化然後在機器上再現）得以迅速發展，尤其是對話代理（聊天機器人）。\n\n1993年，維諾爾·溫奇發表《即將來臨的技術奇點》（The Coming Technological Singularity）一文，預言30年後人類將能夠創造具有超級智慧的機器，由此走上人類終結之路。這個時刻就是後來很多人說的「奇點」。數學家霍金和企業家馬斯克都是機器終結人類說法的信眾。\n\n但對於這個奇點究竟是否存在目前仍有不同看法。\n\n1997年，IBM的深藍超級電腦擊敗世界象棋冠軍卡斯帕洛夫，西蒙1958年的預言算是實現了，儘管晚了近40年。\n\n## 21世紀——深度學習\n\n進入21世紀，許多人工智能的能力已經超越人類，比如圍棋、德州撲克，比如證明數學定理，比如學習從海量數據中自動構建知識，識別語音、面孔、指紋，駕駛汽車，處理海量的文件、物流和製造業的自動化操作。\n\n機器人可以識別和模擬人類情緒，可以充當陪伴和護理員了。AI的應用也因此遍地開花，很快進入人類生活的各個領域。\n\n深度學習和強化學習成了時代強音。\n\n一個普遍認同的說法是，2012年的ImageNet年度挑戰開啟了這一輪AI復興浪潮，把深度學習和大數據推到前台，大量投資資金湧入。ImageNet是為視覺認知軟件研究而設計建立的大型視覺數據庫，由華裔AI科學家李飛飛2007年發起；她當時是普林斯頓大學教授。\n\nImageNet挑戰是每年一度的全行業比武，比誰家的電腦視覺算法最強。2012年奪冠的多倫多大學團隊的圖像識別軟件AlexNet錯誤率比第二名低10.8%。觀察人士總結秘密武器有3個：大數據、更強的電腦、更聰明的算法。\n\n李飛飛現為美國斯坦福大學教授、斯坦福大學人工智能實驗室與視覺實驗室負責人、谷歌雲人工智能和機器學習首席科學家，斯坦福以人為本人工智能研究院共同院長。\n\n另一個值得一提的名字是樊麾，生於中國，圍棋手，職業二段，現任法國圍棋隊總教練。他2015年10月與谷歌人工智能AlphaGO較量0:5敗於對方。他對BBC中文網表示，輸給機器的感覺終身難忘。\n\n過去10年中，人工智能開始寫新聞、搶獨家，經過海量數據訓練學會了識別貓，IBM超級電腦沃森戰勝了智力競賽兩任冠軍，谷歌阿爾法狗戰勝了圍棋世界冠軍，波士頓動力的機器人Atlas學會了三級障礙跳。沃森和阿爾法狗的秘訣都是強化學習。\n\n這個領域的鎮海寶典《深度學習》2015年發表，作者辛頓、本吉奧和楊立昆1980年代就合寫了同樣開行業先河的經典論文，闡述反向傳播算法，2019年獲圖靈獎。\n\n不得不提的是索菲亞。2017年這個擬人機器人亮相時艷驚天下，與人交談語言生動、深刻，沙特搶先給"她"發公民證，後來被楊立昆揭露是個騙局。\n\n因為，索菲亞雖然具備不少先進的技術，包括仿生材料做的皮膚和逼真的面部表情，與人互動時的共情反應，但她只會說事先輸入和設置的話，不具備人們以為她擁有的應用語言智能和思想意識。很快，索菲亞銷聲匿跡。\n\n現代科學誕生前，世界上有迷信，有工匠。然後科學和技術融合，科技和迷信並存；科技和迷信之間有一片寬闊地帶，繁茂地生長著科幻，小說、影視和藝術。\n\n深度學習似乎表明人類向複製自己的原始意願又邁進了一步；人工智能的發展將繼續跌宕起伏，而人與機器的關係、人工智能帶來的倫理挑戰日益成為AI領域的焦點話題。\n\n有人預言，幾百年後，世界上的智慧智能將由3部分組成：人類智能（AI）+人類可控的人工智能+人類不可控的機器智能。\n\n這一切又都離不開人類文明曙光初現時一個古老的夢想。\n\n想象和現實從來不可能一刀兩斷切割，科技和商業更是如影隨形，但區分人工智能（AI）和通用人工智能（AGI），或許有助於減緩第三次「AI寒冬」將至的擔憂和焦慮。\n\n**．**\n\n## 更多相關內容\n\n* ### [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* ### [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* ### [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n* ### [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n* ### [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* ### [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n\n## 頭條新聞\n\n* ### [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](/zhongwen/articles/cvgrmn683pro/trad)\n* ### [「代孕」引爆台灣社會爭論：誰的渴望，誰的風險？](/zhongwen/articles/clyz5pd20jvo/trad)\n* ### [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](/zhongwen/articles/cn0y72184yko/trad)\n\n## 特別推薦\n\n* ### [為什麼中國將英國首相施紀賢來訪視為更大局面的一部分？](/zhongwen/articles/c1m7y585x71o/trad)\n* ### [中國生育率破1新生數回到乾隆年間水平 預測失準後的斷崖式下跌](/zhongwen/articles/cr4kkydv75ro/trad)\n* ### [「時隔太久」：施紀賢習近平在北京「談及人權問題」](/zhongwen/articles/c368y7ex161o/trad)\n* ### [英國首相八年來首次訪華\u3000施紀賢亞洲行的時機和任務](/zhongwen/articles/cx2we08l9qpo/trad)\n* ### [中國調查解放軍最高級將領張又俠 官媒批其「造成極大破壞」](/zhongwen/articles/cx2k4pxdyyzo/trad)\n\n## 更多相關內容\n\n* ### [人工智能：機器人的科幻版vs現實版](/zhongwen/trad/science-39793434)\n* ### [80年前有個機器人叫羅伯特 會抽煙](/zhongwen/trad/world-40123445)\n* ### [養老危機：將來陪伴你的可能是機器人](/zhongwen/trad/science-38798230)\n* ### [機器人刺秦皇—香港動畫人的科幻狂想](/zhongwen/trad/chinese-news-44002560)\n* ### [來見識一下機器人摩托車賽車手](/ukchina/trad/vert-fut-43085904)\n* ### [機器人能否終結令人抓狂的客服電話？](/ukchina/trad/vert-tra-41076500)\n\n## 頭條新聞\n\n* ### [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](/zhongwen/articles/cvgrmn683pro/trad)\n* ### [「代孕」引爆台灣社會爭論：誰的渴望，誰的風險？](/zhongwen/articles/clyz5pd20jvo/trad)\n* ### [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](/zhongwen/articles/cn0y72184yko/trad)\n\n## 特別推薦\n\n* ### [為什麼中國將英國首相施紀賢來訪視為更大局面的一部分？](/zhongwen/articles/c1m7y585x71o/trad)\n* ### [中國生育率破1新生數回到乾隆年間水平 預測失準後的斷崖式下跌](/zhongwen/articles/cr4kkydv75ro/trad)\n* ### [「時隔太久」：施紀賢習近平在北京「談及人權問題」](/zhongwen/articles/c368y7ex161o/trad)\n* ### [英國首相八年來首次訪華\u3000施紀賢亞洲行的時機和任務](/zhongwen/articles/cx2we08l9qpo/trad)\n* ### [中國調查解放軍最高級將領張又俠 官媒批其「造成極大破壞」](/zhongwen/articles/cx2k4pxdyyzo/trad)\n\n## 熱門內容\n\n1. 1\n\n   [美國愛潑斯坦性侵案：解密文件披露百多名政商名人](/zhongwen/trad/world-67890505)\n2. 2\n\n   [「你憑什麼覺得自己是例外？」——中美「斬殺線」的討論與民眾的質疑](https://www.bbc.com/zhongwen/articles/cvgrmn683pro/trad)\n3. [馬斯克的SpaceX準備將100萬顆AI算力衛星送入太空](https://www.bbc.com/zhongwen/articles/cn0y72184yko/trad)\n4. [為何中國如此迅速處決明氏家族11人？](https://www.bbc.com/zhongwen/articles/c5yvzn83ye1o/trad)\n\n7. [此前從未公開的愛潑斯坦島嶼新照片曝光](https://www.bbc.com/zhongwen/articles/cq60906prr3o/trad)\n9. [特權階層接連爆雷，中國網民震怒](https://www.bbc.com/zhongwen/articles/cdxl7w63p1po/trad)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.bbc.com/zhongwen/trad/science-48380424', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.96323055, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 16:14:38,099 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=9, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 16:14:38,100 - __main__ - INFO - handle_download: downloaded=9
2026-02-03 16:14:38,100 - __main__ - INFO - call_tool payload: source_tool=tavily_download, result_type=papers, count=9
2026-02-03 16:14:38,100 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=9
2026-02-03 16:14:38,101 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '[PDF] 人工智能的历史回顾和发展现状 - 集思未来', 'authors': [], 'abstract': "第 38 卷第 3 期 ■特约专稿 157 doi:10.3969/j.issn.0253-9608.2016.03.001 人工智能的历史回顾和发展现状 顾险峰 † 纽约州立大学石溪分校计算机系，纽约 11794 摘要 简略地回顾了人工智能的历史和发展现状。分析比较了人工智能两大领域：符号主义和连接主义，同时介绍了各个领 域的主要原理和方法。着重回顾了深度学习的历史、复兴的原因和主要的应用。 关键词 人工智能；连接主义；符号主义；深度学习；图像识别；语音识别；神经网络 最近，谷歌的阿尔法狗击败了围棋九段李 世石，举世震惊。有为人工智能的发展欢呼雀跃 者，也有为人类前途命运忧心忡忡者；有对机器 蛮力不屑一顾者，也有对人类失去优越感而沮丧 彷徨者。目前，人工智能的浪潮汹涌澎湃，在视 觉图像识别、语音识别、文本处理等诸多方面人 工智能已经达到或超越人类水平，在视觉艺术、 程序设计方面也开始崭露头角，令人惊叹不已。 人们已经相信，在个人电脑时代、网络时代、手 机时代之后，整个社会已经进入人工智能时代。 这里，我们考察人工智能发展的简要历 史、目前的局限和未来的潜力，特别是将人类脑 神经认知和人工神经网络认知进行对比，从而对 人工智能有一个公正客观，而又与时俱进的认 识。 从历史上看，人类的智能主要包括归纳总结 和逻辑演绎，对应着人工智能中的联结主义(如 人工神经网络)和符号主义(如吴文俊方法)。人类 大量的视觉听觉信号的感知处理都是下意识的， 是基于大脑皮层神经网络的学习方法；大量的数 学推导、定理证明是有强烈主观意识的，是基于 公理系统的符号演算方法。 1 符号主义 古希腊人将欧几里得几何归纳整理成欧几 里得公理体系，整个宏伟的理论大厦奠基于几条 不言自明的公理，整个大厦完全由逻辑构造出 来，美轮美奂，无懈可击。这为整个人类科学发 展提供了一套标准的范式。后来，牛顿编撰他 的鸿篇巨著《自然哲学的数学原理》也遵循公理 体系的范式，由公理到定义、引理、定理再到推 论。人类的现代数学和物理知识最终都被系统化 整理成公理体系，比如爱因斯坦的广义相对论也 是遵循公理体系的范式。当然也存在例外。例 如，虽然量子理论已经为人类科技带来天翻地覆 的革命，但是量子理论的公理体系目前还没有建 立起来。符号主义的主要思想就是应用逻辑推理 法则，从公理出发推演整个理论体系。 人工智能中，符号主义的一个代表就是机 器定理证明，吴文俊先生创立的吴文俊方法是其 巅峰之一。目前基于符号计算的机器定理证明的 理论根基是希尔伯特定理：多元多项式环中的理 想都是有限生成的。我们首先将一个几何命题的 条件转换成代数多项式，同时把结论也转换成多 †通信作者，顾险峰与丘成桐先生等合作开创了计算共形几何这一交叉学科，他们合著出版了该领域的权威专 著《计算共形几何》(Computational Conformal Geometry)。E-mail: gu@cs.stonybrook.edu Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 158 项式，然后证明条件多项式生成的根理想包含结 论对应的多项式，即将定理证明转换为根理想成 员判定问题。一般而言，多项式理想的基底并不 唯一，Groebner基方法和吴方法可以生成满足特 定条件的理想基底，从而都可以自动判定理想成 员问题。因此理论上代数范畴的机器定理证明可 以被完成，但是实践中这种方法有重重困难。 首先，从哲学层面上讲，希尔伯特希望用 公理化方法彻底严密化数学基础。哥德尔证明了 对于任何一个包含算术系统的公理体系，都存在 一个命题，其真伪无法在此公理体系中判定。换 言之，这一命题的成立与否都与此公理体系相 容。一方面，这意味着我们无法建立包罗万象的 公理体系，无论如何，总存在真理游离在有限公 理体系之外；另一方面，这也意味着对于真理的 探索过程永无止境。 其次，从计算角度而言，Groebner基方法和 吴方法所要解决的问题的本质复杂度都是超指数 级别的，即便对于简单的几何命题，其机器证明 过程都可能引发存储空间的指数爆炸，这揭示了 机器证明的本质难度。吴方法的成功有赖于大多 数几何定理所涉及的代数计算问题是有结构的， 因而可以快速求解。 第三，能够用理想生成的框架证明的数学 命题，其本身应该是已经被代数化了。如所有的 欧几里得几何命题，初等的解析几何命题。微分 几何中许多问题的代数化，本身就非常具有挑战 性。例如黎曼流形的陈省身-高斯-博内定理： 流形的总曲率是拓扑不变量。如果没有嘉当发明 的外微分和活动标架法，这一定理的证明就无法 被代数化。拓扑学中的许多命题的代数化本身也 是非常困难的，比如众所周知的布劳威尔不动点 定理：我们用咖啡勺缓慢均匀搅拌咖啡，然后抽 离咖啡勺，待咖啡静止后，必有一个分子，其搅 拌前和搅拌后的位置重合。这一命题的严格代数 化是一个非常困难的问题。吴先生的高足高小山 研究员突破性的微分结式理论，系统地将这种机 器证明方法从代数范畴推广到微分范畴 [1]。 最后，机器定理证明过程中推导出的大量 符号公式，人类无法理解其内在的几何含义，无 法建立几何直觉。而几何直觉和审美，实际上是 指导数学家在几何天地中开疆拓土的最主要的原 则。机器无法抽象出几何直觉，也无法建立审美 观念，因此虽然机器定理证明经常对于已知的定 理给出令人匪夷所思的新颖证明方法，但是迄今 为止，机器并没有自行发现深刻的未知数学定 理。 比如，人类借助计算机完成了地图四色定 理的证明，但是对于这一证明的意义一直富有争 议。首先，这种暴力证明方法没有提出新的概 念、新的方法；其次，这个证明没有将这个问题 和其他数学分支发生深刻内在的联系。数学中， 命题猜测的证明本身并不重要，真正重要的是证 明所引发的概念思想、内在联系和理论体系。因 此，许多人认为地图四色定理的证明实际上“验 证”了一个事实，而非“证明”了一个定理。目 前，机器定理证明的主流逐渐演变成机器验证。 因此，和人类智慧相比，人工智能的符号主义方 法依然处于相对幼稚的阶段。 即便如此，人工智能在某些方面的表现已 经超越人类。例如，基于符号主义的人工智能专 家系统IBM的沃森，在电视知识竞赛Jeopardy中 表现出色，击败人类对手，赢得冠军。目前， IBM进一步发展沃森认知计算平台，结合深度卷 积神经网络后获得了更强的数据分析与挖掘能 力，在某些细分疾病领域已能达到顶级医生的医 疗诊断水平。 2 联结主义 人工智能中的联结主义的基本思想是模拟 人类大脑的神经元网络。David Hunter Hubel 和 Torsen Wiesel(图1)共同获得了1981年的诺贝尔生 理学或医学奖。1959年，Hubel和Wiesel在麻醉 的猫的视觉中枢上插入了微电极，然后在猫的眼 前投影各种简单模式，同时观察猫的视觉神经元 的反应。他们发现：猫的视觉中枢中有些神经元 对于某种方向的直线敏感，另外一些神经元对于 另外一种方向的直线敏感；某些初等的神经元对 于简单模式敏感，而另外一些高级的神经元对于 复杂模式敏感，并且其敏感度和复杂模式的位置 第 38 卷第 3 期 ■特约专稿 159 图1 1981年的诺贝尔生理学或医学奖得主 David Hunter Hubel 和Torsen Wiesel 与定向无关。这证明了视觉中枢系统具有由简单 模式构成复杂模式的功能，也启发了计算机科学 家发明人工神经网络。 后来通过对猴子的视觉中枢的解剖，将猴 子的大脑皮层曲面平展在手术台表面上，人们发 现从视网膜到第一级视觉中枢的大脑皮层曲面的 映射(retinotopic mapping)是保角映射 (conformal mapping) [2]。保角变换的最大特点是局部保持形 状，但是忽略面积大小(图2)。这说明视觉处理 对于局部形状非常敏感。 图2 三维曲面到平面的保角映射 人们逐步发现，人类具有多个视觉中枢， 并且这些视觉中枢是阶梯级联，具有层次结构。 人类的视觉计算是一个非常复杂的过程。在大脑 皮层上有多个视觉功能区域(v1 至 v5等)，低级 区域的输出成为高级区域的输入。低级区域识别 图像中像素级别的局部的特征，例如边缘折角结 构，高级区域将低级特征组合成全局特征，形成 复杂的模式，模式的抽象程度逐渐提高，直至语 义级别。 如图3所示，毕加索的名画《格尔尼卡》 (Guernica)中充满了抽象的牛头马面、痛苦嚎哭的 人脸、扭曲破碎的肢体。我们却可以毫不费力地 辨认出这些夸张的几何形体。其实，尽管图中大 量信息丢失，但是提供了足够的整体模式。由此 可见，视觉高级中枢忽略色彩、纹理、光照等局 部细节，侧重整体模式匹配和上下文关系，并可 以主动补充大量缺失信息。 这启发计算机科学家将人工神经网络设计 成多级结构，低级的输出作为高级的输入。最 近，深度学习技术的发展，使得人们能够模拟视 图3 毕加索的名画《格尔尼卡》 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 160 觉中枢的层级结构，考察每一级神经网络形成的 概念。图4显示一个用于人脸识别的人工神经网 络经过训练后习得的各层特征。底层网络总结出 各种边缘结构，中层网络归纳出眼睛、鼻子、嘴 巴等局部特征，高层网络将局部特征组合，得到 各种人脸特征。这样，人工神经网络佐证了视觉 中枢的层次特征结构。 3 深度学习的兴起 人工神经网络在20世纪80年代末和90年代 初达到巅峰，随后迅速衰落，其中一个重要原因 是因为神经网络的发展严重受挫。人们发现，如 果网络的层数加深，那么最终网络的输出结果对 于初始几层的参数影响微乎其微，整个网络的训 练过程无法保证收敛。同时，人们发现大脑具有 不同的功能区域，每个区域专门负责同一类的任 务，例如视觉图像识别、语音信号处理和文字处 理等等。而且，在不同的个体上，这些功能中枢 在大脑皮层上的位置大致相同。在这一阶段，计 算机科学家为不同的任务发展出不同的算法。例 如：为了语音识别，人们发展了隐马尔科夫链模 型；为了人脸识别，发展了Gabor滤波器、SIFT 特征提取算子、马尔科夫随机场的图模型。因 此，在这个阶段人们倾向于发展专用算法。 但是，脑神经科学的几个突破性进展使人 们彻底改变了看法。在2000年，Jitendra Sharma 在《自然》上撰文 [3]，汇报了他们的一个令人耳 目一新的实验。Sharma把幼年鼬鼠的视觉神经 和听觉神经剪断，交换后接合，眼睛接到了听觉 中枢，耳朵接到了视觉中枢。鼬鼠长大后，依 然发展出了视觉和听觉。这意味着大脑中视觉和 听觉的计算方法是通用的。在2009年，Vuillerme 和Cuisinier为盲人发明了一套装置 [4]，将摄像机 的输出表示成二维微电极矩阵，放在舌头表面。 盲人经过一段时间的学习训练，可以用舌头“看 到”障碍物。在2011年，人们发现许多盲人独自 发展出一套“声纳”技术，他们可以通过回声 来探测并规避大的障碍物。Thaler等人的研究表 明，他们的“声纳”技术用的并不是听觉中枢， 而是原来被废置的视觉中枢。 种种研究表明，大脑实际上是一台“万用 学习机器”(universal learning machine)，同样 的学习机制可以用于完全不同的应用。人类的 DNA并不提供各种用途的算法，而只提供基本 的普适的学习机制。人的思维功能主要是依赖于 学习所得，而后天的文化和环境决定了一个人的 思想和能力。换句话而言，学习的机制人人相 同，但是学习的内容决定了人的思维(mind)。 人的大脑具有极强的可塑性，许多功能取 决于后天的训练。例如，不同民族语言具有不同 的元音和辅音，阿拉伯语最为复杂，日语相对简 单。出生不久的婴儿可以辨别听出人类能够发出 的所有元音和辅音，但是在5岁左右，日本幼儿 已经听不出很多阿拉伯语中的音素了。同样，欧 洲人可以非常容易地辨认本民族面孔，但是非常 容易混淆亚洲人面孔。人们发现，如果大脑某个 半球的一个区域受损并产生功能障碍，随着时间 流逝，另一半球的对称区域就会“接替”受损区 域，掌管相应功能。这些都表明大脑神经网络具 有极强的可塑性。 大脑学习算法的普适性和可塑性一直激励 着计算机科学家不懈地努力探索。历史性的突 破发生在2006年左右，计算机科学家Geoffrey 图4 深度学习神经网络经学习得到的不同层次的特征 (作图: Andrew Ng) 第 38 卷第 3 期 ■特约专稿 161 Hinton、Yann Lecun和Yoshua Bengio突破深度学 习的技术瓶颈，进而引领深度学习的浪潮。 与传统神经网络相比，深度学习的最大特 色在于神经网络的层数大为增加。深度网络难以 收敛的技术瓶颈最终被打破，主要的技术突破在 于以下几点：首先是计算能力的空前增强。目前 深度网络动辄上百层，联接参数数十亿，训练样 本经常数千万直至上亿，训练算法需要在大规模 计算机集群上运行数月。这些训练过程需要非常 庞大的计算资源。计算机计算能力的提升，特别 是GPU的迅猛发展，为深度学习提供了强有力 的硬件保障。其次是数据的积累。特别是互联 网的大规模普及，智能手机的广泛使用，使得规 模庞大的图像数据集能够被采集，上传到云端， 集中存储处理。深度学习需要使用越来越大的数 据集，大数据的积累提供数据保障。再就是深度 学习网络初始化的选择。传统神经网络随机初始 化，学习过程漫长，并且容易陷入局部最优而无 法达到性能要求。目前的方法使用非监督数据来 训练模型以达到特征自动提取，有针对性地初始 化网络，加速了学习过程的收敛，提高了学习效 率。更为关键的是优化方法的改进。目前的技术 采用更加简单的优化方法，特别是随机梯度下降 方法的应用提高了收敛速率和系统稳定性。 4 神经网络简史 4.1 第一次浪潮 在1943年，科学家Warren McCulloch 和 Walter Pitts提出了神经网络作为一个计算模 型的理论。1957年，康内尔大学教授 Frank Rosenblatt提出了“感知器” (perceptron)模型。 感知器是第一个用算法来精确定义的神经网络， 第一个具有自组织自学习能力的数学模型，是日 后许多新的神经网络模型的始祖。感知器的技术 在20世纪60年代带来人工智能的第一个高潮。 1969 年，Marvin Minsky 和 Seymour Papert [5] 在出版的《感知器：计算几何简介》一书中强烈 地批判了感知器模型：首先，单层的神经网络无 法解决不可线性分割的问题，典型例子如异或 门；其次，当时的计算能力低下无法支持神经网 络模型所需的计算量。此后的十几年，以神经网 络为基础的人工智能研究进入低潮。 4.2 第二次浪潮 Minsky提出的尖锐问题后来被逐步解决。 传统的感知器用所谓“梯度下降”的算法纠错 时，其运算量和神经元数目的平方成正比，因 而计算量巨大。1986年7月，Hinton 和 David Rumelhart [6]合作在《自然》发表论文，系统地提 出了应用反向传播算法，把纠错的运算量下降到 只和神经元数目成正比。同时，通过在神经网 络里增加一个所谓隐层 (hidden layer)，反向传播 算法同时也解决了感知器无法解决的异或门难 题。 Hinton的博士后Yann Lecun于1989年发表了 论文《反向传播算法在手写邮政编码上的应用》 [7]。 他用美国邮政系统提供的近万个手写数字的样本 来训练神经网络系统，在独立的测试样本中错误 率低至5%，达到实用水准。他进一步运用“卷 积神经网络” (convoluted neural networks) 的技 术，开发出商业软件，用于读取银行支票上的手 写数字，这个支票识别系统在20世纪90年代末占 据了美国接近20%的市场。 贝尔实验室的Vladmir Vapnik在1963年提出 了支持向量机 (support vector machine，SVM) 的 算法。在数据样本线性不可分的时候，支持向量 机使用所谓“核机制”(kernel trick) 的非线性映 射算法，将线性不可分的样本转化到高维特征空 间 (high-dimensional feature space)，使其线性可 分。作为一种分类算法，从20世纪90年代初开 始，SVM在图像和语音识别上找到了广泛的用 途。在手写邮政编码的识别问题上，SVM技术 在1998年错误率降至0.8%，2002年最低达到了 0.56%，远远超越同期的传统神经网络。 这时，传统神经网络的反向传播算法遇 到了本质难题——梯度消失(vanishing gradient problem)。这个问题在1991年被德国学者 Sepp Hochreiter第一次清晰提出并阐明原因。简单地 说，就是成本函数 (cost function)从输出层反向 传播时，每经过一层，梯度衰减速度极快，学习 速度变得极慢，神经网络很容易停滞于局部最优 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 162 解而无法自拔。同时，算法训练时间过长会出现 过度拟合(overfit)，把噪音当成有效信号。SVM 理论完备、机理简单、容易重复，从而得到主流 的追捧。SVM技术在图像和语音识别方面的成 功使得神经网络的研究重新陷入低潮。 4.3 第三次浪潮 (1) 改进算法 2006年，Hinton 和合作者 [8]发表论文《深 信度网络的一种快速算法》。在这篇论文里， Hinton 在算法上的核心是借用了统计力学里的 “玻尔兹曼分布”的概念，使用所谓的“限制玻 尔兹曼机” (RBM)来学习(图5)。 图5 波尔兹曼机与限制波尔兹曼机 RBM 相当于一个两层网络，可以对神经网络 实现“没有监督的训练” (unsupervised training)。深 信度网络就是几层 RBM 叠加在一起，RBM可以从 输入数据中进行预先训练，自行发现重要特征， 对神经网络连接的权重进行有效的初始化。经过 RBM 预先训练初始化后的神经网络，再用反向传 播算法微调，效果得到大幅度提升。 2011 年，加拿大的蒙特利尔大学学者 Xavier Glorot和Yoshua Bengio发表论文《深而稀 疏的修正神经网络》 [9]。论文的算法中使用一 种称为“修正线性单元”(rectified linear unit， RELU) 的激励函数。和使用别的激励函数的模 型相比，RELU识别错误率更低，而且其有效性 对于神经网络是否进行“预先训练”并不敏感。 RELU 的导数是常数，非零即一，不存在传统激 励函数在反向传播计算中的“梯度消失问题”。 由于统计上约一半的神经元在计算过程中输出 为零，使用 RELU 的模型计算效率更高，而 且自然而然地形成了所谓“稀疏表征” (sparse representation)，用少量的神经元可以高效、灵 活、稳健地表达抽象复杂的概念。 2012年7月，Hinton发表论文《通过阻止特 征检测器的共同作用来改进神经网络》 [10]。为了 解决过度拟合的问题，论文中采用了一种新的被 称为“丢弃” (dropout) 的算法。丢弃算法的具 体实施是在每次培训中给每个神经元一定的几率 (比如 50%)，假装它不存在，计算中忽略不计。 使用丢弃算法的神经网络被强迫用不同的、独立 的神经元的子集来接受学习训练。这样网络更强 健，避免了过度拟合，不会因为外在输入的很小 噪音导致输出质量的很大差异(图6)。 图6 标准神经网络(a)与使用丢弃算法后的神经网络(b) (2) 使用GPU提高计算能力 2009年6月，斯坦福大学的Rajat Raina 和吴 恩达(Andrew Ng) [11]合作发表论文《用GPU大规 模无监督深度学习》，论文模型里的参数总数 (就是各层不同神经元之间链接的总数)达到1 亿。与之相比，Hinton在2006年的论文里用到的 参数数目只有170万。论文结果显示，使用GPU 的运行速度和用传统双核CPU相比，最快时要快 近70倍。在一个四层、1亿个参数的深信度网络 上，使用GPU把程序运行时间从几周降到一天。 2010年瑞士学者 Dan Ciresan和合作者发 表论文《Deep big simple neural nets excel on handwritten digit recognition》 [12]，其中使用的还 是20世纪80年代的反向传播计算方法，但是计算 搬移到GPU 上实现，在反向传播计算时速度比 传统 CPU 快了 40 倍。 2012 年还在斯坦福大学做研究生的黎越国 (Quoc Viet Le) 领衔，和他的导师吴恩达，以及 第 38 卷第 3 期 ■特约专稿 163 众多谷歌的科学家联合发表论文《用大规模无 监督学习建造高层次特征》 [13]。黎越国的文章中 使用了九层神经网络，网络的参数数量高达10 亿，是Ciresan 2010年论文中的模型的100倍，是 2009年Raina 论文模型的10倍。 (3) 海量的训练数据 在黎越国文章中，用于训练这个神经网络 的图像都是从谷歌的录像网站youtube上截屏获 得。1 000万个原始录像，每个录像只截取一张 图片，每张图片有4万个像素。与之相比，先前 大部分论文使用的训练图像，原始图像的数目大 多在10万以下，图片的像素大多不到1 000。黎 越国的计算模型分布式地在1 000台机器 (每台机 器有16个CPU内核)上运行，花了三天三夜才完 成培训。互联网的大规模普及，智能手机的广泛 使用，使得规模庞大的图像数据集能够被采集， 并在云端集中存储处理。大数据的积累为深度学 习提供了数据保障。 5 全面超越 5.1 图像识别 2009年，普林斯顿大学计算机系的华人学 者 (第一作者为Jia Deng)发表论文《ImageNet: A large scale hierarchical image database》，宣布 建立第一个超大型图像数据库供计算机视觉研 究者使用 [14]。2010 年，以 ImageNet 为基础的 大型图像识别竞赛ImageNet Large Scale Visual Recognition Challenge 2010 (ILSVRC2010) 第一 次举办。竞赛最初的规则是以数据库内120万个 图像为训练样本，这些图像从属于1 000多个不 同的类别，都被手工标志。经过培训过的程序， 再用于5万个测试图像评估，看看它对图像的分 类是否准确。 2012年，Hinton 教授和他的两个研究生 Alex Krizhevsky、Illya Sutskever将深度学习的最 新技术用到 ImageNet 的问题上。他们的模型是 一个总共八层的卷积神经网络，有65万个神经 元，6 000万个自由参数。这个神经网络使用了 前面两篇文章介绍过的丢弃算法和修正线性单元 (RELU)的激励函数。Hinton 教授的团队使用两 个GPU，让程序接受120万个图像训练，花了接 近6天时间。经过训练的模型，面对15万个测试 图像，预测的头五个类别的错误率只有 15.3%， 在有30个团体参与的2012年 ImageNet的竞赛 中，测试结果稳居第一。排名第二的来自日本团 队的模型，相应的错误率则高达 26.2%。这标志 着神经网络在图像识别领域大幅度超越其他技 术，成为人工智能技术突破的一个转折点。 2015 年12月的Imagenet图像识别的竞赛中， 来自微软亚洲研究院(Microsoft Research Asia, MSRA)的团队夺冠。网络深度增加，学习的效率 反而下降。为了解决有效信息在层层传递中衰减 的问题，MSRA团队尝试了一种称为“深度残余学 习” (Deep Residual Learning) 的算法。MSRA 的深 度残余学习模型，使用深达 152层的神经网络，头 五个类别的识别错误率创造了 3.57%的新低，这个 数字已经低于一个正常人的大约 5% 的错误率。 5.2 语音识别 RNN (recurrent neural network)也称循环神经 网络或多层反馈神经网络，则是另一类非常重要 的神经网络。本质上，RNN 和前馈网络的区别 是，它可以保留一个内存状态的记忆来处理一个 序列的输入，这对手写字的识别、语音识别和自 然语言处理尤为重要。 2012年10月，Geoffrey Hinton、邓力和其他 几位代表四个不同机构 (多伦多大学、微软、谷 歌、IBM) 的研究者，联合发表论文《深度神经 网络在语音识别的声学模型中的应用：四个研 究小组的共同观点》 [15]。研究者们借用了Hinton 使用的“限制玻尔兹曼机” (RBM) 的算法对神 经网络进行了“预培训”。深度神经网络模型 (DNN)被用来估算识别文字的几率。在谷歌的一 个语音输入基准测试中，单词错误率 (word error rate) 最低达到了 12.3%。 2013年3月，多伦多大学的 Alex Graves 领衔发 表论文《深度循环神经网络用于语音识别》 [16]。 论文中使用 RNN/LSTM 的技术——一个包含 三个隐层、430万个自由参数的网络，在一个 叫做 TIMIT 的基准测试中“音位错误率”达到 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 164 17.7%，优于同期的其他所有技术的表现水准。 2015年5月谷歌宣布依靠 RNN/LSTM 相关 的技术，谷歌语音 (Google Voice) 的单词错误率 降到了8% (正常人大约 4%)。 2015年12月，百度 AI 实验室的 Dario Amodei领衔发表论文《英语和汉语的端对端的 语音识别》 [17]。论文的模型使用的是 LSTM 的 一个简化的变种，叫做“封闭循环单元” (gated recurrent unit)。百度的英文语音识别系统接受了 将近12 000小时的语音训练，在 16个GPU上完成 训练需要 3～5 天。在一个叫 WSJ Eval'92 的基 准测试中，其单词错误率低至3.1%，已经超过 正常人的识别能力(5%)。在另外一个小型汉语基 准测试中，机器的识别错误率只有3.7%，而一 个五人小组的集体识别错误率则为4%。 依照这个趋势，机器在语音识别的各种基 准测试上的准确度很快将全面赶上并且超过普通 人了。这是在图像识别之后人工智能即将攻克的 另一个难关。 循环神经网络 (RNN)的本质是可以处理一个长 度变化的序列的输出和输入 (多对多)。广义地看， 如果传统的前馈神经网络做的事，是对一个函数的 优化 (比如图像识别)，那么循环神经网络做的事， 则是对一个程序的优化，应用空间宽阔得多。 5.3 艺术创作 很久以来，人们倾向于认为机器可以理解 人类的逻辑思维，却无法理解人类的丰富感情， 更无法理解人类的美学价值，当然机器也就无法 产生具有美学价值的作品。事实胜于雄辩，阿尔 法狗对局李世石下出石破天惊的一步，棋圣聂卫 平先生向阿尔法狗的下法脱帽致敬，这说明深度 学习算法已经能够自发创造美学价值。许多棋手 在棋盘方寸间纵横一生，所追寻的就是美轮美奂 的神机妙手。如此深邃优美，玄奥抽象，一夜间 变成了枯燥平淡的神经元参数，这令许多人心生 幻灭。 其实，在视觉艺术领域，人工神经网络已 经可以将一幅作品的内容和风格分开，同时向艺 术大师学习艺术风格，并把艺术风格转移到另外 的作品中，用不同艺术家的风格来渲染同样的内 容(图7) [18]。 这意味着人工神经网络可以精确量化原本 许多人文科学中模糊含混的概念，例如特定领域 中的“艺术风格”，博弈中的“棋风”，并且使 这些只可意会、无法言传的技巧风格变得朴实无 华，容易复制和推广。 5.4 其他方面 在游戏博弈方面，谷歌DeepMind团队开发 的深度Q-网络DQN在49种Atari像素游戏中，29 种达到乃至超过人类职业选手的水平。阿尔法狗 更是完胜人类围棋顶级高手。 2016 年5月，来自谷歌的 AI 实验室报道， 研究者用2 865部英文言情小说培训机器，让机 器学习言情小说的叙事和用词风格。从程序的演 化过程看，机器模型先领悟了单词之间的空格的 结构，然后慢慢认识了更多单词，由短到长，标 点符号的规则也慢慢掌握，一些有更多长期相关 性的语句结构，慢慢地也被机器掌握。 2016年5月，谷歌的DeepMind团队撰文他们 开发了一个“神经编程解释器”(NPI)，这个神 经网络能够自己学习并且编辑简单的程序，可以 取代部分初级程序员的工作了。 6 人工智能商业化浪潮 H i n t o n 教授和他的两个研究生A l e x Krizhevsky和 Ilya Sutskever于2012 年底成立了一 个名叫“深度神经网络研究”(DNN research)的公 司，3个月后就被谷歌以500万美元收购。 Hinton 从此一半时间留在多伦多大学，另外一半时间在 硅谷。两位研究生则成为谷歌的全职雇员。原来 在纽约大学教书的Yann Lecun， 2013 年底被脸书 (Facebook)聘请为人工智能研究院的总管。曾在斯 坦福大学和谷歌工作的吴恩达，2012年创立了网 上教育公司 Coursera，2014年5月被百度聘任为首 席科学家负责百度大脑的计划。 2 0 1 5 年，谷歌公布开源机器学习平台 TensorFlow；FaceBook打造其专属机器学习平台 FBLearnerFlow，大幅提高员工效率；2015年5月， 第 38 卷第 3 期 ■特约专稿 165 特斯拉创立开源人工智能系统OpenAI。其他工业巨 头也纷纷斥巨资推动人工智能的发展，例如IBM的 沃森系统、百度大脑计划、微软的同声翻译等等。 2016年的IBM正在率先推动全球人工智能的 第一次商业化浪潮与核心业务转型。目前，深度 学习的研究热点正在迅速转向基于深度卷积神经 网络的物体检测与定位/分割能力，其突破将推 动人工智能的实际应用与产业发展。目前研究热 点是将深度卷积神经网络通过监督学习获得的表 达，即所谓概念向量(thought vector)与推理、注 意力、规划与记忆进行有机整合，涉及推理/规 划、注意力、短期/长期记忆、知识学习、知识 蒸馏和知识迁移，小样本概念学习以及基于监督 和再励学习的大数据病历或棋谱的自动阅读与自 主知识学习。 随着人工智能与大数据、云平台、机器 人、移动互联网及物联网等的深度融合，人工智 能技术与产业开始扮演着基础性、关键性和前沿 性的核心角色。智能机器正逐步获得更多的感知 与决策能力，变得更具自主性，环境适应能力更 强；其应用范围也从制造业不断扩展到家庭、娱 乐、教育、军事等专业服务领域。通过将大数 图7 神经网络能够自动学习艺术风格并用不同的风格渲染同样的内容 Chinese Journal of Nature Vol. 38 No. 3 INVITED SPECIAL PAPER 166 据转化为商业直觉、智能化业务流程和差异化产 品/服务，人工智能开始逐步占据医疗、金融、 保险、律师、新闻、数字个人助理等现代服务业 的核心地位，并且不断渗入人们的日常生活。 7 展望 虽然人工智能取得了突破性进展，但是它 还是在婴幼儿时期。联结主义的方法虽然摧枯拉 朽、无坚不摧，但是依然没有坚实的理论基础。 通过仿生学和经验积累得到的突破，依然无法透 彻理解和预测。简单的神经网络学习机制加上机 器蛮力，能否真正从量变到质变，这需要时间检 验。如何通过小样本进行学习，特别是从周围 环境自主学习(增强型学习)，增加学习的泛化能 力，这些都是人工智能研究的热点问题。 目前来看，人工智能在图像识别、语音识 别、文本处理、游戏博弈、艺术美学、软件设计 等诸多方面全面赶超人类。人工智能开始逐步占 据医疗、金融、保险、律师、新闻、数字个人助 理等现代服务业的核心地位，并且不断渗入人们 的日常生活。 我们相信人工智能的发展将会为人类社会带来 又一次技术革命，人工智能的浪潮正在汹涌澎湃！ (2016年5月10日收稿)■ [1] GAO X S, LI W, YUAN C M. Intersection Theory in differential algebraic geometry: generic intersections and the differential chow form [J]. Trans Amer Math Soc, 2013, 365(9): 4575-4632.\n[2] BREWER A A, LIU J J, WADE A R, et al. Visual field maps and stimulus selectivity in humanventral occipital cortex [J]. Nature Neuroscience, 2005, 8(8): 1102-1109.\n[3] SHARMAJ, ANGELUCCI A, SUR M. Induction of visual orientationmodules in auditory cortex [J]. Nature, 2000, 404: 841-847.\n[4] VUILLERME N, CUISINIER R. Sensory supplementation through tongue electrotactile stimulation to preserve head stabilization in space in the absence of vision [J]. Investigative Ophthalmology & Visual Science, 2008, 50(1): 476-81.\n[5] MINSKY M, PAPERT S. Perceptrons: an introduction to computational geometry [M]. 1st ed. Cambridge: The MIT Press, 1969.\n[6] RUMELHART D E, HINTON G E, WILLIAMS R J. Learning representations by back propagating errors [J]. Nature, 1986, 323(6088): 533-536.\n[7] YANN L C, BOSER B E, DENKER J, et al. Backpropagation applied to handwritten zip code recognition [J]. Neural Computation, 1989, 1(4): 541-551.\n[8] HINTON G E, OSINDERO S, TEH Y W. A fast learning algorithm for deep belief nets [J]. Neural Comput, 2006, 18(7): 1527-1554.\n[9] GLOROT X, BORDES A, BENGIO Y. Deep sparse rectifier neural networks [J]. Journal of Machine Learning Research, 2011, 15: 315-323.\n[10] HINTON G E, SRIVASTAVA N, KRIZHEVSKY, et al. Improving neural networks by preventing co-adaptation of feature detectors [J]. Computer Science, 2012, 3(4): 212-223.\n[11] RAINA R, MADHAVAN A, NG A Y. Large-scale deep unsupervised learning using graphics processors[C]//Proceedings of 26th International Conference on Machine Learning, Montreal, 2009: 873-880.\n[12] DAN C C, MEIER U, GAMBARDELLA L M, et al. Deep big simple neural nets excel on handwritten digit recognition [J]. Corr, 2010, 22(12): 3207-3220. [13] LE Q V, RANZATO M A, MONGA R, et al. Building high-level features using large scale unsupervised learning [C]//Proceedings of the 29th International Conferenceon Machine Learning, Edinburgh, Scotland, UK, 2012.\n[14] DENG J, DONG W, SOCHER R, et al. ImageNet: A large-scale hierarchical image database [M]//Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference on. Miami: IEEE, 2009: 248-255.\n[15] HINTON G, DENG L, YU D, et al. Deep neural networks for acoustic modelling in speech recognition: The shared views of four research groups [J]. IEEE Signal Processing Magazine, 29(6): 82-97.\n[16] GRAVES A, MOHAMED A R, HINTON G. Speech recognition with deep recurrent neural networks [J]. 2013. arXiv:1303.5778v1 [cs.NE]. [17] AMODEI D, ANUBHAI R, BATTENBERG E, et al. Deep speech 2: end-to-end speech recognition in English and Mandarin[J]. Computer Science, 2015. arXiv:1512.02595v1 [cs.CL].\n[18] GATYS L A, ECKER A S, BETHGE M. Neural-style [EB/OL].[2016-05-10]. https://github.com/jcjohnson/neural-style.\n(编辑：段艳芳) 参考文献 Historical review and current development of artificial intelligence GU Xianfeng Department of Computer Science, State University of New York at Stony Brook, NY 11794 Abstract This work gives a brief review of the history of artificial intelligence, and analyzes the current status of the field. The main principles and methodologies of the major branches in AI included symbolism and connectionism. Furthermore, the history, and booming reasons and major applications of deep learning are introduced as well.\nKey words artificial intelligence, connectionism, symbolism, deep learning, image recognition, speech recognition, neuron network", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cdn.gecacademy.cn/oa/upload/2022-03-24%2017-49-26-%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8E%86%E5%8F%B2%E5%9B%9E%E9%A1%BE%E5%92%8C%E5%8F%91%E5%B1%95%E7%8E%B0%E7%8A%B6.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99980897, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_[PDF] 人工智能.md'}}
2026-02-03 16:14:38,108 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': '人工智能的发展时间轴：从过去到未来-百度开发者中心', 'authors': [], 'abstract': '人工智能的发展时间轴：从过去到未来-百度开发者中心\n[![logo]] \n* [登录] \n* |\n* [注册] \n### 开发者热搜* [人工智能] \n* [云原生] \n* [AI应用] \n[推荐] \n[云原生] \n[文心快码 Baidu Comate] \n[飞桨PaddlePaddle] \n[人工智能] \n[超级链] \n[数据库] \n[百度安全] \n[物联网] \n[开源技术] \n[云计算] \n[大数据] \n[开发者] \n[企业服务] \n[更多内容] \n[千帆大模型平台] \n[客悦智能客服] \n# 人工智能的发展时间轴：从过去到未来作者：[谁偷走了我的奶酪] 2024.01.08 08:38浏览量：33\n*简介：*本文将带你了解人工智能的发展历程，从早期的思想萌芽到现代的应用普及，我们将通过时间轴的方式揭示人工智能的冷知识和发展趋势。\n人工智能（AI）的发展历程可以追溯到上个世纪。在这个漫长的时间里，AI经历了多次高潮和低谷，不断推动着科技的进步。下面让我们一起沿着时间轴，了解AI的成长历程和未来展望。\n1943年，美国神经科学家Warren McCulloch和数学家Walter Pitts提出了[神经网络] 的初步概念，他们认为神经元的工作原理与逻辑门相似。这一思想成为人工智能发展的重要起点。\n1956年，美国达特茅斯学院的一次研讨会上，正式提出了“人工智能”这一概念。这次会议标志着AI作为一个独立的学术领域正式诞生。\n1957年，加拿大心理学家Frank Rosenblatt开发了感知机模型，这是一种基于神经网络的[机器学习] 模型。然而，由于当时计算机性能的限制，这一模型并未得到广泛应用。\n1966年，美国科学家Joseph Weizenbaum开发了名为Eliza的自然语言对话程序，这是最早的聊天机器人之一。Eliza能够通过简单的文本对话模拟人类对话，引起了人们对AI的关注。\n1970年，日本ATR实验室开发了名为Shakey的机器人，它是世界上最早的移动机器人之一。Shakey能够自主导航、识别物体并执行任务。\n1981年，日本科学家Satoshi Sekiguchi提出了基于规则的专家系统，这是一种基于知识的计算机系统，用于提供专业领域的建议和决策。\n1988年，美国斯坦福大学教授Fei-Fei Li和她的团队开发了用于[图像识别] 的卷积神经网络LeNet-5。虽然当时的技术有限，但这一研究为现代计算机视觉领域奠定了基础。\n1997年，IBM的超级计算机“深蓝”战胜了国际象棋世界冠军Garry Kasparov，这是计算机首次在传统智力[游戏] 中击败人类。\n2006年，加拿大多伦多大学教授Geoffrey Hinton提出了[深度学习] 的概念，这是一种模拟人脑神经网络的机器学习方法。深度学习在[语音识别] 、图像识别等领域取得了巨大成功。\n2011年，苹果公司发布Siri语音助手，成为首个在消费市场上广泛应用的智能助手。Siri能够理解语音指令并回答问题，为用户提供便利的信息和服务。\n2016年，谷歌DeepMind开发的AlphaGo战胜了围棋世界冠军李世石，这是计算机在围棋领域首次击败人类。AlphaGo使用深度学习和蒙特卡洛树搜索算法，展现了AI在复杂决策问题上的强大能力。\n2020年，Open[AI开发] 的GPT-3语言模型引发了AI文本生成的热潮。GPT-3能够生成连贯、有逻辑的文本内容，被广泛应用于[自然语言处理] 和对话系统等领域。\n未来展望：随着技术的不断进步，AI将在更多领域发挥重要作用。例如，自动驾驶、医疗诊断、金融投资等领域都将受益于AI的发展。同时，我们也需要关注AI带来的伦理和隐私问题，确保技术的可持续发展。\n### 相关文章推荐* [### 文心一言接入指南：通过百度智能云千帆大模型平台API调用\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。\n] \n[十万个为什么] 2023.10.20 16:562564931910\n* [### 从MLOps 到LMOps 的关键技术嬗变本文整理自QCon 全球软件开发大会-从 MLOps 到LMOps 分论坛的同名主题演讲] \n[百度智能云开发者中心] 2023.11.15 18:033441095\n* [### Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n[百度智能云开发者中心] 2023.03.21 10:563032831\n* [### 更轻量的百度百舸，CCE Stack 智算版发布百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的AI 工程能力面向市场推出的解决方案。] \n[百度智能云开发者中心] 2023.03.02 12:172626811\n* [### 打造合规数据闭环，加速自动驾驶技术研发今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n[百度智能云开发者中心] 2023.03.02 15:002767501\n* [### LMOps 工具链与千帆大模型平台LMOps 相关的概念以及关键技术] \n[百度智能云开发者中心] 2023.11.17 15:492395533\n### 发表评论登录后可评论，请前往[登录] 或[注册] \n评论### 开发者关注产品榜* [\n*1*\n### 百度千帆·大模型服务及Agent开发平台\n企业级一站式大模型开发及服务平台模型训练限时免费] \n* [\n*2*\n### 百度千帆·数据智能平台一站式多模态数据管理、加工和分析应用平台平台体验全免费] \n* [\n*3*\n### 秒哒-生成式应用开发平台\n不用写代码，就能实现任意想法全功能免费体验] \n* [\n*4*\n### 百度智能云客悦智能客服平台大模型重塑营销与客服体验0元试用一个月\n] \n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践] \n### 关于作者[![] ### ] \n* 被阅读数* 被赞数* 被收藏数关注活动[\n咨询]', 'doi': '', 'published_date': '2024-01-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2733815', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能简史-腾讯云开发者社区-腾讯云', 'authors': [], 'abstract': '人工智能简史-腾讯云开发者社区-腾讯云\n[] \n[用户9624935] \n## 人工智能简史**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布用户9624935\n**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;人工智能简史\n# 人工智能简史![作者头像] \n用户9624935\n**关注\n发布于2022-04-02 14:58:47\n发布于2022-04-02 14:58:47\n2.2K0\n举报**文章被收录于专栏：[凯云实验室] 凯云实验室\n![] \nArtificial Intelligence (AI)，是在1956年的达特茅斯会议上提出来的，标志着人工智能这一学科的诞生。\n从1956年到2016年，刚好是60年。在过去的60年里，人工智能经历了三个阶段：\n* 二十世纪五十年代到七十年代：推理期，其出发点是，数学家真聪明。让计算机具有逻辑推理能力：为什么仅有逻辑推理能力不能实现人工智能？困难在哪里？* 二十世纪七十年代中期开始：知识期，其出发点是，知识就是力量。让计算机具有知识：由人把知识总结出来，再教给计算机——这是相当困难的。* 二十世纪九十年代到现在：学习期，其出发点是，让系统自己学。同时，也催生了人工智能的三大派别：* 符号主义：主要内容是关于符号计算、演算和逻辑推理，用演算和推理的办法来证明。比如说像机器证明就是符号主义。* 连接主义：目前非常流行的神经网络、神经元网络、深度学习，这些都是连接主义。* 行为主义：行为主义其实是从控制论衍生出来的，目前提及较少，但不能忽略。> 作者注：关于学派的分法，《终极算法》一书分为五类：符号学派，联结学派，进化学派，贝叶斯学派和类推学派。人工智能的三个派别和三个阶段并没有对应和界限，三个派别是在三个阶段的交织中发展起来的。著名信息论和人工智能专家钟义信在《弘扬Simon的源头创新精神，开拓AI的新理念新路径》报告中指出三大学派的的出现是一直以来还原论把复杂的系统分而治之研究的结果。因为整体上解决智能问题在物理和数学上都存在巨大的困难，所以在模仿大脑的功能研究上，出现了符号主义；在模仿大脑结构的研究上，出现了连接主义，在模仿人类行为的研究上（什么样的环境刺激会产生什么样的行为反应），出现了行为主义。\n> 作者注：看待人工智能的历史，要把人工智能的历史和神经网路的历史稍微区分一下，不能把神经网络的历史看作是人工智能的历史。所以本文不单独列举神经网络的发展历史和重大事件，留在下一篇文章中探讨。人工智能发展的过程中，经历了三次大事件，这些大事件导致了人工智能的发展进入三次低谷，被称为&quot;AI winter&quot;：\n* 1973年，英国发表了James Lighthill报告，批评人工智能研究进展令人失望，建议取消机器人的研究。为了回应批评和国会的压力，美国和英国政府停止了人工智能研究的资助。\n* 1992年，日本智能（第五代）计算机的研制宣告失败。这次失败有一个收获，是在潘云鹤《人工智能走向2.0》一文指出的，这次失败表明：驱动人工智能的发展主要靠创新的知识和软件，硬件的作用是支持其运行。\n* 在80年代，也诞生了cyc项目，一个包含所有人类常识的数据库。该项目随着互联网搜索引擎的崛起而衰败。潘云鹤在《人工智能走向2.0》指出：海量知识不能靠专家人工表达，要从环境中自动学习。也就是周志华指出的：由人把知识总结出来，再教给计算机——这是相当困难的。\n在过去的60年里，人工智能领域共有8位科学家成为图领奖得主：\n* 1969，Marvin Minsky：奖励他在创造，塑造，推动和加速人工智能这一领域的核心作用。\n* 1971，John McCarthy：麦卡锡的讲座《人工智能的研究现状》概括了他在人工智能领域的成就，也概括了值得奖励的原因。\n* 1975，Allen Newell and Herbert A. Simon：奖励他们在二十多年的联合科学工作中，最初与兰德公司的JC Shaw合作，随后与卡内基梅隆大学的众多教师和学生同事合作，对人工智能，人类认知心理学和列表处理方面做出的基础贡献。\n* 1994，Edward Feigenbaum and Raj Reddy：奖励他们在开创了大规模人工智能系统的设计和建造，展示了人工智能技术的实际重要性和潜在的商业影响。\n* 2010，Leslie G. Valiant：奖励他对于计算理论的变革性贡献，包括可能近似正确（PAC）学习的理论，枚举和代数计算的复杂性以及并行和分布式计算的理论。\n* 2011，Judea Pearl：奖励他对人工智能的基础贡献：概率和因果推理的微积分。\n上面这8位科学家，Marvin Minsky是MIT教授，最早提出连接主义，后来发表的《Perceptrons》一书指出感知机无法处理异或问题，导致连接主义长时间陷入低谷。不过著名信息论和人工智能专家钟义信说，另一个方面来看，马文·明斯基指出这个问题以后，经过人们的研究，提出了所谓的多层感知机，我们只要增加一个顶层就可以极大地提高神经网络表达的能力，可以逼近任意的问题。所以这个事情又从它的负面走向了正面，产生了积极的效果。\nJohn McCarthy，Allen Newell， Herbert A. Simon、Edward Feigenbaum几位都是非常典型的符号主义代表，他们最早推动了机器证明、人工智能、通用人工智能机、知识工程的进步。\n> 作者注：值得一提的是Herbert A. Simon是美国卡内基－梅隆大学心理学教授，1978年诺贝尔奖金获得者（经济学）。1968-1972年任美国总统科学顾问、行为科学和人工智能的创始人之一。西蒙教授为科学界的知名学者，在企业管理、计算机设计和决策理论方面有所创见。\nRaj Reddy主要是做语音识别的，李开复、沈向阳的老师。\nLeslie G. Valiant的贡献是机器学习理论，Judea Pearl的贡献是概率计算和因果推理，高文院士说，他们的工作是未来人工智能的重点走向。\n以上从分别从三个时期，三大学派，三次大事件以及8位图领奖得主的角度，总结了人工智能的简史。以下是我的一些不成熟思考：\n第一，计算的本质与智能的本质。《类脑智能研究的回顾和展望》指出，现有人工智能系统通用性较差与其计算理论基础和系统设计原理有密不可分的关系。计算机的计算本质和基础架构是图灵机模型和冯诺伊曼体系结构，其共同的缺点是缺乏自适应性。图灵计算的本质是使用预定义的规则对一组输入符号进行处理，规则是限定的，输入也受限于预定义的形式。图灵机模型取决于人对物理世界的认知程度，因此人限定了机器描述问题，解决问题的程度。而冯诺伊曼体系结构是存储程序式计算，程序也是预先设定好的，无法根据外界的变化和需求的变化进行自我演化。总结来看，计算的本质可以用一个数学公式f(x)=y来表达，是问题求解的范畴。\n那智能的本质是什么？如何表达？著名信息论和人工智能专家钟义信给了一个探讨性的定义：智能一定是在环境的作用下，人跟环境相互作用，不断的去学习，不断的去进化，在这个过程当中展开了智能的活动。反之，如果没有这种主体跟客体的相互作用，如果一切都是十全十美，如果不需要做出任何的改进，那就不需要思考、不需要学习，也就不需要智能。所以，一定要在主体跟客体相互作用过程当中来考察智能才有意义。李衍达院士在《沿Simon 开拓下去》的报告中探讨了智能的功能与智能的机理问题，指出基因的层次没有鸿沟，人和所有生物的机理是相同的，区别的是进化：自动适应外界变化而优化自身结构的功能。而且人脑在进化过程里面通过DNA的改变，改变了神经元的连接，这个连接既记录了学习的结果，又优化了学习算法。既简化了所需要的元件，又节省了能耗，非常巧妙。\n> 智能路径：感知反应-&gt;条件反射（存储，记忆）-&gt;决策（意志、欲望和目的）\n第二，关于程序员转型。和第一个问题有关，我们都是学习图灵机模型和冯诺伊曼架构长大的，思维方式相对固定。深度学习今年非常火爆，程序员又要开始转型。关于转型，我注意到几个论调：* 转型深度学习，数学是首要的基础；* 转型深度学习，开始大量学习TensorFlow框架；\n* 大二大三优秀学生学习起来很快，有经验的程序员学习来很苦；以上我都不太认同，人类是万物之灵，遇到新问题，学习新东西，再正常不过的事情，何来转型之说？如果非要说有什么需要转变，我觉得是到思维方式的转变：* 数学只是工具，TensorFlow只是封装的平台，而深度学习是有理论瓶颈的，工程界一直以来轻视学术的思维定势需要改变了。国内程序员同时是科学家的太少了，科学家有点高，做个学者吧。感觉要做一个好的科学家，不只是研究技术，而是在研究哲学，研究一些物质的本质、规律，研究一些最基础的东西。\n* 大多数程序员都是“程序员”思维，这是软件工业化的结果。重接口，重输入，重交付，这是一种软件外包的思维。输入是什么？输出是什么？程序如何实现？这些都造成了思维懒惰的一代程序员，从来不去问为什么程序这么做。而深度学习恰恰是讨论程序为什么这么实现的问题，其输出是模型，是算法。这是程序员需要改变的思维方式。* 人工智能更强调创新，特别是源头创新。在这个领域，有大量的问题都是崭新的，需要采用一些数学理论，结合实际需求来探索。我们在学习机器学习理论和算法的时候，需要有意识的突破已有的认知，特别是图灵机模型和冯诺伊曼体系结构。第三，脑复杂？还是环境复杂？傅小兰在《Simon与认知科学研究》报告中提到了《分布式认知》，指出认知现象在认知主体和环境间分布的本质：认知既分布于个体内与个体间，也分布于媒介、环境、文化、社会和时间等之中（Cole &amp; Engestrom, 1993）。Herbert A. Simon 也指出，一个人，若视作行为系统，是很简单的。他的行为随时间而表现出的表面复杂性主要是他所处环境的复杂性的反映。人——或至少人的智力要素——也许是比较简单的，人的行为的复杂性也许大半来自人的环境，来自人对优秀设计的搜索，因此，“在相当大的程度上，要研究人类便要研究设计科学。它不仅是技术教育的专业要素，也是每个知书识字人的核心学科”。第四，从上而下还是从下而上？人工智能从上而下研究的开创者和代表人物是Herbert A. Simon，他当时想到，人的大脑活动是分层次的，在底层的机理没有搞清楚时，他认为也不妨碍对于高层概念、推理、问题求解层次进行研究。符号学派就是自上而下的典型代表，但至今符号学派一直受到自下而上的连接主义压制。自下而上的代表是日本的第五代计算机计划，东京大学元岗达教授提出“第五代计算机的构想”，随后日本制定了研制五代机的十年计划，总预算达4.3亿美元。以渊一博为所长的“新一代计算机技术研究所”苦苦奋战了近十年，他们几乎没有回过家，近乎玩命式的拼搏；然而，由于没有突破关键性技术难题，无法实现自然语言人机对话，程序自动生成等目标，最终于1992年宣告失败！这或许也是图灵机模型和冯诺伊曼架构的失败。然而，峰回路转，得益于分布式计算和大数据时代，深度学习成为主流的自下而上方法。近五年来，深度学习在“视”、“听”、“说”等领域取得了的巨大成功，但这还不能表明自下而上的胜利或者神经网络模型的正确。神经网络只是从下而上对大脑的粗糙模拟和抽象，是否是正确的大脑学习隐喻还不得而知。但神经网络的成功又引发了一些自下而上的尝试，据称IBM有一个名为“突触”的项目，研究芯片级类脑计算设备，支持低频率，低功耗，和大量链接等神经网络功能。\n第五，鲁棒性？可解释性？魔术性？这几个问题是现在机器学习，特别是深度学习面临的主要问题。人类犯错：水平从九段降到八段，机器犯错：水平从九段降到业余，这就是鲁棒性。鲁棒性要求，“好的时候”要好，“坏的时候”不能太坏。在封闭静态环境中，重要因素大多是“定”的，而在开放动态环境中，一切都是变的，开放环境的鲁棒性，这也是自动驾驶面临的困难所在。关于可解释性，也被称为深度学习的黑箱模型。若学习器不能给出治疗理由，则难以说服患者接受昂贵的治疗方案。若学习器不能给出停机检测的理由，则难以判断停机检测的风险和代价。这些案例都需要机器学习的模型给出解释，否则难以应用到难以用于高风险应用。而机器学习魔术性是指即便相同数据，普通用户很难获得机器学习专家级性能。就是专家之间，是特别考验团队实力的，也有一点运气在里面。门派都一样，功力不一般。第六，目前的研究热点和我的方向。深度学习是很火的，不过周志华说的很中肯：“深度学习中间还有很多困难而又重要的问题值得深入研究，但这些真正值得研究的问题，就我看到的情况而言，好像做的人非常少。大多数人在干什么呢？拿它做做应用，调调参数，性能刷几个点，然后发几篇文章。这样虽然容易发表文章，但恐怕很难产生有影响的成果。”另外，周志华在引领集成学习的发展方向，CCAI17可以看到一些方向，中国香港科技大学计算机系主任杨强谈到的迁移学习，日本理化学研究所杉山将谈到的弱监督机器学习等。我的计划是，从历史中观其大略；感知机，神经网络，反向传播，深度学习是一条线，已经是必备的基础了；然后向增强学习发力；在技术上打通分布式系统，大数据和机器学习；在业务和需求上结合金融场景。\n![] \n第七，已知和未知。我们参考神经生理学，研制了神经网络和深度学习，并且取得了良好的效果。有人指出，大脑的生物物理结构，机制和功能只是大脑处理信息过程中的印记，其中很少一部分可用于有意识的思想（认知）。在学习未知的过程中，我们对学习到底了解了多少？在未知的区域里，既有要学习的对象，也有学习本身。参考文献：《人工智能走向2.0》 潘云鹤《类脑智能研究的回顾与展望》曾毅等《脑启发计算》苏中《机器学习》序言陆汝钤《机器学习：发展与未来》周志华《H. A. Simon学术生平》林建祥\n《Simon的认知科学思想》傅小兰\n《人工智能--螺旋上升的60年》高文院士\n《沿Simon 开拓下去》李衍达《塞蒙终生学术经历简介》林建祥《人工智能的历史》中国人工智能学会《司马贺的创新之路》史忠植《弘扬Simon学术思想 》钟义信《探寻大师足迹，一览马文•明斯基学术风采》史忠植《站在巨人的肩膀上，从人工智能与认知商务》苏中《弘扬Simon的源头创新精神开拓“AI”的新理念新路径》钟义信\n《独家| 周志华：深度学习很有用，但过度追捧就有危险了》AI科技大本营\n本文参与[腾讯云自媒体同步曝光计划] ，分享自微信公众号。\n原始发表：2017-08-06，如有侵权请联系[cloudcommunity@tencent.com] 删除\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n本文分享自补天遗石微信公众号，前往查看如有侵权，请联系[cloudcommunity@tencent.com] 删除。\n本文参与[腾讯云自媒体同步曝光计划] ，欢迎热爱写作的你一起参与！\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n评论登录后参与评论0条评论\n热度最新登录后参与评论推荐阅读相关产品与服务人工智能与机器学习提供全球领先的人脸识别、文字识别、图像识别、语音技术、NLP、人工智能服务平台等多项人工智能技术，共享 AI 领域应用场景和解决方案。[**产品介绍] \n[**AI驱动 智领未来] \n领券* ### 社区* [技术文章] \n* [技术问答] \n* [技术沙龙] \n* [技术视频] \n* [学习中心] \n* [技术百科] \n* [技术专区] \n* ### 活动* [自媒体同步曝光计划] \n* [邀请作者入驻] \n* [自荐上首页] \n* [技术竞赛] \n* ### 圈层* [腾讯云最具价值专家] \n* [腾讯云架构师技术同盟] \n* [腾讯云创作之星] \n* [腾讯云TDP] \n* ### 关于* [社区规范] \n* [免责声明] \n* [联系我们] \n* [友情链接] \n* [MCP广场开源版权声明] \n### 腾讯云开发者![扫码关注腾讯云开发者] \n扫码关注腾讯云开发者领取腾讯云代金券### 热门产品* [域名注册] \n* [云服务器] \n* [区块链服务] \n* [消息队列] \n* [网络加速] \n* [云数据库] \n* [域名解析] \n* [云存储] \n* [视频直播] \n### 热门推荐* [人脸识别] \n* [腾讯会议] \n* [企业云] \n* [CDN加速] \n* [视频通话] \n* [图像分析] \n* [MySQL 数据库] \n* [SSL 证书] \n* [语音识别] \n### 更多推荐* [数据安全] \n* [负载均衡] \n* [短信] \n* [文字识别] \n* [云点播] \n* [大数据] \n* [小程序开发] \n* [网站监控] \n* [数据迁移] \nCopyright ©2013 -2026Tencent Cloud. All Rights Reserved. 腾讯云版权所有[深圳市腾讯计算机系统有限公司] ICP备案/许可证号：[粤B2-20090059]![] [粤公网安备44030502008569号] \n[腾讯云计算（北京）有限责任公司] 京ICP证150476号 |[京ICP备11018762号] \n[问题归档] [专栏文章] [快讯文章归档] [关键词归档] [开发者手册归档] [开发者手册 Section 归档] \nCopyright ©2013 -2026Tencent Cloud.\nAll Rights Reserved. 腾讯云版权所有登录后参与评论**\n**\n**\n000\n推', 'doi': '', 'published_date': '2022-04-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://cloud.tencent.com.cn/developer/article/1971641', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的80年进化编年史：从想象到现实', 'authors': [], 'abstract': '人工智能的80年进化编年史：从想象到现实\\_腾讯新闻\n# 人工智能的80年进化编年史：从想象到现实\n![头像]![] \n[\nWeb3天空之城\n] \n2023-03-01 20:44发布于浙江科技领域创作者\nAGI是Artificial General Intelligence的缩写，即通用人工智能。\nAGI的目标是实现人类般的通用智能，这意味着AI可以像人类一样理解任意通用任务, 并以人类的智力水平执行完成。基本上, 除了&quot;自我意识&quot;的生成，AGI就是人类对人工智能的终极梦想了。\n无论是近一年来火爆的AI绘画，还是当红炸子鸡ChatGPT，AI研究应用的终极目标, 都是向着AGI通用人工智能的大一统目标在迈进。\n读者是否有同感,\xa0这几年各种AI大模型的发展和突破, 着实有让人眼花缭乱之感?\n本文主要把现代到当下一些AI的重要节点做了时间线梳理和简单分析，或有助于大家来理清楚这些年AI发展的关键脉络。\n1942年\n时间回到80年前, 科幻泰斗阿西莫夫提出了著名的&quot;机器人三定律”：\n机器人不得伤害人类，或坐视人类受到伤害；除非违背第一定律，否则机器人必须服从人类命令；除非违背第一或第二定律，否则机器人必须保护自己。这三个定律是人工智能和机器人技术的哲学基础，是对如何设计人工智能系统的基本原则的阐述，至今都有着重要的参考意义。1950年\n计算机科学之父艾伦·图灵（Alan Turing）发表了具有里程碑意义的论文《Computing Machinery and Intelligence（计算机器与智能）》。论文预言了创造出具有真正智能的机器的可能性，第一次提出图灵测试（The Turing test）的概念：\n如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。1956年\nAI概念诞生。\n美国的达特茅斯学院举行了一次具有传奇色彩的学术会议（Dartmouth Conference）， 探讨用机器模拟人类智能的问题。计算机专家约翰·麦卡锡提出了AI&quot;人工智能”一词。这被广泛认为是人工智能正式诞生的日子。参与会议的学者们是最早的AI研究先驱。\n从1956年到现代，这几十年来AI研究的起伏，有兴趣的读者可以参考本号另一篇文章从爆火的chatGPT讲起: 自然语言生成式AI的前世今生, 你想了解的一切&gt;\n当今大众关于AI的记忆，或许是从1997年开始的：\n1997年\n5月11日, IBM公司的电脑&quot;深蓝”战胜了国际象棋世界冠军卡斯帕罗夫，成为首个击败国际象棋世界冠军的AI系统。\n1998年\n现代卷积神经网络CNN诞生。\n1980年，日本学者福岛邦彦（Kunihiko Fukushima）模仿生物的视觉皮层（visual cortex），设计了人工神经网络&quot;neocognitron”，这是现代卷积神经网络的雏形。\n经过多年前赴后继的研究，1998年杨立昆（Yann LeCun，现任Meta首席人工智能科学家）基于前人基础，构建了更加完备的卷积神经网络LeNet-5，在手写数字的识别问题中取得了成功。LeNet-5被认为是现代卷积神经网络的基本结构。\n卷积神经网络CNN是当今&quot;深度学习&quot;AI模型的计算基础架构。一直到2017年Transformer架构横空出世后，CNN才被取代。\n2003年\nYoshua Bengio在2003年发表了《A Neural Probabilistic Language Model》，这是第一篇基于人工神经网络打造自然语言模型的论文，提出了具有奠基意义的NNLM&quot;神经网络语言模型&quot;。它在得到语言模型的同时也产生了副产品&quot;词向量&quot;。\n2006年\n杰弗里·辛顿（Geoffrey Hinton）在science期刊上发表了重要的论文《Reducing the dimensionality of data with neural networks》，提出深度信念网络（Deep Belief Networks，DBNs），&quot;深度学习&quot;正式诞生。\n2009年\n李飞飞主导的Image Net正式发布，有超过1000万数据，两万多个类别。为全世界的AI学者提供了开放的标注图像大数据集。\n2010年开始，Image Net大规模视觉识别挑战赛（ILSVCR）开始举办，全世界图像领域深度学习的专家们同台竞技和交流，从此拉开了计算机视觉的新篇章。\n2012年\nGoogle的吴恩达和Jef Dean使用1.6万个CPU（那时的GPU生态还在婴幼儿阶段）训练了一个当时世界上最大的人工神经网络，用来教AI绘制猫脸图片。训练数据是来自youtube的1000万个猫脸图片，1.6万个CPU整整训练了3天。\n对于计算机AI领域，这是一次具有突破性意义的尝试。AI第一次&quot;生成&quot;了一个图像内容：一张模糊的猫脸\n![图片] \n2013年\nGoogle的托马斯·米科洛夫（Tomas Mikolov）带领研究团队发表了论文《Efficient Estimation of Word Representations inVector Space》，提出了Word2Vec。\nWord2Vec可以根据给定的语料库，通过优化后的训练模型可以快速有效地将一个词语表达成高维空间里的词向量形式，为自然语言处理领域的应用研究提供了新的工具。\n2014年1月\n谷歌斥资400亿美元收购了位于伦敦的明星人工智能企业DeepMind。\n2014年12月\nGAN（对抗式生成网络）诞生。\n2014 年，Lan Goodfellow从博弈论中的&quot;二人零和博弈&quot;得到启发 ，创造性的提出了生成对抗网络（GAN，Generative Adversarial Networks），他在2014年的NIPS会议上首次发表了相关论文，用两个神经网络即生成器（Generator）和判别器（Discriminator）进行对抗。在两个神经网络的对抗和自我迭代中，GAN会逐渐演化出强大的能力。\n作者在最早的文章里形象的把GAN比喻为伪造者和警察：伪造者总想造出以假乱真的钞票，而警察则努力用更先进的技术去鉴别真伪。在博弈过程中，双方都不断提升了自己的技术水平。\nGAN号称21世纪最强大的算法模型之一，&quot;Gan之父&quot;Ian Goodfellow也一跃成为AI领域的顶级专家。\n2015年12月\nOpenAI公司于美国旧金山成立。\nOpenAI诞生的原因是很有趣的：DeepMind被Google收购的消息震动了硅谷，如果发展下去，DeepMind很有可能成为最早实现AGI通用人工智能的公司。为了打破GoogleAI技术的垄断，在一次私人聚会后，大佬们一拍即合成立了OpenAI。\n其中包括，钢铁侠Elon Musk，当时已是著名创业孵化器 Y Combinator 的负责人现在成为OpenAI CEO的Sam Altman，以及著名天使投资人 Peter Thiel等硅谷大佬。\nOpenAI作为一个非营利性组织运营，并立志要做DeepMind和Google无法做到的事情：开放和共享AI技术。\n从今天的眼光看，尽管OpenAI后来的商业模式有所变化，但绝对实现了它诞生的最大愿景之一：狙击Google和DeepMind。\nChatGPT的推出加上微软Bing的推波助澜搞得Google实在是狼狈不堪。\n2015年\n11月， Google开源了重要的深度学习框架Tensor Flow；\n同年，还是Google，开源了用来分类和整理图像的 AI 程序Inceptionism，并命名为 DeepDream。尽管还很初级，但DeepDream被认为是第一个现代的AI绘画应用。\n2016年\n3月，Google的AlphaGo战胜围棋世界冠军李世石;\n4月，Google深度学习框架TensorFlow发布分布式版本;\n9月，Google上线基于深度学习的机器翻译;\n2015到2016年，Google的AI能力可谓是风头一时无两。\n2017年1月\nFacebook人工智能研究院（FAIR）开源了PyTorch。PyTorch和tensorFlow从此成为了当今两大主流深度学习框架。\n2017年7月\nFacebook联合罗格斯大学和查尔斯顿学院艺术史系三方合作得到新AI绘画模型，号称创造性对抗网络（CAN，Creative Adversarial Networks），\nCAN在测试中，有53%的观众认为AI作品出自人类之手，这是类似的图灵测试历史上首次突破半数，这是AI绘画模型小小而扎实的一步。\nFacebook在AI领域其实耕耘了很久，做过很多贡献，可惜后面搞Metaverse连公司名字都改成Meta了， 差点错过了当下这波AI的浪潮。\n不过最近小札醒悟过来，终于官宣要All in AI。Meta还是很有实力的，奋起直追应为时未晚。\n2017年12月\n颠覆性的Tranformer架构出世了!\nGoogl机器翻译团队在年底的顶级会议NIPS上发表了里程碑式的论文《Attention is all you need》，提出只使用自注意力（Self Attention）机制来训练自然语言模型，并给这种架构起了个霸气的名字：Transformer。\n所谓&quot;自我注意力&quot;机制，简单说就是只关心输入信息之间的关系，而不再关注输入和对应输出的关系。和之前大模型训练需要匹配的输入输出标注数据相比，这是一个革命性的变化。\nTransformer彻底抛弃了传统的CNN和RNN等神经网络结构。在这篇论文发布之前，主流AI模型都基于CNN卷积神经网络和RNN循环神经网络（recurrent neural network）; 而之后，便是Transformer一统天下。\nTransformer架构的详细描述不在本文范围，读者只需要知道它具有两点无敌的优势：\n自我注意力机制，让模型训练只需使用未经标注的原始数据，而无需再进行昂贵的的人工标注（标注输入和对应输出）。并行效率是之前的AI模型结构被一直诟病的地方。抛弃了传统CNN/RNN架构后，基于Transformer架构的大模型训练可以实现高度并行化，这大大提高了模型训练的效率;\n从此，大模型大数据大算力，大力出奇迹，成为了AI领域的标配。\n感慨一下，Google首先发明了划时代的Transformer架构，但在5年后的今天，却被OpenAI打得喘不过气。这是命运的偶然吗？\n2018年6月\nOpenAI发布了第一版的GPT（Generative Pre-training Transformers）系列模型 GPT-1。\n同时，OpenAI发表了论文《Improving Language Understanding by Generative Pre-training》\n从论文里可以了解到，GPT-1具有1.17个参数，采用了12层的Transformer 解码器结构，使用5GB的无标注文本数据，在8个GPU上训练了一个月，然后再进行人工监督的微调。\n不过，GPT-1并不是当年的明星，因为同年，Google的BERT大模型也发布了（当时的Google就是强啊）。\n2018年10月\n谷歌发布3亿参数的BERT（Bidirectional Encoder Representation from Transformers），意思即&quot;来自Transformers的双向编码表示”模型。\nGPT和BERT的诞生意味着预训练大模型（Pre-trained Models）成为了自然语言处理领域的主流。\n和GPT相比，BERT最大的区别就是使用文本的上下文来训练模型，而专注于&quot;文本生成&quot;的GPT-1，使用的是上文。\n基于&quot;双向编码&quot;的能力让BERT的性能在当时明显优异于第一代的GPT-1。\n幸好，Open AI 并没有那么容易放弃，一直坚持只用上文训练的&quot;单向编码&quot;纯生成模式。直到GPT-3，神功初成。\n2018年底\n在共同创立公司三年后，钢铁侠马斯克辞去了Open AI董事会职务，原因是&quot;为了消除潜在的未来冲突&quot;。\n实际情况是，2017年6月，马斯克挖走了OpenAI的核心人员Andrej Karpathy，担任Tesla的AI部门主管并直接向自己汇报，负责构建特斯拉的自动驾驶系统。\n所以，确实是存在人才竞争&quot;潜在冲突&quot;的。\n有趣的是，根据前不久的最新消息，ChatGPT大火之后，Andrej Karpathy同学又离开了Tesla回到了OpenAI。这是所谓&quot;鸟择良木而栖&quot;：）\n而马斯克放出了声音，要打造OpenAI的竞争者。不知首富同学是否遗憾当年不得不放走了OpenAI。\n2019年2月\nOpenAI发布了GPT-2。\nGPT-2有48层Transformer结构，使用40GB文本数据训练，参数量突破到了15亿。\n在同时发布的论文《Language Models are Unsupervised Multitask Learners》 中，OpenAI描述了GPT2在经过大量无标注数据生成式训练后，展示出来的零样本（zero-shot）多任务能力。\n所谓零样本学习就是用很大的通用语料去训练模型，然后不再需要做特定任务的训练，大模型就可以直接完成一些具体任务。一个典型例子是翻译。GPT-2具备了良好的语言翻译能力; 而有趣的是，专门做翻译的模型通常使用标注好的语料（即两个不同语言的匹配数据）来训练。但GPT-2并没有使用这类数据，翻译效果还超过了很多专职翻译的小模型。\nGPT-2揭示了一个有趣的现象，仅作为生成式任务来训练打造的大模型，开始具备了多种通用任务能力，比如GPT-2所具备的阅读理解和翻译等等。\n2019年3-7月\n3月份，OpenAI正式宣布重组，成为一家&quot;利润上限（caped-profit）&quot;的公司，规定了投资收益的上限。这是一个很特别的架构。\n而近期披露的OpenAI最新投资架构也再次揭示了这个公司股权结构的与众不同。简单的说，OpenAI把自己租借给了微软，赚到1500亿美金后，将重新变为非营利性组织 -- 至少说是这么说的。5月，Sam Altman辞去了 YC总裁的工作，开始担任新 OpenAI 的CEO。\n7月，重组后的OpenAI拿到了微软包括Azure云计算资源在内的10亿美金投资， 微软将作为&quot;首选合作伙伴”，今后可获得OpenAI 技术成果的独家授权。自此，OpenAI后续技术成果不再承诺开源。\n2020年5月\nOpenAI发布了GPT-3。\nGPT-3的初始版本在内部代号为&quot;davinci&quot;，使用45TB文本数据训练，有1750亿参数。根据公开信息，模型的训练费用是1200万美金。因为太贵，只训练了一次。\n随后，OpenAI发表了近70页的论文《Language Models are Few-Shot Learner》。这篇论文阐述了大模型的各种新能力，而最重要的就是标题所指出的小样本（few-shot）学习能力。\n&quot;few-shot&quot;是一个专业术语，理解起来也简单，就是通过少量的几个例子就能学习一个新的任务。人们发现，GPT-3开始具有类似人类的能力，只要在提示里展示特定任务的几个示例，GPT-3就能完成新示例的输出。而无需进行针对性的额外微调训练。这也被称之为&quot;上下文学习&quot;（in context learning）\n2020年6月\n对AI绘画有重要意义的论文 《Denoising Diffusion Probabilistic Models》发表， 引入了DDPM模型。 作为领域的奠基之作，这篇论文第一次把2015年诞生的Diffusion&quot;扩散模型&quot;用在了图像生成上。\n用扩散模型生成图像的过程，简单理解，就是我们熟知的图片&quot;降噪&quot;：把一幅全部是噪点的随机图像通过AI算法反复&quot;降噪&quot;到最清晰，一个图像便生成了。\nDDPM的出现把Diffusion扩散模型带到了一个新的高度。在不久之后，DDPM以及后续的Diffusion扩散模型就全面取代了GAN（生成式对抗网络），成为了AI绘画大模型当仁不让的主流技术。\n2020年12月\n由于不再认同转型后的公司文化和战略，OpenAI的部分核心团队出走。\n12月31日，OpenAI发布新闻稿，宣布其研究副总裁Dario Amodei在OpenAI工作了近五年后离开了OpenAI。\nOpenAI正是5年前成立的，这位研究副总看来是妥妥的创始核心。\nDario Amodei带着一些OpenAI的早期核心员工随后创办了Anthropic，推出了ChatGPT的直接竞品Claude。\n被ChatGPT逼急了的Google最近刚给Anthropic紧急投资了3亿美金，以获得其10%的股份，并绑定了其云计算提供商的身份。\n这里说个小知识，加州没有竞业协议，真的是创业者的天堂!\n2021年1月\n1月11日，Google发表论文《Switch Transformers：Scaling to Trillion Parameter Models with Simple and Efficient Sparsity》，提出了最新语言模型—Switch Transformer。\n这个Switch Transformer 模型以高达1.6 万亿的参数量打破了GPT-3 作为最大AI 模型的统治地位，成为史上首个万亿级语言模型。然而，时间会证明一切。2年后的今天，这个万亿参数的Switch大模型在当下似乎没产生任何水花，而千亿参数级别的GPT-3.5系列依然风生水起。这是不是说明一个问题：突破千亿阈值后，参数多少并不代表一切。\n2021年2月\nOpen AI开源了新的深度学习模型 CLIP（Contrastive Language-Image Pre-Training）。\nCLIP是一个多模态模型，用来判断文字和图像两个不同&quot;模态&quot;信息的关联匹配程度。\n在CLIP之前，也有人尝试过这个方向，但OpenAI最大的创意是直接使用全互联网上已经标记过的图像数据，巧妙的避免了海量数据标注的昂贵费用。最后以接近40亿的互联网&quot;文本-图像&quot;训练数据打造了CLIP。\n这次重要的开源直接推动了各大AI绘画模型的迅猛发展。CLIP的多模态能力正是各AI绘画大模型从文字到画面想象力的核心基础。\n同时，OpenAI还发布了自己基于CLIP的 AI绘画DALL-E 模型。这或许是大众听说的第一个&quot;文本生成图像&quot;的AI绘画模型了。\n从CLIP到DALL-E，显然OpenAI走在了AI绘画大模型潮流的最前端。\n只是，OpenAI在AI绘画模型的商业决策上出现了失误：因为没有开放使用DALL-E以及后续DALL-E2，而又开源了关键的CLIP模型，导致目前AI绘画模型的光芒完全被其开源继承者Stable Diffusion，还有付费的Midjourney服务掩盖了。\n正是在AI绘画模型上有苦说不出的经历，直接影响了后来OpenAI管理层的决策：决定在第一时间面向公众抢先推出 ChatGPT聊天机器人。\n2021年4月\n华为的盘古NLP大模型发布，号称是中国第一个千亿参数语言大模型。\n2021年6月\n6 月30 日，OpenAI 和GitHub 联合发布了AI 代码补全工具GitHub Copilot，这个工具可以在 VS Code 编辑器中自动完成代码片段，也是OpenAI 拿了微软10 亿美元之后的第一个重大成果。而Copilot 的AI技术核心正是OpenAI的新模型CodeX。这个模型在随后的8月份也对外发布了。\n根据相关论文《Evaluating Large Language Models Trained on Code》，OpenAI基于GPT-3，使用大量公开代码数据训练出了Codex模型。\nCodex拥有120亿参数，使用了159G代码数据进行训练，模型可以将自然语言描述转换为代码。而效果吗，看看码农们对Copilot的赞不绝口就知道了。\nAI生成代码的时代终于到来了。\n据称，Codex的训练数据来自于公共数据源的数十亿行源代码，而其中最重要的来源，无疑正是微软所买下的GitHub 这个世界上最大的开源代码平台。使用GitHub代码训练模型这个事情还引起了一些程序员关于代码版权的热烈讨论。\n不过，正如画师们对砸了自己饭碗的AI绘画大模型怨声载道而然并卵。。。能力突破的AI对人类初级技能的全面覆盖，恐怕是一个不得不接受的事实。\n从商业角度上看，CodeX的诞生和Copilot的成功证明了OpenAI和微软的商业合作确实是一个双赢。\n2021年10月\n第一个开源的AI绘画大模型Disco-Diffusion诞生!\n发布在Github上的Disco-Diffusion是整个2022年AI绘画旋风的起点。从Disco-Diffusion开始，AI绘画大模型突飞猛进的发展让所有人目不暇接，揭开了AI的新时代。\n2021年12月\n百度第三代文心语言大模型，2600亿参数的ERNIE3.0 Titan发布。\n百度文心和华为盘古都是GPT-3量级的模型，关于国产大模型的具体判断，读者有兴趣可以参考本号国产ChatGPT们的真相&gt;一文\n2022 年3 月OpenAI发布InstructGPT， 同时发表论文《Training language models to follow instructions with human feedback》。\n根据论文，InstructGPT基于GPT-3模型做了进一步微调，并且在模型训练中加入了人类的反馈评价数据。\n这里出现的RLHF &quot;从人类反馈中强化学习&quot;，正是后面ChatGPT所依赖的一个关键技术。\n2022年4月\nOpenAI发布了AI绘画大模型DALL-E 2。\n同一时间，面向公众的付费AI绘画服务Midjourney也发布了。\n和开局王炸，第一年就赚取了大把真金白银的MidJourney相比，使用受限的DALL-E 2并没有在大众人群里产生多少影响力。\n如之前所说，OpenAI在绘画大模型的开放上过于保守了，也许还有优先和微软技术合作的考量在内...\n总之，非常遗憾，绘画模型的风头完全被付费的Midjourney和随后的Stable diffusion抢走。\n2022年5月\nOpenAI发布代号为text-davinci-002的新版大模型，GPT系列正式迈入3.5时代。\n有趣的是，按照OpenAI官方文档说法：\nis a base model，so good for pure code-completion tasks\nis an InstructGPT model based on\n就是说，代号为code的002号模型是3.5系列的基础模型，而代号为text的002号模型是基于code 002模型用指令微调技术得到的 （insturctGPT）\n如果，OpenAI没有在模型名字上混淆视听，一个有趣而合理的推断是：GPT-3.5系列的基础核心模型首先是依赖于代码（Code）大数据训练，而不是普通文本（Text）训练的\n如果这个推断差不太多，那么众多ChatGPT的追随者们，如希望自家能力真正比肩基于GPT-3.5的ChatGPT， 那必须要补的一课，就是代码数据的训练了。2022年6月\n6月15日，谷歌研究院联合DeepMind和斯坦福大学等在arxiv上发表了一篇论文：《Emergent Abilities of Large Language', 'doi': '', 'published_date': '2023-03-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://view.inews.qq.com/a/20230301A08BTW00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '万字长文解读AI发展史，看人工智能将如何改变下个时代_腾讯新闻', 'authors': [], 'abstract': '万字长文解读AI发展史，看人工智能将如何改变下个时代\\_腾讯新闻\n# 万字长文解读AI发展史，看人工智能将如何改变下个时代\n![头像]![] \n[\nINDIGO的数字镜像\n] \n2022-11-15 09:06发布于中国香港科技领域创作者\n就在过去几个月里，因为美联储的加息，科技公司的资本狂欢宣告结束，美国上市的SaaS 公司股价基本都跌去了70%，裁员与紧缩是必要选项。但正当市场一片哀嚎的时候，Dall-E 2 发布了，紧接着就是一大批炫酷的AI 公司登场。这些事件在风投界引发了一股风潮，我们看到那些兜售着基于生成式AI（Generative AI）产品的公司，估值达到了数十亿美元，虽然收入还不到百万美元，也没有经过验证的商业模式。不久前，同样的故事在 Web 3 上也发生过！感觉我们又将进入一个全新的繁荣时代，但人工智能这次真的能带动科技产业复苏么？划重点本文将带你领略一次人工智能领域波澜壮阔的发展史，从关键人物推动的学术进展、算法和理念的涌现、公司和产品的进步、还有脑科学对神经网络的迭代影响，这四个维度来深刻理解“机器之心的进化”。先忘掉那些花里胡哨的图片生产应用，我们一起来学点接近AI 本质的东西。文章较长，累计22800 字，请留出一小时左右的阅读时间，欢迎先收藏再阅读！文中每一个链接和引用都是有价值的，特别作为衍生阅读推荐给大家。阅读之前先插播一段Elon Musk 和Jack Ma 在WAIC 2019 关于人工智能的对谈的经典老视频，全程注意Elon Ma 的表情大家觉得机器智能能否超过人类么？带着这个问题来阅读，相信看完就会有系统性的答案！本文在无特别指明的情况下，为了书写简洁，在同一个段落中重复词汇大量出现时，会用AI（Artifical Intelligence）来代表 人工智能，用ML（Machine Learning）来代表机器学习，DL（Deep Learning）来代表深度学习，以及各种英文缩写来优先表达。\n01\nAI 进化史对于机器是否真能&quot;知道&quot;、&quot;思考 &quot;等问题，我们很难严谨地定义这些。我们对人类心理过程的理解，或许只比鱼对游泳的理解更好一点。\n- John McCarthy\n早在1945 年，Alan Turing 就已经在考虑如何用计算机来模拟人脑了。他设计了ACE（Automatic Computing Engine - 自动计算引擎）来模拟大脑工作。在给一位同事的信中写道：&quot;与计算的实际应用相比，我对制作大脑运作的模型可能更感兴趣 ...... 尽管大脑运作机制是通过轴突和树突的生长来计算的复杂神经元回路，但我们还是可以在ACE 中制作一个模型，允许这种可能性的存在，ACE 的实际构造并没有改变，它只是记住了数据......&quot; 这就是机器智能的起源，至少那时在英国都这样定义。1.1 前神经网络时代神经网络是以模仿人脑中的神经元的运作为模型的计算机系统。AI 是伴随着神经网络的发展而出现的。1956年，美国心理学家 Frank Rosenblatt 实现了一个早期的神经网络演示- 感知器模型（Perceptron Model），该网络通过监督 Learning的方法将简单的图像分类，如三角形和正方形。这是一台只有八个模拟神经元的计算机，这些神经元由马达和转盘制成，与 400 个光探测器连接。![图片] 配图01：Frank Rosenblatt &amp; Perceptron Model\nIBM 的Georgetown 实验室在这些研究的基础上，实现了最早的机器语言翻译系统，可以在英语和俄语之间互译。1956年的夏天，在 Dartmouth College 的一次会议上，AI被定义为计算机科学的一个研究领域，Marvin Minsky（明斯基）, John McCarthy（麦卡锡）, Claude Shannon（香农）, 还有Nathaniel Rochester（罗切斯特）组织了这次会议，他们后来被称为 AI 的&quot;奠基人&quot;。\n![图片] 配图02：Participants of the 1956 Dartmouth Summer Research Project on AI\nDARPA 在这个“黄金”时期，将大部分资金投入AI 领域，就在十年后他们还发明了ARPANET（互联网的前身）。早期的 AI 先驱们试图教计算机做模仿人类的复杂心理任务，他们将其分成五个子领域：推理、知识表述、规划、自然语言处理（NLP）和感知，这些听起来很笼统的术语一直沿用至今。\n从专家系统到机器学习1966年，Marvin Minsky 和Seymour Papert 在《感知器：计算几何学导论》一书中阐述了因为硬件的限制，只有几层的神经网络仅能执行最基本的计算，一下子浇灭了这条路线上研发的热情，AI 领域迎来了第一次泡沫破灭。这些先驱们怎么也没想到，计算机的速度能够在随后的几十年里指数级增长，提升了上亿倍。在上世纪八十年代，随着电脑性能的提升，新计算机语言Prolog &amp; Lisp 的流行，可以用复杂的程序结构，例如条件循环来实现逻辑，这时的人工智能就是专家系统（Expert System），iRobot 公司绝对是那个时代明星；但短暂的繁荣之后，硬件存储空间的限制，还有专家系统无法解决具体的、难以计算的逻辑问题，人工智能再一次陷入窘境。我怀疑任何非常类似于形式逻辑的东西能否成为人类推理的良好模型。- Marvin Minsky\n直到IBM 深蓝在1997年战胜了国际象棋冠军卡斯帕罗夫后，新的基于概率推论（Probabilistic Reasoning）思路开始被广泛应用在 AI 领域，随后IBM Watson 的项目使用这种方法在电视游戏节目《Jeopardy》中经常击败参赛的人类。\n概率推论就是典型的机器学习（Machine Learning）。今天的大多数 AI 系统都是由ML 驱动的，其中预测模型是根据历史数据训练的，并用于对未来的预测。这是AI 领域的第一次范式转变，算法不指定如何解决一个任务，而是根据数据来诱导它，动态地达成目标。因为有了ML，才有了大数据（Big Data）这个概念。\n1.2 Machine Learning 的跃迁Machine Learning 算法一般通过分析数据和推断模型来建立参数，或者通过与环境互动，获得反馈来学习。人类可以注释这些数据，也可以不注释，环境可以是模拟的，也可以是真实世界。Deep Learning\nDeep Learning 是一种Machine Learning算法，它使用多层神经网络和反向传播（Backpropagation）技术来训练神经网络。该领域是几乎是由 Geoffrey Hinton 开创的，早在1986年，Hinton 与他的同事一起发表了关于深度神经网络（DNNs - Deep Neural Networks）的开创性论文，这篇文章引入了反向传播的概念，这是一种调整权重的算法，每当你改变权重时，神经网络就会比以前更快接近正确的输出，可以轻松的实现多层的神经网络，突破了 1966 年Minsky 写的感知器局限的魔咒。![图片] 配图03：Geoffrey Hinton &amp; Deep Neural Networks\nDeep Learning 在2012 年才真正兴起，当时Hinton 和他在多伦多的两个学生表明，使用反向传播训练的深度神经网络在图像识别方面击败了最先进的系统，几乎将以前的错误率减半。由于他的工作和对该领域的贡献，Hinton 的名字几乎成为Deep Learning 的代名词。数据是新的石油Deep Learning 是一个革命性的领域，但为了让它按预期工作，需要数据。而最重要的数据集之一，就是由李飞飞创建的ImageNet。曾任斯坦福大学人工智能实验室主任，同时也是谷歌云 AI/ML 首席科学家的李飞飞，早在2009 年就看出数据对Machine Learning 算法的发展至关重要，同年在计算机视觉和模式识别（CVPR）上发表了相关论文。\n![图片] 配图04：FeiFei Li &amp; ImageNet\n该数据集对研究人员非常有用，正因为如此，它变得越来越有名，为最重要的年度DL 竞赛提供了基准。仅仅七年时间，ImageNet 让获胜算法对图像中的物体进行分类的准确率从72% 提高到了98%，超过了人类的平均能力。\nImageNet 成为DL 革命的首选数据集，更确切地说，是由Hinton 领导的AlexNet 卷积神经网络（CNN - Convolution Neural Networks）的数据集。ImageNet 不仅引领了DL 的革命，也为其他数据集开创了先例。自其创建以来，数十种新的数据集被引入，数据更丰富，分类更精确。神经网络大爆发在Deep Learning 理论和数据集的加持下，2012年以来深度神经网络算法开始大爆发，卷积神经网络（CNN）、递归神经网络（RNN - Recurrent Neural Network）和长短期记忆网络（LSTM - Long Short-Term Memory）等等，每一种都有不同的特性。例如，递归神经网络是较高层的神经元直接连接到较低层的神经元。\n来自日本的计算机研究员福岛邦彦（Kunihiko Fukushima）根据人脑中视觉的运作方式，创建了一个人工神经网络模型。该架构是基于人脑中两种类型的神经元细胞，称为简单细胞和复杂细胞。它们存在于初级视觉皮层中，是大脑中处理视觉信息的部分。简单细胞负责检测局部特征，如边缘；复杂细胞汇集了简单细胞在一个区域内产生的结果。例如，一个简单细胞可能检测到一个椅子的边缘，复杂细胞汇总信息产生结果，通知下一个更高层次的简单细胞，这样逐级识别得到完整结果。\n![图片] 配图05：深度神经网络如何识别物体（TensorFlow）\nCNN 的结构是基于这两类细胞的级联模型，主要用于模式识别任务。它在计算上比大多数其他架构更有效、更快速，在许多应用中，包括自然语言处理和图像识别，已经被用来击败大多数其他算法。我们每次对大脑的工作机制的认知多一点，神经网络的算法和模型也会前进一步！1.3 开启潘多拉的魔盒从2012 到现在，深度神经网络的使用呈爆炸式增长，进展惊人。现在Machine Learning 领域的大部分研究都集中在Deep Learning 方面，就像进入了潘多拉的魔盒被开启了的时代。![图片] 配图06：AI 进化史GAN\n生成对抗网络（GAN - Generative Adversarial Network） 是Deep Learning 领域里面另一个重要的里程碑，诞生于2014 年，它可以帮助神经网络用更少的数据进行学习，生成更多的合成图像，然后用来识别和创建更好的神经网络。GANs 的创造者Ian Goodfellow 是在蒙特利尔的一个酒吧里想出这个主意的，它由两个神经网络玩着猫捉老鼠的游戏，一个创造出看起来像真实图像的假图像，而另一个则决定它们是否是真的。![图片] 配图07：GANs 模拟生产人像的进化GANs 将有助于创建图像，还可以创建现实世界的软件模拟，Nvidia 就大量采用这种技术来增强他的现实模拟系统，开发人员可以在那里训练和测试其他类型的软件。你可以用一个神经网络来“压缩”图像，另一个神经网络来生成原始视频或图像，而不是直接压缩数据，Demis Hassabis 在他的一篇论文中就提到了人类大脑“海马体”的记忆回放也是类似的机制。大规模神经网络大脑的工作方式肯定不是靠某人用规则来编程。- Geoffrey Hinton\n大规模神经网络的竞赛从成立于2011 年的Google Brain 开始，现在属于Google Research。他们推动了 TensorFlow 语言的开发，提出了万能模型Transformer 的技术方案并在其基础上开发了BERT，我们在第四章中将详细讨论这些。\nDeepMind 是这个时代的传奇之一，在2014年被 Google 以5.25 亿美元收购的。它专注游戏算法，其使命是&quot;解决智能问题&quot;，然后用这种智能来 &quot;解决其他一切问题&quot;！DeepMind 的团队开发了一种新的算法Deep Q-Network (DQN)，它可以从经验中学习。2015 年10 月AlphaGo 项目首次在围棋中击败人类冠军李世石；之后的AlphaGo Zero 用新的可以自我博弈的改进算法让人类在围棋领域再也无法翻盘。另一个传奇OpenAI，它是一个由Elon Musk, Sam Altman, Peter Thiel, 还有Reid Hoffman 在2015年共同出资十亿美金创立的科研机构，其主要的竞争对手就是 DeepMind。OpenAI 的使命是通用人工智能（AGI –Artificial General Intelligence），即一种高度自主且在大多数具有经济价值的工作上超越人类的系统。2020年推出的 GPT-3 是目前最好的自然语言生成工具（NLP - Natural Language Processing）之一，通过它的 API 可以实现自然语言同步翻译、对话、撰写文案，甚至是代码（Codex），以及现在最流行的生成图像（DALL·E）。\nGartner AI HypeCycle\nGartner 的技术炒作周期（HypeCycle）很值得一看，这是他们 2022 年最新的关于AI 领域下各个技术发展的成熟度预估，可以快速了解AI 进化史这一章中不同技术的发展阶段。![图片] 配图08：Gartner AI HypeCycle 2022\n神经网络，这个在上世纪60 年代碰到的挫折，然后在2012 年之后却迎来了新生。反向传播花了这么长时间才被开发出来的原因之一就是该功能需要计算机进行乘法矩阵运算。在上世纪70 年代末，世界上最强的的超级电脑之一Cray-1，每秒浮点运算速度 50 MFLOP，现在衡量 GPU 算力的单位是TFLOP（Trillion FLOPs），Nvidia 用于数据中心的最新GPU Nvidia Volta 的性能可以达到125 TFLOP，单枚芯片的速度就比五十年前世界上最快的电脑强大 250 万倍。技术的进步是多维度的，一些生不逢时的理论或者方法，在另一些技术条件达成时，就能融合出巨大的能量。02\n软件2.0 的崛起未来的计算机语言将更多得关注目标，而不是由程序员来考虑实现的过程。- Marvin Minsky\nSoftware 2.0 概念的最早提出人是Andrej Karpathy，这位从小随家庭从捷克移民来加拿大的天才少年在多伦多大学师从 Geoffrey Hinton，然后在斯坦福李飞飞团队获得博士学位，主要研究 NLP 和计算机视觉，同时作为创始团队成员加入了OpenAI，Deep Learning 的关键人物和历史节点都被他点亮。在2017 年被Elon Musk 挖墙脚到了Tesla 负责自动驾驶研发，然后就有了重构的FSD（Full Self-Driving）。\n按照Andrej Karpathy 的定义- “软件2.0 使用更抽象、对人类不友好的语言生成，比如神经网络的权重。没人参与编写这些代码，一个典型的神经网络可能有数百万个权重，用权重直接编码比较困难”。Andrej 说他以前试过，这几乎不是人类能干的事儿。。![图片] 配图09：Andrej Karpathy 和神经网络权重2.1 范式转移在创建深度神经网络时，程序员只写几行代码，让神经网络自己学习，计算权重，形成网络连接，而不是手写代码。这种软件开发的新范式始于第一个Machine Learning 语言TensorFlow，我们也把这种新的编码方式被称为软件 2.0。在 Deep Learning 兴起之前，大多数人工智能程序是用Python 和JavaScript 等编程语言手写的。人类编写了每一行代码，也决定了程序的所有规则。![图片] 配图10：How does Machine Learning work？（TensorFlow）\n相比之下，随着Deep Learning 技术的出现，程序员利用这些新方式，给程序指定目标。如赢得围棋比赛，或通过提供适当输入和输出的数据，如向算法提供具有&quot;SPAM” 特征的邮件和其他没有&quot;SPAM” 特征的邮件。编写一个粗略的代码骨架（一个神经网络架构），确定一个程序空间的可搜索子集，并使用我们所能提供的算力在这个空间中搜索，形成一个有效的程序路径。在神经网络里，我们一步步地限制搜索范围到连续的子集上，搜索过程通过反向传播和随机梯度下降（Stochastic Gradient Descent）而变得十分高效。\n神经网络不仅仅是另一个分类器，它代表着我们开发软件的范式开始转移，它是软件2.0。\n软件1.0 人们编写代码，编译后生成可以执行的二进制文件；但在软件2.0 中人们提供数据和神经网络框架，通过训练将数据编译成二进制的神经网络。在当今大多数实际应用中，神经网络结构和训练系统日益标准化为一种商品，因此大多数软件2.0 的开发都由模型设计实施和数据清理标记两部分组成。这从根本上改变了我们在软件开发迭代上的范式，团队也会因此分成了两个部分:2.0 程序员负责模型和数据，而那些1.0 程序员则负责维护和迭代运转模型和数据的基础设施、分析工具以及可视化界面。Marc Andreessen 的经典文章标题《Why Software Is Eating the World》现在可以改成这样：“软件（1.0）正在吞噬世界，而现在人工智能（2.0）正在吞噬软件！\n2.2 软件的演化软件从1.0 发展到软件2.0，经过了一个叫做“数据产品”的中间态。当顶级软件公司在了解大数据的商业潜力后，并开始使用 Machine Learning 构建数据产品时，这种状态就出现了。下图来自Ahmad Mustapha 的一篇文章《The Rise of Software 2.0》很好地呈现了这个过渡。\n![图片] 配图11：软件产品演化的三种状态\n这个中间态也叫大数据和算法推荐。在现实生活中，这样的产品可以是Amazon 的商品推荐，它们可以预测客户会感兴趣什么，可以是Facebook 好友推荐，还可以是Netflix 电影推荐或Tiktok 的短视频推荐。还有呢？Waze 的路由算法、Airbnb 背后的排名算法等等，总之琳琅满目。数据产品有几个重要特点：1、它们都不是软件的主要功能，通常是为了增加体验，达成更好的用户活跃以及销售目标；2、能够随着数据的增加而进化；3、大部分都是基于传统 ML 实现的，最重要的一点数据产品是可解释的。但有些行业正在改变，Machine Learning 是主体。当我们放弃通过编写明确的代码来解决复杂问题时，这个到2.0 技术栈的转变就发生了，在过去几年中，很多领域都在突飞猛进。语音识别曾经涉及大量的预处理、高斯混合模型和隐式Markov 模型，但今天几乎完全被神经网络替代了。早在1985 年，知名信息论和语言识别专家Fred Jelinek 就有一句经常被引用的段子：“每当我解雇一个语言学家，我们的语音识别系统的性能就会得到提高”。![图片] 配图12：图解软件 2.0 的代表应用除了大家熟悉的图像语音识别、语音合成、机器翻译、游戏挑战之外，AI 在很多传统系统也看到了早期的转型迹象。例如The Case for Learned Index Structures 用神经网络取代了数据管理系统的核心组件，在速度上比B-Trees 缓存优化快70%，同时节省了一个数量级的内存。\n所以，软件2.0 的范式具备了这几个新特征：1、Deep Learning 是主体，所有的功能都是围绕神经网络的输入输出构建的，例如语音识别、自动驾驶；2、可解释性并不重要，一个好的大数据推荐广告可以告诉客户用户看到这条广告的理由，但你没法从神经网络中找到规则，至少目前不行；3、高研发投入与低开发投入，现在大量的成功都来自大学和科技公司的研究部门，论文绝对比应用多。。\n2.3 软件2.0 的优势为什么我们应该倾向于将复杂的程序移植到软件2.0 中？Andrej Karpathy 在《Software 2.0》中给出了一个简单的答案：它们在实践中表现得更好！\n容易被写入芯片由于神经网络的指令集相对较小，主要是矩阵乘法（Matrix Multiplication）和阈值判断（Thresholding at Zero），因此把它们写入芯片要容易得多，例如使用定制的 ASIC、神经形态芯片等等（Alan Turing 在设计ACE 时就这样考虑了）。例如，小而廉价的芯片可以带有一个预先训练好的卷积网络，它们可以识别语音、合成音频、处理视觉信号。当我们周围充斥着低能耗的智能时，世界将会因此而大不同（好坏皆可）。非常敏捷敏捷开发意味着灵活高效。如果你有一段C++ 代码，有人希望你把它的速度提高一倍，那么你需要系统性地调优甚至是重写。然而，在软件2.0 中，我们在网络中删除一半的通道，重新训练，然后就可以了。。它的运行速度正好提升两倍，只是输出更差一些，这就像魔法。相反，如果你有更多的数据或算力，通过添加更多的通道和再次训练，你的程序就能工作得更好。模块可以融合成一个最佳的整体做过软件开发的同学都知道，程序模块通常利用公共函数、API 或远程调用来通讯。然而，如果让两个原本分开训练的软件2.0 模块进行互动，我们可以很容易地通过整体进行反向传播来实现。想象一下，如果你的浏览器能够自动整合改进低层次的系统指令，来提升网页加载效率，这将是一件令人惊奇的事情。但在软件2.0 中，这是默认行为。它做得比你好最后，也是最重要的一点，神经网络比你能想到的任何有价值的垂直领域的代码都要好，目前至少在图像、视频、声音、语音相关的任何东西上，比你写的代码要好。2.4 Bug 2.0\n对于传统软件，即软件1.0，大多数程序都通过源代码保存，这些代码可能少至数千行，多至上亿行。据说，谷歌的整个代码库大约有 20 亿行代码。无论代码有多少，传统的软件工程实践表明，使用封装和模块化设计，有助于创建可维护的代码，很容易隔离Bug 来进行修改。但在新的范式中，程序被存储在内存中，作为神经网络架构的权重，程序员编写的代码很少。软件2.0 带来了两个新问题：不可解释和数据污染。因为训练完成的神经网络权重，工程师无法理解（不过现在对理解神经网络的研究有了很多进展，第六章会讲到），所以我们无法知道正确的执行是为什么？错误又是因为什么？这个和大数据算法有很大的不同，虽然大多数的应用只关心结果，无需解释；但对于一些安全敏感的领域，比如自动驾驶和医疗应用，这确实很重要。在2.0 的堆栈中，数据决定了神经网络的连接，所以不正确的数据集和标签，都会混淆神经网络。错误的数据可能来自失误、也可能是人为设计，或者是有针对性地投喂混淆数据（这也是人工智能领域中新的程序道德规范问题）。例如iOS 系统的自动拼写功能被意外的数据训练污染了，我们在输入某些字符的时候就永远得不到正确的结果。训练模型会认为污染数据是一个重要的修正，一旦完成训练部署，这个错误就像病毒一样传播，到达了数百万部iPhone 手机。所以在这种2.0 版的Bug 中，需要对数据以及程序结果进行良好的测试，确保这些边缘案例不会使程序失败。在短期内，软件2.0 将变得越来越普遍，那些没法通过清晰算法和软件逻辑化表述的问题，都会转入2.0 的新范式，现实世界并不适合整齐地封装。', 'doi': '', 'published_date': '2022-11-15T09:06:40+00:00', 'pdf_url': '', 'url': 'https://news.qq.com/rain/a/20221112A04S4N00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来_中央网络安全和信息化委员会办公室', 'authors': [], 'abstract': '人工智能的历史、现状和未来\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能的历史、现状和未来2019年02月16日 12:05来源：\n求是[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n2018年2月25日，在平昌冬奥会闭幕式“北京8分钟”表演中，由沈阳新松机器人自动化股份有限公司研发的智能移动机器人与轮滑演员进行表演。 新华社记者李钢/摄\n![] \n2018年5月3日，中国科学院发布国内首款云端人工智能芯片，理论峰值速度达每秒128万亿次定点运算，达到世界先进水平。 新华社记者金立旺/摄\n![] \n2017年10月，在沙特阿拉伯首都利雅得举行的“未来投资倡议”大会上，机器人索菲亚被授予沙特公民身份，她也因此成为全球首个获得公民身份的机器人。图为2018年7月10日，在香港会展中心，机器人索菲亚亮相主舞台。 ISAAC LAWRENCE/视觉中国\n![] \n2018年11月22日， 在“伟大的变革——庆祝改革开放40周年大型展览”上，第三代国产骨科手术机器人“天玑”正在模拟做手术，它是国际上首个适应症覆盖脊柱全节段和骨盆髋臼手术的骨科机器人，性能指标达到国际领先水平。 麦田/视觉中国\n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。**概念与历程**\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n**现状与影响**\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域产生积极正面影响。另一方面，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能系统可能存在的歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题已经显现出来，需要抓紧提供解决方案。**趋势与展望**\n经过60多年的发展，人工智能在算法、算力（计算能力）和算料（数据）等“三算”方面取得了重要突破，正处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有诸多瓶颈。那么在可以预见的未来，人工智能发展将会出现怎样的趋势与特征呢？\n从专用智能向通用智能发展。如何实现从专用人工智能向通用人工智能的跨越式发展，既是下一代人工智能发展的必然趋势，也是研究与应用领域的重大挑战。2016年10月，美国国家科学技术委员会发布《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。阿尔法狗系统开发团队创始人戴密斯·哈萨比斯提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年成立了通用人工智能实验室，众多感知、学习、推理、自然语言理解等方面的科学家参与其中。\n从人工智能向人机混合智能发展。借鉴脑科学和认知科学的研究成果是人工智能的一个重要研究方向。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。在我国新一代人工智能规划和美国脑计划中，人机混合智能都是重要的研发方向。从“人工+智能”向自主智能系统发展。当前人工智能领域的大量研究集中在深度学习，但是深度学习的局限是需要大量人工干预，比如人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据、用户需要人工适配智能系统等，非常费时费力。因此，科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿尔法狗系统的后续版本阿尔法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类人工智能”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低人员成本。\n人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、天文学等传统科学的发展。人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来10年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，可在现有基础上将劳动生产率提高40%；到2035年，美、日、英、德、法等12个发达国家的年均经济增长率可以翻一番。2018年麦肯锡公司的研究报告预测，到2030年，约70%的公司将采用至少一种形式的人工智能，人工智能新增经济规模将达到13万亿美元。\n人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出，未来5年人工智能将提升各行业运转效率。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n人工智能领域的国际竞争将日益激烈。当前，人工智能领域的国际竞赛已经拉开帷幕，并且将日趋白热化。2018年4月，欧盟委员会计划2018—2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略2018》重点推动物联网建设和人工智能的应用。世界军事强国也已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n人工智能的社会学将提上议程。为了确保人工智能的健康可持续发展，使其发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，制定完善人工智能法律法规，规避可能的风险。2017年9月，联合国犯罪和司法研究所（UNICRI）决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。美国白宫多次组织人工智能领域法律法规问题的研讨会、咨询会。特斯拉等产业巨头牵头成立OpenAI等机构，旨在“以有利于整个人类的方式促进和发展友好的人工智能”。\n**态势与思考**\n当前，我国人工智能发展的总体态势良好。但是我们也要清醒看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少值得重视的问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。高度重视。党中央、国务院高度重视并大力支持发展人工智能。习近平总书记在党的十九大、2018年两院院士大会、全国网络安全和信息化工作会议、十九届中央政治局第九次集体学习等场合多次强调要加快推进新一代人工智能的发展。2017年7月，国务院发布《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动。国家发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n态势喜人。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成为全球人工智能投融资规模最大的国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。根据2017年爱思唯尔文献数据库统计结果，我国在人工智能领域发表的论文数量已居世界第一。近两年，中国科学院大学、清华大学、北京大学等高校纷纷成立人工智能学院，2015年开始的中国人工智能大会已连续成功召开四届并且规模不断扩大。总体来说，我国人工智能领域的创新创业、教育科研活动非常活跃。\n差距不小。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在明显差距。在全球人工智能人才700强中，中国虽然入选人数名列第二，但远远低于约占总量一半的美国。2018年市场研究顾问公司Compass Intelligence对全球100多家人工智能计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国对人工智能可能产生的社会影响还缺少深度分析，制定完善人工智能相关法律法规的进程需要加快。\n前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出，到2030年人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n当前是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧等，需要深入思考。树立理性务实的发展理念。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。实现机器在任意现实环境的自主智能和通用智能，仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此，发展人工智能要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。重视固本强基的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。面临发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。我们要按照习近平总书记提出的支持科学家勇闯人工智能科技前沿“无人区”的要求，努力在人工智能发展方向和理论、方法、工具、系统等方面取得变革性、颠覆性突破，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。构建自主可控的创新生态。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强。我们要以问题为导向，主攻关键核心技术，加快建立新一代人工智能关键共性技术体系，全面增强人工智能科技创新能力，确保人工智能关键核心技术牢牢掌握在自己手里。要着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。同时，我们要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过实施标准加速人工智能驱动经济社会转型升级的进程。推动共担共享的全球治理。目前看，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能进一步拉大发达国家和发展中国家的生产力发展水平差距。在发展中国家中，我国有望成为全球人工智能竞争中的领跑者，应布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合“一带一路”建设，让“智能红利”助推共建人类命运共同体。（作者：谭铁牛，系中央人民政府驻香港特别行政区联络办公室副主任、中国科学院院士）关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:12:01', 'doi': '', 'published_date': '2019-02-17T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2019-02/16/c_1124122584.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '中国人工智能40年发展简史', 'authors': [], 'abstract': '- [新浪首页] \n- [新闻] \n- [体育] \n- [财经] \n- [娱乐] \n- [科技] \n- [博客] \n- [图片] \n- [专栏] \n- [更多] \n\n- [汽车] [教育] [时尚] [女性] [星座] [健康] \n- [房产] [历史] [视频] [收藏] [育儿] [读书] \n- [佛学] [游戏] [旅游] [邮箱] [导航] \n\n[移动客户端] \n\n- [新浪微博] \n- [新浪新闻] \n- [新浪财经] \n- [新浪体育] \n- [新浪众测] \n- [新浪博客] \n- [新浪视频] \n- [新浪游戏] \n- [天气通] \n\n[我的收藏] \n\n[注册] \n\n[登录] \n\n[滚动新闻] >正文\n\n行情股吧新闻外汇新三板\n\n# 中国人工智能40年发展简史\n\n中国人工智能40年发展简史\n\n2025年04月30日 17:06工信头条\n\n[新浪财经APP] [缩小字体] [放大字体] [收藏] [微博] [微信] [分享] \n\n[腾讯QQ] [QQ空间] \n\n智能机器是一种能够呈现出人类智能行为的机器。人工智能(ArtificialIntelligence，AI)是计算机科学或智能科学中涉及研究、设计和应用智能机器的一个分支。人工智能的近期主要目标在于研究用机器来模仿和执行人脑的某些智力功能，而远期目标是用自动机模仿人类的思维活动和智力功能。\n\n人工智能探索历史\n\n人类对人工智能和智能机器的梦想与追求，可以追溯到3000 多年前。中国也不乏这方面的故事与史料。\n\n近代科学技术的许多重大进展都是人类智慧、思维、梦想和奋斗的成果。人类历史上从来没有出现过像今天这样的思想大解放，关于宇宙、星球、生命、人类、时空、进化和智能等思想与作品，如雨后春笋破土而出，似百花争艳迎春怒放。其中，人工智能尤其引人注目。进入20世纪后，人工智能开始孕育于人类社会母胎。到20世纪30—40年代发生了两件极其重要的事件：数理逻辑的形式化和智能可计算(机器能思维)的思想，建立了计算与智能关系的概念。被称为“人工智能之父”(The father of AI)的图灵(Turing AM)，于1936年创立了自动机理论，提出一个理论计算机模型，奠定电子计算机设计基础，促进人工智能特别是思维机器的研究。1950 年图灵的论文“机器能思考吗?”，为即将问世的人工智能提供了科学性和开创性的构思。\n\n1956 年夏季由麦卡锡(McCarthyJ)、明斯基(Minsky ML)、罗彻斯特(Lochester N)和香农(Shannon CE)共同发起，并邀请其他6位年轻的科学家，在美国达特茅斯(Dartmouth)大学举办了一次长达两个月的十人研讨会，讨论用机器模拟人类智能问题，首次使用“人工智能”这一术语。这是人类历史上第一次人工智能研讨会，标志着国际人工智能学科的诞生，具有十分重要的历史意义。发起这次研讨会的人工智能学者麦卡锡和明斯基，则被誉为国际人工智能的“奠基者”或“创始人”(The founding father)，有时也称为“人工智能之父”。\n\n中国的人工智能经历了怎样的发展过程?取得哪些成绩?存在什么问题?面临何种机遇?有哪些解决方案?本文力图逐一探讨。\n\n一、发展过程\n\n与国际上人工智能的发展情况相比，国内的人工智能研究不仅起步较晚，而且发展道路曲折坎坷，历经了质疑、批评甚至打压的十分艰难的发展历程。\n\n01\n\n迷雾重重\n\n20世纪50—60年代，人工智能在西方国家得到重视和发展，而在苏联却受到批判，将其斥为“资产阶级的反动伪科学”。当时，受苏联批判人工智能和控制论(Cybernetics)的影响，中国在20世纪50年代几乎没有人工智能研究;20世纪60年代后期和70年代，虽然苏联解禁了控制论和人工智能的研究，但因中苏关系恶化，中国学术界将苏联的这种解禁斥之为“修正主义”，人工智能研究继续停滞。那时，人工智能在中国要么受到质疑，要么与“特异功能”一起受到批判，被认为是伪科学和修正主义。《摘译外国自然科学哲学》月刊1976年第3期刊文称：“在批判‘图像识别’和‘人工智能’研究领域各种反动思潮的斗争中，走自己的道路”。这足见中国人工智能研究迷雾重重的艰难处境。\n\n1978年3月，全国科学大会在北京召开。大会提出“向科学技术现代化进军”的战略决策，打开解放思想的先河，促进中国科学事业的发展，使中国科技事业迎来了科学的春天\\[9\\]。这是中国改革开放的先声，广大科技人员出现了思想大解放，人工智能也在酝酿着进一步的解禁。吴文俊提出的利用机器证明与发现几何定理的新方法——几何定理机器证明(图1)，获得1978年全国科学大会重大科技成果奖就是一个好的征兆。\n\n20世纪80年代初期，钱学森等主张开展人工智能研究，中国的人工智能研究进一步活跃起来。但是，由于当时社会上把“人工智能”与“特异功能”混为一谈，使中国人工智能走过一段很长的弯路。一方面，包括许多人工智能学者在内的研究者把人工智能与特异功能搅在一起“研究”;另一方面，社会上在批判“特异功能”时将“人工智能”一起进行批判，把两者一并斥之为“伪科学”。\n\n02\n\n艰难起步\n\n20世纪70年代末至80年代，知识工程和专家系统在欧美发达国家得到迅速发展，并取得重大的经济效益。当时中国相关研究处于艰难起步阶段，一些基础性的工作得以开展。\n\n1) 派遣留学生出国研究人工智能。\n\n改革开放后，自1980 年起中国大批派遣留学生赴西方发达国家研究现代科技，学习科技新成果，其中包括人工智能和模式识别等学科领域。这些人工智能“海归”专家，已成为中国人工智能研究与开发应用的学术带头人和中坚力量，为发展中国人工智能做出举足轻重的贡献。\n\n2) 成立中国人工智能学会。\n\n1981 年9 月，中国人工智能学会(CAAI)在长沙成立，秦元勋当选第一任理事长。于光远在大会期间主持了一次大型座谈会，讨论有关人工智能的一些认识问题。他指出：“人工智能是一门新兴的科学，我们应该积极支持;对所谓‘人体特异功能’的研究是一门伪科学，不但不应该支持，而且要坚决反对。”1982年，中国人工智能学会刊物《人工智能学报》在长沙创刊，成为国内首份人工智能学术刊物。\n\nCAAI首任理事长秦元勋也颇受争议。秦元勋获美国哈佛大学博士学位后于1948年回国，历任中国科学院数学研究所研究员、执行副所长，中国核学会计算物理学会理事长，中国人工智能学会首届理事长等职。他在常微分方程的定性理论、运动稳定性、近似解析、机器推理等方面的研究，在中国处于开创的地位。其中极限环的研究，具有国际先进水平。他曾负责完成了中国第一颗原子弹和氢弹的威力计算工作，是1982年国家自然科学奖一等奖的原子弹氢弹设计原理中的物理力学数学理论项目的主要工作者之一，并开辟了计算物理学这一新的学科分支。\n\n3) 开始人工智能的相关项目研究。\n\n20世纪70年代末至80年代前期，一些人工智能相关项目已被纳入国家科研计划。例如，在1978年召开的中国自动化学会年会上，报告了光学文字识别系统、手写体数字识别、生物控制论和模糊集合等研究成果，表明中国人工智能在生物控制和模式识别等方向的研究已开始起步。又如，1978年把“智能模拟”纳入国家研究计划。不过，当时还未能直接提到“人工智能”研究，说明中国的人工智能禁区有待进一步打开。\n\n03\n\n迎来曙光\n\n1984年召开了全国智能计算机及其系统学术讨论会，1985年又召开了全国首届第五代计算机学术研讨会。1986年起把智能计算机系统、智能[机器人] 和智能信息处理等重大项目列入国家高技术研究发展计划(863计划)。\n\n1986 年，清华大学校务委员会经过三次讨论后，决定同意在清华大学出版社出版《人工智能及其应用》著作。\n\n1987年7月《人工智能及其应用》在清华大学出版社公开出版，成为国内首部具有自主知识产权的人工智能专著。接着，中国首部人工智能、机器人学和智能控制著作分别于1987年、1988 年和1990 年问世。1988 年2月，主管国家科技工作的宋健亲笔致信蔡自兴(图2)，对《人工智能及其应用》的公开出版和人工智能学科给予高度评价，指出该人工智能著作的编著和出版“使这一前沿学科的最精彩的成就迅速与中国读者见面，这对人工智能在中国的传播和发展必定会起到重大的推动作用……我深信，以人工智能和模式识别为带头的这门新学科，将为人类迈进智能自动化时期做出奠基性贡献。”宋健对该书的高度评价，体现出他对发展中国人工智能的关注和对作者的鼓励，对中国人工智能的发展产生了重大和深远的影响。\n\n在这封信中宋健还提到：“十年前，当我们和钱先生修订工程控制论时，尚无系统参考书可言，只能断断续续介绍一些思路。现在钱先生看到此书，也一定会欣喜万分。”这体现了宋健的谦虚品德，也表现出钱学森当时对人工智能的热烈支持。\n\n1987年《模式识别与人工智能》杂志创刊。\n\n1989年首次召开了中国人工智能联合会议(CJCAI)，至2004年共召开了8次。此外，还曾经联合召开过6届中国机器人学联合会议。\n\n1993年起，把智能控制和智能自动化等项目列入国家科技攀登计划。\n\n1993年7月，宋健应邀为中国人工智能学会智能机器人分会成立题词“人智能则国智科技强则国强”，向成立大会表示祝贺。本题词很好地阐明了人工智能与提高民族素质、增强科技实力和建设现代化强国的辩证关系。\n\n04\n\n蓬勃发展\n\n进入21世纪后，更多的人工智能与智能系统研究课题获得国家自然科学基金重点和重大项目、国家高技术研究发展计划(863 计划)和国家重点基础研究发展计划(973计划)项目、科技部科技攻关项目、工信部重大项目等各种国家基金计划支持，并与中国国民经济和科技发展的重大需求相结合，力求为国家做出更大贡献。这方面的研究项目很多，代表性的研究有视觉与听觉的认知计算、面向Agent的智能计算机系统、中文智能搜索引擎关键技术、智能化农业专家系统、虹膜识别、语音识别、人工心理与人工情感、基于仿人机器人的人机交互与合作、工程建设中的智能辅助决策系统、未知环境中移动机器人导航与控制等。\n\n2006年8月，中国人工智能学会联合其他学会和有关部门，在北京举办了“庆祝人工智能学科诞生50周年”大型庆祝活动。除了人工智能国际会议外，纪念活动还包括由中国人工智能学会主办的首届中国象棋计算机博弈锦标赛暨首届中国象棋人机大战。东北大学的“棋天大圣”象棋软件获得机器博弈冠军;“浪潮天梭”超级计算机以11：9的成绩战胜了中国象棋大师。这些赛事的成功举办，彰显了中国人工智能科技的长足进步，也向广大公众进行了一次深刻的人工智能基本知识普及教育。主办者认为，这次中国象棋人机大战“无论赢家是人类大师或超级计算机，都是人类智慧的胜利”。\n\n同年，《智能系统学报》创刊(图3)，这是继《人工智能学报》和《模式识别与人工智能》之后国内第3份人工智能类期刊。他们为国内人工智能学者和高校师生提供了一个学术交流平台，对中国人工智能研究与应用起到促进作用。\n\n2009 年，中国人工智能学会牵头组织，向国家学位委员会和国家教育部提出设置“智能科学与技术”学位授权一级学科的建议。该建议指出：现在信息化向智能化迈进”的趋势已经显现;因此，今天培养的智能科学技术高级人才大军，正好赶上明天信息化向智能化大规模迈进的需要。为此，一个顺理而紧迫的建议就是：为了适应信息化向智能化迈进的大趋势，为了实现建设创新型国家的大目标，在中国学位体系中增设智能科学与技术博士和硕士学位授权一级学科。这个建议凝聚了中国广大人工智能教育工作者的心智心血和他们的远见卓识，对中国人工智能学科建设具有十分深远的意义。\n\n05\n\n国家战略\n\n近两年来，中国的人工智能已发展成为国家战略。\n\n2014年6月9日，中国科学院第十七次院士大会、中国工程院第十二次院士大会开幕式上发表重要讲话强调：“由于大数据、云计算、移动互联网等新一代信息技术同机器人技术相互融合步伐加快，3D打印、人工智能迅猛发展，制造机器人的软硬件技术日趋成熟，成本不断降低，性能不断提升，军用无人机、自动驾驶汽车、家政服务机器人已经成为现实，有的人工智能机器人已具有相当程度的自主思维和学习能力。……我们要审时度势、全盘考虑、抓紧谋划、扎实推进。”这是党和国家最高领导人首次对人工智能和相关智能技术的高度评价，是对开展人工智能和智能机器人技术开发的庄严号召和大力推动。\n\n2015年十二届全国人大三次会议上，提出：“人工智能技术将为基于互联网和移动互联网等领域的创新应用提供核心基础。未来人工智能技术将进一步推动关联技术和新兴科技、新兴产业的深度融合，推动新一轮的信息技术革命，势必将成为我国经济结构转型升级的新支点。”这是对人工智能技术的重要作用给予的充分肯定，是对人工智能的有力促进。\n\n这些战略任务，无论是提高创新能力、信息化与工业化深度融合、强化工业基础能力、加强质量品牌建设，或是推动重点领域突破发展、全面推行绿色制造、推进制造业结构调整、发展服务型制造和生产性服务业、提高制造业国际化发展水平，都离不开人工智能的参与，都与人工智能的发展密切相关。人工智能是智能制造不可或缺的核心技术。\n\n2016年4月，工业和信息化部、国家发展改革委、财政部等三部委联合印发了《机器人产业发展规划(2016—2020年)》，为“十三五”期间中国机器人产业发展描绘了清晰的蓝图。该发展规划提出的大部分任务，如智能生产、智能物流、智能工业机器人、人机协作机器人、消防救援机器人、手术机器人、智能型公共服务机器人、智能护理机器人等，都需要采用各种人工智能技术。人工智能也是智能机器人产业发展的关键核心技术。\n\n2016年5月，国家发改委和科技部等4部门联合印发《“互联网+”人工智能三年行动实施方案》，明确未来3年智能产业的发展重点与具体扶持项目，进一步体现出人工智能已被提升至国家战略高度。根据方案的内容，未来3年将在3个大方面、9个小项推进智能产业发展。\n\n《机器人产业发展规划(2016—2020 年)》和《“互联网+”人工智能三年行动实施方案》的发布与施行，体现了中国已把人工智能技术提升到国家发展战略的高度，为人工智能的发展创造了前所未有的优良环境，也赋予人工智能艰巨而光荣的历史使命。\n\n2015年7月在北京召开了“2015中国人工智能大会”。发表了《中国人工智能白皮书》，包括“中国智能机器人白皮书”、“中国自然语言理解白皮书”、“中国模式识别白皮书”、“中国智能驾驶白皮书”和“中国机器学习白皮书”，为中国人工智能相关行业的科技发展描绘一个轮廓，给产业界指引一个发展方向。\n\n2016年4月由中国人工智能学会发起，联合20余家国家一级学会，在北京举行“2016 全球人工智能技术大会暨人工智能60 周年纪念活动启动仪式”(图5)。这次活动恰逢国际人工智能诞辰60周年，谷歌AlphaGo与韩国围棋九段棋手李世石上演“世纪人机大战”(图6)，将人工智能的关注度推到了前所未有的高度。启动仪式共同庆祝国际人工智能诞辰60周年，传承和弘扬人工智能的科学精神，开启智能化时代的新征程。\n\n现在，人工智能已发展成为国家发展战略，中国已有数以10万计的科技人员和大学师生从事不同层次的人工智能相关领域研究、学习、开发与应用，人工智能研究与应用已在中国空前开展，硕果累累，必将为促进其他学科的发展和中国的现代化建设做出新的重大贡献。\n\n二、主要成就\n\n中国的人工智能研究开发、学科建设、产业应用和社会服务等方面，已经取得不俗的成就，主要可以从以下几点得到证实。\n\n01\n\n形成人工智能学科\n\n1981年9月建立了全国性的人工智能组织中国人工智能学会(CAAI)，标志着中国人工智能学科的诞生。1982年在长沙创办中国人工智能学会刊物《人工智能学报》，成为中国人工智能学科领域的第一份学术刊物。中国人工智能学会大会每两年举行一次，至目前已举办16届。中国人工智能学会成立后，又相继成立了中国人工智能学会智能机器人专业委员会、机器学习专业委员会、模式识别专业委员会、自然语言处理专业委员会和智能控制专业委员会、人工智能教育工作委员会等。\n\n此外，中国计算机学会的一些二级学会也开展人工智能相关学术活动，为中国人工智能的发展做出了应有贡献。例如，中国计算机学会成立了人工智能与模式识别专业委员会，中国自动化学会成立了模式识别与机器智能专业委员会以及智能自动化专业委员会等二级学会。有些省市也成立了地方人工智能学会。1989—2004 年，由中国人工智能学会、中国计算机学会等多个学会联合举办过7届中国人工智能联合会议(CJCAI)。\n\n与人工智能密切相关的机器学习、模式识别、智能机器人、自然语言处理、专家系统等领域的学术组织也先后成立，学术活动也十分热烈。例如，国内机器学习的重要学术活动包括每两年举行一次的中国机器学习会议和每年举行的中国机器学习及其应用研讨会。前者由中国计算机学会人工智能与模式识别专业委员会协办，目前已历经15届。后者每届会议包括特邀报告、大会交流及Top Conference Review等部分，迄今已历经13届。又如，中国人工智能学会智能机器人专业委员会自1993年成立以来，每两年举行一次全国智能机器人学术会议，已组织过11届，还与其他学会共同举办过6次中国机器人联合会议。在王湘浩倡导与组织下，全国高校人工智能研讨会研究班自1980年起每年举行一次，是国内最早的人工智能学术研讨活动。\n\n这些人工智能学术组织和会议开展广泛深入的国内外学术交流，对开展人工智能学术活动和组织科技交流起到积极的作用，有力推动了中国人工智能科技发展和学科建设。\n\n02\n\n科学研究成绩斐然\n\n国家已先后设立了各种与人工智能相关的研究课题，如国家自然科学基金重大专项、重点项目和面上项目，国家863计划项目，国家重大战略项目智能制造2025等。在这些科研基金的支持下，国内人工智能研究已取得许多突出成果。\n\n1)人工智能基础研究成果突出\n\n除了前面提到的几何定理证明的“吴氏方法”外，吴文俊还于2004 年发表了重要论文“计算机时代的脑力劳动机械化与科学技术现代化”，宣布他在几何定理证明“机械化”方面的系列成果，指出：“在几何定理机器证明取得成功之后的20多年来，笔者与许多志同道合的同志们在科技部、科学院、基金委等大力支持下，开展了一场可谓‘数学机械化’的‘运动’，在理论与应用诸多方面都已取得了若干成功。”\n\n国内学者在人工智能的诸多领域，如问题求解、不确定推理、泛逻辑理论、拓扑学、模式识别、图像处理、机器学习、专家系统、智能计算和智能控制等领域的基础研究也多有建树，取得一批具有国际先进水平的创造性成果。例如，在模式识别方面，对文字识别、语音识别(图7)、指纹识别、人脸识别、虹膜识别和步态识别等进行深入研究，涉及生物医学、卫星遥感、机器人视觉、货物检测、目标跟踪、自主导航、保安、银行、交通、军事、电子商务和多媒体网络通信等应用领域。\n\n又如，机器学习也是人工智能的核心研究领域之一。现在机器学习的大数据往往体现出多源异构、语义复杂、规模巨大、动态多变等特殊性质，为传统机器学习技术带来了新的挑战。为应对这一挑战，国内科技企业巨头华为、百度等与国外巨头谷歌、微软、亚马逊等展开竞争，纷纷成立以机器学习技术为核心的研究院，以充分挖掘大数据中蕴含的巨大商业与应用价值。深度学习是机器学习领域一个新兴的子领域与研究方向，它是一种通过多层表示来对数据之间的复杂关系进行建模的算法。深度学习模仿人脑结构，具有更强的建模和推理能力，能够更有效地解决多类复杂的智能问题。近年来，中国在深度学习研究方面也取得重要进展，一些研究成果接近或达到国际先进水平。\n\n中国学者在自动规划领域也取得开创性成果。1985年提出与发展了基于专家系统的机器人规划机理与方法，实现了人工智能专家系统与机器人技术的结合，为基于知识的自动规划和高层控制开辟了一条新途径，对提高生产的智能化水平具有重要意义，并推动国内外机器人规划研究的发展。该成果被广泛引用，并被收入清华大学吴麒等主编的全国高校规划教材《自动控制原理》。1999年以来，又在机器人进化规划方面取得创新性成果。\n\n国内在认知计算、情感计算、模式识别、神经网络、智能驾驶、水下机器人和其他智能机器人等领域也取得一批具有国际先进水平的研究成果，培养了一批优秀的学术带头人：郭爱克、任继福、李衍达、王守觉、焦李成、贺汉根、蔡鹤皋、徐玉如和黄心汉等。\n\n此外，有些人工智能基础研究获得国际奖励，如1990年张钹获得ICL欧洲人工智能奖，蔡自兴指导的王勇博士获得2015 IEEE计算智能学会优秀博士学位论文奖等。\n\n值得一提的是美籍华裔学者王浩对人工智能的杰出贡献。1958 年夏天，王浩在纽约州的IBM实验室的一台IBM704机器上用汇编语言编写了3个程序，证明了罗素和怀特海《数学原理》中的200多个定理。他关于数理逻辑的一个命题被国际上定为“ 王氏悖论”。1966年，他在哈佛大学指导的博士生Stephen Cook，因NP 完全性方面的开创性研究成果而获得1982年图灵奖。王浩还与吴文俊进行了合作研究。\n\n2)专用人工智能开发有所突破\n\n中国在专用人工智能领域取得了突破性的进展，已在自然语言处理和语音识别、图像识别、机器学习、虚拟现实、智能处理器、认知计算、智能驾驶和智能机器人等方面取得一大批具有国际先进水平的应用成果。\n\n互联网和大数据推动人工智能进入了新的发展阶段。中国的智能语音技术在移动互联网、呼叫中心、智能家居、汽车电子等领域的研究与应用逐步深入，带动智能语音产业规模持续快速增长。2013年[科大讯飞] 以54.2%的市场份额继续处于国内领先地位。智能语音正在成为主流的交互方式之一。\n\n近几年在多层神经网络基础上发展起来的深度学习和深度神经网络已在中国很多模式识别领域获得成功应用。其中，中国科学院自动化研究所谭铁牛团队在虹膜识别领域，坚持从虹膜图像信息获取的源头进行系统创新，全面突破虹膜识别领域的成像装置、图像处理、特征抽取、识别检索、安全防伪等一系列关键技术，建立了虹膜识别比较系统的计算理论和方法体系，还建成目前国际上最大规模的共享虹膜图像库，已大规模用于煤矿人员辨识和北京城铁监控等，并在70个国家和地区的3000 多个科研团队推广使用，有力推动了虹膜识别学科发展。\n\n在2010年举行的国际上难度最高、规模最大的虹膜识别专业测评竞赛中，谭铁牛团队提交的算法，从来自25个国家和地区的41支参赛团队里脱颖而出，以测试性能指标超过第2名41.3%的绝对优势蝉联虹膜识别算法赛事冠军(图8)。在2008年进行的上届国际虹膜识别算法竞赛上，谭铁牛团队战胜来自35个国家和地区的97支参赛队伍。这充分展示出中国在虹膜识别领域领先国际的整体实力。\n\n在模式识别领域，石青云领衔的北大高科指纹技术有限公司在指纹识别领域取得领先成果，成为国家科技强警的利剑。\n\n专家系统已在国内获得广泛应用，应用领域涉及工业、农业等行业，其经济效益相当可观。例如，在冶金专家系统的开发与应用方面，已把专家系统技术用于高炉建模、监控与诊断等，建立了基于多核学习的高炉自动化框架、', 'doi': '', 'published_date': '2025-04-30T00:00:00+00:00', 'pdf_url': '', 'url': 'https://finance.sina.com.cn/roll/2025-04-30/doc-ineuxwev4150658.shtml', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '中国人工智能40年（上）_腾讯新闻', 'authors': [], 'abstract': '中国人工智能40年（上）\\_腾讯新闻\n# 中国人工智能40年（上）\n![头像]![] \n[\n人机与认知实验室] \n2025-04-25 05:43科技领域创作者\n【作者单位：湖南省自兴人工智能研究院，中南大学智能系统与智能软件研究所】智能机器是一种能够呈现出人类智能行为的机器。人工智能（ArtificialIntelligence，AI）是计算机科学或智能科学中涉及研究、设计和应用智能机器的一个分支。人工智能的近期主要目标在于研究用机器来模仿和执行人脑的某些智力功能，而远期目标是用自动机模仿人类的思维活动和智力功能[1]。\n人类对人工智能和智能机器的梦想与追求，可以追溯到3000多年前。中国也不乏这方面的故事与史料[2]。\n近代科学技术的许多重大进展都是人类智慧、思维、梦想和奋斗的成果。人类历史上从来没有出现过像今天这样的思想大解放，关于宇宙、星球、生命、人类、时空、进化和智能等思想与作品，如雨后春笋破土而出，似百花争艳迎春怒放。其中，人工智能尤其引人注目。进入20世纪后，人工智能开始孕育于人类社会母胎。到20世纪30—40年代发生了两件极其重要的事件：数理逻辑的形式化和智能可计算（机器能思维）的思想，建立了计算与智能关系的概念。被称为“人工智能之父”（The father of AI）的图灵（Turing AM），于1936年创立了自动机理论，提出一个理论计算机模型，奠定电子计算机设计基础，促进人工智能特别是思维机器的研究。1950年图灵的论文“机器能思考吗？”，为即将问世的人工智能提供了科学性和开创性的构思。\n1956年夏季由麦卡锡（McCarthyJ）、明斯基（Minsky ML）、罗彻斯特（Lochester N）和香农（Shannon CE）共同发起，并邀请其他6位年轻的科学家，在美国达特茅斯（Dartmouth）大学举办了一次长达两个月的十人研讨会，讨论用机器模拟人类智能问题，首次使用“人工智能”这一术语。这是人类历史上第一次人工智能研讨会，标志着国际人工智能学科的诞生，具有十分重要的历史意义。发起这次研讨会的人工智能学者麦卡锡和明斯基，则被誉为国际人工智能的“奠基者”或“创始人”（The founding father），有时也称为“人工智能之父”[3]。\n中国的人工智能经历了怎样的发展过程，取得哪些成绩，存在什么问题，面临何种机遇，有哪些解决方案？本文力图逐一探讨。**1发展过程**\n与国际上人工智能的发展情况相比，国内的人工智能研究不仅起步较晚，而且发展道路曲折坎坷，历经了质疑、批评甚至打压的十分艰难的发展历程。直到改革开放之后，中国的人工智能才逐渐走上发展之路。**1.1迷雾重重**\n20世纪50—60年代，人工智能在西方国家得到重视和发展，而在苏联却受到批判，将其斥为“资产阶级的反动伪科学”。当时，受苏联批判人工智能和控制论（Cybernetics）的影响[4]，中国在20世纪50年代几乎没有人工智能研究；20世纪60年代后期和70年代，虽然苏联解禁了控制论和人工智能的研究，但因中苏关系恶化，中国学术界将苏联的这种解禁斥之为“修正主义”，人工智能研究继续停滞。那时，人工智能在中国要么受到质疑，要么与“特异功能”一起受到批判，被认为是伪科学和修正主义。《摘译外国自然科学哲学》月刊1976年第3期刊文称：“在批判‘图像识别’和‘人工智能’研究领域各种反动思潮的斗争中，走自己的道路”。这足见中国人工智能研究迷雾重重的艰难处境[5\\~8]。\n![图片] 1978年3月，全国科学大会在北京召开。在华国锋主持的大会开幕式上，邓小平发表了“科学技术是生产力”的重要讲话。大会提出“向科学技术现代化进军”的战略决策，打开解放思想的先河，促进中国科学事业的发展，使中国科技事业迎来了科学的春天[9]。这是中国改革开放的先声，广大科技人员出现了思想大解放，人工智能也在酝酿着进一步的解禁。吴文俊提出的利用机器证明与发现几何定理的新方法——几何定理机器证明（图1），获得1978年全国科学大会重大科技成果奖就是一个好的征兆[10,11]。\n20世纪80年代初期，钱学森等主张开展人工智能研究，中国的人工智能研究进一步活跃起来[12,13]。但是，由于当时社会上把“人工智能”与“特异功能”混为一谈，使中国人工智能走过一段很长的弯路。一方面，包括许多人工智能学者在内的研究者把人工智能与特异功能搅在一起“研究”；另一方面，社会上在批判“特异功能”时将“人工智能”一起进行批判，把两者一并斥之为“伪科学”。\n**1.2艰难起步**\n20世纪70年代末至80年代，知识工程和专家系统在欧美发达国家得到迅速发展，并取得重大的经济效益。当时中国相关研究处于艰难起步阶段，一些基础性的工作得以开展。\n1） 派遣留学生出国研究人工智能。改革开放后，自1980年起中国大批派遣留学生赴西方发达国家研究现代科技，学习科技新成果，其中包括人工智能和模式识别等学科领域。这些人工智能“海归”专家，已成为中国人工智能研究与开发应用的学术带头人和中坚力量，为发展中国人工智能做出举足轻重的贡献。\n2） 成立中国人工智能学会。1981年9月，中国人工智能学会（CAAI）在长沙成立，秦元勋当选第一任理事长[14]。于光远在大会期间主持了一次大型座谈会，讨论有关人工智能的一些认识问题。他指出：“人工智能是一门新兴的科学，我们应该积极支持；对所谓‘人体特异功能’的研究是一门伪科学，不但不应该支持，而且要坚决反对。”[15]1982年，中国人工智能学会刊物《人工智能学报》在长沙创刊，成为国内首份人工智能学术刊物。\nCAAI首任理事长秦元勋也颇受争议。秦元勋获美国哈佛大学博士学位后于1948年回国，历任中国科学院数学研究所研究员、执行副所长，中国核学会计算物理学会理事长，中国人工智能学会首届理事长等职。他在常微分方程的定性理论、运动稳定性、近似解析、机器推理等方面的研究，在中国处于开创的地位。其中极限环的研究，具有国际先进水平。他曾负责完成了中国第一颗原子弹和氢弹的威力计算工作，是1982年国家自然科学奖一等奖的原子弹氢弹设计原理中的物理力学数学理论项目的主要工作者之一，并开辟了计算物理学这一新的学科分支[16]。\n3） 开始人工智能的相关项目研究。20世纪70年代末至80年代前期，一些人工智能相关项目已被纳入国家科研计划。例如，在1978年召开的中国自动化学会年会上，报告了光学文字识别系统、手写体数字识别、生物控制论和模糊集合等研究成果，表明中国人工智能在生物控制和模式识别等方向的研究已开始起步[17]。又如，1978年把“智能模拟”纳入国家研究计划。不过，当时还未能直接提到“人工智能”研究，说明中国的人工智能禁区有待进一步打开。\n**1.3迎来曙光**\n1984年1月和2月，邓小平分别在深圳和上海观看儿童与计算机下棋时，指示“计算机普及要从娃娃抓起”[18]。此后，中国人工智能研究的境遇有所好转。例如，人民日报关于人工智能的报道也渐渐多了起来[19,20]。20世纪80年代中期，中国的人工智能迎来曙光，开始走上比较正常的发展道路。\n国防科工委于1984年召开了全国智能计算机及其系统学术讨论会，1985年又召开了全国首届第五代计算机学术研讨会。1986年起把智能计算机系统、智能机器人和智能信息处理等重大项目列入国家高技术研究发展计划（863计划）。\n1986年，清华大学校务委员会经过三次讨论后，决定同意在清华大学出版社出版《人工智能及其应用》著作。\n1987年7月《人工智能及其应用》在清华大学出版社公开出版，成为国内首部具有自主知识产权的人工智能专著[21]。接着，中国首部人工智能、机器人学和智能控制著作分别于1987年、1988年和1990年问世[22\\~24]。1988年2月，主管国家科技工作的国务委员兼国家科委主任宋健亲笔致信蔡自兴（图2），对《人工智能及其应用》的公开出版和人工智能学科给予高度评价，指出该人工智能著作的编著和出版“使这一前沿学科的最精彩的成就迅速与中国读者见面，这对人工智能在中国的传播和发展必定会起到重大的推动作用。……现在有了这本书，千千万万的青年科学家得以一览这门学科的系统的、精选的要义，是中国科学界的一件大事。……我深信，以人工智能和模式识别为带头的这门新学科，将为人类迈进智能自动化时期做出奠基性贡献。”[25\\~27]宋健对该书的高度评价，体现出他对发展中国人工智能的关注和对作者的鼓励，对中国人工智能的发展产生了重大和深远的影响。![图片] \n在这封信中宋健还提到：“十年前，当我们和钱先生修订工程控制论时[28]，尚无系统参考书可言，只能断断续续介绍一些思路。现在钱先生看到此书，也一定会欣喜万分。”这体现了宋健的谦虚品德，也表现出钱学森当时对人工智能的热烈支持[27]。\n1987年《模式识别与人工智能》杂志创刊。\n1989年首次召开了中国人工智能联合会议（CJCAI），至2004年共召开了8次。此外，还曾经联合召开过6届中国机器人学联合会议。\n1993年起，把智能控制和智能自动化等项目列入国家科技攀登计划。\n1993年7月，宋健应邀为中国人工智能学会智能机器人分会成立题词“人智能则国智科技强则国强”，向成立大会表示祝贺[29]。本题词很好地阐明了人工智能与提高民族素质、增强科技实力和建设现代化强国的辩证关系，也是国家科技领域领导人对中国人工智能事业的有力支持以及对全国人工智能工作者的殷切期望。\n**1.4蓬勃发展**\n进入21世纪后，更多的人工智能与智能系统研究课题获得国家自然科学基金重点和重大项目、国家高技术研究发展计划（863计划）和国家重点基础研究发展计划（973计划）项目、科技部科技攻关项目、工信部重大项目等各种国家基金计划支持，并与中国国民经济和科技发展的重大需求相结合，力求为国家做出更大贡献。这方面的研究项目很多，代表性的研究有视觉与听觉的认知计算、面向Agent的智能计算机系统、中文智能搜索引擎关键技术、智能化农业专家系统、虹膜识别、语音识别、人工心理与人工情感、基于仿人机器人的人机交互与合作、工程建设中的智能辅助决策系统、未知环境中移动机器人导航与控制等。\n2006年8月，中国人工智能学会联合其他学会和有关部门，在北京举办了“庆祝人工智能学科诞生50周年”大型庆祝活动[30]。除了人工智能国际会议外，纪念活动还包括由中国人工智能学会主办的首届中国象棋计算机博弈锦标赛暨首届中国象棋人机大战。东北大学的“棋天大圣”象棋软件获得机器博弈冠军；“浪潮天梭”超级计算机以11：9的成绩战胜了中国象棋大师。这些赛事的成功举办，彰显了中国人工智能科技的长足进步，也向广大公众进行了一次深刻的人工智能基本知识普及教育。主办者认为，这次中国象棋人机大战“无论赢家是人类大师或超级计算机，都是人类智慧的胜利”[31]。![图片] \n同年，《智能系统学报》创刊（图3），这是继《人工智能学报》和《模式识别与人工智能》之后国内第3份人工智能类期刊。他们为国内人工智能学者和高校师生提供了一个学术交流平台，对中国人工智能研究与应用起到促进作用。\n2009年，中国人工智能学会牵头组织，向国家学位委员会和国家教育部提出设置“智能科学与技术”学位授权一级学科的建议。该建议指出：现在信息化向智能化迈进”的趋势已经显现；因此，今天培养的智能科学技术高级人才大军，正好赶上明天信息化向智能化大规模迈进的需要。为此，一个顺理而紧迫的建议就是：为了适应信息化向智能化迈进的大趋势，为了实现建设创新型国家的大目标，在中国学位体系中增设智能科学与技术博士和硕士学位授权一级学科。这个建议凝聚了中国广大人工智能教育工作者的心智心血和他们的远见卓识，对中国人工智能学科建设具有十分深远的意义[32]。\n**1.5国家战略**\n近两年来，中国的人工智能已发展成为国家战略。国家最高领导人习近平、李克强发表重要讲话，对发展中国人工智能和机器人学给予高屋建瓴的指示与支持。2014年6月9日，习近平总书记在中国科学院第十七次院士大会、中国工程院第十二次院士大会开幕式上发表重要讲话强调：“由于大数据、云计算、移动互联网等新一代信息技术同机器人技术相互融合步伐加快，3D打印、人工智能迅猛发展，制造机器人的软硬件技术日趋成熟，成本不断降低，性能不断提升，军用无人机、自动驾驶汽车、家政服务机器人已经成为现实，有的人工智能机器人已具有相当程度的自主思维和学习能力。……我们要审时度势、全盘考虑、抓紧谋划、扎实推进。”[33]这是党和国家最高领导人首次对人工智能和相关智能技术的高度评价，是对开展人工智能和智能机器人技术开发的庄严号召和大力推动。\n2015年十二届全国人大三次会议上，李克强总理在政府工作报告中提出：“人工智能技术将为基于互联网和移动互联网等领域的创新应用提供核心基础。未来人工智能技术将进一步推动关联技术和新兴科技、新兴产业的深度融合，推动新一轮的信息技术革命，势必将成为我国经济结构转型升级的新支点。”[34]这是对人工智能技术的重要作用给予的充分肯定，是对人工智能的有力促进。\n2015年5月，国务院发布《中国制造2025》（图4），部署全面推进实施制造强国战略。这是中国实施制造强国战略第一个十年的行动纲领。围绕实现制造强国的战略目标，《中国制造2025》明确了9项战略任务和重点[35]。![图片] \n这些战略任务，无论是提高创新能力、信息化与工业化深度融合、强化工业基础能力、加强质量品牌建设，或是推动重点领域突破发展、全面推行绿色制造、推进制造业结构调整、发展服务型制造和生产性服务业、提高制造业国际化发展水平，都离不开人工智能的参与，都与人工智能的发展密切相关。人工智能是智能制造不可或缺的核心技术。2016年4月，工业和信息化部、国家发展改革委、财政部等三部委联合印发了《机器人产业发展规划（2016—2020年）》，为“十三五”期间中国机器人产业发展描绘了清晰的蓝图。该发展规划提出的大部分任务，如智能生产、智能物流、智能工业机器人、人机协作机器人、消防救援机器人、手术机器人、智能型公共服务机器人、智能护理机器人等，都需要采用各种人工智能技术。人工智能也是智能机器人产业发展的关键核心技术[36，37]。![图片] \n2016年5月，国家发改委和科技部等4部门联合印发《“互联网+”人工智能三年行动实施方案》，明确未来3年智能产业的发展重点与具体扶持项目，进一步体现出人工智能已被提升至国家战略高度。根据方案的内容，未来3年将在3个大方面、9个小项推进智能产业发展[38]。\n国家最高领导人对人工智能的高度评价和对发展我国人工智能的指示，《中国制造2025》、《机器人产业发展规划（2016—2020年）》和《“互联网+”人工智能三年行动实施方案》的发布与施行，体现了中国已把人工智能技术提升到国家发展战略的高度，为人工智能的发展创造了前所未有的优良环境，也赋予人工智能艰巨而光荣的历史使命。\n2015年7月在北京召开了“2015中国人工智能大会”。发表了《中国人工智能白皮书》，包括“中国智能机器人白皮书”、“中国自然语言理解白皮书”、“中国模式识别白皮书”、“中国智能驾驶白皮书”和“中国机器学习白皮书”，为中国人工智能相关行业的科技发展描绘一个轮廓，给产业界指引一个发展方向[39]。\n2016年4月由中国人工智能学会发起，联合20余家国家一级学会，在北京举行“2016全球人工智能技术大会暨人工智能60周年纪念活动启动仪式”（图5）[40]。这次活动恰逢国际人工智能诞辰60周年，谷歌AlphaGo与韩国围棋九段棋手李世石上演“世纪人机大战”（图6），将人工智能的关注度推到了前所未有的高度[41]。启动仪式共同庆祝国际人工智能诞辰60周年，传承和弘扬人工智能的科学精神，开启智能化时代的新征程。\n现在，人工智能已发展成为国家发展战略，中国已有数以10万计的科技人员和大学师生从事不同层次的人工智能相关领域研究、学习、开发与应用，人工智能研究与应用已在中国空前开展，硕果累累，必将为促进其他学科的发展和中国的现代化建设做出新的重大贡献。\n**2主要成就**\n中国的人工智能研究开发、学科建设、产业应用和社会服务等方面，已经取得不俗的成就，主要可以从以下几点得到证实。![图片] \n**2.1形成人工智能学科**\n1981年9月建立了全国性的人工智能组织中国人工智能学会（CAAI），标志着中国人工智能学科的诞生[14]。1982年在长沙创办中国人工智能学会刊物《人工智能学报》，成为中国人工智能学科领域的第一份学术刊物。中国人工智能学会大会每两年举行一次，至目前已举办16届。中国人工智能学会成立后，又相继成立了中国人工智能学会智能机器人专业委员会、机器学习专业委员会、模式识别专业委员会、自然语言处理专业委员会和智能控制专业委员会、人工智能教育工作委员会等。\n此外，中国计算机学会的一些二级学会也开展人工智能相关学术活动，为中国人工智能的发展做出了应有贡献。例如，中国计算机学会成立了人工智能与模式识别专业委员会，中国自动化学会成立了模式识别与机器智能专业委员会以及智能自动化专业委员会等二级学会。有些省市也成立了地方人工智能学会。1989—2004年，由中国人工智能学会、中国计算机学会等多个学会联合举办过7届中国人工智能联合会议（CJCAI）[42]。\n与人工智能密切相关的机器学习、模式识别、智能机器人、自然语言处理、专家系统等领域的学术组织也先后成立，学术活动也十分热烈。例如，国内机器学习的重要学术活动包括每两年举行一次的中国机器学习会议和每年举行的中国机器学习及其应用研讨会。前者由中国计算机学会人工智能与模式识别专业委员会协办，目前已历经15届。后者每届会议包括特邀报告、大会交流及Top Conference Review等部分，迄今已历经13届。又如，中国人工智能学会智能机器人专业委员会自1993年成立以来，每两年举行一次全国智能机器人学术会议，已组织过11届，还与其他学会共同举办过6次中国机器人联合会议。在王湘浩倡导与组织下，全国高校人工智能研讨会研究班自1980年起每年举行一次，是国内最早的人工智能学术研讨活动。\n这些人工智能学术组织和会议开展广泛深入的国内外学术交流，对开展人工智能学术活动和组织科技交流起到积极的作用，有力推动了中国人工智能科技发展和学科建设。**2.2科学研究成绩斐然**\n国家已先后设立了各种与人工智能相关的研究课题，如国家自然科学基金重大专项、重点项目和面上项目，国家863计划项目，国家重大战略项目智能制造2025等。在这些科研基金的支持下，国内人工智能研究已取得许多突出成果。\n1）人工智能基础研究成果突出。\n除了前面提到的几何定理证明的“吴氏方法”外[43]，吴文俊还于2004 年发表了重要论文“计算机时代的脑力劳动机械化与科学技术现代化”，宣布他在几何定理证明“机械化”方面的系列成果，指出：“在几何定理机器证明取得成功之后的20多年来，笔者与许多志同道合的同志们在科技部、科学院、基金委等大力支持下，开展了一场可谓‘数学机械化’的‘运动’，在理论与应用诸多方面都已取得了若干成功。”[44]\n国内学者在人工智能的诸多领域，如问题求解、不确定推理、泛逻辑理论、拓扑学、模式识别、图像处理、机器学习、专家系统、智能计算和智能控制等领域的基础研究也多有建树，取得一批具有国际先进水平的创造性成果。例如，在模式识别方面，对文字识别、语音识别（图7）、指纹识别、人脸识别、虹膜识别和步态识别等进行深入研究，涉及生物医学、卫星遥感、机器人视觉、货物检测、目标跟踪、自主导航、保安、银行、交通、军事、电子商务和多媒体网络通信等应用领域[45,46]。又如，机器学习也是人工智能的核心研究领域之一，现在机器学习的大数据往往体现出多源异构、语义复杂、规模巨大、动态多变等特殊性质，为传统机器学习技术带来了新的挑战。为应对这一挑战，国内科技企业巨头华为、百度等与国外巨头谷歌、微软、亚马逊等展开竞争，纷纷成立以机器学习技术为核心的研究院，以充分挖掘大数据中蕴含的巨大商业与应用价值[47,48]。深度学习是机器学习领域一个新兴的子领域与研究方向，它是一种通过多层表示来对数据之间的复杂关系进行建模的算法[49]。深度学习模仿人脑结构，具有更强的建模和推理能力，能够更有效地解决多类复杂的智能问题。近年来，中国在深度学习研究方面也取得重要进展，一些研究成果接近或达到国际先进水平[50,51]。\n中国学者在自动规划领域也取得开创性成果。1985年提出与发展了基于专家系统的机器人规划机理与方法，实现了人工智能专家系统与机器人技术的结合，为基于知识的自动规划和高层控制开辟了一条新途径，对提高生产的智能化水平具有重要意义，并推动国内外机器人规划研究的发展[52\\~54]。该成果被广泛引用，并被收入清华大学吴麒等主编的全国高校规划教材《自动控制原理》[55]。1999年以来，又在机器人进化规划方面取得创新性成果[56\\~58]。\n国内在认知计算、情感计算、模式识别、神经网络、智能驾驶、水下机器人和其他智能机器人等领域也取得一批具有国际先进水平的研究成果，培养了一批优秀的学术带头人：郭爱克、任继福、李衍达、王守觉、焦李成、贺汉根、蔡鹤皋、徐玉如和黄心汉等。此外，有些人工智能基础研究获得国际奖励，如1990年张钹获得ICL欧洲人工智能奖[59]，蔡自兴指导的王勇博士获得2015 IEEE 计算智能学会优秀博士学位论文奖等[60]。\n值得一提的是美籍华裔学者王浩对人工智能的杰出贡献。1958年夏天，王浩在纽约州的IBM实验室的一台IBM704机器上用汇编语言编写了3个程序，证明了罗素和怀特海《数学原理》中的200多个定理。他关于数理逻辑的一个命题被国际上定为“ 王氏悖论”。1966年，他在哈佛大学指导的博士生Stephen Cook，因NP完全性方面的开创性研究成果而获得1982年图灵奖[61,62]。王浩还与吴文俊进行了合作研究[43]。\n2）专用人工智能开发有所突破。\n中国在专用人工智能领域取得了突破性的进展，已在自然语言处理和语音识别、图像识别、机器学习、虚拟现实、智能处理器、认知计算、智能驾驶和智能机器人等方面取得一大批具有国际先进水平的应用成果。互联网和大数据推动人工智能进入了新的发展阶段。中国的智能语音技术在移动互联网、呼叫中心、智能家居、汽车电子等领域的研究与应用逐步深入，带动智能语音产业规模持续快速增长。2013年科大讯飞以54.2%的市场份额继续处于国内领先地位。智能语音正在成为主流的交互方式之一[63]。![图片] \n近几年在多层神经网络基础上发展起来的深度学习和深度神经网络已在中国很多模式识别领域获得成功应用。其中，中国科学院自动化研究所谭铁牛团队在虹膜识别领域，坚持从虹膜图像信息获取的源头进行系统创新，全面突破虹膜识别领域的成像装置、图像处理、特征抽取、识别检索、安全防伪等一系列关键技术，建立了虹膜识别比较系统的计算理论和方法体系，还建成目前国际上最大规模的共享虹膜图像库，已大规模用于煤矿人员辨识和北京城铁监控等，并在70个国家和地区的3000多个科研团队推广使用，有力推动了虹膜识别学科发展[64]。在2010年举行的国际上难度最高、规模最大的虹膜识别专业测评竞赛中，谭铁牛团队提交的算法，从来自25个国家和地区的41支参赛团队里脱颖而出，以测试性能指标超过第2名41.3%的绝对优势蝉联虹膜识别算法赛事冠军（图8）。在2008年进行的上届国际虹膜识别算法竞赛上，谭铁牛团队战胜来自35个国家和地区的97支参赛队伍。这充分展示出中国在虹膜识别领域领先国际的整体实力[65]。\n在模式识别领域，石青云领衔的北大高科指纹技术有限公司在指纹识别领域取得领先成果，成为国家科技强警的利剑[66]。\n专家系统已在国内获得广泛应用，应用领域涉及工业、农业等行业，其经济效益相当可观[67\\~69]。例如，在冶金专家系统的开发与应用方面，已把专家系统技术用于高炉建模、', 'doi': '', 'published_date': '2025-04-25T00:00:00+00:00', 'pdf_url': '', 'url': 'https://news.qq.com/rain/a/20250425A01A5Q00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的历史、现状和未来----中国科学院', 'authors': [], 'abstract': '人工智能的历史、现状和未来----中国科学院\n[PC] /[English] /[联系我们] /[网站地图] /[邮箱] /[无障碍] /[关怀版] \n[![]![]] \n![] \n[![]] [![]] [![]] [![]] [![]] \n* [首页] \n* [组织机构] [主要职责] [院况简介] [院领导集体] [机构设置] \n* [科学研究] [科技专项] [科技奖励] [科技期刊] [科研进展] \n* [成果转化] [知识产权与科技成果转化网] [工作动态] \n* [人才教育] [中国科学院教育简介] [中国科学技术大学] [中国科学院大学] [上海科技大学] [工作动态] \n* [学部与院士] \n* [科学普及] [科学与中国] [中国科普博览] [科普场馆] [工作动态] \n* [党建与科学文化] [工作动态] [反腐倡廉] [文明天地] \n* [信息公开] [信息公开规定] [信息公开指南] [信息公开目录] [信息公开申请] [信息公开联系方式] \n* [首页] \n* [组织机构] \n* [科学研究] \n* [成果转化] \n* [人才教育] \n* [学部与院士] \n* [科学普及] \n* [党建与科学文化] \n* [信息公开] \n主要职责中国科学院贯彻落实党中央关于科技创新的方针政策和决策部署，在履行职责过程中坚持党中央对科技工作的集中统一领导。主要职责是：一、开展使命导向的自然科学领域基础研究，承担国家重大基础研究、应用基础研究、前沿交叉共性技术研究和引领性颠覆性技术研究任务，打造原始创新策源地。[更多+] \n院况简介中国科学院是国家科学技术界最高学术机构、国家科学技术思想库，自然科学基础研究与高技术综合研究的国家战略科技力量。1949年，伴随着新中国的诞生，中国科学院成立。建院70余年来，中国科学院时刻牢记使命，与科学共进，与祖国同行，以国家富强、人民幸福为己任，人才辈出，硕果累累，为我国科技进步、经济社会发展和国家安全作出了不可替代的重要贡献。[更多+] \n院领导集体* [![] \n侯建国] \n* [![] \n吴朝晖] \n* [![] \n孙也刚] \n* [![] \n周\u3000琪] \n* [![] \n汪克强] \n* [![] \n丁赤飚] \n* [![] \n何宏平] \n* [![] \n孙晓明] \n* [![] \n王\u3000华] \n* [![] \n文\u3000亚] \n* [![] \n王大同] \n机构设置* ##### 院机关[办公厅] \n[科技创新发展局] \n[基础科学研究局] \n[战略高技术研究局] \n[重大专项研究局] \n[可持续发展科技研究局] \n[科技基础能力局] \n[学部工作局] \n[人才与人事局] \n[国际合作局] \n[财务与资产管理局] \n[审计与监督局（党组巡视工作领导小组办公室）] \n[机关党委] \n[老专家老干部服务局] \n* ##### 派驻机构[中央纪委国家监委驻中国科学院纪检监察组] \n* ##### 分院[沈阳分院] \n[上海分院] \n[武汉分院] \n[广州分院] \n[成都分院] \n[昆明分院] \n[西安分院] \n[兰州分院] \n[新疆分院] \n* ##### 院属机构[研究单位] \n[学校] \n[管理与公共支撑单位] \n[新闻出版单位] \n[其他单位] \n[共建单位] \n[院级非法人单元] \n[所级分支机构] \n[境外机构] \n[群团和其他组织] \n* [![]] \n* [![]] \n科技奖励![] \n[科技奖励] \n* [国家最高科学技术奖] \n* [国家自然科学奖] \n* [国家技术发明奖] \n* [国家科学技术进步奖\n] \n* [国家科学技术合作奖] \n* [中国科学院杰出科技成就奖] \n* [中国科学院国际科技合作奖] \n* [陈嘉庚科学奖] \n科技期刊![] \n[科技期刊] \n* [期刊导航] \n* [数字平台] \n* [期刊集群] \n* [期刊动态] \n科技专项为方便科研人员全面快捷了解院级科技专项信息并进行项目申报等相关操作，特搭建中国科学院院级科技专项信息管理服务平台。了解科技专项更多内容，请点击进入→[![]] \n科研进展[/更多] \n* [我国成功实现太空金属3D打印] \n* [研究人员在铁电材料中发现一维带电畴壁] \n* [科学家打造“AI科学家团队” 加速新材料创制] \n* [研究揭示高纬度和高海拔多年冻土区土壤碳分解温度敏感性的分异特征] \n* [兰属植物*ndh*基因普遍退化及其演化响应研究取得进展] \n* [研究揭示杜鹃花属物种形成过程中基因流异质性与基因组结构关系] \n[![]] \n工作动态[/更多] \n* [青海盐湖所在碱性溶液萃取提锂关键技术上取得突破] \n* [上海硅酸盐所3D打印硅基生物陶瓷口腔修复产品开发取得新进展] \n* [“制氢+硫磺”，新技术助力工业绿色低碳发展] \n* [亿方级甲烷-二氧化碳干重整示范装置通过72小时标定考核] \n* [国内首台套钢铁行业高炉煤气变压吸附碳捕集示范装置正式投运] \n* [工程热物理所自主研发的循环流化床生物质气化制绿色液体燃料原料气技术示范工程投产] \n* [大连化物所开发出100kWh级磷酸盐基钠离子电池储能系统并实现并网运行] \n* [昆明分院等举办2025腾冲科学家论坛·科技创新成果展示与转化应用对接活动] \n* [山西煤化所等共同建设的千吨级高性能碳纤维项目竣工投产] \n* [大连化物所“苯酚双氧水羟基化制苯二酚固定床新工艺”通过科技成果评价] \n* [低空智能交通技术及载运装备领域科技成果对接系列活动在穗举办] \n* [金属所举办“云南行”科技成果对接活动] \n* [![]] \n[中国科学技术大学（简称“中国科大”）于1958年由中国科学院创建于北京，1970年学校迁至安徽省合肥市。中国科大坚持“全院办校、所系结合”的办学方针，是一所以前沿科学和高新技术为主、兼有特色管理与人文学科的研究型大学。] \n* [![]] \n[中国科学院大学（简称“国科大”）始建于1978年，其前身为中国科学院研究生院，2012年经教育部批准更名为中国科学院大学。国科大实行“科教融合”的办学方针，与中国科学院直属研究机构（包括所、院、台、中心等），在管理体制、师资队伍、培养体系、科研工作等方面高度融合，是一所以研究生教育为主的独具特色的高等学校。] \n* [![]] \n[上海科技大学（简称“上科大”），由上海市人民政府与中国科学院共同举办、共同建设，由上海市人民政府主管，2013年经教育部正式批准。上科大致力于服务国家经济社会发展战略，培养科技创新创业人才，努力建设一所小规模、高水平、国际化的研究型、创新型大学。] \n工作动态[/更多] \n* [国科大举办2025拾光奉献纪念典礼] \n* [上海分院与上海交通大学签约开展战略合作] \n* [2025年中国科大科教融合单位研究生教育工作总结交流会举办] \n* [沈阳分院与大连理工大学举行工作交流] \n* [云南省热带亚洲榕-蜂群落构建与利用国际联合实验室培训班举办] \n* [成都山地所与西南交通大学签署战略合作协议] \n[![]] [![]] [![]] \n科普场馆[/更多] \n* [中国科学院国家授时中心时间科学馆] \n* [中国科学院昆明动物研究所昆明动物博物馆] \n* [中国科学院合肥物质科学研究院合肥现代科技馆] \n* [中国科学院动物研究所国家动物博物馆] \n* [中国科学院新疆生态与地理研究所生物标本馆] \n* [中国科学院新疆生态与地理研究所新疆自然博物馆] \n* [中国科学院南海海洋研究所南海海洋生物标本馆] [![]] \n工作动态[/更多] \n* [“科学与中国”西部行——“千名院士·千场科普”行动在云南举办] \n* [2025“科学与中国”院士专家巡讲团走进香港50所中小学校] \n* [2025年中国科学院科普讲解大赛举办] \n* [中国科学院举办2025年度科普工作骨干培训班] \n* [2025年中国科学院科普讲解大赛即将启幕] \n* [版纳植物园举办第十三届观鸟节] \n* [福建物构所举办科学节活动] [![]] \n工作动态[/更多] \n* [数学院田野院士成为《榜样10》党员先进典型] \n* [天津工生所召开党委理论学习中心组学习会] \n* [理化所召开党委理论学习中心组集体学习会] \n* [昆明分院分党组理论学习中心组召开学习扩大会] \n* [武汉岩土所召开2025年度党（总）支部书记述职考评会] \n* [宁波材料所召开党委理论学习中心组学习会] \n* [授时中心传达学习中国科学院党组冬季扩大会议精神] \n* [版纳植物园召开党委会] \n* [心理所召开2025年度全面从严治党暨党风廉政建设会议] \n[![]] [![]] \n反腐倡廉[/更多] \n* [沈阳分院召开2025年度第四次纪检组扩大会议] \n* [新疆分院纪检组召开2025年第四次纪监审工作会议] \n* [国科控股举办2025年纪检干部培训班] \n* [西安分院召开第四季度纪监审工作交流会] \n[违纪违法举报] \n文明天地[/更多] \n* [中国科学院合唱团举办“2026新年音乐会”] \n* [中国科学院合唱团参加“首都留学人员2026新年音乐会”] \n* [光电所举办“五十五载辉煌路·追光逐电启新程”职工运动会] \n* [计算机网络信息中心举办“榜样之声·初心映耀”身边榜样故事分享会] \n主动公开工作信息相关规定* [信息公开指南] \n* [主动公开事项目录] \n* [其他规定] \n组织机构* [工作机构] \n* [监督机构] \n中国科学院学部基本信息* [学部概况] \n* [院士大会] \n* [院士信息] \n规章制度* [院士章程] \n* [增选工作有关规定] \n* [其他工作规则与管理办法] \n工作进展* [院士增选] \n* [决策咨询] \n* [学术引领] \n* [科学普及] \n* [工作动态] \n学部出版物* [决策咨询系列] \n* [学术引领系列] \n* [科学文化系列] \n* [其他出版物] \n陈嘉庚科学奖* [机构概况] \n* [规章制度] \n* [通知公告] \n中国科学院院部机构设置* [基本情况] \n* [院领导集体] \n* [组织机构] \n规章制度* [综合性制度文件] \n* [政策解读] \n财务资产* [预算决算] \n* [公示公告] \n新闻动态* [重要新闻] \n* [工作动态] \n* [媒体报道] \n* [网站专题] \n* [通知公告] \n科学研究* [科研装备] \n* [科研进展] \n* [成果转化] \n* [科技奖励] \n* [科技期刊] \n人事人才* [人事任免] \n* [人才招聘] \n* [招生与培养] \n国际合作* [国际组织] \n* [政策法规] \n[首页] \\>[访谈·视点] \n## ## 谭铁牛：人工智能的历史、现状和未来## 2019-02-18求是\n【字体：大中小】![] \n语音播报![] \n如同蒸汽时代的蒸汽机、电气时代的发电机、信息时代的计算机和互联网，人工智能正成为推动人类进入智能时代的决定性力量。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷转型发展，抢滩布局人工智能创新生态。世界主要发达国家均把发展人工智能作为提升国家竞争力、维护国家安全的重大战略，力图在国际科技竞争中掌握主导权。习近平总书记在十九届中央政治局第九次集体学习时深刻指出，加快发展新一代人工智能是事关我国能否抓住新一轮科技革命和产业变革机遇的战略问题。错失一个机遇，就有可能错过整整一个时代。新一轮科技革命与产业变革已曙光可见，在这场关乎前途命运的大赛场上，我们必须抢抓机遇、奋起直追、力争超越。**概念与历程**\n了解人工智能向何处去，首先要知道人工智能从何处来。1956年夏，麦卡锡、明斯基等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能（Artificial Intelligence，简称AI）”这一概念，标志着人工智能学科的诞生。\n人工智能是研究开发能够模拟、延伸和扩展人类智能的理论、方法、技术及应用系统的一门新的技术科学，研究目的是促使智能机器会听（语音识别、机器翻译等）、会看（图像识别、文字识别等）、会说（语音合成、人机对话等）、会思考（人机对弈、定理证明等）、会学习（机器学习、知识表示等）、会行动（机器人、自动驾驶汽车等）。人工智能充满未知的探索道路曲折起伏。如何描述人工智能自1956年以来60余年的发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能的发展历程划分为以下6个阶段：\n一是起步发展期：1956年—20世纪60年代初。人工智能概念提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序等，掀起人工智能发展的第一个高潮。\n二是反思发展期：20世纪60年代—70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如，无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入低谷。\n三是应用发展期：20世纪70年代初—80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入应用发展的新高潮。\n四是低迷发展期：20世纪80年代中—90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n五是稳步发展期：20世纪90年代中—2010年。由于网络技术特别是互联网技术的发展，加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年国际商业机器公司（简称IBM）深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念。以上都是这一时期的标志性事件。\n六是蓬勃发展期：2011年至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越了科学与应用之间的“技术鸿沟”，诸如图像分类、语音识别、知识问答、人机对弈、无人驾驶等人工智能技术实现了从“不能用、不好用”到“可以用”的技术突破，迎来爆发式增长的新高潮。\n**现状与影响**\n对于人工智能的发展现状，社会上存在一些“炒作”。比如说，认为人工智能系统的智能水平即将全面超越人类水平、30年内机器人将统治世界、人类将成为人工智能的奴隶，等等。这些有意无意的“炒作”和错误认识会给人工智能的发展带来不利影响。因此，制定人工智能发展的战略、方针和政策，首先要准确把握人工智能技术和产业发展的现状。\n专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定任务（比如下围棋）的专用人工智能系统由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域。例如，阿尔法狗（AlphaGo）在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，人工智能系统诊断皮肤癌达到专业医生水平。\n通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。目前，虽然专用人工智能领域已取得突破性进展，但是通用人工智能领域的研究与应用仍然任重而道远，人工智能总体发展水平仍处于起步阶段。当前的人工智能系统在信息感知、机器学习等“浅层智能”方面进步显著，但是在概念抽象和推理决策等“深层智能”方面的能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才而无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，谷歌在其2017年年度开发者大会上明确提出发展战略从“移动优先”转向“人工智能优先”，微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿。麦肯锡公司报告指出，2016年全球人工智能研发投入超300亿美元并处于高速增长阶段；全球知名风投调研机构CB Insights报告显示，2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n创新生态布局成为人工智能产业发展的战略高地。信息技术和产业的发展史，就是新老信息产业巨头抢滩布局信息产业创新生态的更替史。例如，传统信息产业代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网时代信息产业代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。目前智能科技时代的信息产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动人工智能技术生态的研发布局，全力抢占人工智能相关产业的制高点。\n人工智能的社会影响日益凸显。一方面，人工智能作为新一轮科技革命和产业变革的核心力量，正在推动传统产业升级换代，驱动“无人经济”快速发展，', 'doi': '', 'published_date': '2019-02-18T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cas.cn/zjs/201902/t20190218_4679625.shtml', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '中国人工智能学会', 'authors': [], 'abstract': '中国人工智能学会\n[![办公系统] 办公系统] \n[会员登录] |[会员注册] |[联系我们] |[English] \n[![中国人工智能学会]] \n* [首页] \n* [关于CAAI] \n* [CAAI简介] \n* [学会章程] \n* [条例与法规] \n* [主要领导] \n* [组织机构] \n* [分支机构] \n* [地方学会] \n* [服务矩阵] \n* [新闻动态] \n* [时政要闻] \n* [科协头条] \n* [学会新闻] \n* [通知公告] \n* [活动预告] \n* [学术资源] \n* [学会通讯] \n* [智能系统学报] \n* [CAAI TRIT] \n* [CAAI AIR] \n* [学科皮书系列] \n* [年鉴及发展报告] \n* [数字图书馆] \n* [会议系统] \n* [会员专区] \n* [学会会士] \n* [杰出会员] \n* [高级会员] \n* [会员荣誉] \n* [单位会员] \n* [党建强会] \n* [学会党建小组] \n* [重要讲话] \n* [党建强会] \n* [主题教育] \n* [二十大精神] \n* [思想体系] \n* [伟大精神] \n* [党史百科] \n* [学习书库] \n[![]] \n* [首页] \n* [关于CAAI] \n* [CAAI简介] \n* [学会章程] \n* [条例与法规] \n* [主要领导] \n* [组织机构] \n* [分支机构] \n* [地方学会] \n* [服务矩阵] \n* [新闻动态] \n* [时政要闻] \n* [科协头条] \n* [学会新闻] \n* [通知公告] \n* [活动预告] \n* [学术资源] \n* [学会通讯] \n* [智能系统学报] \n* [CAAI TRIT] \n* [CAAI AIR] \n* [学科皮书系列] \n* [年鉴及发展报告] \n* [数字图书馆] \n* [会议系统] \n* [会员专区] \n* [学会会士] \n* [杰出会员] \n* [高级会员] \n* [会员荣誉] \n* [单位会员] \n* [党建强会] \n* [学会党建小组] \n* [重要讲话] \n* [党建强会] \n* [主题教育] \n* [二十大精神] \n* [思想体系] \n* [伟大精神] \n* [党史百科] \n* [学习书库] \n[![中央八项精神]] \n[![2025年，“十四五”规划收官之年]] \n展开### [新闻公告] \n### 学会新闻[更多![]] \n[\n![] \n##### CAAI自主无人系统专委会换届工作会议顺利召开\n2026年1月16日，中国人工智能学会（CAAI）自主无人系统专委会（以下简称专委会）第六届委员换届会议在北京顺利召开。CAAI组织工委会委员、浙江大学刘哲教授代表学会主持和督导换届会议。第五届专委会主任孙长银教授，副主任贺威教授、王雅琳教授、宋士吉教授、刘允刚教授、葛泉波教授，秘书长余瑶副教授等120余人参加了本次换届会议。会议现场第五届专委会秘书长余瑶副教授作工作汇报，报告从组织学术活动、开展\n] \n* [\n•智能传媒技术发展大会在京举办2026-01-16] \n* [\n•第十届全国智能交互论坛在北京举行2026-01-13] \n* [\n•中国人工智能学会推荐的9场学术会议入选中国科协《重要学术会议指南（2025）》\n2026-01-07] \n* [\n•智汇常州，能动未来2026全国智能体开发者大会在常州召开\n2026-01-05] \n* [\n•CAAI自主无人系统专委会学术年会在杭州举办\n2026-01-04] \n### 通知公告[更多![]] \n* [\n01-222026\n##### 2026 CAAI-腾讯犀牛鸟研究计划AI Lab专项征集正式启动\n] \n* [\n01-142026\n##### 2025年度吴文俊人工智能科学技术奖初评通过项目公示（公示已结束）\n] \n* [\n01-062026\n##### 2025年CAAI-联想蓝天科研基金入选名单公示\n] \n* [\n12-092025\n##### 2025年度吴文俊人工智能科学技术奖形式审查结果公示\n] \n* [\n11-262025\n##### 中国人工智能学会教育工作委员会征集委员通知] \n* [\n•2026 CAAI-腾讯犀牛鸟研究计划AI Lab专项征集正式启动\n2026-01-22] \n* [\n•2025年度吴文俊人工智能科学技术奖初评通过项目公示（公示已结束）\n2026-01-14] \n* [\n•2025年CAAI-联想蓝天科研基金入选名单公示\n2026-01-06] \n* [\n•2025年度吴文俊人工智能科学技术奖形式审查结果公示\n2025-12-09] \n* [\n•中国人工智能学会教育工作委员会征集委员通知2025-11-26] \n### [服务矩阵] \n#### 会员服务咨询电话：010-62283918\n[个人会员注册] [单位会员注册] [个人会籍查询] [单位会员名录] [个人会员缴费通知] [单位会员缴费通知] \n#### 成果奖励咨询电话：010-82158857，010-82158859\n[成果鉴定服务] [吴文俊奖提名] [激励计划提名] \n#### 学术基金咨询电话：010-82158821\n[CAAI-昇思学术基金] [CAAI-昇腾学术基金] [CAAI-蚂蚁科研基金] [CAAI-联想蓝天科研基金] [CAAI-波色量子创新基金] \n#### 学会出版物咨询电话：010-62283919\n[中国人工智能学会通讯] [CAAI Trans.on IT] [智能系统学报] [CAAl AI Research] [CAAI系列白皮书] \n#### 算力平台咨询电话：010-82158821\n[CAAI-华为算力平台] [CAAI-英博数科算力平台] \n### [学会活动] \n#### 重要活动[进入会议系统查看更多![]] \n* {{ formatDate(item.start\\_time) }}{{ formatYear(item.start\\_time) }}\n##### {{ item.fair\\_name }}\n地址：{{ item.city }}|时间：{{ formatDateRange(item.start\\_time, item.end\\_time) }}\n[![]] \n### [新闻动态] \n### 时政要闻[更多![]] \n[\n![习近平在省部级主要领导干部学习贯彻党的二十届四中全会精神专题研讨班开班式上发表重要讲话] \n##### 习近平在省部级主要领导干部学习贯彻党的二十届四中全会精神专题研讨班开班式上发表重要讲话省部级主要领导干部学习贯彻党的二十届四中全会精神专题研讨班20日上午在中央党校（国家行政学院）开班。中共中央总书记、国家主席、中央军委主席习近平在开班式上发表重要讲话强调，要把学习贯彻党的二十届四中全会精神不断引向深入，更好统一思想、凝心聚力，在党中央坚强领导下扎实做好各项工作，努力实现“十五五”良好开局。\n] \n* [\n•习近平会见加拿大总理卡尼2026-01-16] \n* [\n•《求是》杂志发表习近平总书记重要文章《在中央城市工作会议上的讲话》2026-01-15] \n* [\n•中国共产党第二十届中央纪律检查委员会第五次全体会议公报2026-01-14] \n* [\n•习近平在二十届中央纪委五次全会上发表重要讲话2026-01-13] \n### 科协头条[更多![]] \n[\n![拥抱大有作为的黄金时代——中国科学技术协会二〇二六年新年贺词] \n##### 拥抱大有作为的黄金时代——中国科学技术协会二〇二六年新年贺词拥抱大有作为的黄金时代——中国科学技术协会二〇二六年新年贺词] \n* [\n•贺军科在吉林调研科协工作2025-12-25] \n* [\n•中国科协党组理论学习中心组专题学习习近平外交思想2025-12-22] \n* [\n•中国科协党组传达学习中央经济工作会议精神2025-12-12] \n* [\n•中国科协党组理论中心组专题学习研讨党的二十届四中全会精神2025-11-29] \n### [党建强会] \n \n### 重要讲话[更多![]] \n[\n![习近平：推进党的自我革命要做到“五个进一步到位”] \n##### 习近平：推进党的自我革命要做到“五个进一步到位”推进党的自我革命要做到“五个进一步到位”习近平\u3000\u3000在“七一”即将到来之际，中央政治局以健全落实中央八项规定精神、纠治“四风”长效机制为主题进行集体学习，既是推进全党深入贯彻中央八项规定精神学习教育的一项工作安排，也是庆祝党的生日的一次重要活动。我代表党中央，向全国广大共产党员致以节日的问候！\u3000\u3000中央八项规定是党中央徙木立信之举，是新时代管党治党的标志性措施。党的十八大以来，党中央以八项规定开局破题] \n* [\n•习近平：健全网络生态治理长效机制持续营造风清气正的网络空间2025-11-29] \n* [\n•习近平：大力弘扬志愿精神传递真善美传播正能量为强国建设民族复兴伟业贡献志愿服务力量2025-11-28] \n* [\n•习近平：在纪念胡耀邦同志诞辰110周年座谈会上的讲话\n2025-11-20] \n* [\n•习近平：坚持党的领导人民当家作主依法治国有机统一合力开创法治中国建设新局面2025-11-18] \n### 党建强会[更多![]] \n[\n![习近平在中共中央政治局第二十三次集体学习时强调 健全网络生态治理长效机制持续营造风清气正的网络空间] \n##### 习近平在中共中央政治局第二十三次集体学习时强调健全网络生态治理长效机制持续营造风清气正的网络空间中共中央政治局11月28日下午就加强网络生态治理进行第二十三次集体学习。中共中央总书记习近平在主持学习时强调，网络生态治理是网络强国建设的重要任务，事关国家发展和安全，事关人民群众切身利益。要健全网络生态治理长效机制，着力提升治理的前瞻性、精准性、系统性、协同性，持续营造风清气正的网络空间。中国政法大学教授时建中同志就这个问题进行讲解，提出工作建议。中央政治局的同志认真听取讲解，并进行\n] \n* [\n•实现高水平科技自立自强是中国式现代化建设的关键2025-12-01] \n* [\n•因地制宜发展新质生产力，需把握这些基本要求2025-11-25] \n* [\n•以韧劲钻劲恒劲擦亮作风建设“金色名片”2025-11-24] \n* [\n•新质生产力“新”在何处？2025-11-20] \n### [学会出版物] \n[\n![学会通讯] \n学会通讯] \n[\n![智能系统学报] \n智能系统学报] \n[\n![CAAI TRIT] \nCAAI TRIT\n] \n[\n![CAAI AIR] \nCAAI AIR\n] \n[\n![学科皮书系列] \n学科皮书系列] \n[\n![年鉴及发展报告] \n年鉴及发展报告] \n[\n![数字图书馆] \n数字图书馆] \n党政机关科协* [中国政府网] \n* [民政部] \n* [工业和信息化部] \n* [科技部] \n* [国家发改委] \n* [农业农村部] \n* [人力资源部] \n* [中国科学院] \n* [中国科学技术协会] \n* [中国工程院] \n* [共产党员网] \n* [党史学习教育官网] \n地方学会* [安徽省人工智能学会] \n* [海南省人工智能学会] \n* [吉林省人工智能学会] \n* [广西人工智能学会] \n* [黑龙江省人工智能学会] \n* [江苏省人工智能学会] \n* [重庆市人工智能学会] \n* [福建省人工智能学会] \n* [河南省人工智能学会] \n* [湖北省人工智能学会] \n* [湖南省人工智能学会] \n* [山东省人工智能学会] \n* [天津市人工智能学会] \n* [浙江省人工智能学会] \n* [深圳市人工智能学会] \n* [日照市人工智能学会] \n* [香港人工智能与机器人学会] \n* [内蒙古自治区人工智能学会] \n兄弟学会* [中国机械工程学会] \n* [中国仪器仪表学会] \n* [中国汽车工程学会] \n* [中国电工技术学会] \n* [中国电子学会] \n* [中国自动化学会] \n* [中国农业机械学会] \n* [中国微米纳米技术学会] \n* [中国光学工程学会] \n* [中国纺织工程学会] \n* [中国宇航学会] \n* [中国造船工程学会] \n* [中国计量测试学会] \n国际组织* [ACM] \n* [IEEE] \n* [AAAI] \n* [IJCAI] \n常务理事单位* [安谋科技（中国）有限公司] \n* [百度公司] \n* [北京三快在线科技有限公司] \n* [河海大学] \n* [华为技术有限公司] \n* [科大讯飞股份有限公司] \n* [高新兴科技集团股份有限公司] \n* [南京金盾公共安全技术研究院有限公司] \n* [360政企安全集团] \n* [武汉华工智云科技有限公司] \n* [新浪网技术（中国）有限公司] \n* [中国第一汽车股份有限公司] \n* [中兴通讯股份有限公司] \n* [蚂蚁科技集团股份有限公司] \n* [武汉数字化设计与制造创新中心有限公司] \n理事单位* [海信集团有限公司] \n* [平安科技（深圳）有限公司] \n* [东声（苏州）智能科技有限公司] \n* [北京富通东方科技有限公司] \n* [联想（北京）有限公司] \n* [四川长虹电器股份有限公司] \n* [医渡云（北京）技术有限公司] \n* [北方华创科技集团股份有限公司] \n* [北京飞象星球科技有限公司] \n* [易显智能科技有限责任公司] \n* [联通（广东）产业互联网有限公司] \n会员服务* [学会智库] \n* [数字图书馆] \n* [会员注册] \n* [个人会员会费说明] \n* [单位会员会费说明] \n* [分支活动申请表] \n高校机构* [清华大学] \n* [北京大学] \n* [浙江大学] \n* [复旦大学] \n* [北京邮电大学] \n[联系我们] |[网站地图] |[站长统计] \n地址：北京市海淀区西土城路10号 邮编：100876\n[] \nCopyright ©2026 中国人工智能学会互联网ICP备案：[京ICP备06029423号-1]![] [京公网安备11010802045678号] \n技术支持：[中科服] 15701507260\n[![] 媒体平台\n![媒体平台-官微号]![媒体平台-抖音号]![媒体平台-头条号] \n] [![常见问题] 常见问题] [![] 返回顶部] \n### 你知道你的Internet Explorer是过时了吗?\n为了得到我们网站最好的体验效果,我们建议您升级到最新版本的Internet Explorer或选择另一个web浏览器.一个列表最流行的web浏览器在下面可以找到.\n[] [] [] [] []', 'doi': '', 'published_date': '2025-06-05T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.caai.cn/index.php?s=%2Fhome%2Farticle%2Fdetail%2Fid%2F1278.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 16:14:38,109 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 16:14:38,110 - __main__ - INFO - handle_download: downloaded=1
2026-02-03 16:14:38,110 - __main__ - INFO - call_tool payload: source_tool=exa_context_download, result_type=papers, count=1
2026-02-03 16:14:38,111 - __main__ - INFO - call_tool: name=exa_context_download, result_type=papers, count=1
2026-02-03 16:14:38,111 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能的发展时间轴：从过去到未来-百度开发者中心', 'authors': [], 'abstract': '人工智能的发展时间轴：从过去到未来-百度开发者中心\n[![logo]] \n* [登录] \n* |\n* [注册] \n### 开发者热搜* [人工智能] \n* [云原生] \n* [AI应用] \n[推荐] \n[云原生] \n[文心快码 Baidu Comate] \n[飞桨PaddlePaddle] \n[人工智能] \n[超级链] \n[数据库] \n[百度安全] \n[物联网] \n[开源技术] \n[云计算] \n[大数据] \n[开发者] \n[企业服务] \n[更多内容] \n[千帆大模型平台] \n[客悦智能客服] \n# 人工智能的发展时间轴：从过去到未来作者：[谁偷走了我的奶酪] 2024.01.08 08:38浏览量：33\n*简介：*本文将带你了解人工智能的发展历程，从早期的思想萌芽到现代的应用普及，我们将通过时间轴的方式揭示人工智能的冷知识和发展趋势。\n人工智能（AI）的发展历程可以追溯到上个世纪。在这个漫长的时间里，AI经历了多次高潮和低谷，不断推动着科技的进步。下面让我们一起沿着时间轴，了解AI的成长历程和未来展望。\n1943年，美国神经科学家Warren McCulloch和数学家Walter Pitts提出了[神经网络] 的初步概念，他们认为神经元的工作原理与逻辑门相似。这一思想成为人工智能发展的重要起点。\n1956年，美国达特茅斯学院的一次研讨会上，正式提出了“人工智能”这一概念。这次会议标志着AI作为一个独立的学术领域正式诞生。\n1957年，加拿大心理学家Frank Rosenblatt开发了感知机模型，这是一种基于神经网络的[机器学习] 模型。然而，由于当时计算机性能的限制，这一模型并未得到广泛应用。\n1966年，美国科学家Joseph Weizenbaum开发了名为Eliza的自然语言对话程序，这是最早的聊天机器人之一。Eliza能够通过简单的文本对话模拟人类对话，引起了人们对AI的关注。\n1970年，日本ATR实验室开发了名为Shakey的机器人，它是世界上最早的移动机器人之一。Shakey能够自主导航、识别物体并执行任务。\n1981年，日本科学家Satoshi Sekiguchi提出了基于规则的专家系统，这是一种基于知识的计算机系统，用于提供专业领域的建议和决策。\n1988年，美国斯坦福大学教授Fei-Fei Li和她的团队开发了用于[图像识别] 的卷积神经网络LeNet-5。虽然当时的技术有限，但这一研究为现代计算机视觉领域奠定了基础。\n1997年，IBM的超级计算机“深蓝”战胜了国际象棋世界冠军Garry Kasparov，这是计算机首次在传统智力[游戏] 中击败人类。\n2006年，加拿大多伦多大学教授Geoffrey Hinton提出了[深度学习] 的概念，这是一种模拟人脑神经网络的机器学习方法。深度学习在[语音识别] 、图像识别等领域取得了巨大成功。\n2011年，苹果公司发布Siri语音助手，成为首个在消费市场上广泛应用的智能助手。Siri能够理解语音指令并回答问题，为用户提供便利的信息和服务。\n2016年，谷歌DeepMind开发的AlphaGo战胜了围棋世界冠军李世石，这是计算机在围棋领域首次击败人类。AlphaGo使用深度学习和蒙特卡洛树搜索算法，展现了AI在复杂决策问题上的强大能力。\n2020年，Open[AI开发] 的GPT-3语言模型引发了AI文本生成的热潮。GPT-3能够生成连贯、有逻辑的文本内容，被广泛应用于[自然语言处理] 和对话系统等领域。\n未来展望：随着技术的不断进步，AI将在更多领域发挥重要作用。例如，自动驾驶、医疗诊断、金融投资等领域都将受益于AI的发展。同时，我们也需要关注AI带来的伦理和隐私问题，确保技术的可持续发展。\n### 相关文章推荐* [### 文心一言接入指南：通过百度智能云千帆大模型平台API调用\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。\n] \n[十万个为什么] 2023.10.20 16:562564931910\n* [### 从MLOps 到LMOps 的关键技术嬗变本文整理自QCon 全球软件开发大会-从 MLOps 到LMOps 分论坛的同名主题演讲] \n[百度智能云开发者中心] 2023.11.15 18:033441095\n* [### Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n[百度智能云开发者中心] 2023.03.21 10:563032831\n* [### 更轻量的百度百舸，CCE Stack 智算版发布百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的AI 工程能力面向市场推出的解决方案。] \n[百度智能云开发者中心] 2023.03.02 12:172626811\n* [### 打造合规数据闭环，加速自动驾驶技术研发今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n[百度智能云开发者中心] 2023.03.02 15:002767501\n* [### LMOps 工具链与千帆大模型平台LMOps 相关的概念以及关键技术] \n[百度智能云开发者中心] 2023.11.17 15:492395533\n### 发表评论登录后可评论，请前往[登录] 或[注册] \n评论### 开发者关注产品榜* [\n*1*\n### 百度千帆·大模型服务及Agent开发平台\n企业级一站式大模型开发及服务平台模型训练限时免费] \n* [\n*2*\n### 百度千帆·数据智能平台一站式多模态数据管理、加工和分析应用平台平台体验全免费] \n* [\n*3*\n### 秒哒-生成式应用开发平台\n不用写代码，就能实现任意想法全功能免费体验] \n* [\n*4*\n### 百度智能云客悦智能客服平台大模型重塑营销与客服体验0元试用一个月\n] \n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践] \n### 关于作者[![] ### ] \n* 被阅读数* 被赞数* 被收藏数关注活动[\n咨询]', 'doi': '', 'published_date': '2024-01-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2733815', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'save_path': '/home/qinshan/widthresearch/data/downloads/exa_人工智能的发展时间轴.md'}}
2026-02-03 16:14:38,140 - __main__ - INFO - call_tool: name=wikipedia_download, args={'papers': [{'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T16:14:13.072842', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 16:14:13', 'language': 'zh'}}, {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-03T16:14:13.072861', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-03 16:14:13', 'language': 'zh'}}, {'paper_id': '1468546', 'title': '通用人工智慧', 'authors': ['Wikipedia'], 'abstract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'doi': '', 'published_date': '2026-02-03T16:14:13.072869', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'pageid': 1468546, 'fetch_time': '2026-02-03 16:14:13', 'language': 'zh'}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-03 16:14:38,142 - __main__ - INFO - handle_download: searcher=WikipediaSearcher, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-03 16:14:38,143 - __main__ - INFO - handle_download: downloaded=3
2026-02-03 16:14:38,143 - __main__ - INFO - call_tool payload: source_tool=wikipedia_download, result_type=papers, count=3
2026-02-03 16:14:38,143 - __main__ - INFO - call_tool: name=wikipedia_download, result_type=papers, count=3
2026-02-03 16:14:38,144 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-03T16:14:13.072842', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-03 16:14:13', 'language': 'zh', 'saved_path': '/home/qinshan/widthresearch/data/downloads/wiki_317.md'}}
2026-02-03 17:48:51,104 - __main__ - INFO - call_tool: name=exa_summary_search, args={'query': '人工智能在日常生活中的应用与影响 2024', 'type': 'deep'}
2026-02-03 17:48:51,106 - __main__ - INFO - handle_search: searcher=ExaSearcherSummary, query=人工智能在日常生活中的应用与影响 2024, search_type=deep
2026-02-03 17:49:00,761 - __main__ - INFO - handle_search: returned=10
2026-02-03 17:49:00,761 - __main__ - INFO - call_tool payload: source_tool=exa_summary_search, result_type=papers, count=10
2026-02-03 17:49:00,761 - __main__ - INFO - call_tool: name=exa_summary_search, result_type=papers, count=10
2026-02-03 17:49:00,762 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '深度报道丨应用大爆发  AI助手正重塑现代生活与产业格局', 'authors': [], 'abstract': '根据您提供的网页内容，以下是关于“人工智能在日常生活中的应用与影响 2024”的总结：\n\n**人工智能（AI）助手在2024年正经历应用大爆发，以前所未有的深度和广度融入现代生活与产业格局，标志着社会正加速迈入AI助手时代，人机协同成为新趋势。**\n\n### 日常生活与产业应用：\n\n*   **学术研究：** 中国知网（CNKI）推出了AI学术研究助手4.0版本，提升文献检索、研读和学术创作效率。\n*   **国民级产品集成：** 360宣布推出新一代AI助手，并与15家大模型合作，内置于其国民级入口产品中，用户可自选使用多家模型。\n*   **商业与中小企业：** 阿里国际站的AI生意助手升级，商品发布时间从60分钟缩短至最快60秒，AI自动接待功能实现24/7回复，已有超过3万家中小企业使用。\n*   **消费决策：** 值得买科技基于消费大模型研发的AI购物助手“小值”上线，能深度理解用户需求，提供口碑总结、商品对比、全网比价等服务，提升消费决策效率。\n*   **金融领域：** AI助手（如0xAI算法）被用于提升投资胜率（达到95%）、精准预测市场时机（对A股和港股股指预测准确率100%）以及优化风险控制。\n*   **医疗领域：** 科大讯飞的“智医助手”机器人已学习全科知识，在全国400多个区县规模化应用，为医生提供辅助诊断建议和知识推送。\n*   **司法领域：** AI助手已“上岗”辅助法院审判，深圳市中级人民法院的系统已辅助立案29.1万件，辅助生成文书初稿1.16万份。\n\n### 市场趋势与影响：\n\n*   **市场规模预测：** 全球AI助手市场规模预计到2028年达到285亿美元，2023—2028年复合增长率为43%。\n*   **主要驱动力：** AI技术的进步（如NLP', 'doi': '', 'published_date': '2024-08-13T00:00:00+00:00', 'pdf_url': '', 'url': 'https://finance.sina.com.cn/jjxw/2024-08-13/doc-inciniqn0493260.shtml', 'source': 'exa_summary', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 17:49:29,378 - __main__ - INFO - call_tool: name=exa_summary_search, args={'query': '人工智能在日常生活中的应用与影响 2024', 'type': 'auto'}
2026-02-03 17:49:29,379 - __main__ - INFO - handle_search: searcher=ExaSearcherSummary, query=人工智能在日常生活中的应用与影响 2024, search_type=auto
2026-02-03 17:49:44,020 - __main__ - INFO - handle_search: returned=10
2026-02-03 17:49:44,020 - __main__ - INFO - call_tool payload: source_tool=exa_summary_search, result_type=papers, count=10
2026-02-03 17:49:44,020 - __main__ - INFO - call_tool: name=exa_summary_search, result_type=papers, count=10
2026-02-03 17:49:44,020 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '探索未来：人工智能在日常生活中的应用与影响', 'authors': [], 'abstract': '本文探讨了人工智能（AI）在日常生活中的应用及其影响，尤其关注2024年的发展趋势。AI技术已广泛渗透到智能家居、医疗健康、教育和职场等多个领域。智能家居设备的出货量预计到2024年将超过17亿台，能够自动调整环境设置并优化居住体验。在医疗领域，AI通过深度学习提高诊断准确性，并推动个性化治疗的发展。教育方面，智能平台利用AI提供个性化学习体验，提升学习效率。职场上，AI的自动化趋势改变了工作性质，带来了新的技能需求和职业机会。\n\n尽管AI带来了便利，但也引发了隐私、安全和就业等方面的担忧，强调了建立法律和伦理框架的重要性。总体来看，AI在未来将继续深刻影响我们的生活、工作和社会结构。', 'doi': '', 'published_date': '2024-07-25T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.aliyun.com/article/1571786', 'source': 'exa_summary', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 18:00:46,543 - __main__ - INFO - call_tool: name=exa_summary_search, args={'query': '人工智能在日常生活中的应用与影响 2024', 'type': 'auto'}
2026-02-03 18:00:46,544 - __main__ - INFO - handle_search: searcher=ExaSearcherSummary, query=人工智能在日常生活中的应用与影响 2024, search_type=auto
2026-02-03 18:00:59,344 - __main__ - INFO - handle_search: returned=10
2026-02-03 18:00:59,345 - __main__ - INFO - call_tool payload: source_tool=exa_summary_search, result_type=papers, count=10
2026-02-03 18:00:59,345 - __main__ - INFO - call_tool: name=exa_summary_search, result_type=papers, count=10
2026-02-03 18:00:59,345 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'AI 大躍進：2024 年AI 發展回顧，展望未來 - Trend Micro', 'authors': [], 'abstract': '在2024年，人工智能（AI）逐渐融入人们的日常生活，成为企业解决方案的重要组成部分。知名公司如Microsoft和Salesforce已将AI技术嵌入其产品中，推动了AI应用的普及。此外，各类专门的AI应用程序和服务不断涌现，政府和监管机构也开始制定相关规范以引导AI的发展。\n\n2024年的一个显著趋势是代理式AI（agentic AI）的崛起，许多AI公司将研发重心转向这一领域，提供“AI代理服务”。例如，Anthropic推出的Claude 3.5 Sonnet模型能够操作计算机，标志着AI在日常任务中的应用能力提升。\n\n同时，检索增强生成（RAG）技术的应用使得AI系统能够更有效地获取相关信息，从而提高问题解决的准确性。小型化AI模型的开发也在加速，Meta和Nvidia等公司推出了更快速、体积更小的模型，使得AI技术在移动设备上也能高效运行。\n\n然而，AI的普及也带来了新的挑战，尤其是在网络安全方面。AI技术被不法分子用于网络诈骗和勒索，深伪技术的应用使得网络犯罪更加隐蔽和复杂，给社会带来了严重威胁。\n\n总的来说，2024年AI', 'doi': '', 'published_date': '2025-02-04T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.trendmicro.com/zh_tw/research/25/a/top-ai-trends-from-2024-review.html', 'source': 'exa_summary', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 18:02:20,946 - __main__ - INFO - call_tool: name=exa_summary_search, args={'query': '人工智能在日常生活中的应用与影响 2024', 'type': 'auto'}
2026-02-03 18:02:20,947 - __main__ - INFO - handle_search: searcher=ExaSearcherSummary, query=人工智能在日常生活中的应用与影响 2024, search_type=auto
2026-02-03 18:02:35,039 - __main__ - INFO - handle_search: returned=10
2026-02-03 18:02:35,039 - __main__ - INFO - call_tool payload: source_tool=exa_summary_search, result_type=papers, count=10
2026-02-03 18:02:35,039 - __main__ - INFO - call_tool: name=exa_summary_search, result_type=papers, count=10
2026-02-03 18:02:35,039 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'AI元年2024：全球人工智能大事件盘点 - 华为云', 'authors': [], 'abstract': '在2024年，人工智能（AI）在日常生活中的应用与影响显著增强，涵盖多个领域，改变了人们的生活和工作方式。以下是一些关键事件和应用：\n\n1. **人机交互技术**：Neuralink成功植入脑机接口芯片，开启了人机交互的新篇章，展示了AI与神经科学的结合潜力。\n\n2. **智能手机的AI集成**：三星发布的Galaxy S24系列手机，集成了多项AI功能，如智能拍照和个性化推荐，推动了智能手机的AI技术发展。\n\n3. **生成式AI的崛起**：OpenAI推出的视频生成模型Sora和谷歌的Gemini 1.5 Pro，标志着AI在视觉内容生成领域的重大进步，影响了娱乐和教育行业。\n\n4. **医疗领域的应用**：AI辅助诊断工具在阿尔茨海默病早期检测中的应用，提高了诊断效率和准确性，展示了AI在医疗健康领域的潜力。\n\n5. **智能助手的普及**：微软和苹果分别扩展了其智能助手功能，提升了办公效率和设备端的智能处理能力。\n\n6. **新职业的出现**：随着AI技术的普及，19个新职业如网络主播和生成式AI系统应用员获得', 'doi': '', 'published_date': '2025-01-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://bbs.huaweicloud.com/blogs/444342', 'source': 'exa_summary', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 18:11:10,643 - __main__ - INFO - call_tool: name=exa_summary_search, args={'query': '人工智能在日常生活中的应用与影响 2024', 'type': 'auto'}
2026-02-03 18:11:10,644 - __main__ - INFO - handle_search: searcher=ExaSearcherSummary, query=人工智能在日常生活中的应用与影响 2024, search_type=auto
2026-02-03 18:11:22,860 - __main__ - INFO - handle_search: returned=10
2026-02-03 18:11:22,860 - __main__ - INFO - call_tool payload: source_tool=exa_summary_search, result_type=papers, count=10
2026-02-03 18:11:22,860 - __main__ - INFO - call_tool: name=exa_summary_search, result_type=papers, count=10
2026-02-03 18:11:22,860 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'AI元年2024：全球人工智能大事件盘点 - 华为云', 'authors': [], 'abstract': '在2024年，人工智能（AI）在日常生活中的应用和影响显著增强，涵盖多个领域。以下是一些关键事件和趋势：\n\n1. **人机交互**：Neuralink成功植入首个脑机接口芯片，开启了人机交互的新篇章，展示了AI与神经科学的结合潜力。\n\n2. **智能手机**：三星发布的Galaxy S24系列手机集成了多项AI功能，如智能拍照和个性化推荐，推动了智能手机的AI技术发展。\n\n3. **生成式AI**：OpenAI推出的视频生成模型Sora和谷歌的Gemini 1.5 Pro模型，标志着AI在视觉内容生成和多模态处理能力上的重大突破，影响了娱乐和教育行业。\n\n4. **医疗应用**：AI辅助诊断工具在阿尔茨海默病早期检测中的应用，提高了医疗效率和准确性，展示了AI在健康领域的潜力。\n\n5. **智能助手**：微软和苹果分别扩展了其AI助手功能，提升了办公效率和设备智能处理能力，进一步融入用户的日常生活。\n\n6. **职业新生态**：随着AI技术的普及，19个新职业如网络主播和生成式AI系统应用员获得官方认定，反映了AI对职业生态的深远', 'doi': '', 'published_date': '2025-01-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://bbs.huaweicloud.com/blogs/444342', 'source': 'exa_summary', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-03 18:12:04,480 - __main__ - INFO - call_tool: name=exa_summary_search, args={'query': '人工智能在日常生活中的应用与影响 2024', 'type': 'auto'}
2026-02-03 18:12:04,480 - __main__ - INFO - handle_search: searcher=ExaSearcherSummary, query=人工智能在日常生活中的应用与影响 2024, search_type=auto
2026-02-03 18:12:17,020 - __main__ - INFO - handle_search: returned=10
2026-02-03 18:12:17,020 - __main__ - INFO - call_tool payload: source_tool=exa_summary_search, result_type=papers, count=10
2026-02-03 18:12:17,020 - __main__ - INFO - call_tool: name=exa_summary_search, result_type=papers, count=10
2026-02-03 18:12:17,020 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '2024，AI开始改变世界 - 新浪财经', 'authors': [], 'abstract': '在2024年，人工智能（AI）技术实现了显著的应用落地，深刻影响了日常生活的多个方面。以下是主要应用及其影响：\n\n1. **生成式AI**：OpenAI的文生视频大模型Sora等技术使得AI能够生成多模态内容，包括文本、图像和视频。这种能力提升了内容创作的效率，广泛应用于新闻、广告和娱乐行业。\n\n2. **自动驾驶与智能交通**：自动驾驶技术在城市公共交通和个人汽车领域取得了重要进展，多个城市已开始提供自动驾驶出租车服务。AI在交通管理中的应用优化了交通流量和事故预警，推动了智慧城市的建设。\n\n3. **医疗AI**：AI在医疗领域的应用加速，特别是在疾病诊断和个性化治疗方面。AI辅助的图像识别技术提高了疾病检测的准确性，且在药物研发和基因组学分析中发挥了重要作用。\n\n4. **工业AI与智能制造**：AI技术在工业自动化中显著提升了生产效率，通过实时监控和数据分析，预测设备故障并优化生产过程。\n\n尽管AI的应用带来了诸多便利，但也引发了对技术鸿沟、隐私泄露和网络安全等问题的关注，成为未来发展的挑战。', 'doi': '', 'published_date': '2024-12-26T00:00:00+00:00', 'pdf_url': '', 'url': 'https://finance.sina.com.cn/jjxw/2024-12-26/doc-ineatxus9917792.shtml', 'source': 'exa_summary', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
