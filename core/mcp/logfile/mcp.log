2026-02-02 16:21:41,168 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:21:41,169 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=en, search_type=None
2026-02-02 16:21:41,172 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:21:41,173 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 16:21:41,175 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:21:41,175 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 16:21:44,207 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 16:21:44,207 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 16:21:45,104 - __main__ - INFO - handle_search: returned=10
2026-02-02 16:21:45,104 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 16:21:45,104 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 16:21:49,925 - __main__ - INFO - handle_search: returned=10
2026-02-02 16:21:49,926 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-02 16:21:49,926 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '【EP04_短期记忆持久化存储和记忆管理策略】2026必学 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9999826, 'save_path': None}}
2026-02-02 16:23:00,944 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:23:00,945 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=en, search_type=None
2026-02-02 16:23:00,973 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:23:00,974 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 16:23:01,001 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:23:01,001 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 16:23:07,322 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 16:23:07,322 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 16:23:08,824 - __main__ - INFO - handle_search: returned=10
2026-02-02 16:23:08,825 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 16:23:08,825 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 16:23:44,985 - __main__ - INFO - handle_search: returned=10
2026-02-02 16:23:44,986 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-02 16:23:44,986 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '【EP04_短期记忆持久化存储和记忆管理策略】2026必学 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9999826, 'save_path': None}}
2026-02-02 16:24:22,745 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '管理LangGraph Postgres 檢查點以實現短期記憶的最佳實踐是什麼？', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生產環境中，管理 LangGraph Postgres 檢查點以實現短期記憶的最佳實踐是什麼？\n\n我正在為聊天機器人構建一個記憶系統，使用 **LangGraph**。 目前我專注於 **短期記憶**，由 **PostgresSaver** 支援。\n\n每次狀態轉換都會儲存在 `checkpoints` 表格中。正如預期，每次使用者互動（圖調用 / LLM 呼叫）都會建立多個檢查點，因此檢查點表格中的檢查點資料會**隨著使用量線性增長**。\n\n`checkpoints`\n\n在生產環境中，管理這種增長的推薦策略是什麼？\n\n具體來說：\n\n**只保留每個** thread\\_id 的最後 N 個檢查點並刪除較舊的檢查點，這是最佳實踐嗎？\n\n人們如何權衡**恢復/復原安全性**與**資料庫增長**的規模？\n\n供參考：\n\n我已經使用對話摘要，因此較舊的訊息不需要用於上下文\n\n檢查點主要用於短期恢復和狀態連續性，而不是長期記憶\n\nLangGraph 可以**從最後一個檢查點恢復**\n\n很好奇其他人如何在實際的生產系統中處理這個問題。\n\n此外，在 postgres 中，langgraph 建立 4 個關於檢查點的表格：checkpoints, checkpoint\\_writes, checkpoint\\_migrations, checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hant', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99993443, 'save_path': None}}, {'paper_id': '', 'title': '建议收藏：LangChain实战教程- 大模型应用开发者的必备技能', 'authors': [], 'abstract': '# [logo DAMO开发者矩阵](https://damodev.csdn.net "DAMO开发者矩阵")\n\n![logo](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n![](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\n## 登录社区云\n\n登录社区云，与社区用户共同成长\n\n### DAMO开发者矩阵\n\n邀请您加入社区\n\n![]()![]()\n\n# 建议收藏：LangChain实战教程 - 大模型应用开发者的必备技能\n\nLangChain是2022年10月（ChatGPT在2022年11月30问世，比ChatGPT还早），由哈佛大学的Harrison Chase（哈里森·蔡斯）发起研发的一个用于开发基于大语言模型（LLM） 应用程序的开源框架，它的核心目标是简化AI应用的构建过程，让开发者能像搭积木一样，快速组合各种模块来实现复杂功能，如：搭建智能体（Agent）、问答系统（QA）、对话机器人、知识库等。\n\n![](https://profile-avatar.csdnimg.cn/eeb633f233d641ef859131b4ee5aec84_m0_57081622.jpg!1)\n\n### [程序媛饺子](https://devpress.csdn.net/user/m0_57081622)\n\n![](https://profile-avatar.csdnimg.cn/eeb633f233d641ef859131b4ee5aec84_m0_57081622.jpg!1)\n\nLangChain是用于开发大模型应用程序的开源框架，提供高度模块化、可扩展的工具集。文章详细介绍了LangChain的六大核心组件：Model I/O、Chains、Memory、Tools、Agent和Retrieval。通过这些组件，开发者可以快速构建功能复杂的大模型应用，如智能问答系统、对话机器人和知识库等。文章提供了环境准备和各组件的使用方法，适合初学者入门大模型应用开发。\n\n![](https://i-blog.csdnimg.cn/img_convert/612cbcc9f9c682b065b007be815c12f3.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/612cbcc9f9c682b065b007be815c12f3.jpeg)\n\n### 1、LangChain概述\n\n##### 1.1 什么是LangChain\n\nLangChain是2022年10月（ChatGPT在2022年11月30问世，比ChatGPT还早），由哈佛大学的Harrison Chase（哈里森·蔡斯）发起研发的一个用于开发基于大语言模型（LLM） 应用程序的开源框架，它的核心目标是简化AI应用的构建过程，让开发者能像搭积木一样，快速组合各种模块来实现复杂功能，如：搭建智能体（Agent）、问答系统（QA）、对话机器人、知识库等。\n\nLangChain在Github上的热度变化：\n\n![](https://i-blog.csdnimg.cn/img_convert/fc58d017ea20ea3595ff96391f3cf5a9.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/fc58d017ea20ea3595ff96391f3cf5a9.jpeg)\n\nAI大模型架构图：\n\n![](https://i-blog.csdnimg.cn/img_convert/80708237cabe70cf78b935e053a4c83c.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/80708237cabe70cf78b935e053a4c83c.jpeg)\n\nLangChain所处的位置：\n\n![](https://i-blog.csdnimg.cn/img_convert/61fd60c802c72cfa8b05d9359d1608f8.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/61fd60c802c72cfa8b05d9359d1608f8.jpeg)\n\n##### 1.2 为什么使用LangChain\n\n使用 LangChain 的核心价值在于，它提供了一套高度模块化、可扩展的工具集，让开发人员能够快速、灵活地构建功能丰富的大模型应用，无需关注底层复杂的细节。它开发难度小，学习成本低，并且提供了现成的链式组装，能够让复杂的逻辑变得结构化、可扩展。LangChain最初只是一个开源的软件包，如今已称为一个完整的生态系统，它提供了一系列的标准化组件，且都可以单独使用。\n\n下表是直接对接大模型和使用LangChain的对比：\n\n|  |  |  |\n| --- | --- | --- |\n| 对比维度 | 直接调用大模型API | 使用 LangChain 开发 |\n| 开发模式 | 相对直接，但复杂功能需大量自定义代码 | 模块化组装，提供大量预制组件和链，简化复杂逻辑 |\n| 多模型支持 | 通常需为不同供应商的API编写适配代码 | 统一接口，轻松切换或组合不同模型（如OpenAI、Anthropic、Hugging Face等） |\n| 外部数据集成 | 需自行实现数据加载、处理、向量化与检索逻辑 | 内置RAG（检索增强生成） 等强大支持，可轻松连接PDF、数据库、API等外部数据源 |\n| 上下文管理 | 需手动管理对话历史，易超出Token限制 | 内置Memory组件，灵活管理短期和长期记忆，维持连贯对话 |\n| 复杂任务自动化 | 实现多步骤推理或工具调用逻辑复杂 | 通过Agents，让模型能自主决策、调用工具（如计算器、搜索引擎）完成任务 |\n| 生产部署与调试 | 缺乏标准化工具，监控和调试较困难 | 提供LangSmith等平台，用于监控、追踪和调试应用性能 |\n\n##### 1.3 LangChain架构设计（宏观）\n\nLangChain是由多个包组成的框架：\n\n![](https://i-blog.csdnimg.cn/img_convert/df0f6425db407399b5971bd720a17819.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/df0f6425db407399b5971bd720a17819.jpeg)\n\n图中展示了LangChain（V0.3版本）生态系统的主要组件及其分类，分为三个层次：架构(Architecture)、组件(Components)和部署(Deployment)。\n\n结构1：LangChain（架构中的LangChain，也是后文介绍的）：封装了一系列的API。\n\n结构2：LangGraph：基于有向图+条件边来灵活的构建多智能体应用，提供了条件分支、循环、并行等复杂控制流，能够实现状态持久化、断点续跑、时间旅行、人机协作等高级功能。\n\n结构3：LangSmith：用于构建、调试、测试、评估、监控和链路追踪大模型应用程序，提供了6大功能，涉及Debugging (调试)、Playground (沙盒)、Prompt Management (提示管理)、Annotation (注释)、Testing (测试)、Monitoring (监控)等。与LangChain无缝集成，从原型阶段过渡到生产阶段。\n\n结构4：LangServe：将基于 LangChain 开发的链（Chain）、代理（Agent）等快速部署为 REST API 服务。它基于 FastAPI 构建，极大简化了 AI 应用服务化的流程\n\nLangChain当中，目前最火的两个模块就是：LangGraph，LangSmith。\n\n##### 1.4 LangChain核心组件\n\nLangChain提供了一个高度模块化且可组合的框架，开发者能通过灵活集成其六大核心组件，来构建功能复杂的大模型应用。\n\n![](https://i-blog.csdnimg.cn/img_convert/bbc37ef968c9e4f313d62ead7a9e2431.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/bbc37ef968c9e4f313d62ead7a9e2431.jpeg)\n\n后续章节将详细介绍以上组件的使用方式。\n\n### 2、LangChain使用之环境准备\n\n##### 2.1 安装LangChain\n\nLangChain基于Python开发，因此需确保系统中安装了Python环境。\n\n安装LangChain\n\n`方式一：pip install langchain\n方式二：conda install langchain`\n\n##### 2.2 简单demo\n\n`chat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key, # 秘钥\ntemperature=0.7 # 温度参数,控制生成文本的随机性\n)`\n\n![](https://i-blog.csdnimg.cn/img_convert/c98a89d909e1500a64ce5e0875dd9c69.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/c98a89d909e1500a64ce5e0875dd9c69.jpeg)\n\n### 3、LangChain核心组件之Model I/O\n\n##### 3.1 Model I/O\n\nModel I/O 是应用程序与大模型进行交互的组件，它与大模型的关系类似于JDBC与数据库的关系，本质上都是为了解耦应用逻辑与底层实现，提供标准化的交互接口，使应用程序无需关注大模型底层的实现，可与各种大模型进行交互。Model I/O 包括输入提示(Format)、调用模型(Predict)、输出解析(Parse)。分别对应着Prompt Template（提示词模版），Model （大模型）和Output Parser（输出解析器）。\n\n![](https://i-blog.csdnimg.cn/img_convert/4a18421a6499bd0cb6a7f69628083b72.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/4a18421a6499bd0cb6a7f69628083b72.jpeg)\n\n说白了，Model I/O 就是LangChain 提供了一系列与大模型交互的API。\n\n##### 3.2 大模型分类（按功能）\n\n1、LLMs（大语言模型）\n\n也叫非对话模型，是许多语言模型应用程序的支柱，通用的文本生成，能够完成一次性的文本生成任务，如写作、翻译等。\n\n`llm_model = OpenAI()\nllm_model.invoke("什么是LangChain?")`\n\n2、Chat Models（对话模型）\n\n专门为多轮对话场景优化的语言模型。与LLMs处理纯字符串不同，Chat Models的输入和输出都是结构化的消息对象，能更好地理解和维护对话的上下文。\n\n`# 创建ChatOpenAI模型实例\nchat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key, # 秘钥\ntemperature=0.7 # 温度参数,控制生成文本的随机性\n)\n# 调用模型\nresponse = chat_model.invoke("用简单一句话概括一下什么是反洗钱？")\n# 打印模型响应内容\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/1d33c47d916d464c0cddb96670eb4ed0.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/1d33c47d916d464c0cddb96670eb4ed0.jpeg)\n\n3、Embedding Model（嵌入模型）\n\n它的核心任务是将文字、图片等非结构化数据，转换成高维空间中的数值向量。并且能够将语义相近的内容在向量空间中的位置也映射得更近。\n\n`# 我这里使用的嵌入模型是自己本地部署的，OpenAI的类为OpenAIEmbeddings\nembeddings_model = OllamaEmbeddings(\nmodel="nomic-embed-text",\nbase_url="http://127.0.0.1:11434",\n)\nvector = embeddings_model.embed_query("hello world")\nprint(f"嵌入向量长度: {len(vector)}")\nprint(f"前20个值: {vector[:20]}")`\n\n![](https://i-blog.csdnimg.cn/img_convert/d00ae27cad22c2ccc797c08922dd53cd.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/d00ae27cad22c2ccc797c08922dd53cd.jpeg)\n\n##### 3.3 Message（消息）\n\n消息是对话模型中通信的基本单位，用于表示与模型通讯的输入与输出，以及包含与对话相关的上下文信息和元数据，每一条消息都包含一个角色（系统、用户、AI等）和内容（用户的输入或模型的输出）以及其他元信息（id、名称、令牌使用情况等），LangChain提供了一个统一的消息格式，可以在不同模型之间使用。\n\n1、SystemMessage（系统消息）：设定行为准则，用于定义大模型的角色、运行规则、环境信息等。如果模型不支持SystemMessage则LangChain会将消息合并到HumanMessage中一起发送给大模型。\n\n2、HumanMessage（用户消息）：用户的输入，用户向模型发出的提问或指令。\n\n3、AIMessage（大模型消息，一般是模型返回的结果）：大模型的输出，这是大模型对HumanMessage和SystemMessage的响应。它不仅包含生成的文本内容（content属性），还可能包含以下结构化信息（外部工具、调用令牌使用情况等元数据）。\n\n4、ToolMessage/ FunctionMessage：连接外部能力，向模型传递外部工具或函数调用的执行结果，常用于Agent调用tool。\n\n`chat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key # 秘钥\n)\nmessages = [\n# 创建系统消息，定义模型的角色\nSystemMessage(content="我是反洗钱领域的专家，我叫RiskHelper"), # 创建用户消息，用户的提问\nHumanMessage(content="你好，什么是反洗钱？")\n]\n# 返回的类型是AI大模型消息\nresponse = chat_model.invoke(messages)\nprint(type(response)) # 格式是AIMessage`\n\n![](https://i-blog.csdnimg.cn/img_convert/5e7b38e54083581577000e038293638d.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/5e7b38e54083581577000e038293638d.jpeg)\n\n##### 3.4 Prompt Template（提示词模版）\n\nPrompt（提示词）：提示词是与大模型交互时输入的内容，用来指导大模型生成特定类型的回答或执行特定的任务。它可以是一个简单的问题、一段详细的任务说明，或包含角色、背景、示例的复杂文本。其核心目的是约束行为，减少错误，引导模型生成用户期望的响应。好的提示词可以解决60%以上的模型幻觉问题，优化提示词也是我们后续开发中解决大模型幻觉最多且最有效的方式之一。\n\n如下是一个简单的提示词：\n\n`"""\n您是一名资深LangChain框架专家，具备以下专业背景：\n- 精通LangChain 0.3.x及以上版本的核心架构\n- 熟练掌握Models、Prompts、Chains、Agents、Memory五大组件\n- 拥有实际企业级LLM应用部署经验\n请根据用户需求提供：\n1. 架构设计建议（组件选型与组合逻辑）\n2. 代码实现方案（包含最佳实践）\n3. 性能优化策略（处理长文本/高并发场景）\n4. 错误排查指导（常见陷阱与解决方案）用户输入: {input}\n"""`\n\nPrompt Template（提示词模版）：固定的提示词限制了模型的灵活性和适用范围，所以 Prompt Template 是一个模板化的字符串，可以将变量（如用户提问等）插入到模板的占位符中，从而创建出不同的提示。LangChain提供了很多提示词模版，用于与大模型交互，常见的提示词模版如下：\n\n1、PromptTemplate：LLM提示模板，用于生成字符串提示，生成的是单一、无角色区分的纯文本字符串。\n\n`# 创建PromptTemplate\nprompt_template = PromptTemplate(\ntemplate="如何成为一个{domain}领域的专家",\ninput_variables=["domain"]\n)\n# 填充模版参数，将反洗钱填充到domain字段中\nmessages = prompt_template.invoke({"domain": "反洗钱"})\nresponse = chat_model.invoke(messages)\nprint(response.content)`\n\n2、ChatPromptTemplate：创建聊天消息列表的提示模板。生成的是结构化的消息列表，其中每条消息都带有明确的角色（如系统、用户、AI），用在对话模型中。\n\n`# 方式一，使用构造函数创建\nchatprompt_template = ChatPromptTemplate([\n# key: 角色, value: 内容,\n("system", "你是一个反洗钱领域的专家，你的名字是{name}"), # 系统提示词\n("human", "帮我解答一下{question}") # 用户提示词\n])\n# 填充模版参数\nmessage = chatprompt_template.format(name="RiskHelper", question="什么是反洗钱？")\nresponse = chat_model.invoke(message)\nprint(response.content)\n# 方式二，使用from_messages方法创建\nchatprompt_template = ChatPromptTemplate.from_messages([\n("system", "你是一个反洗钱领域的专家，你的名字是{name}"),\n("human", "帮我解答一下{question}")\n])\n# 填充模版参数\nmessages = chatprompt_template.format(name="RiskHelper", question="什么是反洗钱？")\nresponse = chat_model.invoke(messages)\nprint(response.content)`\n\n3、XxxMessagePromptTemplate ：特定角色的消息提示词模板，包括：SystemMessagePromptTemplate、HumanMessagePromptTemplate、AIMessagePromptTemplate、ChatMessagePromptTemplate等，通常用ChatPromptTemplate将消息提示词模版打包在一起，一并发送给模型。\n\n`# 创建聊天提示词模版\nchatprompt_template = ChatPromptTemplate([\n# 创建系统提示词模版\nSystemMessagePromptTemplate.from_template("你是一个反洗钱领域的专家，你的名字是{name}"),\n# 创建用户提示词模版\nHumanMessagePromptTemplate.from_template("帮我解答一下{question}")\n])\n# 填充模版参数\nmessage = chatprompt_template.format(name="RiskHelper", question="什么是反洗钱？")\nresponse = chat_model.invoke(message)\nprint(response.content)`\n\n4、FewShotPromptTemplate ：样本提示词模板，提供少量的样例作为参考来引导大模型按照特定的格式和风格输出。\n\n`# 1. 定义示例数据\nexamples = [\n{\n"question": "什么是Spring Boot？",\n"answer": "Spring Boot是一个基于Spring框架的开源Java框架，用于简化Spring应用程序的创建和部署。"\n},\n{\n"question": "什么是依赖注入？",\n"answer": "依赖注入是一种设计模式，通过外部容器向对象提供其所需的依赖，而不是对象自己创建依赖。"\n},\n{\n"question": "什么是RESTful API？",\n"answer": "RESTful API是遵循REST架构风格的Web服务接口，使用HTTP方法进行资源操作。"\n}\n]\n# 2. 定义示例模板\nexample_prompt = PromptTemplate(\ninput_variables=["question", "answer"],\ntemplate="问题: {question}\\n答案: {answer}"\n)\n# 3. 创建few-shot提示词模版\nfew_shot_prompt = FewShotPromptTemplate(\nexamples=examples,\nexample_prompt=example_prompt,\nsuffix="问题: {question}",\ninput_variables=["question"]\n)\nformatted_prompt = few_shot_prompt.format(question="什么是LangChain？")\nresponse = chat_model.invoke(formatted_prompt)\nprint(response.content)`\n\n还有一些其他的提示词模版，大家感兴趣可以参考：\n\nhttps://python.langchain.com.cn/docs/modules/model\\_io/prompts/prompt\\_templates/\n\n##### 3.5 Output Parsers（输出解析器）\n\n大模型通常返回的内容都是字符串格式，但是我们实际开发中更擅长处理结构化数据，输出解析器就是将大模型输出的结果转换成特定的结构化数据，以便应用程序能更方便的处理。LangChain提供了一些常见的输出解析器，如StrOutputParser（字符串解析器）、JsonOutputParser（json解析器）、CommaSeparatedListOutputParser（csv解析器）、DatetimeOutputParserde（日期解析器）、XmlOutputParser（xml解析器）等下边用JsonOutputParser写一个简单的实例\n\n`json_parser = JsonOutputParser()\nprompt_template = PromptTemplate(\ntemplate="用简单的一句话描述一下什么是{name}？请按照以下格式输出：{format_instructions}",\ninput_variables=["name"],\n# 告诉大模型，按照json格式输出\npartial_variables={"format_instructions": json_parser.get_format_instructions()}\n)\nmessages = prompt_template.invoke({"name": "反洗钱"})\nresponse = chat_model.invoke(messages)\nprint(json_parser.parse(response.content))`\n\n![](https://i-blog.csdnimg.cn/img_convert/8c9ed335b85f14ae3d7740fdbb0a9eb7.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/8c9ed335b85f14ae3d7740fdbb0a9eb7.jpeg)\n\n##### 3.6 模型的调用方式\n\nRunnable 接口是使用LangChain组件的基础，它在许多组件中实现，例如语言模型、输出解析器、检索器、编译的LangGraph 图等。Runnable 方式定义了一个标准接口，允许 Runnable 组件用以下方式调用：\n\n1、invoke：处理单条输入，等待模型完全处理完成后再返回结果，上述的例子都是invoke调用\n\n2、stream：流式响应，逐字符输出模型的响应，类似于我们日常使用的AI应用（元宝）一样，给用户输出是逐字输出，无需等所有的结果生成后一次返回，对于用户交互体验较好。\n\n`# 流式输出\nchat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key, # 秘钥\nstreaming=True # 开启流式输出\n)\nchatprompt_template = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个反洗钱领域的专家"),\nHumanMessagePromptTemplate.from_template("请详细讲一下什么是{value}？")\n])\nmessage = chatprompt_template.invoke({"value": "反洗钱"})\nfor output in chat_model.stream(message):\n# 逐个打印token内容\nprint(output.content, end="", flush=True)`\n\n3、batch：批量处理，可以将多个消息一起发送给模型。\n\n`# 创建三个消息\nmessage1 = [HumanMessage(content="什么是风控？")]\nmessage2 = [HumanMessage(content="什么是反洗钱？")]\nmessage3 = [HumanMessage(content="什么是EDD？")]\nmessages = [message1, message2, message3]\n# 批量调用\nresponse = chat_model.batch(messages)\nprint(response)`\n\nLangChain还提供了与上边相对应的异步方法：\n\n如果对具体的调用方式感兴趣可以参考官方文档：LangChain-Runnable调用\n\nhttps://docs.langchain.com/oss/javascript/langchain/overview\n\n### 4、LangChain核心组件之Chains\n\n##### 4.1 Chain（链）概述\n\n链，它将多个组件（提示词模版、大模型、记忆、工具、输出解析器）串联起来，形成一个可执行的，自动化的工作流程，类似于流水线作业。它将上一个组件的输出作为下一个组件的输入，将多个步骤串连起来执行，最终将模型的响应结果返回给用户。一个小Chain可以包含提示词模版->大模型->输出解析器，一个主Chain也可以将多个子Chain串起来，比如输入一篇文章先翻译（Chain A），再总结（Chain B）。\n\n![](https://i-blog.csdnimg.cn/img_convert/ba085733315250ef60f2e92e1ad27336.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/ba085733315250ef60f2e92e1ad27336.jpeg)\n\n##### 4.2 Chain组件使用\n\n1、LLMChain（已过时）：最基础的Chain，将一个提示词模板和一个大模型封装在一起，构成一个可执行的单元。适用于简单的问答、文本生成等单步任务。它的工作流程是：将用户输入的数据填充提示词模板，然后将格式化后的提示词发送给大模型，最终返回大模型的生成结果。\n\n`chatprompt_template = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个反洗钱领域的专家，你的名字是{name}"),\nHumanMessagePromptTemplate.from_template("帮我解答一下{question}")\n])\n# 创建链\nchain = LLMChain(llm=chat_model, prompt=chatprompt_template)\n# 调用链，先执行prompt，并将结果给到llm，再执行llm，最后返回结果\nresponse = chain.invoke({"name": "RiskHelper", "question": "什么是反洗钱？"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/99e88f6f5b95ceae20b50af4e56a5a23.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/99e88f6f5b95ceae20b50af4e56a5a23.jpeg)\n\n注意：上述是LLMChain的使用，但是LLMChain在0.1.17版本已经被标记为过时，且在1.0版本后会被移除。\n\n2、SequentialChain（顺序链，已过时）：通过将多个Chain串起来，实现分步任务处理，前一个链的输出作为后一个链的输入，适用于需要分步处理的任务，如先总结再翻译。\n\n`chatprompt_template1 = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个{name}领域的专家"),\nHumanMessagePromptTemplate.from_template("请详细讲一下什么是{title}？")\n])\nchain1 = LLMChain(llm=chat_model, prompt=chatprompt_template1, output_key="text")\nchatprompt_template2 = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个文章总结专家"),\nHumanMessagePromptTemplate.from_template("请帮我用一句话概括一下{text}")\n])\nchain2 = LLMChain(llm=chat_model, prompt=chatprompt_template2, output_key="translation")\n# 构建顺序链\nchain = SequentialChain(\nchains=[chain1, chain2],\ninput_variables=["name", "title"],\noutput_variables=["translation"]\n)\nresponse = chain.invoke({"name": "反洗钱", "title": "EDD"})\nprint(response)`\n\nSequentialChain也在0.1.17版本被标记为过时，且在1.0版本后会被移除\n\n3、LCEL（LangChain Expression Language，推荐使用的方式）：是 LangChain 框架中用于构建和组合Chain的一种声明式、模块化且高效的语言。类似于Linux中的管道符 | ，将提示模板、语言模型、输出解析器等组件灵活地组合成可执行的工作流。\n\n`json_parser = JsonOutputParser()\nprompt_template = PromptTemplate(\ntemplate="用简单的一句话描述一下什么是{name}？请按照以下格式输出：{format_instructions}",\ninput_variables=["name"],\n# 告诉大模型，按照json格式输出\npartial_variables={"format_instructions": json_parser.get_format_instructions()}\n)\n# 使用管道符构建chain\nchain = prompt_template | chat_model | json_parser\nresponse = chain.invoke({"name": "反洗钱"})\nprint(response)`\n\n除了上述的chain之外，LangChain还提供了以下类型的chain。\n\n### 5、LangChain核心组件之Memory\n\n##### 5.1 Memory（记忆）概述\n\n我们知道，大模型本身都不会记忆任何上下文信息，那为什么我们常用的大模型应用能够清楚的知道我们之前的对话内容（与AI应用可以进行多轮对话）？并且有一定的记忆能力，这就需要额外的模块去保存我们和大模型进行对话的上下文信息，然后在下一次对话前将历史的记录全部发送给大模型，提供给大模型参考以便能够更准确的回答当前的提问。\n\n在LangChain中，这个用于存储用户和模型交互的历史信息的组件叫Memory，它能够让应用记住用户之前说了什么，从而实现对话的上下文感知能力，为构建真正智能和上下文感知的链式对话系统提供了基础。\n\n##### 5.2 Memory的原理\n\n![](https://i-blog.csdnimg.cn/img_convert/0ee35e925ec4e37e1dba3d77c05ddbf5.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/0ee35e925ec4e37e1dba3d77c05ddbf5.jpeg)\n\nSTEP1：用户输入问题\n\nSTEP2：从Memory中读取历史消息\n\nSTEP3：构建新的提示词，包含历史消息和当前的提问\n\nSTEP4：发送给大模型处理\n\nSTEP5：解析大模型输出，并返回用户\n\nSTEP6：将历史对话和当前对话一起保存在Memory中，以便下一次使用\n\n##### 5.3 Memory组件使用\n\nLangChain中提供了一系列的Memory用于保存历史上下文，不同的Memory保存的内容也不一样，常用的使用方式如下：\n\n1、ChatMessageHistory：用于存储和管理对话消息的基础类，它直接操作消息对象（如HumanMessage, AIMessage 等），是其它记忆组件的底层存储工具。特点：轻量、无需额外依赖、数据不会持久化（程序重启后丢失）。\n\n`# 创建Memory\nhistory = ChatMessageHistory()\n# 添加用户消息\nhistory.add_user_message("你好，我是RiskHelper")\n# 添加AI消息\nhistory.add_ai_message("我是DeepSeek大模型")\n# 添加用户消息\nhistory.add_user_message("我是谁？")\n# 通过将history.messages 直接传入大模型，大模型能够看到完整的对话上下文，从而实现有记忆的连续对话\nresponse = chat_model.invoke(history.messages)\nprint(response.content)`\n\n2、ConversationBufferMemory：是LangChain中最基础、最直接的记忆组件，按顺序完整地记录用户与AI之间的每一轮对话，并将这些历史信息提供给模型，以实现连贯的多轮对话。他能保存全部的上下文信息，对话连贯性最强，但是会消耗大量的Token，且随着对话的进行，会占用大量的内存资源。它适用于短对话，需要保存完整的上下文信息的复杂任务。\n\n`prompt_template = PromptTemplate.from_template(\n"历史对话: {history}，当前问题: {input}"\n)\nmemory = ConversationBufferMemory(memory_key="history")\nchain = LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\nresponse = chain.invoke({"input": "用简单一句话描述什么是LangChain？"})\nprint(response)\nprint("==============================================================")\nresponse = chain.invoke({"input": "如何使用它？"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/61a01fab9110f645539e84dcc6f11e83.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/61a01fab9110f645539e84dcc6f11e83.jpeg)\n\n3、ConversationBufferWindowMemory：只保留最近 K 轮对话，解决ConversationBufferMemory占用内存多、tokken消耗大问题，平衡连贯性与资源消耗。随之带来的问题是会丢失早期上下文，不适合复杂场景。\n\n`prompt_template = PromptTemplate.from_template(\n"历史对话: {history}，当前问题: {input}"\n)\nmemory = ConversationBufferWindowMemory(memory_key="history", k=10) # k表示保留的对话轮数\nchain = LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\nresponse = chain.invoke({"input": "用简单一句话描述什么是LangChain？"})\nprint(response)`\n\n4、ConversationSummaryMemory：它是 LangChain 中一种智能的记忆管理组件，它通过自动生成对话摘要来解决长对话上下文管理的问题。与简单截断历史的记忆类型不同，它使用大模型来提炼对话精髓，实现长期记忆。核心思想是：不存储原始对话记录，而是存储对话的智能摘要。当新的对话发生时，系统会将现有摘要与最新对话结合，生成更新的摘要。\n\n`history = ChatMessageHistory()\nhistory.add_ai_message("你好，我是RiskHelper")\nhistory.add_user_message("你好，什么是反洗钱？")\nhistory.add_user_message("你好，什么是风控”")\nmemory = ConversationSummaryMemory.from_messages(llm=chat_model,chat_memory=history)\nprint(memory.load_memory_variables({}))`\n\n![](https://i-blog.csdnimg.cn/img_convert/a3334737783cac7bce6854c671ff0c27.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/a3334737783cac7bce6854c671ff0c27.jpeg)\n\n5、ConversationSummaryBufferMemory：是LangChain中一种非常实用的混合型记忆组件，它巧妙地将对话摘要与原始对话缓冲区结合起来，旨在解决长对话场景下既要保持上下文连贯性又要控制资源消耗的核心矛盾。其核心创新在于采用了分层记忆管理策略，在对话连贯性和资源消耗之间找到平衡点。\n\n`memory = ConversationSummaryBufferMemory(\nllm=chat_model,\nmax_token_limit=100,\nreturn_messages=True\n)\nmemory.save_context({"input": "你好，我是RiskHelper"},{"output": "你好，我是DeepSeek大模型"})\nmemory.save_context({"input": "你好，什么是反洗钱？"},{"output": "反洗钱是指对洗钱犯罪的预防和打击措施"})\nmemory.save_context({"input": "你好，什么是风控？"},{"output": "风控是指对风险的控制措施"})\nmemory.save_context({"input": "你好，EDD？"},{"output": "EDD是指对客户身份的识别措施"})\nprint(memory.load_memory_variables({}))`\n\n![](https://i-blog.csdnimg.cn/img_convert/bf8a29b39aac861b830c4c5119d0ad36.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/bf8a29b39aac861b830c4c5119d0ad36.jpeg)\n\n注意： 有些模型（如Deepseek）没提供get\\_num\\_tokens\\_from\\_messages（计算token）函数，执行时会报错，解决办法继承ChatOpenAI，然后实现get\\_num\\_tokens\\_from\\_messages函数：\n\n`#创建一个继承于ChatOpenAI的类，并实现get_num_tokens_from_messages方法\nclass DeepSeekChatOpenAI(ChatOpenAI):\ndef get_num_tokens_from_messages(self, messages: List[BaseMessage]) -> int:\n#实现get_num_tokens_from_messages方法，返回消息的token数量\ntotal_tokens = 100 # 自定义函数\nreturn total_tokens;\nchat_model = DeepSeekChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url,\napi_key=api_key\n)`\n\n除了上述介绍的Memory之外，LangChain还提供了一下其他的Memory：\n\n6、ConversationEntityMemory：一种基于实体的对话记忆机制，它能够智能地识别、存储和利用对话中出现的实体信息（如人名、地点、产品等）及其属性/关系，并结构化存储，使 AI 具备更强的上下文理解和记忆能力，能够解决信息过载问题。\n\n7、ConversationKGMemory： 一种基于知识图谱的先进记忆组件，它将对话内容组织成结构化的知识图谱，实现更加语义化和关联性的记忆管理。\n\n8、VectorStoreRetrieverMemory：一种基于向量数据库的先进记忆组件，它利用语义相似度检索技术，从大量历史对话中智能召回与当前对话最相关的记忆片段。\n\n### 6、LangChain核心组件之Tools\n\n##### 6.1 Tools概述\n\nTools是大模型、智能体（Agent）与外部世界进行交互的核心组件，本质上是封装了一些特定功能的可调用的函数（数学计算、获取时间、搜索等）， 允许大模型与外部系统、API、数据源和工具进行交互，其核心价值在于极大地扩展了 LLM 应用的能力边界（动作）。\n\n![](https://i-blog.csdnimg.cn/img_convert/634f5b93bdbd17cbe6ae298aee6d7a24.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/634f5b93bdbd17cbe6ae298aee6d7a24.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/df0a32d8dc494293bcce7afed91c63f0.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/df0a32d8dc494293bcce7afed91c63f0.jpeg)\n\n##### 6.2 Tools组件使用\n\nTool 通常包含如下几个要素：\n\n使用流程：\n\n![](https://i-blog.csdnimg.cn/img_convert/aaf0695a887613038d06cb87e0975cd7.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/aaf0695a887613038d06cb87e0975cd7.jpeg)\n\nSTEP1-工具创建：使用@tool注解创建工具。\n\nSTEP2-工具绑定：将创建的工具绑定到Agent上（可以绑定多个），包括工具的名称、描述、参数、返回等，让Agent知道有哪些工具可用。\n\nSTEP3-工具调用：模型返回调用具体的工具后，Agent根据该工具的参数描述构造参数，并发起调用\n\nSTEP4-工具执行：执行工具的具体逻辑，并返回结果。\n\n两种自定义工具的方式：\n\n方式一：@tool装饰器\n\n`@tool(\n# 指定工具的名称，这是 Agent 识别和调用工具时使用的标识符。\n# 默认值：如果不指定，默认使用函数名作为工具名称。\nname_or_callable="multiply", #\n# 用于告诉 Agent 这个工具的功能和用途。这对 Agent 选择合适的工具至关重要。\n# 默认值：如果不指定，会尝试使用函数的文档字符串（docstring）作为描述。如果文档字符串也没有，则为空字符串。\ndescription="Multiply two numbers",\n# 控制工具执行结果的返回方式\n# True：工具的输出直接作为 Agent 的最终回答返回给用户\n# False：工具的输出会传递给 Agent，由 Agent 进一步处理或与其他信息结合后再回答\nreturn_direct=True\n)\ndef multiply(a: int, b: int) -> int:\n"""Multiply a and b.""" # 如果不指定description，这会成为工具描述\nreturn a * b\nresponse = multiply.invoke({"a": 2, "b": 3})\nprint(response)`\n\n方式二：StructuredTool的from\\_function()\n\n`multiply = StructuredTool.from_function(\n# 绑定函数\nfunc=multiply,\n# 指定工具的名称，这是 Agent 识别和调用工具时使用的标识符。\nname="multiply",\n# 用于告诉 Agent 这个工具的功能和用途。这对 Agent 选择合适的工具至关重要。\ndescription="Multiply two numbers"\n)\nresponse = multiply.invoke({"a": 2, "b": 3})\nprint(response)`\n\n结合大模型使用：\n\n注意：tool一般与agent一起配合使用，agent在下一章详细介绍\n\n`# 将函数封装为LangChain工具对象\nstock_tool = Tool(\nname="getStockPrice", # 工具名称（模型将使用此名称调用工具）\nfunc=getStockPrice, # 工具函数\ndescription="用于查询公司股票价格。输入应该是公司名称（如：腾讯）"\n# 工具描述（模型根据此决定是否调用）\n)\n# 创建工具列表（Agent可以使用的所有工具）\ntools = [stock_tool]\n# 将LangChain工具转换为OpenAI函数调用格式\nfunctools = [convert_to_openai_tool(tool) for tool in tools]\n# 从LangChain Hub加载预定义的提示模板\n# \'hwchase17/structured-chat-agent\'是一个专门为结构化聊天Agent设计的提示模板\nprompt = hub.pull(\'hwchase17/structured-chat-agent\')\n# 创建结构化聊天Agent，# 参数：模型对象、工具列表、提示模板\nagent = create_structured_chat_agent(chat_model, tools, prompt)\n# 创建Agent执行器\nagent_executor = AgentExecutor(\nagent=agent, # 配置好的Agent\ntools=tools, # Agent可用的工具列表\nverbose=True, # 开启详细日志（显示Agent思考过程）\nhandle_parsing_errors=True # 处理解析错误（防止因格式问题崩溃）\n)\n# 执行Agent查询\nresponse = agent_executor.invoke({"input": "查询腾讯当日的股票价格"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/9efdc5d72dac7456f360d085c8edc577.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/9efdc5d72dac7456f360d085c8edc577.jpeg)\n\n注意：实际使用过程中发现，有时候并没有调用自定义的工具，可能原因是：\n\n1、大模型认为这个计算太简单（1+1），无需调用工具。\n\n2、工具的描述不清楚，大模型无法推断出使用这个工具。\n\n3、有些模型对于工具调用支持度不高，如DeepSeek-R1。\n\n具体可通过修改工具描述、提示词或换一个模型等引导模型决定调用自定义工具。\n\n##### 6.3 MCP Server\n\nAgent tools可以看做是实现在AI Agent应用中的一系列函数，但是很多Tool 的功能比较通用，如浏览网页，发送消息，天气查询等，所以将通用的工具封装成一个单独的服务，就可以供不同的Agent使用了，这个单独的服务叫MCP Server，其中MCP是一个通讯协议，用来规范Agent 和MCP Server之间是怎么交互的，如工具的功能，描述，参数等。MCP Server可以与Agent部署在同一台机器上通过标准输入输出通讯，也可以部署在网络上通过http协议通讯。虽然MCP是为了大模型而制定的标准，但实际上MCP本身和大模型没有关系，它并不关心Agent使用哪个模型，MCP只负责帮Agent管理工具、资源和提示词。\n\nLangChain中的Tool 和 MCP Server比较：\n\n|  |  |  |\n| --- | --- | --- |\n| 对比维度 | 内置Tools | MCP Server |\n| 部署位置 | Agent 内部（同一进程） | 独立服务（独立进程/网络） |\n| 代码耦合 | 紧耦合（直接引用） | 松耦合（协议通信） |\n| 复用性 | 仅当前 Agent 可用 | 多个 Agent 可共享 |\n| 更新维护 | 修改需重新编译 Agent | 修改需重新编译 Agent 独立更新 |\n| 性能 | 本地调用，极快 | 需要网络/IPC通信 |\n| 适用场景 | 简单、专用工具 | 通用、复杂工具 |\n\n### 7、LangChain核心组件之Agent\n\n##### 7.1 Agent（智能体）概述\n\n![](https://i-blog.csdnimg.cn/img_convert/0076b76de7921ccb1d65b4a41f889824.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/0076b76de7921ccb1d65b4a41f889824.jpeg)\n\nAgent（智能体）是一个通过动态协调大模型（LLM）和 工具（Tools）来完成复杂任务的智能系统（思考、分析、拆解任务、逐步实现）。它让大模型充当"决策大脑"，根据用户输入自主选择和执行工具（如搜索、计算、数据库查询等），最终生成精准的响应。2025年也被称为Agent元年，标志着人工智能正式从“思考与对话” 转向 “自主决策与行动”。\n\n一个Agent应该具备以下核心能力：\n\n![](https://i-blog.csdnimg.cn/img_convert/b2e832e2300ab48abaa06454261bb92c.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/b2e832e2300ab48abaa06454261bb92c.jpeg)\n\n通用人工智能（AGI）将是AI的终极形态（这天是否会到来？不止是技术的突破，还有伦理、法律、社会认知等）。同样，构建智能体（Agent）则是AI工程应用当下的“终极形态”。\n\n![](https://i-blog.csdnimg.cn/img_convert/201c5556a4e3fb82c3d898dc3a20756b.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/201c5556a4e3fb82c3d898dc3a20756b.jpeg)\n\n##### 7.2 Agent Types（运行模式）\n\n在 LangChain 中，Agent是一种由大模型驱动的组件，能够根据用户的输入动态决定执行哪些操作（如调用工具、访问数据等）。不同的 Agent 类型对应不同的决策逻辑和策略，适用于不同的任务场景。\n\n1、Function Calling：是让LLM学会“使用工具”。预先定义好一系列函数（如get\\_weather， search\\_web），并明确描述它们的功能和参数。当用户提问时，将用户提问以及工具信息（工具描述、参数等关键信息）一起发送给大模型，大模型不直接生成答案，而是判断是否需要调用这些函数，以及如何调用，并将函数参数，函数名等信息以结构化的格式返回（如JSON格式）。\n\n`"""\nOpenAI函数调用Agent\n特点：1、使用OpenAI的函数调用功能，支持结构化工具调用 2、性能最佳，响应速度快，工具调用准确性高 3、支持并行工具调用，可同时执行多个工具 4、原生支持JSON格式的参数传递\n适用场景：1、需要高精度工具调用的应用 2、对响应速度有要求的生产环境 3、需要复杂参数传递的工具集成 4、推荐作为首选Agent类型\n"""\nAgentType.OPENAI_FUNCTIONS\n"""\nOpenAI多函数调用Agent - 高级功能\n特点：1、支持复杂的多步骤工具调用链 2、能够处理工具间的依赖关系 3、支持条件分支和循环调用 4、具备更强的推理和规划能力\n适用场景： 1、需要多步骤复杂任务处理 2、工具间存在依赖关系的场景 3、需要动态决策和分支处理 4、复杂的业务流程自动化\n"""\nAgentType.OPENAIMULTI_FUNCTIONS`\n\n2、ReAct模式（思考与行动）\n\n![](https://i-blog.csdnimg.cn/img_convert/b138f9dd5c54bc47fb1c1acf649ab5ef.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/b138f9dd5c54bc47fb1c1acf649ab5ef.jpeg)\n\n将复杂任务拆解成，Thought (推理) → Action (行动，即调用工具) → Observation (观察结果) → … → Final Answer（最终答案）的循环步骤：\n\nReAct的工作原理：大模型本身不具备此流程（Thought-Action-Observation），实际是根据预先设定好的系统提示词来执行上述步骤的，如下是一个ReAct的系统提示词（hwchase17/react）：\n\n![](https://i-blog.csdnimg.cn/img_convert/0c262fb7e0e15569dc84df2a48945857.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/0c262fb7e0e15569dc84df2a48945857.jpeg)\n\nLangChain中ReAct的类型：\n\n`"""\n零样本ReAct描述Agent\n特点：1、基于ReAct（Reasoning + Acting）模式 2、通过"思考-行动-观察"的循环进行推理 3、不需要示例，完全依赖工具描述 4、具有良好的可解释性和透明度\n适用场景：1、需要清晰推理过程的应用 2、工具描述详细且准确的场景 3、对可解释性有要求的业务场景 4、适合调试和问题排查\n"""\nAgentType.ZERO_SHOT_REACT_DESCRIPTION\n"""\n结构化聊天零样本ReAct Agent\n特点：1、结合了结构化输出和ReAct推理模式 2、支持更复杂的工具参数传递 3、具备更好的多轮对话能力 4、输出格式更加规范和可解析\n适用场景：1、需要结构化输出的聊天应用 2、复杂参数的工具调用场景 3、多轮对话中的工具使用 4、需要格式化响应的业务场景\n"""\nAgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION\n"""\n对话式ReAct Agent\n特点：1、具备对话记忆能力，能记住历史交互 2、基于ReAct模式进行推理和行动 3、支持上下文相关的工具调用 4、适合长期对话和任务跟踪\n适用场景：1、需要维护对话状态的应用 2、长期任务跟踪和管理 3、个性化服务和推荐 4、客户服务和技术支持场景\n"""\nAgentType.CONVERSATIONAL_REACT_DESCRIPTION`\n\n##### 7.3 ReAct Agent 结合大模型使用\n\n`# 创建Tavily搜索工具实例，用于为Agent提供实时网络搜索能力\n# 需要在https://tavily.com/ 申请API key 才能使用\nsearch_tool = TavilySearchResults(\nmax_results=3,\ndescription="用于搜索最新网页信息、新闻和历史数据。输入应该是明确的搜索查询。"\n)\n# 从LangChain Hub拉取预定义的ReAct提示词模板\nprompt = hub.pull("hwchase17/react")\n# 创建ReAct Agent实例\nagent = create_react_agent(\nllm=chat_model,\nprompt=prompt,\ntools=[search_tool]\n)\n# 创建Agent执行器\nagent_executor = AgentExecutor(\nagent=agent,\nhandle_parsing_errors=True, # 自动处理解析错误，提高稳定性\nverbose=True, # 开启详细日志，显示推理过程\ntools=[search_tool] # 工具列表，必须与Agent中的工具保持一致\n)\n# 执行Agent任务\nresponse = agent_executor.invoke( {"input": "2021年2月5日腾讯收盘价是多少？"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/91685ca8612c090f3372367c0513a0f3.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/91685ca8612c090f3372367c0513a0f3.jpeg)\n\n##### 7.4 FUNCTION\\_CALL 结合大模型、Memory 使用\n\n`# 创建Tavily搜索工具实例\nsearch_tool = TavilySearchResults(\nmax_results=3, # 限制搜索结果数量，平衡信息完整性和处理效率\ndescription="用于搜索最新网页信息、新闻和历史数据。输入应该是明确的搜索查询。"\n)\n# 定义工具列表，可以添加多个\ntools = [search_tool]\n# 创建提示词模板\nprompt = ChatPromptTemplate.from_messages([\n("system", "你是一个人工智能小助手，可以回答问题并使用工具。"),\n("placeholder", "{chat_history}"),\n("human", "{input}"),\n("placeholder", "{agent_scratchpad}")\n])\n# 创建对话缓冲记忆实例\nmemory = ConversationBufferMemory(\nmemory_key="chat_history",\nreturn_messages=True\n)\n# 创建工具调用Agent实例\nagent = create_tool_calling_agent(chat_model, tools, prompt)\n# 创建Agent执行器\nagent_executor = AgentExecutor(\nagent=agent,\ntools=tools,\nmemory=memory,\nhandle_parsing_errors=True,\nverbose=True\n)\nresponse = agent_executor.invoke({"input": "2021年2月5日腾讯收盘价是多少？"})\nprint(response)\nresponse = agent_executor.invoke({"input": "阿里呢？"})\n# 嵌入Memory，可以推断出问的股价，\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/5baee6c6032baf33034414c50e5b4966.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/5baee6c6032baf33034414c50e5b4966.jpeg)\n\n### 8、LangChain核心组件之Retrieval\n\n##### 8.1 Retrieval（检索）概述\n\nRetrieval是用于从大量的文档或数据源中查找相关信息的核心模块，它是构建RAG（检索增强生成）的基础，能够让大模型访问外部知识源，解决模型本身的知识局限性和时效性问题。\n\n##### 8.2 大模型幻觉\n\n我们知道大模型有两个主要的特点：\n\n虽然记忆机制扩展了AI工程的应用场景，但大模型在专业领域仍面临显著挑战，由于无法掌握全部专业知识，大模型在回答专业问题时可能生成不准确甚至完全错误的内容，这个现象被称为“幻觉”。尤其在金融、医疗等高要求领域，一次错误的金额评估或医疗诊断失误都是致命的，对于非专业人士来说可能难以辨识。当前还没彻底解决这个问题的方案，不过大家普遍达成共识的一个方案：\n\n##### 8.3 RAG解决方案\n\n在利用大模型处理特定领域的大规模知识问答时，除了微调模型之外，检索增强生成（RAG）是一个有效的缓解大模型幻觉问题的解决方案。RAG通过引入外部知识检索机制，在生成前为模型提供相关的实时、专有信息作为上下文，从而直接应对其固有的“幻觉”问题和知识更新瓶颈。\n\nRAG流程：\n\n![](https://i-blog.csdnimg.cn/img_convert/8707e8cc032cbf9bb4571059cd73f517.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/8707e8cc032cbf9bb4571059cd73f517.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/253ddef4f08743d78c6db34ba7b1f85b.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/253ddef4f08743d78c6db34ba7b1f85b.jpeg)\n\n1、文件解析：解析各种格式的文件并提取出文字。\n\n2、文件切割：把长文本切割成更小的、有逻辑的片段。\n\n3、向量化：将文字片段转换为高纬空间中的向量数字。\n\n4、知识入库：将这些向量数字存进向量数据库中\n\n5、用户提问：用户发起提问\n\n6、检索：基于各种算法（余弦相似度、欧氏距离、点积等）去向量数据库里快速找出和问题最相关的几个文本片段。\n\n7、知识重排序：对找出的片段进行梳理排序，找出相似度最高的。\n\n8、增强：把选好的知识片段和用户的问题打包在一起交给大模型。\n\n9、生成：大模型生成一个准确且相关的回答。\n\n其中第678是RAG步骤中的检索、增强、生成。这里有三个位置涉及到大模型的使用：\n\n第3步：向量化，需要使用EmbeddingModels。\n\n第7步：重排序，需要使用RerankModels（追求回答高精度和高相关性的场景）。\n\n第9步：生成答案，需要使用LLM。\n\nRAG的优点\n\nRAG的缺点\n\n##### 8.4 Retrieval流程\n\n![](https://i-blog.csdnimg.cn/img_convert/42a1c09c1c60278f2e328c38c96612c8.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/42a1c09c1c60278f2e328c38c96612c8.jpeg)\n\n阶段一：Source（数据源），外部知识库，包含各种类型、格式的文件，如图片、视频、网站等\n\n阶段二：Load（加载），将外部知识库加载到内存中并转换成文档(Document)对象。包含内容和元数据等相关信息。\n\n阶段三：Transform（转换），将文档对象转换为更适合检索和生成的表达形式。包括文本分块、清理冗余信息、关键信息提取等，旨在提升后续处理的效率与质量\n\n阶段四：Embed（嵌入），通过嵌入模型将文本转换为高纬度空间中的数值向量，使得计算机能够理解和处理语义信息，文本可用于向量空间中的各种运算，大大拓展了文本分析的可能性，是自然语言处理领域非常重要的技术。\n\n![](https://i-blog.csdnimg.cn/img_convert/e33c4aa5b55684238c0da726cf9e12c0.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/e33c4aa5b55684238c0da726cf9e12c0.jpeg)\n\n文本嵌入为 LangChain 中的问答、检索、推荐等功能提供了重要支持。具体为：\n\n阶段五：Store（存储），将转换后的向量存储在向量数据库中，避免需要时重新计算。\n\n![](https://i-blog.csdnimg.cn/img_convert/cde64acc5653bc5db6429c3dfb5bba4a.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/cde64acc5653bc5db6429c3dfb5bba4a.jpeg)\n\n##### 8.5 Retrieval组件使用\n\n1、Document Loaders（文档加载器）\n\n`# 加载txt文件\ntext_loader = TextLoader("./risk.txt")\ndocs = text_loader.load()\n# print(docs)\n# 加载pdf文件\npdf_loader = PyPDFLoader(file_path="./risk.pdf")\ndocs = pdf_loader.load()\nprint(docs)\n# 加载csv文件\ncsv_loader = CSVLoader(file_path="./risk.csv")\ndocs = csv_loader.load()\nprint(docs)\n#加载json文件\njson_loader = JSONLoader(file_path="./risk.json")\ndocs = json_loader.load()\nprint(docs)`\n\nDocumment对象中有两个重要的属性：\n\n2、Text Splitters（文本拆分器）\n\n![](https://i-blog.csdnimg.cn/img_convert/ea51d3ea5edd29022176393ad2de88a4.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/ea51d3ea5edd29022176393ad2de88a4.jpeg)\n\n文本拆分器是将长文档拆分为语义连贯、大小适中的小片段，主要是解决大模型的上下文窗口限制，并提升检索的准确性和生成内容的质量。它的工作原理通常遵循“先细拆后合并”的策略：首先将文本分割成小句子，然后按顺序将这些小句子合并成较大的块，直到达到设定的块大小限制。在创建新块时，会与上一个块保留部分重叠，以确保上下文连贯。\n\n为什么需要分隔？\n\n基于此，一个有效的解决方案就是将完整的Document对象进行分块处理（Chunking) 。无论是在存储还是检索过程中，都将以这些块(chunks) 为基本单位，这样有效地避免内容不相关性问题和超出最大输入限制的问题。\n\nChunking拆分的策略：\n\n`text_loader = TextLoader("./risk.txt")\ndocs = text_loader.load()\ntext_splitter = CharacterTextSplitter(\n# 文本块大小：每个分割块的最大字符数，1000字符通常包含150-200个中文词汇，适合大多数LLM的上下文窗口处理\nchunk_size=1000,\n# 文本块重叠：相邻块之间的重叠字符数，设置为0表示无重叠，节省存储空间，通常设置为chunk_size的10-20%以保持上下文连续性\nchunk_overlap=0,\n# 长度计算函数：用于计算文本长度的函数，len()函数按字符计数，适合中英文混合文本，也可以使用token计数函数获得更精确的控制\nlength_function=len,\n# 分割符：优先按换行符分割文本，保持段落结构的完整性，避免句子被截断\nseparator="\\n"\n)\ntexts = text_splitter.split_text(docs[0].page_content)\nprint(texts)`\n\n除了CharacterTextSplitter，LangChain还提供了很多拆分器，如：RecursiveCharacterTextSplitter、TokenTextSplitter、CharacterTextSplitter、SemanticChunker、HTMLHeaderTextSplitter等。具体使用可参考官方文档：https://python.langchain.com.cn/docs/modules/data\\_connection/document\\_transformers/\n\n3、Text Embedding Models（文档嵌入模型）\n\n将文本转换为数值向量\n\n![](https://i-blog.csdnimg.cn/img_convert/23f7974f3ad4c795e78fde1bcd38b0ca.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/23f7974f3ad4c795e78fde1bcd38b0ca.jpeg)\n`embeddings_model = OllamaEmbeddings(\nmodel="nomic-embed-text",\nbase_url="http://127.0.0.1:11434",\n)\ntext = "Hello World"\n# 句子向量化\nvector = embeddings_model.embed_query(text=text)\nprint(f"嵌入向量长度: {len(vector)}")\nprint(f"前20个值: {vector[:20]}")\nprint("=======================================")\ntexts = ["Hello World", "Today is a sunny day", "No news is good news"]\n# 文档向量化\nvector = embeddings_model.embed_documents(texts)\nfor v in vector:\nprint(f"前20个值: {v[:20]}")`\n\n![](https://i-blog.csdnimg.cn/img_convert/3634150c2083a3f1693f4fe2da191267.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/3634150c2083a3f1693f4fe2da191267.jpeg)\n\n4、Vector Stores（向量存储）\n\n![](https://i-blog.csdnimg.cn/img_convert/9e704a80b66b37c775bf54727fc6f4ff.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/9e704a80b66b37c775bf54727fc6f4ff.jpeg)\n\n将文本向量化之后，下一步就是进行向量的存储。这里有两部分：\n\nLangChain提供了50多种不同的向量数据库，参考文档：向量存储\n\nhttps://docs.langchain.com/oss/python/langchain/overview\n\n`# 加载txt文件\ntext_loader = TextLoader("./risk.txt", encoding="utf-8")\ndocs = text_loader.load()\n# 文本分割\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntext_docs = text_splitter.split_documents(docs)\n# 向量存储，默认存储在内存中， 可通过persistent_directory参数指定存储磁盘路径\nvectorstore = Chroma.from_documents(text_docs, embeddings_model, persistent_directory=\'./chroma_db\')\n# 相似度搜索，除了similarity_search外，\n# 1、直接对问题向量查询（similarity_search_by_vector）\n# 2、通过L2距离分数进行搜索（similarity_search_with_score）\n# 3、通过余弦相似度分数进行搜索（similarity_search_with_relevance_scores）\n# 4、MMR（最大边际相关性，max_marginal_relevance_search）\nresponse = vectorstore.similarity_search("什么是反洗钱？")\nprint(response)`\n\n5、Retrievers（检索器）\n\n![](https://i-blog.csdnimg.cn/img_convert/8f02d3601dd4e47dd8c17183572f0577.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/8f02d3601dd4e47dd8c17183572f0577.jpeg)\n\n向量数据库提供了核心的相似性计算能力，其内置函数（如余弦相似度，欧式距离，点积等）可直接用于实现基础的向量召回。LangChain还提供了 更加复杂的召回策略 ，这些策略被集成在Retrievers（检索器）组件中。检索器本身不存储数据，而是通过查询向量数据库，并集成重排序、多路检索等高级逻辑，最终返回相关的文档片段。\n\n`# # 加载txt文件\ntext_loader = TextLoader("./risk.txt", encoding="utf-8")\ndocs = text_loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntext_docs = text_splitter.split_documents(docs)\n# 向量存储，默认存储在内存中， 可通过persistent_directory参数指定存储磁盘路径\nvectorstore = Chroma.from_documents(docs, embeddings_model, persistent_directory=\'./chroma_db\')\n# 创建检索器\nretriever = vectorstore.as_retriever(\n# 搜索参数，k表示返回的文档数量，score_threshold表示相似度阈值\nsearch_kwargs={"k": 2, "score_threshold": 0.5},\n# 搜索类型\nsearch_type="similarity_score_threshold"\n)\nchain = retriever | chat_model\nresponse = chain.invoke("什么是反洗钱？")\nprint(response)`\n\n### 9、再谈LangChain\n\n读到这想必你对LangChain有一个清晰的认识了，为了更形象地理解，如果将LLM比作人类的”大脑“，那么LangChain中的组件就像：\n\n整个系统的核心，负责思考、推理、理解和生成。就像人类的大脑，是智能的中枢。它接收来自各方的信息，进行处理，并做出决策或生成回应。\n\n存储海量的专业知识（公司文档、知识库等），并能在需要时快速、准确地检索相关信息提供给“大脑”。它是一个巨大的私人图书馆或长期记忆仓库，当你需要解决一个专业问题时，你会来图书馆查阅相关资料，然后将这些资料带给大脑（LLM）进行参考和分析。\n\n负责决策“如何”完成任务。它接收用户指令，进行规划，决定是直接由大脑（LLM）回答，还是需要调用各种工具（Tools），并按照什么顺序来执行。就像人体的神经系统或小脑。大脑（LLM）负责出主意，而Agent负责协调身体各部分去执行这个主意。例如，你想“拿一杯水”，大脑发出指令，神经系统（Agent）会规划并协调眼睛（观察）、手（抓取）等一系列动作。\n\n是Agent可以调用的具体功能，用于与外部世界交互。就像人的手、脚、眼睛和耳朵。\n\n将多个步骤（LLM调用、工具使用、数据处理）预先定义并链接在一起，形成一个可重复执行的固定流程。像是你学会的一种“技能”或“肌肉记忆”。例如，“泡咖啡”这个技能就是一个链：走到咖啡机前 -> 加咖啡粉 -> 按开关 -> 等待 -> 拿杯子。一旦学会，你就可以不假思索地完成。\n\n用于存储和回顾当前对话的历史信息，使AI能够拥有上下文感知能力，实现连贯的多轮对话。就像你的短期记忆。它让你记得在刚才的对话中对方说了什么，从而能做出相关的回应。没有记忆，每一次对话都是全新的、孤立的。\n\n预先设计好的、结构化的提示词，用于更有效、更稳定地向LLM提问。就像沟通技能、演讲技能，写作技能，都有一套固定的模版。\n\n通过这个比喻，我们可以清晰地看到：LLM是智能的核心（脑）、RAG是知识储备（图书馆）、Agents是协调指挥官（神经系统）、Tools是执行手段（手脚）、Chains是自动化技能（肌肉记忆）、Memory是上下文感知（短期记忆），它们各司其职，紧密协作，共同构成了一个能够理解、推理并作用于外部世界的智能体。\n\n至此，关于LangChain的组件使用就介绍完了，上述内容仅仅只是对LangChain使用的简单介绍以及一些大模型应用开发相关的概念，如果需要更深入的理解LangChain，可以参考官方文档。作为一个初学者，上述内容如果有理解不准确或错误的地方，欢迎指正。如果文章对你有一点点帮助，辛苦点个赞吧🫡\n\n### 如何学习大模型 AI ？\n\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n\n但是具体到个人，只能说是：\n\n**“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。**\n\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n\n**这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【`保证100%免费`】**\n\n`保证100%免费`\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/80dfd54ec491457faa956c46afad1163.png#pic_center)\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/80dfd54ec491457faa956c46afad1163.png#pic_center)\n\n### 为什么要学习大模型？\n\n我国在A大模型领域面临人才短缺,数量与质量均落后于发达国家。2023年，人才缺口已超百万，凸显培养不足。随着AI技术飞速发展，预计到2025年,这一缺口将急剧扩大至400万,严重制约我国AI产业的创新步伐。加强人才培养,优化教育体系,国际合作并进是破解困局、推动AI发展的关键。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6962caeebf3a4e9f94b631fc5da8b689.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6962caeebf3a4e9f94b631fc5da8b689.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/84d4fd89dc10476e9ef6c982793393b4.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/84d4fd89dc10476e9ef6c982793393b4.png)\n\n### 大模型入门到实战全套学习大礼包\n\n#### **1、大模型系统化学习路线**\n\n作为学习AI大模型技术的新手，方向至关重要。 正确的学习路线可以为你节省时间，少走弯路；方向不对，努力白费。这里我给大家准备了一份**最科学最系统的学习成长路线图和学习规划**，带你从零基础入门到精通！\n\n![img](https://i-blog.csdnimg.cn/direct/b3e31603ac324ad98ad7db90e2c1a3f4.jpeg#pic_center)\n\n![img](https://i-blog.csdnimg.cn/direct/b3e31603ac324ad98ad7db90e2c1a3f4.jpeg#pic_center)\n\n#### 2、大模型学习书籍&文档\n\n学习AI大模型离不开书籍文档，我精选了一系列大模型技术的书籍和学习文档（电子版），它们由**领域内的顶尖专家撰写**，内容全面、深入、详尽，为你学习大模型提供坚实的理论基础。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5b97585640c44afe82d295f398bce6cc.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5b97585640c44afe82d295f398bce6cc.png)\n\n#### 3、**AI大模型最新行业报告**\n\n2025最新行业报告，针对**不同行业的现状、趋势、问题、机会**等进行系统地调研和评估，以了解哪些行业更适合引入大模型的技术和应用，以及在哪些方面可以发挥大模型的优势。\n\n![img](https://i-blog.csdnimg.cn/img_convert/321829d5cb17558fa20823004e2878bb.gif)\n\n![img](https://i-blog.csdnimg.cn/img_convert/321829d5cb17558fa20823004e2878bb.gif)\n\n#### 4、**大模型项目实战&配套源码**\n\n**学以致用**，在**项目实战中检验和巩固你所学到的知识**，同时为你找工作就业和职业发展打下坚实的基础。\n\n![img](https://i-blog.csdnimg.cn/img_convert/91d8dc1a6f2e7231de586317805af9aa.gif)\n\n![img](https://i-blog.csdnimg.cn/img_convert/91d8dc1a6f2e7231de586317805af9aa.gif)\n\n#### 5、**大模型大厂面试真题**\n\n面试不仅是技术的较量，更需要充分的准备。在你已经掌握了大模型技术之后，就需要开始准备面试，我精心整理了一份大模型面试题库，**涵盖当前面试中可能遇到的各种技术问题，让你在面试中游刃有余**。\n\n![img](https://i-blog.csdnimg.cn/img_convert/8cd3ce556cb620097c74de0e4330561d.gif)\n\n![img](https://i-blog.csdnimg.cn/img_convert/8cd3ce556cb620097c74de0e4330561d.gif)\n\n##### 适用人群\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e1c768ed14b945499146a0d0f6e05e8d.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e1c768ed14b945499146a0d0f6e05e8d.png)\n\n##### 第一阶段（10天）：初阶应用\n\n该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。\n\n##### 第二阶段（30天）：高阶应用\n\n该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。\n\n##### 第三阶段（30天）：模型训练\n\n恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。\n\n到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？\n\n##### 第四阶段（20天）：商业闭环\n\n对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。\n\n学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。\n\n如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。\n\n###### 这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【`保证100%免费`】\n\n`保证100%免费`\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n![Logo](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\nDAMO开发者矩阵，由阿里巴巴达摩院和中国互联网协会联合发起，致力于探讨最前沿的技术趋势与应用成果，搭建高质量的交流与分享平台，推动技术创新与产业应用链接，围绕“人工智能与新型计算”构建开放共享的开发者生态。\n\n更多推荐\n\n![cover](https://i-blog.csdnimg.cn/direct/9da7c9d3ff3a4cb3bc3c97fe2a7f5fe0.png)\n\n微信社群机器人搭建 教程/开发\n\n![avatar](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\n一体双生: 计算机图形学与计算机视觉本就“同宗同源”\n\n当我们站在现在回望，计算机图形学和计算机视觉的分野，更多是受限于早期算力和算法的无奈之举。算力不足时，CG 只能用光栅化骗过眼睛，CV 只能用边缘检测提取特征。算力充裕时，CG 开始用光线追踪模拟物理，CV 开始用 Transformer 理解全局。如今，随着3D AIGCXR（空间计算）和具身智能（Embodied AI）的兴起，两者正在回归它们的共同本质——对视觉信息的全链路处理。未来的工程师\n\n![avatar](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\n改进型深度Q-网格DQN和蒙特卡洛树搜索MCTS以及模型预测控制MPC强化学习的机器人室内导航仿真\n\n本文摘要： 本研究实现了一个基于TurtleBot3机器人的自主导航系统，包含以下核心技术：1) 通过Gazebo仿真环境构建SLAM地图；2) 采用改进的蒙特卡洛树搜索(MCTS)算法进行路径规划，结合距离启发函数提升搜索效率；3) 设计分层MPC-PID控制器实现路径跟踪；4) 开发一键启动脚本集成整个系统。创新点包括：基于轮廓分析的地图优化、DQN引导的MCTS搜索、安全势场规划以及分层运动\n\n![avatar](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n![浏览量](https://csdnimg.cn/release/devpress/public/img/watch.a5bd9e9b.svg)\n![点赞](https://csdnimg.cn/release/devpress/public/img/thumb.a0b81433.svg)\n![收藏](https://csdnimg.cn/release/devpress/public/img/mark.f1a889ab.svg)\n![](https://csdnimg.cn/release/devpress/public/img/share.f1fdda75.svg)\n\n扫一扫分享内容\n\n![]()\n![](https://csdnimg.cn/release/devpress/public/img/share.f1fdda75.svg)\n\n### 所有评论(0)\n\n![]()![](https://profile-avatar.csdnimg.cn/eeb633f233d641ef859131b4ee5aec84_m0_57081622.jpg!1)\n\n### [程序媛饺子](https://devpress.csdn.net/user/m0_57081622)\n\n![](https://csdnimg.cn/release/devpress/public/img/devote.fe704c8a.svg)\n![](https://csdnimg.cn/release/devpress/public/img/top.c3a2945a.svg)\n![]()![logo](https://csdnimg.cn/release/devpress/public/img/csdn-logo.07312d72.png)\n![logo](https://csdnimg.cn/release/devpress/public/img/csdn-logo.07312d72.png)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://damodev.csdn.net/69251f44791c233193d00f40.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9998832, 'save_path': None}}, {'paper_id': '', 'title': '内存记忆( Memory ) - LangChain 中文文档', 'authors': [], 'abstract': '![10000 AI开发者社群](https://www.aiqbh.com/qun.png)\n\n# 内存记忆 ( Memory )\n\n![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif "LangChain中文网")\n\n![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif "LangChain中文网")\n\n默认情况下，链式模型和代理模型都是无状态的，这意味着它们将每个传入的查询独立处理（就像底层的 LLMs 和聊天模型本身一样）。在某些应用程序中，比如聊天机器人，记住先前的交互是至关重要的。无论是短期还是长期，都要记住先前的交互。**Memory** 类正是做到了这一点。\nLangChain 提供了两种形式的记忆组件。首先，LangChain 提供了用于管理和操作以前的聊天消息的辅助工具。这些工具被设计成模块化的，无论如何使用都很有用。其次，LangChain 提供了将这些工具轻松整合到链式模型中的方法。\n\n## 入门[\u200b](#入门 "Direct link to 入门")\n\n记忆涉及在用户与语言模型的交互过程中始终保留状态的概念。用户与语言模型的交互被捕获在 ChatMessages 的概念中，因此这归结为在一系列聊天消息中摄取、捕获、转换和提取知识。有许多不同的方法可以做到这一点，每种方法都作为自己的记忆类型存在。\n通常情况下，对于每种类型的记忆，有两种理解和使用记忆的方式。一种是独立的函数，从一系列消息中提取信息，然后是您可以在链式模型中使用此类型的记忆的方式。\n记忆可以返回多个信息片段（例如，最近的 N 条消息和所有先前消息的摘要）。返回的信息可以是字符串或消息列表。\n\n我们将介绍最简单的存储形式：“缓冲”存储，它只涉及保留所有先前的消息的缓冲区。我们将展示如何在这里使用模块化实用函数，然后展示它如何在链中使用（返回字符串以及消息列表）。\n\n## 聊天消息历史 (ChatMessageHistory)[\u200b](#聊天消息历史-chatmessagehistory "Direct link to 聊天消息历史 (ChatMessageHistory)")\n\n大多数（如果不是全部）内存模块的核心实用类之一是 `ChatMessageHistory` 类。这是一个超轻量级的包装器，它公开了方便的方法来保存人类消息、AI 消息，然后获取它们全部。\n\n`ChatMessageHistory`\n\n如果您在链外管理内存，可能需要直接使用此类。\n\n`from langchain.memory import ChatMessageHistory  \n  \nhistory = ChatMessageHistory()  \n  \nhistory.add_user_message("hi!")  \n  \nhistory.add_ai_message("whats up?")`\n`history.messages`\n `[HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]`\n\n## ConversationBufferMemory[\u200b](#conversationbuffermemory "Direct link to ConversationBufferMemory")\n\n现在我们展示如何在链中使用这个简单的概念。我们首先展示 `ConversationBufferMemory`，它只是 ChatMessageHistory 的一个包装器，可以提取变量中的消息。\n\n`ConversationBufferMemory`\n\n我们可以首先将其提取为字符串。\n\n`from langchain.memory import ConversationBufferMemory`\n`memory = ConversationBufferMemory()  \nmemory.chat_memory.add_user_message("hi!")  \nmemory.chat_memory.add_ai_message("whats up?")`\n`memory.load_memory_variables({})`\n `{\'history\': \'Human: hi!\\nAI: whats up?\'}`\n\n我们还可以将历史记录作为消息列表获取\n\n`memory = ConversationBufferMemory(return_messages=True)  \nmemory.chat_memory.add_user_message("hi!")  \nmemory.chat_memory.add_ai_message("whats up?")`\n`memory.load_memory_variables({})`\n `{\'history\': [HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]}`\n\n## Using in a chain[\u200b](#using-in-a-chain "Direct link to Using in a chain")\n\nFinally, let\'s take a look at using this in a chain (setting `verbose=True` so we can see the prompt).\n\n`verbose=True`\n`from langchain.llms import OpenAI  \nfrom langchain.chains import ConversationChain  \n  \n  \nllm = OpenAI(temperature=0)  \nconversation = ConversationChain(  \n llm=llm,  \n verbose=True,  \n memory=ConversationBufferMemory()  \n)`\n`conversation.predict(input="Hi there!")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n  \n Human: Hi there!  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " Hi there! It\'s nice to meet you. How can I help you today?"`\n`conversation.predict(input="I\'m doing well! Just having a conversation with an AI.")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n Human: Hi there!  \n AI: Hi there! It\'s nice to meet you. How can I help you today?  \n Human: I\'m doing well! Just having a conversation with an AI.  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " That\'s great! It\'s always nice to have a conversation with someone new. What would you like to talk about?"`\n`conversation.predict(input="Tell me about yourself.")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n Human: Hi there!  \n AI: Hi there! It\'s nice to meet you. How can I help you today?  \n Human: I\'m doing well! Just having a conversation with an AI.  \n AI: That\'s great! It\'s always nice to have a conversation with someone new. What would you like to talk about?  \n Human: Tell me about yourself.  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " Sure! I\'m an AI created to help people with their everyday tasks. I\'m programmed to understand natural language and provide helpful information. I\'m also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers."`\n\n## 保存消息历史[\u200b](#保存消息历史 "Direct link to 保存消息历史")\n\n您经常需要保存消息，然后加载它们以便再次使用。这可以通过先将消息转换为普通的 Python 字典，保存这些字典（如 json 或其他格式），然后加载它们来轻松完成。以下是一个示例。\n\n`import json  \n  \nfrom langchain.memory import ChatMessageHistory  \nfrom langchain.schema import messages_from_dict, messages_to_dict  \n  \nhistory = ChatMessageHistory()  \n  \nhistory.add_user_message("hi!")  \n  \nhistory.add_ai_message("whats up?")`\n`dicts = messages_to_dict(history.messages)`\n`dicts`\n `[{\'type\': \'human\', \'data\': {\'content\': \'hi!\', \'additional_kwargs\': {}}},  \n {\'type\': \'ai\', \'data\': {\'content\': \'whats up?\', \'additional_kwargs\': {}}}]`\n`new_messages = messages_from_dict(dicts)`\n`new_messages`\n `[HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]`\n\n这就是入门的全部内容！有许多不同类型的内存，请查看我们的示例以了解全部内容', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://python.langchain.com.cn/docs/modules/memory/', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99988127, 'save_path': None}}, {'paper_id': '', 'title': '【AI大模型应用开发】以LangChain为例：从短期记忆实战 - 53AI', 'authors': [], 'abstract': '免费POC， 零成本试错\n\n* 工作+AI   \n   大模型提升全员工作效率\n\n  业务+AI   \n   大模型掌握企业知识与流程\n\n  AIx业务   \n   大模型驱动产品智能化改造\n\n* [了解更多 >](/consulting.html)\n* [DeepSeek\n\n  AI场景共创与定制开发\n\n  了解更多 >](/fine-tuning.html)\n\n热门产品\n\n[53AI Brain\n\n让知识在人与AI之间高效流动](/products/53AIKM) [53AI Studio\n\n高准确率的企业级智能体开发平台](/products/53AIStudio) [53AI Hub开源\n\n三分钟搭建出独立的企业AI门户](/products/53AIHub) [53AI Browser\n\n“AI专家”效率倍增的秘密武器\n\n敬请期待...](javascript:;)\n\n[客户案例](/kehuanli.html)\n\n* 行业案例\n\n  [政府央国企   \n   政府央国企大模型落地应用案例](/kehuanli/hangyeanli#solution-230) [能源矿业   \n   新能源与矿业大模型落地应用案例](/kehuanli/hangyeanli#solution-231) [电子科技   \n   电子科技行业大模型落地应用案例](/kehuanli/hangyeanli#solution-232) [贸易流通   \n   贸易流通大模型落地应用案例](/kehuanli/hangyeanli#solution-235) [制造行业   \n   高端制造行业大模型落地应用案例](/kehuanli/hangyeanli#solution-236) [企科数服   \n   企科数服行业大模型落地应用案例](/kehuanli/hangyeanli#solution-237) [生物医药   \n   生物医药行业大模型落地应用案例](/kehuanli/hangyeanli#solution-234) [地产与消费品   \n   地产与消费品行业大模型落地应用案例](/kehuanli/hangyeanli#solution-233)\n\n* 场景案例\n\n  [【智能问答】场景案例   \n   让大模型掌握企业的知识和流程](/kehuanli/solution#solution-148) [【应用智改】场景案例   \n   让大模型融入企业的产品和业务](/kehuanli/solution#solution-149) [【智能工单】场景案例   \n   让大模型创建和受理业务工单](/kehuanli/solution#solution-150) [【智能问数】场景案例   \n   与业务系统数据对话式互动](/kehuanli/solution#solution-151)\n\n[AI知识库](/news.html)\n\n企业AI落地知识库\n\n[前沿技术](/news/qianyanjishu)\n\n[大模型技术](/news/LargeLanguageModel) [多模态技术](/news/MultimodalLargeModel) [RAG技术](/news/RAG) [知识图谱](/news/knowledgegraph) [模型微调](/news/finetuning) [提示词框架](/news/tishicikuangjia) [提示词技巧](/news/tishicijiqiao) [开源大模型](/news/OpenSourceLLM) [智能硬件](/news/zhinengyingjian) [Palantir](/news/Palantir)\n\n[Agent框架](/news/agentplatform)\n\n[langchain](/news/langchain) [llamaindex](/news/llamaindex) [RAGFlow](/news/RAGFlow) [coze](/news/coze) [Dify](/news/dify) [Fastgpt](/news/fastgpt) [Bisheng](/news/Bisheng) [Qanything](/news/Qanything) [MaxKB](/news/MaxKB)\n\n[行业应用](/news/hangyeyingyong)\n\n[AI+汽车](/news/AIqiche) [AI+金融](/news/AIjinrong) [AI+工业](/news/AIgongye) [AI+培训](/news/AIpeixun) [AI+SaaS](/news/AISaaS) [AI+电商](/news/AIdianshang) [AI+医疗](/news/AIyiliao)\n\n[企业落地](/news/qiyejingying)\n\n[内容创作](/news/neirongchuangzuo) [个人提效](/news/gerentixiao) [智能客服](/news/zhinengkefu) [AI面试](/news/AImianshi) [数字员工](/news/shuziyuangong) [ChatBI](/news/zhinengbaobiao) [AI知识库](/news/zhishiguanli) [智能营销](/news/zhinengyingxiao) [智能化改造](/news/zhinenghuagaizao) [Glean](/news/Glean)\n\n[行业报告](/hangyebaogao.html)\n\n[研究报告](/hangyebaogao.html?report_type=研究报告) [行业报告](/hangyebaogao.html?report_type=行业报告) [技术分享](/hangyebaogao.html?report_type=技术分享) [专题报告](/hangyebaogao.html?report_type=专题报告) [课件讲义](/hangyebaogao.html?report_type=课件讲义)\n\n[关于我们](/about.html)\n\n[公司介绍](/about/introduction)  [渠道合作](/about/cooperation)\n\n[GitHub Star 7.5K+](https://github.com/53ai/53aihub)  [预约演示](/trial.html)\n\n* [首页](/)\n* [产品服务](javascript:)\n* [客户案例](javascript:)\n* [AI知识库](javascript:)\n* [关于我们](javascript:)\n\n热门场景\n\n工作+AI\n\n[工作对话](/product/gongzuoduihua) [内容创作](/product/neirongchuangzuo) [方案撰写](/product/zhinengwendang) [魔法菜单](/product/mofacaidan)\n\n业务+AI\n\n[微信分身](/product/weixinfenshen) [海外客服](/product/haiwaikefu) [官网客服](/product/guanwangkefu) [抖音客服](/product/douyinkefu) [数字老师](/product/shuzilaoshi) [数字督导](/product/shuzidudao) [智能服务台](/product/zhinengfuwutai)\n\nAIx业务\n\n[智能问数](/product/zhinengwenshu) [智能审核](/product/zhinengshenhe) [智能工单](/product/zhinenggongdan) [企微跟进助手](/product/qiweigenjinzhushou) [智能报价](/product/zhinengbaojia) [企微销售助手](/product/qiweixiaoshouzhushou) [应用智改](/product/zijianyingyong) [企微客服助手](/product/qiweikefuzhushou)\n\n[落地咨询](/consulting.html)\n\n[定制开发](/fine-tuning.html)\n\n热门产品\n\n[53AI Brain\n\n让知识在人与AI之间高效流动](/products/53AIKM) [53AI Studio\n\n高准确率的企业级智能体开发平台](/products/53AIStudio) [53AI Hub开源\n\n三分钟搭建出独立的企业AI门户](/products/53AIHub) [53AI Browser\n\n“AI专家”效率倍增的秘密武器\n\n敬请期待...](javascript:;)\n\n[行业案例](/kehuanli/hangyeanli) [场景案例](/kehuanli/solution)\n\n[前沿技术](/news/qianyanjishu) [Agent框架](/news/agentplatform) [行业应用](/news/hangyeyingyong) [企业落地](/news/qiyejingying)\n\n[公司介绍](/about/introduction) [渠道合作](/about/cooperation)\n\n53AI知识库\n\n学习大模型的前沿技术与行业应用场景\n\n[立即咨询](javascript:;) [预约演示](javascript:;)\n\n[首页](/)   [AI知识库](/news.html)   [前沿技术](/news/qianyanjishu)   [RAG技术](/news/RAG)\n\n我要投稿\n\n# 【AI大模型应用开发】以LangChain为例：从短期记忆实战，到如何让AI应用保持长期记忆的探索\n\n发布日期：2024-05-05 08:06:56 浏览次数： 5926\n\n作者：同学小张\n\n微信搜一搜，关注“同学小张”\n\n在AI应用中，无论是多轮对话场景、RAG场景还是AI Agent场景中，记忆能力都是不可或缺的一部分。然而，记忆能力是目前大模型的短板，所以，现在很多框架，诸如 LangChain、MetaGPT 等，都封装了自己的记忆模块，以方便开发者实现自己大模型应用的记忆功能。\n\n之前我们简单概览了一下 LangChain 的 Memory 模块，那只是在多轮对话场景中，简单的取最近几次的对话历史作为记忆。这是最简单的使用记忆的方法，也是短期记忆的一种。\n\n本文我们来系统看下实现大模型应用记忆的方法，包括短期记忆和长期记忆。还是以LangChain为例来进行实战。\n\n# 0. LangChain中 Memory 实战\n\n> 我这里将记忆简单理解为对话历史，查询历史等历史记录。\n\n## 0.1 记忆封装罗列\n\n在 LangChain 中提供了多种获取记忆的封装，例如`ConversationBufferMemory`、`ConversationBufferWindowMemory`、`ConversationTokenBufferMemory`等。\n\n简单罗列如下：\n\n* •\xa0`ConversationBufferMemory`可以理解为通用的将全部的历史记录取出来。\n* •\xa0`ConversationBufferWindowMemory`可以理解为滑动窗口，每次只取最近的K条记录。\n* •\xa0`ConversationTokenBufferMemory`可以理解为控制每次取的历史记录的Token数。\n* •\xa0`ConversationSummaryMemory`: 对上下文做摘要\n* •\xa0`ConversationSummaryBufferMemory`: 保存 Token 数限制内的上下文，对更早的做摘要\n* •\xa0`VectorStoreRetrieverMemory`: 将 Memory 存储在向量数据库中，根据用户输入检索回最相关的部分\n* •\xa0`ConversationEntityMemory`：保存一些实体信息，例如从输入中找出一个人名，保存这个人的信息。\n* •\xa0`ConversationKGMemory`：将历史记录按知识图谱的形式保存和查询\n\n> 这里面的大部分记忆封装，之前咱们已经学习过了，这里不再重复。详细的使用教程可以参考我之前的文章：[【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战+细节）](http://mp.weixin.qq.com/s?__biz=MzkxNjYyMjkwMQ==&mid=2247484716&idx=1&sn=8733d020d777fc61ca14b056dd7638e0&chksm=c14c5e76f63bd760613d245632d29a2f5e6a6531ae063b7bfceed561bf277d6f3f8b352aa3b8&scene=21#wechat_redirect)。\n\n下面看下\xa0`VectorStoreRetrieverMemory`\xa0的使用和实现效果。\n\n## 0.2 实践：VectorStoreRetrieverMemory的使用\n\n### 0.2.1 完整代码\n\n```\nfrom from \xa0langchain. memory\xa0 import import \xa0 VectorStoreRetrieverMemory from from \xa0langchain_openai\xa0 import import \xa0 ChatOpenAI from from \xa0langchain. embeddings. openai\xa0 import import \xa0 OpenAIEmbeddings from from \xa0langchain. vectorstores\xa0 import import \xa0 Chroma from from \xa0langchain. chains\xa0 import import \xa0 ConversationChain from from \xa0langchain. prompts\xa0 import import \xa0 PromptTemplate vectorstore\xa0 = \xa0 Chroma(embedding_function = OpenAIEmbeddings()) retriever\xa0 = \xa0vectorstore. as_retriever(search_kwargs = dict dict(k = 1 1)) memory\xa0 = \xa0 VectorStoreRetrieverMemory(retriever = retriever) memory. save_context({"input" "input": \xa0 "我喜欢学习" "我喜欢学习"}, \xa0{"output" "output": \xa0 "你真棒" "你真棒"}) memory. save_context({"input" "input": \xa0 "我不喜欢玩儿" "我不喜欢玩儿"}, \xa0{"output" "output": \xa0 "你可太棒了" "你可太棒了"}) PROMPT_TEMPLATE\xa0 = \xa0"""以下是人类和\xa0AI\xa0之间的友好对话。AI\xa0话语多且提供了许多来自其上下文的具体细节。如果\xa0AI\xa0不知道问题的答案，它会诚实地说不知道。以前对话的相关片段：{history}（如果不相关，你不需要使用这些信息）当前对话：人类：{input}AI：""" """以下是人类和\xa0AI\xa0之间的友好对话。AI\xa0话语多且提供了许多来自其上下文的具体细节。如果\xa0AI\xa0不知道问题的答案，它会诚实地说不知道。 以前对话的相关片段：{history} （如果不相关，你不需要使用这些信息） 当前对话：人类：{input} AI： """ prompt\xa0 = \xa0 PromptTemplate(input_variables =["history" "history", \xa0 "input" "input"], \xa0template = PROMPT_TEMPLATE) chat_model\xa0 = \xa0 ChatOpenAI() conversation_with_summary\xa0 = \xa0 ConversationChain(\xa0\xa0\xa0\xa0llm = chat_model, \xa0\xa0\xa0\xa0prompt = prompt, \xa0\xa0\xa0\xa0memory = memory, \xa0\xa0\xa0\xa0verbose = True True) print print(conversation_with_summary. predict(input input = "你好，我叫同学小张，你叫什么" "你好，我叫同学小张，你叫什么")) print print(conversation_with_summary. predict(input input = "我喜欢干什么？" "我喜欢干什么？"))\n```\n\n### 0.2.2 代码解释\n\n（1）代码中我们使用了\xa0`VectorStoreRetrieverMemory`\xa0作为记忆存储和获取的模块。它既然是向量存储和查询，所以接收参数：`retriever=retriever`，必须要穿给它一个向量数据库才能工作。\n\n（2）然后使用了\xa0`ConversationChain`\xa0作为对话的Chain。它接收一个\xa0`memory = memory`\xa0参数设置，指定使用的记忆类型。默认是最普通的\xa0`ConversationBufferMemory`\xa0类型。\n\n（3）什么时候会去检索记忆呢？在Chain运行 invoke 的一开始，就加载了。源码如下：\n\n可以看到，最后就是用用户的输入，去向量数据库中检索相关的片段作为需要的记忆。\n\n### 0.2.3 运行效果展示\n\n第一个问题，检索到的内容不相关，但是也得检索出一条。\n\n第二个问题，检索到的内容相关，用检索到的内容回答问题。\n\n# 1. 如何让AI应用具备长期记忆？\n\n> 我这里将“长期记忆”理解为持久化记忆或者长上下文记忆。也就是两种形式的记忆我都认为是“长期记忆”：\n>\n> * •\xa0第一种：持久化记忆，对话历史等历史记录持久化保存，不会随着进程的退出而消失。例如保存成功文件或存储进数据库等。\n> * •\xa0第二种：长上下文记忆，当历史记录特别多时，如何从历史记录中找出有用的记忆，而不是只关注最近的几条历史记录。\n\n## 1.1 LangChain 中的记忆模块是否具有长期记忆的能力？\n\n上面罗列的和实战的 LangChain 中的记忆模块，`ConversationBufferMemory`、\xa0`ConversationBufferWindowMemory`、`ConversationTokenBufferMemory`\xa0看起来都无法实现长期记忆的能力：无法持久化（看源码，底层都是一个List类型，保存到内存，随着进程消亡而消亡），也没法查询长的上下文。\n\n`ConversationSummaryMemory`、`ConversationSummaryBufferMemory`\xa0在一定程度上能提供更多的记忆信息（因为其对之前的历史记录做了总结压缩），所以在某些上下文不是特别长的场景中，还是可以用一用来实现简单的长期记忆能力的。\n\n`ConversationEntityMemory`、`ConversationKGMemory`一个只保存实体信息，一个将历史记录组织成知识图谱，会对长上下文场景中的长时记忆功能非常有用。它可以从全局的角度将用户提问中的实体或相关知识作补充，而不是关注最近的几次对话。\n\n`VectorStoreRetrieverMemory`应该是最好和最能实现长期记忆能力的类型了。一方面，它是向量数据库存储，可以方便的持久化数据，另一方面，它的向量检索能力，本来就是针对用户提问检索出最相关的文档片段，不受长上下文的窗口限制。但是其检索的相关片段之间是否存在信息缺失等，会影响长时记忆的准确性，从而影响最终的结果。\n\n> 所以，`ConversationEntityMemory`、`ConversationKGMemory`\xa0+\xa0`VectorStoreRetrieverMemory`\xa0是否可以一试？三者结合，保持相关片段的相关性，同时利用实体关系和知识图谱进行补充，是否可以更好地实现长时记忆的能力？感兴趣的可以一起讨论~\n\n## 1.2 关于让AI应用具备长期记忆的一些研究\n\n### 1.2.1 记忆思考：回忆和后思考使LLM具有长期记忆\n\n> 论文原文：Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory\n\n这篇文章提出了一种名为TiM（Think-in-Memory）的记忆机制，旨在使LLM在对话过程中保持记忆，存储历史思考。TiM包括两个关键阶段：在生成回复之前，LLM从记忆中回想相关思考；在生成回复之后，LLM进行后思考并将历史和新思考结合起来更新记忆。\n\n下图描述了TiM方法的使用方式：\n\n（1）在回答第二个问题时，需要考虑问题1的内容，从问题1中推理出答案，而后在回答问题2。 （2）在回答第三个问题时，需要同时考虑问题1和问题2，从问题1和问题2中推理出答案，而后再回答问题3。\n\n这就导致了问题的存在：问题1被推理了两遍，两遍的结果还可能不一样，导致最终的错误。\n\n而TiM的思路，是将每一个问题的思考也存起来，这样，在回答问题3时，可以使用问题2之前的思考，避免重新思考问题1，从而避免多次思考结果不一致导致的错误。\n\n具体步骤如下：\n\n总的原理是，将相关的记忆放到一起，例如上图中，关于book的谈话放到index 0中，关于moive的谈话放到index 1中。\n\n如何将相关内容放到一起的？论文中实现了一种基于局部敏感哈希（LSH）的存储系统，用于高效地存储和检索大规模的向量数据。LSH的作用是将每个向量映射到一个哈希索引，相似的向量有更高的概率被映射到相同的哈希索引。\n\n而相同的哈希索引可以将用户问题固定到某一块记忆中，然后只在这一块记忆中进行向量检索，大大提高了检索效率。\n\n> 这篇文章还是值得精读一下的，数据的组织方式和索引方式都比较高级，很有启发。\n\n### 1.2.2 递归总结在大型语言模型中实现长期对话记忆\n\n> 论文原文：Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models\n\n这篇文章提出了一种递归总结的方法，用于增强大模型的长期记忆能力，以解决在长对话中无法回忆过去信息和生成不一致响应的问题。该方法首先刺激LLM记忆小的对话上下文，然后递归地使用先前的记忆和后续的上下文生成新的记忆。\n\n其流程如下：\n\n简单概括，就是：上一轮的内容总结 + 本轮的问题回答 = 本轮的内容总结。本轮的内容总结 + 下轮的问题回答 = 下轮的内容总结。...... 不断迭代。与 LangChain中`ConversationSummaryMemory`\xa0的实现很类似。\n\n> 这种方法每一轮都要总结一次，也就是调用一次大模型，使用成本很高啊...... 实际生产中应该落地比较难。\n\n分享：\n\n53AI，企业落地大模型首选服务商\n\n**产品**：场景落地咨询+大模型应用平台+行业解决方案\n\n**承诺**：免费POC验证，效果达标后再合作。**零风险落地应用大模型**，已交付160+中大型企业\n\n[上一篇：RAGFlow：基于OCR和文档解析的下一代 RAG 引擎](/news/RAG/1740.html) [下一篇：RAGFlow（2）：集成深度文档理解能力的RAG引擎](/news/RAG/1629.html)\n\n[返回列表](/news/RAG)\n\n相关资讯\n\n[2026-01-21\n\nSentGraph：一句一句把多跳RAG“画”成图](/news/RAG/2026012179102.html) [2026-01-21\n\n增强型RAG还是Agentic RAG？一场关于检索增强生成系统的全面对比实验](/news/RAG/2026012107495.html) [2026-01-20\n\n别再用向量数据库给AI灌"迷魂汤"了](/news/RAG/2026012048936.html) [2026-01-20\n\nDSPy 3 + GEPA：迄今最先进的 RAG 框架——自动推理与提示](/news/RAG/2026012005394.html) [2026-01-20\n\nAnthropic一夜震撼升级：Claude获得「永久记忆」！全球打工人变天](/news/RAG/2026012063028.html) [2026-01-19\n\n为什么 RAG 越用越慢？如何反向调优？](/news/RAG/2026011935179.html) [2026-01-18\n\nRelink：动态构建查询导向的知识图谱推理框架，新一代 GraphRAG](/news/RAG/2026011805417.html) [2026-01-18\n\n【解密源码】WeKnora 文档切分与 Chunk 构建解析：腾讯生产级 RAG 的底层设计](/news/RAG/2026011846029.html)\n\n[联系获取](https://www.53ai.com/solution.html)\n\n[联系获取](https://www.53ai.com/solution.html)\n\n160+中大型企业正在使用53AI\n\n[立即咨询](javascript:;) [预约演示](javascript:;)\n\n[把握AI发展的机遇，共同探索、共同进步\n\n2025-01-22](/news/dongtai/2025012294502.html) [如何打造基于GenAI的员工服务机器人\n\n2025-01-22](/news/dongtai/2025012234192.html)\n\n热点资讯\n\n[RAG 深度解读：检索增强生成如何改变人工智能\n\n2025-12-04](/news/RAG/2025120493658.html) [RAGFlow 深度介绍\n\n2025-10-31](/news/RAG/2025103137046.html) [大模型生态的“不可能三角”：规模化应用的架构困境？\n\n2025-11-04](/news/RAG/2025110429108.html) [大模型RAG入门宝典｜从AI搜索到实战搭建，小白&程序员必收藏的检索增强指南\n\n2025-12-03](/news/RAG/2025120343879.html) [RAGFlow v0.22.0 发布：数据源同步、变量聚合、全新管理界面与多项重大更新\n\n2025-11-13](/news/RAG/2025111373489.html) [企业级 AI Agent规模化落地的避坑指南，就藏在这四大趋势里\n\n2025-12-02](/news/RAG/2025120251739.html) [5步构建企业级RAG应用：Dify与LangChain v1.0集成实战\n\n2025-11-13](/news/RAG/2025111342718.html) [从 RAG 到 Agentic RAG，再到 Agent Memory：AI 记忆的进化三部曲\n\n2025-11-05](/news/RAG/2025110552760.html) [RAG已经过时了？试试CAG，缓存增强生成技术实战大揭秘！\n\n2025-11-06](/news/RAG/2025110613465.html) [Embedding模型选型思路：相似度高不再代表检索准确（文末附实战指南）\n\n2025-12-07](/news/RAG/2025120709742.html)\n\n大家都在问\n\n[为什么 RAG 越用越慢？如何反向调优？\n\n2026-01-19](/news/RAG/2026011935179.html) [NotebookLM如何在48小时内分析2万份论文？\n\n2026-01-12](/news/RAG/2026011294378.html) [都有混合检索与智能路由了，谁还在给RAG赛博哭坟？\n\n2026-01-08](/news/RAG/2026010820813.html) [如何用NotebookLM，把枯燥的财报解读成精美的PPT？\n\n2026-01-02](/news/RAG/2026010291307.html) [为什么Claude Code不用RAG？](/news/RAG/2025122347285.html) [终于，NotebookLM 和 Gemini 合体了。这是什么神之更新？](/news/RAG/2025122170415.html) [Apple 入局 RAG：深度解析 CLaRa 框架，如何实现 128x 文档语义压缩？](/news/RAG/2025121083401.html)\n\n[内容创作](/news/neirongchuangzuo)   [大模型技术](/news/LargeLanguageModel)   [个人提效](/news/gerentixiao)   [langchain](/news/langchain)   [llamaindex](/news/llamaindex)   [多模态技术](/news/MultimodalLargeModel)   [RAG技术](/news/RAG)   [智能客服](/news/zhinengkefu)   [知识图谱](/news/knowledgegraph)   [模型微调](/news/finetuning)   [RAGFlow](/news/RAGFlow)   [coze](/news/coze)   [Dify](/news/dify)   [Fastgpt](/news/fastgpt)   [Bisheng](/news/Bisheng)   [Qanything](/news/Qanything)   [AI+汽车](/news/AIqiche)   [AI+金融](/news/AIjinrong)   [AI+工业](/news/AIgongye)   [AI+培训](/news/AIpeixun)   [AI+SaaS](/news/AISaaS)   [提示词框架](/news/tishicikuangjia)   [提示词技巧](/news/tishicijiqiao)   [AI+电商](/news/AIdianshang)   [AI面试](/news/AImianshi)   [数字员工](/news/shuziyuangong)   [ChatBI](/news/zhinengbaobiao)   [AI知识库](/news/zhishiguanli)   [开源大模型](/news/OpenSourceLLM)   [智能营销](/news/zhinengyingxiao)   [智能硬件](/news/zhinengyingjian)   [智能化改造](/news/zhinenghuagaizao)   [AI+医疗](/news/AIyiliao)   [MaxKB](/news/MaxKB)   [Palantir](/news/Palantir)   [Glean](/news/Glean)\n\n[应聘简历请发送至： ceo@53ai.com](mailto:ceo@53ai.com)\n\n[产品服务](/product.html)\n\n[工作+AI](/product/quanyuanAI)\n:   [工作对话](/product/gongzuoduihua)\n:   [内容创作](/product/neirongchuangzuo)\n:   [方案撰写](/product/zhinengwendang)\n:   [魔法菜单](/product/mofacaidan)\n\n[业务+AI](/product/yewuAI)\n:   [微信分身](/product/weixinfenshen)\n:   [海外客服](/product/haiwaikefu)\n:   [官网客服](/product/guanwangkefu)\n:   [抖音客服](/product/douyinkefu)\n:   [数字老师](/product/shuzilaoshi)\n:   [数字督导](/product/shuzidudao)\n:   [智能服务台](/product/zhinengfuwutai)\n\n[AIx业务](/product/AIXyewu)\n:   [智能问数](/product/zhinengwenshu)\n:   [智能审核](/product/zhinengshenhe)\n:   [智能工单](/product/zhinenggongdan)\n:   [企微跟进助手](/product/qiweigenjinzhushou)\n:   [智能报价](/product/zhinengbaojia)\n:   [企微销售助手](/product/qiweixiaoshouzhushou)\n:   [应用智改](/product/zijianyingyong)\n:   [企微客服助手](/product/qiweikefuzhushou)\n\n[落地咨询](/consulting.html)\n\n[定制开发](/fine-tuning.html)\n\n[客户案例](/kehuanli.html)\n\n:   [行业案例](/kehuanli/hangyeanli)\n:   [场景案例](/kehuanli/solution)\n\n[AI知识库](/news.html)\n\n:   [前沿技术](/news/qianyanjishu)\n:   [Agent框架](/news/agentplatform)\n:   [行业应用](/news/hangyeyingyong)\n:   [企业落地](/news/qiyejingying)\n:   [结构化提示词](/prompt.html)\n\n[关于我们](/about.html)\n\n:   [公司介绍](/about/introduction)\n:   [渠道合作](/about/cooperation)\n\n友情链接：\n\n[通往AGI之路](https://www.waytoagi.com/) [云璨信息](https://www.yuncan.com/) [企微SCRM](https://www.wescrm.com) [小名片](https://www.mingpian.top) [优网科技](https://www.uweb.net.cn)\n\nCopyRight © 2012-2024 深圳市博思协创网络科技有限公司 版权所有\n\n微信扫码  \n和创始人交个朋友\n\n[186 6662 7370](tel:18666627370)\n\n[185 8882 0121](tel:18588820121)\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.53ai.com/news/RAG/1732.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9998523, 'save_path': None}}, {'paper_id': '', 'title': '《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的 ...', 'authors': [], 'abstract': "# 《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的智能系统[译]\n\n30 分钟阅读[人工智能](/categories/ai)\n\n## 《智能体设计模式》中文翻译计划启动\n\n正如《设计模式》曾是软件工程的圣经，这本由谷歌资深工程主管免费分享的《智能体设计模式》，正为火热的 AI 智能体领域带来首套系统性的设计原则与最佳实践。\n\n本书由 Antonio Gulli 撰写、谷歌 Cloud AI 副总裁 Saurabh Tiwary 作序、高盛 CIO Marco Argenti 鼎力推荐，系统性地提炼出 21 个核心智能体设计模式，涵盖从提示链、工具使用到多智能体协作、自我修正等关键技术。\n\n接下来的一段时间，我将和几位小伙伴一起通过「AI 初次翻译 → AI 交叉评审 → 人工评审 → 人工交叉评审」的方式来翻译这本书，所有翻译内容将会持续更新到开源项目：[github.com/ginobefun/agentic-design-patterns-cn](https://github.com/ginobefun/agentic-design-patterns-cn)\n\n已翻译章节：\n\n* [00 -《智能体设计模式》前言部分](https://www.ginonotes.com/posts/agentic-design-patterns-front-matter-translation)\n* [01 -《智能体设计模式》第一章：提示链模式](https://www.ginonotes.com/posts/agentic-design-patterns-prompt-chaining-translation)\n* [02 -《智能体设计模式》第二章：路由模式](https://www.ginonotes.com/posts/agentic-design-patterns-routing-translation)\n* [03 -《智能体设计模式》第三章：并行模式](https://www.ginonotes.com/posts/agentic-design-patterns-parallelization-translation)\n* [04 -《智能体设计模式》第四章：反思模式](https://www.ginonotes.com/posts/agentic-design-patterns-reflection-translation)\n* [05 -《智能体设计模式》第五章：工具使用模式](https://www.ginonotes.com/posts/agentic-design-patterns-tool-use-translation)\n* [06 -《智能体设计模式》第六章：规划模式](https://www.ginonotes.com/posts/agentic-design-patterns-planning-translation)\n* [07 -《智能体设计模式》第七章：智能体协作模式](https://www.ginonotes.com/posts/agentic-design-patterns-multi-agent-collaboration-translation)\n* [08 -《智能体设计模式》第八章：记忆管理模式](https://www.ginonotes.com/posts/agentic-design-patterns-memory-management-translation)\n\n## 记忆管理模式精华概览\n\n记忆管理是智能体系统的核心能力，使其能够保留历史信息、从经验中学习并提供连贯一致的交互体验。与人类类似，智能体需要同时具备短期记忆和长期记忆才能高效运作，从而超越简单的一次性问答，展现出真正的智能行为。这里为大家梳理几个关键要点：\n\n### 1. 核心理念：双层记忆架构\n\n记忆管理的核心在于建立「短期上下文 + 长期知识」的双层存储架构，让智能体既能处理即时信息，又能积累和调用持久化知识。\n\n* **短期记忆（上下文记忆）**：类似工作记忆，存储当前对话中的即时信息，主要存在于大语言模型的上下文窗口内，包括最近的对话、工具调用结果等。具有临时性，会话结束后即丢失，容量受限于上下文窗口大小。\n* **长期记忆（持久记忆）**：充当长期知识库，存储需要跨会话保留的信息，通常使用外部数据库或向量数据库实现。支持语义搜索，智能体可基于相似性而非精确匹配来检索相关信息。\n\n### 2. 关键组件与架构\n\n不同框架提供了结构化的记忆管理组件：\n\n* **Google ADK 三件套**：\n\n  + `Session`（会话）：跟踪独立的聊天会话，记录消息和执行动作\n  + `State`（状态）：存储会话内的临时数据，支持键前缀管理数据范围（`user:`、`app:`、`temp:`）\n  + `MemoryService`（记忆服务）：管理长期知识的存储与检索，提供多种实现方式（内存、数据库、Vertex AI）\n* **LangChain/LangGraph**：\n\n  + `ChatMessageHistory`：手动管理对话历史\n  + `ConversationBufferMemory`：自动将历史注入提示词\n  + `BaseStore`：支持跨会话的长期记忆存储，使用命名空间组织数据\n\n### 3. 典型应用场景\n\n记忆管理在五大领域发挥关键作用：\n\n* **聊天机器人与对话式 AI**：维持对话流程，记住用户偏好和历史问题，提供连贯个性化的交互体验。\n* **任务导向型智能体**：跟踪多步骤任务的进度、已完成步骤和总体目标，访问用户特定的非即时数据。\n* **个性化体验服务**：存储和调用用户偏好、历史行为模式，动态调整响应策略和建议内容。\n* **信息检索（RAG）**：访问知识库支撑问答准确性，在 RAG 框架中提供上下文增强。\n* **自主控制系统**：存储地图、导航路线、物体位置等环境知识，结合实时感知和通用知识。\n\n### 4. 长期记忆的三种类型\n\n类比人类记忆机制，长期记忆可分为三类：\n\n* **语义记忆（事实记忆）**：存储具体事实和概念知识，如用户偏好或领域知识，可作为用户档案（JSON 文档）或文档集合管理。\n* **情景记忆（经历记忆）**：回忆过往事件或行为序列，通常通过少样本示例提示实现，智能体从历史成功交互中学习。\n* **程序性记忆（规则记忆）**：关于如何执行任务的规则和行为规范，体现在系统提示词中，可通过反思机制自适应优化。\n\n### 5. 使用时机与最佳实践\n\n当智能体需要超越单次问答时，应实施记忆管理：\n\n* **适用场景**：需要维持对话上下文；跟踪多步骤任务进度；提供个性化交互；基于历史学习和改进；处理复杂时序依赖问题。\n* **核心价值**：使智能体从无状态的简单响应者进化为具备记忆、学习和个性化能力的智能系统，能够维护历史记录并持续改进。\n\n---\n\n以下为原书第八章记忆管理设计模式的内容，译者：[@redpomegranate](https://github.com/redpomegranate)，评审：[@Gino](https://github.com/ginobefun)\n\n有效的记忆管理是智能体保留信息的关键。与人类类似，智能体需要多种类型的记忆才能高效运行。本章将深入探讨记忆管理，重点聚焦于智能体的即时（短期）和持久（长期）记忆需求。\n\n在智能体系统中，**记忆** 指智能体从过往交互、观察和学习经验中保留并利用信息的能力。这一能力使智能体能够做出明智决策、维持对话上下文，并持续改进。智能体记忆通常可分为两大主要类型：\n\n* **短期记忆（上下文记忆）**：类似于工作记忆，存储当前正在处理或近期访问的信息。对于基于大语言模型的智能体，短期记忆主要存在于上下文窗口内。该窗口包含最近的对话消息、智能体回复、工具调用结果以及当前交互中的反思内容，这些信息共同为后续的响应和决策提供上下文支撑。上下文窗口的容量有限，限制了智能体可直接访问的近期信息范围。高效的短期记忆管理需要在有限空间内选择性地保留最相关信息，可通过总结旧对话片段或强调关键细节等技术实现。具有「长上下文」窗口的模型虽然扩大了短期记忆容量，允许在单次交互中保存更多信息，但这种上下文仍然是短暂的，会话结束后即丢失，且每次处理成本高昂、效率较低。因此，智能体需要不同类型的记忆来实现真正的持久化，从过往交互中回忆信息并构建持久的知识库。\n* **长期记忆（持久记忆）**：充当一个长期知识库，用于存储智能体在各种交互场景、任务执行或长时间跨度内需要保留的信息。数据通常存储在智能体的运行时环境之外，常见于数据库、知识图谱或向量数据库中。在向量数据库中，信息被转换为数值向量并存储，使智能体能够基于语义相似性而非精确关键词匹配来检索数据，这个过程被称为语义搜索。当智能体需要长期记忆中的信息时，会查询外部存储、检索相关数据并将其整合到短期上下文中以便随时使用，从而将先验知识与当前交互信息相结合。\n\n## 实际应用场景\n\n记忆管理对于智能体至关重要，使其能够持续跟踪信息并在长时间运行中表现出智能行为。这一能力是智能体超越基础问答、展现高级智能的关键。主要应用场景包括：\n\n* **聊天机器人和对话式 AI：** 维持对话流程依赖于短期记忆。聊天机器人需要记住先前的用户输入才能提供连贯的回答。长期记忆使聊天机器人能够调取用户偏好、过往问题或过往对话记录，从而提供个性化且连续一致的交互体验。\n* **任务导向型智能体：** 处理多步骤任务的智能体需要借助短期记忆来跟踪已完成步骤、当前进度状态及总体目标。这些信息通常存储在任务上下文或临时缓存中。长期记忆对于访问非即时上下文的用户特定数据至关重要。\n* **个性化体验服务：** 提供定制化交互的智能体利用长期记忆系统来存储和调用用户偏好、历史行为模式及个人信息。这种能力使得智能体能够动态调整其响应策略和建议内容。\n* **信息检索（RAG）：** 为问答场景设计的智能体需要访问知识库（即长期记忆），这一功能通常在检索增强生成（RAG）框架中实现。智能体通过检索相关文档和数据资源来支撑其回答的准确性和完整性。\n* **自主控制系统：** 机器人或自动驾驶车辆需要记忆系统来存储地图信息、导航路线、物体位置以及学习获得的行为模式。这包括用于实时环境感知的短期记忆和用于通用环境知识存储的长期记忆。\n\n记忆能力使智能体能够维护历史记录、实现持续学习、提供个性化交互，并有效处理复杂的时序依赖性问题。\n\n## 实战代码：使用 Google ADK\n\nGoogle ADK 提供了一套结构化的上下文与记忆管理方法，包含多个可直接应用于实际场景的组件。深入理解 ADK 中会话（Session）、状态（State）和记忆（Memory）这三个核心概念，对于构建需要信息持久化能力的智能体至关重要。\n\n正如人类交流需要记忆，智能体同样需要具备回忆历史对话的能力，才能进行连贯自然的交流。ADK 通过三个核心概念及其配套服务，简化了上下文管理的复杂性。\n\n每次与智能体的交互都可视为一个独立的对话，而智能体往往需要访问历史交互数据。ADK 通过以下架构组织这些信息：\n\n* **Session（会话）：** 一个独立的聊天会话，记录特定交互过程中的消息和执行动作（事件），同时存储与该对话相关的临时数据（状态）。\n* **State（状态，`session.state`）：** 存储在会话内部的数据，仅包含与当前活跃聊天会话相关的上下文信息。\n* **Memory（记忆）：** 一个可检索的信息知识库，数据来源包括历史聊天记录和外部数据源，为超越当前对话范围的数据检索提供支持。\n\nADK 提供专门的服务组件，它们是构建有状态、上下文感知的智能体的关键要素。`SessionService` 负责管理聊天会话（`Session` 对象），处理会话的创建、记录和终止，而 `MemoryService` 负责长期知识（`Memory`）的存储与检索。\n\n`SessionService` 和 `MemoryService` 均提供多种配置选项，允许开发者根据应用需求选择合适的存储方案。比如内存存储适用于测试环境，数据不会持久化，在重启后会丢失。对于需要持久化存储和可扩展性等需求，ADK 支持使用数据库和云服务。\n\n### Session：跟踪每次聊天\n\nADK 中的 `Session` 对象用于跟踪和管理独立的聊天会话。\n\n当用户与智能体开始对话时，`SessionService` 会生成一个 `Session` 对象（`google.adk.sessions.Session`）。该对象封装特定对话线程的所有相关数据，包括唯一标识符（`id`、`app_name`、`user_id`）、按时间顺序记录的事件对象、用于会话临时数据（也称为状态）的存储区域，以及指示最后更新时间的时间戳（`last_update_time`）。\n\n开发者通常通过 `SessionService` 与 `Session` 对象交互。`SessionService` 负责管理对话会话的生命周期，包括启动新会话、恢复先前会话、记录会话活动（含状态更新）、识别活跃会话以及删除会话数据等。\n\nADK 内置了多种 `SessionService` 实现，具有不同的会话历史和临时数据存储机制。例如 `InMemorySessionService` 适用于测试环境，因为它不会在应用重启后保持数据持久化。\n\nThen there's DatabaseSessionService if you want reliable saving to a database you manage.\n\n如果你需要将数据保存到自行管理的数据库中，还可以选择 `DatabaseSessionService`。\n\nBesides, there's VertexAiSessionService which uses Vertex AI infrastructure for scalable production on Google Cloud.\n\n此外，还有 `VertexAiSessionService`，它使用 Google Cloud 上 Vertex AI 的基础设施以满足可扩展的生产部署要求。\n\n选择合适的 `SessionService` 至关重要，因为它决定了智能体的交互历史和临时数据如何存储以及持久化方式。\n\n每次消息交换都遵循以下流程：接收消息后，`Runner` 通过 `SessionService` 检索或创建对应的 `Session`，智能体利用 `Session` 的上下文（包括状态和历史交互）来处理消息，接着智能体生成响应并更新状态，`Runner` 将其封装为 `Event` 事件，`session_service.append_event` 方法记录该事件并更新状态。然后 `Session` 继续等待下一条消息。理想情况下，在交互结束时应该使用 `delete_session` 方法终止会话。\n\n以上过程展示了 `SessionService` 如何通过管理 `Session` 特定的历史和临时数据来维持连续性。\n\n### State：会话暂存区\n\n在 ADK 中，每个代表聊天会话的 `Session` 都包含一个状态组件，类似于智能体在该特定对话期间的临时工作记忆。`session.events` 记录整个聊天历史，而 `session.state` 则存储和更新与当前会话相关的动态信息。\n\n`session.state` 本质上是一个字典（Dictionary），以键值对（Key-Value Pairs）形式存储数据。其主要功能是帮助智能体保留和管理对话连贯性所需的关键信息，例如用户偏好、任务进展、增量数据收集，或影响后续智能体行为的条件标志。\n\n状态结构由字符串键与可序列化 Python 类型值组成，包括字符串、数字、布尔值、列表以及包含这些基本类型的字典。状态是动态的，在整个对话过程中不断演化。这些更改的持久性取决于所使用的 `SessionService`。\n\n可以通过键前缀来管理数据范围和持久性，从而实现有效的状态组织。不带前缀的键属于会话级别的。\n\n* **user:** 该前缀的数据为用户级别，和用户 ID 关联，可以跨多个会话使用。\n* **app:** 该前缀的数据为应用级别，可以在应用内被所有用户共享。\n* **temp:** 该前缀的数据为临时数据，仅在当前处理轮次内有效，不会被持久化。\n\n智能体通过统一的 `session.state` 字典访问所有状态数据。`SessionService` 负责处理数据的检索、合并和持久化。状态更新应该通过 `session_service.append_event()` 向会话历史添加事件来实现。这样可以确保跟踪的完整性，持久化服务中的正确保存以及安全的状态变更。\n\n**1. 简单方法：使用 `output_key`（用于智能体输出的文本）** 如果只需将智能体的最终响应直接保存到状态中，这是最简单的方法。定义 `LlmAgent` 时，只需指定要使用的 `output_key` 属性。`Runner` 会识别此参数设置，并创建必要的操作来将响应保存到状态中。我们来看一个通过 `output_key` 实现状态更新的代码示例。\n\n在幕后，`Runner` 会识别 `output_key`，并在调用 `append_event` 时自动创建带有 `state_delta` 的必要操作。\n\n**2. 标准方法：使用 EventActions.state\\_delta（用于更复杂的场景）** 当需要进行更复杂的操作时，例如同时更新多个键、保存非纯文本内容、针对特定作用域（如 `user:` 或 `app:`），或者执行与智能体最终文本回复无关的更新时，需要手动构建状态变更的字典（即 `state_delta`），并将其放在要附加的 `Event` 的 `EventActions` 中。让我们来看一个示例：\n\n此代码演示了一种基于工具的方法来管理应用程序中的用户会话状态。它定义了一个工具函数 `log_user_login`，负责在用户登录时更新会话状态。\n\n该函数接收由 ADK 提供的 `ToolContext` 对象，用于访问和修改会话的状态字典。在工具内部，它会递增 `user:login_count`，将 `task_status` 设置为 `active`，记录 `user:last_login_ts`（时间戳），并添加临时标志 `temp:validation_needed`。\n\n代码的演示部分模拟了此工具的使用方式。它设置了一个内存会话服务，并创建了一个包含预定义状态的初始会话。随后手动创建 `ToolContext` 来模拟 ADK `Runner` 执行工具的环境。使用此模拟上下文调用 `log_user_login` 函数。最后，代码再次检索会话以展示状态已通过工具执行而更新。其目的是展示与在工具外部直接操作状态相比，将状态变更封装在工具内部可以使代码更加清晰和内聚。\n\n请注意，强烈不建议在检索会话后直接修改 `session.state` 字典，因为这会绕过标准的事件处理机制。此类更改不会被记录在会话的事件历史中，可能导致 `SessionService` 未持久化，引起并发问题，并且不会更新时间戳等关键元数据。更新会话状态的推荐方法包括：在 `LlmAgent` 上使用 `output_key` 参数（专门用于智能体的最终文本输出），或在通过 `session_service.append_event()` 添加事件时，在 `EventActions.state_delta` 中包含状态变更的内容。`session.state` 主要用于读取现有数据。\n\n总而言之，在设计状态时，应保持简洁，使用基本数据类型，使用具体清晰的名称及合适前缀的键，避免深度嵌套，并始终通过 `append_event` 来更新状态。\n\n### 记忆：使用 MemoryService 实现长期知识管理\n\n在智能体系统中，`Session` 组件负责维护单个对话的聊天历史（事件）和临时数据（状态）。然而，为了让智能体能够在多次交互中持久保存信息或访问外部数据，需要实现长期知识管理功能。这一功能由 `MemoryService` 提供支持。\n\n从概念上来说，`Session` 和 `State` 管理的是单个聊天会话的短期记忆，而由 `MemoryService` 管理的长期知识则充当持久化且可搜索的知识库。该知识库可能包含来自多次历史交互或外部数据源的信息。\n\n`MemoryService` 通过 `BaseMemoryService` 接口定义，为管理这种可搜索的长期知识建立了规范。其主要功能包括：信息添加（从会话中提取内容并使用 `add_session_to_memory` 方法存储）和信息检索（允许智能体使用 `search_memory` 方法查询存储库并获取相关数据）。 ADK 提供多种实现来创建这种长期知识存储。`InMemoryMemoryService` 适用于测试目的的临时存储解决方案，但其数据在应用程序重启后不会保留。对于生产环境，通常采用 `VertexAiRagMemoryService`。该服务利用 Google Cloud 的检索增强生成（RAG）服务，提供可扩展、持久化且支持语义搜索的能力（有关 RAG 的详细信息，请参阅第 14 章）。\n\n## 代码实战：使用 LangChain 和 LangGraph\n\n在 LangChain 和 LangGraph 中，记忆是创建智能、自然流畅的对话应用的关键组件。它使智能体能够记住历史交互信息、从反馈中学习并适应用户偏好。\n\nLangChain 的记忆功能通过引用存储的历史记录来丰富当前提示词，并记录最新的交互内容供将来使用。随着智能体处理更复杂的任务，这种能力对提升效率和用户满意度至关重要。\n\n* **短期记忆：** 其作用域限于单个会话，它提供即时上下文，但完整的历史对话记录可能超出大语言模型的上下文窗口限制，导致错误或性能下降。LangGraph 将短期记忆作为智能体状态的一部分管理，通过检查点机制实现持久化，允许随时恢复会话继续执行。\n* **长期记忆：** 跨会话存储用户特定数据或应用级别数据，并在对话之间共享。它保存在自定义的「命名空间」中，可在任何会话的任何时间被检索。LangGraph 提供存储机制来保存和检索长期记忆，使智能体能够永久保留知识。\n\nLangChain 提供了多种工具来管理对话历史，从手动控制到链内自动集成。\n\n**ChatMessageHistory：手动记忆管理** 对于想在链之外简单直接地控制对话历史，`ChatMessageHistory` 类是理想选择。它支持手动跟踪对话交互。\n\n**ConversationBufferMemory：链的自动化记忆管理** 若需将记忆功能直接集成到链中，`ConversationBufferMemory` 是更好的选择。它维护对话内容的缓冲区并提供给提示词。其行为可通过两个关键参数配置：\n\n* `memory_key`：一个字符串参数，用于指定提示词模板中存储聊天历史的变量名称，默认值为「history」。\n* `return_messages`：布尔值参数，控制历史记录的处理方式。若为 False（默认值），则返回单个格式化的字符串，适用于标准的大语言模型；若为 True，则返回消息对象列表，适用于聊天模型。\n\n下面的例子演示将记忆功能集成到 `LLMChain` 后，模型能够访问对话历史并提供上下文相关的响应。\n\n对于聊天模型，建议设置 `return_messages=True` 以使用结构化的消息对象列表。\n\n**长期记忆的类型：** 长期记忆使系统能够跨对话保存信息，提供更深层次的上下文理解和个性化服务。类比人类记忆机制，它可分为以下三种类型：\n\n* **语义记忆：事实记忆** 存储具体的事实信息和概念知识，例如用户偏好或领域知识。它为智能体的响应提供事实依据，实现更加个性化和相关的交互。这类信息可以作为持续更新的用户「档案」（以 JSON 格式保存的文档）或一个独立的文档「集合」进行管理。\n* **情景记忆：经历记忆** 回忆过往事件或行为序列。对于 AI 智能体，情景记忆通常用于记忆如何完成特定任务。在实践中，常通过少样本示例提示实现，智能体从历史成功的交互序列中学习，以正确执行任务。\n* **程序性记忆：规则记忆** 关于如何执行任务的记忆，包括智能体的核心指令和行为规范，通常体现在系统提示词中。常见做法是智能体通过修改自身提示词来实现自适应和改进。一种有效技术是「反思机制」，即向智能体呈现当前指令和近期交互记录，要求其自主优化指令内容。\n\n以下伪代码示例演示了智能体如何运用反思机制来更新存储在 LangGraph `BaseStore` 中的程序记忆：\n\nLangGraph 将长期记忆以 JSON 格式存储起来。每个记忆条目通过自定义命名空间（类似文件夹结构）和唯一键名（类似文件名）组织。这种层次化结构便于信息的系统化组织和高效检索。以下代码示例演示如何使用 `InMemoryStore` 来实现记忆的存储、获取和搜索操作。\n\n## Vertex Memory Bank 服务\n\nMemory Bank 是 Vertex AI Agent Engine 中的托管服务，为智能体提供持久化长期记忆。该服务利用 Gemini 模型异步分析对话历史，提取关键事实信息和用户偏好。\n\n这些信息被持久化存储，按预定义范围（如用户 ID）组织，并通过智能更新机制整合新数据和解决信息冲突。启动新会话时，智能体通过完整数据检索或基于嵌入的相似性搜索来获取相关记忆。这一流程使智能体能够维持跨会话的连续性，并根据检索到的记忆信息提供个性化响应。\n\n智能体的执行器与 `VertexAiMemoryBankService` 服务交互（该服务需预先初始化）。该服务负责自动存储智能体对话过程中生成的记忆内容。每个记忆条目通过唯一的 `USER_ID` 和 `APP_NAME` 标记，确保可以被准确检索。\n\nMemory Bank 可以与 Google ADK 无缝集成，提供开箱即用的体验。对于其他智能体框架（如 LangGraph 和 CrewAI）的用户，Memory Bank 也通过 API 调用提供支持。感兴趣的读者可以通过在线代码示例，了解这些集成方案的实现。\n\n## 要点速览\n\n**问题所在：** 智能体系统需要记住过往交互信息以执行复杂任务并提供连贯体验。若缺少记忆机制，智能体将处于无状态，无法维持对话上下文、从经验中学习或提供个性化响应。这从根本上将它们限制在简单的一次性交互中，无法处理多步骤流程或不断变化的用户需求。核心问题在于如何有效管理单次对话的即时信息与长期积累的持久知识。\n\n**解决之道：** 标准解决方案是实现区分短期与长期存储的双组件记忆系统。短期上下文记忆位于大语言模型的上下文窗口内，保存最近的交互数据以维持对话流程。对于必须持久化的信息，长期记忆解决方案采用外部数据库（通常是向量存储）进行高效的语义检索。智能体框架（如 Google ADK）提供专门的组件来管理记忆，例如 `Session`（对话线程）和 `State`（临时数据）。专门的 `MemoryService` 组件用于与长期知识库交互，允许智能体检索相关历史信息并整合到当前上下文中\n\n**经验法则：** 当智能体需要执行的任务超越单一问题回答时，应采用此模式。对于必须在整个对话中维持上下文、跟踪多步骤任务进度或通过回忆用户偏好和历史来个性化交互的智能体，记忆管理至关重要。当智能体需要基于过去的成功、失败或新获得的信息进行学习或自适应调整时，也应该实施记忆管理。\n\n图 1：记忆管理设计模式\n\n## 核心要点\n\n* 记忆机制对于智能体的事件跟踪、经验学习和个性化交互至关重要。\n* 对话式 AI 系统同时依赖短期记忆（管理单次聊天中的即时上下文）和长期记忆（维护跨多个会话的持久化知识）。\n* 短期记忆（处理即时内容）具有临时性，通常受限于大语言模型的上下文窗口容量或框架的上下文传递机制。\n* 长期记忆（存储持久化内容）利用外部存储系统（如向量数据库）在不同聊天会话间保存信息，并通过搜索机制进行访问。\n* 诸如 ADK 之类的框架通过特定组件管理记忆：`Session`（管理聊天线程）、`State`（存储临时聊天数据）和 `MemoryService`（提供可搜索的长期知识库）。\n* ADK 的 `SessionService` 负责管理聊天会话的完整生命周期，包括历史记录（事件日志）和临时数据（状态信息）。\n* ADK 的 `session.state` 是一个用于存储临时聊天数据的字典结构。前缀标识符（`user:`、`app:`、`temp:`）明确数据归属范围及其持久化特性。\n* 在 ADK 框架中，状态更新应通过 `EventActions.state_delta` 或 `output_key` 在添加事件时进行，而非直接修改状态字典。\n* ADK 的 `MemoryService` 专用于将信息存入长期存储系统，并支持智能体通过工具接口进行搜索检索。\n* LangChain 提供诸如 `ConversationBufferMemory` 等实用工具，能够自动将单次对话历史注入提示词中，使智能体具备即时上下文回忆能力。\n* LangGraph 通过存储机制实现高级长期记忆功能，支持跨用户会话保存和检索语义事实、情景经历乃至可更新的程序规则。\n* Memory Bank 作为托管服务，通过自动提取、存储和检索用户特定信息，为智能体提供持久化长期记忆，从而在 Google ADK、LangGraph 和 CrewAI 等框架中实现个性化连续对话。\n\n## 结语\n\n本章深入探讨了智能体系统中记忆管理这一关键任务，阐明了临时上下文信息与长期持久化知识之间的本质区别。我们剖析了各类记忆机制的架构原理及其在构建智能体系统中的实际应用，并详细介绍了 Google ADK 框架如何通过 `Session`、`State` 和 `MemoryService` 等组件来实现记忆管理。\n\n## 参考文献\n\n1. ADK 的记忆管理：<https://google.github.io/adk-docs/sessions/memory/>\n2. LangGraph 的记忆管理：<https://langchain-ai.github.io/langgraph/concepts/memory/>\n3. Vertex AI 智能体引擎的 Memory Bank：<https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-memory-bank-in-public-preview>\n\nMemory ManagementShort-term MemoryLong-term MemoryAI AgentDesign PatternsAgentic AIGoogle ADKLangChainLangGraphSemantic MemoryEpisodic MemoryProcedural MemoryRAGVertex AISession Management\n\n## 相关文章\n\n[《智能体设计模式》之多智能体协作模式：分工协同突破单一智能体能力边界[译]](/posts/agentic-design-patterns-multi-agent-collaboration-translation)[《智能体设计模式》之规划模式：自主拆解复杂任务的智能化执行[译]](/posts/agentic-design-patterns-planning-translation)[《智能体设计模式》之工具使用模式：突破能力边界的外部工具集成[译]](/posts/agentic-design-patterns-tool-use-translation)[《智能体设计模式》之反思模式：自我评估和迭代改进[译]](/posts/agentic-design-patterns-reflection-translation)\n\n[查看更多 人工智能 的文章](/categories/ai)", 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://ginonotes.com/posts/agentic-design-patterns-memory-management-translation', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9996673, 'save_path': None}}, {'paper_id': '', 'title': 'Short-term memory - Docs by LangChain', 'authors': [], 'abstract': '[Docs by LangChain home page](/)\n\n[LangChain](/oss/python/langchain/overview)[LangGraph](/oss/python/langgraph/overview)[Deep Agents](/oss/python/deepagents/overview)[Integrations](/oss/python/integrations/providers/overview)[Learn](/oss/python/learn)[Reference](/oss/python/reference/overview)[Contribute](/oss/python/contributing/overview)\n\n##### Get started\n\n* [Install](/oss/python/langchain/install)\n* [Quickstart](/oss/python/langchain/quickstart)\n* [Changelog](https://docs.langchain.com/oss/python/releases/changelog)\n* [Philosophy](/oss/python/langchain/philosophy)\n\n##### Core components\n\n* [Agents](/oss/python/langchain/agents)\n* [Models](/oss/python/langchain/models)\n* [Messages](/oss/python/langchain/messages)\n* [Tools](/oss/python/langchain/tools)\n* [Short-term memory](/oss/python/langchain/short-term-memory)\n* [Structured output](/oss/python/langchain/structured-output)\n\n##### Middleware\n\n* [Overview](/oss/python/langchain/middleware/overview)\n* [Built-in middleware](/oss/python/langchain/middleware/built-in)\n* [Custom middleware](/oss/python/langchain/middleware/custom)\n\n##### Advanced usage\n\n* [Guardrails](/oss/python/langchain/guardrails)\n* [Runtime](/oss/python/langchain/runtime)\n* [Context engineering](/oss/python/langchain/context-engineering)\n* [Model Context Protocol (MCP)](/oss/python/langchain/mcp)\n* [Human-in-the-loop](/oss/python/langchain/human-in-the-loop)\n* [Retrieval](/oss/python/langchain/retrieval)\n* [Long-term memory](/oss/python/langchain/long-term-memory)\n\n##### Agent development\n\n* [LangSmith Studio](/oss/python/langchain/studio)\n* [Test](/oss/python/langchain/test)\n* [Agent Chat UI](/oss/python/langchain/ui)\n\n##### Deploy with LangSmith\n\n* [Deployment](/oss/python/langchain/deploy)\n* [Observability](/oss/python/langchain/observability)\n\n* [Overview](#overview)\n* [Usage](#usage)\n* [In production](#in-production)\n* [Customizing agent memory](#customizing-agent-memory)\n* [Common patterns](#common-patterns)\n* [Trim messages](#trim-messages)\n* [Delete messages](#delete-messages)\n* [Summarize messages](#summarize-messages)\n* [Access memory](#access-memory)\n* [Tools](#tools)\n* [Read short-term memory in a tool](#read-short-term-memory-in-a-tool)\n* [Write short-term memory from tools](#write-short-term-memory-from-tools)\n* [Prompt](#prompt)\n* [Before model](#before-model)\n* [After model](#after-model)\n\n[Core components](/oss/python/langchain/agents)\n\n# Short-term memory\n\n## [\u200b](#overview) Overview\n\nMemory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction. Short term memory lets your application remember previous interactions within a single thread or conversation.\n\nA thread organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n\nConversation history is the most common form of short-term memory. Long conversations pose a challenge to today’s LLMs; a full history may not fit inside an LLM’s context window, resulting in an context loss or errors. Even if your model supports the full context length, most LLMs still perform poorly over long contexts. They get “distracted” by stale or off-topic content, all while suffering from slower response times and higher costs. Chat models accept context using [messages](/oss/python/langchain/messages), which include instructions (a system message) and inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited, many applications can benefit from using techniques to remove or “forget” stale information.\n\n## [\u200b](#usage) Usage\n\nTo add short-term memory (thread-level persistence) to an agent, you need to specify a `checkpointer` when creating an agent.\n\nLangChain’s agent manages short-term memory as a part of your agent’s state.By storing these in the graph’s state, the agent can access the full context for a given conversation while maintaining separation between different threads.State is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.Short-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver  agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(), )) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"configurable": {"thread_id": "1"}},  {"configurable": {"thread_id": "1"}}, ))\n```\n\n### [\u200b](#in-production) In production\n\nIn production, use a checkpointer backed by a database:\n\nCopy\n\n```\npip install langgraph-checkpoint-postgres pip  install langgraph-checkpoint-postgres\n```\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from langgraph.checkpoint.postgres import PostgresSaver from langgraph.checkpoint.postgres import  PostgresSaver  DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable" DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"with PostgresSaver.from_conn_string(DB_URI) as checkpointer: with PostgresSaver.from_conn_string(DB_URI) as checkpointer: checkpointer.setup() # auto create tables in PostgresSql checkpointer.setup() # auto create tables in PostgresSql agent = create_agent( agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=checkpointer,  checkpointer =checkpointer,  ) )\n```\n\nFor more checkpointer options including SQLite, Postgres, and Azure Cosmos DB, see the [list of checkpointer libraries](/oss/python/langgraph/persistence#checkpointer-libraries) in the Persistence documentation.\n\n## [\u200b](#customizing-agent-memory) Customizing agent memory\n\nBy default, agents use [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to manage short term memory, specifically the conversation history via a `messages` key. You can extend [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to add additional fields. Custom state schemas are passed to [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) using the [`state_schema`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware.state_schema) parameter.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver class CustomAgentState(AgentState): class  CustomAgentState(AgentState):  user_id: str user_id: str preferences: dict preferences: dict agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomAgentState,  state_schema =CustomAgentState,  checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) # Custom state can be passed in invoke # Custom state can be passed in invokeresult = agent.invoke(result = agent.invoke( { { "messages": [{"role": "user", "content": "Hello"}],  "messages": [{"role": "user", "content": "Hello"}], "user_id": "user_123",  "user_id": "user_123",  "preferences": {"theme": "dark"}  "preferences": {"theme": "dark"}  }, }, {"configurable": {"thread_id": "1"}}) {"configurable": {"thread_id": "1"}})\n```\n\n## [\u200b](#common-patterns) Common patterns\n\nWith [short-term memory](#add-short-term-memory) enabled, long conversations can exceed the LLM’s context window. Common solutions are:\n\n[## Trim messages\n\nRemove first or last N messages (before calling LLM)](#trim-messages)[## Delete messages\n\nDelete messages from LangGraph state permanently](#delete-messages)[## Summarize messages\n\nSummarize earlier messages in the history and replace them with a summary](#summarize-messages)\n\n## Custom strategies\n\nCustom strategies (e.g., message filtering, etc.)\n\nThis allows the agent to keep track of the conversation without exceeding the LLM’s context window.\n\n### [\u200b](#trim-messages) Trim messages\n\nMost LLMs have a maximum supported context window (denominated in tokens). One way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you’re using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the `strategy` (e.g., keep the last `max_tokens`) to use for handling the boundary. To trim message history in an agent, use the [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware decorator:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( your_model_here, your_model_here, tools=your_tools_here,  tools =your_tools_here, middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#delete-messages) Delete messages\n\nYou can delete messages from the graph state to manage the message history. This is useful when you want to remove specific messages or clear the entire message history. To delete messages from the graph state, you can use the `RemoveMessage`. For `RemoveMessage` to work, you need to use a state key with [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) [reducer](/oss/python/langgraph/graph-api#reducers). The default [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) provides this. To remove specific messages:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessage def delete_messages(state): def  delete_messages(state): messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]} \n```\n\nTo remove **all** messages:\n\nCopy\n\n```\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGES def delete_messages(state): def  delete_messages(state): return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  return {"messages": [RemoveMessage(id = REMOVE_ALL_MESSAGES)]} \n```\n\nWhen deleting messages, **make sure** that the resulting message history is valid. Check the limitations of the LLM provider you’re using. For example:\n\n* Some providers expect message history to start with a `user` message\n* Most providers require `assistant` messages with tool calls to be followed by corresponding `tool` result messages.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig  @after_model @after_modeldef delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None: def  delete_old_messages(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove old messages to keep conversation manageable.""" """Remove old messages to keep conversation manageable.""" messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]}  return None  return  None agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], system_prompt="Please be concise and to the point.",  system_prompt ="Please be concise and to the point.", middleware=[delete_old_messages],  middleware =[delete_old_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]]) for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "what\'s my name?"}]}, {"messages": [{"role": "user", "content": "what\'s my name?"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]])\n```\n\nCopy\n\n```\n[(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')] \n```\n\n### [\u200b](#summarize-messages) Summarize messages\n\nThe problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue. Because of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.  To summarize message history in an agent, use the built-in [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization):\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langchain.agents.middleware import SummarizationMiddleware from langchain.agents.middleware import  SummarizationMiddlewarefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig checkpointer = InMemorySaver() checkpointer = InMemorySaver() agent = create_agent(agent = create_agent( model="gpt-4o",  model ="gpt-4o", tools=[],  tools =[], middleware=[ middleware =[ SummarizationMiddleware( SummarizationMiddleware( model="gpt-4o-mini",  model ="gpt-4o-mini", trigger=("tokens", 4000),  trigger =("tokens", 4000), keep=("messages", 20)  keep =("messages", 20) ) ) ], ], checkpointer=checkpointer,  checkpointer =checkpointer,)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}}agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob!Your name is Bob! """ """\n```\n\nSee [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization) for more configuration options.\n\n## [\u200b](#access-memory) Access memory\n\nYou can access and modify the short-term memory (state) of an agent in several ways:\n\n### [\u200b](#tools) Tools\n\n#### [\u200b](#read-short-term-memory-in-a-tool) Read short-term memory in a tool\n\nAccess short term memory (state) in a tool using the `runtime` parameter (typed as `ToolRuntime`). The `runtime` parameter is hidden from the tool signature (so the model doesn’t see it), but the tool can access the state through it.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntime class CustomState(AgentState): class  CustomState(AgentState): user_id: str user_id: str @tool @tooldef get_user_info(def  get_user_info( runtime: ToolRuntime  runtime: ToolRuntime) -> str:) -> str: """Look up user info.""" """Look up user info.""" user_id = runtime.state["user_id"]  user_id = runtime.state["user_id"] return "User is John Smith" if user_id == "user_123" else "Unknown user"  return  "User is John Smith"  if  user_id ==  "user_123"  else  "Unknown user" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomState,  state_schema =CustomState,)) result = agent.invoke({result = agent.invoke({ "messages": "look up user information",  "messages": "look up user information", "user_id": "user_123"  "user_id": "user_123"})})print(result["messages"][-1].content) print(result["messages"][- 1].content)# > User is John Smith.# > User is John Smith.\n```\n\n#### [\u200b](#write-short-term-memory-from-tools) Write short-term memory from tools\n\nTo modify the agent’s short-term memory (state) during execution, you can return state updates directly from the tools. This is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.\n\nCopy\n\n```\nfrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langchain.messages import ToolMessage from langchain.messages import  ToolMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.types import Command from langgraph.types import  Command from pydantic import BaseModel from  pydantic import  BaseModel class CustomState(AgentState): class  CustomState(AgentState):  user_name: str user_name: str class CustomContext(BaseModel): class  CustomContext(BaseModel): user_id: str user_id: str @tool @tooldef update_user_info(def  update_user_info( runtime: ToolRuntime[CustomContext, CustomState],  runtime: ToolRuntime[CustomContext, CustomState],) -> Command:) -> Command: """Look up and update user info.""" """Look up and update user info.""" user_id = runtime.context.user_id  user_id = runtime.context.user_id name = "John Smith" if user_id == "user_123" else "Unknown user"  name =  "John Smith"  if  user_id ==  "user_123"  else  "Unknown user" return Command(update={  return Command(update ={  "user_name": name,  "user_name": name,  # update the message history  # update the message history "messages": [ "messages": [ ToolMessage( ToolMessage( "Successfully looked up user information",  "Successfully looked up user information", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) @tool @tooldef greet(def  greet( runtime: ToolRuntime[CustomContext, CustomState]  runtime: ToolRuntime[CustomContext, CustomState]) -> str | Command:) -> str  | Command: """Use this to greet the user once you found their info.""" """Use this to greet the user once you found their info.""" user_name = runtime.state.get("user_name", None)  user_name = runtime.state.get("user_name", None) if user_name is None:  if  user_name is  None: return Command(update={ return Command(update ={ "messages": [ "messages": [ ToolMessage( ToolMessage( "Please call the \'update_user_info\' tool it will get and update the user\'s name.", "Please call the \'update_user_info\' tool it will get and update the user\'s name.", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) return f"Hello {user_name}!"  return  f "Hello {user_name}!" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[update_user_info, greet],  tools =[update_user_info, greet], state_schema=CustomState,  state_schema =CustomState,  context_schema=CustomContext,  context_schema =CustomContext,)) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "greet the user"}]}, {"messages": [{"role": "user", "content": "greet the user"}]}, context=CustomContext(user_id="user_123"),  context =CustomContext(user_id = "user_123"),))\n```\n\n### [\u200b](#prompt) Prompt\n\nAccess short term memory (state) in middleware to create dynamic prompts based on conversation history or custom state fields.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from typing import TypedDict from  typing import  TypedDictfrom langchain.agents.middleware import dynamic_prompt, ModelRequest from langchain.agents.middleware import dynamic_prompt, ModelRequest class CustomContext(TypedDict): class  CustomContext(TypedDict): user_name: str user_name: str def get_weather(city: str) -> str: def  get_weather(city: str) -> str: """Get the weather in a city.""" """Get the weather in a city.""" return f"The weather in {city} is always sunny!"  return  f "The weather in {city} is always sunny!"  @dynamic_prompt @dynamic_promptdef dynamic_system_prompt(request: ModelRequest) -> str: def  dynamic_system_prompt(request: ModelRequest) -> str: user_name = request.runtime.context["user_name"]  user_name = request.runtime.context["user_name"] system_prompt = f"You are a helpful assistant. Address the user as {user_name}."  system_prompt =  f"You are a helpful assistant. Address the user as {user_name}."  return system_prompt  return  system_prompt agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_weather],  tools =[get_weather], middleware=[dynamic_system_prompt],  middleware =[dynamic_system_prompt], context_schema=CustomContext,  context_schema =CustomContext,)) result = agent.invoke(result = agent.invoke( {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, context=CustomContext(user_name="John Smith"),  context =CustomContext(user_name = "John Smith"),))for msg in result["messages"]: for  msg in result["messages"]: msg.pretty_print() msg.pretty_print() \n```\n\nOutput\n\nCopy\n\n```\n================================ Human Message ================================= ================================  Human  Message ================================= What is the weather in SF? What  is  the  weather  in  SF? ================================== Ai Message ================================== ==================================  Ai  Message ==================================Tool Calls: Tool Calls: get_weather (call_WFQlOGn4b2yoJrv7cih342FG)  get_weather (call_WFQlOGn4b2yoJrv7cih342FG) Call ID: call_WFQlOGn4b2yoJrv7cih342FG  Call ID:  call_WFQlOGn4b2yoJrv7cih342FG Args: Args: city: San Francisco city:  San  Francisco ================================= Tool Message ================================= =================================  Tool  Message =================================Name: get_weatherName:  get_weather The weather in San Francisco is always sunny! The  weather  in  San  Francisco  is  always sunny! ================================== Ai Message ================================== ==================================  Ai  Message ================================== Hi John Smith, the weather in San Francisco is always sunny! Hi  John Smith,  the  weather  in  San  Francisco  is  always sunny!\n```\n\n### [\u200b](#before-model) Before model\n\nAccess short term memory (state) in [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware to process messages before model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver()  checkpointer =InMemorySaver())) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#after-model) After model\n\nAccess short term memory (state) in [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) middleware to process messages after model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime  @after_model @after_modeldef validate_response(state: AgentState, runtime: Runtime) -> dict | None: def  validate_response(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove messages containing sensitive words.""" """Remove messages containing sensitive words.""" STOP_WORDS = ["password", "secret"]  STOP_WORDS = ["password", "secret"] last_message = state["messages"][-1]  last_message = state["messages"][- 1] if any(word in last_message.content for word in STOP_WORDS):  if  any(word in last_message.content for  word in  STOP_WORDS): return {"messages": [RemoveMessage(id=last_message.id)]}  return {"messages": [RemoveMessage(id =last_message.id)]}  return None  return  None agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[],  tools =[], middleware=[validate_response],  middleware =[validate_response], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),))\n```\n\n---\n\n[Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/short-term-memory.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n\n[Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n\nWas this page helpful?\n\n[Tools](/oss/python/langchain/tools)[Overview](/oss/python/langchain/streaming/overview)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://docs.langchain.com/oss/python/langchain/short-term-memory', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9995453, 'save_path': None}}, {'paper_id': '', 'title': 'LangChain+LangGraph内存管理与上下文优化完整指南 - 腾讯云', 'authors': [], 'abstract': '[*腾讯云*](/?from=20060&from_column=20060)\n[*开发者社区*](/developer)\n\n[文档](/document/product?from=20702&from_column=20702)[建议反馈](/voc/?from=20703&from_column=20703)[控制台](https://console.cloud.tencent.com?from=20063&from_column=20063)\n\n[首页](/developer)\n\n文章/答案/技术大牛\n\ndeephub\n\n[社区首页](/developer) >[专栏](/developer/column) >AI代理性能提升实战：LangChain+LangGraph内存管理与上下文优化完整指南\n\n# AI代理性能提升实战：LangChain+LangGraph内存管理与上下文优化完整指南\n\ndeephub\n\n发布于 2025-08-20 14:04:48\n\n发布于 2025-08-20 14:04:48\n\n1.6K0\n\n文章被收录于专栏：[DeepHub IMBA](/developer/column/86944)DeepHub IMBA\n\n### 上下文工程的理论基础\n\nDrew Breunig在其研究中详细阐述了过量上下文信息对系统性能的负面影响，包括上下文污染（错误信息或幻觉内容被引入上下文）、上下文干扰（过量信息导致模型混乱）、上下文混淆（冗余细节影响响应质量）以及上下文冲突（不同上下文片段提供相互矛盾的信息）。\n\n### 基于LangGraph的Scratchpad实现机制\n\nAnthropic的多代理研究系统提供了一个典型的应用案例：LeadResearcher会制定详细的研究计划并将其保存到内存中，这样做的目的是防止当上下文窗口超过200,000个令牌时发生信息截断，确保重要的规划信息不会丢失。\n\nScratchpad的实现方式主要有两种：一种是通过工具调用将信息写入文件系统，另一种是作为会话期间持续存在的运行时状态对象中的字段。简而言之，Scratchpad技术帮助代理在整个会话过程中维护重要的工作记录，从而高效地完成复杂任务。\n\n就LangGraph框架而言，它提供了对短期内存（线程作用域）和长期内存的全面支持。短期内存通过检查点机制在会话期间保存代理状态，其工作原理类似于Scratchpad，允许在代理运行过程中存储信息并在稍后进行检索。\n\n状态对象是在图节点之间传递的核心数据结构。开发者可以自定义其格式（通常采用Python字典结构），它充当共享的Scratchpad，每个节点都可以读取和更新特定字段的内容。\n\n为了确保学习过程的清晰性，我们采用按需导入的方式引入所需模块。为了获得更优质的输出效果，我们将使用Python的`pprint`模块进行格式化打印，以及来自`rich`库的`Console`模块。首先进行这些模块的导入和初始化：\n\n代码语言：javascript\n\n复制\n\n```\n # Import necessary libraries from typing import TypedDict # For defining the state schema with type hints from rich.console import Console # 用于美化输出显示 from rich.pretty import pprint # 用于美化Python对象的打印输出 # 为notebook环境初始化丰富格式化输出的控制台实例 console = Console()\n```\n\n接下来，我们将为状态对象创建一个`TypedDict`类型定义：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用TypedDict定义图状态的数据模式 # 该类作为在图节点间传递的数据结构 # 确保状态具有一致的数据结构并提供类型提示功能 class State(TypedDict): """ 定义笑话生成器工作流的状态结构 属性说明: topic: 用于生成笑话的输入主题 joke: 存储生成笑话内容的输出字段 """ topic: str joke: str\n```\n\n该状态对象将存储主题信息以及代理基于给定主题生成的笑话内容。\n\n在定义状态对象之后，我们可以通过StateGraph向其写入上下文信息。StateGraph是LangGraph框架用于构建有状态代理或工作流的核心工具，可以将其理解为一个有向图结构：节点代表工作流中的执行步骤，每个节点接收当前状态作为输入，对其进行更新，并返回修改结果；边用于连接节点，定义执行流程的路径，这种路径可以是线性的、条件性的，甚至是循环性的。\n\n接下来的实现步骤包括：通过选择Anthropic模型来创建聊天模型，并将其集成到LangGraph工作流中。\n\n代码语言：javascript\n\n复制\n\n```\n # 导入环境管理、显示功能和LangGraph相关的必要库 import getpass import os from IPython.display import Image, display from langchain.chat_models import init_chat_model from langgraph.graph import END, START, StateGraph # --- 环境配置和模型初始化 --- # 设置Anthropic API密钥用于请求认证 from dotenv import load_dotenv api_key = os.getenv("ANTHROPIC_API_KEY") if not api_key: raise ValueError("Missing ANTHROPIC_API_KEY in environment") # 初始化工作流中使用的聊天模型 # 使用特定的Claude模型，temperature=0确保输出的确定性 llm = init_chat_model("anthropic:claude-sonnet-4-20250514", temperature=0)\n```\n\n我们已经成功初始化了Sonnet模型。LangChain框架通过其API接口支持众多开源和商业模型，因此开发者可以根据需求选择合适的模型。\n\n现在需要创建一个使用该Sonnet模型生成响应的函数：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 定义工作流节点函数 --- def generate_joke(state: State) -> dict[str, str]: """ 基于当前状态中的主题信息生成笑话的节点函数 该函数从状态中读取\'topic\'字段，使用LLM生成相应的笑话内容， 并返回用于更新状态中\'joke\'字段的字典 参数: state: 包含主题信息的图当前状态 返回值: 包含\'joke\'键的字典，用于更新状态 """ # 从状态中提取主题信息 topic = state["topic"] print(f"正在生成关于{topic}的笑话") # 调用语言模型生成笑话内容 msg = llm.invoke(f"Write a short joke about {topic}") # 返回生成的笑话用于状态更新 return {"joke": msg.content}\n```\n\n该函数的核心功能是返回包含生成响应（笑话内容）的字典结构。\n\n现在，利用StateGraph可以便捷地构建和编译图结构。让我们继续实现这一过程：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 图结构的构建与编译 --- # 使用预定义的State模式初始化StateGraph实例 workflow = StateGraph(State) # 将\'generate_joke\'函数作为节点添加到图中 workflow.add_node("generate_joke", generate_joke) # 定义工作流的执行路径： # 图从START入口点开始，流向\'generate_joke\'节点 workflow.add_edge(START, "generate_joke") # \'generate_joke\'节点完成后，图执行结束 workflow.add_edge("generate_joke", END) # 将工作流编译为可执行的链式结构 chain = workflow.compile() # --- 图结构可视化 --- # 显示编译后工作流图的可视化表示 display(Image(chain.get_graph().draw_mermaid_png()))\n```\n\n现在可以执行这个工作流程：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 工作流执行 --- # 使用包含主题的初始状态调用编译后的图 # `invoke`方法执行从START节点到END节点的完整流程 joke_generator_state = chain.invoke({"topic": "cats"}) # --- 最终状态显示 --- # 打印执行后图的最终状态 # 将显示输入的\'topic\'和写入状态的输出\'joke\' console.print("\\n[bold blue]笑话生成器状态:[/bold blue]") pprint(joke_generator_state) #### 输出结果 #### { \'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\' }\n```\n\n执行结果返回的字典实际上代表了代理的笑话生成状态。这个简单的示例演示了如何向状态写入上下文信息的基本机制。\n\n开发者可以进一步了解检查点技术用于保存和恢复图状态，以及人机交互循环技术用于在继续执行之前暂停工作流以获取人工输入。\n\n### LangGraph中的内存写入机制\n\n虽然Scratchpad技术有助于代理在单个会话内进行工作，但在某些场景下，代理需要跨多个会话保持信息记忆。Reflexion技术引入了代理在每次交互后进行反思并重用自生成提示的概念，而Generative Agents则通过总结历史代理反馈来创建长期记忆机制。\n\n这些创新理念已被应用于ChatGPT、Cursor和Windsurf等主流产品中，这些系统能够从用户交互中自动创建长期记忆。\n\nLangGraph框架的内存机制包含两个关键组件：检查点技术在线程的每个步骤中保存图的状态，其中线程具有唯一标识符，通常代表一次完整的交互（类似ChatGPT中的单次对话）；长期内存技术允许跨线程保持特定上下文，可以保存单个文件（如用户配置文件）或记忆集合。该系统基于BaseStore接口实现，这是一个键值存储系统，可以在内存中使用（如本示例所示）或与LangGraph平台部署配合使用。\n\n现在让我们创建一个`InMemoryStore`实例，用于在本notebook的多个会话中使用：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.store.memory import InMemoryStore # --- 长期内存存储初始化 --- # 创建InMemoryStore实例，提供简单的非持久化键值存储系统 # 用于当前会话内的数据管理 store = InMemoryStore() # --- 命名空间定义 --- # 命名空间用于在存储中逻辑性地分组相关数据 # 这里使用元组表示分层命名空间结构 # 可能对应用户ID和应用程序上下文 namespace = ("rlm", "joke_generator") # --- 向内存存储写入数据 --- # 使用`put`方法将键值对保存到指定命名空间 # 该操作持久化前一步生成的笑话，使其可在不同会话或线程中检索 store.put( namespace, # 写入目标命名空间 "last_joke", # 数据条目的键标识符 {"joke": joke_generator_state["joke"]}, # 待存储的值 )\n```\n\n我们将在后续部分讨论如何从命名空间中选择上下文。目前可以使用search方法查看命名空间内的项目，以确认数据写入操作的成功：\n\n代码语言：javascript\n\n复制\n\n```\n # 搜索命名空间以查看所有存储项目 stored_items = list(store.search(namespace)) # 使用丰富格式显示存储的项目 console.print("\\n[bold green]内存中存储的项目:[/bold green]") pprint(stored_items) #### 输出结果 #### [ Item(namespace=[\'rlm\', \'joke_generator\'], key=\'last_joke\', value={\'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}, created_at=\'2025-07-24T02:12:25.936238+00:00\', updated_at=\'2025-07-24T02:12:25.936238+00:00\', score=None) ]\n```\n\n现在，让我们将前面实现的所有功能集成到LangGraph工作流中。\n\n工作流编译需要两个关键参数：`checkpointer`用于在线程的每个步骤保存图状态，`store`用于跨不同线程维护上下文。\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.checkpoint.memory import InMemorySaver from langgraph.store.base import BaseStore from langgraph.store.memory import InMemoryStore # 存储组件初始化 checkpointer = InMemorySaver() # 线程级状态持久化 memory_store = InMemoryStore() # 跨线程内存存储 def generate_joke(state: State, store: BaseStore) -> dict[str, str]: """生成具有内存感知能力的笑话 该增强版本在生成新笑话之前检查内存中的现有笑话 参数: state: 包含主题的当前状态 store: 用于持久化上下文的内存存储 返回值: 包含生成笑话的字典 """ # 检查内存中是否存在现有笑话 existing_jokes = list(store.search(namespace)) if existing_jokes: existing_joke = existing_jokes[0].value print(f"现有笑话: {existing_joke}") else: print("现有笑话: 无") # 基于主题生成新笑话 msg = llm.invoke(f"Write a short joke about {state[\'topic\']}") # 将新笑话存储到长期内存中 store.put(namespace, "last_joke", {"joke": msg.content}) # 返回待添加到状态的笑话 return {"joke": msg.content} # 构建具有内存功能的工作流 workflow = StateGraph(State) # 添加内存感知的笑话生成节点 workflow.add_node("generate_joke", generate_joke) # 连接工作流组件 workflow.add_edge(START, "generate_joke") workflow.add_edge("generate_joke", END) # 使用检查点和内存存储进行编译 chain = workflow.compile(checkpointer=checkpointer, store=memory_store)\n```\n\n现在可以执行更新后的工作流，测试启用内存功能后的运行效果：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用基于线程的配置执行工作流 config = {"configurable": {"thread_id": "1"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) # 使用丰富格式显示工作流结果 console.print("\\n[bold cyan]工作流结果 (线程 1):[/bold cyan]") pprint(joke_generator_state) #### 输出结果 #### 现有笑话: 无 工作流结果 (线程 1): {\'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}\n```\n\n由于这是线程1的首次执行，AI代理的内存中没有存储现有笑话，这完全符合新线程的预期行为。\n\n由于工作流使用检查点进行编译，现在可以查看图的最新状态：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 检索和检查图状态 --- # 使用`get_state`方法检索配置中指定线程的最新状态快照 # （在此案例中为线程"1"）。由于使用检查点编译了图，该操作成为可能 latest_state = chain.get_state(config) # --- 状态快照显示 --- # 将检索到的状态输出到控制台。StateSnapshot不仅包含数据（\'topic\'，\'joke\'） # 还包含执行元数据 console.print("\\n[bold magenta]最新图状态 (线程 1):[/bold magenta]") pprint(latest_state)\n```\n\n观察输出结果：\n\n代码语言：javascript\n\n复制\n\n```\n ### 最新状态输出 ### 最新图状态: StateSnapshot( values={ \'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\' }, next=(), config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f06833a-53a7-65a8-8001-548e412001c4\' } }, metadata={\'source\': \'loop\', \'step\': 1, \'parents\': {}}, created_at=\'2025-07-24T02:12:27.317802+00:00\', parent_config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f06833a-4a50-6108-8000-245cde0c2411\' } }, tasks=(), interrupts=() )\n```\n\n可以看到状态中记录了与代理的最后一次对话内容，即我们请求它讲述关于猫的笑话。\n\n现在使用不同的线程ID重新运行工作流：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用不同线程ID执行工作流 config = {"configurable": {"thread_id": "2"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) # 显示结果，展示跨线程的内存持久性 console.print("\\n[bold yellow]工作流结果 (线程 2):[/bold yellow]") pprint(joke_generator_state) #### 输出结果 #### 现有笑话: {\'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'} 工作流结果 (线程 2): {\'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}\n```\n\n可以验证来自第一个线程的笑话已成功保存到内存中。\n\n开发者可以进一步了解LangMem内存抽象技术和Ambient Agents课程，以获得LangGraph代理中内存管理的深入概述。\n\n### Scratchpad上下文选择机制\n\n从Scratchpad中选择上下文的具体方法取决于其实现架构：当Scratchpad作为工具实现时，代理可以通过工具调用直接读取其内容；当其作为代理运行时状态的组成部分时，开发者需要决定在每个执行步骤中与代理共享状态的哪些特定部分，这种方式提供了对暴露上下文内容的精细化控制能力。\n\n在前面的实现中，我们学习了如何向LangGraph状态对象写入数据。现在将探讨如何从状态中选择性地提取上下文信息，并将其传递给下游节点中的LLM调用。这种选择性方法使开发者能够精确控制LLM在执行过程中接收的上下文内容。\n\n代码语言：javascript\n\n复制\n\n```\n def generate_joke(state: State) -> dict[str, str]: """生成基于主题的初始笑话 参数: state: 包含主题信息的当前状态 返回值: 包含生成笑话的字典 """ msg = llm.invoke(f"Write a short joke about {state[\'topic\']}") return {"joke": msg.content} def improve_joke(state: State) -> dict[str, str]: """通过添加文字游戏元素改进现有笑话 该函数演示了从状态中选择上下文的过程——从状态中读取现有笑话 并基于此生成改进版本 参数: state: 包含原始笑话的当前状态 返回值: 包含改进笑话的字典 """ print(f"初始笑话: {state[\'joke\']}") # 从状态中选择笑话内容呈现给LLM msg = llm.invoke(f"Make this joke funnier by adding wordplay: {state[\'joke\']}") return {"improved_joke": msg.content}\n```\n\n为了增加系统复杂性，我们现在向代理添加两个工作流程：第一个是笑话生成流程（与之前相同），第二个是笑话改进流程（获取生成的笑话并对其进行优化）。\n\n这种配置将帮助我们理解Scratchpad选择机制在LangGraph中的运作方式。现在以与之前相同的方式编译此工作流并检查图结构：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建包含两个顺序节点的工作流 workflow = StateGraph(State) # 添加两个笑话处理节点 workflow.add_node("generate_joke", generate_joke) workflow.add_node("improve_joke", improve_joke) # 按顺序连接节点 workflow.add_edge(START, "generate_joke") workflow.add_edge("generate_joke", "improve_joke") workflow.add_edge("improve_joke", END) # 编译工作流 chain = workflow.compile() # 显示工作流可视化 display(Image(chain.get_graph().draw_mermaid_png()))\n```\n\n执行该工作流时的结果如下：\n\n代码语言：javascript\n\n复制\n\n```\n # 执行工作流以观察上下文选择的实际效果 joke_generator_state = chain.invoke({"topic": "cats"}) # 使用丰富格式显示最终状态 console.print("\\n[bold blue]最终工作流状态:[/bold blue]") pprint(joke_generator_state) #### 输出结果 #### 初始笑话: Why did the cat join a band? Because it wanted to be the purr-cussionist! 最终工作流状态: { \'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\' }\n```\n\n完成工作流执行后，我们可以继续进行内存选择步骤的实现。\n\n### 内存选择能力的实现\n\n当代理具备保存记忆的能力时，同样需要为当前任务选择相关的记忆内容。这种能力在以下场景中特别有用：情节记忆（展示期望行为的few-shot示例）、程序记忆（指导行为执行的指令）以及语义记忆（提供任务相关上下文的事实或关系信息）。\n\n一些代理系统使用预定义的文件来存储记忆内容：Claude Code使用`CLAUDE.md`文件，而Cursor和Windsurf使用"规则"文件来存储指令或示例。然而，当需要存储大量事实集合（语义记忆）时，选择过程变得更加复杂。\n\nChatGPT有时会检索不相关的记忆内容，正如Simon Willison所演示的案例，当ChatGPT错误地获取他的位置信息并将其注入图像生成过程中时，导致上下文感觉"不再属于用户本人"。为了改进选择精度，系统通常采用嵌入技术或知识图谱进行索引。\n\n在之前的部分中，我们在图节点中写入了`InMemoryStore`。现在可以使用get方法从中选择上下文，将相关状态信息引入工作流：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.store.memory import InMemoryStore # 初始化内存存储 store = InMemoryStore() # 定义用于组织记忆的命名空间 namespace = ("rlm", "joke_generator") # 将生成的笑话存储在内存中 store.put( namespace, # 组织用命名空间 "last_joke", # 键标识符 {"joke": joke_generator_state["joke"]} # 待存储的值 ) # 从内存中选择（检索）笑话内容 retrieved_joke = store.get(namespace, "last_joke").value # 显示检索到的上下文 console.print("\\n[bold green]从内存检索的上下文:[/bold green]") pprint(retrieved_joke) #### 输出结果 #### 从内存检索的上下文: {\'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}\n```\n\n系统成功地从内存中检索了正确的笑话内容。\n\n现在需要编写一个完整的`generate_joke`函数，该函数能够：获取当前状态（用于scratchpad上下文），利用内存（在执行笑话改进任务时获取历史笑话）。\n\n让我们实现这一功能：\n\n代码语言：javascript\n\n复制\n\n```\n # 初始化存储组件 checkpointer = InMemorySaver() memory_store = InMemoryStore() def generate_joke(state: State, store: BaseStore) -> dict[str, str]: """生成具有内存感知上下文选择能力的笑话 该函数演示了在生成新内容之前从内存中选择上下文的过程， 确保内容一致性并避免重复 参数: state: 包含主题的当前状态 store: 用于持久化上下文的内存存储 返回值: 包含生成笑话的字典 """ # 从内存中选择先前的笑话（如果存在） prior_joke = store.get(namespace, "last_joke") if prior_joke: prior_joke_text = prior_joke.value["joke"] print(f"先前笑话: {prior_joke_text}") else: print("先前笑话: 无") # 生成与先前笑话不同的新笑话 prompt = ( f"Write a short joke about {state[\'topic\']}, " f"but make it different from any prior joke you\'ve written: {prior_joke_text if prior_joke else \'None\'}" ) msg = llm.invoke(prompt) # 将新笑话存储在内存中供未来上下文选择使用 store.put(namespace, "last_joke", {"joke": msg.content}) return {"joke": msg.content}\n```\n\n现在可以以与之前相同的方式执行这个内存感知工作流：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建内存感知工作流 workflow = StateGraph(State) workflow.add_node("generate_joke", generate_joke) # 连接工作流 workflow.add_edge(START, "generate_joke") workflow.add_edge("generate_joke", END) # 使用检查点和内存存储进行编译 chain = workflow.compile(checkpointer=checkpointer, store=memory_store) # 使用第一个线程执行工作流 config = {"configurable": {"thread_id": "1"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) #### 输出结果 #### 先前笑话: 无\n```\n\n没有检测到先前的笑话，现在可以打印最新的状态结构：\n\n代码语言：javascript\n\n复制\n\n```\n # 获取图的最新状态 latest_state = chain.get_state(config) console.print("\\n[bold magenta]最新图状态:[/bold magenta]") pprint(latest_state)\n```\n\n输出结果：\n\n代码语言：javascript\n\n复制\n\n```\n #### 最新状态输出 #### StateSnapshot( values={ \'topic\': \'cats\', \'joke\': "Here\'s a new one:\\n\\nWhy did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!" }, next=(), config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f068357-cc8d-68cb-8001-31f64daf7bb6\' } }, metadata={\'source\': \'loop\', \'step\': 1, \'parents\': {}}, created_at=\'2025-07-24T02:25:38.457825+00:00\', parent_config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f068357-c459-6deb-8000-16ce383a5b6b\' } }, tasks=(), interrupts=() )\n```\n\n系统从内存中获取先前的笑话并将其传递给LLM进行改进：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用第二个线程执行工作流以演示内存持久性 config = {"configurable": {"thread_id": "2"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) #### 输出结果 #### 先前笑话: Here is a new one: Why did the cat join a band? Because it wanted to be the purr-cussionist!\n```\n\n系统已成功从内存中获取正确的笑话并按预期对其进行了改进。\n\n### LangGraph BigTool调用的技术优势\n\n在代理系统中，虽然工具的使用提高了功能性，但为代理提供过多工具可能导致选择困惑，特别是当工具描述存在重叠时。这种情况增加了模型选择正确工具的难度。\n\n一个有效的解决方案是在工具描述上应用RAG（检索增强生成）技术，仅基于语义相似性获取最相关的工具。Drew Breunig将这种方法称为"工具装备"策略。\n\n根据最新研究结果，这种方法能够将工具选择准确率提升3倍。\n\n对于工具选择任务，LangGraph Bigtool库提供了理想的解决方案。该库在工具描述上应用语义相似性搜索来选择最适合执行任务的工具。它利用LangGraph的长期内存存储机制，使代理能够搜索并检索适合特定问题的正确工具。\n\n让我们通过使用包含Python内置数学库所有函数的代理来理解`langgraph-bigtool`的工作原理：\n\n代码语言：javascript\n\n复制\n\n```\n import math # 从`math`内置库收集函数 all_tools = [] for function_name in dir(math): function = getattr(math, function_name) if not isinstance( function, types.BuiltinFunctionType ): continue # 这是`math`库的特定要求 if tool := convert_positional_only_function_to_tool( function ): all_tools.append(tool)\n```\n\n首先将Python数学模块的所有函数收集到列表中。接下来需要将这些工具描述转换为向量嵌入，以便代理能够执行语义相似性搜索。\n\n为此，我们将使用嵌入模型，在本案例中采用OpenAI的文本嵌入模型：\n\n代码语言：javascript\n\n复制\n\n```\n # 创建工具注册表。这是一个将标识符映射到工具实例的字典 tool_registry = { str(uuid.uuid4()): tool for tool in all_tools } # 在LangGraph存储中索引工具名称和描述 # 此处使用简单的内存存储 embeddings = init_embeddings("openai:text-embedding-3-small") store = InMemoryStore( index={ "embed": embeddings, "dims": 1536, "fields": ["description"], } ) for tool_id, tool in tool_registry.items(): store.put( ("tools",), tool_id, { "description": f"{tool.name}: {tool.description}", }, )\n```\n\n每个函数都被分配唯一标识符，并将这些函数结构化为标准格式。这种结构化格式确保函数能够轻松转换为嵌入向量，以支持语义搜索功能。\n\n现在让我们可视化代理，观察在所有数学函数都已嵌入并准备进行语义搜索的情况下系统的表现：\n\n代码语言：javascript\n\n复制\n\n```\n # 初始化代理 builder = create_agent(llm, tool_registry) agent = builder.compile(store=store) agent\n```\n\n现在可以使用简单查询调用代理，观察工具调用代理如何选择和使用最相关的数学函数来回答问题：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入格式化和显示消息的实用函数 from utils import format_messages # 为代理定义查询 # 该查询要求代理使用其数学工具之一计算反余弦值 query = "Use available tools to calculate arc cosine of 0.5." # 使用查询调用代理。代理将搜索其工具， # 根据查询的语义选择\'acos\'工具并执行 result = agent.invoke({"messages": query}) # 格式化并显示代理执行的最终消息 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── Human ───────────────┐ │ Use available tools to calculate │ │ arc cosine of 0.5. │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ I will search for a tool to calculate│ │ the arc cosine of 0.5. │ │ │ │ 🔧 Tool Call: retrieve_tools │ │ Args: { │ │ "query": "arc cosine arccos │ │ inverse cosine trig" │ │ } │ └──────────────────────────────────────┘ ┌────────────── 🔧 Tool Output ────────┐ │ Available tools: [\'acos\', \'acosh\'] │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ Perfect! I found the `acos` function │ │ which calculates the arc cosine. │ │ Now I will use it to calculate the │ │ arc │ │ cosine of 0.5. │ │ │ │ 🔧 Tool Call: acos │ │ Args: { "x": 0.5 } │ │ └──────────────────────────────────────┘ ┌────────────── 🔧 Tool Output ────────┐ │ 1.0471975511965976 │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ The arc cosine of 0.5 is ≈**1.047** │ │ radians. │ │ │ │ ✔ Check: cos(π/3)=0.5, π/3≈1.047 rad │ │ (60°). │ └──────────────────────────────────────┘\n```\n\n可以观察到AI代理如何高效地调用正确的工具。\n\n### 基于上下文工程的RAG系统实现\n\nRAG（检索增强生成）是一个复杂的技术领域，代码代理系统代表了生产环境中代理式RAG的最佳实践案例。\n\n在实际应用中，RAG往往是上下文工程面临的核心技术挑战。正如Windsurf的Varun所指出的：索引处理不等同于上下文检索。基于抽象语法树（AST）分块的嵌入搜索在小规模代码库中表现良好，但随着代码库规模增长会出现性能衰减。我们需要混合检索策略：结合grep模式搜索、文件搜索、知识图谱链接以及基于相关性的重新排序技术。\n\nLangGraph框架提供了丰富的教程和视频资源，帮助开发者将RAG技术集成到代理系统中。通常的做法是构建一个检索工具，该工具可以使用上述任何RAG技术组合。\n\n为了演示这一过程，我们将使用Lilian Weng优秀技术博客中的最新文章为RAG系统获取文档数据。\n\n首先使用`WebBaseLoader`工具获取页面内容：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入WebBaseLoader用于从URL获取文档 from langchain_community.document_loaders import WebBaseLoader # 定义Lilian Weng博客文章的URL列表 urls = [ "https://lilianweng.github.io/posts/2025-05-01-thinking/", "https://lilianweng.github.io/posts/2024-11-28-reward-hacking/", "https://lilianweng.github.io/posts/2024-07-07-hallucination/", "https://lilianweng.github.io/posts/2024-04-12-diffusion-video/", ] # 使用列表推导式从指定URL加载文档 # 为每个URL创建WebBaseLoader实例并调用其load()方法 docs = [WebBaseLoader(url).load() for url in urls]\n```\n\nRAG系统中存在多种数据分块策略，适当的分块技术对于实现有效检索至关重要。\n\n在本实现中，我们将在索引获取的文档到向量存储之前，将其分割为较小的片段。我们采用递归分块技术配合重叠片段的直接方法，在保持片段可管理性的同时，在片段之间保留上下文连续性，以优化嵌入和检索效果：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入用于文档分块的文本分割器 from langchain_text_splitters import RecursiveCharacterTextSplitter # 展平文档列表。WebBaseLoader为每个URL返回文档列表， # 因此得到嵌套列表结构。此推导式将其合并为单一列表 docs_list = [item for sublist in docs for item in sublist] # 初始化文本分割器。该工具将文档分割为指定大小的较小片段， # 片段间保持一定重叠以维持上下文连续性 text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder( chunk_size=2000, chunk_overlap=50 ) # 将文档分割为片段 doc_splits = text_splitter.split_documents(docs_list)\n```\n\n完成文档分割后，可以将其索引到向量存储中进行语义搜索：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入创建内存向量存储所需的类 from langchain_core.vectorstores import InMemoryVectorStore # 从文档片段创建内存向量存储 # 使用前面创建的\'doc_splits\'和之前初始化的\'embeddings\'模型 # 生成文本片段的向量表示 vectorstore = InMemoryVectorStore.from_documents( documents=doc_splits, embedding=embeddings ) # 从向量存储创建检索器 # 检索器提供基于查询搜索相关文档的接口 retriever = vectorstore.as_retriever()\n```\n\n接下来需要创建一个可在代理中使用的检索器工具：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入创建检索器工具的函数 from langchain.tools.retriever import create_retriever_tool # 从向量存储检索器创建检索器工具 # 该工具使代理能够基于查询从博客文章中搜索和检索相关文档 retriever_tool = create_retriever_tool( retriever, "retrieve_blog_posts", "Search and return information about Lilian Weng blog posts.", ) # 以下代码演示了直接调用工具的方法 # 虽然对代理执行流程非必需，但对测试很有用 # retriever_tool.invoke({"query": "types of reward hacking"})\n```\n\n现在可以实现一个能够从工具中选择上下文的代理系统：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用工具增强LLM功能 tools = [retriever_tool] tools_by_name = {tool.name: tool for tool in tools} llm_with_tools = llm.bind_tools(tools)\n```\n\n对于基于RAG的解决方案，需要创建清晰的系统提示来指导代理行为。该提示充当核心指令集：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.graph import MessagesState from langchain_core.messages import SystemMessage, ToolMessage from typing_extensions import Literal rag_prompt = """您是一个专门从Lilian Weng技术博客文章系列中检索信息的智能助手。 在使用检索工具收集上下文之前，请与用户明确研究范围。对获取的任何上下文内容进行分析， 并持续检索直到获得足够的上下文信息来回答用户的研究请求。"""\n```\n\n接下来定义图的核心节点。需要两个主要节点：`llm_call`作为代理的决策中心，接收当前对话历史（用户查询加先前工具输出），然后决定下一步行动——调用工具或生成最终答案；`tool_node`作为代理的执行组件，执行`llm_call`请求的工具调用，并将工具结果返回给代理。\n\n代码语言：javascript\n\n复制\n\n```\n # --- 定义代理节点 --- def llm_call(state: MessagesState): """LLM决策是否调用工具或生成最终答案""" # 将系统提示添加到当前消息状态 messages_with_prompt = [SystemMessage(content=rag_prompt)] + state["messages"] # 使用增强消息列表调用LLM response = llm_with_tools.invoke(messages_with_prompt) # 返回LLM响应以添加到状态 return {"messages": [response]} def tool_node(state: dict): """执行工具调用并返回观察结果""" # 获取包含工具调用的最后一条消息 last_message = state["messages"][-1] # 执行每个工具调用并收集结果 result = [] for tool_call in last_message.tool_calls: tool = tools_by_name[tool_call["name"]] observation = tool.invoke(tool_call["args"]) result.append(ToolMessage(content=str(observation), tool_call_id=tool_call["id"])) # 将工具输出作为消息返回 return {"messages": result}\n```\n\n需要一种方法来控制代理流程，决定应该调用工具还是已完成任务。为此创建条件边函数`should_continue`：该函数检查LLM的最后一条消息是否包含工具调用；如果包含，图路由到`tool_node`；否则执行结束。\n\n代码语言：javascript\n\n复制\n\n```\n # --- 定义条件边 --- def should_continue(state: MessagesState) -> Literal["Action", END]: """根据LLM是否进行工具调用决定下一步""" last_message = state["messages"][-1] # 如果LLM进行了工具调用，路由到tool_node if last_message.tool_calls: return "Action" # 否则结束工作流 return END\n```\n\n现在可以构建工作流并编译图：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建工作流 agent_builder = StateGraph(MessagesState) # 添加节点 agent_builder.add_node("llm_call", llm_call) agent_builder.add_node("environment", tool_node) # 添加连接节点的边 agent_builder.add_edge(START, "llm_call") agent_builder.add_conditional_edges( "llm_call", should_continue, { # should_continue返回的名称 : 下一个访问节点的名称 "Action": "environment", END: END, }, ) agent_builder.add_edge("environment", "llm_call") # 编译代理 agent = agent_builder.compile() # 显示代理结构 display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n```\n\n图结构显示了清晰的循环流程：代理启动并调用LLM；基于LLM的决策，系统要么执行动作（调用检索器工具）并循环回来，要么完成执行并提供答案。\n\n让我们测试RAG代理。我们将询问关于"奖励破解"的具体问题，该问题只能通过从索引的博客文章中检索信息来回答：\n\n代码语言：javascript\n\n复制\n\n```\n # 定义用户查询 query = "What are the types of reward hacking discussed in the blogs?" # 使用查询调用代理 result = agent.invoke({"messages": [("user", query)]}) # --- 显示最终消息 --- # 格式化并打印对话流程 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── Human ───────────────┐ │ Clarify scope: I want types of │ │ reward hacking from Lilian Weng\'s │ │ blog on RL. │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ Fetching context from her posts... │ └──────────────────────────────────────┘ ┌────────────── 🔧 Tool Output ────────┐ │ She lists 3 main types of reward │ │ hacking in RL: │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ 1. **Spec gaming** – Exploit reward │ │ loopholes, not real goal. │ │ │ │ 2. **Reward tampering** – Change or │ │ hack reward signals. │ │ │ │ 3. **Wireheading** – Self-stimulate │ │ reward instead of task. │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ These can cause harmful, unintended │ │ behaviors in RL agents. │ └──────────────────────────────────────┘\n```\n\n如结果所示，代理正确识别出需要使用检索工具，然后成功从博客文章中检索相关上下文，并基于该信息提供了详细而准确的答案。这完美展示了通过RAG实现的上下文工程如何创建强大而知识渊博的代理系统。\n\n### 知识型代理的压缩策略优化\n\n代理交互过程可能跨越数百轮对话并涉及令牌密集型工具调用。总结技术是管理这种复杂性的常用方法。\n\n具体应用案例包括：Claude Code在上下文窗口超过95%容量时使用"自动压缩"功能，对整个用户-代理交互历史进行总结；总结技术可以使用递归或分层总结等策略来压缩代理执行轨迹。\n\n开发者还可以在特定节点添加总结功能：在令牌密集型工具调用之后（例如搜索工具执行后）；在代理间边界处进行知识转移，如Cognition在Devin中使用微调模型执行的操作。\n\nLangGraph作为低级编排框架，为开发者提供全面控制能力：将代理设计为节点集合；在每个节点内明确定义逻辑；在节点间传递共享状态对象。\n\n这种架构使得以不同方式压缩上下文变得简单直接。例如，开发者可以使用消息列表作为代理状态，并利用内置工具对其进行总结。\n\n我们将基于之前编码的RAG工具调用代理，添加对话历史总结功能。\n\n首先需要扩展图状态以包含最终总结字段：\n\n代码语言：javascript\n\n复制\n\n```\n # 定义包含总结字段的扩展状态 class State(MessagesState): """包含用于上下文压缩的总结字段的扩展状态类""" summary: str\n```\n\n接下来定义专门用于总结的提示，同时保留之前的RAG提示：\n\n代码语言：javascript\n\n复制\n\n```\n # 定义总结提示 summarization_prompt = """请总结完整的聊天历史和所有工具反馈信息， 提供用户询问内容和代理执行操作的概要描述。"""\n```\n\n现在创建`summary_node`节点：该节点将在代理工作完成时被触发，生成整个交互过程的简洁总结；`llm_call`和`tool_node`保持不变。\n\n代码语言：javascript\n\n复制\n\n```\n def summary_node(state: MessagesState) -> dict: """ 生成对话和工具交互的总结 参数: state: 包含消息历史的图当前状态 返回值: 包含键"summary"和生成总结字符串的字典，用于更新状态 """ # 将总结系统提示添加到消息历史前端 messages = [SystemMessage(content=summarization_prompt)] + state["messages"] # 调用语言模型生成总结 result = llm.invoke(messages) # 返回存储在状态\'summary\'字段中的总结 return {"summary": result.content}\n```\n\n条件边`should_continue`现在需要决定是调用工具还是继续到新的`summary_node`：\n\n代码语言：javascript\n\n复制\n\n```\n def should_continue(state: MessagesState) -> Literal["Action", "summary_node"]: """根据LLM是否进行工具调用确定下一步骤""" last_message = state["messages"][-1] # 如果LLM进行了工具调用，执行工具 if last_message.tool_calls: return "Action" # 否则进行总结 return "summary_node"\n```\n\n构建在末尾包含总结步骤的图结构：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建RAG代理工作流 agent_builder = StateGraph(State) # 向工作流添加节点 agent_builder.add_node("llm_call", llm_call) agent_builder.add_node("Action", tool_node) agent_builder.add_node("summary_node", summary_node) # 定义工作流边 agent_builder.add_edge(START, "llm_call") agent_builder.add_conditional_edges( "llm_call", should_continue, { "Action": "Action", "summary_node": "summary_node", }, ) agent_builder.add_edge("Action", "llm_call") agent_builder.add_edge("summary_node", END) # 编译代理 agent = agent_builder.compile() # 显示代理工作流 display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n```\n\n现在使用需要获取大量上下文的查询来测试系统：\n\n代码语言：javascript\n\n复制\n\n```\n from rich.markdown import Markdown query = "Why does RL improve LLM reasoning according to the blogs?" result = agent.invoke({"messages": [("user", query)]}) # 打印给用户的最终消息 format_message(result[\'messages\'][-1]) # 打印生成的总结 Markdown(result["summary"]) #### 输出结果 #### 用户询问了为什么强化学习（RL）能够改进LLM推理...\n```\n\n该实现效果良好，但消耗了115k个令牌！这是具有令牌密集型工具调用的代理系统面临的常见挑战。\n\n更高效的方法是在上下文进入代理主要scratchpad之前进行压缩。让我们更新RAG代理以实时总结工具调用输出。\n\n首先为这个特定任务创建新提示：\n\n代码语言：javascript\n\n复制\n\n```\n tool_summarization_prompt = """您将收到来自RAG系统的文档内容。 请总结这些文档，确保保留所有相关和关键信息。 您的目标是将文档大小（令牌数量）减少到更易管理的规模。"""\n```\n\n接下来修改`tool_node`以包含总结步骤：\n\n代码语言：javascript\n\n复制\n\n```\n def tool_node_with_summarization(state: dict): """执行工具调用然后总结输出""" result = [] for tool_call in state["messages"][-1].tool_calls: tool = tools_by_name[tool_call["name"]] observation = tool.invoke(tool_call["args"]) # 总结文档内容 summary_msg = llm.invoke([ SystemMessage(content=tool_summarization_prompt), ("user", str(observation)) ]) result.append(ToolMessage(content=summary_msg.content, tool_call_id=tool_call["id"])) return {"messages": result}\n```\n\n现在`should_continue`边可以简化，因为不再需要最终的`summary_node`：\n\n代码语言：javascript\n\n复制\n\n```\n def should_continue(state: MessagesState) -> Literal["Action", END]: """决定应该继续循环还是停止""" if state["messages"][-1].tool_calls: return "Action" return END\n```\n\n构建和编译这个更高效的代理：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建工作流 agent_builder = StateGraph(MessagesState) # 添加节点 agent_builder.add_node("llm_call", llm_call) agent_builder.add_node("Action", tool_node_with_summarization) # 添加连接节点的边 agent_builder.add_edge(START, "llm_call") agent_builder.add_conditional_edges( "llm_call", should_continue, { "Action": "Action", END: END, }, ) agent_builder.add_edge("Action", "llm_call") # 编译代理 agent = agent_builder.compile() # 显示代理结构 display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n```\n\n使用相同查询测试并观察差异：\n\n代码语言：javascript\n\n复制\n\n```\n query = "Why does RL improve LLM reasoning according to the blogs?" result = agent.invoke({"messages": [("user", query)]}) format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── user ───────────────┐ │ Why does RL improve LLM reasoning?│ │ According to the blogs? │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ Searching Lilian Weng\'s blog for │ │ how RL improves LLM reasoning... │ │ │ │ 🔧 Tool Call: retrieve_blog_posts │ │ Args: { │ │ "query": "Reinforcement Learning │ │ for LLM reasoning" │ │ } │ └───────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ Lilian Weng explains RL helps LLM │ │ reasoning by training on rewards │ │ for each reasoning step (Process- │ │ based Reward Models). This guides │ │ the model to think step-by-step, │ │ improving coherence and logic. │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ RL improves LLM reasoning by │ │ rewarding stepwise thinking via │ │ PRMs, encouraging coherent, │ │ logical argumentation over final │ │ answers. It helps the model self- │ │ correct and explore better paths. │ └───────────────────────────────────┘\n```\n\n这次代理仅使用了60k个令牌。\n\n这个简单的改进将令牌使用量减少了近一半，使代理系统更加高效和经济。\n\n### 基于子代理架构的上下文隔离技术\n\n隔离上下文的常见策略是将其分布到多个子代理中。OpenAI Swarm库专门为这种"关注点分离"架构设计，每个代理使用专属的工具、指令和上下文窗口来管理特定的子任务。\n\nAnthropic的多代理研究系统显示，具有隔离上下文的多代理架构相比单代理系统性能提升90.2%，这是因为每个子代理专注于更窄的特定子任务。\n\n子代理使用独立的上下文窗口并行操作，同时探索问题的不同方面。\n\n然而，多代理系统面临一些技术挑战：令牌使用量显著增加（有时比单代理聊天多15倍的令牌消耗）；需要精心设计的提示工程来规划子代理工作；协调子代理可能变得复杂。\n\nLangGraph框架对多代理配置提供全面支持。常见的实现方法是监督者架构，这也是Anthropic多代理研究员采用的方案。监督者将任务委托给子代理，每个子代理在独立的上下文窗口中运行。\n\n让我们构建一个管理两个专门代理的简单监督者系统：`math_expert`处理数学计算任务，`research_expert`负责搜索和提供研究信息。\n\n监督者将根据查询内容决定调用哪个专家，并在LangGraph工作流中协调他们的响应：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.prebuilt import create_react_agent from langgraph_supervisor import create_supervisor # --- 为每个代理定义专用工具 --- def add(a: float, b: float) -> float: """执行两个数字的加法运算""" return a + b def multiply(a: float, b: float) -> float: """执行两个数字的乘法运算""" return a * b def web_search(query: str) -> str: """模拟网络搜索函数，返回FAANG公司员工数据""" return ( "Here are the headcounts for each of the FAANG companies in 2024:\\n" "1. **Facebook (Meta)**: 67,317 employees.\\n" "2. **Apple**: 164,000 employees.\\n" "3. **Amazon**: 1,551,000 employees.\\n" "4. **Netflix**: 14,000 employees.\\n" "5. **Google (Alphabet)**: 181,269 employees." )\n```\n\n现在创建专门的代理和管理它们的监督者：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 创建具有隔离上下文的专门代理 --- math_agent = create_react_agent( model=llm, tools=[add, multiply], name="math_expert", prompt="您是数学专家。每次只使用一个工具执行计算。" ) research_agent = create_react_agent( model=llm, tools=[web_search], name="research_expert", prompt="您是具有网络搜索能力的世界级研究专家。请不要执行数学运算。" ) # --- 创建用于协调代理的监督者工作流 --- workflow = create_supervisor( [research_agent, math_agent], model=llm, prompt=( "您是团队监督者，负责管理一个研究专家和一个数学专家。" "请将任务委托给适当的代理来回答用户查询。" "对于时事或事实性问题，使用research_agent。" "对于数学问题，使用math_agent。" ) ) # 编译多代理应用程序 app = workflow.compile()\n```\n\n执行工作流并观察监督者如何委托任务：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 执行多代理工作流 --- result = app.invoke({ "messages": [ { "role": "user", "content": "what\'s the combined headcount of the FAANG companies in 2024?" } ] }) # 格式化并显示结果 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── user ───────────────┐ │ Learn more about LangGraph Swarm │ │ and multi-agent systems. │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ Fetching details on LangGraph │ │ Swarm and related resources... │ └───────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ **LangGraph Swarm** │ │ Repo: │ │ https://github.com/langchain-ai/ │ │ langgraph-swarm-py │ │ │ │ • Python library for multi-agent │ │ AI with dynamic collaboration. │ │ • Agents hand off control based │ │ on specialization, keeping │ │ conversation context. │ │ • Supports custom handoffs, │ │ streaming, memory, and human- │ │ in-the-loop. │ │ • Install: │ │ `pip install langgraph-swarm` │ └───────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ **Videos on multi-agent systems** │ │ 1. https://youtu.be/4nZl32FwU-o │ │ 2. https://youtu.be/JeyDrn1dSUQ │ │ 3. https://youtu.be/B_0TNuYi56w │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ LangGraph Swarm makes it easy to │ │ build context-aware multi-agent │ │ systems. Check videos for deeper │ │ insights on multi-agent behavior. │ └───────────────────────────────────┘\n```\n\n在此案例中，监督者正确地为每个任务隔离了上下文——将研究查询分配给研究专家，将数学问题分配给数学专家——展示了有效的上下文隔离机制。\n\n### 基于沙盒环境的隔离技术\n\nHuggingFace的深度研究员展示了一种创新的上下文隔离方法。大多数代理使用工具调用API，这些API返回JSON格式的参数来运行搜索API等工具并获取结果。\n\nHuggingFace采用CodeAgent技术，编写代码来调用工具。这些代码在安全沙盒中执行，代码运行结果被发送回LLM。\n\n这种方法将大容量数据（如图像或音频）保持在LLM令牌限制之外。HuggingFace解释道：\n\n代码代理允许更好的状态处理...需要稍后存储这个图像/音频/其他内容？只需将其保存为状态中的变量并稍后使用。\n\n在LangGraph中使用沙盒技术非常简单。LangChain沙盒使用Pyodide（编译为WebAssembly的Python）安全地运行不受信任的Python代码。开发者可以将其作为工具添加到任何LangGraph代理中。\n\n注意：需要安装Deno。安装地址：https://docs.deno.com/runtime/getting\\_started/installation/\n\n代码语言：javascript\n\n复制\n\n```\n from langchain_sandbox import PyodideSandboxTool from langgraph.prebuilt import create_react_agent # 创建具有网络访问权限的沙盒工具以支持包安装 tool = PyodideSandboxTool(allow_net=True) # 使用沙盒工具创建ReAct代理 agent = create_react_agent(llm, tools=[tool]) # 使用沙盒执行数学查询 result = await agent.ainvoke( {"messages": [{"role": "user", "content": "what\'s 5 + 7?"}]}, ) # 格式化并显示结果 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── user ───────────────┐ │ what\'s 5 + 7? │ └──────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ I can solve this by executing │ │ Python code in the sandbox. │ │ │ │ 🔧 Tool Call: pyodide_sandbox │ │ Args: { │ │ "code": "print(5 + 7)" │ │ } │ └──────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ 12 │ └──────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ The answer is 12. │ └──────────────────────────────────┘\n```\n\n### LangGraph中的状态隔离机制\n\n代理的运行时状态对象提供了另一种优秀的上下文隔离方式，其工作原理类似于沙盒技术。开发者可以使用数据模式（如Pydantic模型）设计状态结构，该模式具有用于存储上下文的不同字段。\n\n例如，一个字段（如`messages`）在每轮交互中都向LLM展示，而其他字段保持信息隔离状态，直到需要时才暴露。\n\nLangGraph围绕状态对象构建，使开发者能够创建自定义状态模式并在代理工作流中访问其字段。\n\n例如，开发者可以将工具调用结果存储在特定字段中，使其对LLM保持隐藏状态，直到必要时才暴露。在本文的notebook示例中已经展示了许多这样的实现案例。\n\n### 总结\n\n通过本文的深入分析，我们系统性地探讨了基于LangChain和LangGraph的AI代理上下文工程优化技术：\n\n我们利用LangGraph的`StateGraph`创建了短期内存的"scratchpad"机制和长期内存的`InMemoryStore`系统，使代理能够有效存储和检索信息。我们演示了如何从代理状态和长期内存中选择性提取相关信息，包括使用检索增强生成（RAG）技术来查找特定知识，以及利用`langgraph-bigtool`从众多选项中选择合适的工具。\n\n为了管理长对话和令牌密集型工具输出，实现了总结技术。展示了如何实时压缩RAG结果，使代理更高效并减少令牌消耗。\n\n通过构建具有监督者架构的多代理系统来探索上下文分离技术，该系统将任务委托给专门的子代理，以及通过使用沙盒环境来运行代码。\n\n这些技术统称为"上下文工程"——一种通过精心管理AI代理的工作内存（上下文）来改进AI代理性能的策略，使它们能够更高效、更准确地处理复杂的长期运行任务。\n\n随着AI代理技术的不断发展，上下文工程将成为构建高性能、可扩展AI系统的关键技术基础。\n\n作者：Fareed Khan\n\n---\n\n本文参与\xa0[腾讯云自媒体同步曝光计划](/developer/support-plan)，分享自微信公众号。\n\n原始发表：2025-07-26，如有侵权请联系\xa0[cloudcommunity@tencent.com](mailto:cloudcommunity@tencent.com) 删除\n\n[代理](/developer/tag/17225)\n\n[工具](/developer/tag/17276)\n\n[内存管理](/developer/tag/17383)\n\n[性能](/developer/tag/17525)\n\n[优化](/developer/tag/17554)\n\n本文分享自 DeepHub IMBA 微信公众号，前往查看\n\n如有侵权，请联系 [cloudcommunity@tencent.com](mailto:cloudcommunity@tencent.com) 删除。\n\n本文参与\xa0[腾讯云自媒体同步曝光计划](/developer/support-plan)\xa0 ，欢迎热爱写作的你一起参与！\n\n[代理](/developer/tag/17225)\n\n[工具](/developer/tag/17276)\n\n[内存管理](/developer/tag/17383)\n\n[性能](/developer/tag/17525)\n\n[优化](/developer/tag/17554)\n\n登录后参与评论\n\n登录 后参与评论\n\n* 上下文工程的理论基础\n\n* 基于LangGraph的Scratchpad实现机制\n\n* LangGraph中的内存写入机制\n\n* Scratchpad上下文选择机制\n\n* 内存选择能力的实现\n\n* LangGraph BigTool调用的技术优势\n\n* 基于上下文工程的RAG系统实现\n\n* 知识型代理的压缩策略优化\n\n* 基于子代理架构的上下文隔离技术\n\n* 基于沙盒环境的隔离技术\n\n* LangGraph中的状态隔离机制\n\n* 总结\n\n[AI驱动 智领未来](https://cloud.tencent.com/act/pro/double12-2025?from=21344&from_column=21344)\n\n* ### 社区\n\n  + [技术文章](/developer/column)\n  + [技术问答](/developer/ask)\n  + [技术沙龙](/developer/salon)\n  + [技术视频](/developer/video)\n  + [学习中心](/developer/learning)\n  + [技术百科](/developer/techpedia)\n  + [技术专区](/developer/zone/list)\n* ### 活动\n\n  + [自媒体同步曝光计划](/developer/support-plan)\n  + [邀请作者入驻](/developer/support-plan-invitation)\n  + [自荐上首页](/developer/article/1535830)\n  + [技术竞赛](/developer/competition)\n* ### 圈层\n\n  + [腾讯云最具价值专家](/tvp)\n  + [腾讯云架构师技术同盟](/developer/program/tm)\n  + [腾讯云创作之星](/developer/program/tci)\n  + [腾讯云TDP](/developer/program/tdp)\n* ### 关于\n\n  + [社区规范](/developer/article/1006434)\n  + [免责声明](/developer/article/1006435)\n  + [联系我们](mailto:cloudcommunity@tencent.com)\n  + [友情链接](/developer/friendlink)\n  + [MCP广场开源版权声明](/developer/article/2537547)\n\n### 腾讯云开发者\n\n### 热门产品\n\n* [域名注册](/product/domain?from=20064&from_column=20064)\n* [云服务器](/product/cvm?from=20064&from_column=20064)\n* [区块链服务](/product/tbaas?from=20064&from_column=20064)\n* [消息队列](/product/message-queue-catalog?from=20064&from_column=20064)\n* [网络加速](/product/ecdn?from=20064&from_column=20064)\n* [云数据库](/product/tencentdb-catalog?from=20064&from_column=20064)\n* [域名解析](/product/dns?from=20064&from_column=20064)\n* [云存储](/product/cos?from=20064&from_column=20064)\n* [视频直播](/product/css?from=20064&from_column=20064)\n\n### 热门推荐\n\n* [人脸识别](/product/facerecognition?from=20064&from_column=20064)\n* [腾讯会议](/product/tm?from=20064&from_column=20064)\n* [企业云](/act/pro/enterprise2022?from=20064&from_column=20064)\n* [CDN加速](/product/cdn?from=20064&from_column=20064)\n* [视频通话](/product/trtc?from=20064&from_column=20064)\n* [图像分析](/product/imagerecognition?from=20064&from_column=20064)\n* [MySQL 数据库](/product/cdb?from=20064&from_column=20064)\n* [SSL 证书](/product/ssl?from=20064&from_column=20064)\n* [语音识别](/product/asr?from=20064&from_column=20064)\n\n### 更多推荐\n\n* [数据安全](/solution/data_protection?from=20064&from_column=20064)\n* [负载均衡](/product/clb?from=20064&from_column=20064)\n* [短信](/product/sms?from=20064&from_column=20064)\n* [文字识别](/product/ocr?from=20064&from_column=20064)\n* [云点播](/product/vod?from=20064&from_column=20064)\n* [大数据](/product/bigdata-class?from=20064&from_column=20064)\n* [小程序开发](/solution/la?from=20064&from_column=20064)\n* [网站监控](/product/tcop?from=20064&from_column=20064)\n* [数据迁移](/product/cdm?from=20064&from_column=20064)\n\nCopyright © 2013 - 2026Tencent Cloud. All Rights Reserved. 腾讯云 版权所有\n\n[深圳市腾讯计算机系统有限公司](https://qcloudimg.tencent-cloud.cn/raw/986376a919726e0c35e96b311f54184d.jpg)\xa0ICP备案/许可证号：[粤B2-20090059](https://beian.miit.gov.cn/#/Integrated/index)[粤公网安备44030502008569号](https://beian.mps.gov.cn/#/query/webSearch?code=44030502008569)\n\n[腾讯云计算（北京）有限责任公司](https://qcloudimg.tencent-cloud.cn/raw/a2390663ee4a95ceeead8fdc34d4b207.jpg) 京ICP证150476号 | \xa0[京ICP备11018762号](https://beian.miit.gov.cn/#/Integrated/index)\n\n[问题归档](/developer/ask/archives.html)[专栏文章](/developer/column/archives.html)[快讯文章归档](/developer/news/archives.html)[关键词归档](/developer/information/all.html)[开发者手册归档](/developer/devdocs/archives.html)[开发者手册 Section 归档](/developer/devdocs/sections_p1.html)\n\nCopyright © 2013 - 2026Tencent Cloud.\n\nAll Rights Reserved. 腾讯云 版权所有\n\n登录 后参与评论', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cloud.tencent.com/developer/article/2557090', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9995005, 'save_path': None}}, {'paper_id': '', 'title': 'AI Agent 实战指南：LangChain/LangGraph 框架深度解析与 ...', 'authors': [], 'abstract': '[代码改变世界](https://www.cnblogs.com/)\n\n\n* [Cnblogs](https://www.cnblogs.com/)\n* [Dashboard](https://i.cnblogs.com/)\n* [Login](https://account.cnblogs.com/signin?returnUrl=https://www.cnblogs.com/tlnshuju/)\n\n* [Home](https://www.cnblogs.com/tlnshuju/)\n* [Contact](https://msg.cnblogs.com/send/tlnshuju)\n* [Gallery](https://www.cnblogs.com/tlnshuju/gallery.html)\n* [Subscribe](javascript:void(0);)\n* [RSS](https://www.cnblogs.com/tlnshuju/rss/)\n\n# [tlnshuju](https://www.cnblogs.com/tlnshuju/)\n\n## [实用指南：AI Agent 实战指南：LangChain/LangGraph 框架深度解析与项目落地](https://www.cnblogs.com/tlnshuju/p/19353187 "发布于 2025-12-15 16:11")\n\n2025-12-15 16:11\xa0 [tlnshuju](https://www.cnblogs.com/tlnshuju)\xa0 阅读(786)\xa0 评论(0)\xa0 \xa0 [收藏](javascript:void(0))\xa0 [举报](javascript:void(0))\n\n### 前言：为什么 AI Agent 是下一代智能应用的核心？\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0最近一年，AI Agent 从概念走向落地，成为继大语言模型（LLM）之后最热门的技术方向。简单来说，AI Agent 是具备**自主决策、工具使用、环境交互**能力的智能体，能像人类一样拆解复杂任务、调用资源、持续迭代。\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0而 LangChain 与 LangGraph 作为目前最成熟的 Agent 开发框架，已成为开发者的首选工具。本文将从核心概念出发，通过实战案例手把手教你掌握 Agent 开发，涵盖内置 Agent 调用、自定义工具、向量数据库集成等关键技能，最后通过一个完整项目案例展示如何构建生产级 AI Agent。\n\n### 一、LangChain 核心概念：6 大组件搭建 Agent 基础\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0LangChain 之所以成为 Agent 开发的事实标准，源于其模块化的设计理念。掌握以下 6 大核心组件，就能理解 Agent 的工作原理：\n\n#### 1. Models：AI Agent 的 “大脑”\n\nModels 是 Agent 的核心算力来源，主要包括：\n\n> * **LLM（大语言模型）**：如 GPT-4、Claude、LLaMA 等，负责自然语言理解与决策\n> * **聊天模型（Chat Models）**：封装了对话格式的 LLM（如 OpenAI 的 ChatCompletion）\n> * **嵌入模型（Embedding Models）**：将文本转为向量，用于语义检索（如 OpenAI Embedding）\n\n**代码示例：初始化 OpenAI 模型**\n\n```\nfrom langchain_openai import OpenAI, ChatOpenAI # 初始化文本生成模型 llm = OpenAI(api_key="your_key", temperature=0) # temperature=0 表示确定性输出 # 初始化聊天模型 chat_model = ChatOpenAI(api_key="your_key", model_name="gpt-3.5-turbo")\n```\n\n#### 2. Prompts：引导 Agent 思考的 “指令”\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Prompts 是与模型交互的输入模板，决定了 Agent 的行为方式。LangChain 提供了\xa0`PromptTemplate`\xa0工具简化提示词管理：\n\n**代码示例：定义提示词模板**\n\n```\nfrom langchain.prompts import PromptTemplate # 简单提示词模板 template = "请将以下文本总结为一句话：{text}" prompt = PromptTemplate(input_variables=["text"], template=template) # 填充变量并生成最终提示词 formatted_prompt = prompt.format(text="LangChain 是一个用于构建 AI Agent 的框架...")\n```\n\n对于复杂场景（如 Agent 思考过程），可使用\xa0`ChatPromptTemplate`\xa0定义多轮对话模板。\n\n#### 3. Chains：串联组件的 “流水线”\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Chains 用于将多个组件（模型、提示词、工具等）按逻辑串联。最基础的\xa0`LLMChain`\xa0可将提示词与模型绑定：\n\n**代码示例：使用 LLMChain 串联组件**\n\n```\nfrom langchain.chains import LLMChain # 绑定提示词与模型 chain = LLMChain(llm=llm, prompt=prompt) # 执行链条 result = chain.run(text="LangChain 是一个用于构建 AI Agent 的框架...") print(result) # 输出：LangChain 是构建 AI Agent 的框架。\n```\n\n复杂场景可使用\xa0`SequentialChain`（顺序执行）或\xa0`RouterChain`（动态选择链条）。\n\n#### 4. Agents：具备决策能力的 “执行者”\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Agents 是 LangChain 的核心，能根据目标自主决策：是否调用工具、调用哪些工具、如何处理结果。其核心逻辑是 “思考 - 行动 - 观察” 循环（Thought-Action-Observation）。\n\n关键概念：\n\n> * **Agent Type**：Agent 的决策模式（如 ZERO\\_SHOT\\_REACT、OPENAI\\_FUNCTIONS）\n> * **Tools**：Agent 可调用的外部能力（如搜索、数据库查询）\n> * **Executor**：执行 Agent 决策的引擎\n\n#### 5. Tools：扩展 Agent 能力的 “双手”\n\nTools 是 Agent 与外部世界交互的接口，包括：\n\n> * **内置工具**：如\xa0`SerpAPIWrapper`（搜索）、`PythonREPLTool`（执行代码）\n> * **自定义工具**：根据业务需求开发的能力（如查询订单、操作数据库）\n\n工具定义需包含：名称、描述、参数说明（帮助 Agent 判断何时调用）。\n\n#### 6. Memory：Agent 的 “记忆系统”\n\nMemory 让 Agent 能记住历史交互，分为：\n\n> * **短期记忆**：如\xa0`ConversationBufferMemory`（存储完整对话）\n> * **长期记忆**：结合向量数据库存储结构化知识（如用户信息、产品数据）\n\n**组件关系图**\n\n**总结**：Models 提供算力，Prompts 定义任务，Chains 串联流程，Tools 扩展能力，Memory 保留上下文，最终通过 Agents 实现自主决策 —— 这就是 LangChain 构建智能体的核心逻辑。\n\n### 二、Agent 实战：从内置类型到自定义工具\n\n#### 1. 快速上手：使用 LangChain 内置 Agent\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0LangChain 提供了多种开箱即用的 Agent 类型，最常用的是\xa0**ZERO\\_SHOT\\_REACT\\_DESCRIPTION**（零样本推理）和\xa0**OPENAI\\_FUNCTIONS**（函数调用）。\n\n##### 案例：用 ZERO\\_SHOT\\_REACT\\_DESCRIPTION 实现天气查询\n\n**步骤 1：安装依赖**\n\n```\npip install langchain langchain-openai python-dotenv serpapi\n```\n\n**步骤 2：配置环境变量**创建\xa0`.env`\xa0文件：\n\n```\nOPENAI_API_KEY=your_openai_key SERPAPI_API_KEY=your_serpapi_key # 用于搜索工具\n```\n\n**步骤 3：初始化工具与 Agent**\n\n```\nfrom langchain.agents import initialize_agent, Tool from langchain.agents import AgentType from langchain_openai import OpenAI from langchain.utilities import SerpAPIWrapper from dotenv import load_dotenv import os # 加载环境变量 load_dotenv() # 初始化搜索工具 search = SerpAPIWrapper() tools = [ Tool( name="Search", func=search.run, description="当需要获取实时信息（如天气、新闻、股票价格）时使用" ) ] # 初始化 LLM llm = OpenAI(temperature=0) # 初始化 Agent（ZERO_SHOT_REACT 类型） agent = initialize_agent( tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True # 输出思考过程 )\n```\n\n**步骤 4：运行 Agent**\n\n```\n# 执行任务：查询北京明天的天气 result = agent.run("北京明天的天气如何？") print(result)\n```\n\n**输出解析**（verbose=True 时可见）：\n\n```\n> Entering new AgentExecutor chain... 我需要查询北京明天的天气，这是实时信息，应该用Search工具。 Action: Search Action Input: 北京明天天气 Observation: 北京明天（11月8日）晴，气温-2~8℃，西北风3-4级。 Thought: 已获取天气信息，无需进一步操作。 Final Answer: 北京明天（11月8日）晴，气温-2~8℃，西北风3-4级。 > Finished chain.\n```\n\n可以看到，Agent 完整执行了 “思考→调用工具→获取结果→整理回答” 的流程。\n\n##### 案例：用 OPENAI\\_FUNCTIONS 实现结构化输出\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0OPENAI\\_FUNCTIONS 类型依赖 LLM 的函数调用能力（如 GPT-3.5-turbo/4），适合需要结构化结果的场景：\n\n```\nfrom langchain.agents import AgentType, initialize_agent from langchain_openai import ChatOpenAI from langchain.tools import tool # 定义工具（用 @tool 装饰器自动生成描述） @tool def get_weather(city: str, date: str) -> str: """获取指定城市和日期的天气""" # 实际项目中可对接真实天气API return f"{city}{date}晴，气温5~15℃" # 初始化聊天模型（必须支持函数调用） chat_model = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0) # 初始化 Agent（OPENAI_FUNCTIONS 类型） agent = initialize_agent( [get_weather], chat_model, agent=AgentType.OPENAI_FUNCTIONS, verbose=True ) # 运行：获取上海后天的天气 result = agent.run("上海后天的天气怎么样？")\n```\n\n**优势**：工具调用格式更规范（通过 JSON 传递参数），适合生产环境。\n\n#### 2. 进阶：自定义 Tools 扩展 Agent 能力\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0内置工具无法满足业务需求时，可自定义工具。核心是明确工具的**功能描述**（帮助 Agent 判断何时调用）和**参数格式**。\n\n##### 案例：自定义 “订单查询” 工具\n\n**步骤 1：定义工具类**\n\n```\nfrom langchain.tools import BaseTool from pydantic import BaseModel, Field from typing import Optional, Type # 定义工具输入参数模型 class OrderQueryInput(BaseModel): order_id: str = Field(description="订单编号，格式为ORD+数字，如ORD123456") # 自定义工具 class OrderQueryTool(BaseTool): name = "OrderQuery" description = "用于查询订单状态，需要传入订单编号" args_schema: Type[BaseModel] = OrderQueryInput # 绑定输入参数模型 def _run(self, order_id: str) -> str: # 模拟查询数据库 if order_id.startswith("ORD") and len(order_id) == 9: return f"订单{order_id}状态：已发货，预计3天后送达" else: return "无效的订单编号，请检查格式" def _arun(self, order_id: str): # 异步实现（可选） raise NotImplementedError("暂不支持异步查询")\n```\n\n**步骤 2：集成到 Agent**\n\n```\n# 初始化工具和 Agent order_tool = OrderQueryTool() agent = initialize_agent( [order_tool], llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True ) # 测试：查询订单 result = agent.run("帮我查一下订单ORD123456的状态")\n```\n\n**关键点**：\n\n> * 工具描述要精确（如 “需要传入订单编号”），避免 Agent 误用\n> * 通过\xa0`args_schema`\xa0定义参数格式，确保输入规范\n> * 实现\xa0`_run`\xa0方法处理核心逻辑，`_arun`\xa0可选（异步场景）\n\n#### 3. 高级：集成向量数据库实现长期记忆\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Agent 仅靠对话历史（短期记忆）无法处理大规模知识，需结合向量数据库存储长期记忆。常用向量库有 Chroma（轻量本地库）、Pinecone（云服务）。\n\n##### 案例：用 Chroma 存储产品知识，让 Agent 回答用户咨询\n\n**步骤 1：安装依赖**\n\n```\npip install chromadb langchain-community\n```\n\n**步骤 2：初始化向量库并加载数据**\n\n```\nfrom langchain.vectorstores import Chroma from langchain.embeddings import OpenAIEmbeddings from langchain.text_splitter import CharacterTextSplitter from langchain.document_loaders import TextLoader # 1. 加载产品知识文档（示例：产品说明书） loader = TextLoader("product_info.txt") # 内容："产品A支持30天无理由退货，保修期1年..." documents = loader.load() # 2. 分割文档（避免文本过长） text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0) docs = text_splitter.split_documents(documents) # 3. 初始化向量库并存储文档 embeddings = OpenAIEmbeddings() # 用OpenAI Embedding生成向量 db = Chroma.from_documents(docs, embeddings, persist_directory="./chroma_db") db.persist() # 持久化存储\n```\n\n**步骤 3：创建 “知识检索” 工具**\n\n```\n@tool def retrieve_knowledge(query: str) -> str: """检索产品知识，回答用户关于产品的问题（如退货政策、保修期）""" # 从向量库中查询相关文档 docs = db.similarity_search(query) return "\\n".join([doc.page_content for doc in docs])\n```\n\n**步骤 4：集成工具到 Agent**\n\n```\n# 组合工具：知识检索 + 搜索（可选） tools = [retrieve_knowledge, search] # 初始化 Agent agent = initialize_agent( tools, chat_model, agent=AgentType.OPENAI_FUNCTIONS, verbose=True ) # 测试：查询产品退货政策 result = agent.run("产品A支持多久无理由退货？")\n```\n\n**效果**：Agent 会自动调用\xa0`retrieve_knowledge`\xa0工具，从向量库中获取产品信息并回答，无需硬编码知识。\n\n### 三、LangGraph：构建更稳定的 Agent 工作流\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0LangGraph 是 LangChain 团队推出的新一代框架，基于 “状态机” 设计，更适合构建复杂、可追溯的 Agent 工作流。其核心优势是：\n\n> * 明确的状态管理（State）\n> * 可控的节点流转（Nodes）\n> * 支持循环与分支逻辑\n\n#### 案例：用 LangGraph 实现 “多轮分析” Agent\n\n**场景**：让 Agent 分析用户问题，若需要补充信息则追问，否则生成答案。\n\n**步骤 1：安装 LangGraph**\n\n```\npip install langgraph\n```\n\n**步骤 2：定义状态与节点**\n\n```\nfrom langgraph.graph import Graph, StateGraph from pydantic import BaseModel, Field from typing import List, Optional # 1. 定义状态（保存对话历史、当前问题、是否需要追问） class State(BaseModel): messages: List[str] = Field(default_factory=list) need_clarify: bool = False # 是否需要追问 final_answer: Optional[str] = None # 2. 定义节点：分析问题 def analyze_node(state: State) -> State: last_msg = state.messages[-1] # 调用 LLM 判断是否需要追问（简化逻辑，实际需用 prompt 引导） if "价格" in last_msg and "产品" not in last_msg: state.need_clarify = True state.messages.append("请问你想了解哪个产品的价格？") else: state.need_clarify = False state.final_answer = f"已收到您的问题：{last_msg}，正在处理..." return state # 3. 定义节点：等待用户输入（仅示例，实际为外部交互） def user_input_node(state: State) -> State: user_input = input("请输入：") # 模拟用户输入 state.messages.append(user_input) return state # 4. 定义条件分支：是否需要追问 def should_continue(state: State) -> str: if state.need_clarify: return "user_input" # 流转到用户输入节点 else: return "end" # 结束流程\n```\n\n**步骤 3：构建并运行工作流**\n\n```\n# 初始化状态机 workflow = StateGraph(State) # 添加节点 workflow.add_node("analyze", analyze_node) # 分析节点 workflow.add_node("user_input", user_input_node) # 用户输入节点 # 定义流转逻辑 workflow.set_entry_point("analyze") # 入口节点 workflow.add_edge("user_input", "analyze") # 用户输入后回到分析节点 workflow.add_conditional_edges( "analyze", should_continue, { "user_input": "user_input", "end": "end" } ) # 编译并运行 app = workflow.compile() initial_state = State(messages=["这个产品的价格是多少？"]) result = app.invoke(initial_state) print(result.final_answer)\n```\n\n**优势**：相比 LangChain 内置 Agent，LangGraph 的工作流更清晰，可通过状态机可视化工具查看节点流转，便于调试复杂逻辑。\n\n### 四、项目实战：构建 “智能客服 Agent”\n\n结合上述知识，我们来构建一个完整的智能客服 Agent，具备以下能力：\n\n1. 回答产品知识（基于向量库）\n2. 查询订单状态（自定义工具）\n3. 调用搜索获取实时信息（如活动公告）\n4. 无法回答时转接人工\n\n#### 1. 架构设计\n\n#### 2. 核心代码实现\n\n```\n# 整合工具 tools = [retrieve_knowledge, OrderQueryTool(), search] # 初始化 Agent（使用 LangGraph 确保流程可控） class SupportAgent: def __init__(self): self.agent = initialize_agent( tools, ChatOpenAI(model_name="gpt-4", temperature=0), agent=AgentType.OPENAI_FUNCTIONS, verbose=True ) self.escalate_keywords = ["人工", "转接", "投诉"] # 需要转接人工的关键词 def handle_query(self, user_query: str) -> str: # 检测是否需要转接人工 if any(keyword in user_query for keyword in self.escalate_keywords): return "已为您转接人工客服，正在接入..." # 正常处理 try: return self.agent.run(user_query) except Exception as e: return f"处理失败：{str(e)}，请稍后再试" # 测试 if __name__ == "__main__": agent = SupportAgent() print(agent.handle_query("产品A的保修期是多久？")) # 调用知识检索 print(agent.handle_query("查一下订单ORD123456")) # 调用订单工具 print(agent.handle_query("转人工")) # 转接人工\n```\n\n### 五、总结与扩展\n\n本文从 LangChain 核心组件出发，通过实战案例讲解了 Agent 开发的关键技能：\n\n> * 内置 Agent 类型的选择（ZERO\\_SHOT\\_REACT 适合快速验证，OPENAI\\_FUNCTIONS 适合生产）\n> * 自定义工具的开发要点（清晰描述、规范参数）\n> * 向量数据库集成（实现长期记忆）\n> * LangGraph 工作流（复杂场景的最佳选择）\n\n**进阶方向**：\n\n1. 多 Agent 协作（用 LangGraph 实现分工）\n2. 工具权限控制（限制 Agent 调用敏感工具）\n3. 错误处理与重试机制（提升稳定性）\n4. 结合 RAG 优化知识检索精度\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0AI Agent 正处于快速发展期，掌握 LangChain/LangGraph 等工具，能让你在智能应用开发中抢占先机。动手实践吧 —— 最好的学习方式就是用代码实现一个属于自己的 Agent！\n\n**互动讨论**：你在开发 Agent 时遇到过哪些坑？有哪些实用技巧？欢迎在评论区分享～\n\n[刷新页面](#)[返回顶部](#top)\n\n[博客园](https://www.cnblogs.com/) \xa0©\xa0 2004-2026   \n [浙公网安备 33010602011771号](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33010602011771) [浙ICP备2021040463号-3](https://beian.miit.gov.cn)\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.cnblogs.com/tlnshuju/p/19353187', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9937588, 'save_path': None}}], 'save_path': '/home/qinshan/deepresearch/data/downloads'}
2026-02-02 16:24:22,747 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=8, save_path=/home/qinshan/deepresearch/data/downloads
2026-02-02 16:24:22,748 - __main__ - WARNING - handle_download: downloaded=0
2026-02-02 16:24:22,748 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=0
2026-02-02 16:32:26,556 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:32:26,557 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=en, search_type=None
2026-02-02 16:32:26,575 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:32:26,575 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 16:32:26,588 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 16:32:26,589 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 16:32:29,566 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 16:32:29,566 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 16:32:31,763 - __main__ - INFO - handle_search: returned=10
2026-02-02 16:32:31,764 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 16:32:31,764 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 16:32:31,943 - __main__ - INFO - handle_search: returned=10
2026-02-02 16:32:31,943 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-02 16:32:31,944 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '【EP04_短期记忆持久化存储和记忆管理策略】2026必学 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9999826, 'save_path': None}}
2026-02-02 16:33:09,520 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '管理LangGraph Postgres 檢查點以實現短期記憶的最佳實踐是什麼？', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生產環境中，管理 LangGraph Postgres 檢查點以實現短期記憶的最佳實踐是什麼？\n\n我正在為聊天機器人構建一個記憶系統，使用 **LangGraph**。 目前我專注於 **短期記憶**，由 **PostgresSaver** 支援。\n\n每次狀態轉換都會儲存在 `checkpoints` 表格中。正如預期，每次使用者互動（圖調用 / LLM 呼叫）都會建立多個檢查點，因此檢查點表格中的檢查點資料會**隨著使用量線性增長**。\n\n`checkpoints`\n\n在生產環境中，管理這種增長的推薦策略是什麼？\n\n具體來說：\n\n**只保留每個** thread\\_id 的最後 N 個檢查點並刪除較舊的檢查點，這是最佳實踐嗎？\n\n人們如何權衡**恢復/復原安全性**與**資料庫增長**的規模？\n\n供參考：\n\n我已經使用對話摘要，因此較舊的訊息不需要用於上下文\n\n檢查點主要用於短期恢復和狀態連續性，而不是長期記憶\n\nLangGraph 可以**從最後一個檢查點恢復**\n\n很好奇其他人如何在實際的生產系統中處理這個問題。\n\n此外，在 postgres 中，langgraph 建立 4 個關於檢查點的表格：checkpoints, checkpoint\\_writes, checkpoint\\_migrations, checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hant', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99993443, 'save_path': None}}, {'paper_id': '', 'title': '建议收藏：LangChain实战教程- 大模型应用开发者的必备技能', 'authors': [], 'abstract': '# [logo DAMO开发者矩阵](https://damodev.csdn.net "DAMO开发者矩阵")\n\n![logo](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n![](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\n## 登录社区云\n\n登录社区云，与社区用户共同成长\n\n### DAMO开发者矩阵\n\n邀请您加入社区\n\n![]()![]()\n\n# 建议收藏：LangChain实战教程 - 大模型应用开发者的必备技能\n\nLangChain是2022年10月（ChatGPT在2022年11月30问世，比ChatGPT还早），由哈佛大学的Harrison Chase（哈里森·蔡斯）发起研发的一个用于开发基于大语言模型（LLM） 应用程序的开源框架，它的核心目标是简化AI应用的构建过程，让开发者能像搭积木一样，快速组合各种模块来实现复杂功能，如：搭建智能体（Agent）、问答系统（QA）、对话机器人、知识库等。\n\n![](https://profile-avatar.csdnimg.cn/eeb633f233d641ef859131b4ee5aec84_m0_57081622.jpg!1)\n\n### [程序媛饺子](https://devpress.csdn.net/user/m0_57081622)\n\n![](https://profile-avatar.csdnimg.cn/eeb633f233d641ef859131b4ee5aec84_m0_57081622.jpg!1)\n\nLangChain是用于开发大模型应用程序的开源框架，提供高度模块化、可扩展的工具集。文章详细介绍了LangChain的六大核心组件：Model I/O、Chains、Memory、Tools、Agent和Retrieval。通过这些组件，开发者可以快速构建功能复杂的大模型应用，如智能问答系统、对话机器人和知识库等。文章提供了环境准备和各组件的使用方法，适合初学者入门大模型应用开发。\n\n![](https://i-blog.csdnimg.cn/img_convert/612cbcc9f9c682b065b007be815c12f3.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/612cbcc9f9c682b065b007be815c12f3.jpeg)\n\n### 1、LangChain概述\n\n##### 1.1 什么是LangChain\n\nLangChain是2022年10月（ChatGPT在2022年11月30问世，比ChatGPT还早），由哈佛大学的Harrison Chase（哈里森·蔡斯）发起研发的一个用于开发基于大语言模型（LLM） 应用程序的开源框架，它的核心目标是简化AI应用的构建过程，让开发者能像搭积木一样，快速组合各种模块来实现复杂功能，如：搭建智能体（Agent）、问答系统（QA）、对话机器人、知识库等。\n\nLangChain在Github上的热度变化：\n\n![](https://i-blog.csdnimg.cn/img_convert/fc58d017ea20ea3595ff96391f3cf5a9.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/fc58d017ea20ea3595ff96391f3cf5a9.jpeg)\n\nAI大模型架构图：\n\n![](https://i-blog.csdnimg.cn/img_convert/80708237cabe70cf78b935e053a4c83c.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/80708237cabe70cf78b935e053a4c83c.jpeg)\n\nLangChain所处的位置：\n\n![](https://i-blog.csdnimg.cn/img_convert/61fd60c802c72cfa8b05d9359d1608f8.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/61fd60c802c72cfa8b05d9359d1608f8.jpeg)\n\n##### 1.2 为什么使用LangChain\n\n使用 LangChain 的核心价值在于，它提供了一套高度模块化、可扩展的工具集，让开发人员能够快速、灵活地构建功能丰富的大模型应用，无需关注底层复杂的细节。它开发难度小，学习成本低，并且提供了现成的链式组装，能够让复杂的逻辑变得结构化、可扩展。LangChain最初只是一个开源的软件包，如今已称为一个完整的生态系统，它提供了一系列的标准化组件，且都可以单独使用。\n\n下表是直接对接大模型和使用LangChain的对比：\n\n|  |  |  |\n| --- | --- | --- |\n| 对比维度 | 直接调用大模型API | 使用 LangChain 开发 |\n| 开发模式 | 相对直接，但复杂功能需大量自定义代码 | 模块化组装，提供大量预制组件和链，简化复杂逻辑 |\n| 多模型支持 | 通常需为不同供应商的API编写适配代码 | 统一接口，轻松切换或组合不同模型（如OpenAI、Anthropic、Hugging Face等） |\n| 外部数据集成 | 需自行实现数据加载、处理、向量化与检索逻辑 | 内置RAG（检索增强生成） 等强大支持，可轻松连接PDF、数据库、API等外部数据源 |\n| 上下文管理 | 需手动管理对话历史，易超出Token限制 | 内置Memory组件，灵活管理短期和长期记忆，维持连贯对话 |\n| 复杂任务自动化 | 实现多步骤推理或工具调用逻辑复杂 | 通过Agents，让模型能自主决策、调用工具（如计算器、搜索引擎）完成任务 |\n| 生产部署与调试 | 缺乏标准化工具，监控和调试较困难 | 提供LangSmith等平台，用于监控、追踪和调试应用性能 |\n\n##### 1.3 LangChain架构设计（宏观）\n\nLangChain是由多个包组成的框架：\n\n![](https://i-blog.csdnimg.cn/img_convert/df0f6425db407399b5971bd720a17819.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/df0f6425db407399b5971bd720a17819.jpeg)\n\n图中展示了LangChain（V0.3版本）生态系统的主要组件及其分类，分为三个层次：架构(Architecture)、组件(Components)和部署(Deployment)。\n\n结构1：LangChain（架构中的LangChain，也是后文介绍的）：封装了一系列的API。\n\n结构2：LangGraph：基于有向图+条件边来灵活的构建多智能体应用，提供了条件分支、循环、并行等复杂控制流，能够实现状态持久化、断点续跑、时间旅行、人机协作等高级功能。\n\n结构3：LangSmith：用于构建、调试、测试、评估、监控和链路追踪大模型应用程序，提供了6大功能，涉及Debugging (调试)、Playground (沙盒)、Prompt Management (提示管理)、Annotation (注释)、Testing (测试)、Monitoring (监控)等。与LangChain无缝集成，从原型阶段过渡到生产阶段。\n\n结构4：LangServe：将基于 LangChain 开发的链（Chain）、代理（Agent）等快速部署为 REST API 服务。它基于 FastAPI 构建，极大简化了 AI 应用服务化的流程\n\nLangChain当中，目前最火的两个模块就是：LangGraph，LangSmith。\n\n##### 1.4 LangChain核心组件\n\nLangChain提供了一个高度模块化且可组合的框架，开发者能通过灵活集成其六大核心组件，来构建功能复杂的大模型应用。\n\n![](https://i-blog.csdnimg.cn/img_convert/bbc37ef968c9e4f313d62ead7a9e2431.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/bbc37ef968c9e4f313d62ead7a9e2431.jpeg)\n\n后续章节将详细介绍以上组件的使用方式。\n\n### 2、LangChain使用之环境准备\n\n##### 2.1 安装LangChain\n\nLangChain基于Python开发，因此需确保系统中安装了Python环境。\n\n安装LangChain\n\n`方式一：pip install langchain\n方式二：conda install langchain`\n\n##### 2.2 简单demo\n\n`chat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key, # 秘钥\ntemperature=0.7 # 温度参数,控制生成文本的随机性\n)`\n\n![](https://i-blog.csdnimg.cn/img_convert/c98a89d909e1500a64ce5e0875dd9c69.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/c98a89d909e1500a64ce5e0875dd9c69.jpeg)\n\n### 3、LangChain核心组件之Model I/O\n\n##### 3.1 Model I/O\n\nModel I/O 是应用程序与大模型进行交互的组件，它与大模型的关系类似于JDBC与数据库的关系，本质上都是为了解耦应用逻辑与底层实现，提供标准化的交互接口，使应用程序无需关注大模型底层的实现，可与各种大模型进行交互。Model I/O 包括输入提示(Format)、调用模型(Predict)、输出解析(Parse)。分别对应着Prompt Template（提示词模版），Model （大模型）和Output Parser（输出解析器）。\n\n![](https://i-blog.csdnimg.cn/img_convert/4a18421a6499bd0cb6a7f69628083b72.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/4a18421a6499bd0cb6a7f69628083b72.jpeg)\n\n说白了，Model I/O 就是LangChain 提供了一系列与大模型交互的API。\n\n##### 3.2 大模型分类（按功能）\n\n1、LLMs（大语言模型）\n\n也叫非对话模型，是许多语言模型应用程序的支柱，通用的文本生成，能够完成一次性的文本生成任务，如写作、翻译等。\n\n`llm_model = OpenAI()\nllm_model.invoke("什么是LangChain?")`\n\n2、Chat Models（对话模型）\n\n专门为多轮对话场景优化的语言模型。与LLMs处理纯字符串不同，Chat Models的输入和输出都是结构化的消息对象，能更好地理解和维护对话的上下文。\n\n`# 创建ChatOpenAI模型实例\nchat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key, # 秘钥\ntemperature=0.7 # 温度参数,控制生成文本的随机性\n)\n# 调用模型\nresponse = chat_model.invoke("用简单一句话概括一下什么是反洗钱？")\n# 打印模型响应内容\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/1d33c47d916d464c0cddb96670eb4ed0.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/1d33c47d916d464c0cddb96670eb4ed0.jpeg)\n\n3、Embedding Model（嵌入模型）\n\n它的核心任务是将文字、图片等非结构化数据，转换成高维空间中的数值向量。并且能够将语义相近的内容在向量空间中的位置也映射得更近。\n\n`# 我这里使用的嵌入模型是自己本地部署的，OpenAI的类为OpenAIEmbeddings\nembeddings_model = OllamaEmbeddings(\nmodel="nomic-embed-text",\nbase_url="http://127.0.0.1:11434",\n)\nvector = embeddings_model.embed_query("hello world")\nprint(f"嵌入向量长度: {len(vector)}")\nprint(f"前20个值: {vector[:20]}")`\n\n![](https://i-blog.csdnimg.cn/img_convert/d00ae27cad22c2ccc797c08922dd53cd.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/d00ae27cad22c2ccc797c08922dd53cd.jpeg)\n\n##### 3.3 Message（消息）\n\n消息是对话模型中通信的基本单位，用于表示与模型通讯的输入与输出，以及包含与对话相关的上下文信息和元数据，每一条消息都包含一个角色（系统、用户、AI等）和内容（用户的输入或模型的输出）以及其他元信息（id、名称、令牌使用情况等），LangChain提供了一个统一的消息格式，可以在不同模型之间使用。\n\n1、SystemMessage（系统消息）：设定行为准则，用于定义大模型的角色、运行规则、环境信息等。如果模型不支持SystemMessage则LangChain会将消息合并到HumanMessage中一起发送给大模型。\n\n2、HumanMessage（用户消息）：用户的输入，用户向模型发出的提问或指令。\n\n3、AIMessage（大模型消息，一般是模型返回的结果）：大模型的输出，这是大模型对HumanMessage和SystemMessage的响应。它不仅包含生成的文本内容（content属性），还可能包含以下结构化信息（外部工具、调用令牌使用情况等元数据）。\n\n4、ToolMessage/ FunctionMessage：连接外部能力，向模型传递外部工具或函数调用的执行结果，常用于Agent调用tool。\n\n`chat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key # 秘钥\n)\nmessages = [\n# 创建系统消息，定义模型的角色\nSystemMessage(content="我是反洗钱领域的专家，我叫RiskHelper"), # 创建用户消息，用户的提问\nHumanMessage(content="你好，什么是反洗钱？")\n]\n# 返回的类型是AI大模型消息\nresponse = chat_model.invoke(messages)\nprint(type(response)) # 格式是AIMessage`\n\n![](https://i-blog.csdnimg.cn/img_convert/5e7b38e54083581577000e038293638d.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/5e7b38e54083581577000e038293638d.jpeg)\n\n##### 3.4 Prompt Template（提示词模版）\n\nPrompt（提示词）：提示词是与大模型交互时输入的内容，用来指导大模型生成特定类型的回答或执行特定的任务。它可以是一个简单的问题、一段详细的任务说明，或包含角色、背景、示例的复杂文本。其核心目的是约束行为，减少错误，引导模型生成用户期望的响应。好的提示词可以解决60%以上的模型幻觉问题，优化提示词也是我们后续开发中解决大模型幻觉最多且最有效的方式之一。\n\n如下是一个简单的提示词：\n\n`"""\n您是一名资深LangChain框架专家，具备以下专业背景：\n- 精通LangChain 0.3.x及以上版本的核心架构\n- 熟练掌握Models、Prompts、Chains、Agents、Memory五大组件\n- 拥有实际企业级LLM应用部署经验\n请根据用户需求提供：\n1. 架构设计建议（组件选型与组合逻辑）\n2. 代码实现方案（包含最佳实践）\n3. 性能优化策略（处理长文本/高并发场景）\n4. 错误排查指导（常见陷阱与解决方案）用户输入: {input}\n"""`\n\nPrompt Template（提示词模版）：固定的提示词限制了模型的灵活性和适用范围，所以 Prompt Template 是一个模板化的字符串，可以将变量（如用户提问等）插入到模板的占位符中，从而创建出不同的提示。LangChain提供了很多提示词模版，用于与大模型交互，常见的提示词模版如下：\n\n1、PromptTemplate：LLM提示模板，用于生成字符串提示，生成的是单一、无角色区分的纯文本字符串。\n\n`# 创建PromptTemplate\nprompt_template = PromptTemplate(\ntemplate="如何成为一个{domain}领域的专家",\ninput_variables=["domain"]\n)\n# 填充模版参数，将反洗钱填充到domain字段中\nmessages = prompt_template.invoke({"domain": "反洗钱"})\nresponse = chat_model.invoke(messages)\nprint(response.content)`\n\n2、ChatPromptTemplate：创建聊天消息列表的提示模板。生成的是结构化的消息列表，其中每条消息都带有明确的角色（如系统、用户、AI），用在对话模型中。\n\n`# 方式一，使用构造函数创建\nchatprompt_template = ChatPromptTemplate([\n# key: 角色, value: 内容,\n("system", "你是一个反洗钱领域的专家，你的名字是{name}"), # 系统提示词\n("human", "帮我解答一下{question}") # 用户提示词\n])\n# 填充模版参数\nmessage = chatprompt_template.format(name="RiskHelper", question="什么是反洗钱？")\nresponse = chat_model.invoke(message)\nprint(response.content)\n# 方式二，使用from_messages方法创建\nchatprompt_template = ChatPromptTemplate.from_messages([\n("system", "你是一个反洗钱领域的专家，你的名字是{name}"),\n("human", "帮我解答一下{question}")\n])\n# 填充模版参数\nmessages = chatprompt_template.format(name="RiskHelper", question="什么是反洗钱？")\nresponse = chat_model.invoke(messages)\nprint(response.content)`\n\n3、XxxMessagePromptTemplate ：特定角色的消息提示词模板，包括：SystemMessagePromptTemplate、HumanMessagePromptTemplate、AIMessagePromptTemplate、ChatMessagePromptTemplate等，通常用ChatPromptTemplate将消息提示词模版打包在一起，一并发送给模型。\n\n`# 创建聊天提示词模版\nchatprompt_template = ChatPromptTemplate([\n# 创建系统提示词模版\nSystemMessagePromptTemplate.from_template("你是一个反洗钱领域的专家，你的名字是{name}"),\n# 创建用户提示词模版\nHumanMessagePromptTemplate.from_template("帮我解答一下{question}")\n])\n# 填充模版参数\nmessage = chatprompt_template.format(name="RiskHelper", question="什么是反洗钱？")\nresponse = chat_model.invoke(message)\nprint(response.content)`\n\n4、FewShotPromptTemplate ：样本提示词模板，提供少量的样例作为参考来引导大模型按照特定的格式和风格输出。\n\n`# 1. 定义示例数据\nexamples = [\n{\n"question": "什么是Spring Boot？",\n"answer": "Spring Boot是一个基于Spring框架的开源Java框架，用于简化Spring应用程序的创建和部署。"\n},\n{\n"question": "什么是依赖注入？",\n"answer": "依赖注入是一种设计模式，通过外部容器向对象提供其所需的依赖，而不是对象自己创建依赖。"\n},\n{\n"question": "什么是RESTful API？",\n"answer": "RESTful API是遵循REST架构风格的Web服务接口，使用HTTP方法进行资源操作。"\n}\n]\n# 2. 定义示例模板\nexample_prompt = PromptTemplate(\ninput_variables=["question", "answer"],\ntemplate="问题: {question}\\n答案: {answer}"\n)\n# 3. 创建few-shot提示词模版\nfew_shot_prompt = FewShotPromptTemplate(\nexamples=examples,\nexample_prompt=example_prompt,\nsuffix="问题: {question}",\ninput_variables=["question"]\n)\nformatted_prompt = few_shot_prompt.format(question="什么是LangChain？")\nresponse = chat_model.invoke(formatted_prompt)\nprint(response.content)`\n\n还有一些其他的提示词模版，大家感兴趣可以参考：\n\nhttps://python.langchain.com.cn/docs/modules/model\\_io/prompts/prompt\\_templates/\n\n##### 3.5 Output Parsers（输出解析器）\n\n大模型通常返回的内容都是字符串格式，但是我们实际开发中更擅长处理结构化数据，输出解析器就是将大模型输出的结果转换成特定的结构化数据，以便应用程序能更方便的处理。LangChain提供了一些常见的输出解析器，如StrOutputParser（字符串解析器）、JsonOutputParser（json解析器）、CommaSeparatedListOutputParser（csv解析器）、DatetimeOutputParserde（日期解析器）、XmlOutputParser（xml解析器）等下边用JsonOutputParser写一个简单的实例\n\n`json_parser = JsonOutputParser()\nprompt_template = PromptTemplate(\ntemplate="用简单的一句话描述一下什么是{name}？请按照以下格式输出：{format_instructions}",\ninput_variables=["name"],\n# 告诉大模型，按照json格式输出\npartial_variables={"format_instructions": json_parser.get_format_instructions()}\n)\nmessages = prompt_template.invoke({"name": "反洗钱"})\nresponse = chat_model.invoke(messages)\nprint(json_parser.parse(response.content))`\n\n![](https://i-blog.csdnimg.cn/img_convert/8c9ed335b85f14ae3d7740fdbb0a9eb7.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/8c9ed335b85f14ae3d7740fdbb0a9eb7.jpeg)\n\n##### 3.6 模型的调用方式\n\nRunnable 接口是使用LangChain组件的基础，它在许多组件中实现，例如语言模型、输出解析器、检索器、编译的LangGraph 图等。Runnable 方式定义了一个标准接口，允许 Runnable 组件用以下方式调用：\n\n1、invoke：处理单条输入，等待模型完全处理完成后再返回结果，上述的例子都是invoke调用\n\n2、stream：流式响应，逐字符输出模型的响应，类似于我们日常使用的AI应用（元宝）一样，给用户输出是逐字输出，无需等所有的结果生成后一次返回，对于用户交互体验较好。\n\n`# 流式输出\nchat_model = ChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url, # 与模型交互的地址\napi_key=api_key, # 秘钥\nstreaming=True # 开启流式输出\n)\nchatprompt_template = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个反洗钱领域的专家"),\nHumanMessagePromptTemplate.from_template("请详细讲一下什么是{value}？")\n])\nmessage = chatprompt_template.invoke({"value": "反洗钱"})\nfor output in chat_model.stream(message):\n# 逐个打印token内容\nprint(output.content, end="", flush=True)`\n\n3、batch：批量处理，可以将多个消息一起发送给模型。\n\n`# 创建三个消息\nmessage1 = [HumanMessage(content="什么是风控？")]\nmessage2 = [HumanMessage(content="什么是反洗钱？")]\nmessage3 = [HumanMessage(content="什么是EDD？")]\nmessages = [message1, message2, message3]\n# 批量调用\nresponse = chat_model.batch(messages)\nprint(response)`\n\nLangChain还提供了与上边相对应的异步方法：\n\n如果对具体的调用方式感兴趣可以参考官方文档：LangChain-Runnable调用\n\nhttps://docs.langchain.com/oss/javascript/langchain/overview\n\n### 4、LangChain核心组件之Chains\n\n##### 4.1 Chain（链）概述\n\n链，它将多个组件（提示词模版、大模型、记忆、工具、输出解析器）串联起来，形成一个可执行的，自动化的工作流程，类似于流水线作业。它将上一个组件的输出作为下一个组件的输入，将多个步骤串连起来执行，最终将模型的响应结果返回给用户。一个小Chain可以包含提示词模版->大模型->输出解析器，一个主Chain也可以将多个子Chain串起来，比如输入一篇文章先翻译（Chain A），再总结（Chain B）。\n\n![](https://i-blog.csdnimg.cn/img_convert/ba085733315250ef60f2e92e1ad27336.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/ba085733315250ef60f2e92e1ad27336.jpeg)\n\n##### 4.2 Chain组件使用\n\n1、LLMChain（已过时）：最基础的Chain，将一个提示词模板和一个大模型封装在一起，构成一个可执行的单元。适用于简单的问答、文本生成等单步任务。它的工作流程是：将用户输入的数据填充提示词模板，然后将格式化后的提示词发送给大模型，最终返回大模型的生成结果。\n\n`chatprompt_template = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个反洗钱领域的专家，你的名字是{name}"),\nHumanMessagePromptTemplate.from_template("帮我解答一下{question}")\n])\n# 创建链\nchain = LLMChain(llm=chat_model, prompt=chatprompt_template)\n# 调用链，先执行prompt，并将结果给到llm，再执行llm，最后返回结果\nresponse = chain.invoke({"name": "RiskHelper", "question": "什么是反洗钱？"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/99e88f6f5b95ceae20b50af4e56a5a23.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/99e88f6f5b95ceae20b50af4e56a5a23.jpeg)\n\n注意：上述是LLMChain的使用，但是LLMChain在0.1.17版本已经被标记为过时，且在1.0版本后会被移除。\n\n2、SequentialChain（顺序链，已过时）：通过将多个Chain串起来，实现分步任务处理，前一个链的输出作为后一个链的输入，适用于需要分步处理的任务，如先总结再翻译。\n\n`chatprompt_template1 = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个{name}领域的专家"),\nHumanMessagePromptTemplate.from_template("请详细讲一下什么是{title}？")\n])\nchain1 = LLMChain(llm=chat_model, prompt=chatprompt_template1, output_key="text")\nchatprompt_template2 = ChatPromptTemplate([\nSystemMessagePromptTemplate.from_template("你是一个文章总结专家"),\nHumanMessagePromptTemplate.from_template("请帮我用一句话概括一下{text}")\n])\nchain2 = LLMChain(llm=chat_model, prompt=chatprompt_template2, output_key="translation")\n# 构建顺序链\nchain = SequentialChain(\nchains=[chain1, chain2],\ninput_variables=["name", "title"],\noutput_variables=["translation"]\n)\nresponse = chain.invoke({"name": "反洗钱", "title": "EDD"})\nprint(response)`\n\nSequentialChain也在0.1.17版本被标记为过时，且在1.0版本后会被移除\n\n3、LCEL（LangChain Expression Language，推荐使用的方式）：是 LangChain 框架中用于构建和组合Chain的一种声明式、模块化且高效的语言。类似于Linux中的管道符 | ，将提示模板、语言模型、输出解析器等组件灵活地组合成可执行的工作流。\n\n`json_parser = JsonOutputParser()\nprompt_template = PromptTemplate(\ntemplate="用简单的一句话描述一下什么是{name}？请按照以下格式输出：{format_instructions}",\ninput_variables=["name"],\n# 告诉大模型，按照json格式输出\npartial_variables={"format_instructions": json_parser.get_format_instructions()}\n)\n# 使用管道符构建chain\nchain = prompt_template | chat_model | json_parser\nresponse = chain.invoke({"name": "反洗钱"})\nprint(response)`\n\n除了上述的chain之外，LangChain还提供了以下类型的chain。\n\n### 5、LangChain核心组件之Memory\n\n##### 5.1 Memory（记忆）概述\n\n我们知道，大模型本身都不会记忆任何上下文信息，那为什么我们常用的大模型应用能够清楚的知道我们之前的对话内容（与AI应用可以进行多轮对话）？并且有一定的记忆能力，这就需要额外的模块去保存我们和大模型进行对话的上下文信息，然后在下一次对话前将历史的记录全部发送给大模型，提供给大模型参考以便能够更准确的回答当前的提问。\n\n在LangChain中，这个用于存储用户和模型交互的历史信息的组件叫Memory，它能够让应用记住用户之前说了什么，从而实现对话的上下文感知能力，为构建真正智能和上下文感知的链式对话系统提供了基础。\n\n##### 5.2 Memory的原理\n\n![](https://i-blog.csdnimg.cn/img_convert/0ee35e925ec4e37e1dba3d77c05ddbf5.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/0ee35e925ec4e37e1dba3d77c05ddbf5.jpeg)\n\nSTEP1：用户输入问题\n\nSTEP2：从Memory中读取历史消息\n\nSTEP3：构建新的提示词，包含历史消息和当前的提问\n\nSTEP4：发送给大模型处理\n\nSTEP5：解析大模型输出，并返回用户\n\nSTEP6：将历史对话和当前对话一起保存在Memory中，以便下一次使用\n\n##### 5.3 Memory组件使用\n\nLangChain中提供了一系列的Memory用于保存历史上下文，不同的Memory保存的内容也不一样，常用的使用方式如下：\n\n1、ChatMessageHistory：用于存储和管理对话消息的基础类，它直接操作消息对象（如HumanMessage, AIMessage 等），是其它记忆组件的底层存储工具。特点：轻量、无需额外依赖、数据不会持久化（程序重启后丢失）。\n\n`# 创建Memory\nhistory = ChatMessageHistory()\n# 添加用户消息\nhistory.add_user_message("你好，我是RiskHelper")\n# 添加AI消息\nhistory.add_ai_message("我是DeepSeek大模型")\n# 添加用户消息\nhistory.add_user_message("我是谁？")\n# 通过将history.messages 直接传入大模型，大模型能够看到完整的对话上下文，从而实现有记忆的连续对话\nresponse = chat_model.invoke(history.messages)\nprint(response.content)`\n\n2、ConversationBufferMemory：是LangChain中最基础、最直接的记忆组件，按顺序完整地记录用户与AI之间的每一轮对话，并将这些历史信息提供给模型，以实现连贯的多轮对话。他能保存全部的上下文信息，对话连贯性最强，但是会消耗大量的Token，且随着对话的进行，会占用大量的内存资源。它适用于短对话，需要保存完整的上下文信息的复杂任务。\n\n`prompt_template = PromptTemplate.from_template(\n"历史对话: {history}，当前问题: {input}"\n)\nmemory = ConversationBufferMemory(memory_key="history")\nchain = LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\nresponse = chain.invoke({"input": "用简单一句话描述什么是LangChain？"})\nprint(response)\nprint("==============================================================")\nresponse = chain.invoke({"input": "如何使用它？"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/61a01fab9110f645539e84dcc6f11e83.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/61a01fab9110f645539e84dcc6f11e83.jpeg)\n\n3、ConversationBufferWindowMemory：只保留最近 K 轮对话，解决ConversationBufferMemory占用内存多、tokken消耗大问题，平衡连贯性与资源消耗。随之带来的问题是会丢失早期上下文，不适合复杂场景。\n\n`prompt_template = PromptTemplate.from_template(\n"历史对话: {history}，当前问题: {input}"\n)\nmemory = ConversationBufferWindowMemory(memory_key="history", k=10) # k表示保留的对话轮数\nchain = LLMChain(llm=chat_model, prompt=prompt_template, memory=memory)\nresponse = chain.invoke({"input": "用简单一句话描述什么是LangChain？"})\nprint(response)`\n\n4、ConversationSummaryMemory：它是 LangChain 中一种智能的记忆管理组件，它通过自动生成对话摘要来解决长对话上下文管理的问题。与简单截断历史的记忆类型不同，它使用大模型来提炼对话精髓，实现长期记忆。核心思想是：不存储原始对话记录，而是存储对话的智能摘要。当新的对话发生时，系统会将现有摘要与最新对话结合，生成更新的摘要。\n\n`history = ChatMessageHistory()\nhistory.add_ai_message("你好，我是RiskHelper")\nhistory.add_user_message("你好，什么是反洗钱？")\nhistory.add_user_message("你好，什么是风控”")\nmemory = ConversationSummaryMemory.from_messages(llm=chat_model,chat_memory=history)\nprint(memory.load_memory_variables({}))`\n\n![](https://i-blog.csdnimg.cn/img_convert/a3334737783cac7bce6854c671ff0c27.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/a3334737783cac7bce6854c671ff0c27.jpeg)\n\n5、ConversationSummaryBufferMemory：是LangChain中一种非常实用的混合型记忆组件，它巧妙地将对话摘要与原始对话缓冲区结合起来，旨在解决长对话场景下既要保持上下文连贯性又要控制资源消耗的核心矛盾。其核心创新在于采用了分层记忆管理策略，在对话连贯性和资源消耗之间找到平衡点。\n\n`memory = ConversationSummaryBufferMemory(\nllm=chat_model,\nmax_token_limit=100,\nreturn_messages=True\n)\nmemory.save_context({"input": "你好，我是RiskHelper"},{"output": "你好，我是DeepSeek大模型"})\nmemory.save_context({"input": "你好，什么是反洗钱？"},{"output": "反洗钱是指对洗钱犯罪的预防和打击措施"})\nmemory.save_context({"input": "你好，什么是风控？"},{"output": "风控是指对风险的控制措施"})\nmemory.save_context({"input": "你好，EDD？"},{"output": "EDD是指对客户身份的识别措施"})\nprint(memory.load_memory_variables({}))`\n\n![](https://i-blog.csdnimg.cn/img_convert/bf8a29b39aac861b830c4c5119d0ad36.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/bf8a29b39aac861b830c4c5119d0ad36.jpeg)\n\n注意： 有些模型（如Deepseek）没提供get\\_num\\_tokens\\_from\\_messages（计算token）函数，执行时会报错，解决办法继承ChatOpenAI，然后实现get\\_num\\_tokens\\_from\\_messages函数：\n\n`#创建一个继承于ChatOpenAI的类，并实现get_num_tokens_from_messages方法\nclass DeepSeekChatOpenAI(ChatOpenAI):\ndef get_num_tokens_from_messages(self, messages: List[BaseMessage]) -> int:\n#实现get_num_tokens_from_messages方法，返回消息的token数量\ntotal_tokens = 100 # 自定义函数\nreturn total_tokens;\nchat_model = DeepSeekChatOpenAI(\nmodel_name=model_name,\nbase_url=base_url,\napi_key=api_key\n)`\n\n除了上述介绍的Memory之外，LangChain还提供了一下其他的Memory：\n\n6、ConversationEntityMemory：一种基于实体的对话记忆机制，它能够智能地识别、存储和利用对话中出现的实体信息（如人名、地点、产品等）及其属性/关系，并结构化存储，使 AI 具备更强的上下文理解和记忆能力，能够解决信息过载问题。\n\n7、ConversationKGMemory： 一种基于知识图谱的先进记忆组件，它将对话内容组织成结构化的知识图谱，实现更加语义化和关联性的记忆管理。\n\n8、VectorStoreRetrieverMemory：一种基于向量数据库的先进记忆组件，它利用语义相似度检索技术，从大量历史对话中智能召回与当前对话最相关的记忆片段。\n\n### 6、LangChain核心组件之Tools\n\n##### 6.1 Tools概述\n\nTools是大模型、智能体（Agent）与外部世界进行交互的核心组件，本质上是封装了一些特定功能的可调用的函数（数学计算、获取时间、搜索等）， 允许大模型与外部系统、API、数据源和工具进行交互，其核心价值在于极大地扩展了 LLM 应用的能力边界（动作）。\n\n![](https://i-blog.csdnimg.cn/img_convert/634f5b93bdbd17cbe6ae298aee6d7a24.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/634f5b93bdbd17cbe6ae298aee6d7a24.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/df0a32d8dc494293bcce7afed91c63f0.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/df0a32d8dc494293bcce7afed91c63f0.jpeg)\n\n##### 6.2 Tools组件使用\n\nTool 通常包含如下几个要素：\n\n使用流程：\n\n![](https://i-blog.csdnimg.cn/img_convert/aaf0695a887613038d06cb87e0975cd7.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/aaf0695a887613038d06cb87e0975cd7.jpeg)\n\nSTEP1-工具创建：使用@tool注解创建工具。\n\nSTEP2-工具绑定：将创建的工具绑定到Agent上（可以绑定多个），包括工具的名称、描述、参数、返回等，让Agent知道有哪些工具可用。\n\nSTEP3-工具调用：模型返回调用具体的工具后，Agent根据该工具的参数描述构造参数，并发起调用\n\nSTEP4-工具执行：执行工具的具体逻辑，并返回结果。\n\n两种自定义工具的方式：\n\n方式一：@tool装饰器\n\n`@tool(\n# 指定工具的名称，这是 Agent 识别和调用工具时使用的标识符。\n# 默认值：如果不指定，默认使用函数名作为工具名称。\nname_or_callable="multiply", #\n# 用于告诉 Agent 这个工具的功能和用途。这对 Agent 选择合适的工具至关重要。\n# 默认值：如果不指定，会尝试使用函数的文档字符串（docstring）作为描述。如果文档字符串也没有，则为空字符串。\ndescription="Multiply two numbers",\n# 控制工具执行结果的返回方式\n# True：工具的输出直接作为 Agent 的最终回答返回给用户\n# False：工具的输出会传递给 Agent，由 Agent 进一步处理或与其他信息结合后再回答\nreturn_direct=True\n)\ndef multiply(a: int, b: int) -> int:\n"""Multiply a and b.""" # 如果不指定description，这会成为工具描述\nreturn a * b\nresponse = multiply.invoke({"a": 2, "b": 3})\nprint(response)`\n\n方式二：StructuredTool的from\\_function()\n\n`multiply = StructuredTool.from_function(\n# 绑定函数\nfunc=multiply,\n# 指定工具的名称，这是 Agent 识别和调用工具时使用的标识符。\nname="multiply",\n# 用于告诉 Agent 这个工具的功能和用途。这对 Agent 选择合适的工具至关重要。\ndescription="Multiply two numbers"\n)\nresponse = multiply.invoke({"a": 2, "b": 3})\nprint(response)`\n\n结合大模型使用：\n\n注意：tool一般与agent一起配合使用，agent在下一章详细介绍\n\n`# 将函数封装为LangChain工具对象\nstock_tool = Tool(\nname="getStockPrice", # 工具名称（模型将使用此名称调用工具）\nfunc=getStockPrice, # 工具函数\ndescription="用于查询公司股票价格。输入应该是公司名称（如：腾讯）"\n# 工具描述（模型根据此决定是否调用）\n)\n# 创建工具列表（Agent可以使用的所有工具）\ntools = [stock_tool]\n# 将LangChain工具转换为OpenAI函数调用格式\nfunctools = [convert_to_openai_tool(tool) for tool in tools]\n# 从LangChain Hub加载预定义的提示模板\n# \'hwchase17/structured-chat-agent\'是一个专门为结构化聊天Agent设计的提示模板\nprompt = hub.pull(\'hwchase17/structured-chat-agent\')\n# 创建结构化聊天Agent，# 参数：模型对象、工具列表、提示模板\nagent = create_structured_chat_agent(chat_model, tools, prompt)\n# 创建Agent执行器\nagent_executor = AgentExecutor(\nagent=agent, # 配置好的Agent\ntools=tools, # Agent可用的工具列表\nverbose=True, # 开启详细日志（显示Agent思考过程）\nhandle_parsing_errors=True # 处理解析错误（防止因格式问题崩溃）\n)\n# 执行Agent查询\nresponse = agent_executor.invoke({"input": "查询腾讯当日的股票价格"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/9efdc5d72dac7456f360d085c8edc577.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/9efdc5d72dac7456f360d085c8edc577.jpeg)\n\n注意：实际使用过程中发现，有时候并没有调用自定义的工具，可能原因是：\n\n1、大模型认为这个计算太简单（1+1），无需调用工具。\n\n2、工具的描述不清楚，大模型无法推断出使用这个工具。\n\n3、有些模型对于工具调用支持度不高，如DeepSeek-R1。\n\n具体可通过修改工具描述、提示词或换一个模型等引导模型决定调用自定义工具。\n\n##### 6.3 MCP Server\n\nAgent tools可以看做是实现在AI Agent应用中的一系列函数，但是很多Tool 的功能比较通用，如浏览网页，发送消息，天气查询等，所以将通用的工具封装成一个单独的服务，就可以供不同的Agent使用了，这个单独的服务叫MCP Server，其中MCP是一个通讯协议，用来规范Agent 和MCP Server之间是怎么交互的，如工具的功能，描述，参数等。MCP Server可以与Agent部署在同一台机器上通过标准输入输出通讯，也可以部署在网络上通过http协议通讯。虽然MCP是为了大模型而制定的标准，但实际上MCP本身和大模型没有关系，它并不关心Agent使用哪个模型，MCP只负责帮Agent管理工具、资源和提示词。\n\nLangChain中的Tool 和 MCP Server比较：\n\n|  |  |  |\n| --- | --- | --- |\n| 对比维度 | 内置Tools | MCP Server |\n| 部署位置 | Agent 内部（同一进程） | 独立服务（独立进程/网络） |\n| 代码耦合 | 紧耦合（直接引用） | 松耦合（协议通信） |\n| 复用性 | 仅当前 Agent 可用 | 多个 Agent 可共享 |\n| 更新维护 | 修改需重新编译 Agent | 修改需重新编译 Agent 独立更新 |\n| 性能 | 本地调用，极快 | 需要网络/IPC通信 |\n| 适用场景 | 简单、专用工具 | 通用、复杂工具 |\n\n### 7、LangChain核心组件之Agent\n\n##### 7.1 Agent（智能体）概述\n\n![](https://i-blog.csdnimg.cn/img_convert/0076b76de7921ccb1d65b4a41f889824.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/0076b76de7921ccb1d65b4a41f889824.jpeg)\n\nAgent（智能体）是一个通过动态协调大模型（LLM）和 工具（Tools）来完成复杂任务的智能系统（思考、分析、拆解任务、逐步实现）。它让大模型充当"决策大脑"，根据用户输入自主选择和执行工具（如搜索、计算、数据库查询等），最终生成精准的响应。2025年也被称为Agent元年，标志着人工智能正式从“思考与对话” 转向 “自主决策与行动”。\n\n一个Agent应该具备以下核心能力：\n\n![](https://i-blog.csdnimg.cn/img_convert/b2e832e2300ab48abaa06454261bb92c.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/b2e832e2300ab48abaa06454261bb92c.jpeg)\n\n通用人工智能（AGI）将是AI的终极形态（这天是否会到来？不止是技术的突破，还有伦理、法律、社会认知等）。同样，构建智能体（Agent）则是AI工程应用当下的“终极形态”。\n\n![](https://i-blog.csdnimg.cn/img_convert/201c5556a4e3fb82c3d898dc3a20756b.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/201c5556a4e3fb82c3d898dc3a20756b.jpeg)\n\n##### 7.2 Agent Types（运行模式）\n\n在 LangChain 中，Agent是一种由大模型驱动的组件，能够根据用户的输入动态决定执行哪些操作（如调用工具、访问数据等）。不同的 Agent 类型对应不同的决策逻辑和策略，适用于不同的任务场景。\n\n1、Function Calling：是让LLM学会“使用工具”。预先定义好一系列函数（如get\\_weather， search\\_web），并明确描述它们的功能和参数。当用户提问时，将用户提问以及工具信息（工具描述、参数等关键信息）一起发送给大模型，大模型不直接生成答案，而是判断是否需要调用这些函数，以及如何调用，并将函数参数，函数名等信息以结构化的格式返回（如JSON格式）。\n\n`"""\nOpenAI函数调用Agent\n特点：1、使用OpenAI的函数调用功能，支持结构化工具调用 2、性能最佳，响应速度快，工具调用准确性高 3、支持并行工具调用，可同时执行多个工具 4、原生支持JSON格式的参数传递\n适用场景：1、需要高精度工具调用的应用 2、对响应速度有要求的生产环境 3、需要复杂参数传递的工具集成 4、推荐作为首选Agent类型\n"""\nAgentType.OPENAI_FUNCTIONS\n"""\nOpenAI多函数调用Agent - 高级功能\n特点：1、支持复杂的多步骤工具调用链 2、能够处理工具间的依赖关系 3、支持条件分支和循环调用 4、具备更强的推理和规划能力\n适用场景： 1、需要多步骤复杂任务处理 2、工具间存在依赖关系的场景 3、需要动态决策和分支处理 4、复杂的业务流程自动化\n"""\nAgentType.OPENAIMULTI_FUNCTIONS`\n\n2、ReAct模式（思考与行动）\n\n![](https://i-blog.csdnimg.cn/img_convert/b138f9dd5c54bc47fb1c1acf649ab5ef.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/b138f9dd5c54bc47fb1c1acf649ab5ef.jpeg)\n\n将复杂任务拆解成，Thought (推理) → Action (行动，即调用工具) → Observation (观察结果) → … → Final Answer（最终答案）的循环步骤：\n\nReAct的工作原理：大模型本身不具备此流程（Thought-Action-Observation），实际是根据预先设定好的系统提示词来执行上述步骤的，如下是一个ReAct的系统提示词（hwchase17/react）：\n\n![](https://i-blog.csdnimg.cn/img_convert/0c262fb7e0e15569dc84df2a48945857.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/0c262fb7e0e15569dc84df2a48945857.jpeg)\n\nLangChain中ReAct的类型：\n\n`"""\n零样本ReAct描述Agent\n特点：1、基于ReAct（Reasoning + Acting）模式 2、通过"思考-行动-观察"的循环进行推理 3、不需要示例，完全依赖工具描述 4、具有良好的可解释性和透明度\n适用场景：1、需要清晰推理过程的应用 2、工具描述详细且准确的场景 3、对可解释性有要求的业务场景 4、适合调试和问题排查\n"""\nAgentType.ZERO_SHOT_REACT_DESCRIPTION\n"""\n结构化聊天零样本ReAct Agent\n特点：1、结合了结构化输出和ReAct推理模式 2、支持更复杂的工具参数传递 3、具备更好的多轮对话能力 4、输出格式更加规范和可解析\n适用场景：1、需要结构化输出的聊天应用 2、复杂参数的工具调用场景 3、多轮对话中的工具使用 4、需要格式化响应的业务场景\n"""\nAgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION\n"""\n对话式ReAct Agent\n特点：1、具备对话记忆能力，能记住历史交互 2、基于ReAct模式进行推理和行动 3、支持上下文相关的工具调用 4、适合长期对话和任务跟踪\n适用场景：1、需要维护对话状态的应用 2、长期任务跟踪和管理 3、个性化服务和推荐 4、客户服务和技术支持场景\n"""\nAgentType.CONVERSATIONAL_REACT_DESCRIPTION`\n\n##### 7.3 ReAct Agent 结合大模型使用\n\n`# 创建Tavily搜索工具实例，用于为Agent提供实时网络搜索能力\n# 需要在https://tavily.com/ 申请API key 才能使用\nsearch_tool = TavilySearchResults(\nmax_results=3,\ndescription="用于搜索最新网页信息、新闻和历史数据。输入应该是明确的搜索查询。"\n)\n# 从LangChain Hub拉取预定义的ReAct提示词模板\nprompt = hub.pull("hwchase17/react")\n# 创建ReAct Agent实例\nagent = create_react_agent(\nllm=chat_model,\nprompt=prompt,\ntools=[search_tool]\n)\n# 创建Agent执行器\nagent_executor = AgentExecutor(\nagent=agent,\nhandle_parsing_errors=True, # 自动处理解析错误，提高稳定性\nverbose=True, # 开启详细日志，显示推理过程\ntools=[search_tool] # 工具列表，必须与Agent中的工具保持一致\n)\n# 执行Agent任务\nresponse = agent_executor.invoke( {"input": "2021年2月5日腾讯收盘价是多少？"})\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/91685ca8612c090f3372367c0513a0f3.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/91685ca8612c090f3372367c0513a0f3.jpeg)\n\n##### 7.4 FUNCTION\\_CALL 结合大模型、Memory 使用\n\n`# 创建Tavily搜索工具实例\nsearch_tool = TavilySearchResults(\nmax_results=3, # 限制搜索结果数量，平衡信息完整性和处理效率\ndescription="用于搜索最新网页信息、新闻和历史数据。输入应该是明确的搜索查询。"\n)\n# 定义工具列表，可以添加多个\ntools = [search_tool]\n# 创建提示词模板\nprompt = ChatPromptTemplate.from_messages([\n("system", "你是一个人工智能小助手，可以回答问题并使用工具。"),\n("placeholder", "{chat_history}"),\n("human", "{input}"),\n("placeholder", "{agent_scratchpad}")\n])\n# 创建对话缓冲记忆实例\nmemory = ConversationBufferMemory(\nmemory_key="chat_history",\nreturn_messages=True\n)\n# 创建工具调用Agent实例\nagent = create_tool_calling_agent(chat_model, tools, prompt)\n# 创建Agent执行器\nagent_executor = AgentExecutor(\nagent=agent,\ntools=tools,\nmemory=memory,\nhandle_parsing_errors=True,\nverbose=True\n)\nresponse = agent_executor.invoke({"input": "2021年2月5日腾讯收盘价是多少？"})\nprint(response)\nresponse = agent_executor.invoke({"input": "阿里呢？"})\n# 嵌入Memory，可以推断出问的股价，\nprint(response)`\n\n![](https://i-blog.csdnimg.cn/img_convert/5baee6c6032baf33034414c50e5b4966.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/5baee6c6032baf33034414c50e5b4966.jpeg)\n\n### 8、LangChain核心组件之Retrieval\n\n##### 8.1 Retrieval（检索）概述\n\nRetrieval是用于从大量的文档或数据源中查找相关信息的核心模块，它是构建RAG（检索增强生成）的基础，能够让大模型访问外部知识源，解决模型本身的知识局限性和时效性问题。\n\n##### 8.2 大模型幻觉\n\n我们知道大模型有两个主要的特点：\n\n虽然记忆机制扩展了AI工程的应用场景，但大模型在专业领域仍面临显著挑战，由于无法掌握全部专业知识，大模型在回答专业问题时可能生成不准确甚至完全错误的内容，这个现象被称为“幻觉”。尤其在金融、医疗等高要求领域，一次错误的金额评估或医疗诊断失误都是致命的，对于非专业人士来说可能难以辨识。当前还没彻底解决这个问题的方案，不过大家普遍达成共识的一个方案：\n\n##### 8.3 RAG解决方案\n\n在利用大模型处理特定领域的大规模知识问答时，除了微调模型之外，检索增强生成（RAG）是一个有效的缓解大模型幻觉问题的解决方案。RAG通过引入外部知识检索机制，在生成前为模型提供相关的实时、专有信息作为上下文，从而直接应对其固有的“幻觉”问题和知识更新瓶颈。\n\nRAG流程：\n\n![](https://i-blog.csdnimg.cn/img_convert/8707e8cc032cbf9bb4571059cd73f517.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/8707e8cc032cbf9bb4571059cd73f517.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/253ddef4f08743d78c6db34ba7b1f85b.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/253ddef4f08743d78c6db34ba7b1f85b.jpeg)\n\n1、文件解析：解析各种格式的文件并提取出文字。\n\n2、文件切割：把长文本切割成更小的、有逻辑的片段。\n\n3、向量化：将文字片段转换为高纬空间中的向量数字。\n\n4、知识入库：将这些向量数字存进向量数据库中\n\n5、用户提问：用户发起提问\n\n6、检索：基于各种算法（余弦相似度、欧氏距离、点积等）去向量数据库里快速找出和问题最相关的几个文本片段。\n\n7、知识重排序：对找出的片段进行梳理排序，找出相似度最高的。\n\n8、增强：把选好的知识片段和用户的问题打包在一起交给大模型。\n\n9、生成：大模型生成一个准确且相关的回答。\n\n其中第678是RAG步骤中的检索、增强、生成。这里有三个位置涉及到大模型的使用：\n\n第3步：向量化，需要使用EmbeddingModels。\n\n第7步：重排序，需要使用RerankModels（追求回答高精度和高相关性的场景）。\n\n第9步：生成答案，需要使用LLM。\n\nRAG的优点\n\nRAG的缺点\n\n##### 8.4 Retrieval流程\n\n![](https://i-blog.csdnimg.cn/img_convert/42a1c09c1c60278f2e328c38c96612c8.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/42a1c09c1c60278f2e328c38c96612c8.jpeg)\n\n阶段一：Source（数据源），外部知识库，包含各种类型、格式的文件，如图片、视频、网站等\n\n阶段二：Load（加载），将外部知识库加载到内存中并转换成文档(Document)对象。包含内容和元数据等相关信息。\n\n阶段三：Transform（转换），将文档对象转换为更适合检索和生成的表达形式。包括文本分块、清理冗余信息、关键信息提取等，旨在提升后续处理的效率与质量\n\n阶段四：Embed（嵌入），通过嵌入模型将文本转换为高纬度空间中的数值向量，使得计算机能够理解和处理语义信息，文本可用于向量空间中的各种运算，大大拓展了文本分析的可能性，是自然语言处理领域非常重要的技术。\n\n![](https://i-blog.csdnimg.cn/img_convert/e33c4aa5b55684238c0da726cf9e12c0.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/e33c4aa5b55684238c0da726cf9e12c0.jpeg)\n\n文本嵌入为 LangChain 中的问答、检索、推荐等功能提供了重要支持。具体为：\n\n阶段五：Store（存储），将转换后的向量存储在向量数据库中，避免需要时重新计算。\n\n![](https://i-blog.csdnimg.cn/img_convert/cde64acc5653bc5db6429c3dfb5bba4a.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/cde64acc5653bc5db6429c3dfb5bba4a.jpeg)\n\n##### 8.5 Retrieval组件使用\n\n1、Document Loaders（文档加载器）\n\n`# 加载txt文件\ntext_loader = TextLoader("./risk.txt")\ndocs = text_loader.load()\n# print(docs)\n# 加载pdf文件\npdf_loader = PyPDFLoader(file_path="./risk.pdf")\ndocs = pdf_loader.load()\nprint(docs)\n# 加载csv文件\ncsv_loader = CSVLoader(file_path="./risk.csv")\ndocs = csv_loader.load()\nprint(docs)\n#加载json文件\njson_loader = JSONLoader(file_path="./risk.json")\ndocs = json_loader.load()\nprint(docs)`\n\nDocumment对象中有两个重要的属性：\n\n2、Text Splitters（文本拆分器）\n\n![](https://i-blog.csdnimg.cn/img_convert/ea51d3ea5edd29022176393ad2de88a4.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/ea51d3ea5edd29022176393ad2de88a4.jpeg)\n\n文本拆分器是将长文档拆分为语义连贯、大小适中的小片段，主要是解决大模型的上下文窗口限制，并提升检索的准确性和生成内容的质量。它的工作原理通常遵循“先细拆后合并”的策略：首先将文本分割成小句子，然后按顺序将这些小句子合并成较大的块，直到达到设定的块大小限制。在创建新块时，会与上一个块保留部分重叠，以确保上下文连贯。\n\n为什么需要分隔？\n\n基于此，一个有效的解决方案就是将完整的Document对象进行分块处理（Chunking) 。无论是在存储还是检索过程中，都将以这些块(chunks) 为基本单位，这样有效地避免内容不相关性问题和超出最大输入限制的问题。\n\nChunking拆分的策略：\n\n`text_loader = TextLoader("./risk.txt")\ndocs = text_loader.load()\ntext_splitter = CharacterTextSplitter(\n# 文本块大小：每个分割块的最大字符数，1000字符通常包含150-200个中文词汇，适合大多数LLM的上下文窗口处理\nchunk_size=1000,\n# 文本块重叠：相邻块之间的重叠字符数，设置为0表示无重叠，节省存储空间，通常设置为chunk_size的10-20%以保持上下文连续性\nchunk_overlap=0,\n# 长度计算函数：用于计算文本长度的函数，len()函数按字符计数，适合中英文混合文本，也可以使用token计数函数获得更精确的控制\nlength_function=len,\n# 分割符：优先按换行符分割文本，保持段落结构的完整性，避免句子被截断\nseparator="\\n"\n)\ntexts = text_splitter.split_text(docs[0].page_content)\nprint(texts)`\n\n除了CharacterTextSplitter，LangChain还提供了很多拆分器，如：RecursiveCharacterTextSplitter、TokenTextSplitter、CharacterTextSplitter、SemanticChunker、HTMLHeaderTextSplitter等。具体使用可参考官方文档：https://python.langchain.com.cn/docs/modules/data\\_connection/document\\_transformers/\n\n3、Text Embedding Models（文档嵌入模型）\n\n将文本转换为数值向量\n\n![](https://i-blog.csdnimg.cn/img_convert/23f7974f3ad4c795e78fde1bcd38b0ca.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/23f7974f3ad4c795e78fde1bcd38b0ca.jpeg)\n`embeddings_model = OllamaEmbeddings(\nmodel="nomic-embed-text",\nbase_url="http://127.0.0.1:11434",\n)\ntext = "Hello World"\n# 句子向量化\nvector = embeddings_model.embed_query(text=text)\nprint(f"嵌入向量长度: {len(vector)}")\nprint(f"前20个值: {vector[:20]}")\nprint("=======================================")\ntexts = ["Hello World", "Today is a sunny day", "No news is good news"]\n# 文档向量化\nvector = embeddings_model.embed_documents(texts)\nfor v in vector:\nprint(f"前20个值: {v[:20]}")`\n\n![](https://i-blog.csdnimg.cn/img_convert/3634150c2083a3f1693f4fe2da191267.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/3634150c2083a3f1693f4fe2da191267.jpeg)\n\n4、Vector Stores（向量存储）\n\n![](https://i-blog.csdnimg.cn/img_convert/9e704a80b66b37c775bf54727fc6f4ff.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/9e704a80b66b37c775bf54727fc6f4ff.jpeg)\n\n将文本向量化之后，下一步就是进行向量的存储。这里有两部分：\n\nLangChain提供了50多种不同的向量数据库，参考文档：向量存储\n\nhttps://docs.langchain.com/oss/python/langchain/overview\n\n`# 加载txt文件\ntext_loader = TextLoader("./risk.txt", encoding="utf-8")\ndocs = text_loader.load()\n# 文本分割\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntext_docs = text_splitter.split_documents(docs)\n# 向量存储，默认存储在内存中， 可通过persistent_directory参数指定存储磁盘路径\nvectorstore = Chroma.from_documents(text_docs, embeddings_model, persistent_directory=\'./chroma_db\')\n# 相似度搜索，除了similarity_search外，\n# 1、直接对问题向量查询（similarity_search_by_vector）\n# 2、通过L2距离分数进行搜索（similarity_search_with_score）\n# 3、通过余弦相似度分数进行搜索（similarity_search_with_relevance_scores）\n# 4、MMR（最大边际相关性，max_marginal_relevance_search）\nresponse = vectorstore.similarity_search("什么是反洗钱？")\nprint(response)`\n\n5、Retrievers（检索器）\n\n![](https://i-blog.csdnimg.cn/img_convert/8f02d3601dd4e47dd8c17183572f0577.jpeg)\n\n![](https://i-blog.csdnimg.cn/img_convert/8f02d3601dd4e47dd8c17183572f0577.jpeg)\n\n向量数据库提供了核心的相似性计算能力，其内置函数（如余弦相似度，欧式距离，点积等）可直接用于实现基础的向量召回。LangChain还提供了 更加复杂的召回策略 ，这些策略被集成在Retrievers（检索器）组件中。检索器本身不存储数据，而是通过查询向量数据库，并集成重排序、多路检索等高级逻辑，最终返回相关的文档片段。\n\n`# # 加载txt文件\ntext_loader = TextLoader("./risk.txt", encoding="utf-8")\ndocs = text_loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ntext_docs = text_splitter.split_documents(docs)\n# 向量存储，默认存储在内存中， 可通过persistent_directory参数指定存储磁盘路径\nvectorstore = Chroma.from_documents(docs, embeddings_model, persistent_directory=\'./chroma_db\')\n# 创建检索器\nretriever = vectorstore.as_retriever(\n# 搜索参数，k表示返回的文档数量，score_threshold表示相似度阈值\nsearch_kwargs={"k": 2, "score_threshold": 0.5},\n# 搜索类型\nsearch_type="similarity_score_threshold"\n)\nchain = retriever | chat_model\nresponse = chain.invoke("什么是反洗钱？")\nprint(response)`\n\n### 9、再谈LangChain\n\n读到这想必你对LangChain有一个清晰的认识了，为了更形象地理解，如果将LLM比作人类的”大脑“，那么LangChain中的组件就像：\n\n整个系统的核心，负责思考、推理、理解和生成。就像人类的大脑，是智能的中枢。它接收来自各方的信息，进行处理，并做出决策或生成回应。\n\n存储海量的专业知识（公司文档、知识库等），并能在需要时快速、准确地检索相关信息提供给“大脑”。它是一个巨大的私人图书馆或长期记忆仓库，当你需要解决一个专业问题时，你会来图书馆查阅相关资料，然后将这些资料带给大脑（LLM）进行参考和分析。\n\n负责决策“如何”完成任务。它接收用户指令，进行规划，决定是直接由大脑（LLM）回答，还是需要调用各种工具（Tools），并按照什么顺序来执行。就像人体的神经系统或小脑。大脑（LLM）负责出主意，而Agent负责协调身体各部分去执行这个主意。例如，你想“拿一杯水”，大脑发出指令，神经系统（Agent）会规划并协调眼睛（观察）、手（抓取）等一系列动作。\n\n是Agent可以调用的具体功能，用于与外部世界交互。就像人的手、脚、眼睛和耳朵。\n\n将多个步骤（LLM调用、工具使用、数据处理）预先定义并链接在一起，形成一个可重复执行的固定流程。像是你学会的一种“技能”或“肌肉记忆”。例如，“泡咖啡”这个技能就是一个链：走到咖啡机前 -> 加咖啡粉 -> 按开关 -> 等待 -> 拿杯子。一旦学会，你就可以不假思索地完成。\n\n用于存储和回顾当前对话的历史信息，使AI能够拥有上下文感知能力，实现连贯的多轮对话。就像你的短期记忆。它让你记得在刚才的对话中对方说了什么，从而能做出相关的回应。没有记忆，每一次对话都是全新的、孤立的。\n\n预先设计好的、结构化的提示词，用于更有效、更稳定地向LLM提问。就像沟通技能、演讲技能，写作技能，都有一套固定的模版。\n\n通过这个比喻，我们可以清晰地看到：LLM是智能的核心（脑）、RAG是知识储备（图书馆）、Agents是协调指挥官（神经系统）、Tools是执行手段（手脚）、Chains是自动化技能（肌肉记忆）、Memory是上下文感知（短期记忆），它们各司其职，紧密协作，共同构成了一个能够理解、推理并作用于外部世界的智能体。\n\n至此，关于LangChain的组件使用就介绍完了，上述内容仅仅只是对LangChain使用的简单介绍以及一些大模型应用开发相关的概念，如果需要更深入的理解LangChain，可以参考官方文档。作为一个初学者，上述内容如果有理解不准确或错误的地方，欢迎指正。如果文章对你有一点点帮助，辛苦点个赞吧🫡\n\n### 如何学习大模型 AI ？\n\n由于新岗位的生产效率，要优于被取代岗位的生产效率，所以实际上整个社会的生产效率是提升的。\n\n但是具体到个人，只能说是：\n\n**“最先掌握AI的人，将会比较晚掌握AI的人有竞争优势”。**\n\n这句话，放在计算机、互联网、移动互联网的开局时期，都是一样的道理。\n\n我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。\n\n我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。\n\n**这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【`保证100%免费`】**\n\n`保证100%免费`\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/80dfd54ec491457faa956c46afad1163.png#pic_center)\n\n![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/80dfd54ec491457faa956c46afad1163.png#pic_center)\n\n### 为什么要学习大模型？\n\n我国在A大模型领域面临人才短缺,数量与质量均落后于发达国家。2023年，人才缺口已超百万，凸显培养不足。随着AI技术飞速发展，预计到2025年,这一缺口将急剧扩大至400万,严重制约我国AI产业的创新步伐。加强人才培养,优化教育体系,国际合作并进是破解困局、推动AI发展的关键。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6962caeebf3a4e9f94b631fc5da8b689.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6962caeebf3a4e9f94b631fc5da8b689.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/84d4fd89dc10476e9ef6c982793393b4.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/84d4fd89dc10476e9ef6c982793393b4.png)\n\n### 大模型入门到实战全套学习大礼包\n\n#### **1、大模型系统化学习路线**\n\n作为学习AI大模型技术的新手，方向至关重要。 正确的学习路线可以为你节省时间，少走弯路；方向不对，努力白费。这里我给大家准备了一份**最科学最系统的学习成长路线图和学习规划**，带你从零基础入门到精通！\n\n![img](https://i-blog.csdnimg.cn/direct/b3e31603ac324ad98ad7db90e2c1a3f4.jpeg#pic_center)\n\n![img](https://i-blog.csdnimg.cn/direct/b3e31603ac324ad98ad7db90e2c1a3f4.jpeg#pic_center)\n\n#### 2、大模型学习书籍&文档\n\n学习AI大模型离不开书籍文档，我精选了一系列大模型技术的书籍和学习文档（电子版），它们由**领域内的顶尖专家撰写**，内容全面、深入、详尽，为你学习大模型提供坚实的理论基础。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5b97585640c44afe82d295f398bce6cc.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5b97585640c44afe82d295f398bce6cc.png)\n\n#### 3、**AI大模型最新行业报告**\n\n2025最新行业报告，针对**不同行业的现状、趋势、问题、机会**等进行系统地调研和评估，以了解哪些行业更适合引入大模型的技术和应用，以及在哪些方面可以发挥大模型的优势。\n\n![img](https://i-blog.csdnimg.cn/img_convert/321829d5cb17558fa20823004e2878bb.gif)\n\n![img](https://i-blog.csdnimg.cn/img_convert/321829d5cb17558fa20823004e2878bb.gif)\n\n#### 4、**大模型项目实战&配套源码**\n\n**学以致用**，在**项目实战中检验和巩固你所学到的知识**，同时为你找工作就业和职业发展打下坚实的基础。\n\n![img](https://i-blog.csdnimg.cn/img_convert/91d8dc1a6f2e7231de586317805af9aa.gif)\n\n![img](https://i-blog.csdnimg.cn/img_convert/91d8dc1a6f2e7231de586317805af9aa.gif)\n\n#### 5、**大模型大厂面试真题**\n\n面试不仅是技术的较量，更需要充分的准备。在你已经掌握了大模型技术之后，就需要开始准备面试，我精心整理了一份大模型面试题库，**涵盖当前面试中可能遇到的各种技术问题，让你在面试中游刃有余**。\n\n![img](https://i-blog.csdnimg.cn/img_convert/8cd3ce556cb620097c74de0e4330561d.gif)\n\n![img](https://i-blog.csdnimg.cn/img_convert/8cd3ce556cb620097c74de0e4330561d.gif)\n\n##### 适用人群\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e1c768ed14b945499146a0d0f6e05e8d.png)\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e1c768ed14b945499146a0d0f6e05e8d.png)\n\n##### 第一阶段（10天）：初阶应用\n\n该阶段让大家对大模型 AI有一个最前沿的认识，对大模型 AI 的理解超过 95% 的人，可以在相关讨论时发表高级、不跟风、又接地气的见解，别人只会和 AI 聊天，而你能调教 AI，并能用代码将大模型和业务衔接。\n\n##### 第二阶段（30天）：高阶应用\n\n该阶段我们正式进入大模型 AI 进阶实战学习，学会构造私有知识库，扩展 AI 的能力。快速开发一个完整的基于 agent 对话机器人。掌握功能最强的大模型开发框架，抓住最新的技术进展，适合 Python 和 JavaScript 程序员。\n\n##### 第三阶段（30天）：模型训练\n\n恭喜你，如果学到这里，你基本可以找到一份大模型 AI相关的工作，自己也能训练 GPT 了！通过微调，训练自己的垂直大模型，能独立训练开源多模态大模型，掌握更多技术方案。\n\n到此为止，大概2个月的时间。你已经成为了一名“AI小子”。那么你还想往下探索吗？\n\n##### 第四阶段（20天）：商业闭环\n\n对全球大模型从性能、吞吐量、成本等方面有一定的认知，可以在云端和本地等多种环境下部署大模型，找到适合自己的项目/创业方向，做一名被 AI 武装的产品经理。\n\n学习是一个过程，只要学习就会有挑战。天道酬勤，你越努力，就会成为越优秀的自己。\n\n如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名大模型 AI 的正确特征了。\n\n###### 这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【`保证100%免费`】\n\n`保证100%免费`\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n\n![https://img-blog.csdnimg.cn/img_convert/05840567e2912bcdcdda7b15cba33d93.jpeg](https://i-blog.csdnimg.cn/direct/8860f19e62134f058ae4494199266f1f.png)\n![Logo](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\nDAMO开发者矩阵，由阿里巴巴达摩院和中国互联网协会联合发起，致力于探讨最前沿的技术趋势与应用成果，搭建高质量的交流与分享平台，推动技术创新与产业应用链接，围绕“人工智能与新型计算”构建开放共享的开发者生态。\n\n更多推荐\n\n![cover](https://i-blog.csdnimg.cn/direct/9da7c9d3ff3a4cb3bc3c97fe2a7f5fe0.png)\n\n微信社群机器人搭建 教程/开发\n\n![avatar](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\n一体双生: 计算机图形学与计算机视觉本就“同宗同源”\n\n当我们站在现在回望，计算机图形学和计算机视觉的分野，更多是受限于早期算力和算法的无奈之举。算力不足时，CG 只能用光栅化骗过眼睛，CV 只能用边缘检测提取特征。算力充裕时，CG 开始用光线追踪模拟物理，CV 开始用 Transformer 理解全局。如今，随着3D AIGCXR（空间计算）和具身智能（Embodied AI）的兴起，两者正在回归它们的共同本质——对视觉信息的全链路处理。未来的工程师\n\n![avatar](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n\n改进型深度Q-网格DQN和蒙特卡洛树搜索MCTS以及模型预测控制MPC强化学习的机器人室内导航仿真\n\n本文摘要： 本研究实现了一个基于TurtleBot3机器人的自主导航系统，包含以下核心技术：1) 通过Gazebo仿真环境构建SLAM地图；2) 采用改进的蒙特卡洛树搜索(MCTS)算法进行路径规划，结合距离启发函数提升搜索效率；3) 设计分层MPC-PID控制器实现路径跟踪；4) 开发一键启动脚本集成整个系统。创新点包括：基于轮廓分析的地图优化、DQN引导的MCTS搜索、安全势场规划以及分层运动\n\n![avatar](https://i-blog.csdnimg.cn/devpress/blog/9f55d92f98764971a5989e18b75fa042.png)\n![浏览量](https://csdnimg.cn/release/devpress/public/img/watch.a5bd9e9b.svg)\n![点赞](https://csdnimg.cn/release/devpress/public/img/thumb.a0b81433.svg)\n![收藏](https://csdnimg.cn/release/devpress/public/img/mark.f1a889ab.svg)\n![](https://csdnimg.cn/release/devpress/public/img/share.f1fdda75.svg)\n\n扫一扫分享内容\n\n![]()\n![](https://csdnimg.cn/release/devpress/public/img/share.f1fdda75.svg)\n\n### 所有评论(0)\n\n![]()![](https://profile-avatar.csdnimg.cn/eeb633f233d641ef859131b4ee5aec84_m0_57081622.jpg!1)\n\n### [程序媛饺子](https://devpress.csdn.net/user/m0_57081622)\n\n![](https://csdnimg.cn/release/devpress/public/img/devote.fe704c8a.svg)\n![](https://csdnimg.cn/release/devpress/public/img/top.c3a2945a.svg)\n![]()![logo](https://csdnimg.cn/release/devpress/public/img/csdn-logo.07312d72.png)\n![logo](https://csdnimg.cn/release/devpress/public/img/csdn-logo.07312d72.png)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://damodev.csdn.net/69251f44791c233193d00f40.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9998832, 'save_path': None}}, {'paper_id': '', 'title': '内存记忆( Memory ) - LangChain 中文文档', 'authors': [], 'abstract': '![10000 AI开发者社群](https://www.aiqbh.com/qun.png)\n\n# 内存记忆 ( Memory )\n\n![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif "LangChain中文网")\n\n![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif "LangChain中文网")\n\n默认情况下，链式模型和代理模型都是无状态的，这意味着它们将每个传入的查询独立处理（就像底层的 LLMs 和聊天模型本身一样）。在某些应用程序中，比如聊天机器人，记住先前的交互是至关重要的。无论是短期还是长期，都要记住先前的交互。**Memory** 类正是做到了这一点。\nLangChain 提供了两种形式的记忆组件。首先，LangChain 提供了用于管理和操作以前的聊天消息的辅助工具。这些工具被设计成模块化的，无论如何使用都很有用。其次，LangChain 提供了将这些工具轻松整合到链式模型中的方法。\n\n## 入门[\u200b](#入门 "Direct link to 入门")\n\n记忆涉及在用户与语言模型的交互过程中始终保留状态的概念。用户与语言模型的交互被捕获在 ChatMessages 的概念中，因此这归结为在一系列聊天消息中摄取、捕获、转换和提取知识。有许多不同的方法可以做到这一点，每种方法都作为自己的记忆类型存在。\n通常情况下，对于每种类型的记忆，有两种理解和使用记忆的方式。一种是独立的函数，从一系列消息中提取信息，然后是您可以在链式模型中使用此类型的记忆的方式。\n记忆可以返回多个信息片段（例如，最近的 N 条消息和所有先前消息的摘要）。返回的信息可以是字符串或消息列表。\n\n我们将介绍最简单的存储形式：“缓冲”存储，它只涉及保留所有先前的消息的缓冲区。我们将展示如何在这里使用模块化实用函数，然后展示它如何在链中使用（返回字符串以及消息列表）。\n\n## 聊天消息历史 (ChatMessageHistory)[\u200b](#聊天消息历史-chatmessagehistory "Direct link to 聊天消息历史 (ChatMessageHistory)")\n\n大多数（如果不是全部）内存模块的核心实用类之一是 `ChatMessageHistory` 类。这是一个超轻量级的包装器，它公开了方便的方法来保存人类消息、AI 消息，然后获取它们全部。\n\n`ChatMessageHistory`\n\n如果您在链外管理内存，可能需要直接使用此类。\n\n`from langchain.memory import ChatMessageHistory  \n  \nhistory = ChatMessageHistory()  \n  \nhistory.add_user_message("hi!")  \n  \nhistory.add_ai_message("whats up?")`\n`history.messages`\n `[HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]`\n\n## ConversationBufferMemory[\u200b](#conversationbuffermemory "Direct link to ConversationBufferMemory")\n\n现在我们展示如何在链中使用这个简单的概念。我们首先展示 `ConversationBufferMemory`，它只是 ChatMessageHistory 的一个包装器，可以提取变量中的消息。\n\n`ConversationBufferMemory`\n\n我们可以首先将其提取为字符串。\n\n`from langchain.memory import ConversationBufferMemory`\n`memory = ConversationBufferMemory()  \nmemory.chat_memory.add_user_message("hi!")  \nmemory.chat_memory.add_ai_message("whats up?")`\n`memory.load_memory_variables({})`\n `{\'history\': \'Human: hi!\\nAI: whats up?\'}`\n\n我们还可以将历史记录作为消息列表获取\n\n`memory = ConversationBufferMemory(return_messages=True)  \nmemory.chat_memory.add_user_message("hi!")  \nmemory.chat_memory.add_ai_message("whats up?")`\n`memory.load_memory_variables({})`\n `{\'history\': [HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]}`\n\n## Using in a chain[\u200b](#using-in-a-chain "Direct link to Using in a chain")\n\nFinally, let\'s take a look at using this in a chain (setting `verbose=True` so we can see the prompt).\n\n`verbose=True`\n`from langchain.llms import OpenAI  \nfrom langchain.chains import ConversationChain  \n  \n  \nllm = OpenAI(temperature=0)  \nconversation = ConversationChain(  \n llm=llm,  \n verbose=True,  \n memory=ConversationBufferMemory()  \n)`\n`conversation.predict(input="Hi there!")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n  \n Human: Hi there!  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " Hi there! It\'s nice to meet you. How can I help you today?"`\n`conversation.predict(input="I\'m doing well! Just having a conversation with an AI.")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n Human: Hi there!  \n AI: Hi there! It\'s nice to meet you. How can I help you today?  \n Human: I\'m doing well! Just having a conversation with an AI.  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " That\'s great! It\'s always nice to have a conversation with someone new. What would you like to talk about?"`\n`conversation.predict(input="Tell me about yourself.")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n Human: Hi there!  \n AI: Hi there! It\'s nice to meet you. How can I help you today?  \n Human: I\'m doing well! Just having a conversation with an AI.  \n AI: That\'s great! It\'s always nice to have a conversation with someone new. What would you like to talk about?  \n Human: Tell me about yourself.  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " Sure! I\'m an AI created to help people with their everyday tasks. I\'m programmed to understand natural language and provide helpful information. I\'m also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers."`\n\n## 保存消息历史[\u200b](#保存消息历史 "Direct link to 保存消息历史")\n\n您经常需要保存消息，然后加载它们以便再次使用。这可以通过先将消息转换为普通的 Python 字典，保存这些字典（如 json 或其他格式），然后加载它们来轻松完成。以下是一个示例。\n\n`import json  \n  \nfrom langchain.memory import ChatMessageHistory  \nfrom langchain.schema import messages_from_dict, messages_to_dict  \n  \nhistory = ChatMessageHistory()  \n  \nhistory.add_user_message("hi!")  \n  \nhistory.add_ai_message("whats up?")`\n`dicts = messages_to_dict(history.messages)`\n`dicts`\n `[{\'type\': \'human\', \'data\': {\'content\': \'hi!\', \'additional_kwargs\': {}}},  \n {\'type\': \'ai\', \'data\': {\'content\': \'whats up?\', \'additional_kwargs\': {}}}]`\n`new_messages = messages_from_dict(dicts)`\n`new_messages`\n `[HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]`\n\n这就是入门的全部内容！有许多不同类型的内存，请查看我们的示例以了解全部内容', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://python.langchain.com.cn/docs/modules/memory/', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99988127, 'save_path': None}}, {'paper_id': '', 'title': 'Short-term memory - Docs by LangChain', 'authors': [], 'abstract': '[Docs by LangChain home page](/)\n\n[LangChain](/oss/python/langchain/overview)[LangGraph](/oss/python/langgraph/overview)[Deep Agents](/oss/python/deepagents/overview)[Integrations](/oss/python/integrations/providers/overview)[Learn](/oss/python/learn)[Reference](/oss/python/reference/overview)[Contribute](/oss/python/contributing/overview)\n\n##### Get started\n\n* [Install](/oss/python/langchain/install)\n* [Quickstart](/oss/python/langchain/quickstart)\n* [Changelog](https://docs.langchain.com/oss/python/releases/changelog)\n* [Philosophy](/oss/python/langchain/philosophy)\n\n##### Core components\n\n* [Agents](/oss/python/langchain/agents)\n* [Models](/oss/python/langchain/models)\n* [Messages](/oss/python/langchain/messages)\n* [Tools](/oss/python/langchain/tools)\n* [Short-term memory](/oss/python/langchain/short-term-memory)\n* [Structured output](/oss/python/langchain/structured-output)\n\n##### Middleware\n\n* [Overview](/oss/python/langchain/middleware/overview)\n* [Built-in middleware](/oss/python/langchain/middleware/built-in)\n* [Custom middleware](/oss/python/langchain/middleware/custom)\n\n##### Advanced usage\n\n* [Guardrails](/oss/python/langchain/guardrails)\n* [Runtime](/oss/python/langchain/runtime)\n* [Context engineering](/oss/python/langchain/context-engineering)\n* [Model Context Protocol (MCP)](/oss/python/langchain/mcp)\n* [Human-in-the-loop](/oss/python/langchain/human-in-the-loop)\n* [Retrieval](/oss/python/langchain/retrieval)\n* [Long-term memory](/oss/python/langchain/long-term-memory)\n\n##### Agent development\n\n* [LangSmith Studio](/oss/python/langchain/studio)\n* [Test](/oss/python/langchain/test)\n* [Agent Chat UI](/oss/python/langchain/ui)\n\n##### Deploy with LangSmith\n\n* [Deployment](/oss/python/langchain/deploy)\n* [Observability](/oss/python/langchain/observability)\n\n* [Overview](#overview)\n* [Usage](#usage)\n* [In production](#in-production)\n* [Customizing agent memory](#customizing-agent-memory)\n* [Common patterns](#common-patterns)\n* [Trim messages](#trim-messages)\n* [Delete messages](#delete-messages)\n* [Summarize messages](#summarize-messages)\n* [Access memory](#access-memory)\n* [Tools](#tools)\n* [Read short-term memory in a tool](#read-short-term-memory-in-a-tool)\n* [Write short-term memory from tools](#write-short-term-memory-from-tools)\n* [Prompt](#prompt)\n* [Before model](#before-model)\n* [After model](#after-model)\n\n[Core components](/oss/python/langchain/agents)\n\n# Short-term memory\n\n## [\u200b](#overview) Overview\n\nMemory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction. Short term memory lets your application remember previous interactions within a single thread or conversation.\n\nA thread organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n\nConversation history is the most common form of short-term memory. Long conversations pose a challenge to today’s LLMs; a full history may not fit inside an LLM’s context window, resulting in an context loss or errors. Even if your model supports the full context length, most LLMs still perform poorly over long contexts. They get “distracted” by stale or off-topic content, all while suffering from slower response times and higher costs. Chat models accept context using [messages](/oss/python/langchain/messages), which include instructions (a system message) and inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited, many applications can benefit from using techniques to remove or “forget” stale information.\n\n## [\u200b](#usage) Usage\n\nTo add short-term memory (thread-level persistence) to an agent, you need to specify a `checkpointer` when creating an agent.\n\nLangChain’s agent manages short-term memory as a part of your agent’s state.By storing these in the graph’s state, the agent can access the full context for a given conversation while maintaining separation between different threads.State is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.Short-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver  agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(), )) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"configurable": {"thread_id": "1"}},  {"configurable": {"thread_id": "1"}}, ))\n```\n\n### [\u200b](#in-production) In production\n\nIn production, use a checkpointer backed by a database:\n\nCopy\n\n```\npip install langgraph-checkpoint-postgres pip  install langgraph-checkpoint-postgres\n```\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from langgraph.checkpoint.postgres import PostgresSaver from langgraph.checkpoint.postgres import  PostgresSaver  DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable" DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"with PostgresSaver.from_conn_string(DB_URI) as checkpointer: with PostgresSaver.from_conn_string(DB_URI) as checkpointer: checkpointer.setup() # auto create tables in PostgresSql checkpointer.setup() # auto create tables in PostgresSql agent = create_agent( agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=checkpointer,  checkpointer =checkpointer,  ) )\n```\n\nFor more checkpointer options including SQLite, Postgres, and Azure Cosmos DB, see the [list of checkpointer libraries](/oss/python/langgraph/persistence#checkpointer-libraries) in the Persistence documentation.\n\n## [\u200b](#customizing-agent-memory) Customizing agent memory\n\nBy default, agents use [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to manage short term memory, specifically the conversation history via a `messages` key. You can extend [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to add additional fields. Custom state schemas are passed to [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) using the [`state_schema`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware.state_schema) parameter.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver class CustomAgentState(AgentState): class  CustomAgentState(AgentState):  user_id: str user_id: str preferences: dict preferences: dict agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomAgentState,  state_schema =CustomAgentState,  checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) # Custom state can be passed in invoke # Custom state can be passed in invokeresult = agent.invoke(result = agent.invoke( { { "messages": [{"role": "user", "content": "Hello"}],  "messages": [{"role": "user", "content": "Hello"}], "user_id": "user_123",  "user_id": "user_123",  "preferences": {"theme": "dark"}  "preferences": {"theme": "dark"}  }, }, {"configurable": {"thread_id": "1"}}) {"configurable": {"thread_id": "1"}})\n```\n\n## [\u200b](#common-patterns) Common patterns\n\nWith [short-term memory](#add-short-term-memory) enabled, long conversations can exceed the LLM’s context window. Common solutions are:\n\n[## Trim messages\n\nRemove first or last N messages (before calling LLM)](#trim-messages)[## Delete messages\n\nDelete messages from LangGraph state permanently](#delete-messages)[## Summarize messages\n\nSummarize earlier messages in the history and replace them with a summary](#summarize-messages)\n\n## Custom strategies\n\nCustom strategies (e.g., message filtering, etc.)\n\nThis allows the agent to keep track of the conversation without exceeding the LLM’s context window.\n\n### [\u200b](#trim-messages) Trim messages\n\nMost LLMs have a maximum supported context window (denominated in tokens). One way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you’re using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the `strategy` (e.g., keep the last `max_tokens`) to use for handling the boundary. To trim message history in an agent, use the [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware decorator:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( your_model_here, your_model_here, tools=your_tools_here,  tools =your_tools_here, middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#delete-messages) Delete messages\n\nYou can delete messages from the graph state to manage the message history. This is useful when you want to remove specific messages or clear the entire message history. To delete messages from the graph state, you can use the `RemoveMessage`. For `RemoveMessage` to work, you need to use a state key with [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) [reducer](/oss/python/langgraph/graph-api#reducers). The default [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) provides this. To remove specific messages:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessage def delete_messages(state): def  delete_messages(state): messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]} \n```\n\nTo remove **all** messages:\n\nCopy\n\n```\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGES def delete_messages(state): def  delete_messages(state): return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  return {"messages": [RemoveMessage(id = REMOVE_ALL_MESSAGES)]} \n```\n\nWhen deleting messages, **make sure** that the resulting message history is valid. Check the limitations of the LLM provider you’re using. For example:\n\n* Some providers expect message history to start with a `user` message\n* Most providers require `assistant` messages with tool calls to be followed by corresponding `tool` result messages.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig  @after_model @after_modeldef delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None: def  delete_old_messages(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove old messages to keep conversation manageable.""" """Remove old messages to keep conversation manageable.""" messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]}  return None  return  None agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], system_prompt="Please be concise and to the point.",  system_prompt ="Please be concise and to the point.", middleware=[delete_old_messages],  middleware =[delete_old_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]]) for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "what\'s my name?"}]}, {"messages": [{"role": "user", "content": "what\'s my name?"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]])\n```\n\nCopy\n\n```\n[(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')] \n```\n\n### [\u200b](#summarize-messages) Summarize messages\n\nThe problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue. Because of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.  To summarize message history in an agent, use the built-in [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization):\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langchain.agents.middleware import SummarizationMiddleware from langchain.agents.middleware import  SummarizationMiddlewarefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig checkpointer = InMemorySaver() checkpointer = InMemorySaver() agent = create_agent(agent = create_agent( model="gpt-4o",  model ="gpt-4o", tools=[],  tools =[], middleware=[ middleware =[ SummarizationMiddleware( SummarizationMiddleware( model="gpt-4o-mini",  model ="gpt-4o-mini", trigger=("tokens", 4000),  trigger =("tokens", 4000), keep=("messages", 20)  keep =("messages", 20) ) ) ], ], checkpointer=checkpointer,  checkpointer =checkpointer,)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}}agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob!Your name is Bob! """ """\n```\n\nSee [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization) for more configuration options.\n\n## [\u200b](#access-memory) Access memory\n\nYou can access and modify the short-term memory (state) of an agent in several ways:\n\n### [\u200b](#tools) Tools\n\n#### [\u200b](#read-short-term-memory-in-a-tool) Read short-term memory in a tool\n\nAccess short term memory (state) in a tool using the `runtime` parameter (typed as `ToolRuntime`). The `runtime` parameter is hidden from the tool signature (so the model doesn’t see it), but the tool can access the state through it.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntime class CustomState(AgentState): class  CustomState(AgentState): user_id: str user_id: str @tool @tooldef get_user_info(def  get_user_info( runtime: ToolRuntime  runtime: ToolRuntime) -> str:) -> str: """Look up user info.""" """Look up user info.""" user_id = runtime.state["user_id"]  user_id = runtime.state["user_id"] return "User is John Smith" if user_id == "user_123" else "Unknown user"  return  "User is John Smith"  if  user_id ==  "user_123"  else  "Unknown user" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomState,  state_schema =CustomState,)) result = agent.invoke({result = agent.invoke({ "messages": "look up user information",  "messages": "look up user information", "user_id": "user_123"  "user_id": "user_123"})})print(result["messages"][-1].content) print(result["messages"][- 1].content)# > User is John Smith.# > User is John Smith.\n```\n\n#### [\u200b](#write-short-term-memory-from-tools) Write short-term memory from tools\n\nTo modify the agent’s short-term memory (state) during execution, you can return state updates directly from the tools. This is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.\n\nCopy\n\n```\nfrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langchain.messages import ToolMessage from langchain.messages import  ToolMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.types import Command from langgraph.types import  Command from pydantic import BaseModel from  pydantic import  BaseModel class CustomState(AgentState): class  CustomState(AgentState):  user_name: str user_name: str class CustomContext(BaseModel): class  CustomContext(BaseModel): user_id: str user_id: str @tool @tooldef update_user_info(def  update_user_info( runtime: ToolRuntime[CustomContext, CustomState],  runtime: ToolRuntime[CustomContext, CustomState],) -> Command:) -> Command: """Look up and update user info.""" """Look up and update user info.""" user_id = runtime.context.user_id  user_id = runtime.context.user_id name = "John Smith" if user_id == "user_123" else "Unknown user"  name =  "John Smith"  if  user_id ==  "user_123"  else  "Unknown user" return Command(update={  return Command(update ={  "user_name": name,  "user_name": name,  # update the message history  # update the message history "messages": [ "messages": [ ToolMessage( ToolMessage( "Successfully looked up user information",  "Successfully looked up user information", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) @tool @tooldef greet(def  greet( runtime: ToolRuntime[CustomContext, CustomState]  runtime: ToolRuntime[CustomContext, CustomState]) -> str | Command:) -> str  | Command: """Use this to greet the user once you found their info.""" """Use this to greet the user once you found their info.""" user_name = runtime.state.get("user_name", None)  user_name = runtime.state.get("user_name", None) if user_name is None:  if  user_name is  None: return Command(update={ return Command(update ={ "messages": [ "messages": [ ToolMessage( ToolMessage( "Please call the \'update_user_info\' tool it will get and update the user\'s name.", "Please call the \'update_user_info\' tool it will get and update the user\'s name.", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) return f"Hello {user_name}!"  return  f "Hello {user_name}!" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[update_user_info, greet],  tools =[update_user_info, greet], state_schema=CustomState,  state_schema =CustomState,  context_schema=CustomContext,  context_schema =CustomContext,)) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "greet the user"}]}, {"messages": [{"role": "user", "content": "greet the user"}]}, context=CustomContext(user_id="user_123"),  context =CustomContext(user_id = "user_123"),))\n```\n\n### [\u200b](#prompt) Prompt\n\nAccess short term memory (state) in middleware to create dynamic prompts based on conversation history or custom state fields.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from typing import TypedDict from  typing import  TypedDictfrom langchain.agents.middleware import dynamic_prompt, ModelRequest from langchain.agents.middleware import dynamic_prompt, ModelRequest class CustomContext(TypedDict): class  CustomContext(TypedDict): user_name: str user_name: str def get_weather(city: str) -> str: def  get_weather(city: str) -> str: """Get the weather in a city.""" """Get the weather in a city.""" return f"The weather in {city} is always sunny!"  return  f "The weather in {city} is always sunny!"  @dynamic_prompt @dynamic_promptdef dynamic_system_prompt(request: ModelRequest) -> str: def  dynamic_system_prompt(request: ModelRequest) -> str: user_name = request.runtime.context["user_name"]  user_name = request.runtime.context["user_name"] system_prompt = f"You are a helpful assistant. Address the user as {user_name}."  system_prompt =  f"You are a helpful assistant. Address the user as {user_name}."  return system_prompt  return  system_prompt agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_weather],  tools =[get_weather], middleware=[dynamic_system_prompt],  middleware =[dynamic_system_prompt], context_schema=CustomContext,  context_schema =CustomContext,)) result = agent.invoke(result = agent.invoke( {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, context=CustomContext(user_name="John Smith"),  context =CustomContext(user_name = "John Smith"),))for msg in result["messages"]: for  msg in result["messages"]: msg.pretty_print() msg.pretty_print() \n```\n\nOutput\n\nCopy\n\n```\n================================ Human Message ================================= ================================  Human  Message ================================= What is the weather in SF? What  is  the  weather  in  SF? ================================== Ai Message ================================== ==================================  Ai  Message ==================================Tool Calls: Tool Calls: get_weather (call_WFQlOGn4b2yoJrv7cih342FG)  get_weather (call_WFQlOGn4b2yoJrv7cih342FG) Call ID: call_WFQlOGn4b2yoJrv7cih342FG  Call ID:  call_WFQlOGn4b2yoJrv7cih342FG Args: Args: city: San Francisco city:  San  Francisco ================================= Tool Message ================================= =================================  Tool  Message =================================Name: get_weatherName:  get_weather The weather in San Francisco is always sunny! The  weather  in  San  Francisco  is  always sunny! ================================== Ai Message ================================== ==================================  Ai  Message ================================== Hi John Smith, the weather in San Francisco is always sunny! Hi  John Smith,  the  weather  in  San  Francisco  is  always sunny!\n```\n\n### [\u200b](#before-model) Before model\n\nAccess short term memory (state) in [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware to process messages before model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver()  checkpointer =InMemorySaver())) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#after-model) After model\n\nAccess short term memory (state) in [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) middleware to process messages after model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime  @after_model @after_modeldef validate_response(state: AgentState, runtime: Runtime) -> dict | None: def  validate_response(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove messages containing sensitive words.""" """Remove messages containing sensitive words.""" STOP_WORDS = ["password", "secret"]  STOP_WORDS = ["password", "secret"] last_message = state["messages"][-1]  last_message = state["messages"][- 1] if any(word in last_message.content for word in STOP_WORDS):  if  any(word in last_message.content for  word in  STOP_WORDS): return {"messages": [RemoveMessage(id=last_message.id)]}  return {"messages": [RemoveMessage(id =last_message.id)]}  return None  return  None agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[],  tools =[], middleware=[validate_response],  middleware =[validate_response], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),))\n```\n\n---\n\n[Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/short-term-memory.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n\n[Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n\nWas this page helpful?\n\n[Tools](/oss/python/langchain/tools)[Overview](/oss/python/langchain/streaming/overview)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://docs.langchain.com/oss/python/langchain/short-term-memory', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9995453, 'save_path': None}}, {'paper_id': '', 'title': 'LangChain+LangGraph内存管理与上下文优化完整指南 - 腾讯云', 'authors': [], 'abstract': '[*腾讯云*](/?from=20060&from_column=20060)\n[*开发者社区*](/developer)\n\n[文档](/document/product?from=20702&from_column=20702)[建议反馈](/voc/?from=20703&from_column=20703)[控制台](https://console.cloud.tencent.com?from=20063&from_column=20063)\n\n[首页](/developer)\n\n文章/答案/技术大牛\n\ndeephub\n\n[社区首页](/developer) >[专栏](/developer/column) >AI代理性能提升实战：LangChain+LangGraph内存管理与上下文优化完整指南\n\n# AI代理性能提升实战：LangChain+LangGraph内存管理与上下文优化完整指南\n\ndeephub\n\n发布于 2025-08-20 14:04:48\n\n发布于 2025-08-20 14:04:48\n\n1.6K0\n\n文章被收录于专栏：[DeepHub IMBA](/developer/column/86944)DeepHub IMBA\n\n### 上下文工程的理论基础\n\nDrew Breunig在其研究中详细阐述了过量上下文信息对系统性能的负面影响，包括上下文污染（错误信息或幻觉内容被引入上下文）、上下文干扰（过量信息导致模型混乱）、上下文混淆（冗余细节影响响应质量）以及上下文冲突（不同上下文片段提供相互矛盾的信息）。\n\n### 基于LangGraph的Scratchpad实现机制\n\nAnthropic的多代理研究系统提供了一个典型的应用案例：LeadResearcher会制定详细的研究计划并将其保存到内存中，这样做的目的是防止当上下文窗口超过200,000个令牌时发生信息截断，确保重要的规划信息不会丢失。\n\nScratchpad的实现方式主要有两种：一种是通过工具调用将信息写入文件系统，另一种是作为会话期间持续存在的运行时状态对象中的字段。简而言之，Scratchpad技术帮助代理在整个会话过程中维护重要的工作记录，从而高效地完成复杂任务。\n\n就LangGraph框架而言，它提供了对短期内存（线程作用域）和长期内存的全面支持。短期内存通过检查点机制在会话期间保存代理状态，其工作原理类似于Scratchpad，允许在代理运行过程中存储信息并在稍后进行检索。\n\n状态对象是在图节点之间传递的核心数据结构。开发者可以自定义其格式（通常采用Python字典结构），它充当共享的Scratchpad，每个节点都可以读取和更新特定字段的内容。\n\n为了确保学习过程的清晰性，我们采用按需导入的方式引入所需模块。为了获得更优质的输出效果，我们将使用Python的`pprint`模块进行格式化打印，以及来自`rich`库的`Console`模块。首先进行这些模块的导入和初始化：\n\n代码语言：javascript\n\n复制\n\n```\n # Import necessary libraries from typing import TypedDict # For defining the state schema with type hints from rich.console import Console # 用于美化输出显示 from rich.pretty import pprint # 用于美化Python对象的打印输出 # 为notebook环境初始化丰富格式化输出的控制台实例 console = Console()\n```\n\n接下来，我们将为状态对象创建一个`TypedDict`类型定义：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用TypedDict定义图状态的数据模式 # 该类作为在图节点间传递的数据结构 # 确保状态具有一致的数据结构并提供类型提示功能 class State(TypedDict): """ 定义笑话生成器工作流的状态结构 属性说明: topic: 用于生成笑话的输入主题 joke: 存储生成笑话内容的输出字段 """ topic: str joke: str\n```\n\n该状态对象将存储主题信息以及代理基于给定主题生成的笑话内容。\n\n在定义状态对象之后，我们可以通过StateGraph向其写入上下文信息。StateGraph是LangGraph框架用于构建有状态代理或工作流的核心工具，可以将其理解为一个有向图结构：节点代表工作流中的执行步骤，每个节点接收当前状态作为输入，对其进行更新，并返回修改结果；边用于连接节点，定义执行流程的路径，这种路径可以是线性的、条件性的，甚至是循环性的。\n\n接下来的实现步骤包括：通过选择Anthropic模型来创建聊天模型，并将其集成到LangGraph工作流中。\n\n代码语言：javascript\n\n复制\n\n```\n # 导入环境管理、显示功能和LangGraph相关的必要库 import getpass import os from IPython.display import Image, display from langchain.chat_models import init_chat_model from langgraph.graph import END, START, StateGraph # --- 环境配置和模型初始化 --- # 设置Anthropic API密钥用于请求认证 from dotenv import load_dotenv api_key = os.getenv("ANTHROPIC_API_KEY") if not api_key: raise ValueError("Missing ANTHROPIC_API_KEY in environment") # 初始化工作流中使用的聊天模型 # 使用特定的Claude模型，temperature=0确保输出的确定性 llm = init_chat_model("anthropic:claude-sonnet-4-20250514", temperature=0)\n```\n\n我们已经成功初始化了Sonnet模型。LangChain框架通过其API接口支持众多开源和商业模型，因此开发者可以根据需求选择合适的模型。\n\n现在需要创建一个使用该Sonnet模型生成响应的函数：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 定义工作流节点函数 --- def generate_joke(state: State) -> dict[str, str]: """ 基于当前状态中的主题信息生成笑话的节点函数 该函数从状态中读取\'topic\'字段，使用LLM生成相应的笑话内容， 并返回用于更新状态中\'joke\'字段的字典 参数: state: 包含主题信息的图当前状态 返回值: 包含\'joke\'键的字典，用于更新状态 """ # 从状态中提取主题信息 topic = state["topic"] print(f"正在生成关于{topic}的笑话") # 调用语言模型生成笑话内容 msg = llm.invoke(f"Write a short joke about {topic}") # 返回生成的笑话用于状态更新 return {"joke": msg.content}\n```\n\n该函数的核心功能是返回包含生成响应（笑话内容）的字典结构。\n\n现在，利用StateGraph可以便捷地构建和编译图结构。让我们继续实现这一过程：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 图结构的构建与编译 --- # 使用预定义的State模式初始化StateGraph实例 workflow = StateGraph(State) # 将\'generate_joke\'函数作为节点添加到图中 workflow.add_node("generate_joke", generate_joke) # 定义工作流的执行路径： # 图从START入口点开始，流向\'generate_joke\'节点 workflow.add_edge(START, "generate_joke") # \'generate_joke\'节点完成后，图执行结束 workflow.add_edge("generate_joke", END) # 将工作流编译为可执行的链式结构 chain = workflow.compile() # --- 图结构可视化 --- # 显示编译后工作流图的可视化表示 display(Image(chain.get_graph().draw_mermaid_png()))\n```\n\n现在可以执行这个工作流程：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 工作流执行 --- # 使用包含主题的初始状态调用编译后的图 # `invoke`方法执行从START节点到END节点的完整流程 joke_generator_state = chain.invoke({"topic": "cats"}) # --- 最终状态显示 --- # 打印执行后图的最终状态 # 将显示输入的\'topic\'和写入状态的输出\'joke\' console.print("\\n[bold blue]笑话生成器状态:[/bold blue]") pprint(joke_generator_state) #### 输出结果 #### { \'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\' }\n```\n\n执行结果返回的字典实际上代表了代理的笑话生成状态。这个简单的示例演示了如何向状态写入上下文信息的基本机制。\n\n开发者可以进一步了解检查点技术用于保存和恢复图状态，以及人机交互循环技术用于在继续执行之前暂停工作流以获取人工输入。\n\n### LangGraph中的内存写入机制\n\n虽然Scratchpad技术有助于代理在单个会话内进行工作，但在某些场景下，代理需要跨多个会话保持信息记忆。Reflexion技术引入了代理在每次交互后进行反思并重用自生成提示的概念，而Generative Agents则通过总结历史代理反馈来创建长期记忆机制。\n\n这些创新理念已被应用于ChatGPT、Cursor和Windsurf等主流产品中，这些系统能够从用户交互中自动创建长期记忆。\n\nLangGraph框架的内存机制包含两个关键组件：检查点技术在线程的每个步骤中保存图的状态，其中线程具有唯一标识符，通常代表一次完整的交互（类似ChatGPT中的单次对话）；长期内存技术允许跨线程保持特定上下文，可以保存单个文件（如用户配置文件）或记忆集合。该系统基于BaseStore接口实现，这是一个键值存储系统，可以在内存中使用（如本示例所示）或与LangGraph平台部署配合使用。\n\n现在让我们创建一个`InMemoryStore`实例，用于在本notebook的多个会话中使用：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.store.memory import InMemoryStore # --- 长期内存存储初始化 --- # 创建InMemoryStore实例，提供简单的非持久化键值存储系统 # 用于当前会话内的数据管理 store = InMemoryStore() # --- 命名空间定义 --- # 命名空间用于在存储中逻辑性地分组相关数据 # 这里使用元组表示分层命名空间结构 # 可能对应用户ID和应用程序上下文 namespace = ("rlm", "joke_generator") # --- 向内存存储写入数据 --- # 使用`put`方法将键值对保存到指定命名空间 # 该操作持久化前一步生成的笑话，使其可在不同会话或线程中检索 store.put( namespace, # 写入目标命名空间 "last_joke", # 数据条目的键标识符 {"joke": joke_generator_state["joke"]}, # 待存储的值 )\n```\n\n我们将在后续部分讨论如何从命名空间中选择上下文。目前可以使用search方法查看命名空间内的项目，以确认数据写入操作的成功：\n\n代码语言：javascript\n\n复制\n\n```\n # 搜索命名空间以查看所有存储项目 stored_items = list(store.search(namespace)) # 使用丰富格式显示存储的项目 console.print("\\n[bold green]内存中存储的项目:[/bold green]") pprint(stored_items) #### 输出结果 #### [ Item(namespace=[\'rlm\', \'joke_generator\'], key=\'last_joke\', value={\'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}, created_at=\'2025-07-24T02:12:25.936238+00:00\', updated_at=\'2025-07-24T02:12:25.936238+00:00\', score=None) ]\n```\n\n现在，让我们将前面实现的所有功能集成到LangGraph工作流中。\n\n工作流编译需要两个关键参数：`checkpointer`用于在线程的每个步骤保存图状态，`store`用于跨不同线程维护上下文。\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.checkpoint.memory import InMemorySaver from langgraph.store.base import BaseStore from langgraph.store.memory import InMemoryStore # 存储组件初始化 checkpointer = InMemorySaver() # 线程级状态持久化 memory_store = InMemoryStore() # 跨线程内存存储 def generate_joke(state: State, store: BaseStore) -> dict[str, str]: """生成具有内存感知能力的笑话 该增强版本在生成新笑话之前检查内存中的现有笑话 参数: state: 包含主题的当前状态 store: 用于持久化上下文的内存存储 返回值: 包含生成笑话的字典 """ # 检查内存中是否存在现有笑话 existing_jokes = list(store.search(namespace)) if existing_jokes: existing_joke = existing_jokes[0].value print(f"现有笑话: {existing_joke}") else: print("现有笑话: 无") # 基于主题生成新笑话 msg = llm.invoke(f"Write a short joke about {state[\'topic\']}") # 将新笑话存储到长期内存中 store.put(namespace, "last_joke", {"joke": msg.content}) # 返回待添加到状态的笑话 return {"joke": msg.content} # 构建具有内存功能的工作流 workflow = StateGraph(State) # 添加内存感知的笑话生成节点 workflow.add_node("generate_joke", generate_joke) # 连接工作流组件 workflow.add_edge(START, "generate_joke") workflow.add_edge("generate_joke", END) # 使用检查点和内存存储进行编译 chain = workflow.compile(checkpointer=checkpointer, store=memory_store)\n```\n\n现在可以执行更新后的工作流，测试启用内存功能后的运行效果：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用基于线程的配置执行工作流 config = {"configurable": {"thread_id": "1"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) # 使用丰富格式显示工作流结果 console.print("\\n[bold cyan]工作流结果 (线程 1):[/bold cyan]") pprint(joke_generator_state) #### 输出结果 #### 现有笑话: 无 工作流结果 (线程 1): {\'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}\n```\n\n由于这是线程1的首次执行，AI代理的内存中没有存储现有笑话，这完全符合新线程的预期行为。\n\n由于工作流使用检查点进行编译，现在可以查看图的最新状态：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 检索和检查图状态 --- # 使用`get_state`方法检索配置中指定线程的最新状态快照 # （在此案例中为线程"1"）。由于使用检查点编译了图，该操作成为可能 latest_state = chain.get_state(config) # --- 状态快照显示 --- # 将检索到的状态输出到控制台。StateSnapshot不仅包含数据（\'topic\'，\'joke\'） # 还包含执行元数据 console.print("\\n[bold magenta]最新图状态 (线程 1):[/bold magenta]") pprint(latest_state)\n```\n\n观察输出结果：\n\n代码语言：javascript\n\n复制\n\n```\n ### 最新状态输出 ### 最新图状态: StateSnapshot( values={ \'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\' }, next=(), config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f06833a-53a7-65a8-8001-548e412001c4\' } }, metadata={\'source\': \'loop\', \'step\': 1, \'parents\': {}}, created_at=\'2025-07-24T02:12:27.317802+00:00\', parent_config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f06833a-4a50-6108-8000-245cde0c2411\' } }, tasks=(), interrupts=() )\n```\n\n可以看到状态中记录了与代理的最后一次对话内容，即我们请求它讲述关于猫的笑话。\n\n现在使用不同的线程ID重新运行工作流：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用不同线程ID执行工作流 config = {"configurable": {"thread_id": "2"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) # 显示结果，展示跨线程的内存持久性 console.print("\\n[bold yellow]工作流结果 (线程 2):[/bold yellow]") pprint(joke_generator_state) #### 输出结果 #### 现有笑话: {\'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'} 工作流结果 (线程 2): {\'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}\n```\n\n可以验证来自第一个线程的笑话已成功保存到内存中。\n\n开发者可以进一步了解LangMem内存抽象技术和Ambient Agents课程，以获得LangGraph代理中内存管理的深入概述。\n\n### Scratchpad上下文选择机制\n\n从Scratchpad中选择上下文的具体方法取决于其实现架构：当Scratchpad作为工具实现时，代理可以通过工具调用直接读取其内容；当其作为代理运行时状态的组成部分时，开发者需要决定在每个执行步骤中与代理共享状态的哪些特定部分，这种方式提供了对暴露上下文内容的精细化控制能力。\n\n在前面的实现中，我们学习了如何向LangGraph状态对象写入数据。现在将探讨如何从状态中选择性地提取上下文信息，并将其传递给下游节点中的LLM调用。这种选择性方法使开发者能够精确控制LLM在执行过程中接收的上下文内容。\n\n代码语言：javascript\n\n复制\n\n```\n def generate_joke(state: State) -> dict[str, str]: """生成基于主题的初始笑话 参数: state: 包含主题信息的当前状态 返回值: 包含生成笑话的字典 """ msg = llm.invoke(f"Write a short joke about {state[\'topic\']}") return {"joke": msg.content} def improve_joke(state: State) -> dict[str, str]: """通过添加文字游戏元素改进现有笑话 该函数演示了从状态中选择上下文的过程——从状态中读取现有笑话 并基于此生成改进版本 参数: state: 包含原始笑话的当前状态 返回值: 包含改进笑话的字典 """ print(f"初始笑话: {state[\'joke\']}") # 从状态中选择笑话内容呈现给LLM msg = llm.invoke(f"Make this joke funnier by adding wordplay: {state[\'joke\']}") return {"improved_joke": msg.content}\n```\n\n为了增加系统复杂性，我们现在向代理添加两个工作流程：第一个是笑话生成流程（与之前相同），第二个是笑话改进流程（获取生成的笑话并对其进行优化）。\n\n这种配置将帮助我们理解Scratchpad选择机制在LangGraph中的运作方式。现在以与之前相同的方式编译此工作流并检查图结构：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建包含两个顺序节点的工作流 workflow = StateGraph(State) # 添加两个笑话处理节点 workflow.add_node("generate_joke", generate_joke) workflow.add_node("improve_joke", improve_joke) # 按顺序连接节点 workflow.add_edge(START, "generate_joke") workflow.add_edge("generate_joke", "improve_joke") workflow.add_edge("improve_joke", END) # 编译工作流 chain = workflow.compile() # 显示工作流可视化 display(Image(chain.get_graph().draw_mermaid_png()))\n```\n\n执行该工作流时的结果如下：\n\n代码语言：javascript\n\n复制\n\n```\n # 执行工作流以观察上下文选择的实际效果 joke_generator_state = chain.invoke({"topic": "cats"}) # 使用丰富格式显示最终状态 console.print("\\n[bold blue]最终工作流状态:[/bold blue]") pprint(joke_generator_state) #### 输出结果 #### 初始笑话: Why did the cat join a band? Because it wanted to be the purr-cussionist! 最终工作流状态: { \'topic\': \'cats\', \'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\' }\n```\n\n完成工作流执行后，我们可以继续进行内存选择步骤的实现。\n\n### 内存选择能力的实现\n\n当代理具备保存记忆的能力时，同样需要为当前任务选择相关的记忆内容。这种能力在以下场景中特别有用：情节记忆（展示期望行为的few-shot示例）、程序记忆（指导行为执行的指令）以及语义记忆（提供任务相关上下文的事实或关系信息）。\n\n一些代理系统使用预定义的文件来存储记忆内容：Claude Code使用`CLAUDE.md`文件，而Cursor和Windsurf使用"规则"文件来存储指令或示例。然而，当需要存储大量事实集合（语义记忆）时，选择过程变得更加复杂。\n\nChatGPT有时会检索不相关的记忆内容，正如Simon Willison所演示的案例，当ChatGPT错误地获取他的位置信息并将其注入图像生成过程中时，导致上下文感觉"不再属于用户本人"。为了改进选择精度，系统通常采用嵌入技术或知识图谱进行索引。\n\n在之前的部分中，我们在图节点中写入了`InMemoryStore`。现在可以使用get方法从中选择上下文，将相关状态信息引入工作流：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.store.memory import InMemoryStore # 初始化内存存储 store = InMemoryStore() # 定义用于组织记忆的命名空间 namespace = ("rlm", "joke_generator") # 将生成的笑话存储在内存中 store.put( namespace, # 组织用命名空间 "last_joke", # 键标识符 {"joke": joke_generator_state["joke"]} # 待存储的值 ) # 从内存中选择（检索）笑话内容 retrieved_joke = store.get(namespace, "last_joke").value # 显示检索到的上下文 console.print("\\n[bold green]从内存检索的上下文:[/bold green]") pprint(retrieved_joke) #### 输出结果 #### 从内存检索的上下文: {\'joke\': \'Why did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!\'}\n```\n\n系统成功地从内存中检索了正确的笑话内容。\n\n现在需要编写一个完整的`generate_joke`函数，该函数能够：获取当前状态（用于scratchpad上下文），利用内存（在执行笑话改进任务时获取历史笑话）。\n\n让我们实现这一功能：\n\n代码语言：javascript\n\n复制\n\n```\n # 初始化存储组件 checkpointer = InMemorySaver() memory_store = InMemoryStore() def generate_joke(state: State, store: BaseStore) -> dict[str, str]: """生成具有内存感知上下文选择能力的笑话 该函数演示了在生成新内容之前从内存中选择上下文的过程， 确保内容一致性并避免重复 参数: state: 包含主题的当前状态 store: 用于持久化上下文的内存存储 返回值: 包含生成笑话的字典 """ # 从内存中选择先前的笑话（如果存在） prior_joke = store.get(namespace, "last_joke") if prior_joke: prior_joke_text = prior_joke.value["joke"] print(f"先前笑话: {prior_joke_text}") else: print("先前笑话: 无") # 生成与先前笑话不同的新笑话 prompt = ( f"Write a short joke about {state[\'topic\']}, " f"but make it different from any prior joke you\'ve written: {prior_joke_text if prior_joke else \'None\'}" ) msg = llm.invoke(prompt) # 将新笑话存储在内存中供未来上下文选择使用 store.put(namespace, "last_joke", {"joke": msg.content}) return {"joke": msg.content}\n```\n\n现在可以以与之前相同的方式执行这个内存感知工作流：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建内存感知工作流 workflow = StateGraph(State) workflow.add_node("generate_joke", generate_joke) # 连接工作流 workflow.add_edge(START, "generate_joke") workflow.add_edge("generate_joke", END) # 使用检查点和内存存储进行编译 chain = workflow.compile(checkpointer=checkpointer, store=memory_store) # 使用第一个线程执行工作流 config = {"configurable": {"thread_id": "1"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) #### 输出结果 #### 先前笑话: 无\n```\n\n没有检测到先前的笑话，现在可以打印最新的状态结构：\n\n代码语言：javascript\n\n复制\n\n```\n # 获取图的最新状态 latest_state = chain.get_state(config) console.print("\\n[bold magenta]最新图状态:[/bold magenta]") pprint(latest_state)\n```\n\n输出结果：\n\n代码语言：javascript\n\n复制\n\n```\n #### 最新状态输出 #### StateSnapshot( values={ \'topic\': \'cats\', \'joke\': "Here\'s a new one:\\n\\nWhy did the cat join a band?\\n\\nBecause it wanted to be the purr-cussionist!" }, next=(), config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f068357-cc8d-68cb-8001-31f64daf7bb6\' } }, metadata={\'source\': \'loop\', \'step\': 1, \'parents\': {}}, created_at=\'2025-07-24T02:25:38.457825+00:00\', parent_config={ \'configurable\': { \'thread_id\': \'1\', \'checkpoint_ns\': \'\', \'checkpoint_id\': \'1f068357-c459-6deb-8000-16ce383a5b6b\' } }, tasks=(), interrupts=() )\n```\n\n系统从内存中获取先前的笑话并将其传递给LLM进行改进：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用第二个线程执行工作流以演示内存持久性 config = {"configurable": {"thread_id": "2"}} joke_generator_state = chain.invoke({"topic": "cats"}, config) #### 输出结果 #### 先前笑话: Here is a new one: Why did the cat join a band? Because it wanted to be the purr-cussionist!\n```\n\n系统已成功从内存中获取正确的笑话并按预期对其进行了改进。\n\n### LangGraph BigTool调用的技术优势\n\n在代理系统中，虽然工具的使用提高了功能性，但为代理提供过多工具可能导致选择困惑，特别是当工具描述存在重叠时。这种情况增加了模型选择正确工具的难度。\n\n一个有效的解决方案是在工具描述上应用RAG（检索增强生成）技术，仅基于语义相似性获取最相关的工具。Drew Breunig将这种方法称为"工具装备"策略。\n\n根据最新研究结果，这种方法能够将工具选择准确率提升3倍。\n\n对于工具选择任务，LangGraph Bigtool库提供了理想的解决方案。该库在工具描述上应用语义相似性搜索来选择最适合执行任务的工具。它利用LangGraph的长期内存存储机制，使代理能够搜索并检索适合特定问题的正确工具。\n\n让我们通过使用包含Python内置数学库所有函数的代理来理解`langgraph-bigtool`的工作原理：\n\n代码语言：javascript\n\n复制\n\n```\n import math # 从`math`内置库收集函数 all_tools = [] for function_name in dir(math): function = getattr(math, function_name) if not isinstance( function, types.BuiltinFunctionType ): continue # 这是`math`库的特定要求 if tool := convert_positional_only_function_to_tool( function ): all_tools.append(tool)\n```\n\n首先将Python数学模块的所有函数收集到列表中。接下来需要将这些工具描述转换为向量嵌入，以便代理能够执行语义相似性搜索。\n\n为此，我们将使用嵌入模型，在本案例中采用OpenAI的文本嵌入模型：\n\n代码语言：javascript\n\n复制\n\n```\n # 创建工具注册表。这是一个将标识符映射到工具实例的字典 tool_registry = { str(uuid.uuid4()): tool for tool in all_tools } # 在LangGraph存储中索引工具名称和描述 # 此处使用简单的内存存储 embeddings = init_embeddings("openai:text-embedding-3-small") store = InMemoryStore( index={ "embed": embeddings, "dims": 1536, "fields": ["description"], } ) for tool_id, tool in tool_registry.items(): store.put( ("tools",), tool_id, { "description": f"{tool.name}: {tool.description}", }, )\n```\n\n每个函数都被分配唯一标识符，并将这些函数结构化为标准格式。这种结构化格式确保函数能够轻松转换为嵌入向量，以支持语义搜索功能。\n\n现在让我们可视化代理，观察在所有数学函数都已嵌入并准备进行语义搜索的情况下系统的表现：\n\n代码语言：javascript\n\n复制\n\n```\n # 初始化代理 builder = create_agent(llm, tool_registry) agent = builder.compile(store=store) agent\n```\n\n现在可以使用简单查询调用代理，观察工具调用代理如何选择和使用最相关的数学函数来回答问题：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入格式化和显示消息的实用函数 from utils import format_messages # 为代理定义查询 # 该查询要求代理使用其数学工具之一计算反余弦值 query = "Use available tools to calculate arc cosine of 0.5." # 使用查询调用代理。代理将搜索其工具， # 根据查询的语义选择\'acos\'工具并执行 result = agent.invoke({"messages": query}) # 格式化并显示代理执行的最终消息 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── Human ───────────────┐ │ Use available tools to calculate │ │ arc cosine of 0.5. │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ I will search for a tool to calculate│ │ the arc cosine of 0.5. │ │ │ │ 🔧 Tool Call: retrieve_tools │ │ Args: { │ │ "query": "arc cosine arccos │ │ inverse cosine trig" │ │ } │ └──────────────────────────────────────┘ ┌────────────── 🔧 Tool Output ────────┐ │ Available tools: [\'acos\', \'acosh\'] │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ Perfect! I found the `acos` function │ │ which calculates the arc cosine. │ │ Now I will use it to calculate the │ │ arc │ │ cosine of 0.5. │ │ │ │ 🔧 Tool Call: acos │ │ Args: { "x": 0.5 } │ │ └──────────────────────────────────────┘ ┌────────────── 🔧 Tool Output ────────┐ │ 1.0471975511965976 │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ The arc cosine of 0.5 is ≈**1.047** │ │ radians. │ │ │ │ ✔ Check: cos(π/3)=0.5, π/3≈1.047 rad │ │ (60°). │ └──────────────────────────────────────┘\n```\n\n可以观察到AI代理如何高效地调用正确的工具。\n\n### 基于上下文工程的RAG系统实现\n\nRAG（检索增强生成）是一个复杂的技术领域，代码代理系统代表了生产环境中代理式RAG的最佳实践案例。\n\n在实际应用中，RAG往往是上下文工程面临的核心技术挑战。正如Windsurf的Varun所指出的：索引处理不等同于上下文检索。基于抽象语法树（AST）分块的嵌入搜索在小规模代码库中表现良好，但随着代码库规模增长会出现性能衰减。我们需要混合检索策略：结合grep模式搜索、文件搜索、知识图谱链接以及基于相关性的重新排序技术。\n\nLangGraph框架提供了丰富的教程和视频资源，帮助开发者将RAG技术集成到代理系统中。通常的做法是构建一个检索工具，该工具可以使用上述任何RAG技术组合。\n\n为了演示这一过程，我们将使用Lilian Weng优秀技术博客中的最新文章为RAG系统获取文档数据。\n\n首先使用`WebBaseLoader`工具获取页面内容：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入WebBaseLoader用于从URL获取文档 from langchain_community.document_loaders import WebBaseLoader # 定义Lilian Weng博客文章的URL列表 urls = [ "https://lilianweng.github.io/posts/2025-05-01-thinking/", "https://lilianweng.github.io/posts/2024-11-28-reward-hacking/", "https://lilianweng.github.io/posts/2024-07-07-hallucination/", "https://lilianweng.github.io/posts/2024-04-12-diffusion-video/", ] # 使用列表推导式从指定URL加载文档 # 为每个URL创建WebBaseLoader实例并调用其load()方法 docs = [WebBaseLoader(url).load() for url in urls]\n```\n\nRAG系统中存在多种数据分块策略，适当的分块技术对于实现有效检索至关重要。\n\n在本实现中，我们将在索引获取的文档到向量存储之前，将其分割为较小的片段。我们采用递归分块技术配合重叠片段的直接方法，在保持片段可管理性的同时，在片段之间保留上下文连续性，以优化嵌入和检索效果：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入用于文档分块的文本分割器 from langchain_text_splitters import RecursiveCharacterTextSplitter # 展平文档列表。WebBaseLoader为每个URL返回文档列表， # 因此得到嵌套列表结构。此推导式将其合并为单一列表 docs_list = [item for sublist in docs for item in sublist] # 初始化文本分割器。该工具将文档分割为指定大小的较小片段， # 片段间保持一定重叠以维持上下文连续性 text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder( chunk_size=2000, chunk_overlap=50 ) # 将文档分割为片段 doc_splits = text_splitter.split_documents(docs_list)\n```\n\n完成文档分割后，可以将其索引到向量存储中进行语义搜索：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入创建内存向量存储所需的类 from langchain_core.vectorstores import InMemoryVectorStore # 从文档片段创建内存向量存储 # 使用前面创建的\'doc_splits\'和之前初始化的\'embeddings\'模型 # 生成文本片段的向量表示 vectorstore = InMemoryVectorStore.from_documents( documents=doc_splits, embedding=embeddings ) # 从向量存储创建检索器 # 检索器提供基于查询搜索相关文档的接口 retriever = vectorstore.as_retriever()\n```\n\n接下来需要创建一个可在代理中使用的检索器工具：\n\n代码语言：javascript\n\n复制\n\n```\n # 导入创建检索器工具的函数 from langchain.tools.retriever import create_retriever_tool # 从向量存储检索器创建检索器工具 # 该工具使代理能够基于查询从博客文章中搜索和检索相关文档 retriever_tool = create_retriever_tool( retriever, "retrieve_blog_posts", "Search and return information about Lilian Weng blog posts.", ) # 以下代码演示了直接调用工具的方法 # 虽然对代理执行流程非必需，但对测试很有用 # retriever_tool.invoke({"query": "types of reward hacking"})\n```\n\n现在可以实现一个能够从工具中选择上下文的代理系统：\n\n代码语言：javascript\n\n复制\n\n```\n # 使用工具增强LLM功能 tools = [retriever_tool] tools_by_name = {tool.name: tool for tool in tools} llm_with_tools = llm.bind_tools(tools)\n```\n\n对于基于RAG的解决方案，需要创建清晰的系统提示来指导代理行为。该提示充当核心指令集：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.graph import MessagesState from langchain_core.messages import SystemMessage, ToolMessage from typing_extensions import Literal rag_prompt = """您是一个专门从Lilian Weng技术博客文章系列中检索信息的智能助手。 在使用检索工具收集上下文之前，请与用户明确研究范围。对获取的任何上下文内容进行分析， 并持续检索直到获得足够的上下文信息来回答用户的研究请求。"""\n```\n\n接下来定义图的核心节点。需要两个主要节点：`llm_call`作为代理的决策中心，接收当前对话历史（用户查询加先前工具输出），然后决定下一步行动——调用工具或生成最终答案；`tool_node`作为代理的执行组件，执行`llm_call`请求的工具调用，并将工具结果返回给代理。\n\n代码语言：javascript\n\n复制\n\n```\n # --- 定义代理节点 --- def llm_call(state: MessagesState): """LLM决策是否调用工具或生成最终答案""" # 将系统提示添加到当前消息状态 messages_with_prompt = [SystemMessage(content=rag_prompt)] + state["messages"] # 使用增强消息列表调用LLM response = llm_with_tools.invoke(messages_with_prompt) # 返回LLM响应以添加到状态 return {"messages": [response]} def tool_node(state: dict): """执行工具调用并返回观察结果""" # 获取包含工具调用的最后一条消息 last_message = state["messages"][-1] # 执行每个工具调用并收集结果 result = [] for tool_call in last_message.tool_calls: tool = tools_by_name[tool_call["name"]] observation = tool.invoke(tool_call["args"]) result.append(ToolMessage(content=str(observation), tool_call_id=tool_call["id"])) # 将工具输出作为消息返回 return {"messages": result}\n```\n\n需要一种方法来控制代理流程，决定应该调用工具还是已完成任务。为此创建条件边函数`should_continue`：该函数检查LLM的最后一条消息是否包含工具调用；如果包含，图路由到`tool_node`；否则执行结束。\n\n代码语言：javascript\n\n复制\n\n```\n # --- 定义条件边 --- def should_continue(state: MessagesState) -> Literal["Action", END]: """根据LLM是否进行工具调用决定下一步""" last_message = state["messages"][-1] # 如果LLM进行了工具调用，路由到tool_node if last_message.tool_calls: return "Action" # 否则结束工作流 return END\n```\n\n现在可以构建工作流并编译图：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建工作流 agent_builder = StateGraph(MessagesState) # 添加节点 agent_builder.add_node("llm_call", llm_call) agent_builder.add_node("environment", tool_node) # 添加连接节点的边 agent_builder.add_edge(START, "llm_call") agent_builder.add_conditional_edges( "llm_call", should_continue, { # should_continue返回的名称 : 下一个访问节点的名称 "Action": "environment", END: END, }, ) agent_builder.add_edge("environment", "llm_call") # 编译代理 agent = agent_builder.compile() # 显示代理结构 display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n```\n\n图结构显示了清晰的循环流程：代理启动并调用LLM；基于LLM的决策，系统要么执行动作（调用检索器工具）并循环回来，要么完成执行并提供答案。\n\n让我们测试RAG代理。我们将询问关于"奖励破解"的具体问题，该问题只能通过从索引的博客文章中检索信息来回答：\n\n代码语言：javascript\n\n复制\n\n```\n # 定义用户查询 query = "What are the types of reward hacking discussed in the blogs?" # 使用查询调用代理 result = agent.invoke({"messages": [("user", query)]}) # --- 显示最终消息 --- # 格式化并打印对话流程 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── Human ───────────────┐ │ Clarify scope: I want types of │ │ reward hacking from Lilian Weng\'s │ │ blog on RL. │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ Fetching context from her posts... │ └──────────────────────────────────────┘ ┌────────────── 🔧 Tool Output ────────┐ │ She lists 3 main types of reward │ │ hacking in RL: │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ 1. **Spec gaming** – Exploit reward │ │ loopholes, not real goal. │ │ │ │ 2. **Reward tampering** – Change or │ │ hack reward signals. │ │ │ │ 3. **Wireheading** – Self-stimulate │ │ reward instead of task. │ └──────────────────────────────────────┘ ┌────────────── 📝 AI ─────────────────┐ │ These can cause harmful, unintended │ │ behaviors in RL agents. │ └──────────────────────────────────────┘\n```\n\n如结果所示，代理正确识别出需要使用检索工具，然后成功从博客文章中检索相关上下文，并基于该信息提供了详细而准确的答案。这完美展示了通过RAG实现的上下文工程如何创建强大而知识渊博的代理系统。\n\n### 知识型代理的压缩策略优化\n\n代理交互过程可能跨越数百轮对话并涉及令牌密集型工具调用。总结技术是管理这种复杂性的常用方法。\n\n具体应用案例包括：Claude Code在上下文窗口超过95%容量时使用"自动压缩"功能，对整个用户-代理交互历史进行总结；总结技术可以使用递归或分层总结等策略来压缩代理执行轨迹。\n\n开发者还可以在特定节点添加总结功能：在令牌密集型工具调用之后（例如搜索工具执行后）；在代理间边界处进行知识转移，如Cognition在Devin中使用微调模型执行的操作。\n\nLangGraph作为低级编排框架，为开发者提供全面控制能力：将代理设计为节点集合；在每个节点内明确定义逻辑；在节点间传递共享状态对象。\n\n这种架构使得以不同方式压缩上下文变得简单直接。例如，开发者可以使用消息列表作为代理状态，并利用内置工具对其进行总结。\n\n我们将基于之前编码的RAG工具调用代理，添加对话历史总结功能。\n\n首先需要扩展图状态以包含最终总结字段：\n\n代码语言：javascript\n\n复制\n\n```\n # 定义包含总结字段的扩展状态 class State(MessagesState): """包含用于上下文压缩的总结字段的扩展状态类""" summary: str\n```\n\n接下来定义专门用于总结的提示，同时保留之前的RAG提示：\n\n代码语言：javascript\n\n复制\n\n```\n # 定义总结提示 summarization_prompt = """请总结完整的聊天历史和所有工具反馈信息， 提供用户询问内容和代理执行操作的概要描述。"""\n```\n\n现在创建`summary_node`节点：该节点将在代理工作完成时被触发，生成整个交互过程的简洁总结；`llm_call`和`tool_node`保持不变。\n\n代码语言：javascript\n\n复制\n\n```\n def summary_node(state: MessagesState) -> dict: """ 生成对话和工具交互的总结 参数: state: 包含消息历史的图当前状态 返回值: 包含键"summary"和生成总结字符串的字典，用于更新状态 """ # 将总结系统提示添加到消息历史前端 messages = [SystemMessage(content=summarization_prompt)] + state["messages"] # 调用语言模型生成总结 result = llm.invoke(messages) # 返回存储在状态\'summary\'字段中的总结 return {"summary": result.content}\n```\n\n条件边`should_continue`现在需要决定是调用工具还是继续到新的`summary_node`：\n\n代码语言：javascript\n\n复制\n\n```\n def should_continue(state: MessagesState) -> Literal["Action", "summary_node"]: """根据LLM是否进行工具调用确定下一步骤""" last_message = state["messages"][-1] # 如果LLM进行了工具调用，执行工具 if last_message.tool_calls: return "Action" # 否则进行总结 return "summary_node"\n```\n\n构建在末尾包含总结步骤的图结构：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建RAG代理工作流 agent_builder = StateGraph(State) # 向工作流添加节点 agent_builder.add_node("llm_call", llm_call) agent_builder.add_node("Action", tool_node) agent_builder.add_node("summary_node", summary_node) # 定义工作流边 agent_builder.add_edge(START, "llm_call") agent_builder.add_conditional_edges( "llm_call", should_continue, { "Action": "Action", "summary_node": "summary_node", }, ) agent_builder.add_edge("Action", "llm_call") agent_builder.add_edge("summary_node", END) # 编译代理 agent = agent_builder.compile() # 显示代理工作流 display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n```\n\n现在使用需要获取大量上下文的查询来测试系统：\n\n代码语言：javascript\n\n复制\n\n```\n from rich.markdown import Markdown query = "Why does RL improve LLM reasoning according to the blogs?" result = agent.invoke({"messages": [("user", query)]}) # 打印给用户的最终消息 format_message(result[\'messages\'][-1]) # 打印生成的总结 Markdown(result["summary"]) #### 输出结果 #### 用户询问了为什么强化学习（RL）能够改进LLM推理...\n```\n\n该实现效果良好，但消耗了115k个令牌！这是具有令牌密集型工具调用的代理系统面临的常见挑战。\n\n更高效的方法是在上下文进入代理主要scratchpad之前进行压缩。让我们更新RAG代理以实时总结工具调用输出。\n\n首先为这个特定任务创建新提示：\n\n代码语言：javascript\n\n复制\n\n```\n tool_summarization_prompt = """您将收到来自RAG系统的文档内容。 请总结这些文档，确保保留所有相关和关键信息。 您的目标是将文档大小（令牌数量）减少到更易管理的规模。"""\n```\n\n接下来修改`tool_node`以包含总结步骤：\n\n代码语言：javascript\n\n复制\n\n```\n def tool_node_with_summarization(state: dict): """执行工具调用然后总结输出""" result = [] for tool_call in state["messages"][-1].tool_calls: tool = tools_by_name[tool_call["name"]] observation = tool.invoke(tool_call["args"]) # 总结文档内容 summary_msg = llm.invoke([ SystemMessage(content=tool_summarization_prompt), ("user", str(observation)) ]) result.append(ToolMessage(content=summary_msg.content, tool_call_id=tool_call["id"])) return {"messages": result}\n```\n\n现在`should_continue`边可以简化，因为不再需要最终的`summary_node`：\n\n代码语言：javascript\n\n复制\n\n```\n def should_continue(state: MessagesState) -> Literal["Action", END]: """决定应该继续循环还是停止""" if state["messages"][-1].tool_calls: return "Action" return END\n```\n\n构建和编译这个更高效的代理：\n\n代码语言：javascript\n\n复制\n\n```\n # 构建工作流 agent_builder = StateGraph(MessagesState) # 添加节点 agent_builder.add_node("llm_call", llm_call) agent_builder.add_node("Action", tool_node_with_summarization) # 添加连接节点的边 agent_builder.add_edge(START, "llm_call") agent_builder.add_conditional_edges( "llm_call", should_continue, { "Action": "Action", END: END, }, ) agent_builder.add_edge("Action", "llm_call") # 编译代理 agent = agent_builder.compile() # 显示代理结构 display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n```\n\n使用相同查询测试并观察差异：\n\n代码语言：javascript\n\n复制\n\n```\n query = "Why does RL improve LLM reasoning according to the blogs?" result = agent.invoke({"messages": [("user", query)]}) format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── user ───────────────┐ │ Why does RL improve LLM reasoning?│ │ According to the blogs? │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ Searching Lilian Weng\'s blog for │ │ how RL improves LLM reasoning... │ │ │ │ 🔧 Tool Call: retrieve_blog_posts │ │ Args: { │ │ "query": "Reinforcement Learning │ │ for LLM reasoning" │ │ } │ └───────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ Lilian Weng explains RL helps LLM │ │ reasoning by training on rewards │ │ for each reasoning step (Process- │ │ based Reward Models). This guides │ │ the model to think step-by-step, │ │ improving coherence and logic. │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ RL improves LLM reasoning by │ │ rewarding stepwise thinking via │ │ PRMs, encouraging coherent, │ │ logical argumentation over final │ │ answers. It helps the model self- │ │ correct and explore better paths. │ └───────────────────────────────────┘\n```\n\n这次代理仅使用了60k个令牌。\n\n这个简单的改进将令牌使用量减少了近一半，使代理系统更加高效和经济。\n\n### 基于子代理架构的上下文隔离技术\n\n隔离上下文的常见策略是将其分布到多个子代理中。OpenAI Swarm库专门为这种"关注点分离"架构设计，每个代理使用专属的工具、指令和上下文窗口来管理特定的子任务。\n\nAnthropic的多代理研究系统显示，具有隔离上下文的多代理架构相比单代理系统性能提升90.2%，这是因为每个子代理专注于更窄的特定子任务。\n\n子代理使用独立的上下文窗口并行操作，同时探索问题的不同方面。\n\n然而，多代理系统面临一些技术挑战：令牌使用量显著增加（有时比单代理聊天多15倍的令牌消耗）；需要精心设计的提示工程来规划子代理工作；协调子代理可能变得复杂。\n\nLangGraph框架对多代理配置提供全面支持。常见的实现方法是监督者架构，这也是Anthropic多代理研究员采用的方案。监督者将任务委托给子代理，每个子代理在独立的上下文窗口中运行。\n\n让我们构建一个管理两个专门代理的简单监督者系统：`math_expert`处理数学计算任务，`research_expert`负责搜索和提供研究信息。\n\n监督者将根据查询内容决定调用哪个专家，并在LangGraph工作流中协调他们的响应：\n\n代码语言：javascript\n\n复制\n\n```\n from langgraph.prebuilt import create_react_agent from langgraph_supervisor import create_supervisor # --- 为每个代理定义专用工具 --- def add(a: float, b: float) -> float: """执行两个数字的加法运算""" return a + b def multiply(a: float, b: float) -> float: """执行两个数字的乘法运算""" return a * b def web_search(query: str) -> str: """模拟网络搜索函数，返回FAANG公司员工数据""" return ( "Here are the headcounts for each of the FAANG companies in 2024:\\n" "1. **Facebook (Meta)**: 67,317 employees.\\n" "2. **Apple**: 164,000 employees.\\n" "3. **Amazon**: 1,551,000 employees.\\n" "4. **Netflix**: 14,000 employees.\\n" "5. **Google (Alphabet)**: 181,269 employees." )\n```\n\n现在创建专门的代理和管理它们的监督者：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 创建具有隔离上下文的专门代理 --- math_agent = create_react_agent( model=llm, tools=[add, multiply], name="math_expert", prompt="您是数学专家。每次只使用一个工具执行计算。" ) research_agent = create_react_agent( model=llm, tools=[web_search], name="research_expert", prompt="您是具有网络搜索能力的世界级研究专家。请不要执行数学运算。" ) # --- 创建用于协调代理的监督者工作流 --- workflow = create_supervisor( [research_agent, math_agent], model=llm, prompt=( "您是团队监督者，负责管理一个研究专家和一个数学专家。" "请将任务委托给适当的代理来回答用户查询。" "对于时事或事实性问题，使用research_agent。" "对于数学问题，使用math_agent。" ) ) # 编译多代理应用程序 app = workflow.compile()\n```\n\n执行工作流并观察监督者如何委托任务：\n\n代码语言：javascript\n\n复制\n\n```\n # --- 执行多代理工作流 --- result = app.invoke({ "messages": [ { "role": "user", "content": "what\'s the combined headcount of the FAANG companies in 2024?" } ] }) # 格式化并显示结果 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── user ───────────────┐ │ Learn more about LangGraph Swarm │ │ and multi-agent systems. │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ Fetching details on LangGraph │ │ Swarm and related resources... │ └───────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ **LangGraph Swarm** │ │ Repo: │ │ https://github.com/langchain-ai/ │ │ langgraph-swarm-py │ │ │ │ • Python library for multi-agent │ │ AI with dynamic collaboration. │ │ • Agents hand off control based │ │ on specialization, keeping │ │ conversation context. │ │ • Supports custom handoffs, │ │ streaming, memory, and human- │ │ in-the-loop. │ │ • Install: │ │ `pip install langgraph-swarm` │ └───────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ **Videos on multi-agent systems** │ │ 1. https://youtu.be/4nZl32FwU-o │ │ 2. https://youtu.be/JeyDrn1dSUQ │ │ 3. https://youtu.be/B_0TNuYi56w │ └───────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ LangGraph Swarm makes it easy to │ │ build context-aware multi-agent │ │ systems. Check videos for deeper │ │ insights on multi-agent behavior. │ └───────────────────────────────────┘\n```\n\n在此案例中，监督者正确地为每个任务隔离了上下文——将研究查询分配给研究专家，将数学问题分配给数学专家——展示了有效的上下文隔离机制。\n\n### 基于沙盒环境的隔离技术\n\nHuggingFace的深度研究员展示了一种创新的上下文隔离方法。大多数代理使用工具调用API，这些API返回JSON格式的参数来运行搜索API等工具并获取结果。\n\nHuggingFace采用CodeAgent技术，编写代码来调用工具。这些代码在安全沙盒中执行，代码运行结果被发送回LLM。\n\n这种方法将大容量数据（如图像或音频）保持在LLM令牌限制之外。HuggingFace解释道：\n\n代码代理允许更好的状态处理...需要稍后存储这个图像/音频/其他内容？只需将其保存为状态中的变量并稍后使用。\n\n在LangGraph中使用沙盒技术非常简单。LangChain沙盒使用Pyodide（编译为WebAssembly的Python）安全地运行不受信任的Python代码。开发者可以将其作为工具添加到任何LangGraph代理中。\n\n注意：需要安装Deno。安装地址：https://docs.deno.com/runtime/getting\\_started/installation/\n\n代码语言：javascript\n\n复制\n\n```\n from langchain_sandbox import PyodideSandboxTool from langgraph.prebuilt import create_react_agent # 创建具有网络访问权限的沙盒工具以支持包安装 tool = PyodideSandboxTool(allow_net=True) # 使用沙盒工具创建ReAct代理 agent = create_react_agent(llm, tools=[tool]) # 使用沙盒执行数学查询 result = await agent.ainvoke( {"messages": [{"role": "user", "content": "what\'s 5 + 7?"}]}, ) # 格式化并显示结果 format_messages(result[\'messages\'])\n```\n\n代码语言：javascript\n\n复制\n\n```\n ┌────────────── user ───────────────┐ │ what\'s 5 + 7? │ └──────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ I can solve this by executing │ │ Python code in the sandbox. │ │ │ │ 🔧 Tool Call: pyodide_sandbox │ │ Args: { │ │ "code": "print(5 + 7)" │ │ } │ └──────────────────────────────────┘ ┌────────────── 🔧 Tool Output ─────┐ │ 12 │ └──────────────────────────────────┘ ┌────────────── 📝 AI ──────────────┐ │ The answer is 12. │ └──────────────────────────────────┘\n```\n\n### LangGraph中的状态隔离机制\n\n代理的运行时状态对象提供了另一种优秀的上下文隔离方式，其工作原理类似于沙盒技术。开发者可以使用数据模式（如Pydantic模型）设计状态结构，该模式具有用于存储上下文的不同字段。\n\n例如，一个字段（如`messages`）在每轮交互中都向LLM展示，而其他字段保持信息隔离状态，直到需要时才暴露。\n\nLangGraph围绕状态对象构建，使开发者能够创建自定义状态模式并在代理工作流中访问其字段。\n\n例如，开发者可以将工具调用结果存储在特定字段中，使其对LLM保持隐藏状态，直到必要时才暴露。在本文的notebook示例中已经展示了许多这样的实现案例。\n\n### 总结\n\n通过本文的深入分析，我们系统性地探讨了基于LangChain和LangGraph的AI代理上下文工程优化技术：\n\n我们利用LangGraph的`StateGraph`创建了短期内存的"scratchpad"机制和长期内存的`InMemoryStore`系统，使代理能够有效存储和检索信息。我们演示了如何从代理状态和长期内存中选择性提取相关信息，包括使用检索增强生成（RAG）技术来查找特定知识，以及利用`langgraph-bigtool`从众多选项中选择合适的工具。\n\n为了管理长对话和令牌密集型工具输出，实现了总结技术。展示了如何实时压缩RAG结果，使代理更高效并减少令牌消耗。\n\n通过构建具有监督者架构的多代理系统来探索上下文分离技术，该系统将任务委托给专门的子代理，以及通过使用沙盒环境来运行代码。\n\n这些技术统称为"上下文工程"——一种通过精心管理AI代理的工作内存（上下文）来改进AI代理性能的策略，使它们能够更高效、更准确地处理复杂的长期运行任务。\n\n随着AI代理技术的不断发展，上下文工程将成为构建高性能、可扩展AI系统的关键技术基础。\n\n作者：Fareed Khan\n\n---\n\n本文参与\xa0[腾讯云自媒体同步曝光计划](/developer/support-plan)，分享自微信公众号。\n\n原始发表：2025-07-26，如有侵权请联系\xa0[cloudcommunity@tencent.com](mailto:cloudcommunity@tencent.com) 删除\n\n[代理](/developer/tag/17225)\n\n[工具](/developer/tag/17276)\n\n[内存管理](/developer/tag/17383)\n\n[性能](/developer/tag/17525)\n\n[优化](/developer/tag/17554)\n\n本文分享自 DeepHub IMBA 微信公众号，前往查看\n\n如有侵权，请联系 [cloudcommunity@tencent.com](mailto:cloudcommunity@tencent.com) 删除。\n\n本文参与\xa0[腾讯云自媒体同步曝光计划](/developer/support-plan)\xa0 ，欢迎热爱写作的你一起参与！\n\n[代理](/developer/tag/17225)\n\n[工具](/developer/tag/17276)\n\n[内存管理](/developer/tag/17383)\n\n[性能](/developer/tag/17525)\n\n[优化](/developer/tag/17554)\n\n登录后参与评论\n\n登录 后参与评论\n\n* 上下文工程的理论基础\n\n* 基于LangGraph的Scratchpad实现机制\n\n* LangGraph中的内存写入机制\n\n* Scratchpad上下文选择机制\n\n* 内存选择能力的实现\n\n* LangGraph BigTool调用的技术优势\n\n* 基于上下文工程的RAG系统实现\n\n* 知识型代理的压缩策略优化\n\n* 基于子代理架构的上下文隔离技术\n\n* 基于沙盒环境的隔离技术\n\n* LangGraph中的状态隔离机制\n\n* 总结\n\n[AI驱动 智领未来](https://cloud.tencent.com/act/pro/double12-2025?from=21344&from_column=21344)\n\n* ### 社区\n\n  + [技术文章](/developer/column)\n  + [技术问答](/developer/ask)\n  + [技术沙龙](/developer/salon)\n  + [技术视频](/developer/video)\n  + [学习中心](/developer/learning)\n  + [技术百科](/developer/techpedia)\n  + [技术专区](/developer/zone/list)\n* ### 活动\n\n  + [自媒体同步曝光计划](/developer/support-plan)\n  + [邀请作者入驻](/developer/support-plan-invitation)\n  + [自荐上首页](/developer/article/1535830)\n  + [技术竞赛](/developer/competition)\n* ### 圈层\n\n  + [腾讯云最具价值专家](/tvp)\n  + [腾讯云架构师技术同盟](/developer/program/tm)\n  + [腾讯云创作之星](/developer/program/tci)\n  + [腾讯云TDP](/developer/program/tdp)\n* ### 关于\n\n  + [社区规范](/developer/article/1006434)\n  + [免责声明](/developer/article/1006435)\n  + [联系我们](mailto:cloudcommunity@tencent.com)\n  + [友情链接](/developer/friendlink)\n  + [MCP广场开源版权声明](/developer/article/2537547)\n\n### 腾讯云开发者\n\n### 热门产品\n\n* [域名注册](/product/domain?from=20064&from_column=20064)\n* [云服务器](/product/cvm?from=20064&from_column=20064)\n* [区块链服务](/product/tbaas?from=20064&from_column=20064)\n* [消息队列](/product/message-queue-catalog?from=20064&from_column=20064)\n* [网络加速](/product/ecdn?from=20064&from_column=20064)\n* [云数据库](/product/tencentdb-catalog?from=20064&from_column=20064)\n* [域名解析](/product/dns?from=20064&from_column=20064)\n* [云存储](/product/cos?from=20064&from_column=20064)\n* [视频直播](/product/css?from=20064&from_column=20064)\n\n### 热门推荐\n\n* [人脸识别](/product/facerecognition?from=20064&from_column=20064)\n* [腾讯会议](/product/tm?from=20064&from_column=20064)\n* [企业云](/act/pro/enterprise2022?from=20064&from_column=20064)\n* [CDN加速](/product/cdn?from=20064&from_column=20064)\n* [视频通话](/product/trtc?from=20064&from_column=20064)\n* [图像分析](/product/imagerecognition?from=20064&from_column=20064)\n* [MySQL 数据库](/product/cdb?from=20064&from_column=20064)\n* [SSL 证书](/product/ssl?from=20064&from_column=20064)\n* [语音识别](/product/asr?from=20064&from_column=20064)\n\n### 更多推荐\n\n* [数据安全](/solution/data_protection?from=20064&from_column=20064)\n* [负载均衡](/product/clb?from=20064&from_column=20064)\n* [短信](/product/sms?from=20064&from_column=20064)\n* [文字识别](/product/ocr?from=20064&from_column=20064)\n* [云点播](/product/vod?from=20064&from_column=20064)\n* [大数据](/product/bigdata-class?from=20064&from_column=20064)\n* [小程序开发](/solution/la?from=20064&from_column=20064)\n* [网站监控](/product/tcop?from=20064&from_column=20064)\n* [数据迁移](/product/cdm?from=20064&from_column=20064)\n\nCopyright © 2013 - 2026Tencent Cloud. All Rights Reserved. 腾讯云 版权所有\n\n[深圳市腾讯计算机系统有限公司](https://qcloudimg.tencent-cloud.cn/raw/986376a919726e0c35e96b311f54184d.jpg)\xa0ICP备案/许可证号：[粤B2-20090059](https://beian.miit.gov.cn/#/Integrated/index)[粤公网安备44030502008569号](https://beian.mps.gov.cn/#/query/webSearch?code=44030502008569)\n\n[腾讯云计算（北京）有限责任公司](https://qcloudimg.tencent-cloud.cn/raw/a2390663ee4a95ceeead8fdc34d4b207.jpg) 京ICP证150476号 | \xa0[京ICP备11018762号](https://beian.miit.gov.cn/#/Integrated/index)\n\n[问题归档](/developer/ask/archives.html)[专栏文章](/developer/column/archives.html)[快讯文章归档](/developer/news/archives.html)[关键词归档](/developer/information/all.html)[开发者手册归档](/developer/devdocs/archives.html)[开发者手册 Section 归档](/developer/devdocs/sections_p1.html)\n\nCopyright © 2013 - 2026Tencent Cloud.\n\nAll Rights Reserved. 腾讯云 版权所有\n\n登录 后参与评论', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://cloud.tencent.com/developer/article/2557090', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9995005, 'save_path': None}}, {'paper_id': '', 'title': 'AI Agent 实战指南：LangChain/LangGraph 框架深度解析与 ...', 'authors': [], 'abstract': '[代码改变世界](https://www.cnblogs.com/)\n\n\n* [Cnblogs](https://www.cnblogs.com/)\n* [Dashboard](https://i.cnblogs.com/)\n* [Login](https://account.cnblogs.com/signin?returnUrl=https://www.cnblogs.com/tlnshuju/)\n\n* [Home](https://www.cnblogs.com/tlnshuju/)\n* [Contact](https://msg.cnblogs.com/send/tlnshuju)\n* [Gallery](https://www.cnblogs.com/tlnshuju/gallery.html)\n* [Subscribe](javascript:void(0);)\n* [RSS](https://www.cnblogs.com/tlnshuju/rss/)\n\n# [tlnshuju](https://www.cnblogs.com/tlnshuju/)\n\n## [实用指南：AI Agent 实战指南：LangChain/LangGraph 框架深度解析与项目落地](https://www.cnblogs.com/tlnshuju/p/19353187 "发布于 2025-12-15 16:11")\n\n2025-12-15 16:11\xa0 [tlnshuju](https://www.cnblogs.com/tlnshuju)\xa0 阅读(786)\xa0 评论(0)\xa0 \xa0 [收藏](javascript:void(0))\xa0 [举报](javascript:void(0))\n\n### 前言：为什么 AI Agent 是下一代智能应用的核心？\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0最近一年，AI Agent 从概念走向落地，成为继大语言模型（LLM）之后最热门的技术方向。简单来说，AI Agent 是具备**自主决策、工具使用、环境交互**能力的智能体，能像人类一样拆解复杂任务、调用资源、持续迭代。\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0而 LangChain 与 LangGraph 作为目前最成熟的 Agent 开发框架，已成为开发者的首选工具。本文将从核心概念出发，通过实战案例手把手教你掌握 Agent 开发，涵盖内置 Agent 调用、自定义工具、向量数据库集成等关键技能，最后通过一个完整项目案例展示如何构建生产级 AI Agent。\n\n### 一、LangChain 核心概念：6 大组件搭建 Agent 基础\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0LangChain 之所以成为 Agent 开发的事实标准，源于其模块化的设计理念。掌握以下 6 大核心组件，就能理解 Agent 的工作原理：\n\n#### 1. Models：AI Agent 的 “大脑”\n\nModels 是 Agent 的核心算力来源，主要包括：\n\n> * **LLM（大语言模型）**：如 GPT-4、Claude、LLaMA 等，负责自然语言理解与决策\n> * **聊天模型（Chat Models）**：封装了对话格式的 LLM（如 OpenAI 的 ChatCompletion）\n> * **嵌入模型（Embedding Models）**：将文本转为向量，用于语义检索（如 OpenAI Embedding）\n\n**代码示例：初始化 OpenAI 模型**\n\n```\nfrom langchain_openai import OpenAI, ChatOpenAI # 初始化文本生成模型 llm = OpenAI(api_key="your_key", temperature=0) # temperature=0 表示确定性输出 # 初始化聊天模型 chat_model = ChatOpenAI(api_key="your_key", model_name="gpt-3.5-turbo")\n```\n\n#### 2. Prompts：引导 Agent 思考的 “指令”\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Prompts 是与模型交互的输入模板，决定了 Agent 的行为方式。LangChain 提供了\xa0`PromptTemplate`\xa0工具简化提示词管理：\n\n**代码示例：定义提示词模板**\n\n```\nfrom langchain.prompts import PromptTemplate # 简单提示词模板 template = "请将以下文本总结为一句话：{text}" prompt = PromptTemplate(input_variables=["text"], template=template) # 填充变量并生成最终提示词 formatted_prompt = prompt.format(text="LangChain 是一个用于构建 AI Agent 的框架...")\n```\n\n对于复杂场景（如 Agent 思考过程），可使用\xa0`ChatPromptTemplate`\xa0定义多轮对话模板。\n\n#### 3. Chains：串联组件的 “流水线”\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Chains 用于将多个组件（模型、提示词、工具等）按逻辑串联。最基础的\xa0`LLMChain`\xa0可将提示词与模型绑定：\n\n**代码示例：使用 LLMChain 串联组件**\n\n```\nfrom langchain.chains import LLMChain # 绑定提示词与模型 chain = LLMChain(llm=llm, prompt=prompt) # 执行链条 result = chain.run(text="LangChain 是一个用于构建 AI Agent 的框架...") print(result) # 输出：LangChain 是构建 AI Agent 的框架。\n```\n\n复杂场景可使用\xa0`SequentialChain`（顺序执行）或\xa0`RouterChain`（动态选择链条）。\n\n#### 4. Agents：具备决策能力的 “执行者”\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Agents 是 LangChain 的核心，能根据目标自主决策：是否调用工具、调用哪些工具、如何处理结果。其核心逻辑是 “思考 - 行动 - 观察” 循环（Thought-Action-Observation）。\n\n关键概念：\n\n> * **Agent Type**：Agent 的决策模式（如 ZERO\\_SHOT\\_REACT、OPENAI\\_FUNCTIONS）\n> * **Tools**：Agent 可调用的外部能力（如搜索、数据库查询）\n> * **Executor**：执行 Agent 决策的引擎\n\n#### 5. Tools：扩展 Agent 能力的 “双手”\n\nTools 是 Agent 与外部世界交互的接口，包括：\n\n> * **内置工具**：如\xa0`SerpAPIWrapper`（搜索）、`PythonREPLTool`（执行代码）\n> * **自定义工具**：根据业务需求开发的能力（如查询订单、操作数据库）\n\n工具定义需包含：名称、描述、参数说明（帮助 Agent 判断何时调用）。\n\n#### 6. Memory：Agent 的 “记忆系统”\n\nMemory 让 Agent 能记住历史交互，分为：\n\n> * **短期记忆**：如\xa0`ConversationBufferMemory`（存储完整对话）\n> * **长期记忆**：结合向量数据库存储结构化知识（如用户信息、产品数据）\n\n**组件关系图**\n\n**总结**：Models 提供算力，Prompts 定义任务，Chains 串联流程，Tools 扩展能力，Memory 保留上下文，最终通过 Agents 实现自主决策 —— 这就是 LangChain 构建智能体的核心逻辑。\n\n### 二、Agent 实战：从内置类型到自定义工具\n\n#### 1. 快速上手：使用 LangChain 内置 Agent\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0LangChain 提供了多种开箱即用的 Agent 类型，最常用的是\xa0**ZERO\\_SHOT\\_REACT\\_DESCRIPTION**（零样本推理）和\xa0**OPENAI\\_FUNCTIONS**（函数调用）。\n\n##### 案例：用 ZERO\\_SHOT\\_REACT\\_DESCRIPTION 实现天气查询\n\n**步骤 1：安装依赖**\n\n```\npip install langchain langchain-openai python-dotenv serpapi\n```\n\n**步骤 2：配置环境变量**创建\xa0`.env`\xa0文件：\n\n```\nOPENAI_API_KEY=your_openai_key SERPAPI_API_KEY=your_serpapi_key # 用于搜索工具\n```\n\n**步骤 3：初始化工具与 Agent**\n\n```\nfrom langchain.agents import initialize_agent, Tool from langchain.agents import AgentType from langchain_openai import OpenAI from langchain.utilities import SerpAPIWrapper from dotenv import load_dotenv import os # 加载环境变量 load_dotenv() # 初始化搜索工具 search = SerpAPIWrapper() tools = [ Tool( name="Search", func=search.run, description="当需要获取实时信息（如天气、新闻、股票价格）时使用" ) ] # 初始化 LLM llm = OpenAI(temperature=0) # 初始化 Agent（ZERO_SHOT_REACT 类型） agent = initialize_agent( tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True # 输出思考过程 )\n```\n\n**步骤 4：运行 Agent**\n\n```\n# 执行任务：查询北京明天的天气 result = agent.run("北京明天的天气如何？") print(result)\n```\n\n**输出解析**（verbose=True 时可见）：\n\n```\n> Entering new AgentExecutor chain... 我需要查询北京明天的天气，这是实时信息，应该用Search工具。 Action: Search Action Input: 北京明天天气 Observation: 北京明天（11月8日）晴，气温-2~8℃，西北风3-4级。 Thought: 已获取天气信息，无需进一步操作。 Final Answer: 北京明天（11月8日）晴，气温-2~8℃，西北风3-4级。 > Finished chain.\n```\n\n可以看到，Agent 完整执行了 “思考→调用工具→获取结果→整理回答” 的流程。\n\n##### 案例：用 OPENAI\\_FUNCTIONS 实现结构化输出\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0OPENAI\\_FUNCTIONS 类型依赖 LLM 的函数调用能力（如 GPT-3.5-turbo/4），适合需要结构化结果的场景：\n\n```\nfrom langchain.agents import AgentType, initialize_agent from langchain_openai import ChatOpenAI from langchain.tools import tool # 定义工具（用 @tool 装饰器自动生成描述） @tool def get_weather(city: str, date: str) -> str: """获取指定城市和日期的天气""" # 实际项目中可对接真实天气API return f"{city}{date}晴，气温5~15℃" # 初始化聊天模型（必须支持函数调用） chat_model = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0) # 初始化 Agent（OPENAI_FUNCTIONS 类型） agent = initialize_agent( [get_weather], chat_model, agent=AgentType.OPENAI_FUNCTIONS, verbose=True ) # 运行：获取上海后天的天气 result = agent.run("上海后天的天气怎么样？")\n```\n\n**优势**：工具调用格式更规范（通过 JSON 传递参数），适合生产环境。\n\n#### 2. 进阶：自定义 Tools 扩展 Agent 能力\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0内置工具无法满足业务需求时，可自定义工具。核心是明确工具的**功能描述**（帮助 Agent 判断何时调用）和**参数格式**。\n\n##### 案例：自定义 “订单查询” 工具\n\n**步骤 1：定义工具类**\n\n```\nfrom langchain.tools import BaseTool from pydantic import BaseModel, Field from typing import Optional, Type # 定义工具输入参数模型 class OrderQueryInput(BaseModel): order_id: str = Field(description="订单编号，格式为ORD+数字，如ORD123456") # 自定义工具 class OrderQueryTool(BaseTool): name = "OrderQuery" description = "用于查询订单状态，需要传入订单编号" args_schema: Type[BaseModel] = OrderQueryInput # 绑定输入参数模型 def _run(self, order_id: str) -> str: # 模拟查询数据库 if order_id.startswith("ORD") and len(order_id) == 9: return f"订单{order_id}状态：已发货，预计3天后送达" else: return "无效的订单编号，请检查格式" def _arun(self, order_id: str): # 异步实现（可选） raise NotImplementedError("暂不支持异步查询")\n```\n\n**步骤 2：集成到 Agent**\n\n```\n# 初始化工具和 Agent order_tool = OrderQueryTool() agent = initialize_agent( [order_tool], llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True ) # 测试：查询订单 result = agent.run("帮我查一下订单ORD123456的状态")\n```\n\n**关键点**：\n\n> * 工具描述要精确（如 “需要传入订单编号”），避免 Agent 误用\n> * 通过\xa0`args_schema`\xa0定义参数格式，确保输入规范\n> * 实现\xa0`_run`\xa0方法处理核心逻辑，`_arun`\xa0可选（异步场景）\n\n#### 3. 高级：集成向量数据库实现长期记忆\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0Agent 仅靠对话历史（短期记忆）无法处理大规模知识，需结合向量数据库存储长期记忆。常用向量库有 Chroma（轻量本地库）、Pinecone（云服务）。\n\n##### 案例：用 Chroma 存储产品知识，让 Agent 回答用户咨询\n\n**步骤 1：安装依赖**\n\n```\npip install chromadb langchain-community\n```\n\n**步骤 2：初始化向量库并加载数据**\n\n```\nfrom langchain.vectorstores import Chroma from langchain.embeddings import OpenAIEmbeddings from langchain.text_splitter import CharacterTextSplitter from langchain.document_loaders import TextLoader # 1. 加载产品知识文档（示例：产品说明书） loader = TextLoader("product_info.txt") # 内容："产品A支持30天无理由退货，保修期1年..." documents = loader.load() # 2. 分割文档（避免文本过长） text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0) docs = text_splitter.split_documents(documents) # 3. 初始化向量库并存储文档 embeddings = OpenAIEmbeddings() # 用OpenAI Embedding生成向量 db = Chroma.from_documents(docs, embeddings, persist_directory="./chroma_db") db.persist() # 持久化存储\n```\n\n**步骤 3：创建 “知识检索” 工具**\n\n```\n@tool def retrieve_knowledge(query: str) -> str: """检索产品知识，回答用户关于产品的问题（如退货政策、保修期）""" # 从向量库中查询相关文档 docs = db.similarity_search(query) return "\\n".join([doc.page_content for doc in docs])\n```\n\n**步骤 4：集成工具到 Agent**\n\n```\n# 组合工具：知识检索 + 搜索（可选） tools = [retrieve_knowledge, search] # 初始化 Agent agent = initialize_agent( tools, chat_model, agent=AgentType.OPENAI_FUNCTIONS, verbose=True ) # 测试：查询产品退货政策 result = agent.run("产品A支持多久无理由退货？")\n```\n\n**效果**：Agent 会自动调用\xa0`retrieve_knowledge`\xa0工具，从向量库中获取产品信息并回答，无需硬编码知识。\n\n### 三、LangGraph：构建更稳定的 Agent 工作流\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0LangGraph 是 LangChain 团队推出的新一代框架，基于 “状态机” 设计，更适合构建复杂、可追溯的 Agent 工作流。其核心优势是：\n\n> * 明确的状态管理（State）\n> * 可控的节点流转（Nodes）\n> * 支持循环与分支逻辑\n\n#### 案例：用 LangGraph 实现 “多轮分析” Agent\n\n**场景**：让 Agent 分析用户问题，若需要补充信息则追问，否则生成答案。\n\n**步骤 1：安装 LangGraph**\n\n```\npip install langgraph\n```\n\n**步骤 2：定义状态与节点**\n\n```\nfrom langgraph.graph import Graph, StateGraph from pydantic import BaseModel, Field from typing import List, Optional # 1. 定义状态（保存对话历史、当前问题、是否需要追问） class State(BaseModel): messages: List[str] = Field(default_factory=list) need_clarify: bool = False # 是否需要追问 final_answer: Optional[str] = None # 2. 定义节点：分析问题 def analyze_node(state: State) -> State: last_msg = state.messages[-1] # 调用 LLM 判断是否需要追问（简化逻辑，实际需用 prompt 引导） if "价格" in last_msg and "产品" not in last_msg: state.need_clarify = True state.messages.append("请问你想了解哪个产品的价格？") else: state.need_clarify = False state.final_answer = f"已收到您的问题：{last_msg}，正在处理..." return state # 3. 定义节点：等待用户输入（仅示例，实际为外部交互） def user_input_node(state: State) -> State: user_input = input("请输入：") # 模拟用户输入 state.messages.append(user_input) return state # 4. 定义条件分支：是否需要追问 def should_continue(state: State) -> str: if state.need_clarify: return "user_input" # 流转到用户输入节点 else: return "end" # 结束流程\n```\n\n**步骤 3：构建并运行工作流**\n\n```\n# 初始化状态机 workflow = StateGraph(State) # 添加节点 workflow.add_node("analyze", analyze_node) # 分析节点 workflow.add_node("user_input", user_input_node) # 用户输入节点 # 定义流转逻辑 workflow.set_entry_point("analyze") # 入口节点 workflow.add_edge("user_input", "analyze") # 用户输入后回到分析节点 workflow.add_conditional_edges( "analyze", should_continue, { "user_input": "user_input", "end": "end" } ) # 编译并运行 app = workflow.compile() initial_state = State(messages=["这个产品的价格是多少？"]) result = app.invoke(initial_state) print(result.final_answer)\n```\n\n**优势**：相比 LangChain 内置 Agent，LangGraph 的工作流更清晰，可通过状态机可视化工具查看节点流转，便于调试复杂逻辑。\n\n### 四、项目实战：构建 “智能客服 Agent”\n\n结合上述知识，我们来构建一个完整的智能客服 Agent，具备以下能力：\n\n1. 回答产品知识（基于向量库）\n2. 查询订单状态（自定义工具）\n3. 调用搜索获取实时信息（如活动公告）\n4. 无法回答时转接人工\n\n#### 1. 架构设计\n\n#### 2. 核心代码实现\n\n```\n# 整合工具 tools = [retrieve_knowledge, OrderQueryTool(), search] # 初始化 Agent（使用 LangGraph 确保流程可控） class SupportAgent: def __init__(self): self.agent = initialize_agent( tools, ChatOpenAI(model_name="gpt-4", temperature=0), agent=AgentType.OPENAI_FUNCTIONS, verbose=True ) self.escalate_keywords = ["人工", "转接", "投诉"] # 需要转接人工的关键词 def handle_query(self, user_query: str) -> str: # 检测是否需要转接人工 if any(keyword in user_query for keyword in self.escalate_keywords): return "已为您转接人工客服，正在接入..." # 正常处理 try: return self.agent.run(user_query) except Exception as e: return f"处理失败：{str(e)}，请稍后再试" # 测试 if __name__ == "__main__": agent = SupportAgent() print(agent.handle_query("产品A的保修期是多久？")) # 调用知识检索 print(agent.handle_query("查一下订单ORD123456")) # 调用订单工具 print(agent.handle_query("转人工")) # 转接人工\n```\n\n### 五、总结与扩展\n\n本文从 LangChain 核心组件出发，通过实战案例讲解了 Agent 开发的关键技能：\n\n> * 内置 Agent 类型的选择（ZERO\\_SHOT\\_REACT 适合快速验证，OPENAI\\_FUNCTIONS 适合生产）\n> * 自定义工具的开发要点（清晰描述、规范参数）\n> * 向量数据库集成（实现长期记忆）\n> * LangGraph 工作流（复杂场景的最佳选择）\n\n**进阶方向**：\n\n1. 多 Agent 协作（用 LangGraph 实现分工）\n2. 工具权限控制（限制 Agent 调用敏感工具）\n3. 错误处理与重试机制（提升稳定性）\n4. 结合 RAG 优化知识检索精度\n\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0AI Agent 正处于快速发展期，掌握 LangChain/LangGraph 等工具，能让你在智能应用开发中抢占先机。动手实践吧 —— 最好的学习方式就是用代码实现一个属于自己的 Agent！\n\n**互动讨论**：你在开发 Agent 时遇到过哪些坑？有哪些实用技巧？欢迎在评论区分享～\n\n[刷新页面](#)[返回顶部](#top)\n\n[博客园](https://www.cnblogs.com/) \xa0©\xa0 2004-2026   \n [浙公网安备 33010602011771号](http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=33010602011771) [浙ICP备2021040463号-3](https://beian.miit.gov.cn)\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.cnblogs.com/tlnshuju/p/19353187', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9937588, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 16:33:09,521 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=6, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 16:33:09,522 - __main__ - WARNING - handle_download: downloaded=0
2026-02-02 16:33:09,522 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=0
2026-02-02 17:06:11,824 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 17:06:11,824 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 17:06:11,896 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 17:06:11,896 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 17:06:11,949 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 17:06:11,950 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=zh, search_type=None
2026-02-02 17:06:15,046 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 17:06:15,046 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 17:06:15,982 - __main__ - INFO - handle_search: returned=10
2026-02-02 17:06:15,983 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 17:06:15,983 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 17:06:20,201 - __main__ - INFO - handle_search: returned=1
2026-02-02 17:06:20,201 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=1
2026-02-02 17:06:20,201 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.81418616, 'save_path': None}}
2026-02-02 17:06:59,104 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.81418616, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 17:06:59,105 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=1, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 17:06:59,105 - __main__ - INFO - handle_download: downloaded=1
2026-02-02 17:06:59,105 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=1
2026-02-02 17:06:59,105 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.81418616, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ....md'}}
2026-02-02 17:06:59,129 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '记忆- LangChain 教程', 'authors': [], 'abstract': '记忆 - LangChain 教程[跳到内容] \n**我们的[使用LangGraph构建环境智能体] 课程现已在LangChain Academy上线！**\n# 内存[¶] \n## 什么是记忆？[¶] \nAI 应用中的记忆指处理、存储和有效回忆过往交互信息的能力。有了记忆，您的智能体可以从反馈中学习并适应用户的偏好。本指南根据记忆召回的范围分为两个部分：短期记忆和长期记忆。**短期记忆**，或[线程] 范围的记忆，可以随时在与用户的单个对话线程**内**被召回。LangGraph 将短期记忆作为智能体[状态] 的一部分进行管理。状态使用[检查点] 持久化到数据库中，以便线程可以随时恢复。当图被调用或步骤完成时，短期记忆会更新，并且在每个步骤开始时读取状态。\n**长期记忆**在对话线程**之间**共享。它可以\\*随时\\*且在**任何线程**中被召回。记忆可以限定在任何自定义命名空间内，而不仅仅是单个线程ID。LangGraph 提供[存储] （[参考文档] ）来让您保存和召回长期记忆。\n理解并在您的应用程序中实现这两种记忆都非常重要。![] \n## 短期记忆[¶] \n短期记忆让您的应用程序能够记住单个[线程] 或对话中的先前交互。[线程] 在一个会话中组织多个交互，类似于电子邮件将消息分组到单个对话中的方式。\nLangGraph 将短期记忆作为智能体状态的一部分进行管理，通过线程范围的检查点进行持久化。此状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索到的文档或生成的工件。通过将这些存储在图的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。由于对话历史是表示短期记忆最常见的形式，因此在下一节中，我们将介绍当消息列表变得**冗长**时管理对话历史的技术。如果您想坚持高层概念，请继续阅读[长期记忆] 部分。\n### 管理长对话历史[¶] \n长对话对当今的LLM 构成了挑战。完整的历史记录甚至可能无法完全适应LLM 的上下文窗口，从而导致不可恢复的错误。即使您的LLM 在技术上支持完整的上下文长度，大多数LLM 在长上下文中表现仍然不佳。它们会被陈旧或偏离主题的内容“分散注意力”，同时响应时间更慢且成本更高。管理短期记忆是平衡[准确率和召回率] 与您应用程序的其他性能要求（延迟和成本）的实践。一如既往，批判性地思考如何为您的 LLM 表示信息并查看您的数据非常重要。我们在下面介绍了几种管理消息列表的常见技术，并希望为您提供足够的上下文，以便您为应用程序选择最佳权衡方案。* [编辑消息列表] ：如何考虑在将消息列表传递给语言模型之前对其进行修剪和过滤。\n* [总结过往对话] ：当您不仅仅想过滤消息列表时，一种常用的技术。### 编辑消息列表[¶] \n聊天模型使用[消息] 接受上下文，其中包括开发者提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随时间增长。由于上下文窗口有限且富含 token 的消息列表可能成本高昂，许多应用程序可以受益于使用手动删除或遗忘陈旧信息的技术。![] \n最直接的方法是从列表中删除旧消息（类似于[最近最少使用缓存] ）。\n在LangGraph 中从列表中删除内容的典型技术是，从节点返回一个更新，告诉系统删除列表的某个部分。您可以定义此更新的外观，但一种常见的方法是让您返回一个对象或字典，指定要保留哪些值。```\n`[] import{Annotation}from"@langchain/langgraph";[] [] constStateAnnotation=Annotation.Root({[] myList:Annotation&lt;any[]&gt;({[] reducer:([] existing:string[],[] updates:string[]|{type:string;from:number;to?:number}[])=&gt;{[] if(Array.isArray(updates)){[] // Normal case, add to the history[] return[...existing,...updates];[]}elseif(typeofupdates==="object"&amp;&amp;updates.type==="keep"){[] // You get to decide what this looks like.[] // For example, you could simplify and just accept a string "DELETE"[] // and clear the entire list.[] returnexisting.slice(updates.from,updates.to);[]}[] // etc. We define how to interpret updates[] returnexisting;[]},[] default:()=&gt;[],[]}),[]});[] [] typeState=typeofStateAnnotation.State;[] [] functionmyNode(state:State){[] return{[] // We return an update for the field "myList" saying to[] // keep only values from index -5 to the end (deleting the rest)[] myList:{type:"keep",from:-5,to:undefined},[]};[]}`\n```\n当在键“myList”下返回更新时，LangGraph 将调用“[reducer] ”函数。在该函数中，我们定义要接受的更新类型。通常，消息会添加到现有列表中（对话将增长）；但是，我们也添加了支持接受一个字典，让您可以“保留”状态的某些部分。这允许您以编程方式丢弃旧消息上下文。\n另一种常见的方法是让您返回一个“删除”对象列表，指定要删除的所有消息的ID。如果您在 LangGraph 中使用LangChain 消息和[`messagesStateReducer`] reducer（或使用相同底层功能的[`MessagesAnnotation`] ），则可以使用`RemoveMessage`来完成此操作。\n```\n`[] import{RemoveMessage,AIMessage}from"@langchain/core/messages";[] import{MessagesAnnotation}from"@langchain/langgraph";[] [] typeState=typeofMessagesAnnotation.State;[] [] functionmyNode1(state:State){[] // Add an AI message to the `messages` list in the state[] return{messages:[newAIMessage({content:"Hi"})]};[]}[] [] functionmyNode2(state:State){[] // Delete all but the last 2 messages from the `messages` list in the state[] constdeleteMessages=state.messages[].slice(0,-2)[].map((m)=&gt;newRemoveMessage({id:m.id}));[] return{messages:deleteMessages};[]}`\n```\n在上面的示例中，`MessagesAnnotation`允许我们将新消息附加到`messages`状态键，如`myNode1`所示。当它看到`RemoveMessage`时，它将从列表中删除具有该ID的消息（然后该RemoveMessage将被丢弃）。有关LangChain特定消息处理的更多信息，请查看[此关于使用`RemoveMessage`的操作指南] 。\n有关示例用法，请参阅此操作[指南] 。\n### 总结过往对话[¶] \n如上所示，修剪或删除消息的问题在于，我们可能会因为筛选消息队列而丢失信息。因此，一些应用程序受益于使用聊天模型总结消息历史的更复杂方法。![] \n可以使用简单的提示和编排逻辑来实现这一点。例如，在LangGraph 中，我们可以扩展[`MessagesAnnotation`] 以包含`summary`键。\n```\n`[] import{MessagesAnnotation,Annotation}from"@langchain/langgraph";[] [] constMyGraphAnnotation=Annotation.Root({[]...MessagesAnnotation.spec,[] summary:Annotation&lt;string&gt;,[]});`\n```\n然后，我们可以生成聊天历史的摘要，使用任何现有摘要作为下一个摘要的上下文。此`summarizeConversation`节点可以在`messages`状态键中积累一定数量的消息后调用。\n```\n`[] import{ChatOpenAI}from"@langchain/openai";[] import{HumanMessage,RemoveMessage}from"@langchain/core/messages";[] [] typeState=typeofMyGraphAnnotation.State;[] [] asyncfunctionsummarizeConversation(state:State){[] // First, we get any existing summary[] constsummary=state.summary||"";[] [] // Create our summarization prompt[] letsummaryMessage:string;[] if(summary){[] // A summary already exists[] summaryMessage=[] `This is a summary of the conversation to date:${summary}\\\\n\\\\n`+[] "Extend the summary by taking into account the new messages above:";[]}else{[] summaryMessage="Create a summary of the conversation above:";[]}[] [] // Add prompt to our history[] constmessages=[[]...state.messages,[] newHumanMessage({content:summaryMessage}),[]];[] [] // Assuming you have a ChatOpenAI model instance[] constmodel=newChatOpenAI();[] constresponse=awaitmodel.invoke(messages);[] [] // Delete all but the 2 most recent messages[] constdeleteMessages=state.messages[].slice(0,-2)[].map((m)=&gt;newRemoveMessage({id:m.id}));[] [] return{[] summary:response.content,[] messages:deleteMessages,[]};[]}`\n```\n有关示例用法，请参见[此处] 。\n### 知道**何时**删除消息[¶] \n大多数LLM 都有一个最大支持上下文窗口（以token 计）。决定何时截断消息的一个简单方法是计算消息历史中的token 数量，并在接近该限制时进行截断。朴素截断很容易自行实现，尽管有一些“陷阱”。某些模型API 进一步限制了消息类型的序列（必须以人类消息开头，不能有相同类型的连续消息等）。如果您正在使用LangChain，可以使用[`trimMessages`] 工具并指定要从列表中保留的 token 数量，以及用于处理边界的`strategy`（例如，保留最后`maxTokens`）。\n下面是一个示例。```\n`[] import{trimMessages}from"@langchain/core/messages";[] import{ChatOpenAI}from"@langchain/openai";[] [] trimMessages(messages,{[] // Keep the last &lt;&lt;= n\\_count tokens of the messages.[] strategy:"last",[] // Remember to adjust based on your model[] // or else pass a custom token\\_encoder[] tokenCounter:newChatOpenAI({modelName:"gpt-4"}),[] // Remember to adjust based on the desired conversation[] // length[] maxTokens:45,[] // Most chat models expect that chat history starts with either:[] // (1) a HumanMessage or[] // (2) a SystemMessage followed by a HumanMessage[] startOn:"human",[] // Most chat models expect that chat history ends with either:[] // (1) a HumanMessage or[] // (2) a ToolMessage[] endOn:["human","tool"],[] // Usually, we want to keep the SystemMessage[] // if it\'s present in the original history.[] // The SystemMessage has special instructions for the model.[] includeSystem:true,[]});`\n```\n## 长期记忆[¶] \nLangGraph 中的长期记忆允许系统在不同对话或会话中保留信息。与线程范围的短期记忆不同，长期记忆保存在自定义的“命名空间”中。LangGraph 将长期记忆作为JSON 文档存储在[存储] （[参考文档] ）中。每个记忆都组织在一个自定义的`namespace`（类似于文件夹）和一个独特的`key`（像文件名）下。命名空间通常包含用户或组织ID或其他标签，以便更容易组织信息。这种结构支持记忆的层次化组织。然后通过内容过滤器支持跨命名空间搜索。请参见下面的示例。\n```\n`[] import{InMemoryStore}from"@langchain/langgraph";[] [] // InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.[] conststore=newInMemoryStore();[] constuserId="my-user";[] constapplicationContext="chitchat";[] constnamespace=[userId,applicationContext];[] awaitstore.put(namespace,"a-memory",{[] rules:[[] "User likes short, direct language",[] "User only speaks English &amp; TypeScript",[]],[] "my-key":"my-value",[]});[] // get the "memory" by ID[] constitem=awaitstore.get(namespace,"a-memory");[] // list "memories" within this namespace, filtering on content equivalence[] constitems=awaitstore.search(namespace,{[] filter:{"my-key":"my-value"},[]});`\n```\n当向智能体添加长期记忆时，重要的是要考虑如何**写入记忆**、如何**存储和管理记忆更新**，以及如何为应用程序中的 LLM**召回和表示记忆**。这些问题都是相互关联的：您希望如何为 LLM 召回和格式化记忆，决定了您应该存储什么以及如何管理它。此外，每种技术都有其权衡。正确的方法在很大程度上取决于您应用程序的需求。LangGraph 旨在为您提供低级原语，以便您根据记忆[存储] 直接控制应用程序的长期记忆。\n长期记忆远非一个已解决的问题。虽然很难提供通用建议，但我们在下面提供了一些可靠的模式供您在实现长期记忆时参考。**您希望在“主路径”中写入记忆还是在“后台”写入记忆？**\n记忆可以作为主要应用程序逻辑的一部分（例如，在应用程序的“主路径”上）或作为后台任务（作为根据主要应用程序状态生成记忆的独立函数）进行更新。我们在[下面的写入记忆部分] 中记录了每种方法的一些权衡。\n**您希望将记忆作为单个档案管理还是作为文档集合管理？**\n我们提供了两种管理长期记忆的主要方法：单个持续更新的文档（称为“档案”或“模式”）或文档集合。每种方法都有其自身的好处，具体取决于您需要存储的信息类型以及您打算如何访问它。当您希望记住有关用户、组织或其他实体（包括智能体本身）的范围明确、具体的信息时，将记忆作为单个、持续更新的“档案”或“模式”进行管理非常有用。您可以预先定义档案的模式，然后使用LLM 根据交互进行更新。查询“记忆”很容易，因为它只是对JSON 文档的简单GET 操作。我们在[记住档案] 中更详细地解释了这一点。这种技术可以提供更高的准确性（在已知信息用例中），但召回率较低（因为您必须预测和建模您的领域，并且文档更新倾向于以更高的频率删除或重写旧信息）。\n另一方面，将长期记忆作为文档集合进行管理，可以存储无限量的信息。当您希望在长时间范围内重复提取和记住项目时，这项技术非常有用，但随着时间的推移，查询和管理可能会更复杂。与“档案”记忆类似，您仍然为每个记忆定义模式。您将插入新文档（并在此过程中可能更新或重新情境化现有文档），而不是覆盖单个文档。我们在[“管理记忆集合”] 中更详细地解释了这种方法。\n**您希望将记忆作为更新的指令还是作为少量样本示例呈现给您的智能体？**\n记忆通常作为系统提示的一部分提供给LLM。为 LLM“框架”记忆的一些常见方式包括提供原始信息，如“与用户 A 之前交互的记忆”，作为系统指令或规则，或作为少量样本示例。将记忆框定为“学习规则或指令”通常意味着将系统提示的一部分专门用于LLM 可以自行管理的指令。在每次对话后，您可以提示LLM 评估其性能并更新指令，', 'doi': '', 'published_date': '2026-02-02T17:06:15.982398', 'pdf_url': '', 'url': 'https://github.langchain.ac.cn/langgraphjs/concepts/memory/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践', 'authors': [], 'abstract': 'Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践 | 亚马逊AWS官方博客[Skip to Main Content] \nAWS Blog\n* [首页] \n* 版本## [亚马逊AWS官方博客] \n# Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践\n[![]] |\n*本文将深入探讨 Agent**应用中的记忆需求、记忆类型、技术组件和主流开源框架，并介绍基于亚马逊云科技的数据产品自行构建记忆模块，以及基于Agent**构建平台Bedrock AgentCore**的Agent memory**的托管方案。*\n## 前言### 当前大语言模型的困境大语言模型在处理和生成文本方面表现出色，但它们在本质上是**无状态（****stateless****）**的。这意味着每次与LLM的交互都是独立的，模型本身不会“记住”过去的对话或经验。大模型在“记忆”上主要局限于：\n* **上下文窗口的限制导致遗忘问题。**LLM通过一个有限的“上下文窗口”（Context Window）来处理信息。所有输入（包括Prompt和之前的对话片段）都必须塞入这个窗口。一旦信息超出这个窗口，LLM就“忘记”了它，无法再访问。这导致了所谓的**“****遗忘”**问题；\n* **难以处理多轮/****复杂任务。**对于需要跨越多轮对话、追踪状态或执行一系列子任务的复杂任务，LLM很难保持连贯性和进展，因为它会不断“忘记”之前的步骤和决策。特别是在Agent的场景，工具的定义和工具的返回值都会存在于上下文中，同时由于Agent具有自主工作的能力，和LLM的平均交互的轮数也大大增加；\n* **无法个性化。**由于不记住特定用户的历史偏好、习惯或之前的互动，LLM难以提供真正个性化的体验。每次互动都像是第一次见面；\n* **长上下文带来的性能和成本影响。推理速度变慢：**LLM在处理更长的上下文时，需要进行更多的计算来处理和理解所有输入信息。这会导致推理时间增加，响应速度变慢。**模型表现下降：**尽管LLM的上下文窗口越来越大，但研究发现，模型在超长上下文中检索关键信息的能力可能会下降。**更高的****Token****费用：**上下文越长，输入的token数量就越多，从而导致每次API调用的成本更高。对于需要频繁交互或处理大量文本的应用来说，这会迅速累积成可观的费用。### 为什么需要记忆模块记忆系统旨在克服LLM的局限性，赋予智能体以下核心能力：\n* **长期保留与高效管理：**存储超出LLM上下文窗口的信息，实现高效检索和过滤，避免信息遗忘；\n* **持续知识更新：**通过存储与环境和用户的交互经验，实现自我改进和知识更新；\n* **个性化服务：**记录用户偏好和历史互动，提供定制化回应；\n* **复杂任务支持：**追踪多Agent任务进展和中间结果，确保连贯完成并优化决策；\n* **提升交互质量：**保持上下文连贯性，支持深入推理，并通过反思机制从错误中学习。## AI Agent 记忆类型智能体的记忆系统主要分为短期记忆和长期记忆两大类。### 短期记忆/工作记忆\n短期记忆（Short-term Memory, STM）是智能体维护当前对话和任务的即时上下文系统，主要包括：\n* **会话缓冲（Context****）记忆**：保留最近对话历史的滚动窗口，确保回答上下文相关性；\n* **工作记忆**：存储当前任务的临时信息，如中间结果、变量值等。\n短期记忆受限于上下文窗口大小，适用于简单对话和单一任务场景。### 长期记忆**长期记忆**（Long-term Memory, LTM）是智能体用于**跨会话、跨任务长期保存知识**的记忆形式。它对应于人类的大脑中持久保存的记忆，例如事实知识、过去经历等。长期记忆的实现通常依赖于**外部存储**或**知识库**，包括但不限于：\n* **摘要记忆**：将长对话内容提炼为关键摘要存储；\n* **结构化知识库**：使用数据库或知识图谱存储结构化信息；\n* **向量化存储**：通过向量数据库实现基于语义的记忆检索。\n长期记忆使智能体能够**随着时间累积经验和知识，**它特别适用于**知识密集型应用**和**需要长期个性化**的场景。\n## 记忆管理与使用相关技术设计开发Agent的记忆系统时要考虑**不同场景下如何选择记忆内容、设计写入策略、组织记忆结构、实现检索召回**四个方面。\n### 记忆产生：判断哪些信息需要被记忆在构建智能体记忆系统时，首先要根据具体的场景确定**哪些信息值得记忆**。这些记忆往往是多维度和动态的信息结构，包括**时间**维度（理解时间依赖的关系和序列）、**空间**维度（解释基于位置的和几何关系）、参与者**状态**（跟踪多个实体及其不断变化的状况）、意图**上下文**（理解目标、动机和隐含的目的），以及文化上下文（在特定社会和文化框架内解释交流）。\n并非所有对话内容都需要长期保存，下面以4种常见场景举例哪些是与任务相关、对后续交互有价值的记忆要点。\n对于**代码助手类的智能体**，记忆应侧重**用户项目的上下文和偏好**。包括：用户项目的**代码库结构**（文件组织、模块关系）、**命名风格**（变量命名约定、代码格式风格）、常用的**框架****/****库**以及用户以前提供的代码片段或指令等。记忆这些信息可以更贴合定制化需求和项目实际情况给出建议。例如，没有记忆支持时，开发者常常需要重复告诉 AI 项目的架构或纠正AI 偏离项目规范的行为，这非常低效。而引入**持久记忆**后，AI 可以持续参考之前存储的项目背景，”记住”用户的技术栈，从而保持技术决策的一致性。同时，代码助手还能记忆用户过往的提问和反馈，例如某段代码曾反复修改，下一次遇到类似问题时可直接调用之前的方案，避免重复推理。总之，在代码场景中，记忆系统使AI能够理解**长期的项目上下文**，提供**风格一致**且**上下文相关**的代码补全和解释。\n对于**智能客服类的智能体**，记忆的重点是**用户历史和偏好**，以便提供连贯且个性化的服务。包括：用户当前**任务的状态，**提过的问题、故障、产品使用，服务配置，和解决方案记录。当用户第二次来询问类似问题时，不必重复描述自己之前的问题细节，系统能够回忆起**上次给出的建议**或已经尝试过某些步骤，直接切入重点解决当前问题。此外，记忆用户的产品使用情况和喜好（例如偏好哪种通信渠道，是否倾向自助解决）可以使响应更加贴合用户习惯。这样实现**更快的问题解决**和**更高的客户满意度，**增强对品牌的信任。\n对于**个人助理**智能体，记忆重点包括：**用户个人信息和日程表**、**目标**（如健身学习计划）、经常执行的**行为模式**（如每周几锻炼）以及对应用和服务的偏好（如偏好哪种提醒方式）等。这样智能体会提醒日程，并结合过往偏好提供个性化安排（比如知道用户周五喜欢外卖，在傍晚时主动推荐餐厅）。随着交互增加，**持续的长期记忆**使智能体能**不断适应用户**，逐渐减少对用户指令的依赖，实现更**主动**和**贴心**的服务。\n对于**推荐服务**智能体，记忆重点包括：**用户的显式反馈**（如用户给某本书点赞或明确表达不喜欢某商品）**和隐式反馈**（如浏览记录、点击行为、购买历史）**，**以此构建兴趣档案，在后续交互中个性化推荐。并持续学习，对过往推荐的反馈（是否点击、购买），**不断调整推荐策略，更新画像。**提高推荐转化率也增强用户忠诚度。\n#### 记忆管理的实际例子以下是在一个长文档处理的Agent项目中使用的上下文压缩提示词，当上下文超过指定的限额时，将触发基于LLM的压缩机制。\n```\n`# Custom system prompt for document processing domain summarization\ncustom\\_system\\_prompt = """您正在总结文档处理工作流对话。创建一个简明扼要的要点摘要，该摘要：\n专注于文档处理任务、章节生成和工作流进度保留特定文件路径、章节名称和任务完成状态维护待办事项列表状态和进度跟踪信息省略对话元素，专注于可操作的工作流信息使用适合文档处理和内容生成的技术术语保留错误消息和重要状态更新以要点形式呈现，不使用对话语言，按以下方式组织：文档处理：[关键处理步骤和结果]\n章节生成：[已完成的章节和当前进度]\n待办状态：[当前工作流状态和待处理任务]\n文件位置：[重要文件路径和输出]\n错误/问题：[遇到的任何问题及解决方案]\n"""`\n```\n### 记忆策略智能体的记忆更新可通过**轮数**或**事件**触发。轮数触发是每隔3-5轮对话自动生成摘要存入记忆；事件触发则在完成任务、场景转换等关键节点记录信息。例如，客服完成问题处理时保存解决方案，个人助理更新日程后写入日历。开发者可实现监控逻辑，在对话累积或话题转换时，让大模型对近期对话生成摘要，提取关键信息并添加标签便于检索。\n系统也可支持用户主动标记需要记住的信息，如通过**口头指令**或**界面**操作。这不仅让用户指定重要内容，也支持删除特定记忆的需求，确保用户对数据的控制权。\n### 记忆存储：记忆组织结构设计记忆数据通常采用**用户****→****会话→****记忆片段**的三层结构管理。**用户**层区分不同账号空间，**会话**层隔离各对话上下文，**记忆片段**层存储具体内容及元数据（如时间、关键词、来源等）。复杂系统可能需要维护多个记忆库，包括短期工作记忆、长期情节记忆、语义知识库等。合理的结构设计有助于快速检索和有效管理记忆内容。\n### 记忆检索：记忆查询与召回逻辑智能体需要基于当前对话意图从记忆库中检索相关信息。主要检索方法包括关**键词匹配**、**向量语义搜索**和**元数据过滤**。系统将检索到的记忆按相关度排序，选取最相关内容加入到对话上下文中，用于生成更准确的响应。例如在推荐场景中，可基于用户历史偏好记忆提供个性化建议。\n## 上下文工程（Context Engineering）与记忆\n### 上下文工程上下文工程与记忆系统形成共生关系，共同支撑智能体的认知能力。记忆系统作为”信息仓库”，存储历史对话、知识和用户偏好；而上下文工程则扮演”智能调度员”，决定从记忆中检索哪些信息及如何组织呈现给LLM。\n上下文工程的核心在于，LLM的性能和有效性根本上取决于其接收的**上下文**。实现了上下文工程的系统一般包含三类**基础组件**：\n1. **上下文检索与生成：**涵盖Prompt生成和外部知识获取；\n2. **上下文处理：**涉及长序列处理、自我完善和结构化信息集成；\n3. **上下文管理：**关注记忆层次、压缩技术和优化策略。\n这些组件是高级应用实现（如RAG、显式记忆系统和智能体系统）的基石。由此，我们可以将上下文工程定义为：上下文工程将上下文C重新概念化为一组动态结构化的信息组件，c1, c2, …, cn。这些组件由一组函数进行来源获取、过滤和格式化，最终由高级组装函数A进行编排。\n### 上下文工程与记忆的关系上下文工程与记忆系统**紧密且共生**，都是AI智能体的重要构建手段。一方面**，记忆是上下文的****“****仓库”****，**智能体的记忆系统（如历史对话、知识库、用户偏好）是信息存储地，为LLM提供**潜在上下文**。另一方面，**上下文工程是记忆的****“****调度员”****和“****优化器”****，上下文工程**决定从记忆中检索哪些信息及如何检索，确保提取最相关的记忆片段。\n### 上下文工程在项目中的例子在一个文档自动化处理生成的Agent项目中，我们面临一个关键挑战：输入文档总量超过500页，远超模型的最大Token限制，同时项目对生成内容的召回率和准确率有较高要求。\n为解决这一问题，我们实施了以下上下文工程策略：1. **文档分块处理：**将大型文档集合切分为适当大小的chunks，并存储在文件系统中；\n2. **摘要生成：**为每个文档块生成精炼的文字摘要，提供内容概览。并生成整个文档的摘要信息；\n3. **动态上下文管理：**赋予Agent自主选择的能力，使其可以根据任务需求动态调取相关文档块；\n4. **上下文优化：**任务完成后自动释放不再需要的上下文，优化资源利用。\n这种方法使Agent能够在保持高准确率的同时，有效处理超过模型上下文限制的文档集合。\n## 主流记忆框架分析基于上个章节介绍的设计思路，核心组件和优化策略，业界涌现了多种记忆机制的实现方案。以下我们从**开源框架（****Mem0****，MemGPT****，LangMem****以及他们与亚马逊云科技服务的集成）**和**亚马逊云科技商业解决方案（****AI Agent****构建托管服务Bedrock AgentCore****的记忆模块）**两个角度，对目前主流的Agent记忆方案进行分析，比较它们的特点、适用场景以及部署成本。\n### Mem0\n[Mem0] 是专为AI Agent设计的开源记忆框架，通过智能记忆管理帮助Agent实现状态持久化。它支持工作记忆、事实记忆、情景记忆和语义记忆等多种类型，提供智能的LLM提取、过滤和衰减机制，有效降低计算成本。同时支持多模态处理和Graph记忆功能，既可使用托管服务也可自建部署。\n从架构来看，Mem0包含几个核心模块：**核心记忆层、大语言模型层、嵌入模型层、向量存储层、图存储层和持久化存储层**。核心记忆层是构建核心逻辑来判断新增、检索、更新和删除记忆的相应实现；大语言模型层负责根据用户输入提取出关键信息，以及生成如何更新记忆的决策；嵌入模型和向量存储层负责支持记忆的向量化存储和检索；图存储层负责存储抽取出的实体关系，丰富记忆的组织形态；持久化存储层负责存储对记忆系统的操作信息。这种分层架构设计确保了记忆系统的可扩展性和可维护性，\n每层职责明确，便于针对不同场景进行优化配置。Mem0 的设计理念专注于智能记忆管理而非简单数据存储，融合了几个关键技术创新：* 双LLM 架构：系统通过两次不同的LLM 调用实现复杂的分工。第一次专注于信息提取，第二次专门处理决策过程，提高准确性并允许专门优化。* 上下文感知处理：在现有记忆上下文中分析新数据，确保记忆系统一致性和连贯性，防止碎片化并维护信息间逻辑关系。* 智能去重机制：结合向量相似性搜索与LLM判断，防止冗余信息存储，保持记忆质量和系统效率。\n* 冲突解决能力：当出现矛盾信息时，智能确定保留、更新或删除的适当行动，适应用户偏好和环境的动态变化。#### Mem0与Agent框架的集成\n开发者可以通过两种方式集成Mem0：一是在环境变量配置依赖信息后，直接调用Mem0的接口函数（如添加、查找、更新记忆等）；二是将Mem0封装成工具传入Agent框架，由Agent根据处理逻辑自主调用相应方法。\n#### Mem0与亚马逊云科技的集成\n亚马逊云科技的多项服务均支持与Mem0集成，为开发者提供完整的企业级记忆解决方案：\n* 模型服务集成：支持Amazon Bedrock的多种模型，包括Claude-3.7-Sonnet用于复杂推理、Titan-Embed-Text-v2用于向量化处理。\n* 存储服务集成：* 向量存储：Amazon Aurora Serverless V2 for PostgreSQL、Amazon OpenSearch\n* 图数据存储：Amazon Neptune Analytics\n* 开发框架集成：亚马逊云科技开源的StrandsAgent框架中内置了基于Mem0能力封装的mem0\\_memory工具。\nMem0作为开源解决方案，为开发者提供了灵活的记忆管理能力。结合亚马逊云科技服务的强大生态，可以构建高性能、可扩展的Agent记忆系统，适合需要深度定制和成本优化的企业级应用场景。更多关于Mem0的深度解析以及和亚马逊云科技的服务的集成请见博客[https://amazon.awsapps.com/workdocs-amazon/index.html#/document/17faaf605c2b12a543d5b9223ec5301aca29c03ffd5f3d1f5dd929d5496471bc] \n### Letta (前身为MemGPT)\n#### Letta 功能介绍Letta（前身为MemGPT）是一个专注于构建具有持续记忆能力的 AI Agent 的框架，它的设计思路是将LLM代理类比为计算机操作系统，采用”**虚拟内存**“的概念来管理智能体的记忆。其核心创新在于双层记忆架构，包括**上下文内记忆**（直接存在于模型上下文窗口中的系统指令、可读写记忆块和当前对话）和**上下文外记忆**（存储历史对话和外部知识的长期存储）。当上下文窗口接近填满时，系统会自动将对话历史压缩为递归摘要并存储为记忆块，同时保留原始对话供后续检索，通过工具如core\\_memory\\_append、core\\_memory\\_replace 和recall 实现记忆的编辑与检索，从而使AI 代理能够在长期交互中保持连贯性，真正实现记住过去、学习新知并随时间演化的能力。#### Letta与亚马逊云科技生态的深度集成\nLetta可无缝对接亚马逊云科技服务栈，以下是一个通过 Letta 框架搭建的电商客服机器人问答流程示例：* 使用Amazon Bedrock 的Claude 或Titan 模型作为基础LLM\n* 采用Amazon PostgreSQL、OpenSearch 作为向量存储后端* 利用ElastiCache 缓存来提升推理（框架原生支持）、问答等场景（需要搭建缓存中间件）的效率* 通过亚马逊云科技Lambda 实现记忆管理的无服务器架构[![]] |\n图1. 通过Letta 框架搭建的电商客服机器人问答流程示例**LangMem**\nLangMem 是由LangChain 开发的，旨在解决AI 代理的”健忘症”问题。传统的大语言模型在会话结束或上下文窗口被超出时会丢失之前的交互信息，而LangMem 为AI 代理提供了长期记忆能力，使其能够跨会话保持知识连续性，记住用户的偏好、过往交互和重要事实。这一创新将AI 代理从简单的反应系统转变为能够随时间学习和适应的动态助手。例如：你的AI 助手能够记住你上周提到的项目细节，了解你的工作习惯，甚至记得你喜欢的咖啡类型。LangMem 框架的设计理念是借鉴人类心理学对记忆的分类，为Agent设计了三种核心记忆类型，每种类型都有其独特的功能和应用场景。\n* **语义记忆 (Semantic Memory)****：**语义记忆是 Agent 的知识基础，存储客观事实、用户偏好和基础知识，作为长期持久化记忆嵌入系统提示中，可通过Collection 方式保存完整历史信息，或通过Profile 方式只保留最新状态，为Agent 提供稳定的知识支撑，确保其能够准确理解和回应用户需求。* **情节记忆（Episodic Memory****）：**捕捉 Agent 的交互经历，不仅存储对话内容，还包含完整上下文和推理过程，作为短期记忆主要用于构建用户提示词，使Agent 能够从过往经验中学习，参考成功案例调整响应策略，从而在类似情境中提供更加个性化和有效的解决方案。* **程序记忆 (Procedural Memory)****：**专注于”如何做”的实操知识，从初始系统提示开始，通过持续反馈和经验积累不断优化，作为短期记忆帮助 Agent 学习最有效的行为模式，既可用于系统提示也可用于用户提示，使Agent 能够根据不同情境灵活调整策略，提高解决问题的效率和准确性。LangMem 不仅能存储对话中的重要信息，还能优化提示和行为，在多次交互后提供更连贯、个性化的响应。它消除了传统AI 代理在会话结束后丢失上下文的问题，减少了重复询问用户已提供信息的需要，显著提升了用户体验的连贯性和个性化程度。LangMem 提供通用存储兼容性和热路径内存工具，使AI代理能在实时会话中即时保存和检索信息。其智能后台内存管理功能自动提取、汇总并更新知识库，且与 LangGraph 平台无缝集成。LangMem 的高级特性包括**主动记忆管理、共享内存机制、命名空间组织和个性化持续进化**能力，使 AI Agent 能根据重要性动态存储信息，支持多个Agent 之间的知识共享，高效组织检索信息，并不断适应用户需求变化，提供越来越精准的服务。目前LangMem 主要是与LangGraph 集成，支持Amazon Bedrock。在记忆存储层面，针对开发场景，有内置的 InMemoryStore，支持快速的迭代、测试和原型设计；另外，提供对 PostgresqlSQL 的支持。对于其他记忆存储引擎，LangMem 提供开放的接口实现方式，需要用户定制开发集成。### Amazon Bedrock AgentCore Memory：亚马逊云科技的托管记忆解决方案\n相比开源框架，亚马逊云科技也提供**开箱即用的托管服务**，通过AI Agent构建平台Bedrock AgentCore中的记忆模块帮助开发者更快捷地为AI Agent赋能记忆功能。您无需运维任何底层资源，只需一键即可集成业界领先的记忆系统。\n[![]] |\n图2-Bedrock AgentCore中的记忆模块核心功能展示\nAmazon Bedrock AgentCore 的Memory 模块是一个由亚马逊云科技托管的持久化记忆系统，用于存储和管理AI Agent 的对话和知识。它提供**短期记忆（****short-term memory****）和长期记忆（long-term memory****）**两种模式。短期记忆负责在一次会话中记录最近的最近几轮对话，确保代理能够“记住”当前对话的上下文。长期记忆则从对话中提取结构化的关键信息，在多个会话之间保留知识，使Agent能够“学习”用户偏好、事实和摘要等信息。\n**记忆的存储**\nMemory 模块在架构上采用分层存储策略：短期记忆层存储原始交互事件作为即时上下文，长期记忆层存储从事件提取的概要知识。Memory 服务背后实现了自动的信息处理流水线：当新的事件被存储时，如果Memory 配置了长期记忆策略，服务会异步地对事件内容进行分析（例如调用基础模型）来提炼出可长期保存的知识片段。AgentCore Memory 内置了多种记忆策略（Memory Strategy）来定义如何将原始对话转化为结构化长期记忆。例如：\n* **SemanticMemoryStrategy**（语义记忆策略）：从对话中抽取出**事实和知识**，以便日后查询。\n* **SummaryMemoryStrategy**（摘要策略）：为每个会话生成**对话摘要**，提炼主要内容。\n* **UserPreferenceMemoryStrategy**（用户偏好策略）：捕获用户的偏好、风格和重复选择等信息。\n使用内置策略时，无需额外配置模型，AgentCore Memory 服务会在后台使用预置的模型来完成提取和归纳。当开发者调用CreateEvent 保存新事件后，这些策略会被自动触发，异步运行LLM分析内容并产生长期记忆记录（memory records）。长期记忆记录生成后存储于 Memory 中，对应特定的命名空间和类型（如事实、摘要、偏好），每条记录也有唯一ID以供检索。\n此外，AgentCore 允许**自定义记忆策略（****CustomMemoryStrategy****）**，开发者可提供自定义的提示词（prompt）和选择特定的基础模型来执行记忆提取，例如只提取某类domain知识。\n', 'doi': '', 'published_date': '2025-09-19T00:00:00+00:00', 'pdf_url': '', 'url': 'https://aws.amazon.com/cn/blogs/china/agentic-ai-infrastructure-deep-practice-experience-thinking-series-three-best-practices-for-agent-memory-module/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': 'YouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下： \\nGitHub地址: https://github.com/NanGePlus/LangChai... \\nGitee地址: https://gitee.com/NanGePlus/LangChain... \\n\\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力 \\n个人项目GitHub地址：https://github.com/NanGePlus \\n个人项目Gitee地址：https://gitee.com/NanGePlus \\n大模型代理平台: https://nangeai.top/ \\n\\n【章节】\\n\\n0:00 引言 源代码下载方式\\n0:37 核心功能\\n1:37 核心概念介绍\\n8:37 准备工作和项目初始化\\n13:27 InMemorySaver测试和源码\\n18:16 PostgresSaver测试和源码\\n21:33 管理策略测试和源码\\n24:05 最后 总结\\n\\n频道项目\\u0026视频推荐：\\n1. 8n自动化工作流平台相关分享 \\nhttps://github.com/NanGePlus/N8NWorkf... \\n\\n2. 大模型应用技术开发-入门系列 \\nhttps://github.com/NanGePlus/LLMsBasi... \\n \\n3. 大模型应用技术开发-MCP系列\\nhttps://github.com/NanGePlus/MCPServe... \\n\\n4. 大模型应用技术开发-RAG系列 \\nhttps://github.com/NanGePlus/RagWithM... \\nhttps://github.com/NanGePlus/LightRAG... \\nhttps://github.com/NanGePlus/KagTest \\n\\n5. 大模型应用技术开发-Agent系列 \\nhttps://github.com/NanGePlus/ReActAge... \\nhttps://github.com/NanGePlus/CrewAIFl... \\nhttps://github.com/NanGePlus/AutoGenV... \\n \\n6. 大模型应用技术开发-Fine-Tuning大模型微调系列 \\nhttps://github.com/NanGePlus/FineTuni...\n| view_count: 55 views | short_view_count: 55 views | num_likes: 4 likes | num_subscribers: 2.95 thousand | duration: 24 minutes 10 seconds', 'doi': '', 'published_date': '2026-01-15T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '别再混淆！一文看懂LangGraph 的短期记忆与长期记忆：原理', 'authors': [], 'abstract': '别再混淆！一文看懂 LangGraph 的短期记忆与长期记忆：原理、实战与避坑清单\\_博客-飞桨星河社区\n![]', 'doi': '', 'published_date': '2025-11-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://aistudio.baidu.com/blog/detail/737084298395525', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '管理内存 - LangChain 框架', 'authors': [], 'abstract': '[跳到内容] \n\n# 管理内存 [¶] \n\n许多 AI 应用程序需要内存才能在多次交互中共享上下文。LangGraph 支持构建对话代理至关重要的两种内存类型：\n\n- [短期内存] ：通过在会话中维护消息历史来跟踪正在进行的对话。\n- [长期内存] ：在会话之间存储用户特定或应用程序级别的数据。\n\n启用 [短期内存] 后，长对话可能会超出 LLM 的上下文窗口。常见的解决方案有：\n\n- [修剪] ：删除前或后 N 条消息（在调用 LLM 之前）\n- [摘要] ：总结历史中较早的消息并用摘要替换它们\n- [从 LangGraph 状态永久删除消息] \n- 自定义策略（例如，消息过滤等）\n\n这使得代理能够跟踪对话，而不会超出 LLM 的上下文窗口。\n\n## 添加短期内存 [¶] \n\n短期内存使代理能够跟踪多轮对话。\n\n_API 参考： [InMemorySaver] \\| [StateGraph] _\n\n```\nfromlanggraph.checkpoint.memoryimport InMemorySaverfromlanggraph.graphimport StateGraphcheckpointer = InMemorySaver()builder = StateGraph(...)graph = builder.compile(checkpointer=checkpointer)graph.invoke({"messages": [{"role": "user", "content": "hi! i am Bob"}]},{"configurable": {"thread_id": "1"}},)\n```\n\n请参阅 [持久化] 指南，了解有关使用短期内存的更多信息。\n\n## 添加长期内存 [¶] \n\n使用长期内存可以在对话之间存储用户特定或应用程序特定的数据。这对于聊天机器人等应用程序非常有用，您可能希望记住用户偏好或其他信息。\n\n_API 参考： [StateGraph] _\n\n```\nfromlanggraph.store.memoryimport InMemoryStorefromlanggraph.graphimport StateGraphstore = InMemoryStore()builder = StateGraph(...)graph = builder.compile(store=store)\n```\n\n请参阅 [持久化] 指南，了解有关使用长期内存的更多信息。\n\n## 修剪消息 [¶] \n\n要修剪消息历史，您可以使用 [`trim_messages`] 函数\n\n_API 参考： [trim\\_messages] \\| [count\\_tokens\\_approximately] _\n\n```\nfromlangchain_core.messages.utilsimport (trim_messages,count_tokens_approximately)defcall_model(state: MessagesState):messages = trim_messages(state["messages"],strategy="last",token_counter=count_tokens_approximately,max_tokens=128,start_on="human",end_on=("human", "tool"),)response = model.invoke(messages)return {"messages": [response]}builder = StateGraph(MessagesState)builder.add_node(call_model)...\n```\n\n完整示例：修剪消息\n\n```\nfromlangchain_core.messages.utilsimport (trim_messages,count_tokens_approximately)fromlangchain.chat_modelsimport init_chat_modelfromlanggraph.graphimport StateGraph, START, MessagesStatemodel = init_chat_model("anthropic:claude-3-7-sonnet-latest")summarization_model = model.bind(max_tokens=128)defcall_model(state: MessagesState):messages = trim_messages(state["messages"],strategy="last",token_counter=count_tokens_approximately,max_tokens=128,start_on="human",end_on=("human", "tool"),)response = model.invoke(messages)return {"messages": [response]}checkpointer = InMemorySaver()builder = StateGraph(MessagesState)builder.add_node(call_model)builder.add_edge(START, "call_model")graph = builder.compile(checkpointer=checkpointer)config = {"configurable": {"thread_id": "1"}}graph.invoke({"messages": "hi, my name is bob"}, config)graph.invoke({"messages": "write a short poem about cats"}, config)graph.invoke({"messages": "now do the same but for dogs"}, config)final_response = graph.invoke({"messages": "what\'s my name?"}, config)final_response["messages"][-1].pretty_print()\n```\n\n```\n================================== Ai Message ==================================\nYour name is Bob, as you mentioned when you first introduced yourself.\n\n```\n\n## 总结消息 [¶] \n\n处理长对话历史的有效策略是，一旦达到某个阈值，就总结较早的消息\n\n_API 参考： [AnyMessage] \\| [count\\_tokens\\_approximately] \\| [StateGraph] \\| [START] _\n\n```\nfromtypingimport Any, TypedDictfromlangchain_core.messagesimport AnyMessagefromlangchain_core.messages.utilsimport count_tokens_approximatelyfromlangmem.short_termimport SummarizationNodefromlanggraph.graphimport StateGraph, START, MessagesStateclassState(MessagesState):context: dict[str, Any] # (1)!classLLMInputState(TypedDict): # (2)!summarized_messages: list[AnyMessage]context: dict[str, Any]summarization_node = SummarizationNode(token_counter=count_tokens_approximately,model=summarization_model,max_tokens=512,max_tokens_before_summary=256,max_summary_tokens=256,)defcall_model(state: LLMInputState): # (3)!response = model.invoke(state["summarized_messages"])return {"messages": [response]}builder = StateGraph(State)builder.add_node(call_model)builder.add_node("summarize", summarization_node)builder.add_edge(START, "summarize")builder.add_edge("summarize", "call_model")...\n```\n\n1. 我们将在 `context` 字段中跟踪运行中的摘要（由 `SummarizationNode` 期望）。\n2. 在此处定义私有状态，该状态将仅用于过滤 `call_model` 节点的输入。\n3. 我们在此处传递一个私有输入状态，以隔离摘要节点返回的消息。\n\n完整示例：总结消息\n\n```\nfromtypingimport Any, TypedDictfromlangchain.chat_modelsimport init_chat_modelfromlangchain_core.messagesimport AnyMessagefromlangchain_core.messages.utilsimport count_tokens_approximatelyfromlanggraph.graphimport StateGraph, START, MessagesStatefromlanggraph.checkpoint.memoryimport InMemorySaverfromlangmem.short_termimport SummarizationNodemodel = init_chat_model("anthropic:claude-3-7-sonnet-latest")summarization_model = model.bind(max_tokens=128)classState(MessagesState):context: dict[str, Any] # (1)!classLLMInputState(TypedDict): # (2)!summarized_messages: list[AnyMessage]context: dict[str, Any]summarization_node = SummarizationNode(token_counter=count_tokens_approximately,model=summarization_model,max_tokens=256,max_tokens_before_summary=256,max_summary_tokens=128,)defcall_model(state: LLMInputState): # (3)!response = model.invoke(state["summarized_messages"])return {"messages": [response]}checkpointer = InMemorySaver()builder = StateGraph(State)builder.add_node(call_model)builder.add_node("summarize", summarization_node)builder.add_edge(START, "summarize")builder.add_edge("summarize", "call_model")graph = builder.compile(checkpointer=checkpointer)# Invoke the graphconfig = {"configurable": {"thread_id": "1"}}graph.invoke({"messages": "hi, my name is bob"}, config)graph.invoke({"messages": "write a short poem about cats"}, config)graph.invoke({"messages": "now do the same but for dogs"}, config)final_response = graph.invoke({"messages": "what\'s my name?"}, config)final_response["messages"][-1].pretty_print()print("\\nSummary:", final_response["context"]["running_summary"].summary)\n```\n\n1. 我们将在 `context` 字段中跟踪运行中的摘要（由 `SummarizationNode` 期望）。\n2. 在此处定义私有状态，该状态将仅用于过滤 `call_model` 节点的输入。\n3. 我们在此处传递一个私有输入状态，以隔离摘要节点返回的消息。\n\n```\n================================== Ai Message ==================================\nFrom our conversation, I can see that you introduced yourself as Bob. That\'s the name you shared with me when we began talking.\nSummary: In this conversation, I was introduced to Bob, who then asked me to write a poem about cats. I composed a poem titled "The Mystery of Cats" that captured cats\' graceful movements, independent nature, and their special relationship with humans. Bob then requested a similar poem about dogs, so I wrote "The Joy of Dogs," which highlighted dogs\' loyalty, enthusiasm, and loving companionship. Both poems were written in a similar style but emphasized the distinct characteristics that make each pet special.\n\n```\n\n## 删除消息 [¶] \n\n要从图状态中删除消息，您可以使用 `RemoveMessage`。\n\n- 删除特定消息\n\n\n\n```\nfromlangchain_core.messagesimport RemoveMessagedefdelete_messages(state):messages = state["messages"]if len(messages) > 2:# remove the earliest two messagesreturn {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}\n```\n\n- 删除 **所有** 消息\n\n\n\n```\nfromlanggraph.graph.messageimport REMOVE_ALL_MESSAGESdefdelete_messages(state):return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}\n```\n\n\n`add_messages` 缩减器\n\n要使 `RemoveMessage` 工作，您需要将状态键与 [`add_messages`] [缩减器] 一起使用，例如 [`MessagesState`] \n\n有效的消息历史\n\n删除消息时， **请确保** 生成的消息历史有效。检查您正在使用的 LLM 提供商的限制。例如：\n\n- 有些提供商期望消息历史以 `user` 消息开头\n- 大多数提供商要求带有工具调用的 `assistant` 消息后跟相应的 `tool` 结果消息。\n\n完整示例：删除消息\n\n```\nfromlangchain_core.messagesimport RemoveMessagedefdelete_messages(state):messages = state["messages"]if len(messages) > 2:# remove the earliest two messagesreturn {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}defcall_model(state: MessagesState):response = model.invoke(state["messages"])return {"messages": response}builder = StateGraph(MessagesState)builder.add_sequence([call_model, delete_messages])builder.add_edge(START, "call_model")checkpointer = InMemorySaver()app = builder.compile(checkpointer=checkpointer)for event in app.stream({"messages": [{"role": "user", "content": "hi! I\'m bob"}]},config,stream_mode="values"):print([(message.type, message.content) for message in event["messages"]])for event in app.stream({"messages": [{"role": "user", "content": "what\'s my name?"}]},config,stream_mode="values"):print([(message.type, message.content) for message in event["messages"]])\n```\n\n```\n[(\'human\', "hi! I\'m bob")]\n[(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! How are you doing today? Is there anything I can help you with?\')]\n[(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! How are you doing today? Is there anything I can help you with?\'), (\'human\', "what\'s my name?")]\n[(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! How are you doing today? Is there anything I can help you with?\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob.\')]\n[(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob.\')]\n\n```\n\n返回顶部', 'doi': '', 'published_date': '2025-01-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://langgraph.com.cn/how-tos/memory/index.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '【AI大模型应用开发】以LangChain为例：从短期记忆实战 - 53AI', 'authors': [], 'abstract': '- [首页] \n- [产品服务] \n- [客户案例] \n- [AI知识库] \n- [关于我们] \n\n热门场景\n\n工作+AI\n\n业务+AI\n\nAIx业务\n\n[落地咨询] \n\n[定制开发] \n\n热门产品\n\n[53AI KM\\\n\\\n让知识在人与AI之间高效流动] [53AI Studio\\\n\\\n高准确率的企业级智能体开发平台] [53AI Hub开源\\\n\\\n三分钟搭建出独立的企业AI门户] [53AI Browser\\\n\\\n“AI专家”效率倍增的秘密武器\\\n\\\n敬请期待...] \n\n[行业案例] [场景案例] \n\n[前沿技术] [Agent框架] [行业应用] [企业落地] \n\n[公司介绍] [渠道合作] \n\n53AI知识库\n\n学习大模型的前沿技术与行业应用场景\n\n[立即咨询] [预约演示] \n\n[首页] [AI知识库] [前沿技术] [RAG技术] \n\n我要投稿\n\n# 【AI大模型应用开发】以LangChain为例：从短期记忆实战，到如何让AI应用保持长期记忆的探索\n\n发布日期：2024-05-05 08:06:56浏览次数： 5521\n\n作者：同学小张\n\n微信搜一搜，关注“同学小张”\n\n在AI应用中，无论是多轮对话场景、RAG场景还是AI Agent场景中，记忆能力都是不可或缺的一部分。然而，记忆能力是目前大模型的短板，所以，现在很多框架，诸如 LangChain、MetaGPT 等，都封装了自己的记忆模块，以方便开发者实现自己大模型应用的记忆功能。\n\n之前我们简单概览了一下 LangChain 的 Memory 模块，那只是在多轮对话场景中，简单的取最近几次的对话历史作为记忆。这是最简单的使用记忆的方法，也是短期记忆的一种。\n\n本文我们来系统看下实现大模型应用记忆的方法，包括短期记忆和长期记忆。还是以LangChain为例来进行实战。\n\n# 0\\. LangChain中 Memory 实战\n\n> 我这里将记忆简单理解为对话历史，查询历史等历史记录。\n\n## 0.1 记忆封装罗列\n\n在 LangChain 中提供了多种获取记忆的封装，例如 `ConversationBufferMemory`、 `ConversationBufferWindowMemory`、 `ConversationTokenBufferMemory` 等。\n\n简单罗列如下：\n\n- •\xa0`ConversationBufferMemory` 可以理解为通用的将全部的历史记录取出来。\n\n- •\xa0`ConversationBufferWindowMemory` 可以理解为滑动窗口，每次只取最近的K条记录。\n\n- •\xa0`ConversationTokenBufferMemory` 可以理解为控制每次取的历史记录的Token数。\n\n- •\xa0`ConversationSummaryMemory`: 对上下文做摘要\n\n- •\xa0`ConversationSummaryBufferMemory`: 保存 Token 数限制内的上下文，对更早的做摘要\n\n- •\xa0`VectorStoreRetrieverMemory`: 将 Memory 存储在向量数据库中，根据用户输入检索回最相关的部分\n\n- •\xa0`ConversationEntityMemory`：保存一些实体信息，例如从输入中找出一个人名，保存这个人的信息。\n\n- •\xa0`ConversationKGMemory`：将历史记录按知识图谱的形式保存和查询\n\n\n> 这里面的大部分记忆封装，之前咱们已经学习过了，这里不再重复。详细的使用教程可以参考我之前的文章： [【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战+细节）] 。\n\n下面看下\xa0`VectorStoreRetrieverMemory`\xa0的使用和实现效果。\n\n## 0.2 实践：VectorStoreRetrieverMemory的使用\n\n### 0.2.1 完整代码\n\n```\nfrom\xa0langchain.memory\xa0importVectorStoreRetrieverMemoryfrom\xa0langchain_openai\xa0importChatOpenAIfrom\xa0langchain.embeddings.openai\xa0importOpenAIEmbeddingsfrom\xa0langchain.vectorstores\xa0importChromafrom\xa0langchain.chains\xa0importConversationChainfrom\xa0langchain.prompts\xa0importPromptTemplatevectorstore\xa0=Chroma(embedding_function=OpenAIEmbeddings())retriever\xa0=\xa0vectorstore.as_retriever(search_kwargs=dict(k=1))memory\xa0=VectorStoreRetrieverMemory(retriever=retriever)memory.save_context({"input":"我喜欢学习"},{"output":"你真棒"})memory.save_context({"input":"我不喜欢玩儿"},{"output":"你可太棒了"})PROMPT_TEMPLATE\xa0="""以下是人类和\xa0AI\xa0之间的友好对话。AI\xa0话语多且提供了许多来自其上下文的具体细节。如果\xa0AI\xa0不知道问题的答案，它会诚实地说不知道。以前对话的相关片段：{history}（如果不相关，你不需要使用这些信息）当前对话：人类：{input}AI："""prompt\xa0=PromptTemplate(input_variables=["history","input"],\xa0template=PROMPT_TEMPLATE)chat_model\xa0=ChatOpenAI()conversation_with_summary\xa0=ConversationChain(\xa0\xa0\xa0\xa0llm=chat_model,\xa0\xa0\xa0\xa0prompt=prompt,\xa0\xa0\xa0\xa0memory=memory,\xa0\xa0\xa0\xa0verbose=True)print(conversation_with_summary.predict(input="你好，我叫同学小张，你叫什么"))print(conversation_with_summary.predict(input="我喜欢干什么？"))\n```\n\n### 0.2.2 代码解释\n\n（1）代码中我们使用了\xa0`VectorStoreRetrieverMemory`\xa0作为记忆存储和获取的模块。它既然是向量存储和查询，所以接收参数： `retriever=retriever`，必须要穿给它一个向量数据库才能工作。\n\n（2）然后使用了\xa0`ConversationChain`\xa0作为对话的Chain。它接收一个\xa0`memory = memory`\xa0参数设置，指定使用的记忆类型。默认是最普通的\xa0`ConversationBufferMemory`\xa0类型。\n\n（3）什么时候会去检索记忆呢？在Chain运行 invoke 的一开始，就加载了。源码如下：\n\n可以看到，最后就是用用户的输入，去向量数据库中检索相关的片段作为需要的记忆。\n\n### 0.2.3 运行效果展示\n\n第一个问题，检索到的内容不相关，但是也得检索出一条。\n\n第二个问题，检索到的内容相关，用检索到的内容回答问题。\n\n# 1\\. 如何让AI应用具备长期记忆？\n\n> 我这里将“长期记忆”理解为持久化记忆或者长上下文记忆。也就是两种形式的记忆我都认为是“长期记忆”：\n>\n> - •\xa0第一种：持久化记忆，对话历史等历史记录持久化保存，不会随着进程的退出而消失。例如保存成功文件或存储进数据库等。\n>\n> - •\xa0第二种：长上下文记忆，当历史记录特别多时，如何从历史记录中找出有用的记忆，而不是只关注最近的几条历史记录。\n\n## 1.1 LangChain 中的记忆模块是否具有长期记忆的能力？\n\n上面罗列的和实战的 LangChain 中的记忆模块， `ConversationBufferMemory`、\xa0`ConversationBufferWindowMemory`、 `ConversationTokenBufferMemory`\xa0看起来都无法实现长期记忆的能力：无法持久化（看源码，底层都是一个List类型，保存到内存，随着进程消亡而消亡），也没法查询长的上下文。\n\n`ConversationSummaryMemory`、 `ConversationSummaryBufferMemory`\xa0在一定程度上能提供更多的记忆信息（因为其对之前的历史记录做了总结压缩），所以在某些上下文不是特别长的场景中，还是可以用一用来实现简单的长期记忆能力的。\n\n`ConversationEntityMemory`、 `ConversationKGMemory` 一个只保存实体信息，一个将历史记录组织成知识图谱，会对长上下文场景中的长时记忆功能非常有用。它可以从全局的角度将用户提问中的实体或相关知识作补充，而不是关注最近的几次对话。\n\n`VectorStoreRetrieverMemory` 应该是最好和最能实现长期记忆能力的类型了。一方面，它是向量数据库存储，可以方便的持久化数据，另一方面，它的向量检索能力，本来就是针对用户提问检索出最相关的文档片段，不受长上下文的窗口限制。但是其检索的相关片段之间是否存在信息缺失等，会影响长时记忆的准确性，从而影响最终的结果。\n\n> 所以， `ConversationEntityMemory`、 `ConversationKGMemory`\xa0+\xa0`VectorStoreRetrieverMemory`\xa0是否可以一试？三者结合，保持相关片段的相关性，同时利用实体关系和知识图谱进行补充，是否可以更好地实现长时记忆的能力？感兴趣的可以一起讨论~\n\n## 1.2 关于让AI应用具备长期记忆的一些研究\n\n### 1.2.1 记忆思考：回忆和后思考使LLM具有长期记忆\n\n> 论文原文：Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory\n\n这篇文章提出了一种名为TiM（Think-in-Memory）的记忆机制，旨在使LLM在对话过程中保持记忆，存储历史思考。TiM包括两个关键阶段：在生成回复之前，LLM从记忆中回想相关思考；在生成回复之后，LLM进行后思考并将历史和新思考结合起来更新记忆。\n\n下图描述了TiM方法的使用方式：\n\n（1）在回答第二个问题时，需要考虑问题1的内容，从问题1中推理出答案，而后在回答问题2。 （2）在回答第三个问题时，需要同时考虑问题1和问题2，从问题1和问题2中推理出答案，而后再回答问题3。\n\n这就导致了问题的存在：问题1被推理了两遍，两遍的结果还可能不一样，导致最终的错误。\n\n而TiM的思路，是将每一个问题的思考也存起来，这样，在回答问题3时，可以使用问题2之前的思考，避免重新思考问题1，从而避免多次思考结果不一致导致的错误。\n\n具体步骤如下：\n\n总的原理是，将相关的记忆放到一起，例如上图中，关于book的谈话放到index 0中，关于moive的谈话放到index 1中。\n\n如何将相关内容放到一起的？论文中实现了一种基于局部敏感哈希（LSH）的存储系统，用于高效地存储和检索大规模的向量数据。LSH的作用是将每个向量映射到一个哈希索引，相似的向量有更高的概率被映射到相同的哈希索引。\n\n而相同的哈希索引可以将用户问题固定到某一块记忆中，然后只在这一块记忆中进行向量检索，大大提高了检索效率。\n\n> 这篇文章还是值得精读一下的，数据的组织方式和索引方式都比较高级，很有启发。\n\n### 1.2.2 递归总结在大型语言模型中实现长期对话记忆\n\n> 论文原文：Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models\n\n这篇文章提出了一种递归总结的方法，用于增强大模型的长期记忆能力，以解决在长对话中无法回忆过去信息和生成不一致响应的问题。该方法首先刺激LLM记忆小的对话上下文，然后递归地使用先前的记忆和后续的上下文生成新的记忆。\n\n其流程如下：\n\n简单概括，就是：上一轮的内容总结 \\+ 本轮的问题回答 = 本轮的内容总结。本轮的内容总结 \\+ 下轮的问题回答 = 下轮的内容总结。...... 不断迭代。与 LangChain中 `ConversationSummaryMemory`\xa0的实现很类似。\n\n> 这种方法每一轮都要总结一次，也就是调用一次大模型，使用成本很高啊...... 实际生产中应该落地比较难。\n\n分享：\n\n53AI，企业落地大模型首选服务商\n\n**产品**：场景落地咨询+大模型应用平台+行业解决方案\n\n**承诺**：免费POC验证，效果达标后再合作。 **零风险落地应用大模型**，已交付160+中大型企业\n\n[上一篇：RAGFlow：基于OCR和文档解析的下一代 RAG 引擎] [下一篇：RAGFlow（2）：集成深度文档理解能力的RAG引擎] \n\n[返回列表] \n\n相关资讯\n\n[2025-12-01\\\n\\\nMCP与数据库的完美结合] [2025-11-30\\\n\\\nKnowEval：RAG 工程化的最后一公里，让问答质量有据可依] [2025-11-30\\\n\\\n大模型文本分类：从原理到工程落地（含代码）] [2025-11-29\\\n\\\nRAG 只是 AI 的上半场，OmniThink 才是类人的真思考（深度）] [2025-11-28\\\n\\\n详解用Palantir AIP几分钟搭建一个文档智能搜索应用] [2025-11-27\\\n\\\n从检索增强到自主检索：构建可行动的 Agentic RAG 系统] [2025-11-27\\\n\\\nRAG被判死刑：Google用一行API架空工程师！] [2025-11-27\\\n\\\n目前较优的知识库解决方案] \n\n[了解更多] \n\n[了解更多] \n\n160+中大型企业正在使用53AI\n\n[立即咨询] [预约演示] \n\n[把握AI发展的机遇，共同探索、共同进步\\\n\\\n2025-01-22] [如何打造基于GenAI的员工服务机器人\\\n\\\n2025-01-22] \n\n热点资讯\n\n[RAG彻底爆了！一文掌握其效果优化的架构设计及核心要点\\\n\\\n2025-09-15] [万字长文详解腾讯优图RAG技术的架构设计与创新实践\\\n\\\n2025-09-08] [DeepMind爆火论文：向量嵌入模型存在数学上限，Scaling laws放缓实锤？\\\n\\\n2025-09-03] [关于多模态应用的几个疑问，以及多模态应该怎么应用于RAG？\\\n\\\n2025-09-10] [您应该为您的 RAG 系统使用哪种分块技术？\\\n\\\n2025-09-10] [Embedding与Rerank：90%的RAG系统都搞错了！为什么单靠向量检索会毁了你的AI应用？\\\n\\\n2025-10-04] [存算一体破局向量检索瓶颈，IBM放出王炸VSM：性能飙升100倍，能效碾压GPU千倍，RAG要变天？\\\n\\\n2025-09-30] [企业级 RAG 系统实战（2万+文档）：10 个项目踩过的坑（附代码工程示例）\\\n\\\n2025-10-11] [总结了 13 个 顶级 RAG 技术\\\n\\\n2025-10-12] [通过两个案例，看RAG如何解决大模型的“知识短板”\\\n\\\n2025-09-08] \n\n大家都在问\n\n[RAG知识库迎来大洗牌：GraphRAG如何让机器真正读懂世界？\\\n\\\n2025-11-23] [再谈RAG的文档解析——文档解析的难点在哪里？\\\n\\\n2025-11-20] [为什么RDF是AI系统的“天然知识层”？\\\n\\\n2025-11-19] [大模型生态的“不可能三角”：规模化应用的架构困境？\\\n\\\n2025-11-04] [Embedding与Rerank：90%的RAG系统都搞错了！为什么单靠向量检索会毁了你的AI应用？\\\n\\\n2025-10-04] [存算一体破局向量检索瓶颈，IBM放出王炸VSM：性能飙升100倍，能效碾压GPU千倍，RAG要变天？\\\n\\\n2025-09-30] [您应该为您的 RAG 系统使用哪种分块技术？\\\n\\\n2025-09-10] [关于多模态应用的几个疑问，以及多模态应该怎么应用于RAG？\\\n\\\n2025-09-10] \n\n热门标签\n\n[内容创作] [大模型技术] [个人提效] [langchain] [llamaindex] [多模态技术] [RAG技术] [智能客服] [知识图谱] [模型微调] [RAGFlow] [coze] [Dify] [Fastgpt] [Bisheng] [Qanything] [AI+汽车] [AI+金融] [AI+工业] [AI+培训] [AI+SaaS] [提示词框架] [提示词技巧] [AI+电商] [AI面试] [数字员工] [ChatBI] [AI知识库] [开源大模型] [智能营销] [智能硬件] [智能化改造] [AI+医疗] [MaxKB] \n\n[应聘简历请发送至： ceo@53ai.com] \n\n联系我们\n\n售前咨询\n\n[186 6662 7370] \n\n预约演示\n\n[185 8882 0121] \n\n微信扫码\n\n添加专属顾问\n\n回到顶部\n\n加载中...\n\n扫码咨询\n\n[预约演示] [微信咨询] [电话咨询]', 'doi': '', 'published_date': '2024-05-05T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.53ai.com/news/RAG/1732.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的 ...', 'authors': [], 'abstract': '# 《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的智能系统\\[译\\]\n\n2025年11月01日30 分钟阅读 [人工智能] \n\n## 《智能体设计模式》中文翻译计划启动\n\n正如《设计模式》曾是软件工程的圣经，这本由谷歌资深工程主管免费分享的《智能体设计模式》，正为火热的 AI 智能体领域带来首套系统性的设计原则与最佳实践。\n\n本书由 Antonio Gulli 撰写、谷歌 Cloud AI 副总裁 Saurabh Tiwary 作序、高盛 CIO Marco Argenti 鼎力推荐，系统性地提炼出 21 个核心智能体设计模式，涵盖从提示链、工具使用到多智能体协作、自我修正等关键技术。\n\n接下来的一段时间，我将和几位小伙伴一起通过「AI 初次翻译 → AI 交叉评审 → 人工评审 → 人工交叉评审」的方式来翻译这本书，所有翻译内容将会持续更新到开源项目： [github.com/ginobefun/agentic-design-patterns-cn] \n\n已翻译章节：\n\n- [00 -《智能体设计模式》前言部分] \n- [01 -《智能体设计模式》第一章：提示链模式] \n- [02 -《智能体设计模式》第二章：路由模式] \n- [03 -《智能体设计模式》第三章：并行模式] \n- [04 -《智能体设计模式》第四章：反思模式] \n- [05 -《智能体设计模式》第五章：工具使用模式] \n- [06 -《智能体设计模式》第六章：规划模式] \n- [07 -《智能体设计模式》第七章：智能体协作模式] \n- [08 -《智能体设计模式》第八章：记忆管理模式] \n\n## 记忆管理模式精华概览\n\n记忆管理是智能体系统的核心能力，使其能够保留历史信息、从经验中学习并提供连贯一致的交互体验。与人类类似，智能体需要同时具备短期记忆和长期记忆才能高效运作，从而超越简单的一次性问答，展现出真正的智能行为。这里为大家梳理几个关键要点：\n\n### 1\\. 核心理念：双层记忆架构\n\n记忆管理的核心在于建立「短期上下文 \\+ 长期知识」的双层存储架构，让智能体既能处理即时信息，又能积累和调用持久化知识。\n\n- **短期记忆（上下文记忆）**：类似工作记忆，存储当前对话中的即时信息，主要存在于大语言模型的上下文窗口内，包括最近的对话、工具调用结果等。具有临时性，会话结束后即丢失，容量受限于上下文窗口大小。\n- **长期记忆（持久记忆）**：充当长期知识库，存储需要跨会话保留的信息，通常使用外部数据库或向量数据库实现。支持语义搜索，智能体可基于相似性而非精确匹配来检索相关信息。\n\n### 2\\. 关键组件与架构\n\n不同框架提供了结构化的记忆管理组件：\n\n- **Google ADK 三件套**：\n\n - `Session`（会话）：跟踪独立的聊天会话，记录消息和执行动作\n - `State`（状态）：存储会话内的临时数据，支持键前缀管理数据范围（ `user:`、 `app:`、 `temp:`）\n - `MemoryService`（记忆服务）：管理长期知识的存储与检索，提供多种实现方式（内存、数据库、Vertex AI）\n- **LangChain/LangGraph**：\n\n - `ChatMessageHistory`：手动管理对话历史\n - `ConversationBufferMemory`：自动将历史注入提示词\n - `BaseStore`：支持跨会话的长期记忆存储，使用命名空间组织数据\n\n### 3\\. 典型应用场景\n\n记忆管理在五大领域发挥关键作用：\n\n- **聊天机器人与对话式 AI**：维持对话流程，记住用户偏好和历史问题，提供连贯个性化的交互体验。\n- **任务导向型智能体**：跟踪多步骤任务的进度、已完成步骤和总体目标，访问用户特定的非即时数据。\n- **个性化体验服务**：存储和调用用户偏好、历史行为模式，动态调整响应策略和建议内容。\n- **信息检索（RAG）**：访问知识库支撑问答准确性，在 RAG 框架中提供上下文增强。\n- **自主控制系统**：存储地图、导航路线、物体位置等环境知识，结合实时感知和通用知识。\n\n### 4\\. 长期记忆的三种类型\n\n类比人类记忆机制，长期记忆可分为三类：\n\n- **语义记忆（事实记忆）**：存储具体事实和概念知识，如用户偏好或领域知识，可作为用户档案（JSON 文档）或文档集合管理。\n- **情景记忆（经历记忆）**：回忆过往事件或行为序列，通常通过少样本示例提示实现，智能体从历史成功交互中学习。\n- **程序性记忆（规则记忆）**：关于如何执行任务的规则和行为规范，体现在系统提示词中，可通过反思机制自适应优化。\n\n### 5\\. 使用时机与最佳实践\n\n当智能体需要超越单次问答时，应实施记忆管理：\n\n- **适用场景**：需要维持对话上下文；跟踪多步骤任务进度；提供个性化交互；基于历史学习和改进；处理复杂时序依赖问题。\n- **核心价值**：使智能体从无状态的简单响应者进化为具备记忆、学习和个性化能力的智能系统，能够维护历史记录并持续改进。\n\n以下为原书第八章记忆管理设计模式的内容，译者： [@redpomegranate] ，评审： [@Gino] \n\n有效的记忆管理是智能体保留信息的关键。与人类类似，智能体需要多种类型的记忆才能高效运行。本章将深入探讨记忆管理，重点聚焦于智能体的即时（短期）和持久（长期）记忆需求。\n\n在智能体系统中， **记忆** 指智能体从过往交互、观察和学习经验中保留并利用信息的能力。这一能力使智能体能够做出明智决策、维持对话上下文，并持续改进。智能体记忆通常可分为两大主要类型：\n\n- **短期记忆（上下文记忆）**：类似于工作记忆，存储当前正在处理或近期访问的信息。对于基于大语言模型的智能体，短期记忆主要存在于上下文窗口内。该窗口包含最近的对话消息、智能体回复、工具调用结果以及当前交互中的反思内容，这些信息共同为后续的响应和决策提供上下文支撑。上下文窗口的容量有限，限制了智能体可直接访问的近期信息范围。高效的短期记忆管理需要在有限空间内选择性地保留最相关信息，可通过总结旧对话片段或强调关键细节等技术实现。具有「长上下文」窗口的模型虽然扩大了短期记忆容量，允许在单次交互中保存更多信息，但这种上下文仍然是短暂的，会话结束后即丢失，且每次处理成本高昂、效率较低。因此，智能体需要不同类型的记忆来实现真正的持久化，从过往交互中回忆信息并构建持久的知识库。\n\n- **长期记忆（持久记忆）**：充当一个长期知识库，用于存储智能体在各种交互场景、任务执行或长时间跨度内需要保留的信息。数据通常存储在智能体的运行时环境之外，常见于数据库、知识图谱或向量数据库中。在向量数据库中，信息被转换为数值向量并存储，使智能体能够基于语义相似性而非精确关键词匹配来检索数据，这个过程被称为语义搜索。当智能体需要长期记忆中的信息时，会查询外部存储、检索相关数据并将其整合到短期上下文中以便随时使用，从而将先验知识与当前交互信息相结合。\n\n\n## 实际应用场景\n\n记忆管理对于智能体至关重要，使其能够持续跟踪信息并在长时间运行中表现出智能行为。这一能力是智能体超越基础问答、展现高级智能的关键。主要应用场景包括：\n\n- **聊天机器人和对话式 AI：** 维持对话流程依赖于短期记忆。聊天机器人需要记住先前的用户输入才能提供连贯的回答。长期记忆使聊天机器人能够调取用户偏好、过往问题或过往对话记录，从而提供个性化且连续一致的交互体验。\n- **任务导向型智能体：** 处理多步骤任务的智能体需要借助短期记忆来跟踪已完成步骤、当前进度状态及总体目标。这些信息通常存储在任务上下文或临时缓存中。长期记忆对于访问非即时上下文的用户特定数据至关重要。\n- **个性化体验服务：** 提供定制化交互的智能体利用长期记忆系统来存储和调用用户偏好、历史行为模式及个人信息。这种能力使得智能体能够动态调整其响应策略和建议内容。\n- **信息检索（RAG）：** 为问答场景设计的智能体需要访问知识库（即长期记忆），这一功能通常在检索增强生成（RAG）框架中实现。智能体通过检索相关文档和数据资源来支撑其回答的准确性和完整性。\n- **自主控制系统：** 机器人或自动驾驶车辆需要记忆系统来存储地图信息、导航路线、物体位置以及学习获得的行为模式。这包括用于实时环境感知的短期记忆和用于通用环境知识存储的长期记忆。\n\n记忆能力使智能体能够维护历史记录、实现持续学习、提供个性化交互，并有效处理复杂的时序依赖性问题。\n\n## 实战代码：使用 Google ADK\n\nGoogle ADK 提供了一套结构化的上下文与记忆管理方法，包含多个可直接应用于实际场景的组件。深入理解 ADK 中会话（Session）、状态（State）和记忆（Memory）这三个核心概念，对于构建需要信息持久化能力的智能体至关重要。\n\n正如人类交流需要记忆，智能体同样需要具备回忆历史对话的能力，才能进行连贯自然的交流。ADK 通过三个核心概念及其配套服务，简化了上下文管理的复杂性。\n\n每次与智能体的交互都可视为一个独立的对话，而智能体往往需要访问历史交互数据。ADK 通过以下架构组织这些信息：\n\n- **Session（会话）：** 一个独立的聊天会话，记录特定交互过程中的消息和执行动作（事件），同时存储与该对话相关的临时数据（状态）。\n- **State（状态， `session.state`）：** 存储在会话内部的数据，仅包含与当前活跃聊天会话相关的上下文信息。\n- **Memory（记忆）：** 一个可检索的信息知识库，数据来源包括历史聊天记录和外部数据源，为超越当前对话范围的数据检索提供支持。\n\nADK 提供专门的服务组件，它们是构建有状态、上下文感知的智能体的关键要素。 `SessionService` 负责管理聊天会话（ `Session` 对象），处理会话的创建、记录和终止，而 `MemoryService` 负责长期知识（ `Memory`）的存储与检索。\n\n`SessionService` 和 `MemoryService` 均提供多种配置选项，允许开发者根据应用需求选择合适的存储方案。比如内存存储适用于测试环境，数据不会持久化，在重启后会丢失。对于需要持久化存储和可扩展性等需求，ADK 支持使用数据库和云服务。\n\n### Session：跟踪每次聊天\n\nADK 中的 `Session` 对象用于跟踪和管理独立的聊天会话。\n\n当用户与智能体开始对话时， `SessionService` 会生成一个 `Session` 对象（ `google.adk.sessions.Session`）。该对象封装特定对话线程的所有相关数据，包括唯一标识符（ `id`、 `app_name`、 `user_id`）、按时间顺序记录的事件对象、用于会话临时数据（也称为状态）的存储区域，以及指示最后更新时间的时间戳（ `last_update_time`）。\n\n开发者通常通过 `SessionService` 与 `Session` 对象交互。 `SessionService` 负责管理对话会话的生命周期，包括启动新会话、恢复先前会话、记录会话活动（含状态更新）、识别活跃会话以及删除会话数据等。\n\nADK 内置了多种 `SessionService` 实现，具有不同的会话历史和临时数据存储机制。例如 `InMemorySessionService` 适用于测试环境，因为它不会在应用重启后保持数据持久化。\n\n```\n# 示例：使用 InMemorySessionService\n# 注意：数据不会持久化，应用重启后会丢失，仅适用于本地开发和测试环境。\nfrom google.adk.sessions import InMemorySessionService\nsession_service = InMemorySessionService()\n```\n\nThen there\'s DatabaseSessionService if you want reliable saving to a database you manage.\n\n如果你需要将数据保存到自行管理的数据库中，还可以选择 `DatabaseSessionService`。\n\n```\n# 示例：使用 DatabaseSessionService\n# 这适用于需要持久存储的生产环境或开发环境。\n# 你需要配置数据库 URL（例如，用于 SQLite、PostgreSQL 等）。\n# 安装依赖：pip install google-adk[sqlalchemy] 和数据库驱动（例如，PostgreSQL 的 psycopg2）\nfrom google.adk.sessions import DatabaseSessionService\n# 使用本地 SQLite 文件的示例：\ndb_url = "sqlite:///./my_agent_data.db"\nsession_service = DatabaseSessionService(db_url=db_url)\n```\n\nBesides, there\'s VertexAiSessionService which uses Vertex AI infrastructure for scalable production on Google Cloud.\n\n此外，还有 `VertexAiSessionService`，它使用 Google Cloud 上 Vertex AI 的基础设施以满足可扩展的生产部署要求。\n\n```\n# 示例：使用 VertexAiSessionService\n# 这适用于 Google Cloud Platform 上的可扩展要求的生产环境，利用 Vertex AI 基础设施进行会话管理。\n# 安装依赖：pip install google-adk[vertexai] 以及 GCP 设置/身份验证\nfrom google.adk.sessions import VertexAiSessionService\n\nPROJECT_ID = "your-gcp-project-id" # 替换为你的 GCP 项目 ID\nLOCATION = "us-central1" # 替换为你所需的 GCP 位置\n# 与此服务一起使用的 app_name 应对应于 Reasoning Engine ID 或名称\nREASONING_ENGINE_APP_NAME = "projects/your-gcp-project-id/locations/us-central1/reasoningEngines/your-engine-id" # 替换为你的 Reasoning Engine 资源名称\n\nsession_service = VertexAiSessionService(project=PROJECT_ID, location=LOCATION)\n# 使用此服务时，将 REASONING_ENGINE_APP_NAME 传递给以下方法：\n# session_service.create_session(app_name=REASONING_ENGINE_APP_NAME, ...)\n# session_service.get_session(app_name=REASONING_ENGINE_APP_NAME, ...)\n# session_service.append_event(session, event, app_name=REASONING_ENGINE_APP_NAME)\n# session_service.delete_session(app_name=REASONING_ENGINE_APP_NAME, ...)\n```\n\n选择合适的 `SessionService` 至关重要，因为它决定了智能体的交互历史和临时数据如何存储以及持久化方式。\n\n每次消息交换都遵循以下流程：接收消息后， `Runner` 通过 `SessionService` 检索或创建对应的 `Session`，智能体利用 `Session` 的上下文（包括状态和历史交互）来处理消息，接着智能体生成响应并更新状态， `Runner` 将其封装为 `Event` 事件， `session_service.append_event` 方法记录该事件并更新状态。然后 `Session` 继续等待下一条消息。理想情况下，在交互结束时应该使用 `delete_session` 方法终止会话。\n\n以上过程展示了 `SessionService` 如何通过管理 `Session` 特定的历史和临时数据来维持连续性。\n\n### State：会话暂存区\n\n在 ADK 中，每个代表聊天会话的 `Session` 都包含一个状态组件，类似于智能体在该特定对话期间的临时工作记忆。 `session.events` 记录整个聊天历史，而 `session.state` 则存储和更新与当前会话相关的动态信息。\n\n`session.state` 本质上是一个字典（Dictionary），以键值对（Key-Value Pairs）形式存储数据。其主要功能是帮助智能体保留和管理对话连贯性所需的关键信息，例如用户偏好、任务进展、增量数据收集，或影响后续智能体行为的条件标志。\n\n状态结构由字符串键与可序列化 Python 类型值组成，包括字符串、数字、布尔值、列表以及包含这些基本类型的字典。状态是动态的，在整个对话过程中不断演化。这些更改的持久性取决于所使用的 `SessionService`。\n\n可以通过键前缀来管理数据范围和持久性，从而实现有效的状态组织。不带前缀的键属于会话级别的。\n\n- **user:** 该前缀的数据为用户级别，和用户 ID 关联，可以跨多个会话使用。\n- **app:** 该前缀的数据为应用级别，可以在应用内被所有用户共享。\n- **temp:** 该前缀的数据为临时数据，仅在当前处理轮次内有效，不会被持久化。\n\n智能体通过统一的 `session.state` 字典访问所有状态数据。 `SessionService` 负责处理数据的检索、合并和持久化。状态更新应该通过 `session_service.append_event()` 向会话历史添加事件来实现。这样可以确保跟踪的完整性，持久化服务中的正确保存以及安全的状态变更。\n\n**1\\. 简单方法：使用 `output_key`（用于智能体输出的文本）** 如果只需将智能体的最终响应直接保存到状态中，这是最简单的方法。定义 `LlmAgent` 时，只需指定要使用的 `output_key` 属性。 `Runner` 会识别此参数设置，并创建必要的操作来将响应保存到状态中。我们来看一个通过 `output_key` 实现状态更新的代码示例。\n\n```\n# 从 Google ADK 导入必要的类\nfrom google.adk.agents import LlmAgent\nfrom google.adk.sessions import InMemorySessionService, Session\nfrom google.adk.runners import Runner\nfrom google.genai.types import Content, Part\n\n# 定义一个带有 output_key 的 LlmAgent。\ngreeting_agent = LlmAgent(\n name="Greeter",\n model="gemini-2.0-flash",\n instruction="Generate a short, friendly greeting.",\n output_key="last_greeting"\n)\n\n# --- 设置 Runner 和 Session ---\napp_name, user_id, session_id = "state_app", "user1", "session1"\nsession_service = InMemorySessionService()\nrunner = Runner(\n agent=greeting_agent,\n app_name=app_name,\n session_service=session_service\n)\n\nsession = session_service.create_session(\n app_name=app_name,\n user_id=user_id,\n session_id=session_id\n)\n\nprint(f"Initial state: {session.state}")\n\n# --- 运行智能体 ---\nuser_message = Content(parts=[Part(text="Hello")])\nprint("\\n--- Running the agent ---")\nfor event in runner.run(\n user_id=user_id,\n session_id=session_id,\n new_message=user_message\n):\n if event.is_final_response():\n print("Agent responded.")\n\n# --- 检查更新后的状态 ---\n# 在 runner 完成处理所有事件后正确检查状态。\nupdated_session = session_service.get_session(app_name, user_id, session_id)\nprint(f"\\nState after agent run: {updated_session.state}")\n```\n\n在幕后， `Runner` 会识别 `output_key`，并在调用 `append_event` 时自动创建带有 `state_delta` 的必要操作。\n\n**2\\. 标准方法：使用 EventActions.state\\_delta（用于更复杂的场景）** 当需要进行更复杂的操作时，例如同时更新多个键、保存非纯文本内容、针对特定作用域（如 `user:` 或 `app:`），或者执行与智能体最终文本回复无关的更新时，需要手动构建状态变更的字典（即 `state_delta`），并将其放在要附加的 `Event` 的 `EventActions` 中。让我们来看一个示例：\n\n```\nimport time\nfrom google.adk.tools.tool_context import ToolContext\nfrom google.adk.sessions import InMemorySessionService\n\n# --- 定义推荐的基于工具的方法 ---\ndef log_user_login(tool_context: ToolContext) -> dict:\n """\n 在用户登录事件时更新会话状态。\n 此工具封装了与用户登录相关的所有状态更改。\n 参数：\n tool_context：由 ADK 自动提供，提供对会话状态的访问。\n 返回：\n 确认操作成功的字典。\n """\n # 通过提供的上下文直接访问状态。\n state = tool_context.state\n\n # 获取当前值或默认值，', 'doi': '', 'published_date': '2025-11-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://ginonotes.com/posts/agentic-design-patterns-memory-management-translation', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '概述 - LangChain 框架', 'authors': [], 'abstract': '概述 - LangChain 框架[跳到内容] \n**我们正在发展壮大，为LangChain、LangGraph和LangSmith招聘多个职位。[加入我们的团队！] **\n[] # 内存[¶] \n## 什么是内存？[¶] \n[内存] 是一种认知功能，它使人们能够存储、检索和使用信息来理解他们的现在和未来。想想看，与一个总是忘记你告诉他们的事情、需要不断重复的同事共事是多么令人沮丧！随着AI代理承担涉及大量用户交互的更复杂任务，为它们配备内存对于效率和用户满意度同样至关重要。通过内存，代理可以从反馈中学习并适应用户的偏好。本指南涵盖了基于召回范围的两种内存类型\n**短期记忆**，或[线程] 范围的记忆，可以随时**从**单个用户对话线程中召回。LangGraph将短期记忆作为代理[状态] 的一部分进行管理。状态通过[检查点] 持久化到数据库中，以便线程可以随时恢复。短期记忆在图被调用或步骤完成时更新，并在每个步骤开始时读取状态。\n**长期记忆**在对话线程**之间共享**。它可以在*任何时候*和**任何线程中**召回。记忆可以限定在任何自定义命名空间，而不仅仅是单个线程ID。LangGraph提供[存储] （[参考文档] ）来让你保存和召回长期记忆。\n这两种记忆对于你的应用程序都非常重要，需要理解并实现。![] \n## 短期记忆[¶] \n短期记忆允许你的应用程序记住单个[线程] 或对话中的先前交互。[线程] 在一个会话中组织多个交互，类似于电子邮件将消息分组到单个对话中的方式。\nLangGraph将短期记忆作为代理状态的一部分进行管理，通过线程范围的检查点持久化。这种状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索到的文档或生成的工件。通过将这些存储在图的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。\n由于对话历史是表示短期记忆最常见的形式，在下一节中，我们将介绍在消息列表变得**很长**时管理对话历史的技术。如果你想坚持高层概念，请继续阅读[长期记忆] 部分。\n### 管理长对话历史记录[¶] \n长对话对当今的LLM构成了挑战。完整的历史记录甚至可能无法完全放入LLM的上下文窗口中，导致不可恢复的错误。即使你的LLM技术上支持完整的上下文长度，大多数LLM在长上下文下表现仍然不佳。它们会被过时或偏离主题的内容“分散注意力”，同时响应时间变慢，成本也更高。\n管理短期记忆是平衡[精确度与召回率] 与应用程序其他性能要求（延迟和成本）之间的练习。一如既往，批判性地思考如何为你的LLM表示信息并查看你的数据非常重要。我们将在下面介绍一些管理消息列表的常用技术，并希望为你提供足够的上下文，以便你为应用程序选择最佳的权衡方案\n* [编辑消息列表] ：如何考虑在传递给语言模型之前修剪和过滤消息列表。\n* [总结过往对话] ：当你不仅仅想过滤消息列表时，一种常用的技术。### 编辑消息列表[¶] \n聊天模型使用[消息] 接受上下文，其中包括开发者提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随时间增长。由于上下文窗口有限，并且包含大量token的消息列表可能成本高昂，许多应用程序可以通过使用手动删除或忘记过时信息的技术而受益。\n![] \n最直接的方法是从列表中删除旧消息（类似于[最近最少使用缓存] ）。\n在LangGraph中，从列表中删除内容的典型技术是从节点返回一个更新，告诉系统删除列表的某些部分。你可以定义这种更新的样式，但一种常见的方法是让你返回一个对象或字典，指定要保留哪些值。\n```\n`[] defmanage\\_list(existing:list,updates:Union[list,dict]):[] ifisinstance(updates,list):[] # Normal case, add to the history[] returnexisting+updates[] elifisinstance(updates,dict)andupdates["type"]=="keep":[] # You get to decide what this looks like.[] # For example, you could simplify and just accept a string "DELETE"[] # and clear the entire list.[] returnexisting[updates["from"]:updates["to"]][] # etc. We define how to interpret updates[] [] classState(TypedDict):[] my\\_list:Annotated[list,manage\\_list][] [] defmy\\_node(state:State):[] return{[] # We return an update for the field "my\\_list" saying to[] # keep only values from index -5 to the end (deleting the rest)[] "my\\_list":{"type":"keep","from":-5,"to":None}[]}`\n```\n只要在"my\\_list"键下返回更新，LangGraph就会调用`manage\\_list`"[reducer] "函数。在该函数中，我们定义接受哪些类型的更新。通常，消息会被添加到现有列表中（对话会增长）；但是，我们也添加了对接受字典的支持，该字典允许你"保留"状态的某些部分。这允许你通过编程方式删除旧的消息上下文。\n另一种常见的方法是让你返回一个“移除”对象的列表，该列表指定要删除的所有消息的ID。如果你在LangGraph中使用LangChain消息和[`add\\_messages`] reducer（或`MessagesState`，它使用相同的基础功能），你可以使用`RemoveMessage`来完成此操作。\n*API参考：[RemoveMessage] |[AIMessage] |[add\\_messages] *\n```\n`[] fromlangchain\\_core.messagesimportRemoveMessage,AIMessage[] fromlanggraph.graphimportadd\\_messages[] # ... other imports[] [] classState(TypedDict):[] # add\\_messages will default to upserting messages by ID to the existing list[] # if a RemoveMessage is returned, it will delete the message in the list by ID[] messages:Annotated[list,add\\_messages][] [] defmy\\_node\\_1(state:State):[] # Add an AI message to the `messages` list in the state[] return{"messages":[AIMessage(content="Hi")]}[] [] defmy\\_node\\_2(state:State):[] # Delete all but the last 2 messages from the `messages` list in the state[] delete\\_messages=[RemoveMessage(id=m.id)forminstate[\'messages\'][:-2]][] return{"messages":delete\\_messages}`\n```\n在上面的示例中，`add\\_messages`reducer允许我们将新消息[追加] 到`messages`状态键，如`my\\_node\\_1`中所示。当它看到一个`RemoveMessage`时，它将从列表中删除该ID的消息（然后`RemoveMessage`将被丢弃）。有关LangChain特定消息处理的更多信息，请查看[此关于使用`RemoveMessage`的操作指南] 。\n有关示例用法，请参阅此操作[指南] 以及我们[LangChain Academy] 课程的模块2。\n### 总结过往对话[¶] \n如上所示，修剪或移除消息的问题在于，我们可能会因为消息队列的淘汰而丢失信息。因此，一些应用程序受益于使用聊天模型总结消息历史的更复杂方法。![] \n可以使用简单的提示和编排逻辑来实现此目的。例如，在LangGraph中，我们可以扩展[MessagesState] 以包含一个`summary`键。\n```\n`[] fromlanggraph.graphimportMessagesState[] classState(MessagesState):[] summary:str`\n```\n然后，我们可以生成聊天历史的摘要，使用任何现有摘要作为下一个摘要的上下文。这个`summarize\\_conversation`节点可以在`messages`状态键中积累一定数量的消息后被调用。\n```\n`[] defsummarize\\_conversation(state:State):[] [] # First, we get any existing summary[] summary=state.get("summary","")[] [] # Create our summarization prompt[] ifsummary:[] [] # A summary already exists[] summary\\_message=([] f"This is a summary of the conversation to date:{summary}\\\\n\\\\n"[] "Extend the summary by taking into account the new messages above:"[])[] [] else:[] summary\\_message="Create a summary of the conversation above:"[] [] # Add prompt to our history[] messages=state["messages"]+[HumanMessage(content=summary\\_message)][] response=model.invoke(messages)[] [] # Delete all but the 2 most recent messages[] delete\\_messages=[RemoveMessage(id=m.id)forminstate["messages"][:-2]][] return{"summary":response.content,"messages":delete\\_messages}`\n```\n有关示例用法，请参阅[此处] 的此操作指南，以及我们[LangChain Academy] 课程的模块2。\n### 知道**何时**移除消息[¶] \n大多数LLM都有一个最大支持的上下文窗口（以token计）。一个决定何时截断消息的简单方法是计算消息历史中的token数量，并在接近该限制时进行截断。简单的截断很容易自行实现，尽管有一些“陷阱”。一些模型API进一步限制了消息类型的顺序（必须以人类消息开始，不能有连续的相同类型的消息等）。如果你正在使用LangChain，你可以使用[`trim\\_messages`] 实用程序，并指定要从列表中保留的token数量，以及用于处理边界的`strategy`（例如，保留最后`max\\_tokens`）。\n下面是一个例子。*API参考：[trim\\_messages] *\n```\n`[] fromlangchain\\_core.messagesimporttrim\\_messages[] trim\\_messages([] messages,[] # Keep the last &lt;&lt;= n\\_count tokens of the messages.[] strategy="last",[] # Remember to adjust based on your model[] # or else pass a custom token\\_encoder[] token\\_counter=ChatOpenAI(model="gpt-4"),[] # Remember to adjust based on the desired conversation[] # length[] max\\_tokens=45,[] # Most chat models expect that chat history starts with either:[] # (1) a HumanMessage or[] # (2) a SystemMessage followed by a HumanMessage[] start\\_on="human",[] # Most chat models expect that chat history ends with either:[] # (1) a HumanMessage or[] # (2) a ToolMessage[] end\\_on=("human","tool"),[] # Usually, we want to keep the SystemMessage[] # if it\'s present in the original history.[] # The SystemMessage has special instructions for the model.[] include\\_system=True,[])`\n```\n## 长期记忆[¶] \nLangGraph中的长期记忆允许系统在不同的对话或会话中保留信息。与**线程范围**的短期记忆不同，长期记忆保存在自定义的“命名空间”中。\n### 存储记忆[¶] \nLangGraph将长期记忆作为JSON文档存储在[存储] 中（[参考文档] ）。每个记忆都组织在一个自定义的`namespace`（类似于文件夹）和一个独特的`key`（像文件名）之下。命名空间通常包括用户或组织ID或其他标签，以便于组织信息。这种结构实现了记忆的层次化组织。通过内容过滤器支持跨命名空间搜索。请参阅下面的示例。\n```\n`[] fromlanggraph.store.memoryimportInMemoryStore[] [] [] defembed(texts:list[str])-&gt;list[list[float]]:[] # Replace with an actual embedding function or LangChain embeddings object[] return[[1.0,2.0]\\*len(texts)][] [] [] # InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.[] store=InMemoryStore(index={"embed":embed,"dims":2})[] user\\_id="my-user"[] application\\_context="chitchat"[] namespace=(user\\_id,application\\_context)[] store.put([] namespace,[] "a-memory",[] {[] "rules":[[] "User likes short, direct language",[] "User only speaks English &amp; python",[]],[] "my-key":"my-value",[]},[])[] # get the "memory" by ID[] item=store.get(namespace,"a-memory")[] # search for "memories" within this namespace, filtering on content equivalence, sorted by vector similarity[] items=store.search([] namespace,filter={"my-key":"my-value"},query="language preferences"[])`\n```\n### 长期记忆的思考框架[¶] \n长期记忆是一个复杂的挑战，没有一劳永逸的解决方案。然而，以下问题提供了一个结构化框架，帮助你探索不同的技术**记忆的类型是什么？**\n人类利用记忆来记住[事实] 、[经验] 和[规则] 。AI代理也可以以相同的方式使用记忆。例如，AI代理可以使用记忆来记住关于用户的具体事实以完成任务。我们将在[下面的部分] 中详细介绍几种记忆类型。\n**你希望何时更新记忆？**\n记忆可以作为代理应用程序逻辑的一部分进行更新（例如，“在热路径上”）。在这种情况下，代理通常在响应用户之前决定记住事实。或者，记忆可以作为后台任务进行更新（在后台/异步运行并生成记忆的逻辑）。我们将在[下面的部分] 中解释这些方法之间的权衡。\n## 记忆类型[¶] \n不同的应用程序需要各种类型的记忆。尽管类比并不完美，但研究[人类记忆类型] 可以提供深刻的见解。一些研究（例如，[CoALA论文] ）甚至将这些人类记忆类型映射到了AI代理中使用的类型。\n|记忆类型|存储内容|人类示例|代理示例|\n语义|事实|我在学校学到的东西|关于用户的事实|\n情景|经验|我做过的事情|代理过去的行动|\n程序|指令|本能或运动技能|代理系统提示|\n### 语义记忆[¶] \n[语义记忆] ，无论是对人类还是AI代理，都涉及特定事实和概念的保留。在人类中，它可能包括在学校学到的信息以及对概念及其关系的理解。对于AI代理，语义记忆通常用于通过记住过去交互中的事实或概念来个性化应用程序。\n> > 注意：不要与“语义搜索”混淆，后者是使用“意义”（通常作为嵌入）查找相似内容的技术。语义记忆是心理学中的一个术语，指的是存储事实和知识，而语义搜索是根据意义而非精确匹配检索信息的方法。> #### 个人资料[¶] \n语义记忆可以通过不同方式进行管理。例如，记忆可以是一个单一的、持续更新的“配置文件”，其中包含关于用户、组织或其他实体（包括代理本身）的范围明确且具体的信息。配置文件通常只是一个JSON文档，包含你为表示你的领域而选择的各种键值对。\n在记忆配置文件时，你会希望确保每次都**更新**配置文件。因此，你会希望传入先前的配置文件并[要求模型生成新的配置文件] （或应用于旧配置文件的某些[JSON补丁] ）。随着配置文件变大，这可能会变得容易出错，并且可能受益于将配置文件拆分为多个文档或生成文档时进行**严格**解码，以确保记忆模式保持有效。\n![] \n#### 集合[¶] \n或者，记忆可以是一个文档集合，随着时间的推移不断更新和扩展。每个单独的记忆可以更狭窄地限定范围，更容易生成，这意味着你随着时间的推移**丢失**信息的可能性更小。LLM更容易为新信息生成*新*对象，而不是将新信息与现有配置文件进行协调。因此，文档集合往往会带来[更高的下游召回率] 。\n然而，这会增加内存更新的复杂性。模型现在必须*删除*或*更新*列表中的现有项目，', 'doi': '', 'published_date': '2026-02-02T17:06:15.982784', 'pdf_url': '', 'url': 'https://langgraph.com.cn/concepts/memory.1.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '核心概念 - LangChain 框架', 'authors': [], 'abstract': '核心概念 - LangChain 教程[跳到内容] \n[] # LLM 应用中的长期记忆[¶] \n长期记忆允许智能体在多次对话中记住重要信息。LangMem 提供了从聊天中提取有意义的细节、存储它们并用于改善未来互动的方法。其核心在于，LangMem 中的每个记忆操作都遵循相同的模式：1. 接收对话和当前记忆状态2. 提示LLM 以决定如何扩展或整合记忆状态3. 返回更新后的记忆状态最好的记忆系统通常是针对特定应用的。在设计您的系统时，以下问题可以作为有用的指南：1. **什么内容**：您的智能体应该学习哪种[类型的内容] ：事实/知识？过去事件的摘要？规则和风格？\n2. **何时**（以及**由谁**）应该[形成记忆] ？\n3. 记忆应该[存储在**何处**] ？（在提示中？语义存储中？）。这在很大程度上决定了它们将如何被回忆。## 记忆类型[¶] \nLLM 应用中的记忆可以反映人类记忆的某些结构，每种类型在构建自适应、具备上下文感知能力的系统中都扮演着独特的角色。|记忆类型|用途|智能体示例|人类示例|典型存储模式|\n语义记忆|事实与知识|用户偏好；知识三元组|知道 Python 是一门编程语言|资料卡或集合|\n情景记忆|过往经历|少样本示例；过去对话的摘要|记得第一天上班的情景|集合|\n程序性记忆|系统行为|核心个性和响应模式|知道如何骑自行车|提示规则或集合|\n### 语义记忆：事实与知识[¶] \n[语义记忆] 存储了支撑智能体响应的基本事实和其他信息。语义记忆的两种常见表示形式是集合（用于记录可在运行时搜索的无限量知识）和资料卡（用于记录遵循严格模式且易于按用户或智能体查找的任务特定信息）。\n#### 集合[¶] \n集合是大多数人想象智能体长期记忆时的第一印象。在这种类型中，记忆以单个文档或记录的形式存储。对于每个新对话，记忆系统可以决定向存储中插入新的记忆。使用集合类型的记忆会给更新记忆状态的过程增加一些复杂性。系统必须将新信息与先前的信念进行协调，通过\\*删除\\*/\\*作废\\*或\\*更新\\*/\\*整合\\*现有记忆。如果系统过度提取，当您的智能体需要搜索存储时，可能会导致记忆的精确度降低。如果提取不足，则可能导致召回率低。LangMem 使用一种记忆丰富化过程，力求在记忆创建和整合之间取得平衡，同时允许您（开发者）自定义指令以进一步调整两者的强度。最后，记忆的相关性不仅仅是语义相似性。回忆应该将相似性与记忆的“重要性”以及记忆的“强度”结合起来，后者是记忆最近/频繁被使用情况的函数。\n![Collection update process] \n提取语义记忆为集合设置*API：[create\\_memory\\_manager] *\n```\n`[] fromlangmemimportcreate\\_memory\\_manager[] [] manager=create\\_memory\\_manager([] "anthropic:claude-3-5-sonnet-latest",[] instructions="Extract all noteworthy facts, events, and relationships. Indicate their importance.",[] enable\\_inserts=True,[])[] [] # Process a conversation to extract semantic memories[] conversation=[[] {"role":"user","content":"I work at Acme Corp in the ML team"},[] {"role":"assistant","content":"I\'ll remember that. What kind of ML work do you do?"},[] {"role":"user","content":"Mostly NLP and large language models"}[]]`\n```\n```\n`[] memories=manager.invoke({"messages":conversation})[] # Example memories:[] # [[] # ExtractedMemory([] # id="27e96a9d-8e53-4031-865e-5ec50c1f7ad5",[] # content=Memory([] # content="[IMPORTANT] User prefers to be called Lex (short for Alex) and appreciates"[] # " casual, witty communication style with relevant emojis."[] # ),[] # ),[] # ExtractedMemory([] # id="e2f6b646-cdf1-4be1-bb40-0fd91d25d00f",[] # content=Memory([] # content="[BACKGROUND] Lex is proficient in Python programming and specializes in developing"[] # " AI systems with a focus on making them sound more natural and less corporate."[] # ),[] # ),[] # ExtractedMemory([] # id="c1e03ebb-a393-4e8d-8eb7-b928d8bed510",[] # content=Memory([] # content="[HOBBY] Lex is a competitive speedcuber (someone who solves Rubik\'s cubes competitively),"[] # " showing an interest in both technical and recreational puzzle-solving."[] # ),[] # ),[] # ExtractedMemory([] # id="ee7fc6e4-0118-425f-8704-6b3145881ff7",[] # content=Memory([] # content="[PERSONALITY] Based on communication style and interests, Lex appears to value authenticity,"[] # " creativity, and technical excellence while maintaining a fun, approachable demeanor."[] # ),[] # ),[] # ]`\n```\n#### 资料卡[¶] \n另一方面，**资料卡**则适用于特定任务。资料卡是一个表示当前状态的单一文档，例如用户使用应用的主要目标、他们偏好的称呼和响应风格等。当新信息到达时，它会更新现有文档而不是创建新文档。当您只关心最新状态并希望避免记住无关信息时，这种方法是理想的。\n![Profile update process] \n使用资料卡管理用户偏好设置*API：[create\\_memory\\_manager] *\n```\n`[] fromlangmemimportcreate\\_memory\\_manager[] frompydanticimportBaseModel[] [] [] classUserProfile(BaseModel):[] """Save the user\'s preferences."""[] name:str[] preferred\\_name:str[] response\\_style\\_preference:str[] special\\_skills:list[str][] other\\_preferences:list[str][] [] [] manager=create\\_memory\\_manager([] "anthropic:claude-3-5-sonnet-latest",[] schemas=[UserProfile],[] instructions="Extract user preferences and settings",[] enable\\_inserts=False,[])[] [] # Extract user preferences from a conversation[] conversation=[[] {"role":"user","content":"Hi! I\'m Alex but please call me Lex. I\'m a wizard at Python and love making AI systems that don\'t sound like boring corporate robots 🤖"},[] {"role":"assistant","content":"Nice to meet you, Lex! Love the anti-corporate-robot stance. How would you like me to communicate with you?"},[] {"role":"user","content":"Keep it casual and witty - and maybe throw in some relevant emojis when it feels right ✨Also, besides AI, I do competitive speedcubing!"},[]]`\n```\n```\n`[] profile=manager.invoke({"messages":conversation})[0][] print(profile)[] # Example profile:[] # ExtractedMemory([] # id="6f555d97-387e-4af6-a23f-a66b4e809b0e",[] # content=UserProfile([] # name="Alex",[] # preferred\\_name="Lex",[] # response\\_style\\_preference="casual and witty with appropriate emojis",[] # special\\_skills=[[] # "Python programming",[] # "AI development",[] # "competitive speedcubing",[] # ],[] # other\\_preferences=[[] # "prefers informal communication",[] # "dislikes corporate-style interactions",[] # ],[] # ),[] # )`\n```\n根据您将如何使用数据来选择使用资料卡还是集合：当您需要快速访问当前状态以及对可存储信息类型有数据要求时，资料卡表现出色。它们也易于呈现给用户进行手动编辑。当您希望在多次互动中跟踪知识而无信息损失，并且希望根据上下文而不是每次都回忆特定信息时，集合非常有用。### 情景记忆：过往经历[¶] \n情景记忆将成功的互动保存为学习示例，以指导未来的行为。与存储事实的语义记忆不同，情景记忆捕捉了互动的完整上下文——情境、导致成功的思考过程以及该方法为何有效。这些记忆帮助智能体从经验中学习，根据以往的成功经验调整其响应。定义和提取情景设置*API：[create\\_memory\\_manager] *\n```\n`[] frompydanticimportBaseModel,Field[] fromlangmemimportcreate\\_memory\\_manager[] [] classEpisode(BaseModel):[] """An episode captures how to handle a specific situation, including the reasoning process[] and what made it successful."""[] [] observation:str=Field([]...,[] description="The situation and relevant context"[])[] thoughts:str=Field([]...,[] description="Key considerations and reasoning process"[])[] action:str=Field([]...,[] description="What was done in response"[])[] result:str=Field([]...,[] description="What happened and why it worked"[])[] [] manager=create\\_memory\\_manager([] "anthropic:claude-3-5-sonnet-latest",[] schemas=[Episode],[] instructions="Extract examples of successful interactions. Include the context, thought process, and why the approach worked.",[] enable\\_inserts=True,[])[] [] # Example conversation[] conversation=[[] {"role":"user","content":"What\'s a binary tree? I work with family trees if that helps"},[] {"role":"assistant","content":"A binary tree is like a family tree, but each parent has at most 2 children. Here\'s a simple example:\\\\nBob\\\\n/\\\\\\\\\\\\nAmy Carl\\\\n\\\\nJust like in family trees, we call Bob the \'parent\' and Amy and Carl the \'children\'."},[] {"role":"user","content":"Oh that makes sense! So in a binary search tree, would it be like organizing a family by age?"},[]]`\n```\n```\n`[] # Extract episode(s)[] episodes=manager.invoke({"messages":conversation})[] # Example episode:[] # [[] # ExtractedMemory([] # id="f9194af3-a63f-4d8a-98e9-16c66e649844",[] # content=Episode([] # observation="User struggled debugging a recursive "[] # "function for longest path in binary "[] # "tree, unclear on logic.",[] # thoughts="Used explorer in treehouse village "[] # "metaphor to explain recursion:\\\\n"[] # "- Houses = Nodes\\\\n"[] # "- Bridges = Edges\\\\n"[] # "- Explorer\'s path = Traversal",[] # action="Reframed problem using metaphor, "[] # "outlined steps:\\\\n"[] # "1. Check left path\\\\n"[] # "2. Check right path\\\\n"[] # "3. Add 1 for current position\\\\n"[] # "Highlighted common bugs",[] # result="Metaphor helped user understand logic. "[] # "Worked because it:\\\\n"[] # "1. Made concepts tangible\\\\n"[] # "2. Created mental model\\\\n"[] # "3. Showed key steps\\\\n"[] # "4. Pointed to likely bugs",[] # ),[] # )[] # ]`\n```\n### 程序性记忆：系统指令[¶] \n程序性记忆编码了智能体应如何行为和响应。它始于定义核心行为的系统提示，然后通过反馈和经验不断演进。随着智能体与用户的互动，它会完善这些指令，学习哪些方法在不同情况下最有效。![Instructions update process] \n根据反馈优化提示设置*API：[create\\_prompt\\_optimizer] *\n```\n`[] fromlangmemimportcreate\\_prompt\\_optimizer[] [] optimizer=create\\_prompt\\_optimizer([] "anthropic:claude-3-5-sonnet-latest",[] kind="metaprompt",[] config={"max\\_reflection\\_steps":3}[])`\n```\n```\n`[] prompt="You are a helpful assistant."[] trajectory=[[] {"role":"user","content":"Explain inheritance in Python"},[] {"role":"assistant","content":"Here\'s a detailed theoretical explanation..."},[] {"role":"user","content":"Show me a practical example instead"},[]][] optimized=optimizer.invoke({[] "trajectories":[(trajectory,{"user\\_score":0})],[] "prompt":prompt[]})[] print(optimized)[] # You are a helpful assistant with expertise in explaining technical concepts clearly and practically. When explaining programming', 'doi': '', 'published_date': '2016-06-09T00:00:00+00:00', 'pdf_url': '', 'url': 'https://github.langchain.ac.cn/langmem/concepts/conceptual_guide', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 17:06:59,130 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 17:06:59,133 - __main__ - WARNING - handle_download: downloaded=0
2026-02-02 17:06:59,133 - __main__ - INFO - call_tool: name=exa_context_download, result_type=papers, count=0
2026-02-02 17:12:55,520 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 17:12:55,521 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 17:12:55,528 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 17:12:55,529 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=zh, search_type=None
2026-02-02 17:12:55,537 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 17:12:55,537 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, limit=10, language=None, search_type=None
2026-02-02 17:12:59,062 - __main__ - INFO - handle_search: returned=10
2026-02-02 17:12:59,062 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 17:12:59,062 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 17:13:00,808 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 17:13:00,808 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 17:13:06,141 - __main__ - INFO - handle_search: returned=1
2026-02-02 17:13:06,141 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=1
2026-02-02 17:13:06,141 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.81418616, 'save_path': None}}
2026-02-02 17:13:51,513 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.81418616, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 17:13:51,514 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=1, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 17:13:51,515 - __main__ - INFO - handle_download: downloaded=1
2026-02-02 17:13:51,515 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=1
2026-02-02 17:13:51,515 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.81418616, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ....md'}}
2026-02-02 17:13:51,528 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '记忆- LangChain 教程', 'authors': [], 'abstract': '记忆 - LangChain 教程[跳到内容] \n**我们的[使用LangGraph构建环境智能体] 课程现已在LangChain Academy上线！**\n# 内存[¶] \n## 什么是记忆？[¶] \nAI 应用中的记忆指处理、存储和有效回忆过往交互信息的能力。有了记忆，您的智能体可以从反馈中学习并适应用户的偏好。本指南根据记忆召回的范围分为两个部分：短期记忆和长期记忆。**短期记忆**，或[线程] 范围的记忆，可以随时在与用户的单个对话线程**内**被召回。LangGraph 将短期记忆作为智能体[状态] 的一部分进行管理。状态使用[检查点] 持久化到数据库中，以便线程可以随时恢复。当图被调用或步骤完成时，短期记忆会更新，并且在每个步骤开始时读取状态。\n**长期记忆**在对话线程**之间**共享。它可以\\*随时\\*且在**任何线程**中被召回。记忆可以限定在任何自定义命名空间内，而不仅仅是单个线程ID。LangGraph 提供[存储] （[参考文档] ）来让您保存和召回长期记忆。\n理解并在您的应用程序中实现这两种记忆都非常重要。![] \n## 短期记忆[¶] \n短期记忆让您的应用程序能够记住单个[线程] 或对话中的先前交互。[线程] 在一个会话中组织多个交互，类似于电子邮件将消息分组到单个对话中的方式。\nLangGraph 将短期记忆作为智能体状态的一部分进行管理，通过线程范围的检查点进行持久化。此状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索到的文档或生成的工件。通过将这些存储在图的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。由于对话历史是表示短期记忆最常见的形式，因此在下一节中，我们将介绍当消息列表变得**冗长**时管理对话历史的技术。如果您想坚持高层概念，请继续阅读[长期记忆] 部分。\n### 管理长对话历史[¶] \n长对话对当今的LLM 构成了挑战。完整的历史记录甚至可能无法完全适应LLM 的上下文窗口，从而导致不可恢复的错误。即使您的LLM 在技术上支持完整的上下文长度，大多数LLM 在长上下文中表现仍然不佳。它们会被陈旧或偏离主题的内容“分散注意力”，同时响应时间更慢且成本更高。管理短期记忆是平衡[准确率和召回率] 与您应用程序的其他性能要求（延迟和成本）的实践。一如既往，批判性地思考如何为您的 LLM 表示信息并查看您的数据非常重要。我们在下面介绍了几种管理消息列表的常见技术，并希望为您提供足够的上下文，以便您为应用程序选择最佳权衡方案。* [编辑消息列表] ：如何考虑在将消息列表传递给语言模型之前对其进行修剪和过滤。\n* [总结过往对话] ：当您不仅仅想过滤消息列表时，一种常用的技术。### 编辑消息列表[¶] \n聊天模型使用[消息] 接受上下文，其中包括开发者提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随时间增长。由于上下文窗口有限且富含 token 的消息列表可能成本高昂，许多应用程序可以受益于使用手动删除或遗忘陈旧信息的技术。![] \n最直接的方法是从列表中删除旧消息（类似于[最近最少使用缓存] ）。\n在LangGraph 中从列表中删除内容的典型技术是，从节点返回一个更新，告诉系统删除列表的某个部分。您可以定义此更新的外观，但一种常见的方法是让您返回一个对象或字典，指定要保留哪些值。```\n`[] import{Annotation}from"@langchain/langgraph";[] [] constStateAnnotation=Annotation.Root({[] myList:Annotation&lt;any[]&gt;({[] reducer:([] existing:string[],[] updates:string[]|{type:string;from:number;to?:number}[])=&gt;{[] if(Array.isArray(updates)){[] // Normal case, add to the history[] return[...existing,...updates];[]}elseif(typeofupdates==="object"&amp;&amp;updates.type==="keep"){[] // You get to decide what this looks like.[] // For example, you could simplify and just accept a string "DELETE"[] // and clear the entire list.[] returnexisting.slice(updates.from,updates.to);[]}[] // etc. We define how to interpret updates[] returnexisting;[]},[] default:()=&gt;[],[]}),[]});[] [] typeState=typeofStateAnnotation.State;[] [] functionmyNode(state:State){[] return{[] // We return an update for the field "myList" saying to[] // keep only values from index -5 to the end (deleting the rest)[] myList:{type:"keep",from:-5,to:undefined},[]};[]}`\n```\n当在键“myList”下返回更新时，LangGraph 将调用“[reducer] ”函数。在该函数中，我们定义要接受的更新类型。通常，消息会添加到现有列表中（对话将增长）；但是，我们也添加了支持接受一个字典，让您可以“保留”状态的某些部分。这允许您以编程方式丢弃旧消息上下文。\n另一种常见的方法是让您返回一个“删除”对象列表，指定要删除的所有消息的ID。如果您在 LangGraph 中使用LangChain 消息和[`messagesStateReducer`] reducer（或使用相同底层功能的[`MessagesAnnotation`] ），则可以使用`RemoveMessage`来完成此操作。\n```\n`[] import{RemoveMessage,AIMessage}from"@langchain/core/messages";[] import{MessagesAnnotation}from"@langchain/langgraph";[] [] typeState=typeofMessagesAnnotation.State;[] [] functionmyNode1(state:State){[] // Add an AI message to the `messages` list in the state[] return{messages:[newAIMessage({content:"Hi"})]};[]}[] [] functionmyNode2(state:State){[] // Delete all but the last 2 messages from the `messages` list in the state[] constdeleteMessages=state.messages[].slice(0,-2)[].map((m)=&gt;newRemoveMessage({id:m.id}));[] return{messages:deleteMessages};[]}`\n```\n在上面的示例中，`MessagesAnnotation`允许我们将新消息附加到`messages`状态键，如`myNode1`所示。当它看到`RemoveMessage`时，它将从列表中删除具有该ID的消息（然后该RemoveMessage将被丢弃）。有关LangChain特定消息处理的更多信息，请查看[此关于使用`RemoveMessage`的操作指南] 。\n有关示例用法，请参阅此操作[指南] 。\n### 总结过往对话[¶] \n如上所示，修剪或删除消息的问题在于，我们可能会因为筛选消息队列而丢失信息。因此，一些应用程序受益于使用聊天模型总结消息历史的更复杂方法。![] \n可以使用简单的提示和编排逻辑来实现这一点。例如，在LangGraph 中，我们可以扩展[`MessagesAnnotation`] 以包含`summary`键。\n```\n`[] import{MessagesAnnotation,Annotation}from"@langchain/langgraph";[] [] constMyGraphAnnotation=Annotation.Root({[]...MessagesAnnotation.spec,[] summary:Annotation&lt;string&gt;,[]});`\n```\n然后，我们可以生成聊天历史的摘要，使用任何现有摘要作为下一个摘要的上下文。此`summarizeConversation`节点可以在`messages`状态键中积累一定数量的消息后调用。\n```\n`[] import{ChatOpenAI}from"@langchain/openai";[] import{HumanMessage,RemoveMessage}from"@langchain/core/messages";[] [] typeState=typeofMyGraphAnnotation.State;[] [] asyncfunctionsummarizeConversation(state:State){[] // First, we get any existing summary[] constsummary=state.summary||"";[] [] // Create our summarization prompt[] letsummaryMessage:string;[] if(summary){[] // A summary already exists[] summaryMessage=[] `This is a summary of the conversation to date:${summary}\\\\n\\\\n`+[] "Extend the summary by taking into account the new messages above:";[]}else{[] summaryMessage="Create a summary of the conversation above:";[]}[] [] // Add prompt to our history[] constmessages=[[]...state.messages,[] newHumanMessage({content:summaryMessage}),[]];[] [] // Assuming you have a ChatOpenAI model instance[] constmodel=newChatOpenAI();[] constresponse=awaitmodel.invoke(messages);[] [] // Delete all but the 2 most recent messages[] constdeleteMessages=state.messages[].slice(0,-2)[].map((m)=&gt;newRemoveMessage({id:m.id}));[] [] return{[] summary:response.content,[] messages:deleteMessages,[]};[]}`\n```\n有关示例用法，请参见[此处] 。\n### 知道**何时**删除消息[¶] \n大多数LLM 都有一个最大支持上下文窗口（以token 计）。决定何时截断消息的一个简单方法是计算消息历史中的token 数量，并在接近该限制时进行截断。朴素截断很容易自行实现，尽管有一些“陷阱”。某些模型API 进一步限制了消息类型的序列（必须以人类消息开头，不能有相同类型的连续消息等）。如果您正在使用LangChain，可以使用[`trimMessages`] 工具并指定要从列表中保留的 token 数量，以及用于处理边界的`strategy`（例如，保留最后`maxTokens`）。\n下面是一个示例。```\n`[] import{trimMessages}from"@langchain/core/messages";[] import{ChatOpenAI}from"@langchain/openai";[] [] trimMessages(messages,{[] // Keep the last &lt;&lt;= n\\_count tokens of the messages.[] strategy:"last",[] // Remember to adjust based on your model[] // or else pass a custom token\\_encoder[] tokenCounter:newChatOpenAI({modelName:"gpt-4"}),[] // Remember to adjust based on the desired conversation[] // length[] maxTokens:45,[] // Most chat models expect that chat history starts with either:[] // (1) a HumanMessage or[] // (2) a SystemMessage followed by a HumanMessage[] startOn:"human",[] // Most chat models expect that chat history ends with either:[] // (1) a HumanMessage or[] // (2) a ToolMessage[] endOn:["human","tool"],[] // Usually, we want to keep the SystemMessage[] // if it\'s present in the original history.[] // The SystemMessage has special instructions for the model.[] includeSystem:true,[]});`\n```\n## 长期记忆[¶] \nLangGraph 中的长期记忆允许系统在不同对话或会话中保留信息。与线程范围的短期记忆不同，长期记忆保存在自定义的“命名空间”中。LangGraph 将长期记忆作为JSON 文档存储在[存储] （[参考文档] ）中。每个记忆都组织在一个自定义的`namespace`（类似于文件夹）和一个独特的`key`（像文件名）下。命名空间通常包含用户或组织ID或其他标签，以便更容易组织信息。这种结构支持记忆的层次化组织。然后通过内容过滤器支持跨命名空间搜索。请参见下面的示例。\n```\n`[] import{InMemoryStore}from"@langchain/langgraph";[] [] // InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.[] conststore=newInMemoryStore();[] constuserId="my-user";[] constapplicationContext="chitchat";[] constnamespace=[userId,applicationContext];[] awaitstore.put(namespace,"a-memory",{[] rules:[[] "User likes short, direct language",[] "User only speaks English &amp; TypeScript",[]],[] "my-key":"my-value",[]});[] // get the "memory" by ID[] constitem=awaitstore.get(namespace,"a-memory");[] // list "memories" within this namespace, filtering on content equivalence[] constitems=awaitstore.search(namespace,{[] filter:{"my-key":"my-value"},[]});`\n```\n当向智能体添加长期记忆时，重要的是要考虑如何**写入记忆**、如何**存储和管理记忆更新**，以及如何为应用程序中的 LLM**召回和表示记忆**。这些问题都是相互关联的：您希望如何为 LLM 召回和格式化记忆，决定了您应该存储什么以及如何管理它。此外，每种技术都有其权衡。正确的方法在很大程度上取决于您应用程序的需求。LangGraph 旨在为您提供低级原语，以便您根据记忆[存储] 直接控制应用程序的长期记忆。\n长期记忆远非一个已解决的问题。虽然很难提供通用建议，但我们在下面提供了一些可靠的模式供您在实现长期记忆时参考。**您希望在“主路径”中写入记忆还是在“后台”写入记忆？**\n记忆可以作为主要应用程序逻辑的一部分（例如，在应用程序的“主路径”上）或作为后台任务（作为根据主要应用程序状态生成记忆的独立函数）进行更新。我们在[下面的写入记忆部分] 中记录了每种方法的一些权衡。\n**您希望将记忆作为单个档案管理还是作为文档集合管理？**\n我们提供了两种管理长期记忆的主要方法：单个持续更新的文档（称为“档案”或“模式”）或文档集合。每种方法都有其自身的好处，具体取决于您需要存储的信息类型以及您打算如何访问它。当您希望记住有关用户、组织或其他实体（包括智能体本身）的范围明确、具体的信息时，将记忆作为单个、持续更新的“档案”或“模式”进行管理非常有用。您可以预先定义档案的模式，然后使用LLM 根据交互进行更新。查询“记忆”很容易，因为它只是对JSON 文档的简单GET 操作。我们在[记住档案] 中更详细地解释了这一点。这种技术可以提供更高的准确性（在已知信息用例中），但召回率较低（因为您必须预测和建模您的领域，并且文档更新倾向于以更高的频率删除或重写旧信息）。\n另一方面，将长期记忆作为文档集合进行管理，可以存储无限量的信息。当您希望在长时间范围内重复提取和记住项目时，这项技术非常有用，但随着时间的推移，查询和管理可能会更复杂。与“档案”记忆类似，您仍然为每个记忆定义模式。您将插入新文档（并在此过程中可能更新或重新情境化现有文档），而不是覆盖单个文档。我们在[“管理记忆集合”] 中更详细地解释了这种方法。\n**您希望将记忆作为更新的指令还是作为少量样本示例呈现给您的智能体？**\n记忆通常作为系统提示的一部分提供给LLM。为 LLM“框架”记忆的一些常见方式包括提供原始信息，如“与用户 A 之前交互的记忆”，作为系统指令或规则，或作为少量样本示例。将记忆框定为“学习规则或指令”通常意味着将系统提示的一部分专门用于LLM 可以自行管理的指令。在每次对话后，您可以提示LLM 评估其性能并更新指令，', 'doi': '', 'published_date': '2026-02-02T17:12:59.061856', 'pdf_url': '', 'url': 'https://github.langchain.ac.cn/langgraphjs/concepts/memory/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '别再混淆！一文看懂LangGraph 的短期记忆与长期记忆：原理', 'authors': [], 'abstract': '别再混淆！一文看懂 LangGraph 的短期记忆与长期记忆：原理、实战与避坑清单\\_博客-飞桨星河社区\n![]', 'doi': '', 'published_date': '2025-11-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://aistudio.baidu.com/blog/detail/737084298395525', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '管理内存 - LangChain 框架', 'authors': [], 'abstract': '[跳到内容] \n\n# 管理内存 [¶] \n\n许多 AI 应用程序需要内存才能在多次交互中共享上下文。LangGraph 支持构建对话代理至关重要的两种内存类型：\n\n- [短期内存] ：通过在会话中维护消息历史来跟踪正在进行的对话。\n- [长期内存] ：在会话之间存储用户特定或应用程序级别的数据。\n\n启用 [短期内存] 后，长对话可能会超出 LLM 的上下文窗口。常见的解决方案有：\n\n- [修剪] ：删除前或后 N 条消息（在调用 LLM 之前）\n- [摘要] ：总结历史中较早的消息并用摘要替换它们\n- [从 LangGraph 状态永久删除消息] \n- 自定义策略（例如，消息过滤等）\n\n这使得代理能够跟踪对话，而不会超出 LLM 的上下文窗口。\n\n## 添加短期内存 [¶] \n\n短期内存使代理能够跟踪多轮对话。\n\n_API 参考： [InMemorySaver] \\| [StateGraph] _\n\n```\nfromlanggraph.checkpoint.memoryimport InMemorySaverfromlanggraph.graphimport StateGraphcheckpointer = InMemorySaver()builder = StateGraph(...)graph = builder.compile(checkpointer=checkpointer)graph.invoke({"messages": [{"role": "user", "content": "hi! i am Bob"}]},{"configurable": {"thread_id": "1"}},)\n```\n\n请参阅 [持久化] 指南，了解有关使用短期内存的更多信息。\n\n## 添加长期内存 [¶] \n\n使用长期内存可以在对话之间存储用户特定或应用程序特定的数据。这对于聊天机器人等应用程序非常有用，您可能希望记住用户偏好或其他信息。\n\n_API 参考： [StateGraph] _\n\n```\nfromlanggraph.store.memoryimport InMemoryStorefromlanggraph.graphimport StateGraphstore = InMemoryStore()builder = StateGraph(...)graph = builder.compile(store=store)\n```\n\n请参阅 [持久化] 指南，了解有关使用长期内存的更多信息。\n\n## 修剪消息 [¶] \n\n要修剪消息历史，您可以使用 [`trim_messages`] 函数\n\n_API 参考： [trim\\_messages] \\| [count\\_tokens\\_approximately] _\n\n```\nfromlangchain_core.messages.utilsimport (trim_messages,count_tokens_approximately)defcall_model(state: MessagesState):messages = trim_messages(state["messages"],strategy="last",token_counter=count_tokens_approximately,max_tokens=128,start_on="human",end_on=("human", "tool"),)response = model.invoke(messages)return {"messages": [response]}builder = StateGraph(MessagesState)builder.add_node(call_model)...\n```\n\n完整示例：修剪消息\n\n```\nfromlangchain_core.messages.utilsimport (trim_messages,count_tokens_approximately)fromlangchain.chat_modelsimport init_chat_modelfromlanggraph.graphimport StateGraph, START, MessagesStatemodel = init_chat_model("anthropic:claude-3-7-sonnet-latest")summarization_model = model.bind(max_tokens=128)defcall_model(state: MessagesState):messages = trim_messages(state["messages"],strategy="last",token_counter=count_tokens_approximately,max_tokens=128,start_on="human",end_on=("human", "tool"),)response = model.invoke(messages)return {"messages": [response]}checkpointer = InMemorySaver()builder = StateGraph(MessagesState)builder.add_node(call_model)builder.add_edge(START, "call_model")graph = builder.compile(checkpointer=checkpointer)config = {"configurable": {"thread_id": "1"}}graph.invoke({"messages": "hi, my name is bob"}, config)graph.invoke({"messages": "write a short poem about cats"}, config)graph.invoke({"messages": "now do the same but for dogs"}, config)final_response = graph.invoke({"messages": "what\'s my name?"}, config)final_response["messages"][-1].pretty_print()\n```\n\n```\n================================== Ai Message ==================================\nYour name is Bob, as you mentioned when you first introduced yourself.\n\n```\n\n## 总结消息 [¶] \n\n处理长对话历史的有效策略是，一旦达到某个阈值，就总结较早的消息\n\n_API 参考： [AnyMessage] \\| [count\\_tokens\\_approximately] \\| [StateGraph] \\| [START] _\n\n```\nfromtypingimport Any, TypedDictfromlangchain_core.messagesimport AnyMessagefromlangchain_core.messages.utilsimport count_tokens_approximatelyfromlangmem.short_termimport SummarizationNodefromlanggraph.graphimport StateGraph, START, MessagesStateclassState(MessagesState):context: dict[str, Any] # (1)!classLLMInputState(TypedDict): # (2)!summarized_messages: list[AnyMessage]context: dict[str, Any]summarization_node = SummarizationNode(token_counter=count_tokens_approximately,model=summarization_model,max_tokens=512,max_tokens_before_summary=256,max_summary_tokens=256,)defcall_model(state: LLMInputState): # (3)!response = model.invoke(state["summarized_messages"])return {"messages": [response]}builder = StateGraph(State)builder.add_node(call_model)builder.add_node("summarize", summarization_node)builder.add_edge(START, "summarize")builder.add_edge("summarize", "call_model")...\n```\n\n1. 我们将在 `context` 字段中跟踪运行中的摘要（由 `SummarizationNode` 期望）。\n2. 在此处定义私有状态，该状态将仅用于过滤 `call_model` 节点的输入。\n3. 我们在此处传递一个私有输入状态，以隔离摘要节点返回的消息。\n\n完整示例：总结消息\n\n```\nfromtypingimport Any, TypedDictfromlangchain.chat_modelsimport init_chat_modelfromlangchain_core.messagesimport AnyMessagefromlangchain_core.messages.utilsimport count_tokens_approximatelyfromlanggraph.graphimport StateGraph, START, MessagesStatefromlanggraph.checkpoint.memoryimport InMemorySaverfromlangmem.short_termimport SummarizationNodemodel = init_chat_model("anthropic:claude-3-7-sonnet-latest")summarization_model = model.bind(max_tokens=128)classState(MessagesState):context: dict[str, Any] # (1)!classLLMInputState(TypedDict): # (2)!summarized_messages: list[AnyMessage]context: dict[str, Any]summarization_node = SummarizationNode(token_counter=count_tokens_approximately,model=summarization_model,max_tokens=256,max_tokens_before_summary=256,max_summary_tokens=128,)defcall_model(state: LLMInputState): # (3)!response = model.invoke(state["summarized_messages"])return {"messages": [response]}checkpointer = InMemorySaver()builder = StateGraph(State)builder.add_node(call_model)builder.add_node("summarize", summarization_node)builder.add_edge(START, "summarize")builder.add_edge("summarize", "call_model")graph = builder.compile(checkpointer=checkpointer)# Invoke the graphconfig = {"configurable": {"thread_id": "1"}}graph.invoke({"messages": "hi, my name is bob"}, config)graph.invoke({"messages": "write a short poem about cats"}, config)graph.invoke({"messages": "now do the same but for dogs"}, config)final_response = graph.invoke({"messages": "what\'s my name?"}, config)final_response["messages"][-1].pretty_print()print("\\nSummary:", final_response["context"]["running_summary"].summary)\n```\n\n1. 我们将在 `context` 字段中跟踪运行中的摘要（由 `SummarizationNode` 期望）。\n2. 在此处定义私有状态，该状态将仅用于过滤 `call_model` 节点的输入。\n3. 我们在此处传递一个私有输入状态，以隔离摘要节点返回的消息。\n\n```\n================================== Ai Message ==================================\nFrom our conversation, I can see that you introduced yourself as Bob. That\'s the name you shared with me when we began talking.\nSummary: In this conversation, I was introduced to Bob, who then asked me to write a poem about cats. I composed a poem titled "The Mystery of Cats" that captured cats\' graceful movements, independent nature, and their special relationship with humans. Bob then requested a similar poem about dogs, so I wrote "The Joy of Dogs," which highlighted dogs\' loyalty, enthusiasm, and loving companionship. Both poems were written in a similar style but emphasized the distinct characteristics that make each pet special.\n\n```\n\n## 删除消息 [¶] \n\n要从图状态中删除消息，您可以使用 `RemoveMessage`。\n\n- 删除特定消息\n\n\n\n```\nfromlangchain_core.messagesimport RemoveMessagedefdelete_messages(state):messages = state["messages"]if len(messages) > 2:# remove the earliest two messagesreturn {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}\n```\n\n- 删除 **所有** 消息\n\n\n\n```\nfromlanggraph.graph.messageimport REMOVE_ALL_MESSAGESdefdelete_messages(state):return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}\n```\n\n\n`add_messages` 缩减器\n\n要使 `RemoveMessage` 工作，您需要将状态键与 [`add_messages`] [缩减器] 一起使用，例如 [`MessagesState`] \n\n有效的消息历史\n\n删除消息时， **请确保** 生成的消息历史有效。检查您正在使用的 LLM 提供商的限制。例如：\n\n- 有些提供商期望消息历史以 `user` 消息开头\n- 大多数提供商要求带有工具调用的 `assistant` 消息后跟相应的 `tool` 结果消息。\n\n完整示例：删除消息\n\n```\nfromlangchain_core.messagesimport RemoveMessagedefdelete_messages(state):messages = state["messages"]if len(messages) > 2:# remove the earliest two messagesreturn {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}defcall_model(state: MessagesState):response = model.invoke(state["messages"])return {"messages": response}builder = StateGraph(MessagesState)builder.add_sequence([call_model, delete_messages])builder.add_edge(START, "call_model")checkpointer = InMemorySaver()app = builder.compile(checkpointer=checkpointer)for event in app.stream({"messages": [{"role": "user", "content": "hi! I\'m bob"}]},config,stream_mode="values"):print([(message.type, message.content) for message in event["messages"]])for event in app.stream({"messages": [{"role": "user", "content": "what\'s my name?"}]},config,stream_mode="values"):print([(message.type, message.content) for message in event["messages"]])\n```\n\n```\n[(\'human\', "hi! I\'m bob")]\n[(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! How are you doing today? Is there anything I can help you with?\')]\n[(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! How are you doing today? Is there anything I can help you with?\'), (\'human\', "what\'s my name?")]\n[(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! How are you doing today? Is there anything I can help you with?\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob.\')]\n[(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob.\')]\n\n```\n\n返回顶部', 'doi': '', 'published_date': '2025-01-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://langgraph.com.cn/how-tos/memory/index.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '如何为聊天机器人添加记忆 | 🦜️🔗 LangChain 框架', 'authors': [], 'abstract': '[跳到主要内容] \n\n**我们的 [使用 LangGraph 构建环境智能体] 课程现已在 LangChain Academy 上线！**\n\n本页内容\n\n聊天机器人的一个关键特性是能够将之前对话回合的内容作为上下文使用。这种状态管理可以有多种形式，包括\n\n- 简单地将之前的消息填充到聊天模型提示中。\n- 同上，但会修剪旧消息以减少模型需要处理的干扰信息量。\n- 更复杂的修改，例如为长时间运行的对话生成摘要。\n\n我们将在下面详细介绍一些技术！\n\n注意\n\n本操作指南之前使用 [RunnableWithMessageHistory] 构建了一个聊天机器人。您可以在 [v0.2 文档] 中查看此版本的指南。\n\n从 LangChain v0.3 版本开始，我们建议 LangChain 用户利用 [LangGraph persistence] 将 `memory` 整合到新的 LangChain 应用程序中。\n\n如果您的代码已经依赖于 `RunnableWithMessageHistory` 或 `BaseChatMessageHistory`，您 **无需** 进行任何更改。我们近期不打算弃用此功能，因为它适用于简单的聊天应用程序，并且任何使用 `RunnableWithMessageHistory` 的代码将继续按预期工作。\n\n请参阅 [如何迁移到LangGraph记忆] 了解更多详细信息。\n\n## 设置 [\u200b] \n\n您需要安装一些软件包，并将您的 OpenAI API 密钥设置为名为 `OPENAI_API_KEY` 的环境变量\n\n```\n%pip install --upgrade --quiet langchain langchain-openai langgraphimport getpassimport osifnot os.environ.get("OPENAI_API_KEY"): os.environ["OPENAI_API_KEY"]= getpass.getpass("OpenAI API Key:")\n```\n\n```\nOpenAI API Key: ········\n```\n\n我们还要设置一个聊天模型，用于以下示例。\n\n```\nfrom langchain_openai import ChatOpenAImodel = ChatOpenAI(model="gpt-4o-mini")\n```\n\n**API 参考：** [ChatOpenAI] \n\n## 消息传递 [\u200b] \n\n最简单的记忆形式就是简单地将聊天历史消息传递到一个链中。下面是一个例子\n\n```\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessagefrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderprompt = ChatPromptTemplate.from_messages([ SystemMessage( content="You are a helpful assistant. Answer all questions to the best of your ability."), MessagesPlaceholder(variable_name="messages"),])chain = prompt | modelai_msg = chain.invoke({"messages":[ HumanMessage( content="Translate from English to French: I love programming."), AIMessage(content="J\'adore la programmation."), HumanMessage(content="What did you just say?"),],})print(ai_msg.content)\n```\n\n**API 参考：** [AIMessage] \\| [HumanMessage] \\| [SystemMessage] \\| [ChatPromptTemplate] \\| [MessagesPlaceholder] \n\n```\nI said, "I love programming" in French: "J\'adore la programmation."\n```\n\n我们可以看到，通过将之前的对话传递到一个链中，它可以使用其作为上下文来回答问题。这是聊天机器人记忆的基本概念——本指南的其余部分将演示传递或重新格式化消息的便捷技术。\n\n## 自动历史管理 [\u200b] \n\n前面的示例明确地将消息传递给链（和模型）。这是一种完全可以接受的方法，但它确实需要外部管理新消息。LangChain 还提供了一种使用 LangGraph 的 [persistence] 构建具有记忆的应用程序的方式。您可以通过在编译图时提供一个 `checkpointer` 来在 LangGraph 应用程序中 [启用持久性] 。\n\n```\nfrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraphworkflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldefcall_model(state: MessagesState): system_prompt =("You are a helpful assistant. Answer all questions to the best of your ability.") messages =[SystemMessage(content=system_prompt)]+ state["messages"] response = model.invoke(messages)return{"messages": response}# Define the node and edgeworkflow.add_node("model", call_model)workflow.add_edge(START,"model")# Add simple in-memory checkpointermemory = MemorySaver()app = workflow.compile(checkpointer=memory)\n```\n\n**API 参考：** [MemorySaver] \\| [StateGraph] \n\n我们在这里将最新的输入传递给对话，并让 LangGraph 使用 checkpointer 跟踪对话历史\n\n```\napp.invoke({"messages":[HumanMessage(content="Translate to French: I love programming.")]}, config={"configurable":{"thread_id":"1"}},)\n```\n\n```\n{\'messages\': [HumanMessage(content=\'Translate to French: I love programming.\', additional_kwargs={}, response_metadata={}, id=\'be5e7099-3149-4293-af49-6b36c8ccd71b\'), AIMessage(content="J\'aime programmer.", additional_kwargs={\'refusal\': None}, response_metadata={\'token_usage\': {\'completion_tokens\': 4, \'prompt_tokens\': 35, \'total_tokens\': 39, \'completion_tokens_details\': {\'reasoning_tokens\': 0}}, \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_e9627b5346\', \'finish_reason\': \'stop\', \'logprobs\': None}, id=\'run-8a753d7a-b97b-4d01-a661-626be6f41b38-0\', usage_metadata={\'input_tokens\': 35, \'output_tokens\': 4, \'total_tokens\': 39})]}\n```\n\n```\napp.invoke({"messages":[HumanMessage(content="What did I just ask you?")]}, config={"configurable":{"thread_id":"1"}},)\n```\n\n```\n{\'messages\': [HumanMessage(content=\'Translate to French: I love programming.\', additional_kwargs={}, response_metadata={}, id=\'be5e7099-3149-4293-af49-6b36c8ccd71b\'), AIMessage(content="J\'aime programmer.", additional_kwargs={\'refusal\': None}, response_metadata={\'token_usage\': {\'completion_tokens\': 4, \'prompt_tokens\': 35, \'total_tokens\': 39, \'completion_tokens_details\': {\'reasoning_tokens\': 0}}, \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_e9627b5346\', \'finish_reason\': \'stop\', \'logprobs\': None}, id=\'run-8a753d7a-b97b-4d01-a661-626be6f41b38-0\', usage_metadata={\'input_tokens\': 35, \'output_tokens\': 4, \'total_tokens\': 39}), HumanMessage(content=\'What did I just ask you?\', additional_kwargs={}, response_metadata={}, id=\'c667529b-7c41-4cc0-9326-0af47328b816\'), AIMessage(content=\'You asked me to translate "I love programming" into French.\', additional_kwargs={\'refusal\': None}, response_metadata={\'token_usage\': {\'completion_tokens\': 13, \'prompt_tokens\': 54, \'total_tokens\': 67, \'completion_tokens_details\': {\'reasoning_tokens\': 0}}, \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_1bb46167f9\', \'finish_reason\': \'stop\', \'logprobs\': None}, id=\'run-134a7ea0-d3a4-4923-bd58-25e5a43f6a1f-0\', usage_metadata={\'input_tokens\': 54, \'output_tokens\': 13, \'total_tokens\': 67})]}\n```\n\n## 修改聊天历史 [\u200b] \n\n修改存储的聊天消息可以帮助您的聊天机器人处理各种情况。以下是一些示例\n\n### 修剪消息 [\u200b] \n\nLLM 和聊天模型具有有限的上下文窗口，即使您没有直接达到限制，您可能也希望限制模型需要处理的干扰量。一种解决方案是在将历史消息传递给模型之前对其进行修剪。让我们使用上面声明的 `app` 的示例历史记录\n\n```\ndemo_ephemeral_chat_history =[ HumanMessage(content="Hey there! I\'m Nemo."), AIMessage(content="Hello!"), HumanMessage(content="How are you today?"), AIMessage(content="Fine thanks!"),]app.invoke({"messages": demo_ephemeral_chat_history+[HumanMessage(content="What\'s my name?")]}, config={"configurable":{"thread_id":"2"}},)\n```\n\n```\n{\'messages\': [HumanMessage(content="Hey there! I\'m Nemo.", additional_kwargs={}, response_metadata={}, id=\'6b4cab70-ce18-49b0-bb06-267bde44e037\'), AIMessage(content=\'Hello!\', additional_kwargs={}, response_metadata={}, id=\'ba3714f4-8876-440b-a651-efdcab2fcb4c\'), HumanMessage(content=\'How are you today?\', additional_kwargs={}, response_metadata={}, id=\'08d032c0-1577-4862-a3f2-5c1b90687e21\'), AIMessage(content=\'Fine thanks!\', additional_kwargs={}, response_metadata={}, id=\'21790e16-db05-4537-9a6b-ecad0fcec436\'), HumanMessage(content="What\'s my name?", additional_kwargs={}, response_metadata={}, id=\'c933eca3-5fd8-4651-af16-20fe2d49c216\'), AIMessage(content=\'Your name is Nemo.\', additional_kwargs={\'refusal\': None}, response_metadata={\'token_usage\': {\'completion_tokens\': 5, \'prompt_tokens\': 63, \'total_tokens\': 68, \'completion_tokens_details\': {\'reasoning_tokens\': 0}}, \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_1bb46167f9\', \'finish_reason\': \'stop\', \'logprobs\': None}, id=\'run-a0b21acc-9dbb-4fb6-a953-392020f37d88-0\', usage_metadata={\'input_tokens\': 63, \'output_tokens\': 5, \'total_tokens\': 68})]}\n```\n\n我们可以看到应用程序记住了预加载的名称。\n\n但是假设我们的上下文窗口非常小，并且我们希望将传递给模型的消息数量修剪到只有最近的 2 条。我们可以使用内置的 [trim\\_messages] 实用程序，根据消息的 token 数量在它们到达我们的提示之前对其进行修剪。在这种情况下，我们将每条消息计算为 1 个“token”，并且只保留最后两条消息\n\n```\nfrom langchain_core.messages import trim_messagesfrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Define trimmer# count each message as 1 "token" (token_counter=len) and keep only the last two messagestrimmer = trim_messages(strategy="last", max_tokens=2, token_counter=len)workflow = StateGraph(state_schema=MessagesState)# Define the function that calls the modeldefcall_model(state: MessagesState): trimmed_messages = trimmer.invoke(state["messages"]) system_prompt =("You are a helpful assistant. Answer all questions to the best of your ability.") messages =[SystemMessage(content=system_prompt)]+ trimmed_messages response = model.invoke(messages)return{"messages": response}# Define the node and edgeworkflow.add_node("model", call_model)workflow.add_edge(START,"model")# Add simple in-memory checkpointermemory = MemorySaver()app = workflow.compile(checkpointer=memory)\n```\n\n**API 参考：** [trim\\_messages] \\| [MemorySaver] \\| [StateGraph] \n\n让我们调用这个新应用程序并检查响应\n\n```\napp.invoke({"messages": demo_ephemeral_chat_history+[HumanMessage(content="What is my name?")]}, config={"configurable":{"thread_id":"3"}},)\n```\n\n```\n{\'messages\': [HumanMessage(content="Hey there! I\'m Nemo.", additional_kwargs={}, response_metadata={}, id=\'6b4cab70-ce18-49b0-bb06-267bde44e037\'), AIMessage(content=\'Hello!\', additional_kwargs={}, response_metadata={}, id=\'ba3714f4-8876-440b-a651-efdcab2fcb4c\'), HumanMessage(content=\'How are you today?\', additional_kwargs={}, response_metadata={}, id=\'08d032c0-1577-4862-a3f2-5c1b90687e21\'), AIMessage(content=\'Fine thanks!\', additional_kwargs={}, response_metadata={}, id=\'21790e16-db05-4537-9a6b-ecad0fcec436\'), HumanMessage(content=\'What is my name?\', additional_kwargs={}, response_metadata={}, id=\'a22ab7c5-8617-4821-b3e9-a9e7dca1ff78\'), AIMessage(content="I\'m sorry, but I don\'t have access to personal information about you unless you share it with me. How can I assist you today?", additional_kwargs={\'refusal\': None}, response_metadata={\'token_usage\': {\'completion_tokens\': 27, \'prompt_tokens\': 39, \'total_tokens\': 66, \'completion_tokens_details\': {\'reasoning_tokens\': 0}}, \'model_name\': \'gpt-4o-mini-2024-07-18\', \'system_fingerprint\': \'fp_1bb46167f9\', \'finish_reason\': \'stop\', \'logprobs\': None}, id=\'run-f7b32d72-9f57-4705-be7e-43bf1c3d293b-0\', usage_metadata={\'input_tokens\': 39, \'output_tokens\': 27, \'total_tokens\': 66})]}\n```\n\n我们可以看到 `trim_messages` 被调用，并且只有两条最新的消息会被传递给模型。在这种情况下，这意味着模型忘记了我们给它的名字。\n\n查看我们的 [关于修剪消息的操作指南] 了解更多。\n\n### 摘要记忆 [\u200b] \n\n我们也可以通过其他方式使用相同的模式。例如，我们可以在调用应用程序之前，使用额外的 LLM 调用来生成对话摘要。', 'doi': '', 'published_date': '2025-02-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://python.langchain.ac.cn/docs/how_to/chatbots_memory', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '如何迁移到 LangGraph 内存 | LangChain中文指南(LangChain官网官方文档)', 'authors': [], 'abstract': '\ufeff\n\n[Skip to main content] \n\n**本文档均内容由官方英文文档翻译而来，如有差异请以官方英文文档（ [https://python.langchain.com/] ）为准！**\n\n本页内容\n\n从 LangChain v0.3 版本开始，我们建议 LangChain 用户利用 [LangGraph 持久化] 来整合 `memory` 添加到他们的 LangChain 应用程序中。\n\n- 依赖 `RunnableWithMessageHistory` 或 `BaseChatMessageHistory` **不需要** 进行任何更改，但建议考虑将 LangGraph 用于更复杂的用例。\n- 依赖 LangChain 0.0.x 中已弃用的内存抽象的用户应按照本指南升级到 LangChain 0.3.x 中新的 LangGraph 持久化功能。\n\n## 为什么使用 LangGraph 进行内存处理？ [\u200b] \n\nLangGraph 持久化的主要优点是：\n\n- 对多个用户和对话的内置支持，这是实际对话式 AI 应用程序的典型要求。\n- 能够随时保存和恢复复杂的对话。这有助于：\n - 错误恢复\n - 允许人工干预 AI 工作流\n - 探索不同的对话路径（“时间旅行”）\n- 与传统 [语言模型] 和现代 [聊天模型] 完全兼容。LangChain 中的早期内存实现不是为较新的聊天模型 API 设计的，这会导致工具调用等功能出现问题。LangGraph 内存可以持久化任何自定义状态。\n- 高度可定制，允许您完全控制内存的工作方式并使用不同的存储后端。\n\n## LangChain 中内存的演变\n\n自首次发布以来，内存的概念在 LangChain 中发生了重大变化。\n\n### LangChain 0.0.x 内存\n\n从广义上讲，LangChain 0.0.x 内存用于处理三个主要用例：\n\n| 用例 | 例 |\n| --- | --- |\n| Managing conversation history | Keep only the last `n` turns of the conversation between the user and the AI. |\n| Extraction of structured information | Extract structured information from the conversation history, such as a list of facts learned about the user. |\n| Composite memory implementations | Combine multiple memory sources, e.g., a list of known facts about the user along with facts learned during a given conversation. |\n\n虽然 LangChain 0.0.x 内存抽象很有用，但它们的功能有限，不太适合现实世界的对话式 AI 应用程序。这些内存抽象缺乏对多用户、多对话场景的内置支持，而这对于实际的对话式 AI 系统至关重要。\n\n这些实现中的大多数已在 LangChain 0.3.x 中被正式弃用，以支持 LangGraph 持久化。\n\n### RunnableWithMessageHistory 和 BaseChatMessageHistory\n\n注意\n\n如果您想使用 [BaseChatMessageHistory 和 LangGraph，请参阅 How to use BaseChatMessageHistory with LangGraph] `BaseChatMessageHistory`（带或不带 `RunnableWithMessageHistory`） 中。\n\n从 LangChain v0.1 开始，我们开始建议用户主要依赖 [BaseChatMessageHistory] 。 `BaseChatMessageHistory` 服务\n作为在对话中存储和检索消息的简单持久性。\n\n当时，编排 LangChain 链的唯一选择是通过 [LCEL。] 要将内存与 `LCEL`，用户必须使用 [RunnableWithMessageHistory] 接口。虽然对于基本的聊天应用程序来说已经足够了，但许多用户发现 API 不直观且难以使用。\n\n从 LangChain v0.3 开始，我们建议 **新** 代码将 LangGraph 用于编排和持久化：\n\n- 编排：在 LangGraph 中，用户定义指定应用程序流程的 [图形] 。这允许用户继续使用 `LCEL` 在单个节点中，当 `LCEL`，同时可以轻松定义更具可读性和可维护性的复杂编排逻辑。\n- 持久化：用户可以依靠 LangGraph 的 [持久化] 来存储和检索数据。LangGraph 持久化非常灵活，可以支持比 `RunnableWithMessageHistory` 接口。\n\n重要\n\n如果您一直在使用 `RunnableWithMessageHistory` 或 `BaseChatMessageHistory`，则无需进行任何更改。我们不打算在不久的将来弃用任何一项功能。此功能对于简单的聊天应用程序和任何使用 `RunnableWithMessageHistory` 将继续按预期工作。\n\n## 迁移\n\n先决条件\n\n这些指南假定您熟悉以下概念：\n\n- [LangGraph] \n- [v0.0.x 内存] \n- [如何向图形添加持久性（“内存”）] \n\n### 1\\. 管理对话历史记录\n\n管理对话历史记录的目标是以最适合聊天模型使用的方式存储和检索历史记录。\n\n这通常涉及修剪和/或总结对话历史记录，以保留对话中最相关的部分，同时使对话适合聊天模型的上下文窗口。\n\n属于此类别的内存类包括：\n\n| 内存类型 | 如何迁移 | 描述 |\n| --- | --- | --- |\n| `ConversationBufferMemory` | [Link to Migration Guide] | A basic memory implementation that simply stores the conversation history. |\n| `ConversationStringBufferMemory` | [Link to Migration Guide] | A special case of `ConversationBufferMemory` designed for LLMs and no longer relevant. |\n| `ConversationBufferWindowMemory` | [Link to Migration Guide] | Keeps the last `n` turns of the conversation. Drops the oldest turn when the buffer is full. |\n| `ConversationTokenBufferMemory` | [Link to Migration Guide] | Keeps only the most recent messages in the conversation under the constraint that the total number of tokens in the conversation does not exceed a certain limit. |\n| `ConversationSummaryMemory` | [Link to Migration Guide] | Continually summarizes the conversation history. The summary is updated after each conversation turn. The abstraction returns the summary of the conversation history. |\n| `ConversationSummaryBufferMemory` | [Link to Migration Guide] | Provides a running summary of the conversation together with the most recent messages in the conversation under the constraint that the total number of tokens in the conversation does not exceed a certain limit. |\n| `VectorStoreRetrieverMemory` | See related [long-term memory agent tutorial] | Stores the conversation history in a vector store and retrieves the most relevant parts of past conversation based on the input. |\n\n### 2\\. 从对话历史中提取结构化信息\n\n请参阅 [long-term memory agent tutorial] 实现可以从对话历史记录中提取结构化信息的代理。\n\n属于此类别的内存类包括：\n\n| 内存类型 | 描述 |\n| --- | --- |\n| `BaseEntityStore` | An abstract interface that resembles a key-value store. It was used for storing structured information learned during the conversation. The information had to be represented as a dictionary of key-value pairs. |\n| `ConversationEntityMemory` | Combines the ability to summarize the conversation while extracting structured information from the conversation history. |\n\n以及抽象的特定后端实现：\n\n| 内存类型 | 描述 |\n| --- | --- |\n| `InMemoryEntityStore` | An implementation of `BaseEntityStore` that stores the information in the literal computer memory (RAM). |\n| `RedisEntityStore` | A specific implementation of `BaseEntityStore` that uses Redis as the backend. |\n| `SQLiteEntityStore` | A specific implementation of `BaseEntityStore` that uses SQLite as the backend. |\n| `UpstashRedisEntityStore` | A specific implementation of `BaseEntityStore` that uses Upstash as the backend. |\n\n这些抽象自首次发布以来一直受到有限的开发。这是因为它们通常需要大量定制才能使特定应用程序有效，这使得\n它们的使用不如 Conversation History Management 抽象。\n\n因此，没有针对这些抽象的迁移指南。如果您正在努力迁移应用程序\n依赖于这些抽象，请：\n\n1. 请查看此 [Long-term memory agent 教程] ，该教程应该为如何从对话历史记录中提取结构化信息提供一个很好的起点。\n2. 如果您仍在苦苦挣扎，请在 LangChain GitHub 存储库上打开一个问题，解释您的用例，我们将尝试提供有关如何迁移这些抽象的更多指导。\n\n从对话历史记录中提取结构化信息的一般策略是使用具有工具调用功能的聊天模型从对话历史记录中提取结构化信息。\n然后，可以将提取的信息保存到适当的数据结构（例如，字典）中，并且可以根据需要检索其中的信息并将其添加到提示中。\n\n### 3\\. 在一个或多个内存实现之上提供复合逻辑的实现\n\n属于此类别的内存类包括：\n\n| 内存类型 | 描述 |\n| --- | --- |\n| `CombinedMemory` | This abstraction accepted a list of `BaseMemory` and fetched relevant memory information from each of them based on the input. |\n| `SimpleMemory` | Used to add read-only hard-coded context. Users can simply write this information into the prompt. |\n| `ReadOnlySharedMemory` | Provided a read-only view of an existing `BaseMemory` implementation. |\n\n这些实现似乎没有得到广泛使用或提供重要价值。用户应该能够\n重新实现这些，而不会在自定义代码中遇到太大困难。\n\n## 相关资源\n\n使用 LangGraph 探索持久化：\n\n- [LangGraph 快速入门教程] \n- [如何向图形添加持久性（“内存”）] \n- [如何管理对话记录] \n- [如何添加对话历史记录摘要] \n\n使用简单的 LCEL 添加持久性（对于更复杂的用例，首选 langgraph）：\n\n- [如何添加消息历史记录] \n\n使用消息历史记录：\n\n- [如何修剪消息] \n- [如何过滤消息] \n- [如何合并消息运行] \n\n- [为什么使用 LangGraph 进行内存处理？] \n- [LangChain 中内存的演变] \n - [LangChain 0.0.x 内存] \n - [RunnableWithMessageHistory 和 BaseChatMessageHistory] \n- [迁移] \n - [1\\. 管理对话历史记录] \n - [2\\. 从对话历史中提取结构化信息] \n - [3\\. 在一个或多个内存实现之上提供复合逻辑的实现] \n- [相关资源]', 'doi': '', 'published_date': '2025-01-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://langchain.cadn.net.cn/python/docs/versions/migrating_memory/index.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '如何迁移到 LangGraph 内存 | 🦜️🔗 LangChain 框架', 'authors': [], 'abstract': '如何迁移到 LangGraph 内存| 🦜️🔗LangChain Python 教程[跳到主要内容] \n**我们的[使用 LangGraph 构建环境智能体] 课程现已在 LangChain Academy 上线！**\n本页内容[![Open on GitHub]] \n# 如何迁移到LangGraph记忆\n自LangChain v0.3 发布以来，我们建议LangChain 用户利用[LangGraph 的持久化功能] ，将`memory`集成到其 LangChain 应用程序中。* 依赖`RunnableWithMessageHistory`或`BaseChatMessageHistory`的用户\\*\\*不需要\\*\\*进行任何更改，但我们鼓励他们在更复杂的用例中考虑使用 LangGraph。\n* 依赖LangChain 0.0.x 中已弃用内存抽象的用户应遵循本指南，升级到LangChain 0.3.x 中新的LangGraph 持久化功能。## 为什么使用LangGraph 进行内存管理？[\u200b] \nLangGraph 持久化的主要优势是* 内置支持多用户和多会话，这是真实世界对话式AI 应用程序的典型要求。* 能够在任何时候保存和恢复复杂的会话。这有助于* 错误恢复* 允许人工干预AI 工作流程* 探索不同的会话路径（“时间旅行”）* 与传统[语言模型] 和现代[聊天模型] 完全兼容。LangChain 中早期的内存实现并未针对较新的聊天模型API 进行设计，导致了工具调用等功能的问题。LangGraph 内存可以持久化任何自定义状态。* 高度可定制，允许您完全控制内存的工作方式并使用不同的存储后端。## LangChain 中内存的演变[\u200b] \n自首次发布以来，LangChain 中的内存概念已显著演变。### LangChain 0.0.x 内存[\u200b] \n广义而言，LangChain 0.0.x 内存主要用于处理三种用例|用例|示例|\n管理会话历史|仅保留用户和 AI 之间会话的最后`n`轮。|\n提取结构化信息|从会话历史中提取结构化信息，例如关于用户学习到的事实列表。|\n复合内存实现|结合多个内存源，例如，关于用户的已知事实列表以及在给定会话中学习到的事实。|\n尽管LangChain 0.0.x 内存抽象很有用，但它们的功能有限，不适用于真实世界的对话式AI 应用程序。这些内存抽象缺乏对多用户、多会话场景的内置支持，而这些场景对于实用的对话式AI 系统至关重要。这些实现中的大多数已在LangChain 0.3.x 中正式弃用，取而代之的是LangGraph 持久化。### RunnableWithMessageHistory 和BaseChatMessageHistory[\u200b] \n注意如果您想在LangGraph 中使用`BaseChatMessageHistory`（无论是否与`RunnableWithMessageHistory`结合），请参阅[如何在 LangGraph 中使用BaseChatMessageHistory] 。\n自LangChain v0.1 起，我们开始建议用户主要依赖[BaseChatMessageHistory] 。`BaseChatMessageHistory`作为一种简单的持久化机制，用于存储和检索会话中的消息。\n当时，编排LangChain 链的唯一选择是通过[LCEL] 。为了将内存与`LCEL`集成，用户必须使用[RunnableWithMessageHistory] 接口。虽然这对于基本的聊天应用程序来说已经足够，但许多用户发现该 API 不直观且难以使用。自LangChain v0.3 起，我们建议\\*\\*新\\*\\*代码利用 LangGraph 进行编排和持久化* 编排：在LangGraph 中，用户定义[图] 来指定应用程序的流程。这使得用户在需要`LCEL`时可以在各个节点内继续使用`LCEL`，同时更容易定义更具可读性和可维护性的复杂编排逻辑。\n* 持久化：用户可以依赖LangGraph 的[持久化功能] 来存储和检索数据。LangGraph 持久化功能非常灵活，可以支持比`RunnableWithMessageHistory`接口更广泛的用例。\n重要如果您一直在使用`RunnableWithMessageHistory`或`BaseChatMessageHistory`，则无需进行任何更改。我们不打算在近期弃用这两种功能。此功能对于简单的聊天应用程序来说已足够，并且任何使用`RunnableWithMessageHistory`的代码都将继续按预期工作。\n## 迁移[\u200b] \n先决条件这些指南假定您对以下概念有所了解* [LangGraph] \n* [v0.0.x 内存] \n* [如何为图添加持久性（“内存”）] \n### 1. 管理会话历史[\u200b] \n管理会话历史的目标是以最适合聊天模型使用的方式存储和检索历史。这通常涉及修剪和/或总结会话历史，以保留会话中最相关的部分，同时将会话适配到聊天模型的上下文窗口内。\n属于此类的内存类包括|内存类型|如何迁移|描述|\n`ConversationBufferMemory`|[迁移指南链接] |一个基本的内存实现，它简单地存储会话历史。|\n`ConversationStringBufferMemory`|[迁移指南链接] |`ConversationBufferMemory`的一个特例，专为 LLM 设计，现已不再相关。|\n`ConversationBufferWindowMemory`|[迁移指南链接] |保留会话的最后`n`轮。当缓冲区满时，丢弃最旧的一轮。|\n`ConversationTokenBufferMemory`|[迁移指南链接] |在会话总 token 数不超过特定限制的约束下，仅保留会话中最新的消息。|\n`ConversationSummaryMemory`|[迁移指南链接] |持续总结会话历史。摘要在每次会话轮次后更新。该抽象返回会话历史的摘要。|\n`ConversationSummaryBufferMemory`|[迁移指南链接] |提供会话的运行摘要以及会话中最新的消息，同时受限于会话的总 token 数不超过特定限制。|\n`VectorStoreRetrieverMemory`|参见相关的[长期记忆代理教程] |将会话历史存储在向量存储中，并根据输入检索过去会话中最相关的部分。|\n### 2. 从会话历史中提取结构化信息[\u200b] \n请参阅[长期记忆代理教程] ，该教程实现了一个可以从会话历史中提取结构化信息的代理。\n属于此类的内存类包括|内存类型|描述|\n`BaseEntityStore`|一个类似于键值存储的抽象接口。它用于存储在会话中学习到的结构化信息。这些信息必须表示为键值对的字典。|\n`ConversationEntityMemory`|结合了总结会话的能力，同时从会话历史中提取结构化信息。|\n以及特定后端抽象实现|内存类型|描述|\n`InMemoryEntityStore`|`BaseEntityStore`的一个实现，它将信息存储在计算机的实际内存（RAM）中。|\n`RedisEntityStore`|`BaseEntityStore`的一个特定实现，它使用 Redis 作为后端。|\n`SQLiteEntityStore`|`BaseEntityStore`的一个特定实现，它使用 SQLite 作为后端。|\n`UpstashRedisEntityStore`|`BaseEntityStore`的一个特定实现，它使用 Upstash 作为后端。|\n这些抽象自首次发布以来开发有限。这是因为它们通常需要针对特定应用程序进行大量定制才能有效，因此它们的使用范围不如会话历史管理抽象广泛。因此，这些抽象没有迁移指南。如果您在迁移依赖这些抽象的应用程序时遇到困难，请1. 请查阅此[长期记忆代理教程] ，它应该为您如何从会话历史中提取结构化信息提供一个很好的起点。\n2. 如果您仍然遇到困难，请在LangChain GitHub 仓库上提出一个问题，说明您的用例，我们将尽力提供更多关于如何迁移这些抽象的指导。从会话历史中提取结构化信息的通用策略是使用具有工具调用能力的聊天模型来提取会话历史中的结构化信息。然后，提取的信息可以保存到适当的数据结构中（例如，字典），并根据需要从中检索信息并添加到提示中。### 3. 在一个或多个内存实现之上提供复合逻辑的实现[\u200b] \n属于此类的内存类包括|内存类型|描述|\n`CombinedMemory`|此抽象接受`BaseMemory`列表，并根据输入从每个内存中获取相关内存信息。|\n`SimpleMemory`|用于添加只读的硬编码上下文。用户可以直接将这些信息写入提示中。|\n`ReadOnlySharedMemory`|提供了现有`BaseMemory`实现的只读视图。|\n这些实现似乎并未被广泛使用，也未提供显著价值。用户应该能够在自定义代码中不费太多力气地重新实现它们。## 相关资源[\u200b] \n探索LangGraph 的持久性* [LangGraph 快速入门教程] \n* [如何为图添加持久性（“内存”）] \n* [如何管理对话历史] \n* [如何添加对话历史摘要] \n使用简单LCEL 添加持久性（对于更复杂的用例，推荐使用LangGraph）\n* [如何添加消息历史] \n使用消息历史记录* [如何修剪消息] \n* [如何过滤消息] \n* [如何合并消息运行] \n* [为什么使用 LangGraph 进行内存管理？] \n* [LangChain 中内存的演变] \n* [LangChain 0.0.x 内存] \n* [RunnableWithMessageHistory 和BaseChatMessageHistory] \n* [迁移] \n* [1. 管理会话历史] \n* [2. 从会话历史中提取结构化信息] \n* [3. 在一个或多个内存实现之上提供复合逻辑的实现] \n* [相关资源] \n&copy;**. This site is unofficial and not affiliated with LangChain, Inc.\n**这些文档随着 LangChain v1.0 在2025 年10 月的发布而弃用，并且不再维护。[请访问 v1.0 文档] **', 'doi': '', 'published_date': '2025-02-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://python.langchain.ac.cn/docs/versions/migrating_memory', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践', 'authors': [], 'abstract': '[Skip to Main Content] \n\n## [亚马逊AWS官方博客] \n\n# Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践\n\n_本文将深入探讨 Agent_ _应用中的记忆需求、记忆类型、技术组件和主流开源框架，并介绍基于亚马逊云科技的数据产品自行构建记忆模块，以及基于Agent_ _构建平台Bedrock AgentCore_ _的Agent memory_ _的托管方案。_\n\n## 前言\n\n### 当前大语言模型的困境\n\n大语言模型在处理和生成文本方面表现出色，但它们在本质上是 **无状态（** **stateless** **）** 的。这意味着每次与LLM的交互都是独立的，模型本身不会“记住”过去的对话或经验。大模型在“记忆”上主要局限于：\n\n- **上下文窗口的限制导致遗忘问题。** LLM通过一个有限的“上下文窗口”（Context Window）来处理信息。所有输入（包括Prompt和之前的对话片段）都必须塞入这个窗口。一旦信息超出这个窗口，LLM就“忘记”了它，无法再访问。这导致了所谓的 **“** **遗忘”** 问题；\n- **难以处理多轮/** **复杂任务。** 对于需要跨越多轮对话、追踪状态或执行一系列子任务的复杂任务，LLM很难保持连贯性和进展，因为它会不断“忘记”之前的步骤和决策。特别是在Agent的场景，工具的定义和工具的返回值都会存在于上下文中，同时由于Agent具有自主工作的能力，和LLM的平均交互的轮数也大大增加；\n- **无法个性化。** 由于不记住特定用户的历史偏好、习惯或之前的互动，LLM难以提供真正个性化的体验。每次互动都像是第一次见面；\n- **长上下文带来的性能和成本影响。推理速度变慢：** LLM在处理更长的上下文时，需要进行更多的计算来处理和理解所有输入信息。这会导致推理时间增加，响应速度变慢。 **模型表现下降：** 尽管LLM的上下文窗口越来越大，但研究发现，模型在超长上下文中检索关键信息的能力可能会下降。 **更高的** **Token** **费用：** 上下文越长，输入的token数量就越多，从而导致每次API调用的成本更高。对于需要频繁交互或处理大量文本的应用来说，这会迅速累积成可观的费用。\n\n### 为什么需要记忆模块\n\n记忆系统旨在克服LLM的局限性，赋予智能体以下核心能力：\n\n- **长期保留与高效管理：** 存储超出LLM上下文窗口的信息，实现高效检索和过滤，避免信息遗忘；\n- **持续知识更新：** 通过存储与环境和用户的交互经验，实现自我改进和知识更新；\n- **个性化服务：** 记录用户偏好和历史互动，提供定制化回应；\n- **复杂任务支持：** 追踪多Agent任务进展和中间结果，确保连贯完成并优化决策；\n- **提升交互质量：** 保持上下文连贯性，支持深入推理，并通过反思机制从错误中学习。\n\n## AI Agent 记忆类型\n\n智能体的记忆系统主要分为短期记忆和长期记忆两大类。\n\n### 短期记忆/工作记忆\n\n短期记忆（Short-term Memory, STM）是智能体维护当前对话和任务的即时上下文系统，主要包括：\n\n- **会话缓冲（Context** **）记忆**：保留最近对话历史的滚动窗口，确保回答上下文相关性；\n- **工作记忆**：存储当前任务的临时信息，如中间结果、变量值等。\n\n短期记忆受限于上下文窗口大小，适用于简单对话和单一任务场景。\n\n### 长期记忆\n\n**长期记忆**（Long-term Memory, LTM）是智能体用于 **跨会话、跨任务长期保存知识** 的记忆形式。它对应于人类的大脑中持久保存的记忆，例如事实知识、过去经历等。长期记忆的实现通常依赖于 **外部存储** 或 **知识库**，包括但不限于：\n\n- **摘要记忆**：将长对话内容提炼为关键摘要存储；\n- **结构化知识库**：使用数据库或知识图谱存储结构化信息；\n- **向量化存储**：通过向量数据库实现基于语义的记忆检索。\n\n长期记忆使智能体能够 **随着时间累积经验和知识，** 它特别适用于 **知识密集型应用** 和 **需要长期个性化** 的场景。\n\n## 记忆管理与使用相关技术\n\n设计开发Agent的记忆系统时要考虑 **不同场景下如何选择记忆内容、设计写入策略、组织记忆结构、实现检索召回** 四个方面。\n\n### 记忆产生：判断哪些信息需要被记忆\n\n在构建智能体记忆系统时，首先要根据具体的场景确定 **哪些信息值得记忆**。这些记忆往往是多维度和动态的信息结构，包括 **时间** 维度（理解时间依赖的关系和序列）、 **空间** 维度（解释基于位置的和几何关系）、参与者 **状态**（跟踪多个实体及其不断变化的状况）、意图 **上下文**（理解目标、动机和隐含的目的），以及文化上下文（在特定社会和文化框架内解释交流）。\n\n并非所有对话内容都需要长期保存，下面以4种常见场景举例哪些是与任务相关、对后续交互有价值的记忆要点。\n\n对于 **代码助手类的智能体**，记忆应侧重 **用户项目的上下文和偏好**。包括：用户项目的 **代码库结构**（文件组织、模块关系）、 **命名风格**（变量命名约定、代码格式风格）、常用的 **框架** **/** **库** 以及用户以前提供的代码片段或指令等。记忆这些信息可以更贴合定制化需求和项目实际情况给出建议。例如，没有记忆支持时，开发者常常需要重复告诉 AI 项目的架构或纠正 AI 偏离项目规范的行为，这非常低效。而引入 **持久记忆** 后，AI 可以持续参考之前存储的项目背景，”记住”用户的技术栈，从而保持技术决策的一致性。同时，代码助手还能记忆用户过往的提问和反馈，例如某段代码曾反复修改，下一次遇到类似问题时可直接调用之前的方案，避免重复推理。总之，在代码场景中，记忆系统使AI能够理解 **长期的项目上下文**，提供 **风格一致** 且 **上下文相关** 的代码补全和解释。\n\n对于 **智能客服类的智能体**，记忆的重点是 **用户历史和偏好**，以便提供连贯且个性化的服务。包括：用户当前 **任务的状态，** 提过的问题、故障、产品使用，服务配置，和解决方案记录。当用户第二次来询问类似问题时，不必重复描述自己之前的问题细节，系统能够回忆起 **上次给出的建议** 或已经尝试过某些步骤，直接切入重点解决当前问题。此外，记忆用户的产品使用情况和喜好（例如偏好哪种通信渠道，是否倾向自助解决）可以使响应更加贴合用户习惯。这样实现 **更快的问题解决** 和 **更高的客户满意度，** 增强对品牌的信任。\n\n对于 **个人助理** 智能体，记忆重点包括： **用户个人信息和日程表**、 **目标**（如健身学习计划）、经常执行的 **行为模式**（如每周几锻炼）以及对应用和服务的偏好（如偏好哪种提醒方式）等。这样智能体会提醒日程，并结合过往偏好提供个性化安排（比如知道用户周五喜欢外卖，在傍晚时主动推荐餐厅）。随着交互增加， **持续的长期记忆** 使智能体能 **不断适应用户**，逐渐减少对用户指令的依赖，实现更 **主动** 和 **贴心** 的服务。\n\n对于 **推荐服务** 智能体，记忆重点包括： **用户的显式反馈**（如用户给某本书点赞或明确表达不喜欢某商品） **和隐式反馈**（如浏览记录、点击行为、购买历史） **，** 以此构建兴趣档案，在后续交互中个性化推荐。并持续学习，对过往推荐的反馈（是否点击、购买）， **不断调整推荐策略，更新画像。** 提高推荐转化率也增强用户忠诚度。\n\n#### 记忆管理的实际例子\n\n以下是在一个长文档处理的Agent项目中使用的上下文压缩提示词，当上下文超过指定的限额时，将触发基于LLM的压缩机制。\n\n```\n# Custom system prompt for document processing domain summarization\ncustom_system_prompt = """您正在总结文档处理工作流对话。创建一个简明扼要的要点摘要，该摘要：\n 专注于文档处理任务、章节生成和工作流进度\n 保留特定文件路径、章节名称和任务完成状态\n 维护待办事项列表状态和进度跟踪信息\n 省略对话元素，专注于可操作的工作流信息\n 使用适合文档处理和内容生成的技术术语\n 保留错误消息和重要状态更新\n 以要点形式呈现，不使用对话语言，按以下方式组织：\n 文档处理：[关键处理步骤和结果]\n 章节生成：[已完成的章节和当前进度]\n 待办状态：[当前工作流状态和待处理任务]\n 文件位置：[重要文件路径和输出]\n 错误/问题：[遇到的任何问题及解决方案]\n """\n```\n\n### 记忆策略\n\n智能体的记忆更新可通过 **轮数** 或 **事件** 触发。轮数触发是每隔3-5轮对话自动生成摘要存入记忆；事件触发则在完成任务、场景转换等关键节点记录信息。例如，客服完成问题处理时保存解决方案，个人助理更新日程后写入日历。开发者可实现监控逻辑，在对话累积或话题转换时，让大模型对近期对话生成摘要，提取关键信息并添加标签便于检索。\n\n系统也可支持用户主动标记需要记住的信息，如通过 **口头指令** 或 **界面** 操作。这不仅让用户指定重要内容，也支持删除特定记忆的需求，确保用户对数据的控制权。\n\n### 记忆存储：记忆组织结构设计\n\n记忆数据通常采用 **用户** **→** **会话→** **记忆片段** 的三层结构管理。 **用户** 层区分不同账号空间， **会话** 层隔离各对话上下文， **记忆片段** 层存储具体内容及元数据（如时间、关键词、来源等）。复杂系统可能需要维护多个记忆库，包括短期工作记忆、长期情节记忆、语义知识库等。合理的结构设计有助于快速检索和有效管理记忆内容。\n\n### 记忆检索：记忆查询与召回逻辑\n\n智能体需要基于当前对话意图从记忆库中检索相关信息。主要检索方法包括关 **键词匹配**、 **向量语义搜索** 和 **元数据过滤**。系统将检索到的记忆按相关度排序，选取最相关内容加入到对话上下文中，用于生成更准确的响应。例如在推荐场景中，可基于用户历史偏好记忆提供个性化建议。\n\n## 上下文工程（Context Engineering）与记忆\n\n### 上下文工程\n\n上下文工程与记忆系统形成共生关系，共同支撑智能体的认知能力。记忆系统作为”信息仓库”，存储历史对话、知识和用户偏好；而上下文工程则扮演”智能调度员”，决定从记忆中检索哪些信息及如何组织呈现给LLM。\n\n上下文工程的核心在于，LLM的性能和有效性根本上取决于其接收的 **上下文**。实现了上下文工程的系统一般包含三类 **基础组件**：\n\n1. **上下文检索与生成：** 涵盖Prompt生成和外部知识获取；\n2. **上下文处理：** 涉及长序列处理、自我完善和结构化信息集成；\n3. **上下文管理：** 关注记忆层次、压缩技术和优化策略。\n\n这些组件是高级应用实现（如RAG、显式记忆系统和智能体系统）的基石。由此，我们可以将上下文工程定义为：上下文工程将上下文C重新概念化为一组动态结构化的信息组件，c1, c2, …, cn。这些组件由一组函数进行来源获取、过滤和格式化，最终由高级组装函数A进行编排。\n\n### 上下文工程与记忆的关系\n\n上下文工程与记忆系统 **紧密且共生**，都是AI智能体的重要构建手段。一方面 **，记忆是上下文的** **“** **仓库”** **，**\xa0智能体的记忆系统（如历史对话、知识库、用户偏好）是信息存储地，为LLM提供 **潜在上下文**。另一方面， **上下文工程是记忆的** **“** **调度员”** **和“** **优化器”** **，上下文工程** 决定从记忆中检索哪些信息及如何检索，确保提取最相关的记忆片段。\n\n### 上下文工程在项目中的例子\n\n在一个文档自动化处理生成的Agent项目中，我们面临一个关键挑战：输入文档总量超过500页，远超模型的最大Token限制，同时项目对生成内容的召回率和准确率有较高要求。\n\n为解决这一问题，我们实施了以下上下文工程策略：\n\n1. **文档分块处理：** 将大型文档集合切分为适当大小的chunks，并存储在文件系统中；\n2. **摘要生成：** 为每个文档块生成精炼的文字摘要，提供内容概览。并生成整个文档的摘要信息；\n3. **动态上下文管理：** 赋予Agent自主选择的能力，使其可以根据任务需求动态调取相关文档块；\n4. **上下文优化：** 任务完成后自动释放不再需要的上下文，优化资源利用。\n\n这种方法使Agent能够在保持高准确率的同时，有效处理超过模型上下文限制的文档集合。\n\n## 主流记忆框架分析\n\n基于上个章节介绍的设计思路，核心组件和优化策略，业界涌现了多种记忆机制的实现方案。以下我们从 **开源框架（** **Mem0** **，MemGPT** **，LangMem** **以及他们与亚马逊云科技服务的集成）** 和 **亚马逊云科技商业解决方案（** **AI Agent** **构建托管服务Bedrock AgentCore** **的记忆模块）** 两个角度，对目前主流的Agent记忆方案进行分析，比较它们的特点、适用场景以及部署成本。\n\n### Mem0\n\n[Mem0] 是专为AI Agent设计的开源记忆框架，通过智能记忆管理帮助Agent实现状态持久化。它支持工作记忆、事实记忆、情景记忆和语义记忆等多种类型，提供智能的LLM提取、过滤和衰减机制，有效降低计算成本。同时支持多模态处理和Graph记忆功能，既可使用托管服务也可自建部署。\n\n从架构来看，Mem0包含几个核心模块： **核心记忆层、大语言模型层、嵌入模型层、向量存储层、图存储层和持久化存储层**。核心记忆层是构建核心逻辑来判断新增、检索、更新和删除记忆的相应实现；大语言模型层负责根据用户输入提取出关键信息，以及生成如何更新记忆的决策；嵌入模型和向量存储层负责支持记忆的向量化存储和检索；图存储层负责存储抽取出的实体关系，丰富记忆的组织形态；持久化存储层负责存储对记忆系统的操作信息。这种分层架构设计确保了记忆系统的可扩展性和可维护性，\n\n每层职责明确，便于针对不同场景进行优化配置。\n\nMem0 的设计理念专注于智能记忆管理而非简单数据存储，融合了几个关键技术创新：\n\n- 双 LLM 架构：系统通过两次不同的 LLM 调用实现复杂的分工。第一次专注于信息提取，第二次专门处理决策过程，提高准确性并允许专门优化。\n- 上下文感知处理：在现有记忆上下文中分析新数据，确保记忆系统一致性和连贯性，防止碎片化并维护信息间逻辑关系。\n- 智能去重机制：结合向量相似性搜索与LLM判断，防止冗余信息存储，保持记忆质量和系统效率。\n- 冲突解决能力：当出现矛盾信息时，智能确定保留、更新或删除的适当行动，适应用户偏好和环境的动态变化。\n\n#### Mem0与Agent框架的集成\n\n开发者可以通过两种方式集成Mem0：一是在环境变量配置依赖信息后，直接调用Mem0的接口函数（如添加、查找、更新记忆等）；二是将Mem0封装成工具传入Agent框架，由Agent根据处理逻辑自主调用相应方法。\n\n#### Mem0与亚马逊云科技的集成\n\n亚马逊云科技的多项服务均支持与Mem0集成，为开发者提供完整的企业级记忆解决方案：\n\n- 模型服务集成：支持Amazon Bedrock的多种模型，包括Claude-3.7-Sonnet用于复杂推理、Titan-Embed-Text-v2用于向量化处理。\n- 存储服务集成：\n - 向量存储：Amazon Aurora Serverless V2 for PostgreSQL、Amazon OpenSearch\n - 图数据存储：Amazon Neptune Analytics\n- 开发框架集成：亚马逊云科技开源的StrandsAgent框架中内置了基于Mem0能力封装的mem0\\_memory工具。\n\nMem0作为开源解决方案，为开发者提供了灵活的记忆管理能力。结合亚马逊云科技服务的强大生态，可以构建高性能、可扩展的Agent记忆系统，适合需要深度定制和成本优化的企业级应用场景。更多关于Mem0的深度解析以及和亚马逊云科技的服务的集成请见博客\xa0[https://amazon.awsapps.com/workdocs-amazon/index.html#/document/17faaf605c2b12a543d5b9223ec5301aca29c03ffd5f3d1f5dd929d5496471bc] \n\n### Letta (前身为MemGPT)\n\n#### Letta 功能介绍\n\nLetta（前身为MemGPT）是一个专注于构建具有持续记忆能力的 AI Agent 的框架，它的设计思路是将LLM代理类比为计算机操作系统，采用” **虚拟内存**“的概念来管理智能体的记忆。其核心创新在于双层记忆架构，包括 **上下文内记忆**（直接存在于模型上下文窗口中的系统指令、可读写记忆块和当前对话）和 **上下文外记忆**（存储历史对话和外部知识的长期存储）。当上下文窗口接近填满时，系统会自动将对话历史压缩为递归摘要并存储为记忆块，同时保留原始对话供后续检索，通过工具如core\\_memory\\_append、core\\_memory\\_replace 和 recall 实现记忆的编辑与检索，从而使 AI 代理能够在长期交互中保持连贯性，真正实现记住过去、学习新知并随时间演化的能力。\n\n#### Letta与亚马逊云科技生态的深度集成\n\nLetta可无缝对接亚马逊云科技服务栈，以下是一个通过 Letta 框架搭建的电商客服机器人问答流程示例：\n\n- 使用 Amazon Bedrock 的 Claude 或 Titan 模型作为基础 LLM\n- 采用 Amazon PostgreSQL、OpenSearch 作为向量存储后端\n- 利用 ElastiCache 缓存来提升推理（框架原生支持）、问答等场景（需要搭建缓存中间件）的效率\n- 通过 亚马逊云科技 Lambda 实现记忆管理的无服务器架构\n\n图1\\. 通过 Letta 框架搭建的电商客服机器人问答流程示例\n\n**LangMem**\n\nLangMem 是由 LangChain 开发的，旨在解决 AI 代理的”健忘症”问题。传统的大语言模型在会话结束或上下文窗口被超出时会丢失之前的交互信息，而 LangMem 为 AI 代理提供了长期记忆能力，使其能够跨会话保持知识连续性，记住用户的偏好、过往交互和重要事实。这一创新将 AI 代理从简单的反应系统转变为能够随时间学习和适应的动态助手。例如：你的 AI 助手能够记住你上周提到的项目细节，了解你的工作习惯，甚至记得你喜欢的咖啡类型。\n\nLangMem 框架的设计理念是借鉴人类心理学对记忆的分类，为Agent设计了三种核心记忆类型，每种类型都有其独特的功能和应用场景。\n\n- **语义记忆 (Semantic Memory)** **：** 语义记忆是 Agent 的知识基础，存储客观事实、用户偏好和基础知识，作为长期持久化记忆嵌入系统提示中，可通过 Collection 方式保存完整历史信息，或通过 Profile 方式只保留最新状态，为Agent 提供稳定的知识支撑，确保其能够准确理解和回应用户需求。\n- **情节记忆（Episodic Memory** **）：** 捕捉 Agent 的交互经历，不仅存储对话内容，还包含完整上下文和推理过程，作为短期记忆主要用于构建用户提示词，使 Agent 能够从过往经验中学习，参考成功案例调整响应策略，从而在类似情境中提供更加个性化和有效的解决方案。\n- **程序记忆 (Procedural Memory)** **：** 专注于”如何做”的实操知识，从初始系统提示开始，通过持续反馈和经验积累不断优化，作为短期记忆帮助 Agent 学习最有效的行为模式，既可用于系统提示也可用于用户提示，使 Agent 能够根据不同情境灵活调整策略，提高解决问题的效率和准确性。\n\nLangMem 不仅能存储对话中的重要信息，还能优化提示和行为，在多次交互后提供更连贯、个性化的响应。它消除了传统 AI 代理在会话结束后丢失上下文的问题，减少了重复询问用户已提供信息的需要，显著提升了用户体验的连贯性和个性化程度。LangMem 提供通用存储兼容性和热路径内存工具，使AI代理能在实时会话中即时保存和检索信息。其智能后台内存管理功能自动提取、汇总并更新知识库，且与 LangGraph 平台无缝集成。LangMem 的高级特性包括 **主动记忆管理、共享内存机制、命名空间组织和个性化持续进化** 能力，使 AI Agent 能根据重要性动态存储信息，支持多个 Agent 之间的知识共享，高效组织检索信息，并不断适应用户需求变化，提供越来越精准的服务。\n\n目前 LangMem 主要是与 LangGraph 集成，支持 Amazon Bedrock。在记忆存储层面，针对开发场景，有内置的 InMemoryStore，支持快速的迭代、测试和原型设计；另外，提供对 PostgresqlSQL 的支持。对于其他记忆存储引擎，LangMem 提供开放的接口实现方式，需要用户定制开发集成。\n\n### Amazon Bedrock AgentCore Memory：亚马逊云科技的托管记忆解决方案\n\n相比开源框架，亚马逊云科技也提供 **开箱即用的托管服务**，通过AI Agent构建平台Bedrock AgentCore中的记忆模块帮助开发者更快捷地为AI Agent赋能记忆功能。您无需运维任何底层资源，只需一键即可集成业界领先的记忆系统。\n\n图2-Bedrock AgentCore中的记忆模块核心功能展示\n\nAmazon Bedrock AgentCore 的 Memory 模块是一个由亚马逊云科技托管的持久化记忆系统，用于存储和管理 AI Agent 的对话和知识。它提供 **短期记忆（** **short-term memory** **）和长期记忆（long-term memory** **）** 两种模式。短期记忆负责在一次会话中记录最近的最近几轮对话，确保代理能够“记住”当前对话的上下文。长期记忆则从对话中提取结构化的关键信息，在多个会话之间保留知识，使Agent能够“学习”用户偏好、事实和摘要等信息。\n\n**记忆的存储**\n\nMemory 模块在架构上采用分层存储策略：短期记忆层存储原始交互事件作为即时上下文，长期记忆层存储从事件提取的概要知识。Memory 服务背后实现了自动的信息处理流水线：当新的事件被存储时，如果 Memory 配置了长期记忆策略，服务会异步地对事件内容进行分析（例如调用基础模型）来提炼出可长期保存的知识片段。\n\nAgentCore Memory 内置了多种记忆策略（Memory Strategy）来定义如何将原始对话转化为结构化长期记忆。例如：\n\n- **SemanticMemoryStrategy**（语义记忆策略）：从对话中抽取出 **事实和知识**，以便日后查询。\n- **SummaryMemoryStrategy**（摘要策略）：为每个会话生成 **对话摘要**，提炼主要内容。\n- **UserPreferenceMemoryStrategy**（用户偏好策略）：捕获用户的偏好、风格和重复选择等信息。\n\n使用内置策略时，无需额外配置模型，AgentCore Memory 服务会在后台使用预置的模型来完成提取和归纳。当开发者调用 CreateEvent 保存新事件后，', 'doi': '', 'published_date': '2025-09-19T00:00:00+00:00', 'pdf_url': '', 'url': 'https://aws.amazon.com/cn/blogs/china/agentic-ai-infrastructure-deep-practice-experience-thinking-series-three-best-practices-for-agent-memory-module/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': 'YouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下： \\nGitHub地址: https://github.com/NanGePlus/LangChai... \\nGitee地址: https://gitee.com/NanGePlus/LangChain... \\n\\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力 \\n个人项目GitHub地址：https://github.com/NanGePlus \\n个人项目Gitee地址：https://gitee.com/NanGePlus \\n大模型代理平台: https://nangeai.top/ \\n\\n【章节】\\n\\n0:00 引言 源代码下载方式\\n0:37 核心功能\\n1:37 核心概念介绍\\n8:37 准备工作和项目初始化\\n13:27 InMemorySaver测试和源码\\n18:16 PostgresSaver测试和源码\\n21:33 管理策略测试和源码\\n24:05 最后 总结\\n\\n频道项目\\u0026视频推荐：\\n1. 8n自动化工作流平台相关分享 \\nhttps://github.com/NanGePlus/N8NWorkf... \\n\\n2. 大模型应用技术开发-入门系列 \\nhttps://github.com/NanGePlus/LLMsBasi... \\n \\n3. 大模型应用技术开发-MCP系列\\nhttps://github.com/NanGePlus/MCPServe... \\n\\n4. 大模型应用技术开发-RAG系列 \\nhttps://github.com/NanGePlus/RagWithM... \\nhttps://github.com/NanGePlus/LightRAG... \\nhttps://github.com/NanGePlus/KagTest \\n\\n5. 大模型应用技术开发-Agent系列 \\nhttps://github.com/NanGePlus/ReActAge... \\nhttps://github.com/NanGePlus/CrewAIFl... \\nhttps://github.com/NanGePlus/AutoGenV... \\n \\n6. 大模型应用技术开发-Fine-Tuning大模型微调系列 \\nhttps://github.com/NanGePlus/FineTuni...\n| view_count: 55 views | short_view_count: 55 views | num_likes: 4 likes | num_subscribers: 2.95 thousand | duration: 24 minutes 10 seconds', 'doi': '', 'published_date': '2026-01-15T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '【AI大模型应用开发】以LangChain为例：从短期记忆实战 - 53AI', 'authors': [], 'abstract': '- [首页] \n- [产品服务] \n- [客户案例] \n- [AI知识库] \n- [关于我们] \n\n热门场景\n\n工作+AI\n\n业务+AI\n\nAIx业务\n\n[落地咨询] \n\n[定制开发] \n\n热门产品\n\n[53AI KM\\\n\\\n让知识在人与AI之间高效流动] [53AI Studio\\\n\\\n高准确率的企业级智能体开发平台] [53AI Hub开源\\\n\\\n三分钟搭建出独立的企业AI门户] [53AI Browser\\\n\\\n“AI专家”效率倍增的秘密武器\\\n\\\n敬请期待...] \n\n[行业案例] [场景案例] \n\n[前沿技术] [Agent框架] [行业应用] [企业落地] \n\n[公司介绍] [渠道合作] \n\n53AI知识库\n\n学习大模型的前沿技术与行业应用场景\n\n[立即咨询] [预约演示] \n\n[首页] [AI知识库] [前沿技术] [RAG技术] \n\n我要投稿\n\n# 【AI大模型应用开发】以LangChain为例：从短期记忆实战，到如何让AI应用保持长期记忆的探索\n\n发布日期：2024-05-05 08:06:56浏览次数： 5521\n\n作者：同学小张\n\n微信搜一搜，关注“同学小张”\n\n在AI应用中，无论是多轮对话场景、RAG场景还是AI Agent场景中，记忆能力都是不可或缺的一部分。然而，记忆能力是目前大模型的短板，所以，现在很多框架，诸如 LangChain、MetaGPT 等，都封装了自己的记忆模块，以方便开发者实现自己大模型应用的记忆功能。\n\n之前我们简单概览了一下 LangChain 的 Memory 模块，那只是在多轮对话场景中，简单的取最近几次的对话历史作为记忆。这是最简单的使用记忆的方法，也是短期记忆的一种。\n\n本文我们来系统看下实现大模型应用记忆的方法，包括短期记忆和长期记忆。还是以LangChain为例来进行实战。\n\n# 0\\. LangChain中 Memory 实战\n\n> 我这里将记忆简单理解为对话历史，查询历史等历史记录。\n\n## 0.1 记忆封装罗列\n\n在 LangChain 中提供了多种获取记忆的封装，例如 `ConversationBufferMemory`、 `ConversationBufferWindowMemory`、 `ConversationTokenBufferMemory` 等。\n\n简单罗列如下：\n\n- •\xa0`ConversationBufferMemory` 可以理解为通用的将全部的历史记录取出来。\n\n- •\xa0`ConversationBufferWindowMemory` 可以理解为滑动窗口，每次只取最近的K条记录。\n\n- •\xa0`ConversationTokenBufferMemory` 可以理解为控制每次取的历史记录的Token数。\n\n- •\xa0`ConversationSummaryMemory`: 对上下文做摘要\n\n- •\xa0`ConversationSummaryBufferMemory`: 保存 Token 数限制内的上下文，对更早的做摘要\n\n- •\xa0`VectorStoreRetrieverMemory`: 将 Memory 存储在向量数据库中，根据用户输入检索回最相关的部分\n\n- •\xa0`ConversationEntityMemory`：保存一些实体信息，例如从输入中找出一个人名，保存这个人的信息。\n\n- •\xa0`ConversationKGMemory`：将历史记录按知识图谱的形式保存和查询\n\n\n> 这里面的大部分记忆封装，之前咱们已经学习过了，这里不再重复。详细的使用教程可以参考我之前的文章： [【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战+细节）] 。\n\n下面看下\xa0`VectorStoreRetrieverMemory`\xa0的使用和实现效果。\n\n## 0.2 实践：VectorStoreRetrieverMemory的使用\n\n### 0.2.1 完整代码\n\n```\nfrom\xa0langchain.memory\xa0importVectorStoreRetrieverMemoryfrom\xa0langchain_openai\xa0importChatOpenAIfrom\xa0langchain.embeddings.openai\xa0importOpenAIEmbeddingsfrom\xa0langchain.vectorstores\xa0importChromafrom\xa0langchain.chains\xa0importConversationChainfrom\xa0langchain.prompts\xa0importPromptTemplatevectorstore\xa0=Chroma(embedding_function=OpenAIEmbeddings())retriever\xa0=\xa0vectorstore.as_retriever(search_kwargs=dict(k=1))memory\xa0=VectorStoreRetrieverMemory(retriever=retriever)memory.save_context({"input":"我喜欢学习"},{"output":"你真棒"})memory.save_context({"input":"我不喜欢玩儿"},{"output":"你可太棒了"})PROMPT_TEMPLATE\xa0="""以下是人类和\xa0AI\xa0之间的友好对话。AI\xa0话语多且提供了许多来自其上下文的具体细节。如果\xa0AI\xa0不知道问题的答案，它会诚实地说不知道。以前对话的相关片段：{history}（如果不相关，你不需要使用这些信息）当前对话：人类：{input}AI："""prompt\xa0=PromptTemplate(input_variables=["history","input"],\xa0template=PROMPT_TEMPLATE)chat_model\xa0=ChatOpenAI()conversation_with_summary\xa0=ConversationChain(\xa0\xa0\xa0\xa0llm=chat_model,\xa0\xa0\xa0\xa0prompt=prompt,\xa0\xa0\xa0\xa0memory=memory,\xa0\xa0\xa0\xa0verbose=True)print(conversation_with_summary.predict(input="你好，我叫同学小张，你叫什么"))print(conversation_with_summary.predict(input="我喜欢干什么？"))\n```\n\n### 0.2.2 代码解释\n\n（1）代码中我们使用了\xa0`VectorStoreRetrieverMemory`\xa0作为记忆存储和获取的模块。它既然是向量存储和查询，所以接收参数： `retriever=retriever`，必须要穿给它一个向量数据库才能工作。\n\n（2）然后使用了\xa0`ConversationChain`\xa0作为对话的Chain。它接收一个\xa0`memory = memory`\xa0参数设置，指定使用的记忆类型。默认是最普通的\xa0`ConversationBufferMemory`\xa0类型。\n\n（3）什么时候会去检索记忆呢？在Chain运行 invoke 的一开始，就加载了。源码如下：\n\n可以看到，最后就是用用户的输入，去向量数据库中检索相关的片段作为需要的记忆。\n\n### 0.2.3 运行效果展示\n\n第一个问题，检索到的内容不相关，但是也得检索出一条。\n\n第二个问题，检索到的内容相关，用检索到的内容回答问题。\n\n# 1\\. 如何让AI应用具备长期记忆？\n\n> 我这里将“长期记忆”理解为持久化记忆或者长上下文记忆。也就是两种形式的记忆我都认为是“长期记忆”：\n>\n> - •\xa0第一种：持久化记忆，对话历史等历史记录持久化保存，不会随着进程的退出而消失。例如保存成功文件或存储进数据库等。\n>\n> - •\xa0第二种：长上下文记忆，当历史记录特别多时，如何从历史记录中找出有用的记忆，而不是只关注最近的几条历史记录。\n\n## 1.1 LangChain 中的记忆模块是否具有长期记忆的能力？\n\n上面罗列的和实战的 LangChain 中的记忆模块， `ConversationBufferMemory`、\xa0`ConversationBufferWindowMemory`、 `ConversationTokenBufferMemory`\xa0看起来都无法实现长期记忆的能力：无法持久化（看源码，底层都是一个List类型，保存到内存，随着进程消亡而消亡），也没法查询长的上下文。\n\n`ConversationSummaryMemory`、 `ConversationSummaryBufferMemory`\xa0在一定程度上能提供更多的记忆信息（因为其对之前的历史记录做了总结压缩），所以在某些上下文不是特别长的场景中，还是可以用一用来实现简单的长期记忆能力的。\n\n`ConversationEntityMemory`、 `ConversationKGMemory` 一个只保存实体信息，一个将历史记录组织成知识图谱，会对长上下文场景中的长时记忆功能非常有用。它可以从全局的角度将用户提问中的实体或相关知识作补充，而不是关注最近的几次对话。\n\n`VectorStoreRetrieverMemory` 应该是最好和最能实现长期记忆能力的类型了。一方面，它是向量数据库存储，可以方便的持久化数据，另一方面，它的向量检索能力，本来就是针对用户提问检索出最相关的文档片段，不受长上下文的窗口限制。但是其检索的相关片段之间是否存在信息缺失等，会影响长时记忆的准确性，从而影响最终的结果。\n\n> 所以， `ConversationEntityMemory`、 `ConversationKGMemory`\xa0+\xa0`VectorStoreRetrieverMemory`\xa0是否可以一试？三者结合，保持相关片段的相关性，同时利用实体关系和知识图谱进行补充，是否可以更好地实现长时记忆的能力？感兴趣的可以一起讨论~\n\n## 1.2 关于让AI应用具备长期记忆的一些研究\n\n### 1.2.1 记忆思考：回忆和后思考使LLM具有长期记忆\n\n> 论文原文：Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory\n\n这篇文章提出了一种名为TiM（Think-in-Memory）的记忆机制，旨在使LLM在对话过程中保持记忆，存储历史思考。TiM包括两个关键阶段：在生成回复之前，LLM从记忆中回想相关思考；在生成回复之后，LLM进行后思考并将历史和新思考结合起来更新记忆。\n\n下图描述了TiM方法的使用方式：\n\n（1）在回答第二个问题时，需要考虑问题1的内容，从问题1中推理出答案，而后在回答问题2。 （2）在回答第三个问题时，需要同时考虑问题1和问题2，从问题1和问题2中推理出答案，而后再回答问题3。\n\n这就导致了问题的存在：问题1被推理了两遍，两遍的结果还可能不一样，导致最终的错误。\n\n而TiM的思路，是将每一个问题的思考也存起来，这样，在回答问题3时，可以使用问题2之前的思考，避免重新思考问题1，从而避免多次思考结果不一致导致的错误。\n\n具体步骤如下：\n\n总的原理是，将相关的记忆放到一起，例如上图中，关于book的谈话放到index 0中，关于moive的谈话放到index 1中。\n\n如何将相关内容放到一起的？论文中实现了一种基于局部敏感哈希（LSH）的存储系统，用于高效地存储和检索大规模的向量数据。LSH的作用是将每个向量映射到一个哈希索引，相似的向量有更高的概率被映射到相同的哈希索引。\n\n而相同的哈希索引可以将用户问题固定到某一块记忆中，然后只在这一块记忆中进行向量检索，大大提高了检索效率。\n\n> 这篇文章还是值得精读一下的，数据的组织方式和索引方式都比较高级，很有启发。\n\n### 1.2.2 递归总结在大型语言模型中实现长期对话记忆\n\n> 论文原文：Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models\n\n这篇文章提出了一种递归总结的方法，用于增强大模型的长期记忆能力，以解决在长对话中无法回忆过去信息和生成不一致响应的问题。该方法首先刺激LLM记忆小的对话上下文，然后递归地使用先前的记忆和后续的上下文生成新的记忆。\n\n其流程如下：\n\n简单概括，就是：上一轮的内容总结 \\+ 本轮的问题回答 = 本轮的内容总结。本轮的内容总结 \\+ 下轮的问题回答 = 下轮的内容总结。...... 不断迭代。与 LangChain中 `ConversationSummaryMemory`\xa0的实现很类似。\n\n> 这种方法每一轮都要总结一次，也就是调用一次大模型，使用成本很高啊...... 实际生产中应该落地比较难。\n\n分享：\n\n53AI，企业落地大模型首选服务商\n\n**产品**：场景落地咨询+大模型应用平台+行业解决方案\n\n**承诺**：免费POC验证，效果达标后再合作。 **零风险落地应用大模型**，已交付160+中大型企业\n\n[上一篇：RAGFlow：基于OCR和文档解析的下一代 RAG 引擎] [下一篇：RAGFlow（2）：集成深度文档理解能力的RAG引擎] \n\n[返回列表] \n\n相关资讯\n\n[2025-12-01\\\n\\\nMCP与数据库的完美结合] [2025-11-30\\\n\\\nKnowEval：RAG 工程化的最后一公里，让问答质量有据可依] [2025-11-30\\\n\\\n大模型文本分类：从原理到工程落地（含代码）] [2025-11-29\\\n\\\nRAG 只是 AI 的上半场，OmniThink 才是类人的真思考（深度）] [2025-11-28\\\n\\\n详解用Palantir AIP几分钟搭建一个文档智能搜索应用] [2025-11-27\\\n\\\n从检索增强到自主检索：构建可行动的 Agentic RAG 系统] [2025-11-27\\\n\\\nRAG被判死刑：Google用一行API架空工程师！] [2025-11-27\\\n\\\n目前较优的知识库解决方案] \n\n[了解更多] \n\n[了解更多] \n\n160+中大型企业正在使用53AI\n\n[立即咨询] [预约演示] \n\n[把握AI发展的机遇，共同探索、共同进步\\\n\\\n2025-01-22] [如何打造基于GenAI的员工服务机器人\\\n\\\n2025-01-22] \n\n热点资讯\n\n[RAG彻底爆了！一文掌握其效果优化的架构设计及核心要点\\\n\\\n2025-09-15] [万字长文详解腾讯优图RAG技术的架构设计与创新实践\\\n\\\n2025-09-08] [DeepMind爆火论文：向量嵌入模型存在数学上限，Scaling laws放缓实锤？\\\n\\\n2025-09-03] [关于多模态应用的几个疑问，以及多模态应该怎么应用于RAG？\\\n\\\n2025-09-10] [您应该为您的 RAG 系统使用哪种分块技术？\\\n\\\n2025-09-10] [Embedding与Rerank：90%的RAG系统都搞错了！为什么单靠向量检索会毁了你的AI应用？\\\n\\\n2025-10-04] [存算一体破局向量检索瓶颈，IBM放出王炸VSM：性能飙升100倍，能效碾压GPU千倍，RAG要变天？\\\n\\\n2025-09-30] [企业级 RAG 系统实战（2万+文档）：10 个项目踩过的坑（附代码工程示例）\\\n\\\n2025-10-11] [总结了 13 个 顶级 RAG 技术\\\n\\\n2025-10-12] [通过两个案例，看RAG如何解决大模型的“知识短板”\\\n\\\n2025-09-08] \n\n大家都在问\n\n[RAG知识库迎来大洗牌：GraphRAG如何让机器真正读懂世界？\\\n\\\n2025-11-23] [再谈RAG的文档解析——文档解析的难点在哪里？\\\n\\\n2025-11-20] [为什么RDF是AI系统的“天然知识层”？\\\n\\\n2025-11-19] [大模型生态的“不可能三角”：规模化应用的架构困境？\\\n\\\n2025-11-04] [Embedding与Rerank：90%的RAG系统都搞错了！为什么单靠向量检索会毁了你的AI应用？\\\n\\\n2025-10-04] [存算一体破局向量检索瓶颈，IBM放出王炸VSM：性能飙升100倍，能效碾压GPU千倍，RAG要变天？\\\n\\\n2025-09-30] [您应该为您的 RAG 系统使用哪种分块技术？\\\n\\\n2025-09-10] [关于多模态应用的几个疑问，以及多模态应该怎么应用于RAG？\\\n\\\n2025-09-10] \n\n热门标签\n\n[内容创作] [大模型技术] [个人提效] [langchain] [llamaindex] [多模态技术] [RAG技术] [智能客服] [知识图谱] [模型微调] [RAGFlow] [coze] [Dify] [Fastgpt] [Bisheng] [Qanything] [AI+汽车] [AI+金融] [AI+工业] [AI+培训] [AI+SaaS] [提示词框架] [提示词技巧] [AI+电商] [AI面试] [数字员工] [ChatBI] [AI知识库] [开源大模型] [智能营销] [智能硬件] [智能化改造] [AI+医疗] [MaxKB] \n\n[应聘简历请发送至： ceo@53ai.com] \n\n联系我们\n\n售前咨询\n\n[186 6662 7370] \n\n预约演示\n\n[185 8882 0121] \n\n微信扫码\n\n添加专属顾问\n\n回到顶部\n\n加载中...\n\n扫码咨询\n\n[预约演示] [微信咨询] [电话咨询]', 'doi': '', 'published_date': '2024-05-05T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.53ai.com/news/RAG/1732.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 17:13:51,529 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:05:58,354 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 20:05:58,356 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, search_type=None
2026-02-02 20:05:58,364 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 20:05:58,365 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, search_type=None
2026-02-02 20:05:58,374 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 20:05:58,374 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, search_type=None
2026-02-02 20:06:01,267 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 20:06:01,267 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 20:06:01,953 - __main__ - INFO - handle_search: returned=1
2026-02-02 20:06:01,954 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=1
2026-02-02 20:06:01,954 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 20:06:02,586 - __main__ - INFO - handle_search: returned=1
2026-02-02 20:06:02,587 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=1
2026-02-02 20:06:02,587 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.999979, 'save_path': None}}
2026-02-02 20:06:40,127 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:06:40,128 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.999979, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:06:40,128 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=1, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:06:40,128 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=1, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:06:40,129 - __main__ - INFO - handle_download: downloaded=1
2026-02-02 20:06:40,129 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=1
2026-02-02 20:06:40,129 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.999979, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ....md'}}
2026-02-02 20:17:04,198 - __main__ - INFO - call_tool: name=tavily_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 20:17:04,199 - __main__ - INFO - handle_search: searcher=TavilySearch, query=langchain 中短期记忆管理的最佳实践是什么？, search_type=None
2026-02-02 20:17:04,241 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 20:17:04,241 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=langchain 中短期记忆管理的最佳实践是什么？, search_type=None
2026-02-02 20:17:04,294 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': 'langchain 中短期记忆管理的最佳实践是什么？'}
2026-02-02 20:17:04,294 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=langchain 中短期记忆管理的最佳实践是什么？, search_type=None
2026-02-02 20:17:07,154 - __main__ - WARNING - handle_search: returned=0 for query=langchain 中短期记忆管理的最佳实践是什么？
2026-02-02 20:17:07,154 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=0
2026-02-02 20:17:10,321 - __main__ - INFO - handle_search: returned=10
2026-02-02 20:17:10,321 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 20:17:10,321 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 20:17:14,182 - __main__ - INFO - handle_search: returned=10
2026-02-02 20:17:14,182 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=10
2026-02-02 20:17:14,183 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': '# 【EP04_短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1.x全家桶LangChain+LangGraph+DeepAgents分享\n## 南哥AGI研习社\n2980 subscribers\n4 likes\n\n### Description\n60 views\nPosted: 16 Jan 2026\nYouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下：        \nGitHub地址: https://github.com/NanGePlus/LangChain_V1_Test      \nGitee地址: https://gitee.com/NanGePlus/LangChain_V1_Test        \n\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力                    \n个人项目GitHub地址：https://github.com/NanGePlus                    \n个人项目Gitee地址：https://gitee.com/NanGePlus                                 \n大模型代理平台: https://nangeai.top/          \n\n【章节】\n\n0:00 引言 源代码下载方式\n0:37 核心功能\n1:37 核心概念介绍\n8:37 准备工作和项目初始化\n13:27 InMemorySaver测试和源码\n18:16 PostgresSaver测试和源码\n21:33 管理策略测试和源码\n24:05 最后 总结\n\n频道项目&视频推荐：\n1. 8n自动化工作流平台相关分享          \nhttps://github.com/NanGePlus/N8NWorkflowsTest       \n\n2. 大模型应用技术开发-入门系列            \nhttps://github.com/NanGePlus/LLMsBasisDevelopment               \n          \n3. 大模型应用技术开发-MCP系列\nhttps://github.com/NanGePlus/MCPServerTest               \n\n4. 大模型应用技术开发-RAG系列                                  \nhttps://github.com/NanGePlus/RagWithMilvusTest                  \nhttps://github.com/NanGePlus/LightRAGTest                          \nhttps://github.com/NanGePlus/KagTest                      \n\n5. 大模型应用技术开发-Agent系列                       \nhttps://github.com/NanGePlus/ReActAgentsTest                      \nhttps://github.com/NanGePlus/CrewAIFlowsFullStack                        \nhttps://github.com/NanGePlus/AutoGenV04Test                  \n      \n6. 大模型应用技术开发-Fine-Tuning大模型微调系列        \nhttps://github.com/NanGePlus/FineTuningLab\n\n5 comments\n### Transcript:\n大家好 我是坚持AGI知识开源分享的南哥 所有源文件免费提供 本期视频为大家分享的是 如何在LangChain最新版本V1版本中 实现Agent的短期记忆功能 包括短期记忆持久化存储和管理策略 以及中间件 那本期视频涉及到的源码 操作说明文档等全部资料 都是开源分享给大家的 大家可以在本期视频置顶评论中 获取免费资料链接进行下载 那也希望大家对我本期视频点点赞 你们的点赞就是对我最大的支持 如果大家还没有关注我的 也可以点一下关注 那后面我所有的分享 你们都会及时的收到 那本期用例的核心功能主要包含 第一块 是关于短期记忆持久化存储的 两种方式 这两种方式 一个是基于内存的短期记忆临时存储 它主要是用来在大家平常测试 开发中可以去使用 那第二种方式呢 是建议在生产上去使用的 就是基于数据库的 短期记忆持久化存储 那本期视频给大家分享的用例 我们都会给大家去演示这两种方式 那第二块呢 是关于短期记忆管理策略 那这边也会给大家介绍两种策略 那这两种策略呢 主要是来控制上下文窗口的大小的 那还有一个 就是内置中间件 和自定义中间件的使用 那这一块呢 就是因为我们要给大家去介绍 这个短期记忆管理策略 这两种方式 那这两种方式呢 在LangChain这个生态里面使用的 就是通过中间件的方式去使用的 所以这边的话也会给大家去介绍 如何去使用LangChain 内置的预置的中间件 以及我们如何自己去定义一个中间件 去使用 那关于这两种管理策略 一个是修剪消息 一个是消息摘要 那在接下来实操演示的环节中 也会给大家具体去介绍 好下面的话 就给大家介绍一下基本的概念 第一块是短期记忆持久化存储 短期记忆允许应用程序 在单个对话线程内 记住之前的交互对话历史 是最常见的短期记忆形式 那在LangChain里面 它是通过一个线程ID 那一般我们会使用会话ID 来作为线程ID 那在一个会话里面 所有的对话内容 是作为短期记忆进行存储的 那要为Agent添加短期记忆 需要在创建Agent时指定checkpoint参数 那这边提供了两种方式 那第一种方式呢 是基于内存的存储 它的作用是 把Agent的状态保存在进程内存里 进程重启或实例销毁后 数据就丢失 主要的特点是无需额外依赖开发环境 本地调试非常方便 读写速度快 但不支持跨进程跨服务共享 也不能在服务重启后恢复进程 那这一块呢 大家可以理解为 只有你运行了当前的这个程序之后 只有在当前你所运行的这个进程里面 它所保存的所有的短期记忆的内容 只对当前这个进程是有效的 一旦你把这个进程给关掉 那它的保存的数据就全部会丢失 所以它是一个不能跨进程存储 那还有一种方式呢 是可以去把Agent的状态持久化 到Postgresql数据库中 可以跨进程跨实例共享 并在重启后恢复对话 线程 那这块大家可以这么理解 就是把所有的短期记忆的内容 全部持久化 存储到Postgresql数据库之后 那对于应用程序来说 不管你开了多少个端口 也就是不管你开了多少个进程 那对于每个进程内 都是可以访问到Postgresql数据库的 短期记忆数据的 那它的主要特点是适合生产环境 有可靠持久化和并发访问能力 需要维护Postgresql实例 引入一定运维成本 那这里面有两个概念 大家要注意区分一下 不要混淆 第一个就是这里面刚刚提到了进程 那这个进程大家可以理解就是 你启动一个应用程序 就是一个进程 那还有个 我们在前面给大家介绍 这个短期记忆的时候 它是基于在会话线程里的持久化 所以这里面要有一个线程 那如何去理解这个线程呢 在LangChain框架里面 它分为短期记忆和长期记忆 那对于短期记忆 它就是基于会话线程进行的持久化 所谓的线程就是LangChain这个框架 它在设计使用checkpoint 去保存短期记忆内容的时候 那checkpoint它有一个唯一的ID 那这个ID呢 就是使用线程ID 来作为它的为ID进行存储的 那一般在工程实践里面 也就是我们实际的项目中 我们一般会使用某一个用户 所创建的会话ID 作为线程ID 把它存到checkpoint里面去 那还有一块是长期记忆 在LangChain这个框架里面 长期记忆它其实是可以跨线程的 也就是我一个用户 我创建了10个会话 那在这个10个会话里面 我在任意一个会话里面 都是可以去拿取长期记忆里面的内容 来在当前的某一个会话里面 去进行问答的 那这一块呢 我们在下一期视频 也会给大家去分享到 如何在LangChain这个框架里面 去实现长期记忆 那第二块的核心概念 是关于短期记忆管理策略 那这边会给大家提供两种策略 那这两种策略都是为了解决对话太长 超过上下文窗口的问题 但思路完全不同 那第一个管理策略是修剪消息 它的主要作用是在调用大模型之前 直接删除对话历史中的部分消息 比如只保留最近几条 让整体消息数量或长度降下来 它主要的特点是实现简单 成本最低 不需要再调一个大模型来进行摘要 生成 被删除的消息 原文和消息都真正丢失 后续模型完全看不到那一段历史 适合对很久以前的细节不重要 最近几轮才关键的场景 例如闲聊简单问答 那这一块功能的在用例中的实现 我们会去使用自定义一个中间件 来去实现这部分的功能 那第二块呢 是消息摘要 它的主要作用是当历史消息太长时 用一个聊天模型 把早期的对话压缩成摘要 再用这段摘要替换早期原始信息 同时保留最近若干条原文消息 主要特点是更智能 尽量保留早期对话中的关 键信息设定和事实 只是变成浓缩版 需要额外的大模型调用 有一定额外延迟与费用 适合需要长期记住用户偏好 背景设定前文事实的应用 比如复杂的助手长任务协作等 那关于这一块功能的实现 会去使用LangChain 它提供了内置的中间件 我们直接去使用就可以了 好下面给大家介绍一下 什么是LangChain中的中间件 在LangChain中 中间件是预构建的生产级组件 可根据具体需求进行配置 用于处理Agent开发中常见问题 在LangChain中主要分为两大类 第一大类是LangChain官方 它内置的一些 已经帮大家实现好的中间件 那对于这些中间件 大家可以直接去使用的 那还有一种 就是开放了一个自定义的接口 就是大家可以去自定 自定义你自己的中间件 那第一个是关于内置的中间件 LangChain提供了15种 适用于所有大模型提供商的中间件 我把所有的中间件分了一个类别 那首先第一个类是对话管理类 主要有两个中间件 一个是摘要化中间件 一个是上下文编辑中间件 那关于摘要化中间件 本期视频也会给大家去使用 它是当接近TOKEN限制时 自动压缩对话历史 保留最近的消息 那第二个类别呢 是执行控制类 主要包含模型调用限制工具调用限制 人机协作中间件 那关于人机协作 我们在后面视频也会给大家分享 关于这一块的功能 那第三个类别呢 是容错与重试类 包括模型 降级工具重试 模型重试 那第四类呢 是安全与合规类 那它主要是这个PII检测 它主要是检测和处理 对话中的个人身份信息 支持编辑、掩码、哈希、阻止等策略 那这个其实也是一个在你实际项目中 比较常用 也比较重要的一个中间件 那第五个类别呢 是任务规划类 待办事项列表 第六个类别呢 是工具优化类 大模型工具选择器 大模型工具模拟器 第七个类别是开发工具类 包括shell工具 文件搜索工具 那第八个呢 是特定供应商中间件 就是除了前面给大家介绍的 适用于所有大模型提供商的中间件 那对于特定的大模型厂商 也有特定的中间件 比如说Anthropic提供提示缓存 bash工具 文本编辑器内存和文件搜索中间件 那对于OpenAI 就是提供了内容审核中间件等 那第二种呢 就是自定义中间件 中间件 通过在Agent执行流程中的特定节点 实现钩子函数来拦截执行 中间件提供两种类型的钩子 那节点式钩子和包装式钩子 那这块的话 我们会使用这个节点式钩子 也就是使用这里面所提供的钩子 我们来去实现自定义的中间件 那关于中间件的介绍 大家可以到它的官方文档里面 有非常详细的描述 大家去参考 那这边的话 我只是简单给大家罗列一下 那接下来就来给大家实操 那关于实操部分的第一块和第二块 也就是准备工作和项目初始化 这边我就不给大 家重复去介绍了 大家可以去看我本期合集 也就是这个系列的第二期视频 就是有一个LangChain的快速入门用例 那期视频 里面有非常详细的构建的过程 那我把这个视频也放在这个地方了 大家可以先去看那期视频 那本期视频 也是在那期视频的基础上 我们进行了迭代 那关于这个系列 已经给大家分享了一二三四 四期的内容了 那我们的每一期的功能 都是基于上一期的内容的基础上 进行迭代的 所以大家在学习本期视频 那有一些 关于前几期 已经给大家分享过的一些功能 我就不给大家重复去介绍了 包括源码的分享等等 我都不给大家重复去介绍了 大家可以去看一下我前面几期的视频 下面我们就直接进入到 我们项目工程里面来 那对于本期视频给大家提供的源码 大家可以在我的视频置顶评论中 获取到下载链接 大家把源码下载下来 下载完成之后 只要复制粘贴到 本期项目的根目录下面 就可以了 那本期视频所对应的文件夹 就是04这个文件夹 那在目录里面呢 大家可以打开这个操作文档 那在这个操作文档 我们可以继续往下 那首先的话 我们就是来安装一下环境 因为我们本期视频会用到checkpoint 所以这边的话 我们需要去安装一个依赖包 那这个依赖包的话 我这边也提供给大家 大家只要去复制去安装一下就可以了 那这边的话 我就先来给大家安装一下那 这边我们打开我们的命令行终端 直接去安装这个包 那关于它的版本的话 大家可以先使用我提供给大家的版本 好那这边安装完成之后的话 我们就来给大家实操演示一下 那在给大家去测试用例之前呢 我们还是先把所有的需要用到的服务 全部安装好 那这边的话 因为我们要去使用Postgresql 去进行持久化的存储 所以这边我们需要去安装 和部署一个Postgresql数据库服务 那这边的话我是使用Docker的方式 那关于Docker的方式如何去安装 那这边的话我先给大家来演示一下 首先大家一定要去下载一个Docker 那关于Docker的下载 大家只要进入到这边 我给大家放了一个它的官网 进入到官网之后 根据你自己的所使用电脑的操作系统 你去下载对应版本的Docker的 安装包 那安装包安装完成之后 大家会看到 你的桌面上 会多一个叫Docker Desktop这样的一个软件 那这个软件呢 大家只要把它双击打开 打开之后 大家看到就是这样的一个页面 那这块的话 就可以去使用你的Docker服务 那关于这个Postgresql服务的安装 大家只要进入到我这边 我这边提供给大家的一个Docker文件 那在这个Docker文件里面 大家只要去执行这个命令就可以了 那这边的话我先来给大家去运行一下 那这边大家首先 你要进入到这个Docker配置文件 所在的文件目录 那是在我们当前的这个文件 夹下面的 好我只要去运行这个指令就可以了 那这边的话 大家只要等待 它把Postgresql这个镜像文件 拉取到你的本地仓库 并且会帮你自动去运行一个容器 那这个容器呢 就会是在这个地方 大家就会看到 会帮你去开启一个容器 那也就是 会帮你去把这个服务给部署好 并且我们就可以去 直接使用Postgresql这个服务了 好 那这边大家可以看到它已经完成了 那完成之后呢 我这边会多一个Postgresql的一个服务 并且我本地的镜像 大家可以看到 在这个postgres这个地方 我会也去把这个Postgresql这个镜像 也会拉取到我的本地仓库 好这个时候 我们就可以直接去使用这个Postgresql 数据库 那关于Postgresql数据库的操作 这边我提供了一个客户端软件 给到大家 大家可以去下载 那这是一个开源免费的 当然你也可以用你自己的数据库 客户端软件 也是可以的 那这边的话 大家只要打开这个客户端软件 在这边直接去新建一个连接 选择Postgresql 然后去填写这个对应的 对应的主机的名称以及数据库 那这边的话 如果说你是使用 我提供给大家的Docker配置文件的话 那这边呢 数据库大家默认的 我默认的是postgres 包括它的用户名和密码都是 所以 这边大家只要填写对应的这个密码 然后点击这个测试连接 那比如说这边给大家测一下 你就可以点击测试连接 那这边的话它会提示你连接成功那 之后的话你就可以直接点击完成 那完成之后呢 这边就是你的postgres数据库 里面的一些表 你就可以在这个地方 去进行相关的一个一个查询 那大家在第一次安装的时候 是不存在这些表的 那是因为我有历史数据在本地 所以我这边会给大家演示的时候 会把它给清除掉 那大家第一次登录 登录进来之后 你这个表是空的 好那接下来的话 我们就来继续往下来 给大家去把每个脚本都给测试一下 那首先 我们先来给大家测试第一种方式 也就是基于内存的存储的 那它对应的是在这个脚本 我们先把这个脚本给打开 好 接下来我们先来运行一下这个脚本 那在运行这个脚本的时候 大家要注意 首先你要进入到脚本所在的文件夹 那我们是在这个04这个文件夹 根目录下面 那再一个呢 大家在运行之前 需要去设置你的大模型的APIKEY 那这边的话根据大家自己的选择 你要去修改你的URL地址以及APIKEY 那如果说你是使用我的代理平台的话 那URL地址你可以不变 那这边的APIKEY 大家只要登录到这个管理平台 这个大模型代理平台 大家去申请一个令牌就可以了 那这个令牌的话大家只要去复制 那复制完成之后 大家只要去粘贴在这个地方就可以了 那接下来我们就来运行一下这个脚本 好我们还是先运行一下 我们先看一下现象 然后再读一下源码 那我们先来 运行一下第一个 首先我们先来看一下 它打印出来的日志信息 那关于第一个第一轮的问答 用户的问题是杭州的天气怎么样 那最终Agent的回复是 把杭州的相关的信息 按照我们结构化的输出进行了打印 那这个例子呢 跟前面给大家分享的几期使用的例子 是同一个例子 那第二个问题呢 是我问的是 我刚才问的是哪个城市的天气 那我刚才问的是杭州的天气 所以他这边会回复我 我的名字 因为我告诉他我的名字是谁 然后你刚才问的是杭州的天气 所以这个时候大家可以看到 他是知道我上一轮的问答的内容的 他基于我上一轮的问答的内容 来回复我 第二个问题 好再看第3个问答 那第三个问答 我问的还是同样的问题 我刚才问的是哪个城市的天气 那这个时候我们看他的回答 他这个时候他回答的是 我问的是北京的天气 那我明明问的是杭州的天气 但是他在最后一轮的时候 告诉我是问的北京的天气 那这个是因为什么呢 首先我们看到这个现象 然后我们再来读一下这个源码 我们先来找到 我们三次调用大模型的地方 那在这个第一次问答 也就是在这一块的功能里面 我们来把它给找一下 那首先我们会去发送一个配置参数 那这个配置参数我们可以看一下 我们配置的是线程ID是1 是1 然后第二次 我们配置的这个线程ID也是1 然后我们第三次问 答的时候配置的线程ID是2 那现在ID不一样 其实代表的就是你当前这个用户 我其实问的3次问答 前两次是在同一个会话里 那第三次是在另外一个会话里 所以这个时候 前两次在同一个会话ID里面 他的上下文的信息 我是全部都能够拿到的 所以他知道 我问的是哪一个城市的天气 所以他告诉我是杭州的天气 因为我在上一轮问的 就是杭州的天气如何 那第三次问答 为什么他不知道我在杭州呢 是因为我新开启了一个会话 那新开启了一个会话之后 我的整个的上下文内容是空的 也就是我的没有上一轮对话 那这个时候 他为什么知道我是在北京呢 这个其实也不是他随便乱猜的 这个是因为 我们在在这个调用Agent的时候 我们传入了一个用户的ID 这用户ID的话 会到你的工具里面 去查询你当前所在的位置 所以他根据我这个ID 他知道我是1 我传入的是1 所以他知道我是在北京 所以他最后告诉我 我刚才问的是北京的天气 虽然说我没有问 但是他拿到了这个地址 然后他就去回了这样的一句 当然这个显然是不符合逻辑的 对吧这个 你是可以在你实际的业务过程中 通过prompt去把它 把他这个限制住的 就是给他一些规则 不要让他随便去回答 比如说像我现在问的这个问题 就是一个不存在的事情 他就是应该回答的是我不知道 或者就 是你还没有问关于某一个地方的天气 好 那下面的话我们就来看一下这个代码 它是怎么实现的 首先我们在这个用例里面呢 它是使用的是InMemory 这样的一个一种方式 那我们引入的话 也就是在这个地方 我们直接通过这个包 我们把相关的方法给引入进来 引入进来之后呢 我们只要在这个地方 去实例化一个checkpoint 那最后我们在创建Agent的时候 把checkpoint给配置在这个地方配置一下 那后面的话 我们只要再去进行每一次问答的时候 在这个配置参数里面 直接把线程ID把它带进去就可以了 那这个方式呢 它就是基于进程 当前进程的内存的 也就是我运行一次这个脚本 它这个脚本就是一次运行的进程 那在这个进程里面 它所有的数据 都是保存在 当前这个进程的内存里面的 一旦我这个进程 这个应用程序跑完了之后 它内存里面的数据就会消失 就会被清除 那你下次再运行的时候 它原先的数据是会被丢失掉的 所以它不是一个持久化存储的方式 那我们再给大家演示第二种方式 也就是使用Postgresql进行持久化存储 也就是对应的02这个代码 那下面的话我们先来给大家演示一下 那这边的话我就先把它清除一下 好我们还是来运行一下这个脚本 先来看一下现象 我刚刚复现了一个报错 那这个报错呢 也有朋友在评论区里面提过这个问题 那这个问 题的原因是什么呢 有两个因素 第一个因素是 你所选择使用的大模型的能力 本身不够强 它没有办法去进行格式化的 强制的输出 那还有一种情况呢 就是你的prompt给的提示不够的清晰 所以对于这种情况 首先大家一定要想着 先到你的prompt里面去添加一些规则 比如说我这边添加了一个规则 就是最终输出要以给定的JOSN 格式化进行输出 那你加了这句之后 你再去测试它 会明显的会变好 因为大模型本身是一个概率模型 所以它偶尔会有不确的 不确定的因素存在 那唯一能够解决它的办法 就是在prompt里面给它更多的提示 告诉它你应该要怎么样 那我把这边清掉之后 我再来重新跑一下 那在跑之前呢 因为在我的这里面已经产生了数据表 所以我 我先把这个数据表给给全部删掉 之后我再来重新跑一下 好 那我现在把这个里面的表全部清掉了 那我现在是一个空表 好下面的话我来跑一下 跑完之后呢 我们再来一起看一下现象 那这边日志信息 跟前面给大家演示的第一个脚本 展示出来的日志信息是一样的 因为我们三轮对话 跟上面给大家演示的 那个脚本的三轮对话 是一样的 那我们大家在运行完这个脚本之后 大家去刷新你这边的表 那刷新完成之后 大家可以看到会多四个表出来 那这个表就是存储 就是你的checkpoint 也就是它会以这个线程ID 因为我们每三轮的话 我们前两轮的话 是以线程ID一来存储的 那后面两轮呢是使用的是 后面的一轮使用的是2这个线程ID 所以这边的话会存储 每一轮中间的所有的对话的的过程 都会记录在这个checkpoint里面 那这个时候 如果说你还是接着线程ID为1的话 再去进行问答 那最后它所有的问答的对话的数据 都会记录在这个这张表里面 会一直往下追加 那它就会把你每一个会话里面的 所有的数据 都会把它记录下来 好那接下来我们就来看一下 它这个源码是如何实现的 那关于大模型每次的调用这一块 其实是没有任何的改变的 那唯一的改变就是在我们使用了 我们使用了这种持久化存储的方式 并且这边也是一样 我们需要去实例化一个checkpoint 拿到这个checkpoint之后呢 我们就会去把它配置到你的Agent 也就是在你在创建Agent的时候 把它配置到这个checkpoint 这个参数上面来就可以了 那这边的话 因为我们是要去使用Postgresql数据库 所以这边的话 我们是要去以这样的方式 去创建一个 数据库的检查点的存储器 那关于这个配置 我是把它写到了config 这个配置文件里面来 那在这一块的话 我们就会配置一个 Postgresql数据库的配置参数 那这边主要是根据 你自己所部署的Postgresql数据库服务 对应的参数来进行拼接就可以了 那最后一块呢 就是关于短期记忆的管理 策略 那这边提供了两个脚本给到大家 第一个是关于使用自定义中间件 实现的一个消息修剪 第二个呢 是使用LangChain内置的一个中间件 那首先先给大家看一下第一个吧 它的使用方式 大家只要在这个地方 把它这个方法给引入进来 引入进来之后 大家在创建Agent的时候 直接把它配置到这个中间件 这个参数里面就可以了 那这个方法有三个参数 那第一个参数是 你进行摘要生成的时候 使用哪一个Chat模型 所以这边你需要去配置一个Chat模型 那第二个呢是它的一个触发 触发的话就是当累计TOKEN数超过4,000时 启动一次对历史消息做摘要 那第三个参数呢 是一个保留的这个消息的条数 也就是你前面生成了摘要之后 那关于最近三条数据 你是在某一次具体的对话里面 他会把最新三条消息 以及前面生成的摘要的消息 一起给到Agent 去进行相关的 作为他的一个上下文内容 那另外一个脚本就是我们使用LangChain 它提供给我们的自定义中间件的方法 来去定义了一个方法 那这个方法呢 我们其实也是通过它所提供的 这样的一个装饰器 通过这个装饰器呢 我们就可以定义一个函数 那在这个函数里面 我们主要就是做的功能逻辑 就是对它获取到所有的 这个当前会话里面 所有的消息 进行一个修剪 也就是我们可以控制 最终给到大模型去使用的消息 控制在多 少条所以这边的话 做了一个简单的一个逻辑 那这块每行代码都有注释 大家可以详细看一下这个逻辑 那这个函数这个方法定义好之后呢 我们只要去把这个方法 也是通过中间件的形式 把它加载到这个参数里面来 那对于当前所创建的这个Agent 它就可以在执行大模型调用之前 会去触发这个函数 因为我们使用的是这个装饰器 那这个装饰器代表了 就是在你调用模型之前 会先执行这段逻辑 那这段逻辑就是对你的上下文的消息 进行一个裁剪 那裁剪后的消息才会给到大模型 作为大模型的一个上下文的内容 去进行后续的一个回复的生成 那关于这两个脚本 我就不给大家实际去测了 大家可以自己去测一测 那在前面给大家演示的这两个脚本呢 我其实都给大家加了这个 短期记忆的管理策略 在的这个边给大家看一下 也就是我们在定义Agent的时候 那在这个地方呢 我默认是把这个这种方式的 把它给加载进来了 所以我这两个脚本使用的都是它 当然你可以根据你自己实际情况 你自己去做相应的调整 好那本期视频就为大家分享到这里 如果大家觉得对你有所帮助的话 也希望大家对本期视频点点赞 你们的点赞就是对我最大的支持 那本期视频就到这里 我们下期视频见', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.999979, 'save_path': None}}
2026-02-02 20:17:57,381 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南', 'authors': [], 'abstract': 'Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南 - 知乎[] \n\u200b[直答] \n切换模式登录/注册\n# Multi-Agent系统构建初探：基于LangGraph的长短期记忆管理实践指南\n[![腾讯技术工程]] \n[腾讯技术工程] [\u200b![]] \n编程话题下的优秀答主作者：adacyang\n> 如何让AI智能体（Agent）像人类一样拥有持久的记忆，从而在复杂的连续任务中保持上下文感知和深度理解？这已成为构建高级智能体的核心挑战。本文将深入探讨Agent Memory的核心概念，并聚焦于\n> LangGraph\n> 框架下的长短期记忆实现，详解短期会话与长期知识的存储、管理、语义检索等技巧。更进一步地，我们将通过一个引入> MCP协议\n> 的实战案例，手把手带你构建一个真实的融合长记忆机制的Multi-Agent系统，直观展示中断、记忆与协作的融合。\n基于大语言模型（LLM）的智能体（Agent）系统中，记忆机制是实现持续、连贯和个性化交互的核心基石，通过记忆，可以让Agent记住过往的交互，保持上下文的一致性，并能从反馈中学习，适应用户的偏好。\n**本文核心要点概述：**\n1.介绍Agent Memory的基本情况\n2.LangGraph长短期记忆详解及案例说明：包含短期记忆实现、管理方法，长期记忆的实现方法，以及搭建了融合postgres数据库、集成Embedding服务进行语义搜索等可用于生产环境的真实案例。\n3.引入MCP协议构建真实的Agent长记忆应用：搭建一个基于supervisor架构，集成中断机制、长短期记忆机制的multi-agent系统。\n### **记忆机制介绍**\n### **Agent Memory是什么？**\n![] \n上图中（来源于Mem0[1]），左边是没有Memory的agent，右边是有Memory的agent，后者可以根据用户的过往信息（素食主义者、不喜欢乳制品）给出更合理的响应（不含乳制品的素食菜单），而前者的回答显然是不合适的。\n简单来说，Memory是赋予Agent记忆能力的技术和架构，能够让Agent像人一样记住过去的交互、学到的知识、执行过的任务及未来的计划，是将一个LLM转变为能够执行复杂、长期任务的真正”智能体“的核心所在。\n### **关于Agent Memory我们需要考虑什么？**\n如何获取记忆：通过和用户交互、环境交互...\n怎么组织记忆：模型参数、模型上下文、数据库怎么利用记忆：RAG、Few-shot...\n### **有哪些Memory类型？**\n关于Memory的分类，有许多种分类体系，这里我们只讨论最常见及最易于理解的。\n正如人类利用长短期记忆进行有效的交互和学习一样，Agent的记忆机制通常划分为短期记忆（short-term memory）和长期记忆(long-term memory)，短期记忆决定了Agent在微观任务上的即时表现，而长期记忆则作为持久知识库，决定了Agent在宏观时间尺度上的智能深度和个性化水平，通过两者配合，Agent才能表现出连贯性、上下文感知能力，才会显得更智能。\n### **Agent Memory如何工作？**\nAgent通常通过以下几步来有效地管理记忆，使得每次于用户的交互都更加精准智能：\n1. 记忆存储：通过设计一系列策略来存储重要的交互信息，这些信息可能来源于对话内容、历史数据或任务要求等等。2. 记忆更新：记忆会随着交互的发生，不断地进行更新，例如用户的偏好、最新的近况等等。记忆更新使得Agent能够不断优化其响应。\n3. 记忆检索：Agent根据当下的需求，去记忆中检索需要的记忆内容，从而提供更加智能的回复。### **Agent Memory怎么实现？**\n1. 物理外挂：即外置数据库和RAG，需要检索当前query相关的内容，例如：Mem0、ACE。好处是即插即用，坏处是不够end-to-end\n2. Memory as Reasoning / Tool：通过训练Reasoning或Tool的方式动态更新context，例如：MemAgent、memory-R1。好处是更接近end-to-end，但不是很灵活。\n3.参数更新：LLM本身就是一个Memory体，所有参数都是它的Memory，通过更新参数来更新记忆，这种方式是最本质的，但也是最难实现的。\n### **LangGraph中的记忆管理**\nLangGraph[2]作为一款面向多智能体协作与状态管理的框架，其设计了巧妙的记忆管理系统，旨在为Agent提供在不同交互中存储、检索和利用信息的能力。它区分了两种主要的记忆类型：短期记忆和长期记忆。在实际使用中，通过这两种记忆协同，既能保障实时任务的高效执行，又支持了跨任务、跨周期的经验复用。\n●short-term memory（通过Checkpointer实现）：针对单个对话线程，核心价值在于保障对话的临时性，使得Agent能够跟踪会话中的多轮对话，可以在该线程内的任何时刻被回忆。\n●long-term memory（通过Store实现）：可以跨对话线程共享，可以在任何时间，任何线程中被回忆，而不像短期记忆局限于单个对话。\n![] \n通过下表，可以更清晰的看到两者的区别：||short-term memory|long-term memory|\n目的|维持对话上下文|存储跨会话的持久化事实、偏好和知识|\n持久性|会话级别（可以临时，可以持久）|应用级别（始终持久）|\n作用域|单一会话|跨会话、跨用户|\n持久化方式|检查点（checkpoint）|存储（Store）|\n更新机制|自动（在每个图步骤后保存状态）|手动/显式|\n典型用途|对话历史、中间状态|用户偏好、知识库、语义记忆|\n![] ### **LangGraph记忆的架构基础**\n要想更好的理解LangGraph中的记忆机制，首先需要理解其支持双轨记忆系统的核心概念。\n### **Checkpointer**\nLangGraph有一个内置的持久化（Persistence）层，通过checkpointer实现，能够持久化存储图状态，这使得开发记忆功能和人类干预功能成为可能。\n当使用检查点编译一个图时，检查点会在每个super-step保存图状态的checkpoint，这些checkpoint被保存到一个thread中，可以在图执行后访问。因为threads允许在执行后访问图的状态，所以可以实现记忆、人机协作、时间旅行、容错等多种强大的功能。\n![] \n工作流程：```\n`用户输入 →[节点 1] →💾保存状态→[节点 2] →💾保存状态→输出↓↓Checkpoint 1 Checkpoint 2`\n```\n### **Thread**\n为了管理多个独立的对话，LangGraph使用了thread的概念。thread\\_id是由checkpointer保存的每个checkpoint的唯一id，是激活和区分不同对话线程的唯一key。在调用图的invoke或stream方法时，通过configurable字典传入一个thread\\_id，就代表这次操作属于thread\\_id这个特定的对话。\n### **Store**\n如上所述，图状态可以由checkpointer在每个super-step写入线程，从而实现状态的持久化。但是，如果想在多个线程之间保留一些信息的话，那么就需要用到Store。Store本质上是一个暴露给图节点和工具的键值数据库，与checkpointer的自动化快照不同，Store需要显式和主动的进行操作。\n![] ### **Namespace**\nStore中的数据通常通过更持久的标识来组织。user\\_id是最常见的，用于关联用户的所有信息，此外，namespace提供了一种数据隔离机制，例如，使用使用 (“memories”, user\\_id) 这样的元组作为命名空间，可以将用户的记忆与其他类型的数据（如用户偏好(“preferences”, user\\_id)）清晰地分离开来，避免数据冲突，保持知识库的整洁有序。\n### **短期记忆详解**\n### **InMemorySaver内存会话临时存储**\n对于开发、原型设计和测试阶段，最简单快捷的方式是使用InMemorySaver。它将所有的对话状态存储在内存中的一个Python字典里。\n1.**设置记忆管理检查点**\n```\n`from langchain\\_openai import ChatOpenAI\nfrom langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.prebuilt import create\\_react\\_agent\n# 初始化检查点保存器checkpointer = InMemorySaver()`\n```\n2.**定义大模型并创建agent**\n```\n`BASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nagent = create\\_react\\_agent(\nmodel=model,\ntools=[],\n# 传入检查点，是将持久化能力“注入”图的关键步骤。编译后的graph对象现在具备了状态管理的能力。\ncheckpointer=checkpointer\n)`\n```\n如果是底层自定义api在图构建阶段传入检查点的代码是graph = builder.compile(checkpointer=checkpointer)。\n3.**短期记忆-内存后端**\n```\n`config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;}} # 激活记忆机制的核心。如果没有提供thread\\_id，每次invoke调用都将是无状态的，只要使用相同的thread\\_id，LangGraph就会在多次调用之间维持对话状态\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(&#39;&#39;------------线程1------------------&#39;&#39;)\nprint(f&#34;&#34;thread1\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)\nnew\\_config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;2&#34;&#34;}}\nresponse = agent.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nnew\\_config\n)\nprint(&#39;&#39;------------线程2------------------&#39;&#39;)\nprint(f&#34;&#34;thread2\\_bot\\_answer：{response[&#39;&#39;messages&#39;&#39;][-1].content}&#34;&#34;)`\n```\n执行上面代码，可以看到输出如下：```\n`thread1\\_bot\\_answer：你好，Ada！很高兴认识你！😊\n这是一个很美的名字呢！有什么我可以帮助你的吗？无论是想聊聊天，还是有任何问题需要解答，我都很乐意为你提供帮助。------------线程1------------------\nthread1\\_bot\\_answer：当然记得！你刚才告诉我你叫 Ada～很高兴再次和你打招呼！😊\n------------线程2------------------\nthread2\\_bot\\_answer：你好！很抱歉，我无法记住之前对话中的个人信息，比如你的名字。这是为了保护你的隐私，所以我不会保留这类数据。你可以告诉我你的名字，或者任何你想让我称呼你的方式，我会很乐意在这次的对话中使用它！😊`\n```\n**短期记忆与线程相关，在对话时，需要在配置中传入thread\\_id**。通过上面的结果我们可以看到，当我们传入相同的thread\\_id时，agent就可以记住用户的名字，然而当我们更换thread\\_id时，agent就不记得用户的名字了。\n需要注意的是，**InMemorySaver将所有状态都保存在内存中**，一旦程序终止，那么所有对话历史都会消失。\n### **数据库持久化存储**\n可以发现，上面一小节的代码在应用程序结束后再启动，记忆就又消失了。这是因为InMemorySaver仅仅是把记忆保存在内存中，应用程序结束后释放内存记忆就消失了。在生产环境中常常使用数据库支持的检查点记录器持久化保存记忆，以保证数据的可靠性和服务的连续性。\n这里我们以postgres数据库为例来说明，怎么持久化地保存记忆数据。\n1.首先安装以下依赖：\n```\n`pip install -U &#34;psycopg[binary,pool]&#34; langgraph-checkpoint-postgres`\n```\n2.安装postgres数据库，具体的安装方法可以参考：[Linux下安装PostgreSQL\\_linux安装postgresql-CSDN博客] 。这里选择以源码的方式进行安装，安装包从官网（[PostgreSQL: Downloads] ）下载，选择最新的postgresql-18.0.tar.gz。\n3.安装数据库成功后，编码如下代码。\nDB\\_URI是数据库连接的URL。想要自动保存在数据库中的State需要在PostgresSaver.from\\_conn\\_string(DB\\_URI)上下文中操作。\n```\n`from langchain.chat\\_models import init\\_chat\\_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres import PostgresSaver\nBASE\\_URL=&#34;&#34;&#34;&#34; TOKEN=&#34;&#34;&#34;&#34;\nMODEL\\_NAME=&#34;&#34;&#34;&#34;\nmodel = init\\_chat\\_model(\nmodel=MODEL\\_NAME,\nmodel\\_provider=&#34;&#34;openai&#34;&#34;, base\\_url=BASE\\_URL,\napi\\_key=TOKEN,\ntemperature=0,\n)\nDB\\_URI = &#34;&#34;postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable&#34;&#34;\nwith PostgresSaver.from\\_conn\\_string(DB\\_URI) as checkpointer:\ncheckpointer.setup() # 第一次调用时必须要setup()\ndef call\\_model(state: MessagesState):\nresponse = model.invoke(state[&#34;&#34;messages&#34;&#34;])\nreturn {&#34;&#34;messages&#34;&#34;: response}\nbuilder = StateGraph(MessagesState)\nbuilder.add\\_node(call\\_model)\nbuilder.add\\_edge(START, &#34;&#34;call\\_model&#34;&#34;)\ngraph = builder.compile(checkpointer=checkpointer)\nconfig = {\n&#34;&#34;configurable&#34;&#34;: {\n&#34;&#34;thread\\_id&#34;&#34;: &#34;&#34;1&#34;&#34;\n}\n}\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，我叫ada！&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)\nresponse = graph.invoke(\n{&#34;&#34;messages&#34;&#34;: [{&#34;&#34;role&#34;&#34;: &#34;&#34;user&#34;&#34;, &#34;&#34;content&#34;&#34;: &#34;&#34;你好，请问你还记得我叫什么名字么？&#34;&#34;}]},\nconfig\n)\nprint(response[&#39;&#39;messages&#39;&#39;][-1].content)`\n```\n运行一次上述代码后，关闭应用程序后重启，再次运行上述代码，print结果如下：\n```\n`bot\\_answer\\_1：你好，Ada！很高兴再次见到你！😊\n你的名字真动听！今天有什么我可以帮你解答或者想聊的话题吗？bot\\_answer\\_2：当然记得！你告诉我你叫 \\*\\*Ada\\*\\*。很高兴再次和你打招呼！😊`\n```\n可以看到，记忆已经被保存了。我们检查数据库可以发现，postgres数据库中出现了四个表：\n![] \n上述表中，checkpoints表是”状态快照“表，每当程序执行一个step时，它就会在这张表中创建一条新记录，这条记录就是一个检查点的快照。查询该表，可以得到如下结果：\n![] \n接下来，我们来分析每一列的含义：![] |列名|含义|举例说明|\nthread\\_id|线程ID|上表中，所有thread\\_id都为1，表示这些记录都属于同一个会话流|\ncheckpoint\\_ns|检查点命名空间（Namespace），用于对检查点进行分组或分类|上表中都是空的，表示未使用或使用了默认的命名空间|\ncheckpoint\\_id|检查点的唯一标识符，该记录的主键||\nparent\\_checkpoint\\_id|父检查点的ID，它将检查点链接起来|第一条记录的parent\\_checkpoint\\_id是空的，代表是整个流程的起点。|\ncheckpoint|核心状态数据，是一个json对象。|ts代表时间戳；channel\\_values代表通道值，可以理解为工作流中的变量值；updated\\_channels代表在当前这步中被修改过的通道|\nmetadata|该检查点本身的元数据|step表示这是工作流的第几步；source表来源，&#34;input&#34;指外外部输入，&#34;loop&#34;指工作流内部循环或某个节点执行的结果|\n理解了上面checkpoints表后，那么不禁会问，真正的消息内容被存到了哪里呢？真正的消息内容存储在checkpoint\\_writes表中，如下：\n![] \n除了PostgreSQL之外，LangGraph还支持MongoDB、Redis等数据库。\n### **子图中的记忆**\n当构建复杂的、由多个子图嵌套而成的应用时，需要更灵活的记忆管理策略。●记忆继承（默认）：默认情况下，子图会继承其父图的checkpointer。这意味着整个嵌套图共享同一个对话状态，数据可以在父子图之间无缝流动。这对于将一个大型任务分解为多个模块化子任务非常有用。\n●记忆隔离：在某些场景下，例如构建多智能体系统，希望每个智能体（由一个子图表示）拥有自己独立的内存空间，互不干扰。此时，可以在编译子图时设置checkpointer=True。\n如下代码，可以在子图中直接使用父图的短期记忆：```\n`from langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\nclass State(TypedDict):\nfoo: str\n# 子图def subgraph\\_node\\_1(state: State):\nreturn {&#34;&#34;foo&#34;&#34;: state[&#34;&#34;foo&#34;&#34;] + &#34;&#34;bar&#34;&#34;}\nsubgraph\\_builder = StateGraph(State)\nsubgraph\\_builder.add\\_node(subgraph\\_node\\_1)\nsubgraph\\_builder.add\\_edge(START, &#34;&#34;subgraph\\_node\\_1&#34;&#34;', 'doi': '', 'published_date': '2025-12-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://zhuanlan.zhihu.com/p/1981392181592871894', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '记忆- LangChain 教程', 'authors': [], 'abstract': '记忆 - LangChain 教程[跳到内容] \n**我们的[使用LangGraph构建环境智能体] 课程现已在LangChain Academy上线！**\n# 内存[¶] \n## 什么是记忆？[¶] \nAI 应用中的记忆指处理、存储和有效回忆过往交互信息的能力。有了记忆，您的智能体可以从反馈中学习并适应用户的偏好。本指南根据记忆召回的范围分为两个部分：短期记忆和长期记忆。**短期记忆**，或[线程] 范围的记忆，可以随时在与用户的单个对话线程**内**被召回。LangGraph 将短期记忆作为智能体[状态] 的一部分进行管理。状态使用[检查点] 持久化到数据库中，以便线程可以随时恢复。当图被调用或步骤完成时，短期记忆会更新，并且在每个步骤开始时读取状态。\n**长期记忆**在对话线程**之间**共享。它可以\\*随时\\*且在**任何线程**中被召回。记忆可以限定在任何自定义命名空间内，而不仅仅是单个线程ID。LangGraph 提供[存储] （[参考文档] ）来让您保存和召回长期记忆。\n理解并在您的应用程序中实现这两种记忆都非常重要。![] \n## 短期记忆[¶] \n短期记忆让您的应用程序能够记住单个[线程] 或对话中的先前交互。[线程] 在一个会话中组织多个交互，类似于电子邮件将消息分组到单个对话中的方式。\nLangGraph 将短期记忆作为智能体状态的一部分进行管理，通过线程范围的检查点进行持久化。此状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索到的文档或生成的工件。通过将这些存储在图的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。由于对话历史是表示短期记忆最常见的形式，因此在下一节中，我们将介绍当消息列表变得**冗长**时管理对话历史的技术。如果您想坚持高层概念，请继续阅读[长期记忆] 部分。\n### 管理长对话历史[¶] \n长对话对当今的LLM 构成了挑战。完整的历史记录甚至可能无法完全适应LLM 的上下文窗口，从而导致不可恢复的错误。即使您的LLM 在技术上支持完整的上下文长度，大多数LLM 在长上下文中表现仍然不佳。它们会被陈旧或偏离主题的内容“分散注意力”，同时响应时间更慢且成本更高。管理短期记忆是平衡[准确率和召回率] 与您应用程序的其他性能要求（延迟和成本）的实践。一如既往，批判性地思考如何为您的 LLM 表示信息并查看您的数据非常重要。我们在下面介绍了几种管理消息列表的常见技术，并希望为您提供足够的上下文，以便您为应用程序选择最佳权衡方案。* [编辑消息列表] ：如何考虑在将消息列表传递给语言模型之前对其进行修剪和过滤。\n* [总结过往对话] ：当您不仅仅想过滤消息列表时，一种常用的技术。### 编辑消息列表[¶] \n聊天模型使用[消息] 接受上下文，其中包括开发者提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随时间增长。由于上下文窗口有限且富含 token 的消息列表可能成本高昂，许多应用程序可以受益于使用手动删除或遗忘陈旧信息的技术。![] \n最直接的方法是从列表中删除旧消息（类似于[最近最少使用缓存] ）。\n在LangGraph 中从列表中删除内容的典型技术是，从节点返回一个更新，告诉系统删除列表的某个部分。您可以定义此更新的外观，但一种常见的方法是让您返回一个对象或字典，指定要保留哪些值。```\n`[] import{Annotation}from"@langchain/langgraph";[] [] constStateAnnotation=Annotation.Root({[] myList:Annotation&lt;any[]&gt;({[] reducer:([] existing:string[],[] updates:string[]|{type:string;from:number;to?:number}[])=&gt;{[] if(Array.isArray(updates)){[] // Normal case, add to the history[] return[...existing,...updates];[]}elseif(typeofupdates==="object"&amp;&amp;updates.type==="keep"){[] // You get to decide what this looks like.[] // For example, you could simplify and just accept a string "DELETE"[] // and clear the entire list.[] returnexisting.slice(updates.from,updates.to);[]}[] // etc. We define how to interpret updates[] returnexisting;[]},[] default:()=&gt;[],[]}),[]});[] [] typeState=typeofStateAnnotation.State;[] [] functionmyNode(state:State){[] return{[] // We return an update for the field "myList" saying to[] // keep only values from index -5 to the end (deleting the rest)[] myList:{type:"keep",from:-5,to:undefined},[]};[]}`\n```\n当在键“myList”下返回更新时，LangGraph 将调用“[reducer] ”函数。在该函数中，我们定义要接受的更新类型。通常，消息会添加到现有列表中（对话将增长）；但是，我们也添加了支持接受一个字典，让您可以“保留”状态的某些部分。这允许您以编程方式丢弃旧消息上下文。\n另一种常见的方法是让您返回一个“删除”对象列表，指定要删除的所有消息的ID。如果您在 LangGraph 中使用LangChain 消息和[`messagesStateReducer`] reducer（或使用相同底层功能的[`MessagesAnnotation`] ），则可以使用`RemoveMessage`来完成此操作。\n```\n`[] import{RemoveMessage,AIMessage}from"@langchain/core/messages";[] import{MessagesAnnotation}from"@langchain/langgraph";[] [] typeState=typeofMessagesAnnotation.State;[] [] functionmyNode1(state:State){[] // Add an AI message to the `messages` list in the state[] return{messages:[newAIMessage({content:"Hi"})]};[]}[] [] functionmyNode2(state:State){[] // Delete all but the last 2 messages from the `messages` list in the state[] constdeleteMessages=state.messages[].slice(0,-2)[].map((m)=&gt;newRemoveMessage({id:m.id}));[] return{messages:deleteMessages};[]}`\n```\n在上面的示例中，`MessagesAnnotation`允许我们将新消息附加到`messages`状态键，如`myNode1`所示。当它看到`RemoveMessage`时，它将从列表中删除具有该ID的消息（然后该RemoveMessage将被丢弃）。有关LangChain特定消息处理的更多信息，请查看[此关于使用`RemoveMessage`的操作指南] 。\n有关示例用法，请参阅此操作[指南] 。\n### 总结过往对话[¶] \n如上所示，修剪或删除消息的问题在于，我们可能会因为筛选消息队列而丢失信息。因此，一些应用程序受益于使用聊天模型总结消息历史的更复杂方法。![] \n可以使用简单的提示和编排逻辑来实现这一点。例如，在LangGraph 中，我们可以扩展[`MessagesAnnotation`] 以包含`summary`键。\n```\n`[] import{MessagesAnnotation,Annotation}from"@langchain/langgraph";[] [] constMyGraphAnnotation=Annotation.Root({[]...MessagesAnnotation.spec,[] summary:Annotation&lt;string&gt;,[]});`\n```\n然后，我们可以生成聊天历史的摘要，使用任何现有摘要作为下一个摘要的上下文。此`summarizeConversation`节点可以在`messages`状态键中积累一定数量的消息后调用。\n```\n`[] import{ChatOpenAI}from"@langchain/openai";[] import{HumanMessage,RemoveMessage}from"@langchain/core/messages";[] [] typeState=typeofMyGraphAnnotation.State;[] [] asyncfunctionsummarizeConversation(state:State){[] // First, we get any existing summary[] constsummary=state.summary||"";[] [] // Create our summarization prompt[] letsummaryMessage:string;[] if(summary){[] // A summary already exists[] summaryMessage=[] `This is a summary of the conversation to date:${summary}\\\\n\\\\n`+[] "Extend the summary by taking into account the new messages above:";[]}else{[] summaryMessage="Create a summary of the conversation above:";[]}[] [] // Add prompt to our history[] constmessages=[[]...state.messages,[] newHumanMessage({content:summaryMessage}),[]];[] [] // Assuming you have a ChatOpenAI model instance[] constmodel=newChatOpenAI();[] constresponse=awaitmodel.invoke(messages);[] [] // Delete all but the 2 most recent messages[] constdeleteMessages=state.messages[].slice(0,-2)[].map((m)=&gt;newRemoveMessage({id:m.id}));[] [] return{[] summary:response.content,[] messages:deleteMessages,[]};[]}`\n```\n有关示例用法，请参见[此处] 。\n### 知道**何时**删除消息[¶] \n大多数LLM 都有一个最大支持上下文窗口（以token 计）。决定何时截断消息的一个简单方法是计算消息历史中的token 数量，并在接近该限制时进行截断。朴素截断很容易自行实现，尽管有一些“陷阱”。某些模型API 进一步限制了消息类型的序列（必须以人类消息开头，不能有相同类型的连续消息等）。如果您正在使用LangChain，可以使用[`trimMessages`] 工具并指定要从列表中保留的 token 数量，以及用于处理边界的`strategy`（例如，保留最后`maxTokens`）。\n下面是一个示例。```\n`[] import{trimMessages}from"@langchain/core/messages";[] import{ChatOpenAI}from"@langchain/openai";[] [] trimMessages(messages,{[] // Keep the last &lt;&lt;= n\\_count tokens of the messages.[] strategy:"last",[] // Remember to adjust based on your model[] // or else pass a custom token\\_encoder[] tokenCounter:newChatOpenAI({modelName:"gpt-4"}),[] // Remember to adjust based on the desired conversation[] // length[] maxTokens:45,[] // Most chat models expect that chat history starts with either:[] // (1) a HumanMessage or[] // (2) a SystemMessage followed by a HumanMessage[] startOn:"human",[] // Most chat models expect that chat history ends with either:[] // (1) a HumanMessage or[] // (2) a ToolMessage[] endOn:["human","tool"],[] // Usually, we want to keep the SystemMessage[] // if it\'s present in the original history.[] // The SystemMessage has special instructions for the model.[] includeSystem:true,[]});`\n```\n## 长期记忆[¶] \nLangGraph 中的长期记忆允许系统在不同对话或会话中保留信息。与线程范围的短期记忆不同，长期记忆保存在自定义的“命名空间”中。LangGraph 将长期记忆作为JSON 文档存储在[存储] （[参考文档] ）中。每个记忆都组织在一个自定义的`namespace`（类似于文件夹）和一个独特的`key`（像文件名）下。命名空间通常包含用户或组织ID或其他标签，以便更容易组织信息。这种结构支持记忆的层次化组织。然后通过内容过滤器支持跨命名空间搜索。请参见下面的示例。\n```\n`[] import{InMemoryStore}from"@langchain/langgraph";[] [] // InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.[] conststore=newInMemoryStore();[] constuserId="my-user";[] constapplicationContext="chitchat";[] constnamespace=[userId,applicationContext];[] awaitstore.put(namespace,"a-memory",{[] rules:[[] "User likes short, direct language",[] "User only speaks English &amp; TypeScript",[]],[] "my-key":"my-value",[]});[] // get the "memory" by ID[] constitem=awaitstore.get(namespace,"a-memory");[] // list "memories" within this namespace, filtering on content equivalence[] constitems=awaitstore.search(namespace,{[] filter:{"my-key":"my-value"},[]});`\n```\n当向智能体添加长期记忆时，重要的是要考虑如何**写入记忆**、如何**存储和管理记忆更新**，以及如何为应用程序中的 LLM**召回和表示记忆**。这些问题都是相互关联的：您希望如何为 LLM 召回和格式化记忆，决定了您应该存储什么以及如何管理它。此外，每种技术都有其权衡。正确的方法在很大程度上取决于您应用程序的需求。LangGraph 旨在为您提供低级原语，以便您根据记忆[存储] 直接控制应用程序的长期记忆。\n长期记忆远非一个已解决的问题。虽然很难提供通用建议，但我们在下面提供了一些可靠的模式供您在实现长期记忆时参考。**您希望在“主路径”中写入记忆还是在“后台”写入记忆？**\n记忆可以作为主要应用程序逻辑的一部分（例如，在应用程序的“主路径”上）或作为后台任务（作为根据主要应用程序状态生成记忆的独立函数）进行更新。我们在[下面的写入记忆部分] 中记录了每种方法的一些权衡。\n**您希望将记忆作为单个档案管理还是作为文档集合管理？**\n我们提供了两种管理长期记忆的主要方法：单个持续更新的文档（称为“档案”或“模式”）或文档集合。每种方法都有其自身的好处，具体取决于您需要存储的信息类型以及您打算如何访问它。当您希望记住有关用户、组织或其他实体（包括智能体本身）的范围明确、具体的信息时，将记忆作为单个、持续更新的“档案”或“模式”进行管理非常有用。您可以预先定义档案的模式，然后使用LLM 根据交互进行更新。查询“记忆”很容易，因为它只是对JSON 文档的简单GET 操作。我们在[记住档案] 中更详细地解释了这一点。这种技术可以提供更高的准确性（在已知信息用例中），但召回率较低（因为您必须预测和建模您的领域，并且文档更新倾向于以更高的频率删除或重写旧信息）。\n另一方面，将长期记忆作为文档集合进行管理，可以存储无限量的信息。当您希望在长时间范围内重复提取和记住项目时，这项技术非常有用，但随着时间的推移，查询和管理可能会更复杂。与“档案”记忆类似，您仍然为每个记忆定义模式。您将插入新文档（并在此过程中可能更新或重新情境化现有文档），而不是覆盖单个文档。我们在[“管理记忆集合”] 中更详细地解释了这种方法。\n**您希望将记忆作为更新的指令还是作为少量样本示例呈现给您的智能体？**\n记忆通常作为系统提示的一部分提供给LLM。为 LLM“框架”记忆的一些常见方式包括提供原始信息，如“与用户 A 之前交互的记忆”，作为系统指令或规则，或作为少量样本示例。将记忆框定为“学习规则或指令”通常意味着将系统提示的一部分专门用于LLM 可以自行管理的指令。在每次对话后，您可以提示LLM 评估其性能并更新指令，', 'doi': '', 'published_date': '2026-02-02T20:17:10.320740', 'pdf_url': '', 'url': 'https://github.langchain.ac.cn/langgraphjs/concepts/memory/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践', 'authors': [], 'abstract': 'Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践 | 亚马逊AWS官方博客[Skip to Main Content] \nAWS Blog\n* [首页] \n* 版本## [亚马逊AWS官方博客] \n# Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践\n[![]] |\n*本文将深入探讨 Agent**应用中的记忆需求、记忆类型、技术组件和主流开源框架，并介绍基于亚马逊云科技的数据产品自行构建记忆模块，以及基于Agent**构建平台Bedrock AgentCore**的Agent memory**的托管方案。*\n## 前言### 当前大语言模型的困境大语言模型在处理和生成文本方面表现出色，但它们在本质上是**无状态（****stateless****）**的。这意味着每次与LLM的交互都是独立的，模型本身不会“记住”过去的对话或经验。大模型在“记忆”上主要局限于：\n* **上下文窗口的限制导致遗忘问题。**LLM通过一个有限的“上下文窗口”（Context Window）来处理信息。所有输入（包括Prompt和之前的对话片段）都必须塞入这个窗口。一旦信息超出这个窗口，LLM就“忘记”了它，无法再访问。这导致了所谓的**“****遗忘”**问题；\n* **难以处理多轮/****复杂任务。**对于需要跨越多轮对话、追踪状态或执行一系列子任务的复杂任务，LLM很难保持连贯性和进展，因为它会不断“忘记”之前的步骤和决策。特别是在Agent的场景，工具的定义和工具的返回值都会存在于上下文中，同时由于Agent具有自主工作的能力，和LLM的平均交互的轮数也大大增加；\n* **无法个性化。**由于不记住特定用户的历史偏好、习惯或之前的互动，LLM难以提供真正个性化的体验。每次互动都像是第一次见面；\n* **长上下文带来的性能和成本影响。推理速度变慢：**LLM在处理更长的上下文时，需要进行更多的计算来处理和理解所有输入信息。这会导致推理时间增加，响应速度变慢。**模型表现下降：**尽管LLM的上下文窗口越来越大，但研究发现，模型在超长上下文中检索关键信息的能力可能会下降。**更高的****Token****费用：**上下文越长，输入的token数量就越多，从而导致每次API调用的成本更高。对于需要频繁交互或处理大量文本的应用来说，这会迅速累积成可观的费用。### 为什么需要记忆模块记忆系统旨在克服LLM的局限性，赋予智能体以下核心能力：\n* **长期保留与高效管理：**存储超出LLM上下文窗口的信息，实现高效检索和过滤，避免信息遗忘；\n* **持续知识更新：**通过存储与环境和用户的交互经验，实现自我改进和知识更新；\n* **个性化服务：**记录用户偏好和历史互动，提供定制化回应；\n* **复杂任务支持：**追踪多Agent任务进展和中间结果，确保连贯完成并优化决策；\n* **提升交互质量：**保持上下文连贯性，支持深入推理，并通过反思机制从错误中学习。## AI Agent 记忆类型智能体的记忆系统主要分为短期记忆和长期记忆两大类。### 短期记忆/工作记忆\n短期记忆（Short-term Memory, STM）是智能体维护当前对话和任务的即时上下文系统，主要包括：\n* **会话缓冲（Context****）记忆**：保留最近对话历史的滚动窗口，确保回答上下文相关性；\n* **工作记忆**：存储当前任务的临时信息，如中间结果、变量值等。\n短期记忆受限于上下文窗口大小，适用于简单对话和单一任务场景。### 长期记忆**长期记忆**（Long-term Memory, LTM）是智能体用于**跨会话、跨任务长期保存知识**的记忆形式。它对应于人类的大脑中持久保存的记忆，例如事实知识、过去经历等。长期记忆的实现通常依赖于**外部存储**或**知识库**，包括但不限于：\n* **摘要记忆**：将长对话内容提炼为关键摘要存储；\n* **结构化知识库**：使用数据库或知识图谱存储结构化信息；\n* **向量化存储**：通过向量数据库实现基于语义的记忆检索。\n长期记忆使智能体能够**随着时间累积经验和知识，**它特别适用于**知识密集型应用**和**需要长期个性化**的场景。\n## 记忆管理与使用相关技术设计开发Agent的记忆系统时要考虑**不同场景下如何选择记忆内容、设计写入策略、组织记忆结构、实现检索召回**四个方面。\n### 记忆产生：判断哪些信息需要被记忆在构建智能体记忆系统时，首先要根据具体的场景确定**哪些信息值得记忆**。这些记忆往往是多维度和动态的信息结构，包括**时间**维度（理解时间依赖的关系和序列）、**空间**维度（解释基于位置的和几何关系）、参与者**状态**（跟踪多个实体及其不断变化的状况）、意图**上下文**（理解目标、动机和隐含的目的），以及文化上下文（在特定社会和文化框架内解释交流）。\n并非所有对话内容都需要长期保存，下面以4种常见场景举例哪些是与任务相关、对后续交互有价值的记忆要点。\n对于**代码助手类的智能体**，记忆应侧重**用户项目的上下文和偏好**。包括：用户项目的**代码库结构**（文件组织、模块关系）、**命名风格**（变量命名约定、代码格式风格）、常用的**框架****/****库**以及用户以前提供的代码片段或指令等。记忆这些信息可以更贴合定制化需求和项目实际情况给出建议。例如，没有记忆支持时，开发者常常需要重复告诉 AI 项目的架构或纠正AI 偏离项目规范的行为，这非常低效。而引入**持久记忆**后，AI 可以持续参考之前存储的项目背景，”记住”用户的技术栈，从而保持技术决策的一致性。同时，代码助手还能记忆用户过往的提问和反馈，例如某段代码曾反复修改，下一次遇到类似问题时可直接调用之前的方案，避免重复推理。总之，在代码场景中，记忆系统使AI能够理解**长期的项目上下文**，提供**风格一致**且**上下文相关**的代码补全和解释。\n对于**智能客服类的智能体**，记忆的重点是**用户历史和偏好**，以便提供连贯且个性化的服务。包括：用户当前**任务的状态，**提过的问题、故障、产品使用，服务配置，和解决方案记录。当用户第二次来询问类似问题时，不必重复描述自己之前的问题细节，系统能够回忆起**上次给出的建议**或已经尝试过某些步骤，直接切入重点解决当前问题。此外，记忆用户的产品使用情况和喜好（例如偏好哪种通信渠道，是否倾向自助解决）可以使响应更加贴合用户习惯。这样实现**更快的问题解决**和**更高的客户满意度，**增强对品牌的信任。\n对于**个人助理**智能体，记忆重点包括：**用户个人信息和日程表**、**目标**（如健身学习计划）、经常执行的**行为模式**（如每周几锻炼）以及对应用和服务的偏好（如偏好哪种提醒方式）等。这样智能体会提醒日程，并结合过往偏好提供个性化安排（比如知道用户周五喜欢外卖，在傍晚时主动推荐餐厅）。随着交互增加，**持续的长期记忆**使智能体能**不断适应用户**，逐渐减少对用户指令的依赖，实现更**主动**和**贴心**的服务。\n对于**推荐服务**智能体，记忆重点包括：**用户的显式反馈**（如用户给某本书点赞或明确表达不喜欢某商品）**和隐式反馈**（如浏览记录、点击行为、购买历史）**，**以此构建兴趣档案，在后续交互中个性化推荐。并持续学习，对过往推荐的反馈（是否点击、购买），**不断调整推荐策略，更新画像。**提高推荐转化率也增强用户忠诚度。\n#### 记忆管理的实际例子以下是在一个长文档处理的Agent项目中使用的上下文压缩提示词，当上下文超过指定的限额时，将触发基于LLM的压缩机制。\n```\n`# Custom system prompt for document processing domain summarization\ncustom\\_system\\_prompt = """您正在总结文档处理工作流对话。创建一个简明扼要的要点摘要，该摘要：\n专注于文档处理任务、章节生成和工作流进度保留特定文件路径、章节名称和任务完成状态维护待办事项列表状态和进度跟踪信息省略对话元素，专注于可操作的工作流信息使用适合文档处理和内容生成的技术术语保留错误消息和重要状态更新以要点形式呈现，不使用对话语言，按以下方式组织：文档处理：[关键处理步骤和结果]\n章节生成：[已完成的章节和当前进度]\n待办状态：[当前工作流状态和待处理任务]\n文件位置：[重要文件路径和输出]\n错误/问题：[遇到的任何问题及解决方案]\n"""`\n```\n### 记忆策略智能体的记忆更新可通过**轮数**或**事件**触发。轮数触发是每隔3-5轮对话自动生成摘要存入记忆；事件触发则在完成任务、场景转换等关键节点记录信息。例如，客服完成问题处理时保存解决方案，个人助理更新日程后写入日历。开发者可实现监控逻辑，在对话累积或话题转换时，让大模型对近期对话生成摘要，提取关键信息并添加标签便于检索。\n系统也可支持用户主动标记需要记住的信息，如通过**口头指令**或**界面**操作。这不仅让用户指定重要内容，也支持删除特定记忆的需求，确保用户对数据的控制权。\n### 记忆存储：记忆组织结构设计记忆数据通常采用**用户****→****会话→****记忆片段**的三层结构管理。**用户**层区分不同账号空间，**会话**层隔离各对话上下文，**记忆片段**层存储具体内容及元数据（如时间、关键词、来源等）。复杂系统可能需要维护多个记忆库，包括短期工作记忆、长期情节记忆、语义知识库等。合理的结构设计有助于快速检索和有效管理记忆内容。\n### 记忆检索：记忆查询与召回逻辑智能体需要基于当前对话意图从记忆库中检索相关信息。主要检索方法包括关**键词匹配**、**向量语义搜索**和**元数据过滤**。系统将检索到的记忆按相关度排序，选取最相关内容加入到对话上下文中，用于生成更准确的响应。例如在推荐场景中，可基于用户历史偏好记忆提供个性化建议。\n## 上下文工程（Context Engineering）与记忆\n### 上下文工程上下文工程与记忆系统形成共生关系，共同支撑智能体的认知能力。记忆系统作为”信息仓库”，存储历史对话、知识和用户偏好；而上下文工程则扮演”智能调度员”，决定从记忆中检索哪些信息及如何组织呈现给LLM。\n上下文工程的核心在于，LLM的性能和有效性根本上取决于其接收的**上下文**。实现了上下文工程的系统一般包含三类**基础组件**：\n1. **上下文检索与生成：**涵盖Prompt生成和外部知识获取；\n2. **上下文处理：**涉及长序列处理、自我完善和结构化信息集成；\n3. **上下文管理：**关注记忆层次、压缩技术和优化策略。\n这些组件是高级应用实现（如RAG、显式记忆系统和智能体系统）的基石。由此，我们可以将上下文工程定义为：上下文工程将上下文C重新概念化为一组动态结构化的信息组件，c1, c2, …, cn。这些组件由一组函数进行来源获取、过滤和格式化，最终由高级组装函数A进行编排。\n### 上下文工程与记忆的关系上下文工程与记忆系统**紧密且共生**，都是AI智能体的重要构建手段。一方面**，记忆是上下文的****“****仓库”****，**智能体的记忆系统（如历史对话、知识库、用户偏好）是信息存储地，为LLM提供**潜在上下文**。另一方面，**上下文工程是记忆的****“****调度员”****和“****优化器”****，上下文工程**决定从记忆中检索哪些信息及如何检索，确保提取最相关的记忆片段。\n### 上下文工程在项目中的例子在一个文档自动化处理生成的Agent项目中，我们面临一个关键挑战：输入文档总量超过500页，远超模型的最大Token限制，同时项目对生成内容的召回率和准确率有较高要求。\n为解决这一问题，我们实施了以下上下文工程策略：1. **文档分块处理：**将大型文档集合切分为适当大小的chunks，并存储在文件系统中；\n2. **摘要生成：**为每个文档块生成精炼的文字摘要，提供内容概览。并生成整个文档的摘要信息；\n3. **动态上下文管理：**赋予Agent自主选择的能力，使其可以根据任务需求动态调取相关文档块；\n4. **上下文优化：**任务完成后自动释放不再需要的上下文，优化资源利用。\n这种方法使Agent能够在保持高准确率的同时，有效处理超过模型上下文限制的文档集合。\n## 主流记忆框架分析基于上个章节介绍的设计思路，核心组件和优化策略，业界涌现了多种记忆机制的实现方案。以下我们从**开源框架（****Mem0****，MemGPT****，LangMem****以及他们与亚马逊云科技服务的集成）**和**亚马逊云科技商业解决方案（****AI Agent****构建托管服务Bedrock AgentCore****的记忆模块）**两个角度，对目前主流的Agent记忆方案进行分析，比较它们的特点、适用场景以及部署成本。\n### Mem0\n[Mem0] 是专为AI Agent设计的开源记忆框架，通过智能记忆管理帮助Agent实现状态持久化。它支持工作记忆、事实记忆、情景记忆和语义记忆等多种类型，提供智能的LLM提取、过滤和衰减机制，有效降低计算成本。同时支持多模态处理和Graph记忆功能，既可使用托管服务也可自建部署。\n从架构来看，Mem0包含几个核心模块：**核心记忆层、大语言模型层、嵌入模型层、向量存储层、图存储层和持久化存储层**。核心记忆层是构建核心逻辑来判断新增、检索、更新和删除记忆的相应实现；大语言模型层负责根据用户输入提取出关键信息，以及生成如何更新记忆的决策；嵌入模型和向量存储层负责支持记忆的向量化存储和检索；图存储层负责存储抽取出的实体关系，丰富记忆的组织形态；持久化存储层负责存储对记忆系统的操作信息。这种分层架构设计确保了记忆系统的可扩展性和可维护性，\n每层职责明确，便于针对不同场景进行优化配置。Mem0 的设计理念专注于智能记忆管理而非简单数据存储，融合了几个关键技术创新：* 双LLM 架构：系统通过两次不同的LLM 调用实现复杂的分工。第一次专注于信息提取，第二次专门处理决策过程，提高准确性并允许专门优化。* 上下文感知处理：在现有记忆上下文中分析新数据，确保记忆系统一致性和连贯性，防止碎片化并维护信息间逻辑关系。* 智能去重机制：结合向量相似性搜索与LLM判断，防止冗余信息存储，保持记忆质量和系统效率。\n* 冲突解决能力：当出现矛盾信息时，智能确定保留、更新或删除的适当行动，适应用户偏好和环境的动态变化。#### Mem0与Agent框架的集成\n开发者可以通过两种方式集成Mem0：一是在环境变量配置依赖信息后，直接调用Mem0的接口函数（如添加、查找、更新记忆等）；二是将Mem0封装成工具传入Agent框架，由Agent根据处理逻辑自主调用相应方法。\n#### Mem0与亚马逊云科技的集成\n亚马逊云科技的多项服务均支持与Mem0集成，为开发者提供完整的企业级记忆解决方案：\n* 模型服务集成：支持Amazon Bedrock的多种模型，包括Claude-3.7-Sonnet用于复杂推理、Titan-Embed-Text-v2用于向量化处理。\n* 存储服务集成：* 向量存储：Amazon Aurora Serverless V2 for PostgreSQL、Amazon OpenSearch\n* 图数据存储：Amazon Neptune Analytics\n* 开发框架集成：亚马逊云科技开源的StrandsAgent框架中内置了基于Mem0能力封装的mem0\\_memory工具。\nMem0作为开源解决方案，为开发者提供了灵活的记忆管理能力。结合亚马逊云科技服务的强大生态，可以构建高性能、可扩展的Agent记忆系统，适合需要深度定制和成本优化的企业级应用场景。更多关于Mem0的深度解析以及和亚马逊云科技的服务的集成请见博客[https://amazon.awsapps.com/workdocs-amazon/index.html#/document/17faaf605c2b12a543d5b9223ec5301aca29c03ffd5f3d1f5dd929d5496471bc] \n### Letta (前身为MemGPT)\n#### Letta 功能介绍Letta（前身为MemGPT）是一个专注于构建具有持续记忆能力的 AI Agent 的框架，它的设计思路是将LLM代理类比为计算机操作系统，采用”**虚拟内存**“的概念来管理智能体的记忆。其核心创新在于双层记忆架构，包括**上下文内记忆**（直接存在于模型上下文窗口中的系统指令、可读写记忆块和当前对话）和**上下文外记忆**（存储历史对话和外部知识的长期存储）。当上下文窗口接近填满时，系统会自动将对话历史压缩为递归摘要并存储为记忆块，同时保留原始对话供后续检索，通过工具如core\\_memory\\_append、core\\_memory\\_replace 和recall 实现记忆的编辑与检索，从而使AI 代理能够在长期交互中保持连贯性，真正实现记住过去、学习新知并随时间演化的能力。#### Letta与亚马逊云科技生态的深度集成\nLetta可无缝对接亚马逊云科技服务栈，以下是一个通过 Letta 框架搭建的电商客服机器人问答流程示例：* 使用Amazon Bedrock 的Claude 或Titan 模型作为基础LLM\n* 采用Amazon PostgreSQL、OpenSearch 作为向量存储后端* 利用ElastiCache 缓存来提升推理（框架原生支持）、问答等场景（需要搭建缓存中间件）的效率* 通过亚马逊云科技Lambda 实现记忆管理的无服务器架构[![]] |\n图1. 通过Letta 框架搭建的电商客服机器人问答流程示例**LangMem**\nLangMem 是由LangChain 开发的，旨在解决AI 代理的”健忘症”问题。传统的大语言模型在会话结束或上下文窗口被超出时会丢失之前的交互信息，而LangMem 为AI 代理提供了长期记忆能力，使其能够跨会话保持知识连续性，记住用户的偏好、过往交互和重要事实。这一创新将AI 代理从简单的反应系统转变为能够随时间学习和适应的动态助手。例如：你的AI 助手能够记住你上周提到的项目细节，了解你的工作习惯，甚至记得你喜欢的咖啡类型。LangMem 框架的设计理念是借鉴人类心理学对记忆的分类，为Agent设计了三种核心记忆类型，每种类型都有其独特的功能和应用场景。\n* **语义记忆 (Semantic Memory)****：**语义记忆是 Agent 的知识基础，存储客观事实、用户偏好和基础知识，作为长期持久化记忆嵌入系统提示中，可通过Collection 方式保存完整历史信息，或通过Profile 方式只保留最新状态，为Agent 提供稳定的知识支撑，确保其能够准确理解和回应用户需求。* **情节记忆（Episodic Memory****）：**捕捉 Agent 的交互经历，不仅存储对话内容，还包含完整上下文和推理过程，作为短期记忆主要用于构建用户提示词，使Agent 能够从过往经验中学习，参考成功案例调整响应策略，从而在类似情境中提供更加个性化和有效的解决方案。* **程序记忆 (Procedural Memory)****：**专注于”如何做”的实操知识，从初始系统提示开始，通过持续反馈和经验积累不断优化，作为短期记忆帮助 Agent 学习最有效的行为模式，既可用于系统提示也可用于用户提示，使Agent 能够根据不同情境灵活调整策略，提高解决问题的效率和准确性。LangMem 不仅能存储对话中的重要信息，还能优化提示和行为，在多次交互后提供更连贯、个性化的响应。它消除了传统AI 代理在会话结束后丢失上下文的问题，减少了重复询问用户已提供信息的需要，显著提升了用户体验的连贯性和个性化程度。LangMem 提供通用存储兼容性和热路径内存工具，使AI代理能在实时会话中即时保存和检索信息。其智能后台内存管理功能自动提取、汇总并更新知识库，且与 LangGraph 平台无缝集成。LangMem 的高级特性包括**主动记忆管理、共享内存机制、命名空间组织和个性化持续进化**能力，使 AI Agent 能根据重要性动态存储信息，支持多个Agent 之间的知识共享，高效组织检索信息，并不断适应用户需求变化，提供越来越精准的服务。目前LangMem 主要是与LangGraph 集成，支持Amazon Bedrock。在记忆存储层面，针对开发场景，有内置的 InMemoryStore，支持快速的迭代、测试和原型设计；另外，提供对 PostgresqlSQL 的支持。对于其他记忆存储引擎，LangMem 提供开放的接口实现方式，需要用户定制开发集成。### Amazon Bedrock AgentCore Memory：亚马逊云科技的托管记忆解决方案\n相比开源框架，亚马逊云科技也提供**开箱即用的托管服务**，通过AI Agent构建平台Bedrock AgentCore中的记忆模块帮助开发者更快捷地为AI Agent赋能记忆功能。您无需运维任何底层资源，只需一键即可集成业界领先的记忆系统。\n[![]] |\n图2-Bedrock AgentCore中的记忆模块核心功能展示\nAmazon Bedrock AgentCore 的Memory 模块是一个由亚马逊云科技托管的持久化记忆系统，用于存储和管理AI Agent 的对话和知识。它提供**短期记忆（****short-term memory****）和长期记忆（long-term memory****）**两种模式。短期记忆负责在一次会话中记录最近的最近几轮对话，确保代理能够“记住”当前对话的上下文。长期记忆则从对话中提取结构化的关键信息，在多个会话之间保留知识，使Agent能够“学习”用户偏好、事实和摘要等信息。\n**记忆的存储**\nMemory 模块在架构上采用分层存储策略：短期记忆层存储原始交互事件作为即时上下文，长期记忆层存储从事件提取的概要知识。Memory 服务背后实现了自动的信息处理流水线：当新的事件被存储时，如果Memory 配置了长期记忆策略，服务会异步地对事件内容进行分析（例如调用基础模型）来提炼出可长期保存的知识片段。AgentCore Memory 内置了多种记忆策略（Memory Strategy）来定义如何将原始对话转化为结构化长期记忆。例如：\n* **SemanticMemoryStrategy**（语义记忆策略）：从对话中抽取出**事实和知识**，以便日后查询。\n* **SummaryMemoryStrategy**（摘要策略）：为每个会话生成**对话摘要**，提炼主要内容。\n* **UserPreferenceMemoryStrategy**（用户偏好策略）：捕获用户的偏好、风格和重复选择等信息。\n使用内置策略时，无需额外配置模型，AgentCore Memory 服务会在后台使用预置的模型来完成提取和归纳。当开发者调用CreateEvent 保存新事件后，这些策略会被自动触发，异步运行LLM分析内容并产生长期记忆记录（memory records）。长期记忆记录生成后存储于 Memory 中，对应特定的命名空间和类型（如事实、摘要、偏好），每条记录也有唯一ID以供检索。\n此外，AgentCore 允许**自定义记忆策略（****CustomMemoryStrategy****）**，开发者可提供自定义的提示词（prompt）和选择特定的基础模型来执行记忆提取，例如只提取某类domain知识。\n', 'doi': '', 'published_date': '2025-09-19T00:00:00+00:00', 'pdf_url': '', 'url': 'https://aws.amazon.com/cn/blogs/china/agentic-ai-infrastructure-deep-practice-experience-thinking-series-three-best-practices-for-agent-memory-module/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '别再混淆！一文看懂LangGraph 的短期记忆与长期记忆：原理', 'authors': [], 'abstract': '别再混淆！一文看懂 LangGraph 的短期记忆与长期记忆：原理、实战与避坑清单\\_博客-飞桨星河社区\n![]', 'doi': '', 'published_date': '2025-11-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://aistudio.baidu.com/blog/detail/737084298395525', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '【AI大模型应用开发】以LangChain为例：从短期记忆实战 - 53AI', 'authors': [], 'abstract': '- [首页] \n- [产品服务] \n- [客户案例] \n- [AI知识库] \n- [关于我们] \n\n热门场景\n\n工作+AI\n\n业务+AI\n\nAIx业务\n\n[落地咨询] \n\n[定制开发] \n\n热门产品\n\n[53AI KM\\\n\\\n让知识在人与AI之间高效流动] [53AI Studio\\\n\\\n高准确率的企业级智能体开发平台] [53AI Hub开源\\\n\\\n三分钟搭建出独立的企业AI门户] [53AI Browser\\\n\\\n“AI专家”效率倍增的秘密武器\\\n\\\n敬请期待...] \n\n[行业案例] [场景案例] \n\n[前沿技术] [Agent框架] [行业应用] [企业落地] \n\n[公司介绍] [渠道合作] \n\n53AI知识库\n\n学习大模型的前沿技术与行业应用场景\n\n[立即咨询] [预约演示] \n\n[首页] [AI知识库] [前沿技术] [RAG技术] \n\n我要投稿\n\n# 【AI大模型应用开发】以LangChain为例：从短期记忆实战，到如何让AI应用保持长期记忆的探索\n\n发布日期：2024-05-05 08:06:56浏览次数： 5521\n\n作者：同学小张\n\n微信搜一搜，关注“同学小张”\n\n在AI应用中，无论是多轮对话场景、RAG场景还是AI Agent场景中，记忆能力都是不可或缺的一部分。然而，记忆能力是目前大模型的短板，所以，现在很多框架，诸如 LangChain、MetaGPT 等，都封装了自己的记忆模块，以方便开发者实现自己大模型应用的记忆功能。\n\n之前我们简单概览了一下 LangChain 的 Memory 模块，那只是在多轮对话场景中，简单的取最近几次的对话历史作为记忆。这是最简单的使用记忆的方法，也是短期记忆的一种。\n\n本文我们来系统看下实现大模型应用记忆的方法，包括短期记忆和长期记忆。还是以LangChain为例来进行实战。\n\n# 0\\. LangChain中 Memory 实战\n\n> 我这里将记忆简单理解为对话历史，查询历史等历史记录。\n\n## 0.1 记忆封装罗列\n\n在 LangChain 中提供了多种获取记忆的封装，例如 `ConversationBufferMemory`、 `ConversationBufferWindowMemory`、 `ConversationTokenBufferMemory` 等。\n\n简单罗列如下：\n\n- •\xa0`ConversationBufferMemory` 可以理解为通用的将全部的历史记录取出来。\n\n- •\xa0`ConversationBufferWindowMemory` 可以理解为滑动窗口，每次只取最近的K条记录。\n\n- •\xa0`ConversationTokenBufferMemory` 可以理解为控制每次取的历史记录的Token数。\n\n- •\xa0`ConversationSummaryMemory`: 对上下文做摘要\n\n- •\xa0`ConversationSummaryBufferMemory`: 保存 Token 数限制内的上下文，对更早的做摘要\n\n- •\xa0`VectorStoreRetrieverMemory`: 将 Memory 存储在向量数据库中，根据用户输入检索回最相关的部分\n\n- •\xa0`ConversationEntityMemory`：保存一些实体信息，例如从输入中找出一个人名，保存这个人的信息。\n\n- •\xa0`ConversationKGMemory`：将历史记录按知识图谱的形式保存和查询\n\n\n> 这里面的大部分记忆封装，之前咱们已经学习过了，这里不再重复。详细的使用教程可以参考我之前的文章： [【AI大模型应用开发】【LangChain系列】3. 一文了解LangChain的记忆模块（理论实战+细节）] 。\n\n下面看下\xa0`VectorStoreRetrieverMemory`\xa0的使用和实现效果。\n\n## 0.2 实践：VectorStoreRetrieverMemory的使用\n\n### 0.2.1 完整代码\n\n```\nfrom\xa0langchain.memory\xa0importVectorStoreRetrieverMemoryfrom\xa0langchain_openai\xa0importChatOpenAIfrom\xa0langchain.embeddings.openai\xa0importOpenAIEmbeddingsfrom\xa0langchain.vectorstores\xa0importChromafrom\xa0langchain.chains\xa0importConversationChainfrom\xa0langchain.prompts\xa0importPromptTemplatevectorstore\xa0=Chroma(embedding_function=OpenAIEmbeddings())retriever\xa0=\xa0vectorstore.as_retriever(search_kwargs=dict(k=1))memory\xa0=VectorStoreRetrieverMemory(retriever=retriever)memory.save_context({"input":"我喜欢学习"},{"output":"你真棒"})memory.save_context({"input":"我不喜欢玩儿"},{"output":"你可太棒了"})PROMPT_TEMPLATE\xa0="""以下是人类和\xa0AI\xa0之间的友好对话。AI\xa0话语多且提供了许多来自其上下文的具体细节。如果\xa0AI\xa0不知道问题的答案，它会诚实地说不知道。以前对话的相关片段：{history}（如果不相关，你不需要使用这些信息）当前对话：人类：{input}AI："""prompt\xa0=PromptTemplate(input_variables=["history","input"],\xa0template=PROMPT_TEMPLATE)chat_model\xa0=ChatOpenAI()conversation_with_summary\xa0=ConversationChain(\xa0\xa0\xa0\xa0llm=chat_model,\xa0\xa0\xa0\xa0prompt=prompt,\xa0\xa0\xa0\xa0memory=memory,\xa0\xa0\xa0\xa0verbose=True)print(conversation_with_summary.predict(input="你好，我叫同学小张，你叫什么"))print(conversation_with_summary.predict(input="我喜欢干什么？"))\n```\n\n### 0.2.2 代码解释\n\n（1）代码中我们使用了\xa0`VectorStoreRetrieverMemory`\xa0作为记忆存储和获取的模块。它既然是向量存储和查询，所以接收参数： `retriever=retriever`，必须要穿给它一个向量数据库才能工作。\n\n（2）然后使用了\xa0`ConversationChain`\xa0作为对话的Chain。它接收一个\xa0`memory = memory`\xa0参数设置，指定使用的记忆类型。默认是最普通的\xa0`ConversationBufferMemory`\xa0类型。\n\n（3）什么时候会去检索记忆呢？在Chain运行 invoke 的一开始，就加载了。源码如下：\n\n可以看到，最后就是用用户的输入，去向量数据库中检索相关的片段作为需要的记忆。\n\n### 0.2.3 运行效果展示\n\n第一个问题，检索到的内容不相关，但是也得检索出一条。\n\n第二个问题，检索到的内容相关，用检索到的内容回答问题。\n\n# 1\\. 如何让AI应用具备长期记忆？\n\n> 我这里将“长期记忆”理解为持久化记忆或者长上下文记忆。也就是两种形式的记忆我都认为是“长期记忆”：\n>\n> - •\xa0第一种：持久化记忆，对话历史等历史记录持久化保存，不会随着进程的退出而消失。例如保存成功文件或存储进数据库等。\n>\n> - •\xa0第二种：长上下文记忆，当历史记录特别多时，如何从历史记录中找出有用的记忆，而不是只关注最近的几条历史记录。\n\n## 1.1 LangChain 中的记忆模块是否具有长期记忆的能力？\n\n上面罗列的和实战的 LangChain 中的记忆模块， `ConversationBufferMemory`、\xa0`ConversationBufferWindowMemory`、 `ConversationTokenBufferMemory`\xa0看起来都无法实现长期记忆的能力：无法持久化（看源码，底层都是一个List类型，保存到内存，随着进程消亡而消亡），也没法查询长的上下文。\n\n`ConversationSummaryMemory`、 `ConversationSummaryBufferMemory`\xa0在一定程度上能提供更多的记忆信息（因为其对之前的历史记录做了总结压缩），所以在某些上下文不是特别长的场景中，还是可以用一用来实现简单的长期记忆能力的。\n\n`ConversationEntityMemory`、 `ConversationKGMemory` 一个只保存实体信息，一个将历史记录组织成知识图谱，会对长上下文场景中的长时记忆功能非常有用。它可以从全局的角度将用户提问中的实体或相关知识作补充，而不是关注最近的几次对话。\n\n`VectorStoreRetrieverMemory` 应该是最好和最能实现长期记忆能力的类型了。一方面，它是向量数据库存储，可以方便的持久化数据，另一方面，它的向量检索能力，本来就是针对用户提问检索出最相关的文档片段，不受长上下文的窗口限制。但是其检索的相关片段之间是否存在信息缺失等，会影响长时记忆的准确性，从而影响最终的结果。\n\n> 所以， `ConversationEntityMemory`、 `ConversationKGMemory`\xa0+\xa0`VectorStoreRetrieverMemory`\xa0是否可以一试？三者结合，保持相关片段的相关性，同时利用实体关系和知识图谱进行补充，是否可以更好地实现长时记忆的能力？感兴趣的可以一起讨论~\n\n## 1.2 关于让AI应用具备长期记忆的一些研究\n\n### 1.2.1 记忆思考：回忆和后思考使LLM具有长期记忆\n\n> 论文原文：Think-in-Memory: Recalling and Post-thinking Enable LLMs with Long-Term Memory\n\n这篇文章提出了一种名为TiM（Think-in-Memory）的记忆机制，旨在使LLM在对话过程中保持记忆，存储历史思考。TiM包括两个关键阶段：在生成回复之前，LLM从记忆中回想相关思考；在生成回复之后，LLM进行后思考并将历史和新思考结合起来更新记忆。\n\n下图描述了TiM方法的使用方式：\n\n（1）在回答第二个问题时，需要考虑问题1的内容，从问题1中推理出答案，而后在回答问题2。 （2）在回答第三个问题时，需要同时考虑问题1和问题2，从问题1和问题2中推理出答案，而后再回答问题3。\n\n这就导致了问题的存在：问题1被推理了两遍，两遍的结果还可能不一样，导致最终的错误。\n\n而TiM的思路，是将每一个问题的思考也存起来，这样，在回答问题3时，可以使用问题2之前的思考，避免重新思考问题1，从而避免多次思考结果不一致导致的错误。\n\n具体步骤如下：\n\n总的原理是，将相关的记忆放到一起，例如上图中，关于book的谈话放到index 0中，关于moive的谈话放到index 1中。\n\n如何将相关内容放到一起的？论文中实现了一种基于局部敏感哈希（LSH）的存储系统，用于高效地存储和检索大规模的向量数据。LSH的作用是将每个向量映射到一个哈希索引，相似的向量有更高的概率被映射到相同的哈希索引。\n\n而相同的哈希索引可以将用户问题固定到某一块记忆中，然后只在这一块记忆中进行向量检索，大大提高了检索效率。\n\n> 这篇文章还是值得精读一下的，数据的组织方式和索引方式都比较高级，很有启发。\n\n### 1.2.2 递归总结在大型语言模型中实现长期对话记忆\n\n> 论文原文：Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models\n\n这篇文章提出了一种递归总结的方法，用于增强大模型的长期记忆能力，以解决在长对话中无法回忆过去信息和生成不一致响应的问题。该方法首先刺激LLM记忆小的对话上下文，然后递归地使用先前的记忆和后续的上下文生成新的记忆。\n\n其流程如下：\n\n简单概括，就是：上一轮的内容总结 \\+ 本轮的问题回答 = 本轮的内容总结。本轮的内容总结 \\+ 下轮的问题回答 = 下轮的内容总结。...... 不断迭代。与 LangChain中 `ConversationSummaryMemory`\xa0的实现很类似。\n\n> 这种方法每一轮都要总结一次，也就是调用一次大模型，使用成本很高啊...... 实际生产中应该落地比较难。\n\n分享：\n\n53AI，企业落地大模型首选服务商\n\n**产品**：场景落地咨询+大模型应用平台+行业解决方案\n\n**承诺**：免费POC验证，效果达标后再合作。 **零风险落地应用大模型**，已交付160+中大型企业\n\n[上一篇：RAGFlow：基于OCR和文档解析的下一代 RAG 引擎] [下一篇：RAGFlow（2）：集成深度文档理解能力的RAG引擎] \n\n[返回列表] \n\n相关资讯\n\n[2025-12-01\\\n\\\nMCP与数据库的完美结合] [2025-11-30\\\n\\\nKnowEval：RAG 工程化的最后一公里，让问答质量有据可依] [2025-11-30\\\n\\\n大模型文本分类：从原理到工程落地（含代码）] [2025-11-29\\\n\\\nRAG 只是 AI 的上半场，OmniThink 才是类人的真思考（深度）] [2025-11-28\\\n\\\n详解用Palantir AIP几分钟搭建一个文档智能搜索应用] [2025-11-27\\\n\\\n从检索增强到自主检索：构建可行动的 Agentic RAG 系统] [2025-11-27\\\n\\\nRAG被判死刑：Google用一行API架空工程师！] [2025-11-27\\\n\\\n目前较优的知识库解决方案] \n\n[了解更多] \n\n[了解更多] \n\n160+中大型企业正在使用53AI\n\n[立即咨询] [预约演示] \n\n[把握AI发展的机遇，共同探索、共同进步\\\n\\\n2025-01-22] [如何打造基于GenAI的员工服务机器人\\\n\\\n2025-01-22] \n\n热点资讯\n\n[RAG彻底爆了！一文掌握其效果优化的架构设计及核心要点\\\n\\\n2025-09-15] [万字长文详解腾讯优图RAG技术的架构设计与创新实践\\\n\\\n2025-09-08] [DeepMind爆火论文：向量嵌入模型存在数学上限，Scaling laws放缓实锤？\\\n\\\n2025-09-03] [关于多模态应用的几个疑问，以及多模态应该怎么应用于RAG？\\\n\\\n2025-09-10] [您应该为您的 RAG 系统使用哪种分块技术？\\\n\\\n2025-09-10] [Embedding与Rerank：90%的RAG系统都搞错了！为什么单靠向量检索会毁了你的AI应用？\\\n\\\n2025-10-04] [存算一体破局向量检索瓶颈，IBM放出王炸VSM：性能飙升100倍，能效碾压GPU千倍，RAG要变天？\\\n\\\n2025-09-30] [企业级 RAG 系统实战（2万+文档）：10 个项目踩过的坑（附代码工程示例）\\\n\\\n2025-10-11] [总结了 13 个 顶级 RAG 技术\\\n\\\n2025-10-12] [通过两个案例，看RAG如何解决大模型的“知识短板”\\\n\\\n2025-09-08] \n\n大家都在问\n\n[RAG知识库迎来大洗牌：GraphRAG如何让机器真正读懂世界？\\\n\\\n2025-11-23] [再谈RAG的文档解析——文档解析的难点在哪里？\\\n\\\n2025-11-20] [为什么RDF是AI系统的“天然知识层”？\\\n\\\n2025-11-19] [大模型生态的“不可能三角”：规模化应用的架构困境？\\\n\\\n2025-11-04] [Embedding与Rerank：90%的RAG系统都搞错了！为什么单靠向量检索会毁了你的AI应用？\\\n\\\n2025-10-04] [存算一体破局向量检索瓶颈，IBM放出王炸VSM：性能飙升100倍，能效碾压GPU千倍，RAG要变天？\\\n\\\n2025-09-30] [您应该为您的 RAG 系统使用哪种分块技术？\\\n\\\n2025-09-10] [关于多模态应用的几个疑问，以及多模态应该怎么应用于RAG？\\\n\\\n2025-09-10] \n\n热门标签\n\n[内容创作] [大模型技术] [个人提效] [langchain] [llamaindex] [多模态技术] [RAG技术] [智能客服] [知识图谱] [模型微调] [RAGFlow] [coze] [Dify] [Fastgpt] [Bisheng] [Qanything] [AI+汽车] [AI+金融] [AI+工业] [AI+培训] [AI+SaaS] [提示词框架] [提示词技巧] [AI+电商] [AI面试] [数字员工] [ChatBI] [AI知识库] [开源大模型] [智能营销] [智能硬件] [智能化改造] [AI+医疗] [MaxKB] \n\n[应聘简历请发送至： ceo@53ai.com] \n\n联系我们\n\n售前咨询\n\n[186 6662 7370] \n\n预约演示\n\n[185 8882 0121] \n\n微信扫码\n\n添加专属顾问\n\n回到顶部\n\n加载中...\n\n扫码咨询\n\n[预约演示] [微信咨询] [电话咨询]', 'doi': '', 'published_date': '2024-05-05T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.53ai.com/news/RAG/1732.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的 ...', 'authors': [], 'abstract': '《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的智能系统[译] - Gino Notes\n![Gino] Gino\n# 《智能体设计模式》之记忆管理模式：打造具备学习与记忆能力的智能系统[译]\n2025年11月01日30分钟阅读[人工智能] \n## [] 《智能体设计模式》中文翻译计划启动\n正如《设计模式》曾是软件工程的圣经，这本由谷歌资深工程主管免费分享的《智能体设计模式》，正为火热的AI 智能体领域带来首套系统性的设计原则与最佳实践。本书由Antonio Gulli 撰写、谷歌Cloud AI 副总裁Saurabh Tiwary 作序、高盛CIO Marco Argenti 鼎力推荐，系统性地提炼出21 个核心智能体设计模式，涵盖从提示链、工具使用到多智能体协作、自我修正等关键技术。接下来的一段时间，我将和几位小伙伴一起通过「AI 初次翻译→AI 交叉评审→人工评审→人工交叉评审」的方式来翻译这本书，所有翻译内容将会持续更新到开源项目：[github.com/ginobefun/agentic-design-patterns-cn] \n已翻译章节：* [00 -《智能体设计模式》前言部分] \n* [01 -《智能体设计模式》第一章：提示链模式] \n* [02 -《智能体设计模式》第二章：路由模式] \n* [03 -《智能体设计模式》第三章：并行模式] \n* [04 -《智能体设计模式》第四章：反思模式] \n* [05 -《智能体设计模式》第五章：工具使用模式] \n* [06 -《智能体设计模式》第六章：规划模式] \n* [07 -《智能体设计模式》第七章：智能体协作模式] \n* [08 -《智能体设计模式》第八章：记忆管理模式] ## [] 记忆管理模式精华概览\n记忆管理是智能体系统的核心能力，使其能够保留历史信息、从经验中学习并提供连贯一致的交互体验。与人类类似，智能体需要同时具备短期记忆和长期记忆才能高效运作，从而超越简单的一次性问答，展现出真正的智能行为。这里为大家梳理几个关键要点：### [] 1. 核心理念：双层记忆架构记忆管理的核心在于建立「短期上下文+ 长期知识」的双层存储架构，让智能体既能处理即时信息，又能积累和调用持久化知识。* **短期记忆（上下文记忆）**：类似工作记忆，存储当前对话中的即时信息，主要存在于大语言模型的上下文窗口内，包括最近的对话、工具调用结果等。具有临时性，会话结束后即丢失，容量受限于上下文窗口大小。\n* **长期记忆（持久记忆）**：充当长期知识库，存储需要跨会话保留的信息，通常使用外部数据库或向量数据库实现。支持语义搜索，智能体可基于相似性而非精确匹配来检索相关信息。### [] 2. 关键组件与架构不同框架提供了结构化的记忆管理组件：* **Google ADK 三件套**：\n* `Session`（会话）：跟踪独立的聊天会话，记录消息和执行动作\n* `State`（状态）：存储会话内的临时数据，支持键前缀管理数据范围（`user:`、`app:`、`temp:`）\n* `MemoryService`（记忆服务）：管理长期知识的存储与检索，提供多种实现方式（内存、数据库、Vertex AI）\n* **LangChain/LangGraph**：\n* `ChatMessageHistory`：手动管理对话历史\n* `ConversationBufferMemory`：自动将历史注入提示词\n* `BaseStore`：支持跨会话的长期记忆存储，使用命名空间组织数据### [] 3. 典型应用场景记忆管理在五大领域发挥关键作用：* **聊天机器人与对话式 AI**：维持对话流程，记住用户偏好和历史问题，提供连贯个性化的交互体验。\n* **任务导向型智能体**：跟踪多步骤任务的进度、已完成步骤和总体目标，访问用户特定的非即时数据。\n* **个性化体验服务**：存储和调用用户偏好、历史行为模式，动态调整响应策略和建议内容。\n* **信息检索（RAG）**：访问知识库支撑问答准确性，在 RAG 框架中提供上下文增强。* **自主控制系统**：存储地图、导航路线、物体位置等环境知识，结合实时感知和通用知识。### [] 4. 长期记忆的三种类型类比人类记忆机制，长期记忆可分为三类：* **语义记忆（事实记忆）**：存储具体事实和概念知识，如用户偏好或领域知识，可作为用户档案（JSON 文档）或文档集合管理。* **情景记忆（经历记忆）**：回忆过往事件或行为序列，通常通过少样本示例提示实现，智能体从历史成功交互中学习。\n* **程序性记忆（规则记忆）**：关于如何执行任务的规则和行为规范，体现在系统提示词中，可通过反思机制自适应优化。### [] 5. 使用时机与最佳实践当智能体需要超越单次问答时，应实施记忆管理：* **适用场景**：需要维持对话上下文；跟踪多步骤任务进度；提供个性化交互；基于历史学习和改进；处理复杂时序依赖问题。\n* **核心价值**：使智能体从无状态的简单响应者进化为具备记忆、学习和个性化能力的智能系统，能够维护历史记录并持续改进。\n以下为原书第八章记忆管理设计模式的内容，译者：[@redpomegranate] ，评审：[@Gino] \n有效的记忆管理是智能体保留信息的关键。与人类类似，智能体需要多种类型的记忆才能高效运行。本章将深入探讨记忆管理，重点聚焦于智能体的即时（短期）和持久（长期）记忆需求。在智能体系统中，**记忆**指智能体从过往交互、观察和学习经验中保留并利用信息的能力。这一能力使智能体能够做出明智决策、维持对话上下文，并持续改进。智能体记忆通常可分为两大主要类型：\n* **短期记忆（上下文记忆）**：类似于工作记忆，存储当前正在处理或近期访问的信息。对于基于大语言模型的智能体，短期记忆主要存在于上下文窗口内。该窗口包含最近的对话消息、智能体回复、工具调用结果以及当前交互中的反思内容，这些信息共同为后续的响应和决策提供上下文支撑。上下文窗口的容量有限，限制了智能体可直接访问的近期信息范围。高效的短期记忆管理需要在有限空间内选择性地保留最相关信息，可通过总结旧对话片段或强调关键细节等技术实现。具有「长上下文」窗口的模型虽然扩大了短期记忆容量，允许在单次交互中保存更多信息，但这种上下文仍然是短暂的，会话结束后即丢失，且每次处理成本高昂、效率较低。因此，智能体需要不同类型的记忆来实现真正的持久化，从过往交互中回忆信息并构建持久的知识库。\n* **长期记忆（持久记忆）**：充当一个长期知识库，用于存储智能体在各种交互场景、任务执行或长时间跨度内需要保留的信息。数据通常存储在智能体的运行时环境之外，常见于数据库、知识图谱或向量数据库中。在向量数据库中，信息被转换为数值向量并存储，使智能体能够基于语义相似性而非精确关键词匹配来检索数据，这个过程被称为语义搜索。当智能体需要长期记忆中的信息时，会查询外部存储、检索相关数据并将其整合到短期上下文中以便随时使用，从而将先验知识与当前交互信息相结合。\n## [] 实际应用场景\n记忆管理对于智能体至关重要，使其能够持续跟踪信息并在长时间运行中表现出智能行为。这一能力是智能体超越基础问答、展现高级智能的关键。主要应用场景包括：* **聊天机器人和对话式 AI：**维持对话流程依赖于短期记忆。聊天机器人需要记住先前的用户输入才能提供连贯的回答。长期记忆使聊天机器人能够调取用户偏好、过往问题或过往对话记录，从而提供个性化且连续一致的交互体验。\n* **任务导向型智能体：**处理多步骤任务的智能体需要借助短期记忆来跟踪已完成步骤、当前进度状态及总体目标。这些信息通常存储在任务上下文或临时缓存中。长期记忆对于访问非即时上下文的用户特定数据至关重要。\n* **个性化体验服务：**提供定制化交互的智能体利用长期记忆系统来存储和调用用户偏好、历史行为模式及个人信息。这种能力使得智能体能够动态调整其响应策略和建议内容。\n* **信息检索（RAG）：**为问答场景设计的智能体需要访问知识库（即长期记忆），这一功能通常在检索增强生成（RAG）框架中实现。智能体通过检索相关文档和数据资源来支撑其回答的准确性和完整性。\n* **自主控制系统：**机器人或自动驾驶车辆需要记忆系统来存储地图信息、导航路线、物体位置以及学习获得的行为模式。这包括用于实时环境感知的短期记忆和用于通用环境知识存储的长期记忆。\n记忆能力使智能体能够维护历史记录、实现持续学习、提供个性化交互，并有效处理复杂的时序依赖性问题。## [] 实战代码：使用 Google ADK\nGoogle ADK 提供了一套结构化的上下文与记忆管理方法，包含多个可直接应用于实际场景的组件。深入理解ADK 中会话（Session）、状态（State）和记忆（Memory）这三个核心概念，对于构建需要信息持久化能力的智能体至关重要。\n正如人类交流需要记忆，智能体同样需要具备回忆历史对话的能力，才能进行连贯自然的交流。ADK 通过三个核心概念及其配套服务，简化了上下文管理的复杂性。每次与智能体的交互都可视为一个独立的对话，而智能体往往需要访问历史交互数据。ADK 通过以下架构组织这些信息：* **Session（会话）：**一个独立的聊天会话，记录特定交互过程中的消息和执行动作（事件），同时存储与该对话相关的临时数据（状态）。\n* **State（状态，`session.state`）：**存储在会话内部的数据，仅包含与当前活跃聊天会话相关的上下文信息。\n* **Memory（记忆）：**一个可检索的信息知识库，数据来源包括历史聊天记录和外部数据源，为超越当前对话范围的数据检索提供支持。\nADK 提供专门的服务组件，它们是构建有状态、上下文感知的智能体的关键要素。`SessionService`负责管理聊天会话（`Session`对象），处理会话的创建、记录和终止，而`MemoryService`负责长期知识（`Memory`）的存储与检索。\n`SessionService`和`MemoryService`均提供多种配置选项，允许开发者根据应用需求选择合适的存储方案。比如内存存储适用于测试环境，数据不会持久化，在重启后会丢失。对于需要持久化存储和可扩展性等需求，ADK 支持使用数据库和云服务。### [] Session：跟踪每次聊天\nADK 中的`Session`对象用于跟踪和管理独立的聊天会话。\n当用户与智能体开始对话时，`SessionService`会生成一个`Session`对象（`google.adk.sessions.Session`）。该对象封装特定对话线程的所有相关数据，包括唯一标识符（`id`、`app\\_name`、`user\\_id`）、按时间顺序记录的事件对象、用于会话临时数据（也称为状态）的存储区域，以及指示最后更新时间的时间戳（`last\\_update\\_time`）。\n开发者通常通过`SessionService`与`Session`对象交互。`SessionService`负责管理对话会话的生命周期，包括启动新会话、恢复先前会话、记录会话活动（含状态更新）、识别活跃会话以及删除会话数据等。\nADK 内置了多种`SessionService`实现，具有不同的会话历史和临时数据存储机制。例如`InMemorySessionService`适用于测试环境，因为它不会在应用重启后保持数据持久化。\n```\n`# 示例：使用InMemorySessionService# 注意：数据不会持久化，应用重启后会丢失，仅适用于本地开发和测试环境。fromgoogle.adk.sessionsimportInMemorySessionServicesession\\_service=InMemorySessionService()`\n```\nThen there&#x27;s DatabaseSessionService if you want reliable saving to a database you manage.\n如果你需要将数据保存到自行管理的数据库中，还可以选择`DatabaseSessionService`。\n```\n`# 示例：使用DatabaseSessionService# 这适用于需要持久存储的生产环境或开发环境。# 你需要配置数据库URL（例如，用于 SQLite、PostgreSQL 等）。# 安装依赖：pip install google-adk[sqlalchemy] 和数据库驱动（例如，PostgreSQL 的psycopg2）fromgoogle.adk.sessionsimportDatabaseSessionService# 使用本地SQLite 文件的示例：db\\_url=&quot;&quot;sqlite:///./my\\_agent\\_data.db&quot;&quot;session\\_service=DatabaseSessionService(db\\_url=db\\_url)`\n```\nBesides, there&#x27;s VertexAiSessionService which uses Vertex AI infrastructure for scalable production on Google Cloud.\n此外，还有`VertexAiSessionService`，它使用 Google Cloud 上Vertex AI 的基础设施以满足可扩展的生产部署要求。```\n`# 示例：使用VertexAiSessionService# 这适用于Google Cloud Platform 上的可扩展要求的生产环境，利用Vertex AI 基础设施进行会话管理。# 安装依赖：pip install google-adk[vertexai] 以及GCP 设置/身份验证fromgoogle.adk.sessionsimportVertexAiSessionServicePROJECT\\_ID=&quot;your-gcp-project-id&quot;# 替换为你的GCP 项目IDLOCATION=&quot;us-central1&quot;# 替换为你所需的GCP 位置# 与此服务一起使用的app\\_name 应对应于Reasoning Engine ID 或名称REASONING\\_ENGINE\\_APP\\_NAME=&quot;projects/your-gcp-project-id/locations/us-central1/reasoningEngines/your-engine-id&quot;# 替换为你的Reasoning Engine 资源名称session\\_service=VertexAiSessionService(project=PROJECT\\_ID,location=LOCATION)# 使用此服务时，将REASONING\\_ENGINE\\_APP\\_NAME 传递给以下方法：# session\\_service.create\\_session(app\\_name=REASONING\\_ENGINE\\_APP\\_NAME, ...)# session\\_service.get\\_session(app\\_name=REASONING\\_ENGINE\\_APP\\_NAME, ...)# session\\_service.append\\_event(session, event, app\\_name=REASONING\\_ENGINE\\_APP\\_NAME)# session\\_service.delete\\_session(app\\_name=REASONING\\_ENGINE\\_APP\\_NAME, ...)`\n```\n选择合适的`SessionService`至关重要，因为它决定了智能体的交互历史和临时数据如何存储以及持久化方式。\n每次消息交换都遵循以下流程：接收消息后，`Runner`通过`SessionService`检索或创建对应的`Session`，智能体利用`Session`的上下文（包括状态和历史交互）来处理消息，接着智能体生成响应并更新状态，`Runner`将其封装为`Event`事件，`session\\_service.append\\_event`方法记录该事件并更新状态。然后`Session`继续等待下一条消息。理想情况下，在交互结束时应该使用`delete\\_session`方法终止会话。\n以上过程展示了`SessionService`如何通过管理`Session`特定的历史和临时数据来维持连续性。\n### [] State：会话暂存区\n在ADK 中，每个代表聊天会话的`Session`都包含一个状态组件，类似于智能体在该特定对话期间的临时工作记忆。`session.events`记录整个聊天历史，而`session.state`则存储和更新与当前会话相关的动态信息。\n`session.state`本质上是一个字典（Dictionary），以键值对（Key-Value Pairs）形式存储数据。其主要功能是帮助智能体保留和管理对话连贯性所需的关键信息，例如用户偏好、任务进展、增量数据收集，或影响后续智能体行为的条件标志。\n状态结构由字符串键与可序列化Python 类型值组成，包括字符串、数字、布尔值、列表以及包含这些基本类型的字典。状态是动态的，在整个对话过程中不断演化。这些更改的持久性取决于所使用的`SessionService`。\n可以通过键前缀来管理数据范围和持久性，从而实现有效的状态组织。不带前缀的键属于会话级别的。* **user:**该前缀的数据为用户级别，和用户 ID 关联，可以跨多个会话使用。* **app:**该前缀的数据为应用级别，可以在应用内被所有用户共享。\n* **temp:**该前缀的数据为临时数据，仅在当前处理轮次内有效，不会被持久化。\n智能体通过统一的`session.state`字典访问所有状态数据。`SessionService`负责处理数据的检索、合并和持久化。状态更新应该通过`session\\_service.append\\_event()`向会话历史添加事件来实现。这样可以确保跟踪的完整性，持久化服务中的正确保存以及安全的状态变更。\n**1. 简单方法：使用`output\\_key`（用于智能体输出的文本）**如果只需将智能体的最终响应直接保存到状态中，这是最简单的方法。定义`LlmAgent`时，只需指定要使用的`output\\_key`属性。`Runner`会识别此参数设置，并创建必要的操作来将响应保存到状态中。我们来看一个通过`output\\_key`实现状态更新的代码示例。\n```\n`# 从Google ADK 导入必要的类fromgoogle.adk.agentsimportLlmAgentfromgoogle.adk.sessionsimportInMemorySessionService, Sessionfromgoogle.adk.runnersimportRunnerfromgoogle.genai.typesimportContent, Part# 定义一个带有output\\_key 的LlmAgent。greeting\\_agent=LlmAgent(name=&quot;Greeter&quot;,model=&quot;gemini-2.0-flash&quot;,instruction=&quot;Generate a short, friendly greeting.&quot;,output\\_key=&quot;&quot;last\\_greeting&quot;&quot;)# --- 设置Runner 和Session ---app\\_name, user\\_id, session\\_id=&quot;&quot;state\\_app&quot;&quot;,&quot;user1&quot;,&quot;session1&quot;session\\_service=InMemorySessionService()runner=Runner(agent=greeting\\_agent,app\\_name=app\\_name,session\\_service=session\\_service)session=session\\_service.create\\_session(app\\_name=app\\_name,user\\_id=user\\_id,session\\_id=session\\_id)print(f&quot;Initial state:{session.state}&quot;)# --- 运行智能体---user\\_message=Content(parts=[Part(text=&quot;Hello&quot;)])print(&quot;\\\\n--- Running the agent ---&quot;)foreventinrunner.run(user\\_id=user\\_id,session\\_id=session\\_id,new\\_message=user\\_message):ifevent.is\\_final\\_response():print(&quot;Agent responded.&quot;)# --- 检查更新后的状态---# 在runner 完成处理所有事件后正确检查状态。updated\\_session=session\\_service.get\\_session(app\\_name, user\\_id, session\\_id)print(f&quot;\\\\nState after agent run:{updated\\_session.state}&quot;)`\n```\n在幕后，`Runner`会识别`output\\_key`，并在调用`append\\_event`时自动创建带有`state\\_delta`的必要操作。\n**2. 标准方法：使用EventActions.state\\_delta（用于更复杂的场景）**当需要进行更复杂的操作时，例如同时更新多个键、保存非纯文本内容、针对特定作用域（如`user:`或`app:`），或者执行与智能体最终文本回复无关的更新时，需要手动构建状态变更的字典（即`state\\_delta`），并将其放在要附加的`Event`的`EventActions`中。让我们来看一个示例：\n```\n`importtimefromgoogle.adk.tools.tool\\_contextimportToolContextfromgoogle.adk.sessionsimportInMemorySessionService# --- 定义推荐的基于工具的方法---deflog\\_user\\_login(tool\\_context: ToolContext) -&gt;&gt;dict:&quot;&quot;&quot;在用户登录事件时更新会话状态。此工具封装了与用户登录相关的所有状态更改。参数：tool\\_context：由 ADK 自动提供，提供对会话状态的访问。返回：确认操作成功的字典。&quot;&quot;&quot;# 通过提供的上下文直接访问状态。', 'doi': '', 'published_date': '2025-11-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://ginonotes.com/posts/agentic-design-patterns-memory-management-translation', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '短期记忆持久化存储和记忆管理策略】2026必学！LangChain最新V1 ...', 'authors': [], 'abstract': 'YouTube、B站频道关于LangChain V1.x、LangGraph V1.x、LangSmith及DeepAgents等开发经验分享，所有资源全部开源免费，仓库如下： \\nGitHub地址: https://github.com/NanGePlus/LangChai... \\nGitee地址: https://gitee.com/NanGePlus/LangChain... \\n\\n🙏🏻如果内容对你有帮助，拜托给我的视频点个赞，你们的支持就是我持续开源分享的功力 \\n个人项目GitHub地址：https://github.com/NanGePlus \\n个人项目Gitee地址：https://gitee.com/NanGePlus \\n大模型代理平台: https://nangeai.top/ \\n\\n【章节】\\n\\n0:00 引言 源代码下载方式\\n0:37 核心功能\\n1:37 核心概念介绍\\n8:37 准备工作和项目初始化\\n13:27 InMemorySaver测试和源码\\n18:16 PostgresSaver测试和源码\\n21:33 管理策略测试和源码\\n24:05 最后 总结\\n\\n频道项目\\u0026视频推荐：\\n1. 8n自动化工作流平台相关分享 \\nhttps://github.com/NanGePlus/N8NWorkf... \\n\\n2. 大模型应用技术开发-入门系列 \\nhttps://github.com/NanGePlus/LLMsBasi... \\n \\n3. 大模型应用技术开发-MCP系列\\nhttps://github.com/NanGePlus/MCPServe... \\n\\n4. 大模型应用技术开发-RAG系列 \\nhttps://github.com/NanGePlus/RagWithM... \\nhttps://github.com/NanGePlus/LightRAG... \\nhttps://github.com/NanGePlus/KagTest \\n\\n5. 大模型应用技术开发-Agent系列 \\nhttps://github.com/NanGePlus/ReActAge... \\nhttps://github.com/NanGePlus/CrewAIFl... \\nhttps://github.com/NanGePlus/AutoGenV... \\n \\n6. 大模型应用技术开发-Fine-Tuning大模型微调系列 \\nhttps://github.com/NanGePlus/FineTuni...\n| view_count: 55 views | short_view_count: 55 views | num_likes: 4 likes | num_subscribers: 2.95 thousand | duration: 24 minutes 10 seconds', 'doi': '', 'published_date': '2026-01-15T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.youtube.com/watch?v=rEhoJaNStzI', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '概述 - LangChain 框架', 'authors': [], 'abstract': '概述 - LangChain 框架[跳到内容] \n**我们正在发展壮大，为LangChain、LangGraph和LangSmith招聘多个职位。[加入我们的团队！] **\n[] # 内存[¶] \n## 什么是内存？[¶] \n[内存] 是一种认知功能，它使人们能够存储、检索和使用信息来理解他们的现在和未来。想想看，与一个总是忘记你告诉他们的事情、需要不断重复的同事共事是多么令人沮丧！随着AI代理承担涉及大量用户交互的更复杂任务，为它们配备内存对于效率和用户满意度同样至关重要。通过内存，代理可以从反馈中学习并适应用户的偏好。本指南涵盖了基于召回范围的两种内存类型\n**短期记忆**，或[线程] 范围的记忆，可以随时**从**单个用户对话线程中召回。LangGraph将短期记忆作为代理[状态] 的一部分进行管理。状态通过[检查点] 持久化到数据库中，以便线程可以随时恢复。短期记忆在图被调用或步骤完成时更新，并在每个步骤开始时读取状态。\n**长期记忆**在对话线程**之间共享**。它可以在*任何时候*和**任何线程中**召回。记忆可以限定在任何自定义命名空间，而不仅仅是单个线程ID。LangGraph提供[存储] （[参考文档] ）来让你保存和召回长期记忆。\n这两种记忆对于你的应用程序都非常重要，需要理解并实现。![] \n## 短期记忆[¶] \n短期记忆允许你的应用程序记住单个[线程] 或对话中的先前交互。[线程] 在一个会话中组织多个交互，类似于电子邮件将消息分组到单个对话中的方式。\nLangGraph将短期记忆作为代理状态的一部分进行管理，通过线程范围的检查点持久化。这种状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索到的文档或生成的工件。通过将这些存储在图的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。\n由于对话历史是表示短期记忆最常见的形式，在下一节中，我们将介绍在消息列表变得**很长**时管理对话历史的技术。如果你想坚持高层概念，请继续阅读[长期记忆] 部分。\n### 管理长对话历史记录[¶] \n长对话对当今的LLM构成了挑战。完整的历史记录甚至可能无法完全放入LLM的上下文窗口中，导致不可恢复的错误。即使你的LLM技术上支持完整的上下文长度，大多数LLM在长上下文下表现仍然不佳。它们会被过时或偏离主题的内容“分散注意力”，同时响应时间变慢，成本也更高。\n管理短期记忆是平衡[精确度与召回率] 与应用程序其他性能要求（延迟和成本）之间的练习。一如既往，批判性地思考如何为你的LLM表示信息并查看你的数据非常重要。我们将在下面介绍一些管理消息列表的常用技术，并希望为你提供足够的上下文，以便你为应用程序选择最佳的权衡方案\n* [编辑消息列表] ：如何考虑在传递给语言模型之前修剪和过滤消息列表。\n* [总结过往对话] ：当你不仅仅想过滤消息列表时，一种常用的技术。### 编辑消息列表[¶] \n聊天模型使用[消息] 接受上下文，其中包括开发者提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随时间增长。由于上下文窗口有限，并且包含大量token的消息列表可能成本高昂，许多应用程序可以通过使用手动删除或忘记过时信息的技术而受益。\n![] \n最直接的方法是从列表中删除旧消息（类似于[最近最少使用缓存] ）。\n在LangGraph中，从列表中删除内容的典型技术是从节点返回一个更新，告诉系统删除列表的某些部分。你可以定义这种更新的样式，但一种常见的方法是让你返回一个对象或字典，指定要保留哪些值。\n```\n`[] defmanage\\_list(existing:list,updates:Union[list,dict]):[] ifisinstance(updates,list):[] # Normal case, add to the history[] returnexisting+updates[] elifisinstance(updates,dict)andupdates["type"]=="keep":[] # You get to decide what this looks like.[] # For example, you could simplify and just accept a string "DELETE"[] # and clear the entire list.[] returnexisting[updates["from"]:updates["to"]][] # etc. We define how to interpret updates[] [] classState(TypedDict):[] my\\_list:Annotated[list,manage\\_list][] [] defmy\\_node(state:State):[] return{[] # We return an update for the field "my\\_list" saying to[] # keep only values from index -5 to the end (deleting the rest)[] "my\\_list":{"type":"keep","from":-5,"to":None}[]}`\n```\n只要在"my\\_list"键下返回更新，LangGraph就会调用`manage\\_list`"[reducer] "函数。在该函数中，我们定义接受哪些类型的更新。通常，消息会被添加到现有列表中（对话会增长）；但是，我们也添加了对接受字典的支持，该字典允许你"保留"状态的某些部分。这允许你通过编程方式删除旧的消息上下文。\n另一种常见的方法是让你返回一个“移除”对象的列表，该列表指定要删除的所有消息的ID。如果你在LangGraph中使用LangChain消息和[`add\\_messages`] reducer（或`MessagesState`，它使用相同的基础功能），你可以使用`RemoveMessage`来完成此操作。\n*API参考：[RemoveMessage] |[AIMessage] |[add\\_messages] *\n```\n`[] fromlangchain\\_core.messagesimportRemoveMessage,AIMessage[] fromlanggraph.graphimportadd\\_messages[] # ... other imports[] [] classState(TypedDict):[] # add\\_messages will default to upserting messages by ID to the existing list[] # if a RemoveMessage is returned, it will delete the message in the list by ID[] messages:Annotated[list,add\\_messages][] [] defmy\\_node\\_1(state:State):[] # Add an AI message to the `messages` list in the state[] return{"messages":[AIMessage(content="Hi")]}[] [] defmy\\_node\\_2(state:State):[] # Delete all but the last 2 messages from the `messages` list in the state[] delete\\_messages=[RemoveMessage(id=m.id)forminstate[\'messages\'][:-2]][] return{"messages":delete\\_messages}`\n```\n在上面的示例中，`add\\_messages`reducer允许我们将新消息[追加] 到`messages`状态键，如`my\\_node\\_1`中所示。当它看到一个`RemoveMessage`时，它将从列表中删除该ID的消息（然后`RemoveMessage`将被丢弃）。有关LangChain特定消息处理的更多信息，请查看[此关于使用`RemoveMessage`的操作指南] 。\n有关示例用法，请参阅此操作[指南] 以及我们[LangChain Academy] 课程的模块2。\n### 总结过往对话[¶] \n如上所示，修剪或移除消息的问题在于，我们可能会因为消息队列的淘汰而丢失信息。因此，一些应用程序受益于使用聊天模型总结消息历史的更复杂方法。![] \n可以使用简单的提示和编排逻辑来实现此目的。例如，在LangGraph中，我们可以扩展[MessagesState] 以包含一个`summary`键。\n```\n`[] fromlanggraph.graphimportMessagesState[] classState(MessagesState):[] summary:str`\n```\n然后，我们可以生成聊天历史的摘要，使用任何现有摘要作为下一个摘要的上下文。这个`summarize\\_conversation`节点可以在`messages`状态键中积累一定数量的消息后被调用。\n```\n`[] defsummarize\\_conversation(state:State):[] [] # First, we get any existing summary[] summary=state.get("summary","")[] [] # Create our summarization prompt[] ifsummary:[] [] # A summary already exists[] summary\\_message=([] f"This is a summary of the conversation to date:{summary}\\\\n\\\\n"[] "Extend the summary by taking into account the new messages above:"[])[] [] else:[] summary\\_message="Create a summary of the conversation above:"[] [] # Add prompt to our history[] messages=state["messages"]+[HumanMessage(content=summary\\_message)][] response=model.invoke(messages)[] [] # Delete all but the 2 most recent messages[] delete\\_messages=[RemoveMessage(id=m.id)forminstate["messages"][:-2]][] return{"summary":response.content,"messages":delete\\_messages}`\n```\n有关示例用法，请参阅[此处] 的此操作指南，以及我们[LangChain Academy] 课程的模块2。\n### 知道**何时**移除消息[¶] \n大多数LLM都有一个最大支持的上下文窗口（以token计）。一个决定何时截断消息的简单方法是计算消息历史中的token数量，并在接近该限制时进行截断。简单的截断很容易自行实现，尽管有一些“陷阱”。一些模型API进一步限制了消息类型的顺序（必须以人类消息开始，不能有连续的相同类型的消息等）。如果你正在使用LangChain，你可以使用[`trim\\_messages`] 实用程序，并指定要从列表中保留的token数量，以及用于处理边界的`strategy`（例如，保留最后`max\\_tokens`）。\n下面是一个例子。*API参考：[trim\\_messages] *\n```\n`[] fromlangchain\\_core.messagesimporttrim\\_messages[] trim\\_messages([] messages,[] # Keep the last &lt;&lt;= n\\_count tokens of the messages.[] strategy="last",[] # Remember to adjust based on your model[] # or else pass a custom token\\_encoder[] token\\_counter=ChatOpenAI(model="gpt-4"),[] # Remember to adjust based on the desired conversation[] # length[] max\\_tokens=45,[] # Most chat models expect that chat history starts with either:[] # (1) a HumanMessage or[] # (2) a SystemMessage followed by a HumanMessage[] start\\_on="human",[] # Most chat models expect that chat history ends with either:[] # (1) a HumanMessage or[] # (2) a ToolMessage[] end\\_on=("human","tool"),[] # Usually, we want to keep the SystemMessage[] # if it\'s present in the original history.[] # The SystemMessage has special instructions for the model.[] include\\_system=True,[])`\n```\n## 长期记忆[¶] \nLangGraph中的长期记忆允许系统在不同的对话或会话中保留信息。与**线程范围**的短期记忆不同，长期记忆保存在自定义的“命名空间”中。\n### 存储记忆[¶] \nLangGraph将长期记忆作为JSON文档存储在[存储] 中（[参考文档] ）。每个记忆都组织在一个自定义的`namespace`（类似于文件夹）和一个独特的`key`（像文件名）之下。命名空间通常包括用户或组织ID或其他标签，以便于组织信息。这种结构实现了记忆的层次化组织。通过内容过滤器支持跨命名空间搜索。请参阅下面的示例。\n```\n`[] fromlanggraph.store.memoryimportInMemoryStore[] [] [] defembed(texts:list[str])-&gt;list[list[float]]:[] # Replace with an actual embedding function or LangChain embeddings object[] return[[1.0,2.0]\\*len(texts)][] [] [] # InMemoryStore saves data to an in-memory dictionary. Use a DB-backed store in production use.[] store=InMemoryStore(index={"embed":embed,"dims":2})[] user\\_id="my-user"[] application\\_context="chitchat"[] namespace=(user\\_id,application\\_context)[] store.put([] namespace,[] "a-memory",[] {[] "rules":[[] "User likes short, direct language",[] "User only speaks English &amp; python",[]],[] "my-key":"my-value",[]},[])[] # get the "memory" by ID[] item=store.get(namespace,"a-memory")[] # search for "memories" within this namespace, filtering on content equivalence, sorted by vector similarity[] items=store.search([] namespace,filter={"my-key":"my-value"},query="language preferences"[])`\n```\n### 长期记忆的思考框架[¶] \n长期记忆是一个复杂的挑战，没有一劳永逸的解决方案。然而，以下问题提供了一个结构化框架，帮助你探索不同的技术**记忆的类型是什么？**\n人类利用记忆来记住[事实] 、[经验] 和[规则] 。AI代理也可以以相同的方式使用记忆。例如，AI代理可以使用记忆来记住关于用户的具体事实以完成任务。我们将在[下面的部分] 中详细介绍几种记忆类型。\n**你希望何时更新记忆？**\n记忆可以作为代理应用程序逻辑的一部分进行更新（例如，“在热路径上”）。在这种情况下，代理通常在响应用户之前决定记住事实。或者，记忆可以作为后台任务进行更新（在后台/异步运行并生成记忆的逻辑）。我们将在[下面的部分] 中解释这些方法之间的权衡。\n## 记忆类型[¶] \n不同的应用程序需要各种类型的记忆。尽管类比并不完美，但研究[人类记忆类型] 可以提供深刻的见解。一些研究（例如，[CoALA论文] ）甚至将这些人类记忆类型映射到了AI代理中使用的类型。\n|记忆类型|存储内容|人类示例|代理示例|\n语义|事实|我在学校学到的东西|关于用户的事实|\n情景|经验|我做过的事情|代理过去的行动|\n程序|指令|本能或运动技能|代理系统提示|\n### 语义记忆[¶] \n[语义记忆] ，无论是对人类还是AI代理，都涉及特定事实和概念的保留。在人类中，它可能包括在学校学到的信息以及对概念及其关系的理解。对于AI代理，语义记忆通常用于通过记住过去交互中的事实或概念来个性化应用程序。\n> > 注意：不要与“语义搜索”混淆，后者是使用“意义”（通常作为嵌入）查找相似内容的技术。语义记忆是心理学中的一个术语，指的是存储事实和知识，而语义搜索是根据意义而非精确匹配检索信息的方法。> #### 个人资料[¶] \n语义记忆可以通过不同方式进行管理。例如，记忆可以是一个单一的、持续更新的“配置文件”，其中包含关于用户、组织或其他实体（包括代理本身）的范围明确且具体的信息。配置文件通常只是一个JSON文档，包含你为表示你的领域而选择的各种键值对。\n在记忆配置文件时，你会希望确保每次都**更新**配置文件。因此，你会希望传入先前的配置文件并[要求模型生成新的配置文件] （或应用于旧配置文件的某些[JSON补丁] ）。随着配置文件变大，这可能会变得容易出错，并且可能受益于将配置文件拆分为多个文档或生成文档时进行**严格**解码，以确保记忆模式保持有效。\n![] \n#### 集合[¶] \n或者，记忆可以是一个文档集合，随着时间的推移不断更新和扩展。每个单独的记忆可以更狭窄地限定范围，更容易生成，这意味着你随着时间的推移**丢失**信息的可能性更小。LLM更容易为新信息生成*新*对象，而不是将新信息与现有配置文件进行协调。因此，文档集合往往会带来[更高的下游召回率] 。\n然而，这会增加内存更新的复杂性。模型现在必须*删除*或*更新*列表中的现有项目，', 'doi': '', 'published_date': '2026-02-02T20:17:10.321086', 'pdf_url': '', 'url': 'https://langgraph.com.cn/concepts/memory.1.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '核心概念 - LangChain 框架', 'authors': [], 'abstract': '核心概念 - LangChain 教程[跳到内容] \n[] # LLM 应用中的长期记忆[¶] \n长期记忆允许智能体在多次对话中记住重要信息。LangMem 提供了从聊天中提取有意义的细节、存储它们并用于改善未来互动的方法。其核心在于，LangMem 中的每个记忆操作都遵循相同的模式：1. 接收对话和当前记忆状态2. 提示LLM 以决定如何扩展或整合记忆状态3. 返回更新后的记忆状态最好的记忆系统通常是针对特定应用的。在设计您的系统时，以下问题可以作为有用的指南：1. **什么内容**：您的智能体应该学习哪种[类型的内容] ：事实/知识？过去事件的摘要？规则和风格？\n2. **何时**（以及**由谁**）应该[形成记忆] ？\n3. 记忆应该[存储在**何处**] ？（在提示中？语义存储中？）。这在很大程度上决定了它们将如何被回忆。## 记忆类型[¶] \nLLM 应用中的记忆可以反映人类记忆的某些结构，每种类型在构建自适应、具备上下文感知能力的系统中都扮演着独特的角色。|记忆类型|用途|智能体示例|人类示例|典型存储模式|\n语义记忆|事实与知识|用户偏好；知识三元组|知道 Python 是一门编程语言|资料卡或集合|\n情景记忆|过往经历|少样本示例；过去对话的摘要|记得第一天上班的情景|集合|\n程序性记忆|系统行为|核心个性和响应模式|知道如何骑自行车|提示规则或集合|\n### 语义记忆：事实与知识[¶] \n[语义记忆] 存储了支撑智能体响应的基本事实和其他信息。语义记忆的两种常见表示形式是集合（用于记录可在运行时搜索的无限量知识）和资料卡（用于记录遵循严格模式且易于按用户或智能体查找的任务特定信息）。\n#### 集合[¶] \n集合是大多数人想象智能体长期记忆时的第一印象。在这种类型中，记忆以单个文档或记录的形式存储。对于每个新对话，记忆系统可以决定向存储中插入新的记忆。使用集合类型的记忆会给更新记忆状态的过程增加一些复杂性。系统必须将新信息与先前的信念进行协调，通过\\*删除\\*/\\*作废\\*或\\*更新\\*/\\*整合\\*现有记忆。如果系统过度提取，当您的智能体需要搜索存储时，可能会导致记忆的精确度降低。如果提取不足，则可能导致召回率低。LangMem 使用一种记忆丰富化过程，力求在记忆创建和整合之间取得平衡，同时允许您（开发者）自定义指令以进一步调整两者的强度。最后，记忆的相关性不仅仅是语义相似性。回忆应该将相似性与记忆的“重要性”以及记忆的“强度”结合起来，后者是记忆最近/频繁被使用情况的函数。\n![Collection update process] \n提取语义记忆为集合设置*API：[create\\_memory\\_manager] *\n```\n`[] fromlangmemimportcreate\\_memory\\_manager[] [] manager=create\\_memory\\_manager([] "anthropic:claude-3-5-sonnet-latest",[] instructions="Extract all noteworthy facts, events, and relationships. Indicate their importance.",[] enable\\_inserts=True,[])[] [] # Process a conversation to extract semantic memories[] conversation=[[] {"role":"user","content":"I work at Acme Corp in the ML team"},[] {"role":"assistant","content":"I\'ll remember that. What kind of ML work do you do?"},[] {"role":"user","content":"Mostly NLP and large language models"}[]]`\n```\n```\n`[] memories=manager.invoke({"messages":conversation})[] # Example memories:[] # [[] # ExtractedMemory([] # id="27e96a9d-8e53-4031-865e-5ec50c1f7ad5",[] # content=Memory([] # content="[IMPORTANT] User prefers to be called Lex (short for Alex) and appreciates"[] # " casual, witty communication style with relevant emojis."[] # ),[] # ),[] # ExtractedMemory([] # id="e2f6b646-cdf1-4be1-bb40-0fd91d25d00f",[] # content=Memory([] # content="[BACKGROUND] Lex is proficient in Python programming and specializes in developing"[] # " AI systems with a focus on making them sound more natural and less corporate."[] # ),[] # ),[] # ExtractedMemory([] # id="c1e03ebb-a393-4e8d-8eb7-b928d8bed510",[] # content=Memory([] # content="[HOBBY] Lex is a competitive speedcuber (someone who solves Rubik\'s cubes competitively),"[] # " showing an interest in both technical and recreational puzzle-solving."[] # ),[] # ),[] # ExtractedMemory([] # id="ee7fc6e4-0118-425f-8704-6b3145881ff7",[] # content=Memory([] # content="[PERSONALITY] Based on communication style and interests, Lex appears to value authenticity,"[] # " creativity, and technical excellence while maintaining a fun, approachable demeanor."[] # ),[] # ),[] # ]`\n```\n#### 资料卡[¶] \n另一方面，**资料卡**则适用于特定任务。资料卡是一个表示当前状态的单一文档，例如用户使用应用的主要目标、他们偏好的称呼和响应风格等。当新信息到达时，它会更新现有文档而不是创建新文档。当您只关心最新状态并希望避免记住无关信息时，这种方法是理想的。\n![Profile update process] \n使用资料卡管理用户偏好设置*API：[create\\_memory\\_manager] *\n```\n`[] fromlangmemimportcreate\\_memory\\_manager[] frompydanticimportBaseModel[] [] [] classUserProfile(BaseModel):[] """Save the user\'s preferences."""[] name:str[] preferred\\_name:str[] response\\_style\\_preference:str[] special\\_skills:list[str][] other\\_preferences:list[str][] [] [] manager=create\\_memory\\_manager([] "anthropic:claude-3-5-sonnet-latest",[] schemas=[UserProfile],[] instructions="Extract user preferences and settings",[] enable\\_inserts=False,[])[] [] # Extract user preferences from a conversation[] conversation=[[] {"role":"user","content":"Hi! I\'m Alex but please call me Lex. I\'m a wizard at Python and love making AI systems that don\'t sound like boring corporate robots 🤖"},[] {"role":"assistant","content":"Nice to meet you, Lex! Love the anti-corporate-robot stance. How would you like me to communicate with you?"},[] {"role":"user","content":"Keep it casual and witty - and maybe throw in some relevant emojis when it feels right ✨Also, besides AI, I do competitive speedcubing!"},[]]`\n```\n```\n`[] profile=manager.invoke({"messages":conversation})[0][] print(profile)[] # Example profile:[] # ExtractedMemory([] # id="6f555d97-387e-4af6-a23f-a66b4e809b0e",[] # content=UserProfile([] # name="Alex",[] # preferred\\_name="Lex",[] # response\\_style\\_preference="casual and witty with appropriate emojis",[] # special\\_skills=[[] # "Python programming",[] # "AI development",[] # "competitive speedcubing",[] # ],[] # other\\_preferences=[[] # "prefers informal communication",[] # "dislikes corporate-style interactions",[] # ],[] # ),[] # )`\n```\n根据您将如何使用数据来选择使用资料卡还是集合：当您需要快速访问当前状态以及对可存储信息类型有数据要求时，资料卡表现出色。它们也易于呈现给用户进行手动编辑。当您希望在多次互动中跟踪知识而无信息损失，并且希望根据上下文而不是每次都回忆特定信息时，集合非常有用。### 情景记忆：过往经历[¶] \n情景记忆将成功的互动保存为学习示例，以指导未来的行为。与存储事实的语义记忆不同，情景记忆捕捉了互动的完整上下文——情境、导致成功的思考过程以及该方法为何有效。这些记忆帮助智能体从经验中学习，根据以往的成功经验调整其响应。定义和提取情景设置*API：[create\\_memory\\_manager] *\n```\n`[] frompydanticimportBaseModel,Field[] fromlangmemimportcreate\\_memory\\_manager[] [] classEpisode(BaseModel):[] """An episode captures how to handle a specific situation, including the reasoning process[] and what made it successful."""[] [] observation:str=Field([]...,[] description="The situation and relevant context"[])[] thoughts:str=Field([]...,[] description="Key considerations and reasoning process"[])[] action:str=Field([]...,[] description="What was done in response"[])[] result:str=Field([]...,[] description="What happened and why it worked"[])[] [] manager=create\\_memory\\_manager([] "anthropic:claude-3-5-sonnet-latest",[] schemas=[Episode],[] instructions="Extract examples of successful interactions. Include the context, thought process, and why the approach worked.",[] enable\\_inserts=True,[])[] [] # Example conversation[] conversation=[[] {"role":"user","content":"What\'s a binary tree? I work with family trees if that helps"},[] {"role":"assistant","content":"A binary tree is like a family tree, but each parent has at most 2 children. Here\'s a simple example:\\\\nBob\\\\n/\\\\\\\\\\\\nAmy Carl\\\\n\\\\nJust like in family trees, we call Bob the \'parent\' and Amy and Carl the \'children\'."},[] {"role":"user","content":"Oh that makes sense! So in a binary search tree, would it be like organizing a family by age?"},[]]`\n```\n```\n`[] # Extract episode(s)[] episodes=manager.invoke({"messages":conversation})[] # Example episode:[] # [[] # ExtractedMemory([] # id="f9194af3-a63f-4d8a-98e9-16c66e649844",[] # content=Episode([] # observation="User struggled debugging a recursive "[] # "function for longest path in binary "[] # "tree, unclear on logic.",[] # thoughts="Used explorer in treehouse village "[] # "metaphor to explain recursion:\\\\n"[] # "- Houses = Nodes\\\\n"[] # "- Bridges = Edges\\\\n"[] # "- Explorer\'s path = Traversal",[] # action="Reframed problem using metaphor, "[] # "outlined steps:\\\\n"[] # "1. Check left path\\\\n"[] # "2. Check right path\\\\n"[] # "3. Add 1 for current position\\\\n"[] # "Highlighted common bugs",[] # result="Metaphor helped user understand logic. "[] # "Worked because it:\\\\n"[] # "1. Made concepts tangible\\\\n"[] # "2. Created mental model\\\\n"[] # "3. Showed key steps\\\\n"[] # "4. Pointed to likely bugs",[] # ),[] # )[] # ]`\n```\n### 程序性记忆：系统指令[¶] \n程序性记忆编码了智能体应如何行为和响应。它始于定义核心行为的系统提示，然后通过反馈和经验不断演进。随着智能体与用户的互动，它会完善这些指令，学习哪些方法在不同情况下最有效。![Instructions update process] \n根据反馈优化提示设置*API：[create\\_prompt\\_optimizer] *\n```\n`[] fromlangmemimportcreate\\_prompt\\_optimizer[] [] optimizer=create\\_prompt\\_optimizer([] "anthropic:claude-3-5-sonnet-latest",[] kind="metaprompt",[] config={"max\\_reflection\\_steps":3}[])`\n```\n```\n`[] prompt="You are a helpful assistant."[] trajectory=[[] {"role":"user","content":"Explain inheritance in Python"},[] {"role":"assistant","content":"Here\'s a detailed theoretical explanation..."},[] {"role":"user","content":"Show me a practical example instead"},[]][] optimized=optimizer.invoke({[] "trajectories":[(trajectory,{"user\\_score":0})],[] "prompt":prompt[]})[] print(optimized)[] # You are a helpful assistant with expertise in explaining technical concepts clearly and practically. When explaining programming', 'doi': '', 'published_date': '2016-06-09T00:00:00+00:00', 'pdf_url': '', 'url': 'https://github.langchain.ac.cn/langmem/concepts/conceptual_guide', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '记忆概述', 'authors': [], 'abstract': '[跳至主要內容] \n\n# 记忆概述\n\n[记忆] 是一个记住关于先前交互信息的系统。对于AI代理来说，记忆至关重要，因为它使它们能够记住先前的交互，从反馈中学习，并适应用户偏好。随着代理处理更多具有大量用户交互的复杂任务，这种能力对于效率和用户满意度都变得至关重要。\n\n本概念指南涵盖两种类型的记忆，基于它们的回忆范围：\n\n- [短期记忆] ，或 [线程] 范围的记忆，通过维护会话中的消息历史来跟踪正在进行的对话。LangGraph将短期记忆作为代理 [状态] 的一部分进行管理。状态通过 [checkpointer] 持久化到数据库，因此线程可以随时恢复。短期记忆在图形被调用或步骤完成时更新，并且在每个步骤开始时读取状态。\n- [长期记忆] 存储跨会话的用户特定或应用程序级数据，并在会话线程之间共享。它可以在任何时间和任何线程中被调用。记忆的范围不限于单个线程ID，而是可以自定义命名空间。LangGraph提供 [存储] （ [参考文档] ）让您保存和调用长期记忆。\n\n## [短期记忆] \n\n[短期记忆] 让您的应用程序记住单个 [线程] 或对话中的先前交互。 [线程] 组织会话中的多个交互，类似于电子邮件在单个对话中组织消息的方式。\n\nLangGraph将短期记忆作为代理状态的一部分进行管理，通过线程范围的检查点持久化。这种状态通常可以包括对话历史以及其他有状态数据，例如上传的文件、检索的文档或生成的工件。通过将这些存储在图形的状态中，机器人可以访问给定对话的完整上下文，同时保持不同线程之间的分离。\n\n### [管理短期记忆] \n\n对话历史是最常见的短期记忆形式，而长对话对当今的LLM提出了挑战。完整的历史可能无法容纳在LLM的上下文窗口中，导致不可恢复的错误。即使您的LLM支持完整的上下文长度，大多数LLM在长上下文中的表现仍然很差。它们会被过时或偏离主题的内容"分散注意力"，同时还会遭受较慢的响应时间和更高的成本。\n\n聊天模型使用消息接受上下文，包括开发人员提供的指令（系统消息）和用户输入（人类消息）。在聊天应用程序中，消息在人类输入和模型响应之间交替，导致消息列表随着时间的推移变得更长。由于上下文窗口有限且富含token的消息列表可能成本高昂，许多应用程序可以受益于使用手动删除或忘记过时信息的技术。\n\n有关管理消息的常见技术的更多信息，请参阅 [添加和管理记忆] 指南。\n\n## [长期记忆] \n\nLangGraph中的 [长期记忆] 允许系统在不同的对话或会话中保留信息。与 **线程范围的** 短期记忆不同，长期记忆保存在自定义的"命名空间"中。\n\n长期记忆是一个复杂的挑战，没有一刀切的解决方案。然而，以下问题提供了一个框架来帮助您浏览不同的技术：\n\n- 记忆的类型是什么？人类使用记忆来记住事实（ [语义记忆] ）、经历（ [情景记忆] ）和规则（ [程序记忆] ）。AI代理可以以相同的方式使用记忆。例如，AI代理可以使用记忆来记住关于用户的特定事实以完成任务。\n- [您想何时更新记忆？] 记忆可以作为代理应用程序逻辑的一部分进行更新（例如，"在热路径上"）。在这种情况下，代理通常决定在响应用户之前记住事实。或者，记忆可以作为后台任务更新（在后台/异步运行并生成记忆的逻辑）。我们在下面的 [部分] 中解释了这些方法之间的权衡。\n\n不同的应用程序需要各种类型的记忆。虽然类比并不完美，但研究 [人类记忆类型] 可能会有启发。一些研究（例如， [CoALA论文] ）甚至将这些人类记忆类型映射到AI代理中使用的记忆类型。\n\n| 记忆类型 | 存储内容 | 人类示例 | 代理示例 |\n| --- | --- | --- | --- |\n| [语义] | 事实 | 我在学校学到的东西 | 关于用户的事实 |\n| [情景] | 经历 | 我做过的事情 | 过去的代理行动 |\n| [程序] | 指令 | 本能或运动技能 | 代理系统提示 |\n\n### [语义记忆] \n\n[语义记忆] ，无论是在人类还是AI代理中，都涉及特定事实和概念的保留。在人类中，它可以包括在学校学到的信息以及对概念及其关系的理解。对于AI代理，语义记忆通常用于通过记住过去交互中的事实或概念来个性化应用程序。\n\n**注意：** 语义记忆与"语义搜索"不同，后者是一种使用"含义"（通常作为嵌入）查找相似内容的技术。语义记忆是来自心理学的术语，指存储事实和知识，而语义搜索是一种基于含义而非精确匹配检索信息的方法。\n\n#### [配置文件] \n\n语义记忆可以以不同的方式管理。例如，记忆可以是一个单一的、不断更新的"配置文件"，包含有关用户、组织或其他实体（包括代理本身）的范围良好且特定的信息。配置文件通常只是一个JSON文档，包含您选择代表您的域的各种键值对。\n\n当记住配置文件时，您需要确保每次都在 **更新** 配置文件。因此，您需要传入先前的配置文件，并 [要求模型生成新的配置文件] （或一些 [JSON补丁] 以应用于旧配置文件）。随着配置文件变大，这可能变得容易出错，并且可能受益于将配置文件拆分为多个文档或在生成文档时进行 **严格** 解码，以确保记忆模式保持有效。\n\n#### [集合] \n\n或者，记忆可以是一组不断更新和扩展的文档。每个单独的记忆可以范围更窄，更容易生成，这意味着您随着时间的推移 **丢失** 信息的可能性更小。对于LLM来说，为新信息生成 **新** 对象比将新信息与现有配置文件协调更容易。因此，文档集合往往导致 [下游更高的召回率] 。\n\n然而，这将一些复杂性转移到了记忆更新上。模型现在必须 _删除_ 或 _更新_ 列表中的现有项目，这可能很棘手。此外，一些模型可能默认过度插入，而其他模型可能默认过度更新。请参阅 [Trustcall] 包以了解管理这一点的一种方法，并考虑评估（例如，使用像 [LangSmith] 这样的工具）来帮助您调整行为。\n\n使用文档集合还将复杂性转移到了对列表的记忆 **搜索** 上。 `Store` 目前支持 [语义搜索] 和 [按内容过滤] 。\n\n最后，使用记忆集合可能会使向模型提供全面上下文变得具有挑战性。虽然各个记忆可能遵循特定的模式，但这种结构可能无法捕捉记忆之间的完整上下文或关系。因此，当使用这些记忆生成响应时，模型可能缺乏重要的上下文信息，这些信息在统一的配置文件方法中会更容易获得。\n\n无论记忆管理方法如何，中心点是代理将使用语义记忆来 [为其响应提供基础] ，这通常会导致更个性化和相关的交互。\n\n### [情景记忆] \n\n[情景记忆] ，无论是在人类还是AI代理中，都涉及回忆过去的事件或行动。 [CoALA论文] 对此进行了很好的描述：事实可以写入语义记忆，而 _经历_ 可以写入情景记忆。对于AI代理，情景记忆通常用于帮助代理记住如何完成任务。\n\n在实践中，情景记忆通常通过 [少样本示例提示] 实现，其中代理从过去的序列中学习以正确执行任务。有时"展示"比"告诉"更容易，LLM从示例中学习得很好。少样本学习让您通过用输入-输出示例更新提示来"编程"您的LLM，以说明预期行为。虽然可以使用各种 [最佳实践] 来生成少样本示例，但挑战通常在于根据用户输入选择最相关的示例。\n\n请注意，记忆 [存储] 只是存储少样本示例数据的一种方式。如果您希望有更多的开发人员参与，或者将少样本与您的评估工具更紧密地联系起来，您也可以使用 [LangSmith Dataset] 来存储您的数据。然后可以使用开箱即用的动态少样本示例选择器来实现相同的目标。LangSmith将为您索引数据集，并基于关键字相似性（ [使用类似BM25的算法] 进行基于关键字的相似性）启用与用户输入最相关的少样本示例的检索。\n\n请参阅此操作方法 [视频] ，了解LangSmith中动态少样本示例选择的示例用法。此外，请参阅此 [博客文章] ，展示使用少样本提示来提高工具调用性能，以及此 [博客文章] ，使用少样本示例来使LLM与人类偏好保持一致。\n\n### [程序记忆] \n\n[程序记忆] ，无论是在人类还是AI代理中，都涉及记住用于执行任务的规则。在人类中，程序记忆就像执行任务的内在知识，例如通过基本运动技能和平衡骑自行车。另一方面，情景记忆涉及回忆特定经历，例如第一次成功骑自行车而不使用辅助轮或通过风景路线进行的难忘自行车骑行。对于AI代理，程序记忆是模型权重、代理代码和代理提示的组合，共同决定代理的功能。\n\n在实践中，代理修改其模型权重或重写其代码是相当罕见的。然而，代理修改自己的提示更为常见。\n\n一种改进代理指令的有效方法是通过 ["反思"] 或元提示。这涉及向代理提供其当前指令（例如，系统提示）以及最近的对话或明确的用户反馈。然后，代理根据此输入完善自己的指令。这种方法对于预先难以指定指令的任务特别有用，因为它允许代理从其交互中学习和适应。\n\n例如，我们使用外部反馈和提示重写构建了一个 [推文生成器] ，为Twitter生成高质量的论文摘要。在这种情况下，特定的摘要提示很难 _事先_ 指定，但用户很容易批评生成的推文并提供关于如何改进摘要过程的反馈。\n\n下面的伪代码展示了如何使用LangGraph记忆 [存储] 实现这一点，使用存储保存提示， `update_instructions` 节点获取当前提示（以及在 `state["messages"]` 中捕获的与用户对话的反馈），更新提示，并将新提示保存回存储。然后， `call_model` 从存储中获取更新后的提示并使用它生成响应。\n\n#### [Python示例] \n\n```\n# 使用指令的节点\ndef call_model(state: State, store: BaseStore):\n namespace = ("agent_instructions", )\n instructions = store.get(namespace, key="agent_a")[0]\n # 应用程序逻辑\n prompt = prompt_template.format(instructions=instructions.value["instructions"])\n ...\n\n# 更新指令的节点\ndef update_instructions(state: State, store: BaseStore):\n namespace = ("instructions",)\n instructions = store.search(namespace)[0]\n # 记忆逻辑\n prompt = prompt_template.format(instructions=instructions.value["instructions"], conversation=state["messages"])\n output = llm.invoke(prompt)\n new_instructions = output[\'new_instructions\']\n store.put(("agent_instructions",), "agent_a", {"instructions": new_instructions})\n ...\n```\n\n#### [JavaScript示例] \n\n```\n// 使用指令的节点\nconst callModel = async (state: State, store: BaseStore) => {\n const namespace = ["agent_instructions"];\n const instructions = await store.get(namespace, "agent_a");\n // 应用程序逻辑\n const prompt = promptTemplate.format({\n instructions: instructions[0].value.instructions\n });\n // ...\n};\n\n// 更新指令的节点\nconst updateInstructions = async (state: State, store: BaseStore) => {\n const namespace = ["instructions"];\n const currentInstructions = await store.search(namespace);\n // 记忆逻辑\n const prompt = promptTemplate.format({\n instructions: currentInstructions[0].value.instructions,\n conversation: state.messages\n });\n const output = await llm.invoke(prompt);\n const newInstructions = output.new_instructions;\n await store.put(["agent_instructions"], "agent_a", {\n instructions: newInstructions\n });\n // ...\n};\n```\n\n### [写入记忆] \n\n代理写入记忆有两种主要方法： ["在热路径中"] 和 ["在后台"] 。\n\n#### [在热路径中] \n\n在运行时创建记忆既有优点也有挑战。积极的一面是，这种方法允许实时更新，使新记忆可以立即用于后续交互。它还实现了透明度，因为可以在创建和存储记忆时通知用户。\n\n然而，这种方法也存在挑战。如果代理需要一个新工具来决定将什么提交到记忆中，它可能会增加复杂性。此外，推理将什么保存到记忆中可能会影响代理延迟。最后，代理必须在记忆创建和其其他责任之间进行多任务处理，可能影响创建的记忆的数量和质量。\n\n例如，ChatGPT使用 [save\\_memories] 工具将记忆作为内容字符串插入，决定是否以及如何对每条用户消息使用此工具。请参阅我们的 [memory-agent] 模板作为参考实现。\n\n#### [在后台] \n\n将记忆创建为单独的后台任务提供了几个优势。它消除了主应用程序中的延迟，将应用程序逻辑与记忆管理分开，并允许代理更专注于任务完成。这种方法还提供了在定时记忆创建方面的灵活性，以避免重复工作。\n\n然而，这种方法也有自己的挑战。确定记忆写入频率变得至关重要，因为不频繁的更新可能会使其他线程没有新的上下文。决定何时触发记忆形成也很重要。常见策略包括在设定的时间段后调度（如果发生新事件则重新调度）、使用cron调度或允许用户或应用程序逻辑手动触发。\n\n请参阅我们的 [memory-service] 模板作为参考实现。\n\n### [记忆存储] \n\nLangGraph将长期记忆作为JSON文档存储在 [存储] 中。每个记忆都组织在自定义的 `namespace`（类似于文件夹）和不同的 `key`（如文件名）下。命名空间通常包括用户或组织ID或其他标签，使组织信息更容易。这种结构支持记忆的层次组织。然后通过内容过滤器支持跨命名空间搜索。\n\n#### [Python示例] \n\n```\nfrom langgraph.store.memory import InMemoryStore\n\ndef embed(texts: list[str]) -> list[list[float]]:\n # 替换为实际的嵌入函数或LangChain嵌入对象\n return [[1.0, 2.0] * len(texts)]\n\n# InMemoryStore将数据保存到内存字典中。在生产环境中使用数据库支持的存储。\nstore = InMemoryStore(index={"embed": embed, "dims": 2})\nuser_id = "my-user"\napplication_context = "chitchat"\nnamespace = (user_id, application_context)\nstore.put(\n namespace,\n "a-memory",\n {\n "rules": [\n "User likes short, direct language",\n "User only speaks English & python",\n ],\n "my-key": "my-value",\n },\n)\n# 通过ID获取"记忆"\nitem = store.get(namespace, "a-memory")\n# 在这个命名空间内搜索"记忆"，过滤内容等价性，按向量相似性排序\nitems = store.search(\n namespace, filter={"my-key": "my-value"}, query="language preferences"\n)\n```\n\n#### [JavaScript示例] \n\n```\nimport { InMemoryStore } from "@langchain/langgraph";\n\nconst embed = (texts: string[]): number[][] => {\n // 替换为实际的嵌入函数或LangChain嵌入对象\n return texts.map(() => [1.0, 2.0]);\n};\n\n// InMemoryStore将数据保存到内存字典中。在生产环境中使用数据库支持的存储。\nconst store = new InMemoryStore({ index: { embed, dims: 2 } });\nconst userId = "my-user";\nconst applicationContext = "chitchat";\nconst namespace = [userId, applicationContext];\n\nawait store.put(\n namespace,\n "a-memory",\n {\n rules: [\n "User likes short, direct language",\n "User only speaks English & TypeScript",\n ],\n "my-key": "my-value",\n }\n);\n\n// 通过ID获取"记忆"\nconst item = await store.get(namespace, "a-memory");\n\n// 在这个命名空间内搜索"记忆"，过滤内容等价性，按向量相似性排序\nconst items = await store.search(\n namespace,\n {\n filter: { "my-key": "my-value" },\n query: "language preferences"\n }\n);\n```\n\n有关记忆存储的更多信息，请参阅 [持久化] 指南。', 'doi': '', 'published_date': '2026-02-02T20:17:10.321170', 'pdf_url': '', 'url': 'https://langchain-doc.cn/v1/python/langgraph/memory.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:17:57,383 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:17:57,386 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': 'Short-term memory - Docs by LangChain', 'authors': [], 'abstract': '[Docs by LangChain home page](/)\n\n[LangChain](/oss/python/langchain/overview)[LangGraph](/oss/python/langgraph/overview)[Deep Agents](/oss/python/deepagents/overview)[Integrations](/oss/python/integrations/providers/overview)[Learn](/oss/python/learn)[Reference](/oss/python/reference/overview)[Contribute](/oss/python/contributing/overview)\n\n##### Get started\n\n* [Install](/oss/python/langchain/install)\n* [Quickstart](/oss/python/langchain/quickstart)\n* [Changelog](https://docs.langchain.com/oss/python/releases/changelog)\n* [Philosophy](/oss/python/langchain/philosophy)\n\n##### Core components\n\n* [Agents](/oss/python/langchain/agents)\n* [Models](/oss/python/langchain/models)\n* [Messages](/oss/python/langchain/messages)\n* [Tools](/oss/python/langchain/tools)\n* [Short-term memory](/oss/python/langchain/short-term-memory)\n* [Structured output](/oss/python/langchain/structured-output)\n\n##### Middleware\n\n* [Overview](/oss/python/langchain/middleware/overview)\n* [Built-in middleware](/oss/python/langchain/middleware/built-in)\n* [Custom middleware](/oss/python/langchain/middleware/custom)\n\n##### Advanced usage\n\n* [Guardrails](/oss/python/langchain/guardrails)\n* [Runtime](/oss/python/langchain/runtime)\n* [Context engineering](/oss/python/langchain/context-engineering)\n* [Model Context Protocol (MCP)](/oss/python/langchain/mcp)\n* [Human-in-the-loop](/oss/python/langchain/human-in-the-loop)\n* [Retrieval](/oss/python/langchain/retrieval)\n* [Long-term memory](/oss/python/langchain/long-term-memory)\n\n##### Agent development\n\n* [LangSmith Studio](/oss/python/langchain/studio)\n* [Test](/oss/python/langchain/test)\n* [Agent Chat UI](/oss/python/langchain/ui)\n\n##### Deploy with LangSmith\n\n* [Deployment](/oss/python/langchain/deploy)\n* [Observability](/oss/python/langchain/observability)\n\n* [Overview](#overview)\n* [Usage](#usage)\n* [In production](#in-production)\n* [Customizing agent memory](#customizing-agent-memory)\n* [Common patterns](#common-patterns)\n* [Trim messages](#trim-messages)\n* [Delete messages](#delete-messages)\n* [Summarize messages](#summarize-messages)\n* [Access memory](#access-memory)\n* [Tools](#tools)\n* [Read short-term memory in a tool](#read-short-term-memory-in-a-tool)\n* [Write short-term memory from tools](#write-short-term-memory-from-tools)\n* [Prompt](#prompt)\n* [Before model](#before-model)\n* [After model](#after-model)\n\n[Core components](/oss/python/langchain/agents)\n\n# Short-term memory\n\n## [\u200b](#overview) Overview\n\nMemory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction. Short term memory lets your application remember previous interactions within a single thread or conversation.\n\nA thread organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n\nConversation history is the most common form of short-term memory. Long conversations pose a challenge to today’s LLMs; a full history may not fit inside an LLM’s context window, resulting in an context loss or errors. Even if your model supports the full context length, most LLMs still perform poorly over long contexts. They get “distracted” by stale or off-topic content, all while suffering from slower response times and higher costs. Chat models accept context using [messages](/oss/python/langchain/messages), which include instructions (a system message) and inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited, many applications can benefit from using techniques to remove or “forget” stale information.\n\n## [\u200b](#usage) Usage\n\nTo add short-term memory (thread-level persistence) to an agent, you need to specify a `checkpointer` when creating an agent.\n\nLangChain’s agent manages short-term memory as a part of your agent’s state.By storing these in the graph’s state, the agent can access the full context for a given conversation while maintaining separation between different threads.State is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.Short-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver  agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(), )) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"configurable": {"thread_id": "1"}},  {"configurable": {"thread_id": "1"}}, ))\n```\n\n### [\u200b](#in-production) In production\n\nIn production, use a checkpointer backed by a database:\n\nCopy\n\n```\npip install langgraph-checkpoint-postgres pip  install langgraph-checkpoint-postgres\n```\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from langgraph.checkpoint.postgres import PostgresSaver from langgraph.checkpoint.postgres import  PostgresSaver  DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable" DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"with PostgresSaver.from_conn_string(DB_URI) as checkpointer: with PostgresSaver.from_conn_string(DB_URI) as checkpointer: checkpointer.setup() # auto create tables in PostgresSql checkpointer.setup() # auto create tables in PostgresSql agent = create_agent( agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=checkpointer,  checkpointer =checkpointer,  ) )\n```\n\nFor more checkpointer options including SQLite, Postgres, and Azure Cosmos DB, see the [list of checkpointer libraries](/oss/python/langgraph/persistence#checkpointer-libraries) in the Persistence documentation.\n\n## [\u200b](#customizing-agent-memory) Customizing agent memory\n\nBy default, agents use [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to manage short term memory, specifically the conversation history via a `messages` key. You can extend [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to add additional fields. Custom state schemas are passed to [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) using the [`state_schema`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware.state_schema) parameter.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver class CustomAgentState(AgentState): class  CustomAgentState(AgentState):  user_id: str user_id: str preferences: dict preferences: dict agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomAgentState,  state_schema =CustomAgentState,  checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) # Custom state can be passed in invoke # Custom state can be passed in invokeresult = agent.invoke(result = agent.invoke( { { "messages": [{"role": "user", "content": "Hello"}],  "messages": [{"role": "user", "content": "Hello"}], "user_id": "user_123",  "user_id": "user_123",  "preferences": {"theme": "dark"}  "preferences": {"theme": "dark"}  }, }, {"configurable": {"thread_id": "1"}}) {"configurable": {"thread_id": "1"}})\n```\n\n## [\u200b](#common-patterns) Common patterns\n\nWith [short-term memory](#add-short-term-memory) enabled, long conversations can exceed the LLM’s context window. Common solutions are:\n\n[## Trim messages\n\nRemove first or last N messages (before calling LLM)](#trim-messages)[## Delete messages\n\nDelete messages from LangGraph state permanently](#delete-messages)[## Summarize messages\n\nSummarize earlier messages in the history and replace them with a summary](#summarize-messages)\n\n## Custom strategies\n\nCustom strategies (e.g., message filtering, etc.)\n\nThis allows the agent to keep track of the conversation without exceeding the LLM’s context window.\n\n### [\u200b](#trim-messages) Trim messages\n\nMost LLMs have a maximum supported context window (denominated in tokens). One way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you’re using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the `strategy` (e.g., keep the last `max_tokens`) to use for handling the boundary. To trim message history in an agent, use the [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware decorator:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( your_model_here, your_model_here, tools=your_tools_here,  tools =your_tools_here, middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#delete-messages) Delete messages\n\nYou can delete messages from the graph state to manage the message history. This is useful when you want to remove specific messages or clear the entire message history. To delete messages from the graph state, you can use the `RemoveMessage`. For `RemoveMessage` to work, you need to use a state key with [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) [reducer](/oss/python/langgraph/graph-api#reducers). The default [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) provides this. To remove specific messages:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessage def delete_messages(state): def  delete_messages(state): messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]} \n```\n\nTo remove **all** messages:\n\nCopy\n\n```\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGES def delete_messages(state): def  delete_messages(state): return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  return {"messages": [RemoveMessage(id = REMOVE_ALL_MESSAGES)]} \n```\n\nWhen deleting messages, **make sure** that the resulting message history is valid. Check the limitations of the LLM provider you’re using. For example:\n\n* Some providers expect message history to start with a `user` message\n* Most providers require `assistant` messages with tool calls to be followed by corresponding `tool` result messages.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig  @after_model @after_modeldef delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None: def  delete_old_messages(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove old messages to keep conversation manageable.""" """Remove old messages to keep conversation manageable.""" messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]}  return None  return  None agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], system_prompt="Please be concise and to the point.",  system_prompt ="Please be concise and to the point.", middleware=[delete_old_messages],  middleware =[delete_old_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]]) for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "what\'s my name?"}]}, {"messages": [{"role": "user", "content": "what\'s my name?"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]])\n```\n\nCopy\n\n```\n[(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')] \n```\n\n### [\u200b](#summarize-messages) Summarize messages\n\nThe problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue. Because of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.  To summarize message history in an agent, use the built-in [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization):\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langchain.agents.middleware import SummarizationMiddleware from langchain.agents.middleware import  SummarizationMiddlewarefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig checkpointer = InMemorySaver() checkpointer = InMemorySaver() agent = create_agent(agent = create_agent( model="gpt-4o",  model ="gpt-4o", tools=[],  tools =[], middleware=[ middleware =[ SummarizationMiddleware( SummarizationMiddleware( model="gpt-4o-mini",  model ="gpt-4o-mini", trigger=("tokens", 4000),  trigger =("tokens", 4000), keep=("messages", 20)  keep =("messages", 20) ) ) ], ], checkpointer=checkpointer,  checkpointer =checkpointer,)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}}agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob!Your name is Bob! """ """\n```\n\nSee [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization) for more configuration options.\n\n## [\u200b](#access-memory) Access memory\n\nYou can access and modify the short-term memory (state) of an agent in several ways:\n\n### [\u200b](#tools) Tools\n\n#### [\u200b](#read-short-term-memory-in-a-tool) Read short-term memory in a tool\n\nAccess short term memory (state) in a tool using the `runtime` parameter (typed as `ToolRuntime`). The `runtime` parameter is hidden from the tool signature (so the model doesn’t see it), but the tool can access the state through it.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntime class CustomState(AgentState): class  CustomState(AgentState): user_id: str user_id: str @tool @tooldef get_user_info(def  get_user_info( runtime: ToolRuntime  runtime: ToolRuntime) -> str:) -> str: """Look up user info.""" """Look up user info.""" user_id = runtime.state["user_id"]  user_id = runtime.state["user_id"] return "User is John Smith" if user_id == "user_123" else "Unknown user"  return  "User is John Smith"  if  user_id ==  "user_123"  else  "Unknown user" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomState,  state_schema =CustomState,)) result = agent.invoke({result = agent.invoke({ "messages": "look up user information",  "messages": "look up user information", "user_id": "user_123"  "user_id": "user_123"})})print(result["messages"][-1].content) print(result["messages"][- 1].content)# > User is John Smith.# > User is John Smith.\n```\n\n#### [\u200b](#write-short-term-memory-from-tools) Write short-term memory from tools\n\nTo modify the agent’s short-term memory (state) during execution, you can return state updates directly from the tools. This is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.\n\nCopy\n\n```\nfrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langchain.messages import ToolMessage from langchain.messages import  ToolMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.types import Command from langgraph.types import  Command from pydantic import BaseModel from  pydantic import  BaseModel class CustomState(AgentState): class  CustomState(AgentState):  user_name: str user_name: str class CustomContext(BaseModel): class  CustomContext(BaseModel): user_id: str user_id: str @tool @tooldef update_user_info(def  update_user_info( runtime: ToolRuntime[CustomContext, CustomState],  runtime: ToolRuntime[CustomContext, CustomState],) -> Command:) -> Command: """Look up and update user info.""" """Look up and update user info.""" user_id = runtime.context.user_id  user_id = runtime.context.user_id name = "John Smith" if user_id == "user_123" else "Unknown user"  name =  "John Smith"  if  user_id ==  "user_123"  else  "Unknown user" return Command(update={  return Command(update ={  "user_name": name,  "user_name": name,  # update the message history  # update the message history "messages": [ "messages": [ ToolMessage( ToolMessage( "Successfully looked up user information",  "Successfully looked up user information", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) @tool @tooldef greet(def  greet( runtime: ToolRuntime[CustomContext, CustomState]  runtime: ToolRuntime[CustomContext, CustomState]) -> str | Command:) -> str  | Command: """Use this to greet the user once you found their info.""" """Use this to greet the user once you found their info.""" user_name = runtime.state.get("user_name", None)  user_name = runtime.state.get("user_name", None) if user_name is None:  if  user_name is  None: return Command(update={ return Command(update ={ "messages": [ "messages": [ ToolMessage( ToolMessage( "Please call the \'update_user_info\' tool it will get and update the user\'s name.", "Please call the \'update_user_info\' tool it will get and update the user\'s name.", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) return f"Hello {user_name}!"  return  f "Hello {user_name}!" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[update_user_info, greet],  tools =[update_user_info, greet], state_schema=CustomState,  state_schema =CustomState,  context_schema=CustomContext,  context_schema =CustomContext,)) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "greet the user"}]}, {"messages": [{"role": "user", "content": "greet the user"}]}, context=CustomContext(user_id="user_123"),  context =CustomContext(user_id = "user_123"),))\n```\n\n### [\u200b](#prompt) Prompt\n\nAccess short term memory (state) in middleware to create dynamic prompts based on conversation history or custom state fields.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from typing import TypedDict from  typing import  TypedDictfrom langchain.agents.middleware import dynamic_prompt, ModelRequest from langchain.agents.middleware import dynamic_prompt, ModelRequest class CustomContext(TypedDict): class  CustomContext(TypedDict): user_name: str user_name: str def get_weather(city: str) -> str: def  get_weather(city: str) -> str: """Get the weather in a city.""" """Get the weather in a city.""" return f"The weather in {city} is always sunny!"  return  f "The weather in {city} is always sunny!"  @dynamic_prompt @dynamic_promptdef dynamic_system_prompt(request: ModelRequest) -> str: def  dynamic_system_prompt(request: ModelRequest) -> str: user_name = request.runtime.context["user_name"]  user_name = request.runtime.context["user_name"] system_prompt = f"You are a helpful assistant. Address the user as {user_name}."  system_prompt =  f"You are a helpful assistant. Address the user as {user_name}."  return system_prompt  return  system_prompt agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_weather],  tools =[get_weather], middleware=[dynamic_system_prompt],  middleware =[dynamic_system_prompt], context_schema=CustomContext,  context_schema =CustomContext,)) result = agent.invoke(result = agent.invoke( {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, context=CustomContext(user_name="John Smith"),  context =CustomContext(user_name = "John Smith"),))for msg in result["messages"]: for  msg in result["messages"]: msg.pretty_print() msg.pretty_print() \n```\n\nOutput\n\nCopy\n\n```\n================================ Human Message ================================= ================================  Human  Message ================================= What is the weather in SF? What  is  the  weather  in  SF? ================================== Ai Message ================================== ==================================  Ai  Message ==================================Tool Calls: Tool Calls: get_weather (call_WFQlOGn4b2yoJrv7cih342FG)  get_weather (call_WFQlOGn4b2yoJrv7cih342FG) Call ID: call_WFQlOGn4b2yoJrv7cih342FG  Call ID:  call_WFQlOGn4b2yoJrv7cih342FG Args: Args: city: San Francisco city:  San  Francisco ================================= Tool Message ================================= =================================  Tool  Message =================================Name: get_weatherName:  get_weather The weather in San Francisco is always sunny! The  weather  in  San  Francisco  is  always sunny! ================================== Ai Message ================================== ==================================  Ai  Message ================================== Hi John Smith, the weather in San Francisco is always sunny! Hi  John Smith,  the  weather  in  San  Francisco  is  always sunny!\n```\n\n### [\u200b](#before-model) Before model\n\nAccess short term memory (state) in [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware to process messages before model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver()  checkpointer =InMemorySaver())) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#after-model) After model\n\nAccess short term memory (state) in [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) middleware to process messages after model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime  @after_model @after_modeldef validate_response(state: AgentState, runtime: Runtime) -> dict | None: def  validate_response(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove messages containing sensitive words.""" """Remove messages containing sensitive words.""" STOP_WORDS = ["password", "secret"]  STOP_WORDS = ["password", "secret"] last_message = state["messages"][-1]  last_message = state["messages"][- 1] if any(word in last_message.content for word in STOP_WORDS):  if  any(word in last_message.content for  word in  STOP_WORDS): return {"messages": [RemoveMessage(id=last_message.id)]}  return {"messages": [RemoveMessage(id =last_message.id)]}  return None  return  None agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[],  tools =[], middleware=[validate_response],  middleware =[validate_response], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),))\n```\n\n---\n\n[Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/short-term-memory.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n\n[Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n\nWas this page helpful?\n\n[Tools](/oss/python/langchain/tools)[Overview](/oss/python/langchain/streaming/overview)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://docs.langchain.com/oss/python/langchain/short-term-memory', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9999573, 'save_path': None}}, {'paper_id': '', 'title': '管理LangGraph Postgres 檢查點以實現短期記憶的最佳實踐是什麼？', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生產環境中，管理 LangGraph Postgres 檢查點以實現短期記憶的最佳實踐是什麼？\n\n我正在為聊天機器人構建一個記憶系統，使用 **LangGraph**。 目前我專注於 **短期記憶**，由 **PostgresSaver** 支援。\n\n每次狀態轉換都會儲存在 `checkpoints` 表格中。正如預期，每次使用者互動（圖調用 / LLM 呼叫）都會建立多個檢查點，因此檢查點表格中的檢查點資料會**隨著使用量線性增長**。\n\n`checkpoints`\n\n在生產環境中，管理這種增長的推薦策略是什麼？\n\n具體來說：\n\n**只保留每個** thread\\_id 的最後 N 個檢查點並刪除較舊的檢查點，這是最佳實踐嗎？\n\n人們如何權衡**恢復/復原安全性**與**資料庫增長**的規模？\n\n供參考：\n\n我已經使用對話摘要，因此較舊的訊息不需要用於上下文\n\n檢查點主要用於短期恢復和狀態連續性，而不是長期記憶\n\nLangGraph 可以**從最後一個檢查點恢復**\n\n很好奇其他人如何在實際的生產系統中處理這個問題。\n\n此外，在 postgres 中，langgraph 建立 4 個關於檢查點的表格：checkpoints, checkpoint\\_writes, checkpoint\\_migrations, checkpoint\\_blobs\n\nCreate your account and connect with a world of communities.\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hant', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99993443, 'save_path': None}}, {'paper_id': '', 'title': '在生产环境中管理LangGraph Postgres 检查点以实现短期记忆的最佳 ...', 'authors': [], 'abstract': '## Thanks for the feedback!\n\nTell us more about why this content is not helpful.\n\n![r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=ea606d2214268fc77497c4cc4ee63ea67c8b32ac)\n\n# 在生产环境中管理 LangGraph Postgres 检查点以实现短期记忆的最佳实践是什么？\n\n我正在使用 **LangGraph** 为聊天机器人构建一个记忆系统。 目前我专注于 **短期记忆**，由 **PostgresSaver** 提供支持。\n\n每次状态转换都存储在 `checkpoints` 表中。正如预期的那样，每次用户交互（图调用/LLM 调用）都会创建多个检查点，因此检查点表中的检查点数据会**随着使用量线性增长**。\n\n`checkpoints`\n\n在生产环境中，管理这种增长的推荐策略是什么？\n\n具体来说：\n\n**最好只保留每个** thread\\_id 的最后 N 个检查点并删除较旧的检查点吗？\n\n人们如何平衡**恢复/恢复安全**与**数据库增长**？\n\n作为背景：\n\n我已经使用了对话总结，因此旧消息不再需要用于上下文\n\n检查点主要用于短期恢复和状态连续性，而不是长期记忆\n\nLangGraph 可以**从最后一个检查点恢复**\n\n很好奇其他人如何在实际生产系统中处理这个问题。\n\n此外，在 postgres 中，langgraph 创建了 4 个关于检查点的表：checkpoints,checkpoint\\_writes,checkpoint\\_migrations,checkpoint\\_blobs\n\nAnyone can view, post, and comment to this community\n\n![](https://id.rlcdn.com/472486.gif)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.reddit.com/r/LangChain/comments/1qna46j/best_practice_for_managing_langgraph_postgres/?tl=zh-hans', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99992156, 'save_path': None}}, {'paper_id': '', 'title': '内存记忆( Memory ) - LangChain 中文文档', 'authors': [], 'abstract': '![10000 AI开发者社群](https://www.aiqbh.com/qun.png)\n\n# 内存记忆 ( Memory )\n\n![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif "LangChain中文网")\n\n![LangChain](https://pica.zhimg.com/50/v2-56e8bbb52aa271012541c1fe1ceb11a2_r.gif "LangChain中文网")\n\n默认情况下，链式模型和代理模型都是无状态的，这意味着它们将每个传入的查询独立处理（就像底层的 LLMs 和聊天模型本身一样）。在某些应用程序中，比如聊天机器人，记住先前的交互是至关重要的。无论是短期还是长期，都要记住先前的交互。**Memory** 类正是做到了这一点。\nLangChain 提供了两种形式的记忆组件。首先，LangChain 提供了用于管理和操作以前的聊天消息的辅助工具。这些工具被设计成模块化的，无论如何使用都很有用。其次，LangChain 提供了将这些工具轻松整合到链式模型中的方法。\n\n## 入门[\u200b](#入门 "Direct link to 入门")\n\n记忆涉及在用户与语言模型的交互过程中始终保留状态的概念。用户与语言模型的交互被捕获在 ChatMessages 的概念中，因此这归结为在一系列聊天消息中摄取、捕获、转换和提取知识。有许多不同的方法可以做到这一点，每种方法都作为自己的记忆类型存在。\n通常情况下，对于每种类型的记忆，有两种理解和使用记忆的方式。一种是独立的函数，从一系列消息中提取信息，然后是您可以在链式模型中使用此类型的记忆的方式。\n记忆可以返回多个信息片段（例如，最近的 N 条消息和所有先前消息的摘要）。返回的信息可以是字符串或消息列表。\n\n我们将介绍最简单的存储形式：“缓冲”存储，它只涉及保留所有先前的消息的缓冲区。我们将展示如何在这里使用模块化实用函数，然后展示它如何在链中使用（返回字符串以及消息列表）。\n\n## 聊天消息历史 (ChatMessageHistory)[\u200b](#聊天消息历史-chatmessagehistory "Direct link to 聊天消息历史 (ChatMessageHistory)")\n\n大多数（如果不是全部）内存模块的核心实用类之一是 `ChatMessageHistory` 类。这是一个超轻量级的包装器，它公开了方便的方法来保存人类消息、AI 消息，然后获取它们全部。\n\n`ChatMessageHistory`\n\n如果您在链外管理内存，可能需要直接使用此类。\n\n`from langchain.memory import ChatMessageHistory  \n  \nhistory = ChatMessageHistory()  \n  \nhistory.add_user_message("hi!")  \n  \nhistory.add_ai_message("whats up?")`\n`history.messages`\n `[HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]`\n\n## ConversationBufferMemory[\u200b](#conversationbuffermemory "Direct link to ConversationBufferMemory")\n\n现在我们展示如何在链中使用这个简单的概念。我们首先展示 `ConversationBufferMemory`，它只是 ChatMessageHistory 的一个包装器，可以提取变量中的消息。\n\n`ConversationBufferMemory`\n\n我们可以首先将其提取为字符串。\n\n`from langchain.memory import ConversationBufferMemory`\n`memory = ConversationBufferMemory()  \nmemory.chat_memory.add_user_message("hi!")  \nmemory.chat_memory.add_ai_message("whats up?")`\n`memory.load_memory_variables({})`\n `{\'history\': \'Human: hi!\\nAI: whats up?\'}`\n\n我们还可以将历史记录作为消息列表获取\n\n`memory = ConversationBufferMemory(return_messages=True)  \nmemory.chat_memory.add_user_message("hi!")  \nmemory.chat_memory.add_ai_message("whats up?")`\n`memory.load_memory_variables({})`\n `{\'history\': [HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]}`\n\n## Using in a chain[\u200b](#using-in-a-chain "Direct link to Using in a chain")\n\nFinally, let\'s take a look at using this in a chain (setting `verbose=True` so we can see the prompt).\n\n`verbose=True`\n`from langchain.llms import OpenAI  \nfrom langchain.chains import ConversationChain  \n  \n  \nllm = OpenAI(temperature=0)  \nconversation = ConversationChain(  \n llm=llm,  \n verbose=True,  \n memory=ConversationBufferMemory()  \n)`\n`conversation.predict(input="Hi there!")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n  \n Human: Hi there!  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " Hi there! It\'s nice to meet you. How can I help you today?"`\n`conversation.predict(input="I\'m doing well! Just having a conversation with an AI.")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n Human: Hi there!  \n AI: Hi there! It\'s nice to meet you. How can I help you today?  \n Human: I\'m doing well! Just having a conversation with an AI.  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " That\'s great! It\'s always nice to have a conversation with someone new. What would you like to talk about?"`\n`conversation.predict(input="Tell me about yourself.")`\n `> Entering new ConversationChain chain...  \n Prompt after formatting:  \n The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.  \n  \n Current conversation:  \n Human: Hi there!  \n AI: Hi there! It\'s nice to meet you. How can I help you today?  \n Human: I\'m doing well! Just having a conversation with an AI.  \n AI: That\'s great! It\'s always nice to have a conversation with someone new. What would you like to talk about?  \n Human: Tell me about yourself.  \n AI:  \n  \n > Finished chain.  \n  \n  \n  \n  \n  \n " Sure! I\'m an AI created to help people with their everyday tasks. I\'m programmed to understand natural language and provide helpful information. I\'m also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers."`\n\n## 保存消息历史[\u200b](#保存消息历史 "Direct link to 保存消息历史")\n\n您经常需要保存消息，然后加载它们以便再次使用。这可以通过先将消息转换为普通的 Python 字典，保存这些字典（如 json 或其他格式），然后加载它们来轻松完成。以下是一个示例。\n\n`import json  \n  \nfrom langchain.memory import ChatMessageHistory  \nfrom langchain.schema import messages_from_dict, messages_to_dict  \n  \nhistory = ChatMessageHistory()  \n  \nhistory.add_user_message("hi!")  \n  \nhistory.add_ai_message("whats up?")`\n`dicts = messages_to_dict(history.messages)`\n`dicts`\n `[{\'type\': \'human\', \'data\': {\'content\': \'hi!\', \'additional_kwargs\': {}}},  \n {\'type\': \'ai\', \'data\': {\'content\': \'whats up?\', \'additional_kwargs\': {}}}]`\n`new_messages = messages_from_dict(dicts)`\n`new_messages`\n `[HumanMessage(content=\'hi!\', additional_kwargs={}),  \n AIMessage(content=\'whats up?\', additional_kwargs={})]`\n\n这就是入门的全部内容！有许多不同类型的内存，请查看我们的示例以了解全部内容', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://python.langchain.com.cn/docs/modules/memory/', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99988127, 'save_path': None}}, {'paper_id': '', 'title': 'LangChain让LLM带上记忆- 程序员半支烟 - 博客园', 'authors': [], 'abstract': '![](https://img2024.cnblogs.com/blog/35695/202506/35695-20250620221146444-645204917.webp)\n![博客园logo](//assets.cnblogs.com/logo.svg)\n![搜索](//assets.cnblogs.com/icons/search.svg)\n![搜索](//assets.cnblogs.com/icons/enter.svg)\n![搜索](//assets.cnblogs.com/icons/search.svg)\n![搜索](//assets.cnblogs.com/icons/search.svg)\n![写随笔](//assets.cnblogs.com/icons/newpost.svg)\n![我的博客](//assets.cnblogs.com/icons/myblog.svg)\n![短消息](//assets.cnblogs.com/icons/message.svg)\n![简洁模式](//assets.cnblogs.com/icons/lite-mode-on.svg)\n![用户头像](//assets.cnblogs.com/icons/avatar-default.svg)\n![返回主页](/skins/custom/images/logo.gif)\n\n# [程序员半支烟](https://www.cnblogs.com/mangod)\n\n## 一个既懂技术又懂业务的技术直男。14余年IT行业经验，做过架构创过业。专注于软件开发、云原生、人工智能 等领域。wetchat：yclxiao\n\n# [LangChain让LLM带上记忆](https://www.cnblogs.com/mangod/p/18243321 "发布于 2024-06-12 09:36")\n\n最近两年，我们见识了“百模大战”，领略到了大型语言模型（LLM）的风采，但它们也存在一个显著的缺陷：没有记忆。\n\n在对话中，无法记住上下文的 LLM 常常会让用户感到困扰。本文探讨如何利用 LangChain，快速为 LLM 添加记忆能力，提升对话体验。\n\n**LangChain 是 LLM 应用开发领域的最大社区和最重要的框架。**\n\n## 1. LLM 固有缺陷，没有记忆\n\n当前的 LLM 非常智能，在理解和生成自然语言方面表现优异，但是有一个显著的缺陷：**没有记忆**。\n\nLLM 的本质是基于统计和概率来生成文本，对于每次请求，它们都将上下文视为独立事件。这意味着当你与 LLM 进行对话时，它不会记住你之前说过的话，这就导致了 LLM 有时表现得不够智能。\n\n这种“无记忆”属性使得 LLM 无法在长期对话中有效跟踪上下文，也无法积累历史信息。比如，当你在聊天过程中提到一个人名，后续再次提及该人时，LLM 可能会忘记你之前的描述。\n\n本着`发现问题解决问题`的原则，既然没有记忆，那就给 LLM 装上记忆吧。\n\n`发现问题解决问题`\n\n## 2. 记忆组件的原理\n\n### 2.1. 没有记忆的烦恼\n\n当我们与 LLM 聊天时，它们无法记住上下文信息，比如下图的示例：\n\n![]()\n\n![]()\n\n### 2.2. 原理\n\n如果将已有信息放入到 memory 中，每次跟 LLM 对话时，把已有的信息丢给 LLM，那么 LLM 就能够正确回答，见如下示例：\n\n![]()\n\n![]()\n\n目前业内解决 LLM 记忆问题就是采用了类似上图的方案，即：**将每次的对话记录再次丢入到 Prompt 里**，这样 LLM 每次对话时，就拥有了之前的历史对话信息。\n\n但如果每次对话，都需要自己手动将本次对话信息继续加入到`history`信息中，那未免太繁琐。有没有轻松一些的方式呢？**有，LangChain**！LangChain 对记忆组件做了高度封装，开箱即用。\n\n`history`\n\n### 2.3. 长期记忆和短期记忆\n\n在解决 LLM 的记忆问题时，有两种记忆方案，长期记忆和短期记忆。\n\n## 3. LangChain 让 LLM 记住上下文\n\nLangChain 提供了灵活的内存组件工具来帮助开发者为 LLM 添加记忆能力。\n\n### 3.1. 单独用 ConversationBufferMemory 做短期记忆\n\nLangchain 提供了 `ConversationBufferMemory` 类，可以用来存储和管理对话。\n\n`ConversationBufferMemory`\n\n`ConversationBufferMemory` 包含`input`变量和`output`变量，`input`代表人类输入，`output`代表 AI 输出。\n\n`ConversationBufferMemory`\n`input`\n`output`\n`input`\n`output`\n\n每次往`ConversationBufferMemory`组件里存入对话信息时，都会存储到`history`的变量里。\n\n`ConversationBufferMemory`\n`history`\n\n![]()\n\n![]()\n\n### 3.2. 利用 MessagesPlaceholder 手动添加 history\n\n`from langchain.memory import ConversationBufferMemory\nmemory = ConversationBufferMemory(return_messages=True)\nmemory.load_memory_variables({})\nmemory.save_context({"input": "我的名字叫张三"}, {"output": "你好，张三"})\nmemory.load_memory_variables({})\nmemory.save_context({"input": "我是一名 IT 程序员"}, {"output": "好的，我知道了"})\nmemory.load_memory_variables({})\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\nprompt = ChatPromptTemplate.from_messages(\n[\n("system", "你是一个乐于助人的助手。"),\nMessagesPlaceholder(variable_name="history"),\n("human", "{user_input}"),\n]\n)\nchain = prompt | model\nuser_input = "你知道我的名字吗？"\nhistory = memory.load_memory_variables({})["history"]\nchain.invoke({"user_input": user_input, "history": history})\nuser_input = "中国最高的山是什么山？"\nres = chain.invoke({"user_input": user_input, "history": history})\nmemory.save_context({"input": user_input}, {"output": res.content})\nres = chain.invoke({"user_input": "我们聊得最后一个问题是什么？", "history": history})`\n\n执行结果如下：\n\n![]()\n\n![]()\n\n### 3.3. 利用 ConversationChain 自动添加 history\n\n我们利用 LangChain 的`ConversationChain`对话链，自动添加`history`的方式添加临时记忆，无需手动添加。一个`链`实际上就是将一部分繁琐的小功能做了高度封装，这样多个链就可以组合形成易用的强大功能。这里`链`的优势一下子就体现出来了：\n\n`ConversationChain`\n`history`\n`链`\n`链`\n`from langchain.chains import ConversationChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\nmemory = ConversationBufferMemory(return_messages=True)\nchain = ConversationChain(llm=model, memory=memory)\nres = chain.invoke({"input": "你好，我的名字是张三，我是一名程序员。"})\nres[\'response\']\nres = chain.invoke({"input":"南京是哪个省？"})\nres[\'response\']\nres = chain.invoke({"input":"我告诉过你我的名字，是什么？，我的职业是什么？"})\nres[\'response\']`\n\n执行结果如下，可以看到利用`ConversationChain`对话链，可以让 LLM 快速拥有记忆：\n\n`ConversationChain`\n\n![]()\n\n![]()\n\n### 3.4. 对话链结合 PromptTemplate 和 MessagesPlaceholder\n\n在 Langchain 中，`MessagesPlaceholder`是一个占位符，用于在对话模板中动态插入上下文信息。它可以帮助我们灵活地管理对话内容，确保 LLM 能够使用最上下文来生成响应。\n\n`MessagesPlaceholder`\n\n采用`ConversationChain`对话链结合`PromptTemplate`和`MessagesPlaceholder`，几行代码就可以轻松让 LLM 拥有短时记忆。\n\n`ConversationChain`\n`PromptTemplate`\n`MessagesPlaceholder`\n`prompt = ChatPromptTemplate.from_messages(\n[\n("system", "你是一个爱撒娇的女助手，喜欢用可爱的语气回答问题。"),\nMessagesPlaceholder(variable_name="history"),\n("human", "{input}"),\n]\n)\nmemory = ConversationBufferMemory(return_messages=True)\nchain = ConversationChain(llm=model, memory=memory, prompt=prompt)\nres = chain.invoke({"input": "今天你好，我的名字是张三，我是你的老板"})\nres[\'response\']\nres = chain.invoke({"input": "帮我安排一场今天晚上的高规格的晚饭"})\nres[\'response\']\nres = chain.invoke({"input": "你还记得我叫什么名字吗？"})\nres[\'response\']`\n\n![]()\n\n![]()\n\n## 4. 使用长期记忆\n\n短期记忆在会话关闭或者服务器重启后，就会丢失。如果想长期记住对话信息，只能采用长期记忆组件。\n\nLangChain 支持多种长期记忆组件，比如`Elasticsearch`、`MongoDB`、`Redis`等，下面以`Redis`为例，演示如何使用长期记忆。\n\n`Elasticsearch`\n`MongoDB`\n`Redis`\n`Redis`\n`from langchain_community.chat_message_histories import RedisChatMessageHistory\nfrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_core.runnables.history import RunnableWithMessageHistory\nfrom langchain_openai import ChatOpenAI\nmodel = ChatOpenAI(\nmodel="gpt-3.5-turbo",\nopenai_api_key="sk-xxxxxxxxxxxxxxxxxxx",\nopenai_api_base="https://api.aigc369.com/v1",\n)\nprompt = ChatPromptTemplate.from_messages(\n[\n("system", "你是一个擅长{ability}的助手"),\nMessagesPlaceholder(variable_name="history"),\n("human", "{question}"),\n]\n)\nchain = prompt | model\nchain_with_history = RunnableWithMessageHistory(\nchain,\n# 使用redis存储聊天记录\nlambda session_id: RedisChatMessageHistory(\nsession_id, url="redis://10.22.11.110:6379/3"\n),\ninput_messages_key="question",\nhistory_messages_key="history",\n)\n# 每次调用都会保存聊天记录，需要有对应的session_id\nchain_with_history.invoke(\n{"ability": "物理", "question": "地球到月球的距离是多少？"},\nconfig={"configurable": {"session_id": "baily_question"}},\n)\nchain_with_history.invoke(\n{"ability": "物理", "question": "地球到太阳的距离是多少？"},\nconfig={"configurable": {"session_id": "baily_question"}},\n)\nchain_with_history.invoke(\n{"ability": "物理", "question": "地球到他俩之间谁更近"},\nconfig={"configurable": {"session_id": "baily_question"}},\n)`\n\nLLM 的回答如下，同时关闭 session 后，直接再次提问最后一个问题，LLM 仍然能给出正确答案。\n\n只要`configurable`配置的`session_id`能对应上，LLM 就能给出正确答案。\n\n`configurable`\n`session_id`\n\n![]()\n\n![]()\n\n然后，继续查看`redis`存储的数据，可以看到数据在 `redis` 中是以 `list`的数据结构存储的。\n\n`redis`\n `redis`\n`list`\n\n![]()\n\n![]()\n\n## 5. 总结\n\n本文介绍了 LLM 缺乏记忆功能的固有缺陷，以及记忆组件的原理，还讨论了如何利用 LangChain 给 LLM 装上记忆组件，让 LLM 能够在对话中更好地保持上下文。希望对你有帮助！\n\n======>>>>>> [关于我](https://mp.weixin.qq.com/s/xHu3SS2fKqw7dvzNlGBLOQ) <<<<<<======\n\n**本篇完结！欢迎点赞 关注 收藏！！！**\n\n**原文链接：**<https://mp.weixin.qq.com/s/bWZsP5CXYxsO6dARd1LtFQ>\n\n![]()\n\n![]()\n![](https://img2024.cnblogs.com/blog/35695/202512/35695-20251205182619157-1150461542.webp)\n\n\n### 公告\n\n![](//assets.cnblogs.com/images/ghs.png)浙公网安备 33010602011771号', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.cnblogs.com/mangod/p/18243321', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9997749, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:17:57,387 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=5, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:17:57,388 - __main__ - INFO - handle_download: downloaded=5
2026-02-02 20:17:57,389 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=5
2026-02-02 20:17:57,389 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': 'Short-term memory - Docs by LangChain', 'authors': [], 'abstract': '[Docs by LangChain home page](/)\n\n[LangChain](/oss/python/langchain/overview)[LangGraph](/oss/python/langgraph/overview)[Deep Agents](/oss/python/deepagents/overview)[Integrations](/oss/python/integrations/providers/overview)[Learn](/oss/python/learn)[Reference](/oss/python/reference/overview)[Contribute](/oss/python/contributing/overview)\n\n##### Get started\n\n* [Install](/oss/python/langchain/install)\n* [Quickstart](/oss/python/langchain/quickstart)\n* [Changelog](https://docs.langchain.com/oss/python/releases/changelog)\n* [Philosophy](/oss/python/langchain/philosophy)\n\n##### Core components\n\n* [Agents](/oss/python/langchain/agents)\n* [Models](/oss/python/langchain/models)\n* [Messages](/oss/python/langchain/messages)\n* [Tools](/oss/python/langchain/tools)\n* [Short-term memory](/oss/python/langchain/short-term-memory)\n* [Structured output](/oss/python/langchain/structured-output)\n\n##### Middleware\n\n* [Overview](/oss/python/langchain/middleware/overview)\n* [Built-in middleware](/oss/python/langchain/middleware/built-in)\n* [Custom middleware](/oss/python/langchain/middleware/custom)\n\n##### Advanced usage\n\n* [Guardrails](/oss/python/langchain/guardrails)\n* [Runtime](/oss/python/langchain/runtime)\n* [Context engineering](/oss/python/langchain/context-engineering)\n* [Model Context Protocol (MCP)](/oss/python/langchain/mcp)\n* [Human-in-the-loop](/oss/python/langchain/human-in-the-loop)\n* [Retrieval](/oss/python/langchain/retrieval)\n* [Long-term memory](/oss/python/langchain/long-term-memory)\n\n##### Agent development\n\n* [LangSmith Studio](/oss/python/langchain/studio)\n* [Test](/oss/python/langchain/test)\n* [Agent Chat UI](/oss/python/langchain/ui)\n\n##### Deploy with LangSmith\n\n* [Deployment](/oss/python/langchain/deploy)\n* [Observability](/oss/python/langchain/observability)\n\n* [Overview](#overview)\n* [Usage](#usage)\n* [In production](#in-production)\n* [Customizing agent memory](#customizing-agent-memory)\n* [Common patterns](#common-patterns)\n* [Trim messages](#trim-messages)\n* [Delete messages](#delete-messages)\n* [Summarize messages](#summarize-messages)\n* [Access memory](#access-memory)\n* [Tools](#tools)\n* [Read short-term memory in a tool](#read-short-term-memory-in-a-tool)\n* [Write short-term memory from tools](#write-short-term-memory-from-tools)\n* [Prompt](#prompt)\n* [Before model](#before-model)\n* [After model](#after-model)\n\n[Core components](/oss/python/langchain/agents)\n\n# Short-term memory\n\n## [\u200b](#overview) Overview\n\nMemory is a system that remembers information about previous interactions. For AI agents, memory is crucial because it lets them remember previous interactions, learn from feedback, and adapt to user preferences. As agents tackle more complex tasks with numerous user interactions, this capability becomes essential for both efficiency and user satisfaction. Short term memory lets your application remember previous interactions within a single thread or conversation.\n\nA thread organizes multiple interactions in a session, similar to the way email groups messages in a single conversation.\n\nConversation history is the most common form of short-term memory. Long conversations pose a challenge to today’s LLMs; a full history may not fit inside an LLM’s context window, resulting in an context loss or errors. Even if your model supports the full context length, most LLMs still perform poorly over long contexts. They get “distracted” by stale or off-topic content, all while suffering from slower response times and higher costs. Chat models accept context using [messages](/oss/python/langchain/messages), which include instructions (a system message) and inputs (human messages). In chat applications, messages alternate between human inputs and model responses, resulting in a list of messages that grows longer over time. Because context windows are limited, many applications can benefit from using techniques to remove or “forget” stale information.\n\n## [\u200b](#usage) Usage\n\nTo add short-term memory (thread-level persistence) to an agent, you need to specify a `checkpointer` when creating an agent.\n\nLangChain’s agent manages short-term memory as a part of your agent’s state.By storing these in the graph’s state, the agent can access the full context for a given conversation while maintaining separation between different threads.State is persisted to a database (or memory) using a checkpointer so the thread can be resumed at any time.Short-term memory updates when the agent is invoked or a step (like a tool call) is completed, and the state is read at the start of each step.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver  agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(), )) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"messages": [{"role": "user", "content": "Hi! My name is Bob."}]}, {"configurable": {"thread_id": "1"}},  {"configurable": {"thread_id": "1"}}, ))\n```\n\n### [\u200b](#in-production) In production\n\nIn production, use a checkpointer backed by a database:\n\nCopy\n\n```\npip install langgraph-checkpoint-postgres pip  install langgraph-checkpoint-postgres\n```\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from langgraph.checkpoint.postgres import PostgresSaver from langgraph.checkpoint.postgres import  PostgresSaver  DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable" DB_URI = "postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable"with PostgresSaver.from_conn_string(DB_URI) as checkpointer: with PostgresSaver.from_conn_string(DB_URI) as checkpointer: checkpointer.setup() # auto create tables in PostgresSql checkpointer.setup() # auto create tables in PostgresSql agent = create_agent( agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], checkpointer=checkpointer,  checkpointer =checkpointer,  ) )\n```\n\nFor more checkpointer options including SQLite, Postgres, and Azure Cosmos DB, see the [list of checkpointer libraries](/oss/python/langgraph/persistence#checkpointer-libraries) in the Persistence documentation.\n\n## [\u200b](#customizing-agent-memory) Customizing agent memory\n\nBy default, agents use [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to manage short term memory, specifically the conversation history via a `messages` key. You can extend [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) to add additional fields. Custom state schemas are passed to [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) using the [`state_schema`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware.state_schema) parameter.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaver class CustomAgentState(AgentState): class  CustomAgentState(AgentState):  user_id: str user_id: str preferences: dict preferences: dict agent = create_agent(agent = create_agent( "gpt-5", "gpt-5", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomAgentState,  state_schema =CustomAgentState,  checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) # Custom state can be passed in invoke # Custom state can be passed in invokeresult = agent.invoke(result = agent.invoke( { { "messages": [{"role": "user", "content": "Hello"}],  "messages": [{"role": "user", "content": "Hello"}], "user_id": "user_123",  "user_id": "user_123",  "preferences": {"theme": "dark"}  "preferences": {"theme": "dark"}  }, }, {"configurable": {"thread_id": "1"}}) {"configurable": {"thread_id": "1"}})\n```\n\n## [\u200b](#common-patterns) Common patterns\n\nWith [short-term memory](#add-short-term-memory) enabled, long conversations can exceed the LLM’s context window. Common solutions are:\n\n[## Trim messages\n\nRemove first or last N messages (before calling LLM)](#trim-messages)[## Delete messages\n\nDelete messages from LangGraph state permanently](#delete-messages)[## Summarize messages\n\nSummarize earlier messages in the history and replace them with a summary](#summarize-messages)\n\n## Custom strategies\n\nCustom strategies (e.g., message filtering, etc.)\n\nThis allows the agent to keep track of the conversation without exceeding the LLM’s context window.\n\n### [\u200b](#trim-messages) Trim messages\n\nMost LLMs have a maximum supported context window (denominated in tokens). One way to decide when to truncate messages is to count the tokens in the message history and truncate whenever it approaches that limit. If you’re using LangChain, you can use the trim messages utility and specify the number of tokens to keep from the list, as well as the `strategy` (e.g., keep the last `max_tokens`) to use for handling the boundary. To trim message history in an agent, use the [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware decorator:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( your_model_here, your_model_here, tools=your_tools_here,  tools =your_tools_here, middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#delete-messages) Delete messages\n\nYou can delete messages from the graph state to manage the message history. This is useful when you want to remove specific messages or clear the entire message history. To delete messages from the graph state, you can use the `RemoveMessage`. For `RemoveMessage` to work, you need to use a state key with [`add_messages`](https://reference.langchain.com/python/langgraph/graphs/#langgraph.graph.message.add_messages) [reducer](/oss/python/langgraph/graph-api#reducers). The default [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState) provides this. To remove specific messages:\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessage def delete_messages(state): def  delete_messages(state): messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]} \n```\n\nTo remove **all** messages:\n\nCopy\n\n```\nfrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGES def delete_messages(state): def  delete_messages(state): return {"messages": [RemoveMessage(id=REMOVE_ALL_MESSAGES)]}  return {"messages": [RemoveMessage(id = REMOVE_ALL_MESSAGES)]} \n```\n\nWhen deleting messages, **make sure** that the resulting message history is valid. Check the limitations of the LLM provider you’re using. For example:\n\n* Some providers expect message history to start with a `user` message\n* Most providers require `assistant` messages with tool calls to be followed by corresponding `tool` result messages.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig  @after_model @after_modeldef delete_old_messages(state: AgentState, runtime: Runtime) -> dict | None: def  delete_old_messages(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove old messages to keep conversation manageable.""" """Remove old messages to keep conversation manageable.""" messages = state["messages"]  messages = state["messages"] if len(messages) > 2:  if  len(messages) >  2:  # remove the earliest two messages  # remove the earliest two messages return {"messages": [RemoveMessage(id=m.id) for m in messages[:2]]}  return {"messages": [RemoveMessage(id =m.id) for  m in messages[: 2]]}  return None  return  None agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], system_prompt="Please be concise and to the point.",  system_prompt ="Please be concise and to the point.", middleware=[delete_old_messages],  middleware =[delete_old_messages], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, {"messages": [{"role": "user", "content": "hi! I\'m bob"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]]) for event in agent.stream(for  event in agent.stream( {"messages": [{"role": "user", "content": "what\'s my name?"}]}, {"messages": [{"role": "user", "content": "what\'s my name?"}]}, config, config, stream_mode="values",  stream_mode = "values",):): print([(message.type, message.content) for message in event["messages"]])  print([(message.type, message.content) for  message in event["messages"]])\n```\n\nCopy\n\n```\n[(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?")][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "hi! I\'m bob"), (\'ai\', \'Hi Bob! Nice to meet you. How can I help you today? I can answer questions, brainstorm ideas, draft text, explain things, or help with code.\'), (\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')][(\'human\', "what\'s my name?"), (\'ai\', \'Your name is Bob. How can I help you today, Bob?\')] \n```\n\n### [\u200b](#summarize-messages) Summarize messages\n\nThe problem with trimming or removing messages, as shown above, is that you may lose information from culling of the message queue. Because of this, some applications benefit from a more sophisticated approach of summarizing the message history using a chat model.  To summarize message history in an agent, use the built-in [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization):\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agentfrom langchain.agents.middleware import SummarizationMiddleware from langchain.agents.middleware import  SummarizationMiddlewarefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfig checkpointer = InMemorySaver() checkpointer = InMemorySaver() agent = create_agent(agent = create_agent( model="gpt-4o",  model ="gpt-4o", tools=[],  tools =[], middleware=[ middleware =[ SummarizationMiddleware( SummarizationMiddleware( model="gpt-4o-mini",  model ="gpt-4o-mini", trigger=("tokens", 4000),  trigger =("tokens", 4000), keep=("messages", 20)  keep =("messages", 20) ) ) ], ], checkpointer=checkpointer,  checkpointer =checkpointer,)) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}}agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob!Your name is Bob! """ """\n```\n\nSee [`SummarizationMiddleware`](/oss/python/langchain/middleware#summarization) for more configuration options.\n\n## [\u200b](#access-memory) Access memory\n\nYou can access and modify the short-term memory (state) of an agent in several ways:\n\n### [\u200b](#tools) Tools\n\n#### [\u200b](#read-short-term-memory-in-a-tool) Read short-term memory in a tool\n\nAccess short term memory (state) in a tool using the `runtime` parameter (typed as `ToolRuntime`). The `runtime` parameter is hidden from the tool signature (so the model doesn’t see it), but the tool can access the state through it.\n\nCopy\n\n```\nfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntime class CustomState(AgentState): class  CustomState(AgentState): user_id: str user_id: str @tool @tooldef get_user_info(def  get_user_info( runtime: ToolRuntime  runtime: ToolRuntime) -> str:) -> str: """Look up user info.""" """Look up user info.""" user_id = runtime.state["user_id"]  user_id = runtime.state["user_id"] return "User is John Smith" if user_id == "user_123" else "Unknown user"  return  "User is John Smith"  if  user_id ==  "user_123"  else  "Unknown user" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_user_info],  tools =[get_user_info], state_schema=CustomState,  state_schema =CustomState,)) result = agent.invoke({result = agent.invoke({ "messages": "look up user information",  "messages": "look up user information", "user_id": "user_123"  "user_id": "user_123"})})print(result["messages"][-1].content) print(result["messages"][- 1].content)# > User is John Smith.# > User is John Smith.\n```\n\n#### [\u200b](#write-short-term-memory-from-tools) Write short-term memory from tools\n\nTo modify the agent’s short-term memory (state) during execution, you can return state updates directly from the tools. This is useful for persisting intermediate results or making information accessible to subsequent tools or prompts.\n\nCopy\n\n```\nfrom langchain.tools import tool, ToolRuntime from langchain.tools import tool, ToolRuntimefrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langchain.messages import ToolMessage from langchain.messages import  ToolMessagefrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langgraph.types import Command from langgraph.types import  Command from pydantic import BaseModel from  pydantic import  BaseModel class CustomState(AgentState): class  CustomState(AgentState):  user_name: str user_name: str class CustomContext(BaseModel): class  CustomContext(BaseModel): user_id: str user_id: str @tool @tooldef update_user_info(def  update_user_info( runtime: ToolRuntime[CustomContext, CustomState],  runtime: ToolRuntime[CustomContext, CustomState],) -> Command:) -> Command: """Look up and update user info.""" """Look up and update user info.""" user_id = runtime.context.user_id  user_id = runtime.context.user_id name = "John Smith" if user_id == "user_123" else "Unknown user"  name =  "John Smith"  if  user_id ==  "user_123"  else  "Unknown user" return Command(update={  return Command(update ={  "user_name": name,  "user_name": name,  # update the message history  # update the message history "messages": [ "messages": [ ToolMessage( ToolMessage( "Successfully looked up user information",  "Successfully looked up user information", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) @tool @tooldef greet(def  greet( runtime: ToolRuntime[CustomContext, CustomState]  runtime: ToolRuntime[CustomContext, CustomState]) -> str | Command:) -> str  | Command: """Use this to greet the user once you found their info.""" """Use this to greet the user once you found their info.""" user_name = runtime.state.get("user_name", None)  user_name = runtime.state.get("user_name", None) if user_name is None:  if  user_name is  None: return Command(update={ return Command(update ={ "messages": [ "messages": [ ToolMessage( ToolMessage( "Please call the \'update_user_info\' tool it will get and update the user\'s name.", "Please call the \'update_user_info\' tool it will get and update the user\'s name.", tool_call_id=runtime.tool_call_id  tool_call_id =runtime.tool_call_id ) ) ] ] }) }) return f"Hello {user_name}!"  return  f "Hello {user_name}!" agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[update_user_info, greet],  tools =[update_user_info, greet], state_schema=CustomState,  state_schema =CustomState,  context_schema=CustomContext,  context_schema =CustomContext,)) agent.invoke(agent.invoke( {"messages": [{"role": "user", "content": "greet the user"}]}, {"messages": [{"role": "user", "content": "greet the user"}]}, context=CustomContext(user_id="user_123"),  context =CustomContext(user_id = "user_123"),))\n```\n\n### [\u200b](#prompt) Prompt\n\nAccess short term memory (state) in middleware to create dynamic prompts based on conversation history or custom state fields.\n\nCopy\n\n```\nfrom langchain.agents import create_agent from langchain.agents import  create_agent from typing import TypedDict from  typing import  TypedDictfrom langchain.agents.middleware import dynamic_prompt, ModelRequest from langchain.agents.middleware import dynamic_prompt, ModelRequest class CustomContext(TypedDict): class  CustomContext(TypedDict): user_name: str user_name: str def get_weather(city: str) -> str: def  get_weather(city: str) -> str: """Get the weather in a city.""" """Get the weather in a city.""" return f"The weather in {city} is always sunny!"  return  f "The weather in {city} is always sunny!"  @dynamic_prompt @dynamic_promptdef dynamic_system_prompt(request: ModelRequest) -> str: def  dynamic_system_prompt(request: ModelRequest) -> str: user_name = request.runtime.context["user_name"]  user_name = request.runtime.context["user_name"] system_prompt = f"You are a helpful assistant. Address the user as {user_name}."  system_prompt =  f"You are a helpful assistant. Address the user as {user_name}."  return system_prompt  return  system_prompt agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[get_weather],  tools =[get_weather], middleware=[dynamic_system_prompt],  middleware =[dynamic_system_prompt], context_schema=CustomContext,  context_schema =CustomContext,)) result = agent.invoke(result = agent.invoke( {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, {"messages": [{"role": "user", "content": "What is the weather in SF?"}]}, context=CustomContext(user_name="John Smith"),  context =CustomContext(user_name = "John Smith"),))for msg in result["messages"]: for  msg in result["messages"]: msg.pretty_print() msg.pretty_print() \n```\n\nOutput\n\nCopy\n\n```\n================================ Human Message ================================= ================================  Human  Message ================================= What is the weather in SF? What  is  the  weather  in  SF? ================================== Ai Message ================================== ==================================  Ai  Message ==================================Tool Calls: Tool Calls: get_weather (call_WFQlOGn4b2yoJrv7cih342FG)  get_weather (call_WFQlOGn4b2yoJrv7cih342FG) Call ID: call_WFQlOGn4b2yoJrv7cih342FG  Call ID:  call_WFQlOGn4b2yoJrv7cih342FG Args: Args: city: San Francisco city:  San  Francisco ================================= Tool Message ================================= =================================  Tool  Message =================================Name: get_weatherName:  get_weather The weather in San Francisco is always sunny! The  weather  in  San  Francisco  is  always sunny! ================================== Ai Message ================================== ==================================  Ai  Message ================================== Hi John Smith, the weather in San Francisco is always sunny! Hi  John Smith,  the  weather  in  San  Francisco  is  always sunny!\n```\n\n### [\u200b](#before-model) Before model\n\nAccess short term memory (state) in [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) middleware to process messages before model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.graph.message import REMOVE_ALL_MESSAGES from langgraph.graph.message import  REMOVE_ALL_MESSAGESfrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import before_model from langchain.agents.middleware import  before_modelfrom langchain_core.runnables import RunnableConfig from langchain_core.runnables import  RunnableConfigfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime from typing import Any from  typing import  Any  @before_model @before_modeldef trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None: def  trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] |  None: """Keep only the last few messages to fit context window.""" """Keep only the last few messages to fit context window.""" messages = state["messages"]  messages = state["messages"]  if len(messages) <= 3:  if  len(messages) <=  3:  return None # No changes needed  return  None  # No changes needed  first_msg = messages[0]  first_msg = messages[0] recent_messages = messages[-3:] if len(messages) % 2 == 0 else messages[-4:]  recent_messages = messages[- 3:] if  len(messages) %  2 ==  0  else messages[- 4:] new_messages = [first_msg] + recent_messages  new_messages = [first_msg] +  recent_messages  return { return { "messages": [ "messages": [ RemoveMessage(id=REMOVE_ALL_MESSAGES), RemoveMessage(id = REMOVE_ALL_MESSAGES), *new_messages * new_messages ] ] } } agent = create_agent(agent = create_agent( "gpt-5-nano", "gpt-5-nano", tools=[],  tools =[], middleware=[trim_messages],  middleware =[trim_messages], checkpointer=InMemorySaver()  checkpointer =InMemorySaver())) config: RunnableConfig = {"configurable": {"thread_id": "1"}}config: RunnableConfig = {"configurable": {"thread_id": "1"}} agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "hi, my name is bob"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "write a short poem about cats"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)agent.invoke({"messages": "now do the same but for dogs"}, config)final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response = agent.invoke({"messages": "what\'s my name?"}, config) final_response["messages"][-1].pretty_print()final_response["messages"][- 1].pretty_print() """ """ ================================== Ai Message ================================== ================================== Ai Message ================================== Your name is Bob. You told me that earlier.Your name is Bob. You told me that earlier.If you\'d like me to call you a nickname or use a different name, just say the word.If you\'d like me to call you a nickname or use a different name, just say the word. """ """\n```\n\n### [\u200b](#after-model) After model\n\nAccess short term memory (state) in [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) middleware to process messages after model calls.\n\nCopy\n\n```\nfrom langchain.messages import RemoveMessage from langchain.messages import  RemoveMessagefrom langgraph.checkpoint.memory import InMemorySaver from langgraph.checkpoint.memory import  InMemorySaverfrom langchain.agents import create_agent, AgentState from langchain.agents import create_agent, AgentStatefrom langchain.agents.middleware import after_model from langchain.agents.middleware import  after_modelfrom langgraph.runtime import Runtime from langgraph.runtime import  Runtime  @after_model @after_modeldef validate_response(state: AgentState, runtime: Runtime) -> dict | None: def  validate_response(state: AgentState, runtime: Runtime) -> dict  |  None: """Remove messages containing sensitive words.""" """Remove messages containing sensitive words.""" STOP_WORDS = ["password", "secret"]  STOP_WORDS = ["password", "secret"] last_message = state["messages"][-1]  last_message = state["messages"][- 1] if any(word in last_message.content for word in STOP_WORDS):  if  any(word in last_message.content for  word in  STOP_WORDS): return {"messages": [RemoveMessage(id=last_message.id)]}  return {"messages": [RemoveMessage(id =last_message.id)]}  return None  return  None agent = create_agent(agent = create_agent( model="gpt-5-nano",  model ="gpt-5-nano", tools=[],  tools =[], middleware=[validate_response],  middleware =[validate_response], checkpointer=InMemorySaver(),  checkpointer =InMemorySaver(),))\n```\n\n---\n\n[Edit this page on GitHub](https://github.com/langchain-ai/docs/edit/main/src/oss/langchain/short-term-memory.mdx) or [file an issue](https://github.com/langchain-ai/docs/issues/new/choose).\n\n[Connect these docs](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.\n\nWas this page helpful?\n\n[Tools](/oss/python/langchain/tools)[Overview](/oss/python/langchain/streaming/overview)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://docs.langchain.com/oss/python/langchain/short-term-memory', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9999573, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_Short-term memory - Docs by LangChain.md'}}
2026-02-02 20:24:59,046 - __main__ - INFO - call_tool: name=tavily_search, args={'query': '人工智能的发展历史？'}
2026-02-02 20:24:59,046 - __main__ - INFO - handle_search: searcher=TavilySearch, query=人工智能的发展历史？, search_type=None
2026-02-02 20:24:59,086 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': '人工智能的发展历史？'}
2026-02-02 20:24:59,086 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=人工智能的发展历史？, search_type=None
2026-02-02 20:24:59,100 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': '人工智能的发展历史？'}
2026-02-02 20:24:59,101 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=人工智能的发展历史？, search_type=None
2026-02-02 20:25:02,973 - __main__ - INFO - handle_search: returned=10
2026-02-02 20:25:02,973 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 20:25:02,974 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '人工智能史 - 维基百科，自由的百科全书[跳转到内容] \n[![]![维基百科]![自由的百科全书]] \n[搜索] \n搜索# 人工智能史30种语言\n* [Afrikaans] \n* [العربية] \n* [Azərbaycanca] \n* [বাংলা] \n* [Català] \n* [کوردی] \n* [Deutsch] \n* [Ελληνικά] \n* [English] \n* [Español] \n* [Euskara] \n* [فارسی] \n* [Français] \n* [עברית] \n* [हिन्दी] \n* [Հայերեն] \n* [Bahasa Indonesia] \n* [Íslenska] \n* [日本語] \n* [한국어] \n* [پښتو] \n* [Português] \n* [Русский] \n* [Српски / srpski] \n* [தமிழ்] \n* [Türkçe] \n* [Українська] \n* [Tiếng Việt] \n* [粵語] \n* [IsiZulu] \n[编辑链接] \n维基百科，自由的百科全书|[人工智能] 系列内容|\n[![]] |\n主要目标* [知识表示] \n* [自动规划] （英语：[Automated planning and scheduling] ）\n* [机器学习] \n* [语言处理] \n* [电脑视觉] \n* [机器人学] \n* [强人工智慧] \n* [弱人工智慧] \n* [人工智能对齐] \n|\n实现方式* [符号人工智能] \n* [深度学习] \n* [贝氏网路] \n* [进化算法] \n* [混合智能系统] \n* [混合专家模型] \n* [生成式人工智慧] \n* [代理式人工智能] （英语：[Agentic AI] ）\n|\n[人工智能哲学] \n* [伦理] （英语：[Ethics of artificial intelligence] ）\n* [人工智能安全] （英语：[AI safety] ）\n* [幻觉] \n* [存在风险] （英语：[Existential risk from artificial general intelligence] ）\n* [图灵测试] \n* [中文房间] \n* [可解释人工智慧] \n* [友好的人工智能] （英语：[Friendly artificial intelligence] ）\n* [人工智能监管] （英语：[Regulation of artificial intelligence] ）\n|\n历史* [时间轴] （英语：[Timeline of artificial intelligence] ）\n* [发展] （英语：[Progress in artificial intelligence] ）\n* [专家系统] \n* [人工智慧低谷] \n* [人工智能热潮] \n* [人工智能法案] \n|\n[人工智能的应用] \n* [应用] \n* [AlphaFold] \n* [深度伪造] \n* [AI艺术] \n* [音乐] \n* [医疗保健] \n* [工业] \n* [机器翻译] \n* [军事] \n* [项目] （英语：[List of artificial intelligence projects] ）\n* [编程语言] （英语：[List of programming languages for artificial intelligence] ）\n|\n主题与列表* [主题] \n* [术语表] \n* [AI概述] \n* [AI公司列表] （英语：[List of artificial intelligence companies] ）\n* [AI项目列表] （英语：[List of artificial intelligence projects] ）\n|\n* [查] \n* [论] \n* [编] \n|\n参见：[人工智能发展年表] （英语：[Timeline of artificial intelligence] ）\n**人工智能的历史**源远流长。在古代的[神话] [传说] 中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[&#91;1&#93;] 现代意义上的[AI] 始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑] 的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，[人工智能] 的研究领域确立于在[达特茅斯学院] 举行的[会议] 。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[&#91;2&#93;] 他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮] （也被称作AI之冬）。由于[詹姆斯·莱特希尔] 爵士的批评和国会方面的压力，[美国] 和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[&#91;3&#93;] \n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平] 的机器至今仍未出现。[图灵] 在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[&#91;4&#93;] \n在21世纪的第一个十年，[机器学习] 得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n|[计算历史] （英语：[History of computing] ）|\n[硬件] |\n* [1960年代之前] \n* [1960年代至今] （英语：[History of computing hardware (1960s–present)] ）|\n[软件] |\n* [软体] （英语：[History of software] ）\n* [Unix] （英语：[History of Unix] ）\n* [自由和开源软件] （英语：[History of free and open-source software] ）|\n[计算机科学] |\n* 人工智能* [编译器构造] （英语：[History of compiler construction] ）\n* [计算机科学] （英语：[History of computing] ）\n* [操作系统] \n* [程式语言] \n* [杰出先驱者] （英语：[List of pioneers in computer science] ）\n* [软体工程] （英语：[History of software engineering] ）|\n现代概念|\n* [通用CPU] （英语：[History of general-purpose CPUs] ）\n* [图形用户界面] \n* [互联网] \n* [个人电脑] （英语：[History of personal computers] ）\n* [笔记型电脑] （英语：[History of laptops] ）\n* [电子游戏] \n* [全球资讯网] （英语：[History of the World Wide Web] ）|\n按国家|\n* [保加利亚] （英语：[History of computer hardware in Bulgaria] ）\n* [波兰] （英语：[History of computing in Poland] ）\n* [罗马尼亚] （英语：[History of computing in Romania] ）\n* [苏联集团国家] （英语：[History of computer hardware in Soviet Bloc countries] ）\n* [苏联] （英语：[History of computing in the Soviet Union] ）\n* [南斯拉夫] （英语：[History of computer hardware in Yugoslavia] ）|\n[计算年表] （英语：[Timeline of computing] ）|\n* [1950年之前] （英语：[Timeline of computing hardware before 1950] ）\n* [1950–1979] （英语：[Timeline of computing 1950–1979] ）\n* [1980–1989] （英语：[Timeline of computing 1980–1989] ）\n* [1990–1999] （英语：[Timeline of computing 1990–1999] ）\n* [2000–2009] （英语：[Timeline of computing 2000–2009] ）\n* [2010–2019] （英语：[Timeline of computing 2010–2019] ）\n* [更多年表……] |\n[计算机科学词汇] （英语：[Glossary of computer science] ）|\n* ![分类] [分类] |\n* [查] \n* [论] \n* [编] \n|\n## 先驱[[编辑]]\n奥特曼写道[&#91;1&#93;] ：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机] ）的实践之中。[&#91;5&#93;] \n### 神话，幻想和预言中的AI\n[[编辑]]\n[希腊神话] 中已经出现了机械人和人造人，如[赫淮斯托斯] 的黄金机器人和[皮格马利翁] 的[伽拉忒亚] 。[&#91;6&#93;] 中世纪出现了使用巫术或[炼金术] 将意识赋予无生命物质的传说，如[贾比尔] 的*Takwin*，[帕拉塞尔苏斯] 的[何蒙库鲁兹] 和Judah Loew的[魔像] 。[&#91;7&#93;] 19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱] 的《[弗兰肯斯坦] 》和[卡雷尔·恰佩克] 的《罗素姆的万能机器人》。[&#91;8&#93;] Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[&#91;9&#93;] 至今人工智能仍然是科幻小说的重要元素。\n### 自动人偶[[编辑]]\n主条目：[自动机] \n[![]] [加扎利] 的可编程自动人偶（1206年）\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师] （中国西周）[&#91;10&#93;] ，[希罗] （希腊）[&#91;11&#93;] ，[加扎利] [&#91;12&#93;] 和Wolfgang von Kempelen[&#91;13&#93;] 等等。已知最古老的“机器人”是[古埃及] 和[古希腊] 的[圣像] ，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯] （[赫耳墨斯·特里斯墨吉斯忒斯] ）写道“当发现神的本性时，人就能够重现他”[&#91;14&#93;] [&#91;15&#93;] 。\n### 形式推理[[编辑]]\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德] （对三段论逻辑进行了形式分析），[欧几里得] （其著作《[几何原本] 》是形式推理的典范），[花剌子密] （代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉] 和[邓斯·司各脱] 。[&#91;16&#93;] \n[马略卡] 哲学家[拉蒙·柳利] （1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[&#91;17&#93;] 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[&#91;18&#93;] Llull的工作对[莱布尼兹] 产生了很大影响，后者进一步发展了他的思想。[&#91;19&#93;] \n[![]] [莱布尼兹] 猜测人类的思想可以简化为机械计算\n在17世纪中，[莱布尼兹] ，[托马斯·霍布斯] 和[笛卡儿] 尝试将理性的思考系统化为代数学或几何学那样的体系。[&#91;20&#93;] 霍布斯在其著作《[利维坦] 》中有一句名言：“推理就是计算（reason is nothing but reckoning）。”[&#91;21&#93;] 莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字] ），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[&#91;22&#93;] 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，[数理逻辑] 研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔] 的《思维的定律》与[弗雷格] 的《[概念文字] 》。基于弗雷格的系统，[罗素] 和[怀特海] 在他们于1913年出版的巨著《[数学原理] 》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特] ，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?”[&#91;16&#93;] 这个问题的最终回答由[哥德尔不完备定理] ，[图灵机] 和[Alonzo Church] 的[λ演算] 给出。[&#91;16&#93;] [&#91;23&#93;] 他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n[![]] 在摩尔学校的电气工程的ENIAC计算机\n[邱奇-图灵论题] 暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机] ：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[&#91;16&#93;] [&#91;24&#93;] \n### 计算机科学[[编辑]]\n主条目：[计算机硬体历史] \n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇] 设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝] 预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[&#91;25&#93;] （她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数] 的方法。）\n第一批现代计算机是[二战] 期间建造的大型译码机（包括Z3，[ENIAC] 和Colossus等）。[&#91;26&#93;] 后两个机器的理论基础是[图灵] 和[约翰·冯·诺伊曼] 提出和发展的学说。[&#91;27&#93;] \n## 人工智能的诞生：1943 - 1956\n[[编辑]]\n[&#91;28&#93;] 在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n### 控制论与早期神经网络[[编辑]]\n[![]] IBM 702：第一代AI研究者使用的电脑\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳] 的[控制论] 描述了电子网络的控制和稳定性。[克劳德·香农] 提出的[信息论] 则描述了[数字信号] （即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[&#91;29&#93;] \n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[&#91;30&#93;] \nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。', 'doi': '', 'published_date': '2026-02-02T20:25:02.972652', 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 20:25:05,639 - __main__ - INFO - handle_search: returned=3
2026-02-02 20:25:05,639 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=3
2026-02-02 20:25:05,640 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-02T20:25:05.639155', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-02 20:25:05', 'language': 'zh'}}
2026-02-02 20:25:07,792 - __main__ - INFO - handle_search: returned=7
2026-02-02 20:25:07,792 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=7
2026-02-02 20:25:07,792 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '![](/static/images/icons/zhwiki-25.svg)\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n![自由的百科全书](/static/images/mobile/copyright/wikipedia-tagline-zh-25-hans.svg)\n\n## 目录\n\n# 人工智能史\n\n| [人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")系列内容 |\n| --- |\n|  |\n| 主要目标  * [知识表示](/wiki/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA "知识表示") * [自动规划](/w/index.php?title=%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92%E5%92%8C%E8%B0%83%E5%BA%A6&action=edit&redlink=1 "自动规划和调度（页面不存在）")（英语：[Automated planning and scheduling](https://en.wikipedia.org/wiki/Automated_planning_and_scheduling "en:Automated planning and scheduling")） * [机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习") * [语言处理](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理") * [电脑视觉](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89 "计算机视觉") * [机器人学](/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6 "机器人学") * [强人工智慧](/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "通用人工智慧") * [弱人工智慧](/wiki/%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "弱人工智慧") * [人工智能对齐](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%B9%E9%BD%90 "人工智能对齐") |\n| 实现方式  * [符号人工智能](/wiki/%E7%AC%A6%E8%99%9F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "符号人工智能") * [深度学习](/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0 "深度学习") * [贝氏网路](/wiki/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF "贝氏网路") * [进化算法](/wiki/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95 "进化算法") * [混合智能系统](/wiki/%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%B3%BB%E7%B5%B1 "混合智能系统")   + [混合专家模型](/wiki/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B "混合专家模型") * [生成式人工智慧](/wiki/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "生成式人工智慧") * [代理式人工智能](/w/index.php?title=%E4%BB%A3%E7%90%86%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "代理式人工智能（页面不存在）")（英语：[AI agent](https://en.wikipedia.org/wiki/AI_agent "en:AI agent")） |\n| [人工智能哲学](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%93%B2%E5%AD%B8 "人工智能哲学")  * [伦理](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BC%A6%E7%90%86&action=edit&redlink=1 "人工智能伦理（页面不存在）")（英语：[Ethics of artificial intelligence](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence "en:Ethics of artificial intelligence")） * [人工智能安全](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%89%E5%85%A8&action=edit&redlink=1 "人工智能安全（页面不存在）")（英语：[AI safety](https://en.wikipedia.org/wiki/AI_safety "en:AI safety")）   + [幻觉](/wiki/%E5%B9%BB%E8%A7%89_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD) "幻觉 (人工智能)")   + [存在风险](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%98%E5%9C%A8%E9%A3%8E%E9%99%A9&action=edit&redlink=1 "人工智能的存在风险（页面不存在）")（英语：[Existential risk from artificial general intelligence](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence "en:Existential risk from artificial general intelligence")） * [图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试") * [中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间") * [可解释人工智慧](/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "可解释人工智慧") * [友好的人工智能](/w/index.php?title=%E5%8F%8B%E5%A5%BD%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "友好的人工智能（页面不存在）")（英语：[Friendly artificial intelligence](https://en.wikipedia.org/wiki/Friendly_artificial_intelligence "en:Friendly artificial intelligence")） * [人工智能监管](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9B%91%E7%AE%A1&action=edit&redlink=1 "人工智能监管（页面不存在）")（英语：[Regulation of artificial intelligence](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence "en:Regulation of artificial intelligence")） |\n| 历史  * [时间轴](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E9%97%B4%E8%BD%B4&action=edit&redlink=1 "人工智能时间轴（页面不存在）")（英语：[Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence "en:Timeline of artificial intelligence")） * [发展](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95&action=edit&redlink=1 "人工智能发展（页面不存在）")（英语：[Progress in artificial intelligence](https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence "en:Progress in artificial intelligence")） * [专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统") * [人工智慧低谷](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷") * [人工智能热潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%83%AD%E6%BD%AE "人工智能热潮") * [人工智能法案](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B3%95%E6%A1%88 "人工智能法案") |\n| [人工智能的应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")  * [应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")   + [AlphaFold](/wiki/AlphaFold "AlphaFold")   + [深度伪造](/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%AA%E9%80%A0 "深度伪造")   + [AI艺术](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%97%9D%E8%A1%93 "人工智慧艺术")   + [音乐](/wiki/%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "音乐和人工智能")   + [医疗保健](/wiki/%E5%8C%BB%E7%96%97%E9%A2%86%E5%9F%9F%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "医疗领域的人工智能")   + [工业](/wiki/%E5%B7%A5%E4%B8%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "工业人工智能")   + [机器翻译](/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91 "机器翻译")   + [军事](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BB%8D%E5%82%99%E7%AB%B6%E8%B3%BD "人工智能军备竞赛") * [项目](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B9%E7%9B%AE%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能项目列表（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） * [编程语言](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能编程语言列表（页面不存在）")（英语：[List of programming languages for artificial intelligence](https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence "en:List of programming languages for artificial intelligence")） |\n| 主题与列表  * [主题](/wiki/Portal:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Portal:人工智能") * [术语表](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AF%E8%AF%AD%E8%A1%A8 "人工智能术语表") * [AI概述](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%BF%B0 "人工智能概述") * [AI公司列表](/w/index.php?title=List_of_artificial_intelligence_companies&action=edit&redlink=1 "List of artificial intelligence companies（页面不存在）")（英语：[List of artificial intelligence companies](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies "en:List of artificial intelligence companies")） * [AI项目列表](/w/index.php?title=List_of_artificial_intelligence_projects&action=edit&redlink=1 "List of artificial intelligence projects（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） |\n| * [查](/wiki/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template:人工智能") * [论](/wiki/Template_talk:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template talk:人工智能") * [编](/wiki/Special:EditPage/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Special:EditPage/Template:人工智能") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png/250px-Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png)\n\n**人工智能的历史**源远流长。在古代的[神话](/wiki/%E7%A5%9E%E8%A9%B1 "神话")[传说](/wiki/%E4%BC%A0%E8%AF%B4 "传说")中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](/wiki/%E9%9B%BB%E8%85%A6 "电脑")的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n\n1956年，[人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")的研究领域确立于在[达特茅斯学院](/wiki/%E8%BE%BE%E7%89%B9%E8%8C%85%E6%96%AF%E5%AD%A6%E9%99%A2 "达特茅斯学院")举行的[会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2]](#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")（也被称作AI之冬）。由于[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")爵士的批评和国会方面的压力，[美国](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3]](#cite_note-3)\n\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "强人工智慧")的机器至今仍未出现。[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4]](#cite_note-TuringQuote-4)\n\n在21世纪的第一个十年，[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n| [计算历史](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） |\n| --- |\n| [硬件](/wiki/%E7%A1%AC%E4%BB%B6 "硬件") |\n| * [1960年代之前](/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2 "计算机硬体历史") * [1960年代至今](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2_(1960%E5%B9%B4%E4%BB%A3%E8%87%B3%E4%BB%8A)&action=edit&redlink=1 "计算机硬体历史 (1960年代至今)（页面不存在）")（英语：[History of computing hardware (1960s–present)](https://en.wikipedia.org/wiki/History_of_computing_hardware_(1960s%E2%80%93present) "en:History of computing hardware (1960s–present)")） |\n| [软件](/wiki/%E8%BD%AF%E4%BB%B6 "软件") |\n| * [软体](/w/index.php?title=%E8%BB%9F%E9%AB%94%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体历史（页面不存在）")（英语：[History of software](https://en.wikipedia.org/wiki/History_of_software "en:History of software")） * [Unix](/w/index.php?title=Unix%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Unix历史（页面不存在）")（英语：[History of Unix](https://en.wikipedia.org/wiki/History_of_Unix "en:History of Unix")） * [自由和开源软件](/w/index.php?title=%E8%87%AA%E7%94%B1%E5%92%8C%E9%96%8B%E6%BA%90%E8%BB%9F%E4%BB%B6%E7%9A%84%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "自由和开源软件的历史（页面不存在）")（英语：[History of free and open-source software](https://en.wikipedia.org/wiki/History_of_free_and_open-source_software "en:History of free and open-source software")） |\n| [计算机科学](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6 "计算机科学") |\n| * 人工智能 * [编译器构造](/w/index.php?title=%E7%BC%96%E8%AF%91%E5%99%A8%E6%9E%84%E9%80%A0%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "编译器构造历史（页面不存在）")（英语：[History of compiler construction](https://en.wikipedia.org/wiki/History_of_compiler_construction "en:History of compiler construction")） * [计算机科学](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算机科学历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） * [操作系统](/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%86%E5%8F%B2 "操作系统历史") * [程式语言](/wiki/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80%E6%AD%B7%E5%8F%B2 "程式语言历史") * [杰出先驱者](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%85%88%E9%A9%B1%E8%80%85%E5%88%97%E8%A1%A8&action=edit&redlink=1 "计算机科学先驱者列表（页面不存在）")（英语：[List of pioneers in computer science](https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science "en:List of pioneers in computer science")） * [软体工程](/w/index.php?title=%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体工程历史（页面不存在）")（英语：[History of software engineering](https://en.wikipedia.org/wiki/History_of_software_engineering "en:History of software engineering")） |\n| 现代概念 |\n| * [通用CPU](/w/index.php?title=%E9%80%9A%E7%94%A8%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "通用中央处理器历史（页面不存在）")（英语：[History of general-purpose CPUs](https://en.wikipedia.org/wiki/History_of_general-purpose_CPUs "en:History of general-purpose CPUs")） * [图形用户界面](/wiki/%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2 "图形用户界面") * [互联网](/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%8E%86%E5%8F%B2 "互联网历史") * [个人电脑](/w/index.php?title=%E5%80%8B%E4%BA%BA%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "个人电脑历史（页面不存在）")（英语：[History of personal computers](https://en.wikipedia.org/wiki/History_of_personal_computers "en:History of personal computers")） * [笔记型电脑](/w/index.php?title=%E7%AD%86%E8%A8%98%E5%9E%8B%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "笔记型电脑历史（页面不存在）")（英语：[History of laptops](https://en.wikipedia.org/wiki/History_of_laptops "en:History of laptops")） * [电子游戏](/wiki/%E9%9B%BB%E5%AD%90%E9%81%8A%E6%88%B2%E5%8F%B2 "电子游戏史") * [全球资讯网](/w/index.php?title=%E5%85%A8%E7%90%83%E8%B3%87%E8%A8%8A%E7%B6%B2%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "全球资讯网历史（页面不存在）")（英语：[History of the World Wide Web](https://en.wikipedia.org/wiki/History_of_the_World_Wide_Web "en:History of the World Wide Web")） |\n| 按国家 |\n| * [保加利亚](/w/index.php?title=%E4%BF%9D%E5%8A%A0%E5%88%A9%E4%BA%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "保加利亚计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Bulgaria](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Bulgaria "en:History of computer hardware in Bulgaria")） * [波兰](/w/index.php?title=%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "波兰计算历史（页面不存在）")（英语：[History of computing in Poland](https://en.wikipedia.org/wiki/History_of_computing_in_Poland "en:History of computing in Poland")） * [罗马尼亚](/w/index.php?title=%E7%BD%97%E9%A9%AC%E5%B0%BC%E4%BA%9A%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "罗马尼亚计算历史（页面不存在）")（英语：[History of computing in Romania](https://en.wikipedia.org/wiki/History_of_computing_in_Romania "en:History of computing in Romania")） * [苏联集团国家](/w/index.php?title=%E8%8B%8F%E8%81%94%E9%9B%86%E5%9B%A2%E5%9B%BD%E5%AE%B6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联集团国家计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Soviet Bloc countries](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Soviet_Bloc_countries "en:History of computer hardware in Soviet Bloc countries")） * [苏联](/w/index.php?title=%E8%8B%8F%E8%81%94%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联计算历史（页面不存在）")（英语：[History of computing in the Soviet Union](https://en.wikipedia.org/wiki/History_of_computing_in_the_Soviet_Union "en:History of computing in the Soviet Union")） * [南斯拉夫](/w/index.php?title=%E5%8D%97%E6%96%AF%E6%8B%89%E5%A4%AB%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "南斯拉夫计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Yugoslavia](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Yugoslavia "en:History of computer hardware in Yugoslavia")） |\n| [计算年表](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "计算年表（页面不存在）")（英语：[Timeline of computing](https://en.wikipedia.org/wiki/Timeline_of_computing "en:Timeline of computing")） |\n| * [1950年之前](/w/index.php?title=1950%E5%B9%B4%E4%B9%8B%E5%89%8D%E7%9A%84%E8%AE%A1%E7%AE%97%E7%A1%AC%E4%BB%B6%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "1950年之前的计算硬件年表（页面不存在）")（英语：[Timeline of computing hardware before 1950](https://en.wikipedia.org/wiki/Timeline_of_computing_hardware_before_1950 "en:Timeline of computing hardware before 1950")） * [1950–1979](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1950%E2%80%931979)&action=edit&redlink=1 "计算年表 (1950–1979)（页面不存在）")（英语：[Timeline of computing 1950–1979](https://en.wikipedia.org/wiki/Timeline_of_computing_1950%E2%80%931979 "en:Timeline of computing 1950–1979")） * [1980–1989](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1980%E2%80%931989)&action=edit&redlink=1 "计算年表 (1980–1989)（页面不存在）")（英语：[Timeline of computing 1980–1989](https://en.wikipedia.org/wiki/Timeline_of_computing_1980%E2%80%931989 "en:Timeline of computing 1980–1989")） * [1990–1999](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1990%E2%80%931999)&action=edit&redlink=1 "计算年表 (1990–1999)（页面不存在）")（英语：[Timeline of computing 1990–1999](https://en.wikipedia.org/wiki/Timeline_of_computing_1990%E2%80%931999 "en:Timeline of computing 1990–1999")） * [2000–2009](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2000%E2%80%932009)&action=edit&redlink=1 "计算年表 (2000–2009)（页面不存在）")（英语：[Timeline of computing 2000–2009](https://en.wikipedia.org/wiki/Timeline_of_computing_2000%E2%80%932009 "en:Timeline of computing 2000–2009")） * [2010–2019](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2010%E2%80%932019)&action=edit&redlink=1 "计算年表 (2010–2019)（页面不存在）")（英语：[Timeline of computing 2010–2019](https://en.wikipedia.org/wiki/Timeline_of_computing_2010%E2%80%932019 "en:Timeline of computing 2010–2019")） * [更多年表……](/wiki/Category:%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8 "Category:计算年表") |\n| [计算机科学词汇](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E8%AF%8D%E6%B1%87&action=edit&redlink=1 "计算机科学词汇（页面不存在）")（英语：[Glossary of computer science](https://en.wikipedia.org/wiki/Glossary_of_computer_science "en:Glossary of computer science")） |\n| * [分类](/wiki/Category:%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B2 "Category:计算机历史") |\n| * [查](/wiki/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Template:计算历史") * [论](/w/index.php?title=Template_talk:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Template talk:计算历史（页面不存在）") * [编](/wiki/Special:EditPage/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Special:EditPage/Template:计算历史") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)\n\n## 先驱\n\n奥特曼写道[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](/wiki/%E8%87%AA%E5%8B%95%E6%A9%9F "自动机")）的实践之中。[[5]](#cite_note-FOOTNOTEMcCorduck20045–35-5)\n\n### 神话，幻想和预言中的AI\n\n[希腊神话](/wiki/%E5%B8%8C%E8%85%8A%E7%A5%9E%E8%AF%9D "希腊神话")中已经出现了机械人和人造人，如[赫淮斯托斯](/wiki/%E8%B5%AB%E6%B7%AE%E6%96%AF%E6%89%98%E6%96%AF "赫淮斯托斯")的黄金机器人和[皮格马利翁](/wiki/%E7%9A%AE%E6%A0%BC%E9%A9%AC%E5%88%A9%E7%BF%81 "皮格马利翁")的[伽拉忒亚](/wiki/%E4%BC%BD%E6%8B%89%E5%BF%92%E4%BA%9A "伽拉忒亚")。[[6]](#cite_note-6)中世纪出现了使用巫术或[炼金术](/wiki/%E7%82%BC%E9%87%91%E6%9C%AF "炼金术")将意识赋予无生命物质的传说，如[贾比尔](/wiki/%E8%B4%BE%E6%AF%94%E5%B0%94 "贾比尔")的*Takwin*，[帕拉塞尔苏斯](/wiki/%E5%B8%95%E6%8B%89%E5%A1%9E%E5%B0%94%E8%8B%8F%E6%96%AF "帕拉塞尔苏斯")的[何蒙库鲁兹](/wiki/%E4%BD%95%E8%92%99%E5%BA%93%E9%B2%81%E5%85%B9 "何蒙库鲁兹")和Judah Loew的[魔像](/wiki/%E9%AD%94%E5%83%8F "魔像")。[[7]](#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](/wiki/%E7%8E%9B%E4%B8%BD%C2%B7%E9%9B%AA%E8%8E%B1 "玛丽·雪莱")的《[弗兰肯斯坦](/wiki/%E5%BC%97%E5%85%B0%E8%82%AF%E6%96%AF%E5%9D%A6 "弗兰肯斯坦")》和[卡雷尔·恰佩克](/wiki/%E5%8D%A1%E9%9B%B7%E5%B0%94%C2%B7%E6%81%B0%E4%BD%A9%E5%85%8B "卡雷尔·恰佩克")的《罗素姆的万能机器人》。[[8]](#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9]](#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。\n\n### 自动人偶\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)\n\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师](/wiki/%E5%81%83%E5%B8%88 "偃师")（中国西周）[[10]](#cite_note-10)，[希罗](/wiki/%E5%B8%8C%E7%BD%97 "希罗")（希腊）[[11]](#cite_note-11)，[加扎利](/wiki/%E5%8A%A0%E6%89%8E%E5%88%A9 "加扎利")[[12]](#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13]](#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](/wiki/%E5%8F%A4%E5%9F%83%E5%8F%8A "古埃及")和[古希腊](/wiki/%E5%8F%A4%E5%B8%8C%E8%85%8A "古希腊")的[圣像](/wiki/%E8%81%96%E5%83%8F "圣像")，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")（[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")）写道“当发现神的本性时，人就能够重现他”[[14]](#cite_note-14)[[15]](#cite_note-15)。\n\n### 形式推理\n\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](/wiki/%E4%BA%9A%E9%87%8C%E5%A3%AB%E5%A4%9A%E5%BE%B7 "亚里士多德")（对三段论逻辑进行了形式分析），[欧几里得](/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97 "欧几里得")（其著作《[几何原本](/wiki/%E5%87%A0%E4%BD%95%E5%8E%9F%E6%9C%AC "几何原本")》是形式推理的典范），[花剌子密](/wiki/%E8%8A%B1%E5%89%8C%E5%AD%90%E5%AF%86 "花剌子密")（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E7%9A%84%E5%A8%81%E5%BB%89 "奥卡姆的威廉")和[邓斯·司各脱](/wiki/%E9%82%93%E6%96%AF%C2%B7%E5%8F%B8%E5%90%84%E8%84%B1 "邓斯·司各脱")。[[16]](#cite_note-Berlinski_2000-16)\n\n[马略卡](/wiki/%E9%A9%AC%E7%95%A5%E5%8D%A1 "马略卡")哲学家[拉蒙·柳利](/wiki/%E6%8B%89%E8%92%99%C2%B7%E6%9F%B3%E5%88%A9 "拉蒙·柳利")（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17]](#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18]](#cite_note-18)Llull的工作对[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")产生了很大影响，后者进一步发展了他的思想。[[19]](#cite_note-19)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/250px-Gottfried_Wilhelm_von_Leibniz.jpg)\n\n在17世纪中，[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")，[托马斯·霍布斯](/wiki/%E6%89%98%E9%A9%AC%E6%96%AF%C2%B7%E9%9C%8D%E5%B8%83%E6%96%AF "托马斯·霍布斯")和[笛卡儿](/wiki/%E7%AC%9B%E5%8D%A1%E5%84%BF "笛卡儿")尝试将理性的思考系统化为代数学或几何学那样的体系。[[20]](#cite_note-20)霍布斯在其著作《[利维坦](/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF) "利维坦 (霍布斯)")》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21]](#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](/wiki/%E9%80%9A%E7%94%A8%E8%A1%A8%E6%84%8F%E6%96%87%E5%AD%97 "通用表意文字")），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22]](#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n\n在20世纪，[数理逻辑](/wiki/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91 "数理逻辑")研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](/wiki/%E4%B9%94%E6%B2%BB%C2%B7%E5%B8%83%E5%B0%94 "乔治·布尔")的《思维的定律》与[弗雷格](/wiki/%E6%88%88%E7%89%B9%E6%B4%9B%E5%B8%83%C2%B7%E5%BC%97%E9%9B%B7%E6%A0%BC "戈特洛布·弗雷格")的《[概念文字](/wiki/%E6%A6%82%E5%BF%B5%E6%96%87%E5%AD%97 "概念文字")》。基于弗雷格的系统，[罗素](/wiki/%E7%BD%97%E7%B4%A0 "罗素")和[怀特海](/wiki/%E6%80%80%E7%89%B9%E6%B5%B7 "怀特海")在他们于1913年出版的巨著《[数学原理](/wiki/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86 "数学原理")》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9 "希尔伯特")，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16]](#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")，[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")和[Alonzo Church](/wiki/Alonzo_Church "Alonzo Church")的[λ演算](/wiki/%CE%9B%E6%BC%94%E7%AE%97 "Λ演算")给出。[[16]](#cite_note-Berlinski_2000-16)[[23]](#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)\n\n[邱奇-图灵论题](/wiki/%E9%82%B1%E5%A5%87-%E5%9B%BE%E7%81%B5%E8%AE%BA%E9%A2%98 "邱奇-图灵论题")暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16]](#cite_note-Berlinski_2000-16)[[24]](#cite_note-24)\n\n### 计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](/wiki/%E6%9F%A5%E5%B0%94%E6%96%AF%C2%B7%E5%B7%B4%E8%B4%9D%E5%A5%87 "查尔斯·巴贝奇")设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](/wiki/%E6%84%9B%E9%81%94%C2%B7%E5%8B%92%E8%8A%99%E8%95%BE%E7%B5%B2 "爱达·勒芙蕾丝")预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25]](#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%95%B0 "伯努利数")的方法。）\n\n第一批现代计算机是[二战](/wiki/%E4%BA%8C%E6%88%98 "二战")期间建造的大型译码机（包括Z3，[ENIAC](/wiki/ENIAC "ENIAC")和Colossus等）。[[26]](#cite_note-26)后两个机器的理论基础是[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")和[约翰·冯·诺伊曼](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC "约翰·冯·诺伊曼")提出和发展的学说。[[27]](#cite_note-27)\n\n## 人工智能的诞生：1943 - 1956\n\n[[28]](#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n### 控制论与早期神经网络\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/250px-BRL61-IBM_702.jpg)\n\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](/wiki/%E8%AF%BA%E4%BC%AF%E7%89%B9%C2%B7%E7%BB%B4%E7%BA%B3 "诺伯特·维纳")的[控制论](/wiki/%E6%8E%A7%E5%88%B6%E8%AE%BA "控制论")描述了电子网络的控制和稳定性。[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")提出的[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")则描述了[数字信号](/wiki/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7 "数字信号")（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29]](#cite_note-29)\n\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30]](#cite_note-30)\n\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")”的学者。[[31]](#cite_note-31)[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](/w/index.php?title=SNARC&action=edit&redlink=1 "SNARC（页面不存在）")。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n### 游戏AI\n\n1951年，[克里斯托弗·斯特雷奇](/wiki/%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%BC%97%C2%B7%E6%96%AF%E7%89%B9%E9%9B%B7%E5%A5%87 "克里斯托弗·斯特雷奇")使用[曼彻斯特大学](/wiki/%E6%9B%BC%E5%BD%BB%E6%96%AF%E7%89%B9%E5%A4%A7%E5%AD%A6 "曼彻斯特大学")的Ferranti Mark 1机器写出了一个[西洋跳棋](/wiki/%E8%A5%BF%E6%B4%8B%E8%B7%B3%E6%A3%8B "西洋跳棋")（checkers）程序；[迪特里希·普林茨](/w/index.php?title=%E8%BF%AA%E7%89%B9%E9%87%8C%E5%B8%8C%C2%B7%E6%99%AE%E6%9E%97%E8%8C%A8&action=edit&redlink=1 "迪特里希·普林茨（页面不存在）")（Dietrich Prinz）则写出了一个[国际象棋](/wiki/%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B "国际象棋")程序。[[32]](#cite_note-32)[亚瑟·李·塞谬尔](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E6%9D%8E%C2%B7%E5%A1%9E%E8%AC%AC%E7%88%BE "亚瑟·李·塞谬尔")（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33]](#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。\n\n### 图灵测试\n\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34]](#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试")：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35]](#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。\n\n### 符号推理与“逻辑理论家”程序\n\n50年代中期，随着数位计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36]](#cite_note-36)\n\n1955年，[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和后来荣获诺贝尔奖的[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")在J. C. Shaw的协助下开发了“[逻辑理论家](/wiki/%E9%80%BB%E8%BE%91%E7%90%86%E8%AE%BA%E5%AE%B6 "逻辑理论家")（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37]](#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](/wiki/%E5%BF%83%E8%BA%AB%E4%BA%8C%E5%88%86%E6%B3%95 "心身二分法")，解释了物质构成的系统如何获得心灵的性质。”[[38]](#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92 "约翰·罗杰斯·希尔勒")称为“强人工智能”，即机器可以像人一样具有思想。）[[39]](#cite_note-39)\n\n### 1956年达特茅斯会议：AI的诞生\n\n1956年[达特矛斯会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")[[40]](#cite_note-40)的组织者是[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")，[约翰·麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")和另两位资深科学家[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](/wiki/IBM "IBM")。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41]](#cite_note-41)与会者包括[雷·索罗门诺夫](/w/index.php?title=%E9%9B%B7%C2%B7%E7%B4%A2%E7%BE%85%E9%96%80%E8%AB%BE%E5%A4%AB&action=edit&redlink=1 "雷·索罗门诺夫（页面不存在）")（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42]](#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")则说服与会者接受“人工智能”一词作为本领域的名称。[[43]](#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44]](#cite_note-44)\n\n## 第一波浪潮 - 黄金年代：1956 - 1974\n\n[达特矛斯](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45]](#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46]](#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47]](#cite_note-47) [DARPA](/wiki/DARPA "DARPA")（[国防高等研究计划署](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")）等政府机构向这一新兴领域投入了大笔资金。[[48]](#cite_note-48)\n\n### 研究工作\n\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n#### 搜索式推理\n\n许多AI程序使用相同的基本[算法](/wiki/%E7%AE%97%E6%B3%95 "算法")。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95 "回溯法")。这就是“搜索式推理”。[[49]](#cite_note-49)\n\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95 "启发式算法")去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50]](#cite_note-50)\n\n艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](/wiki/%E4%B8%80%E8%88%AC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%99%A8 "一般问题解决器")（General Problem Solver）”程序，将这一算法推广到一般情形。[[51]](#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52]](#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](/wiki/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6 "斯坦福大学")为控制机器人Shakey而开发的STRIPS系统。[[53]](#cite_note-53)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)\n\n#### 自然语言\n\nAI研究的一个重要目标是使计算机能够通过[自然语言](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理")（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54]](#cite_note-54)\n\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](/wiki/%E8%AF%AD%E4%B9%89%E7%BD%91 "语义网")（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55]](#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56]](#cite_note-56)\n\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57]](#cite_note-57)\n\n#### 微世界\n\n60年代后期，[麻省理工大学](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")AI实验室的马文·闵斯基和[西摩尔·派普特](/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9 "西摩尔·派普特")建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58]](#cite_note-58)\n\n在这一指导思想下，[杰拉德·杰伊·萨斯曼](/wiki/%E5%82%91%E6%8B%89%E5%BE%B7%C2%B7%E5%82%91%E4%BC%8A%C2%B7%E8%96%A9%E6%96%AF%E6%9B%BC "杰拉德·杰伊·萨斯曼")（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](/w/index.php?title=%E5%A4%A7%E8%A1%9B%C2%B7%E7%93%A6%E7%88%BE%E8%8C%B2&action=edit&redlink=1 "大卫·瓦尔兹（页面不存在）")（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](/wiki/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89 "机器视觉")领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](/wiki/SHRDLU "SHRDLU")，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59]](#cite_note-59)\n\n### 乐观思潮\n\n第一代AI研究者们曾作出了如下预言:\n\n### 经费\n\n1963年6月，[MIT](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64]](#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](/wiki/%E5%8D%A1%E5%86%85%E5%9F%BA%E6%A2%85%E9%9A%86%E5%A4%A7%E5%AD%A6 "卡内基梅隆大学")的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65]](#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](/wiki/%E7%88%B1%E4%B8%81%E5%A0%A1%E5%A4%A7%E5%AD%A6 "爱丁堡大学")建立。[[66]](#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67]](#cite_note-67)\n\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68]](#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](/wiki/Hacker "Hacker")文化的形成，[[69]](#cite_note-69)但是好景不长。\n\n## 第一次AI低谷：1974 - 1980\n\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70]](#cite_note-70)同时，由于马文·闵斯基对[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")的激烈批评，[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")（即[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")）销声匿迹了十年。[[71]](#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](/wiki/%E9%80%BB%E8%BE%91%E7%BC%96%E7%A8%8B "逻辑编程")，常识推理等一些领域还是有所进展。[[72]](#cite_note-72)\n\n### 问题\n\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73]](#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74]](#cite_note-74)\n\n### 停止拨款\n\n由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81]](#cite_note-81)1973年[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82]](#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83]](#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84]](#cite_note-84)到了1974年已经很难再找到对AI项目的资助。\n\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85]](#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86]](#cite_note-86)\n\n### 来自大学的批评\n\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")已经证明[形式系统](/wiki/%E5%BD%A2%E5%BC%8F%E7%B3%BB%E7%BB%9F "形式系统")（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87]](#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88]](#cite_note-88)[[89]](#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间")”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](/wiki/%E6%84%8F%E5%90%91%E6%80%A7 "意向性")（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90]](#cite_note-90)\n\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](/wiki/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7 "计算复杂性")和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91]](#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92]](#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93]](#cite_note-93)\n\n约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94]](#cite_note-94)\n\n### 感知器与联结主义遭到冷落\n\n[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")是[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71]](#cite_note-Perceptrons-71)\n\n### “简约派（the neats）”：逻辑，Prolog语言和专家系统\n\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95]](#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96]](#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](/wiki/Prolog "Prolog")。[[97]](#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](/w/index.php?title=%E7%94%9F%E7%94%A2%E8%A6%8F%E5%89%87&action=edit&redlink=1 "生产规则（页面不存在）")（英语：[Production\\_system\\_(computer\\_science)](https://en.wikipedia.org/wiki/Production_system_(computer_science) "en:Production system (computer science)")）”密切相关的“[霍恩子句](/wiki/%E9%9C%8D%E6%81%A9%E5%AD%90%E5%8F%A5 "霍恩子句")”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](/wiki/%E6%84%9B%E5%BE%B7%E8%8F%AF%C2%B7%E8%B2%BB%E6%A0%B9%E9%AE%91%E5%A7%86 "爱德华·费根鲍姆")的[专家系统](/wiki/%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1 "专家系统")以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")及[认知统一理论](/wiki/%E8%AA%8D%E7%9F%A5%E7%B5%B1%E4%B8%80%E7%90%86%E8%AB%96 "认知统一理论")。[[98]](#cite_note-98)\n\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](/wiki/%E9%98%BF%E6%91%A9%E5%8F%B8%C2%B7%E7%89%B9%E6%B2%83%E6%96%AF%E5%9F%BA "阿摩司·特沃斯基")，Daniel Kahneman等人的实验证明了这一点。[[99]](#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100]](#cite_note-100)\n\n### “芜杂派（the scruffies）”：框架和脚本\n\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101]](#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102]](#cite_note-102)\n\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103]](#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n## 第二波浪潮 - 繁荣：1980—1987\n\n在80年代，一类名为“[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n### 专家系统获得赏识\n\n[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104]](#cite_note-104)\n\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105]](#cite_note-105)\n\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106]](#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107]](#cite_note-107)\n\n### 知识革命\n\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108]](#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109]](#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110]](#cite_note-110)\n\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111]](#cite_note-111)\n\n### 重获拨款：第五代工程\n\n1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](/wiki/%E7%AC%AC%E4%BA%94%E4%BB%A3%E9%9B%BB%E8%85%A6 "第五代电脑")项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112]](#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](/wiki/Prolog "Prolog")作为该项目的主要编程语言。[[113]](#cite_note-113)\n\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114]](#cite_note-114)[[115]](#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116]](#cite_note-116)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/250px-Hopfield-net.png)\n\n### 联结主义的重生\n\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 "反向传播算法")，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115]](#cite_note-Norvig_25-115)[[117]](#cite_note-117)\n\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86 "分布式并行处理")”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115]](#cite_note-Norvig_25-115)[[118]](#cite_note-118)\n\n## 第二次AI低谷：1987—1993\n\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n### 人工智慧的低谷\n\n“[AI之冬](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119]](#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120]](#cite_note-120)\n\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")）））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121]](#cite_note-121)\n\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122]](#cite_note-122)\n\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123]](#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123]](#cite_note-FifthGenEnd-123)\n\n### 躯体的重要性：Nouvelle AI与嵌入式推理\n\n80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124]](#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](/wiki/%E8%8E%AB%E6%8B%89%E7%B6%AD%E5%85%8B%E6%82%96%E8%AB%96 "莫拉维克悖论")）。[[125]](#cite_note-125)他们号召“[自底向上](/wiki/%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%92%8C%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%A8%AD%E8%A8%88 "自上而下和自下而上设计")”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。\n\n另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126]](#cite_note-126)\n\n在发表于1990年的论文“大象不玩象棋（Elephants Don\'t Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](/wiki/%E7%89%A9%E7%90%86%E7%AC%A6%E8%99%9F%E7%B3%BB%E7%B5%B1 "物理符号系统")”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127]](#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](/wiki/%E9%AB%94%E5%8C%96%E8%AA%8D%E7%9F%A5 "体化认知")（embodied mind/reason/cognition）”论题。[[128]](#cite_note-128)\n\n## 第三波浪潮 - 大数据与机器学习：1993—2019\n\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129]](#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。\n\n### 里程碑和摩尔定律\n\n1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](/wiki/%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BE%85%E5%A4%AB "卡斯帕罗夫")的第一个计算机系统。[[130]](#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131]](#cite_note-131)2009年，[蓝脑计画](/wiki/%E8%97%8D%E8%85%A6%E8%A8%88%E7%95%AB "蓝脑计画")声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](/w/index.php?title=IBM_%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%A8%8B%E5%BA%8F)&action=edit&redlink=1 "IBM 沃森 (人工智慧程序)（页面不存在）")参加《[危险边缘](/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98 "危险边缘")》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](/wiki/AlphaGo "AlphaGo")击败[李世乭](/wiki/%E6%9D%8E%E4%B8%96%E4%B9%AD "李世乭")，成为第一个不让子而击败职业[围棋](/wiki/%E5%9C%8D%E6%A3%8B "围棋")棋士的[电脑围棋](/wiki/%E7%94%B5%E8%84%91%E5%9B%B4%E6%A3%8B "电脑围棋")程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](/wiki/%E4%B8%AD%E5%9B%BD%E4%B9%8C%E9%95%87%E5%9B%B4%E6%A3%8B%E5%B3%B0%E4%BC%9A "中国乌镇围棋峰会")的三局比赛中击败[[132]](#cite_note-wuzhensecond-132)当时世界排名第一[[133]](#cite_note-133)[[134]](#cite_note-134)的中国棋手[柯洁](/wiki/%E6%9F%AF%E6%B4%81 "柯洁")。\n\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135]](#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136]](#cite_note-136)这种剧烈增长可以用[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n### 智能代理\n\n90年代，被称为“[智能代理](/wiki/%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86 "智能代理")”的新范式被广泛接受。[[137]](#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138]](#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139]](#cite_note-R27-139)当经济学中的“[理性代理](/wiki/%E7%90%86%E6%80%A7%E4%B8%BB%E4%BD%93 "理性主体")（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140]](#cite_note-140)\n\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](/w/index.php?title=%E4%BB%A3%E7%90%86%E6%9E%B6%E6%9E%84&action=edit&redlink=1 "代理架构（页面不存在）")（英语：[Agent\\_architecture](https://en.wikipedia.org/wiki/Agent_architecture "en:Agent architecture")）（像Newell的[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139]](#cite_note-R27-139)[[141]](#cite_note-141)\n\n### “简约派”的胜利\n\n越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142]](#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143]](#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144]](#cite_note-RN25-144)[[145]](#cite_note-145)\n\nJudea Pearl发表于1988年的名著[[146]](#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C "贝叶斯网络")，[隐马尔可夫模型](/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B "隐马尔可夫模型")，[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144]](#cite_note-RN25-144)\n\n### 幕后的AI\n\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147]](#cite_note-147)这些解决方案在产业界起到了重要作用。[[148]](#cite_note-148)应用了AI技术的有[数据挖掘](/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98 "数据挖掘")，[工业机器人](/wiki/%E5%B7%A5%E4%B8%9A%E6%9C%BA%E5%99%A8%E4%BA%BA "工业机器人")，[物流](/wiki/%E7%89%A9%E6%B5%81 "物流")[[149]](#cite_note-149)，[语音识别](/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB "语音识别")[[150]](#cite_note-150)，银行业软件[[151]](#cite_note-CNN7242006-151)，医疗诊断[[151]](#cite_note-CNN7242006-151)和[Google](/wiki/Google "Google")搜索引擎等。[[152]](#cite_note-152)\n\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153]](#cite_note-153)[尼克·博斯特罗姆](/wiki/%E5%B0%BC%E5%85%8B%C2%B7%E5%8D%9A%E6%96%AF%E7%89%B9%E7%BD%97%E5%A7%86 "尼克·博斯特罗姆")解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154]](#cite_note-154)\n\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](/wiki/%E4%BF%A1%E6%81%AF%E5%AD%A6 "信息学")，[知识系统](/w/index.php?title=%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "知识系统（页面不存在）")，[认知系统](/w/index.php?title=%E8%AE%A4%E7%9F%A5%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "认知系统（页面不存在）")或[计算智能](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD&action=edit&redlink=1 "计算智能（页面不存在）")。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155]](#cite_note-155)[[156]](#cite_note-156)[[157]](#cite_note-157)\n\n### HAL 9000在哪里?\n\n1968年[亚瑟·克拉克](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E5%85%8B%E6%8B%89%E5%85%8B "亚瑟·克拉克")和[史丹利·库柏力克](/wiki/%E5%8F%B2%E4%B8%B9%E5%88%A9%C2%B7%E5%BA%AB%E6%9F%8F%E5%8A%9B%E5%85%8B "史丹利·库柏力克")创作的《“[2001太空漫游](/wiki/2001%E5%A4%AA%E7%A9%BA%E6%BC%AB%E6%B8%B8 "2001太空漫游")”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158]](#cite_note-158)\n\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159]](#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")））。[[160]](#cite_note-160)[雷蒙德·库茨魏尔](/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94 "雷蒙德·库茨魏尔")相信问题在于计算机性能，根据[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")，他预测具有人类智能水平的机器将在2029年出现。[[161]](#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162]](#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n### 深度学习，大数据和通用人工智能：2011至2019\n\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n#### 深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](/wiki/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86 "MNIST数据集")（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n#### 大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n## 第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n### 大型语言模型\n\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](/wiki/ChatGPT "ChatGPT")基于[GPT-3.5](/wiki/GPT-3 "GPT-3")架构的[大型语言模型](/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B "大型语言模型")并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，[GPT-4](/wiki/GPT-4 "GPT-4")正式推出，进一步加强大型语言模型的推理能力。2023年8月，中国百度公司向公众开放使用[文心一言](/wiki/%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80 "文心一言")，让中国内地民众都可以使用内地版的大型语言模型。2025年1月，[深度求索](/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2 "深度求索")推出著名的[DeepSeek-R1](/wiki/DeepSeek-R1 "DeepSeek-R1") [开源](/wiki/%E9%96%8B%E6%BA%90 "开源")大型语言模型，并使用新的算法减低训练成本。\n\n### 机器人整合与人工智能的实际应用（2025年至今）\n\n先进的人工智能（AI）系统能够高精度理解和回应人类对话，已成熟到能够与机器人无缝整合，改变了制造业、医疗保健、公共服务和材料研究等行业。[[163]](#cite_note-163) 人工智能还通过高级数据分析和假设生成加速科学研究。[[164]](#cite_note-164) 包括中国、美国和日本在内的国家在政策和资金方面进行了大量投资，以部署人工智能驱动的机器人和人工智能的实际应用，解决劳动力短缺问题，促进创新并提高效率，同时实施监管框架以确保道德和安全发展。[[165]](#cite_note-165)\n\n#### 中国\n\n2025年被誉为“人工智能机器人年”，标志著人工智能（AI）与机器人无缝整合的关键时刻。在2025年，中国投资约7300亿元人民币（约1000亿美元）用于智能制造和医疗保健领域的人工智能和机器人技术发展。[[166]](#cite_note-166) [[167]](#cite_note-167) 第十四个五年规划（2021-2025年）优先发展服务机器人，人工智能系统使机器人能够执行复杂任务，例如协助手术或自动化工厂装配线。[[168]](#cite_note-168) 例如，中国医院中的人工智能人形机器人可以解读患者请求、运送物资并协助护士完成日常任务，显示现有的人工智能对话能力足以应用于实际的机器人应用。部分资金还支持国防应用，例如自主无人机。[[169]](#cite_note-169)[[170]](#cite_note-170) 自2025年9月起，中国要求对人工智能生成的内容进行标记，以确保技术的透明度和公众信任。[[171]](#cite_note-171)\n\n#### 美国\n\n2025年1月，人工智能基础设施投资取得重大进展，[星际之门计划](/wiki/%E6%98%9F%E9%99%85%E4%B9%8B%E9%97%A8%E8%AE%A1%E5%88%92 "星际之门计划") 成立。这家由 [OpenAI](/wiki/OpenAI "OpenAI")、[SoftBank Group](/wiki/SoftBank_Group "SoftBank Group")、[Oracle](/wiki/Oracle_Corporation "Oracle Corporation") 和 [MGX](/w/index.php?title=MGX_Fund_Management_Limited&action=edit&redlink=1 "MGX Fund Management Limited（页面不存在）") 组成的合资企业宣布计划到2029年在[美国](/wiki/%E7%BE%8E%E5%9C%8B "美国")投资5000亿美元用于人工智能基础设施，首期投资1000亿美元，以支持美国的再工业化并提供保护美国及其盟友国家安全的战略能力。[[172]](#cite_note-172) 该合资企业于2025年1月21日由美国总统唐纳德·特朗普正式宣布，SoftBank Group首席执行官 [孙正义](/wiki/%E5%AD%AB%E6%AD%A3%E7%BE%A9 "孙正义") 被任命为主席。[[173]](#cite_note-reuters-173)[[174]](#cite_note-174)\n\n美国政府拨款约20亿美元用于在制造业和物流业中整合人工智能和机器人技术，利用人工智能处理自然语言和执行用户指令的能力。[[175]](#cite_note-175) 各州政府补充资金支持服务机器人，例如部署在仓库中执行口头指令进行库存管理，或在养老院中回应居民的援助请求。[[176]](#cite_note-176) 这些应用表明，将已经熟练于人类交互的高级人工智能与机器人硬体结合是一项实际的前进步骤。\n\n2025年1月，第14179号行政命令确立了“人工智能行动计划”，以加速这些技术的创新和部署。[[177]](#cite_note-177)\n\n#### 影响\n\n2020年代各国政府和机构对AI的投资加速了人工智能的发展，推动了科学进步，提高了劳动效率，并通过自动化复杂任务改变了各行业。[[178]](#cite_note-178) 通过将成熟的人工智能系统整合到各行业的应用当中，这些发展有望彻底改变智能制造和服务行业，重塑人类的日常生活。\n\n## 注释\n\n## 参考文献\n\n`|date=`\n`|date=`\n`|date=`\n\n.\n\n![](https://zh.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&type=1x1&usesul3=1)\n![Wikimedia Foundation](/static/images/footer/wikimedia.svg)\n![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99847525, 'save_path': None}}
2026-02-02 20:26:16,913 - __main__ - INFO - call_tool: name=wikipedia_download, args={'papers': [{'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-02T20:25:05.639155', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-02 20:25:05', 'language': 'zh'}}, {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-02T20:25:05.639170', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-02 20:25:05', 'language': 'zh'}}, {'paper_id': '1468546', 'title': '通用人工智慧', 'authors': ['Wikipedia'], 'abstract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'doi': '', 'published_date': '2026-02-02T20:25:05.639177', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'pageid': 1468546, 'fetch_time': '2026-02-02 20:25:05', 'language': 'zh'}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:26:16,914 - __main__ - INFO - handle_download: searcher=WikipediaSearcher, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:26:16,923 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '人工智能史 - 维基百科，自由的百科全书[跳转到内容] \n[![]![维基百科]![自由的百科全书]] \n[搜索] \n搜索# 人工智能史30种语言\n* [Afrikaans] \n* [العربية] \n* [Azərbaycanca] \n* [বাংলা] \n* [Català] \n* [کوردی] \n* [Deutsch] \n* [Ελληνικά] \n* [English] \n* [Español] \n* [Euskara] \n* [فارسی] \n* [Français] \n* [עברית] \n* [हिन्दी] \n* [Հայերեն] \n* [Bahasa Indonesia] \n* [Íslenska] \n* [日本語] \n* [한국어] \n* [پښتو] \n* [Português] \n* [Русский] \n* [Српски / srpski] \n* [தமிழ்] \n* [Türkçe] \n* [Українська] \n* [Tiếng Việt] \n* [粵語] \n* [IsiZulu] \n[编辑链接] \n维基百科，自由的百科全书|[人工智能] 系列内容|\n[![]] |\n主要目标* [知识表示] \n* [自动规划] （英语：[Automated planning and scheduling] ）\n* [机器学习] \n* [语言处理] \n* [电脑视觉] \n* [机器人学] \n* [强人工智慧] \n* [弱人工智慧] \n* [人工智能对齐] \n|\n实现方式* [符号人工智能] \n* [深度学习] \n* [贝氏网路] \n* [进化算法] \n* [混合智能系统] \n* [混合专家模型] \n* [生成式人工智慧] \n* [代理式人工智能] （英语：[Agentic AI] ）\n|\n[人工智能哲学] \n* [伦理] （英语：[Ethics of artificial intelligence] ）\n* [人工智能安全] （英语：[AI safety] ）\n* [幻觉] \n* [存在风险] （英语：[Existential risk from artificial general intelligence] ）\n* [图灵测试] \n* [中文房间] \n* [可解释人工智慧] \n* [友好的人工智能] （英语：[Friendly artificial intelligence] ）\n* [人工智能监管] （英语：[Regulation of artificial intelligence] ）\n|\n历史* [时间轴] （英语：[Timeline of artificial intelligence] ）\n* [发展] （英语：[Progress in artificial intelligence] ）\n* [专家系统] \n* [人工智慧低谷] \n* [人工智能热潮] \n* [人工智能法案] \n|\n[人工智能的应用] \n* [应用] \n* [AlphaFold] \n* [深度伪造] \n* [AI艺术] \n* [音乐] \n* [医疗保健] \n* [工业] \n* [机器翻译] \n* [军事] \n* [项目] （英语：[List of artificial intelligence projects] ）\n* [编程语言] （英语：[List of programming languages for artificial intelligence] ）\n|\n主题与列表* [主题] \n* [术语表] \n* [AI概述] \n* [AI公司列表] （英语：[List of artificial intelligence companies] ）\n* [AI项目列表] （英语：[List of artificial intelligence projects] ）\n|\n* [查] \n* [论] \n* [编] \n|\n参见：[人工智能发展年表] （英语：[Timeline of artificial intelligence] ）\n**人工智能的历史**源远流长。在古代的[神话] [传说] 中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[&#91;1&#93;] 现代意义上的[AI] 始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑] 的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，[人工智能] 的研究领域确立于在[达特茅斯学院] 举行的[会议] 。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[&#91;2&#93;] 他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮] （也被称作AI之冬）。由于[詹姆斯·莱特希尔] 爵士的批评和国会方面的压力，[美国] 和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[&#91;3&#93;] \n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平] 的机器至今仍未出现。[图灵] 在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[&#91;4&#93;] \n在21世纪的第一个十年，[机器学习] 得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n|[计算历史] （英语：[History of computing] ）|\n[硬件] |\n* [1960年代之前] \n* [1960年代至今] （英语：[History of computing hardware (1960s–present)] ）|\n[软件] |\n* [软体] （英语：[History of software] ）\n* [Unix] （英语：[History of Unix] ）\n* [自由和开源软件] （英语：[History of free and open-source software] ）|\n[计算机科学] |\n* 人工智能* [编译器构造] （英语：[History of compiler construction] ）\n* [计算机科学] （英语：[History of computing] ）\n* [操作系统] \n* [程式语言] \n* [杰出先驱者] （英语：[List of pioneers in computer science] ）\n* [软体工程] （英语：[History of software engineering] ）|\n现代概念|\n* [通用CPU] （英语：[History of general-purpose CPUs] ）\n* [图形用户界面] \n* [互联网] \n* [个人电脑] （英语：[History of personal computers] ）\n* [笔记型电脑] （英语：[History of laptops] ）\n* [电子游戏] \n* [全球资讯网] （英语：[History of the World Wide Web] ）|\n按国家|\n* [保加利亚] （英语：[History of computer hardware in Bulgaria] ）\n* [波兰] （英语：[History of computing in Poland] ）\n* [罗马尼亚] （英语：[History of computing in Romania] ）\n* [苏联集团国家] （英语：[History of computer hardware in Soviet Bloc countries] ）\n* [苏联] （英语：[History of computing in the Soviet Union] ）\n* [南斯拉夫] （英语：[History of computer hardware in Yugoslavia] ）|\n[计算年表] （英语：[Timeline of computing] ）|\n* [1950年之前] （英语：[Timeline of computing hardware before 1950] ）\n* [1950–1979] （英语：[Timeline of computing 1950–1979] ）\n* [1980–1989] （英语：[Timeline of computing 1980–1989] ）\n* [1990–1999] （英语：[Timeline of computing 1990–1999] ）\n* [2000–2009] （英语：[Timeline of computing 2000–2009] ）\n* [2010–2019] （英语：[Timeline of computing 2010–2019] ）\n* [更多年表……] |\n[计算机科学词汇] （英语：[Glossary of computer science] ）|\n* ![分类] [分类] |\n* [查] \n* [论] \n* [编] \n|\n## 先驱[[编辑]]\n奥特曼写道[&#91;1&#93;] ：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机] ）的实践之中。[&#91;5&#93;] \n### 神话，幻想和预言中的AI\n[[编辑]]\n[希腊神话] 中已经出现了机械人和人造人，如[赫淮斯托斯] 的黄金机器人和[皮格马利翁] 的[伽拉忒亚] 。[&#91;6&#93;] 中世纪出现了使用巫术或[炼金术] 将意识赋予无生命物质的传说，如[贾比尔] 的*Takwin*，[帕拉塞尔苏斯] 的[何蒙库鲁兹] 和Judah Loew的[魔像] 。[&#91;7&#93;] 19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱] 的《[弗兰肯斯坦] 》和[卡雷尔·恰佩克] 的《罗素姆的万能机器人》。[&#91;8&#93;] Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[&#91;9&#93;] 至今人工智能仍然是科幻小说的重要元素。\n### 自动人偶[[编辑]]\n主条目：[自动机] \n[![]] [加扎利] 的可编程自动人偶（1206年）\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师] （中国西周）[&#91;10&#93;] ，[希罗] （希腊）[&#91;11&#93;] ，[加扎利] [&#91;12&#93;] 和Wolfgang von Kempelen[&#91;13&#93;] 等等。已知最古老的“机器人”是[古埃及] 和[古希腊] 的[圣像] ，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯] （[赫耳墨斯·特里斯墨吉斯忒斯] ）写道“当发现神的本性时，人就能够重现他”[&#91;14&#93;] [&#91;15&#93;] 。\n### 形式推理[[编辑]]\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德] （对三段论逻辑进行了形式分析），[欧几里得] （其著作《[几何原本] 》是形式推理的典范），[花剌子密] （代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉] 和[邓斯·司各脱] 。[&#91;16&#93;] \n[马略卡] 哲学家[拉蒙·柳利] （1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[&#91;17&#93;] 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[&#91;18&#93;] Llull的工作对[莱布尼兹] 产生了很大影响，后者进一步发展了他的思想。[&#91;19&#93;] \n[![]] [莱布尼兹] 猜测人类的思想可以简化为机械计算\n在17世纪中，[莱布尼兹] ，[托马斯·霍布斯] 和[笛卡儿] 尝试将理性的思考系统化为代数学或几何学那样的体系。[&#91;20&#93;] 霍布斯在其著作《[利维坦] 》中有一句名言：“推理就是计算（reason is nothing but reckoning）。”[&#91;21&#93;] 莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字] ），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[&#91;22&#93;] 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，[数理逻辑] 研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔] 的《思维的定律》与[弗雷格] 的《[概念文字] 》。基于弗雷格的系统，[罗素] 和[怀特海] 在他们于1913年出版的巨著《[数学原理] 》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特] ，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?”[&#91;16&#93;] 这个问题的最终回答由[哥德尔不完备定理] ，[图灵机] 和[Alonzo Church] 的[λ演算] 给出。[&#91;16&#93;] [&#91;23&#93;] 他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n[![]] 在摩尔学校的电气工程的ENIAC计算机\n[邱奇-图灵论题] 暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机] ：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[&#91;16&#93;] [&#91;24&#93;] \n### 计算机科学[[编辑]]\n主条目：[计算机硬体历史] \n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇] 设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝] 预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[&#91;25&#93;] （她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数] 的方法。）\n第一批现代计算机是[二战] 期间建造的大型译码机（包括Z3，[ENIAC] 和Colossus等）。[&#91;26&#93;] 后两个机器的理论基础是[图灵] 和[约翰·冯·诺伊曼] 提出和发展的学说。[&#91;27&#93;] \n## 人工智能的诞生：1943 - 1956\n[[编辑]]\n[&#91;28&#93;] 在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n### 控制论与早期神经网络[[编辑]]\n[![]] IBM 702：第一代AI研究者使用的电脑\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳] 的[控制论] 描述了电子网络的控制和稳定性。[克劳德·香农] 提出的[信息论] 则描述了[数字信号] （即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[&#91;29&#93;] \n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[&#91;30&#93;] \nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。', 'doi': '', 'published_date': '2026-02-02T20:25:02.972652', 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI 简史：从神经元到现代大模型 - CSDN博客', 'authors': [], 'abstract': '# AI 简史：从神经元到现代大模型\n\n原创已于\xa02024-12-25 16:28:52\xa0修改·1.4w 阅读\n\n·46\n\n·86\n·\n\nCC 4.0 BY-SA版权\n\n版权声明：本文为博主原创文章，遵循 [CC 4.0 BY-NC-SA] 版权协议，转载请附上原文出处链接和本声明。\n\n文章标签：\n\n[#深度学习] [#人工智能] [#ai] [#神经网络] [#transformer] [#卷积神经网络] [#机器学习] \n\n于\xa02024-12-25 10:54:28\xa0首次发布\n\n[生成AI专栏收录该内容] \n\n45 篇文章\n\n订阅专栏\n\n## AI 简史：从神经元到现代大模型\n\n人工智能 (AI) 和深度学习 (DL) 在过去的几十年中飞速发展，推动了计算机视觉、自然语言处理和机器人等领域的进步。今年的诺贝尔物理学奖更是颁给了美国科学家约翰·霍普菲尔德 (John Hopfield）和英国科学家杰弗里·辛顿（Geoffrey Hinton），表彰他们“在人工神经网络机器学习方面的基础性发现和发明”。本文将为大家概述 AI 的发展历程，梳理出从早期神经网络模型到现代大型语言模型发展过程中的重要里程碑。\n\n图 1\\. AI 发展全景图\n\n#### 文章目录\n\n- [1\\. 人工智能诞生 (1956)] \n- [2\\. AI 的演进：从基于规则的系统到深度神经网络] \n- [3\\. 早期人工神经网络 (1940s – 1960s)] \n - [3.1 McCulloch-Pitts 神经元 (1943)] \n - [3.2 Rosenblatt 感知机模型 (1957)] \n - [3.3 ADALINE (1959)] \n - [3.4 异或（XOR）问题 (1969)] \n- [4\\. 多层感知机 (1960)] \n - [4.1 隐藏层 (Hidden Layers)] \n - [4.2 多层感知机的历史背景与挑战] \n- [5\\. 反向传播 (1970s – 1980s)] \n - [5.1 早期发展 (1970 年代)] \n - [5.2 强化与普及（1980 年代）] \n - [5.3 通用逼近定理 (1989)] \n - [5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)] \n - [5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)] \n - [深度学习的复兴 (2000 年代末 – 现在)] \n- [6\\. 卷积神经网络 (1980s – 2010s)] \n - [6.1 早期发展 (1980 – 1998)] \n - [6.2 CNN 的崛起：AlexNet (2012)] \n - [6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）] \n - [6.4 后续架构改进] \n - [6.5 CNN 的应用] \n- [7\\. 循环神经网络 (1986 – 2017)] \n - [7.1 早期发展 (1980s – 1990s)] \n - [7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)] \n - [7.3 RNN 的应用] \n - [7.4 RNN 的挑战] \n- [8\\. Transformer (2017 – 现在)] \n - [8.1 Transformer 简介] \n - [8.2 Transformer 的衍生模型] \n - [8.3 OpenAI GPT 的发展历程] \n - [8.4 其他知名大语言模型] \n- [9\\. 多模态模型 (2023 – 现在)] \n - [9.1 GPT-4V (2023) 和 GPT-4o (2024)] \n - [9.2 Google’s Gemini (2023 – 现在)] \n - [9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)] \n - [9.4 LLaVA (2023)] \n- [10\\. 扩散模型 (2015 – 现在)] \n - [10.1 扩散模型简介 (2015)] \n - [10.2 扩散模型的发展 (2020 – 现在)] \n - [10.3 文生图模型] \n - [10.4 文生视频模型] \n- [11\\. 尾声] \n\n### 1\\. 人工智能诞生 (1956)\n\n人工智能（AI）的概念由来已久，但现代 AI 的雏形是在 20 世纪中期逐渐形成的。“人工智能”这个术语是由计算机科学家和认知科学家约翰·麦卡锡 (John McCarthy) 在 1956 年召开的达特茅斯人工智能夏季研讨项目上首次提出并被大家接受，AI 从此走上历史舞台。\n\n图 2.\n[A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence] (1955)\n\n达特茅斯会议通常被视为 AI 研究的发源地。这次会议汇聚了计算机科学家、数学家和认知科学家，共同探讨创造能够模拟人类智能的机器的可能性。与会者中大佬云集，包括：\n\n- **约翰·麦卡锡 (John McCarthy)** ：计算机科学家、Lisp 编程语言发明人之一。\n\n- **马文·明斯基 (Marvin Minsky)**：计算机科学家、框架理论的创立者。\n\n- **雷·索洛莫诺夫 (Ray Solomonoff)**：算法概率论创始人，通用概率分布之父，通用归纳推理理论的创建者。\n\n- **纳撒尼尔·罗切斯特 (Nathaniel Rochester)** ：IBM 701 的首席设计师，编写了世界上第一个汇编程序。\n\n- **克劳德·香农 (Claude Shannon)** ：数学家、发明家、密码学家，信息论创始人。\n\n- **奥利弗·塞弗里奇 (Oliver Selfridge)**：模式识别的奠基人、人工智能的先驱，被誉为“机器知觉之父”。\n\n\n图 3\\. 参加达特茅斯会议的部分重量级人物\n\n达特茅斯会议对计算机科学的发展产生了深远的影响，它为计算机科学的发展指明了方向，推动了计算机科学的快速发展。会议的成果为后来的计算机科学研究提供了重要的思想和方法支持，为计算机科学的教育和培训提供了重要的参考。达特茅斯会议也为跨学科合作和交流提供了一个成功的范例，为后来的跨学科研究提供了重要的经验和启示。\n\n### 2\\. AI 的演进：从基于规则的系统到深度神经网络\n\n纵观整个 AI 的发展史，有一条清晰的发展脉络，那就是从基于规则的系统向深度神经网络的不断进化。\n\n人工智能 (AI) 的发展始于上个世纪 50 年代，那时人们开始开发用于国际象棋和问题求解的算法。第一个 AI 程序 Logical Theorist 于 1956 年诞生。到了 1960 和 1970 年代，基于规则的专家系统如 MYCIN 被引入，它们可以帮助进行复杂的决策。1980 年代，机器学习开始兴起，使 AI 系统能够从数据中学习并不断改进，为现代深度学习技术奠定了基础。\n\n今天，大多数最前沿的 AI 技术都由深度学习驱动，深刻改变了 AI 的发展格局。深度学习是机器学习的一个独立分支，它通过多层人工神经网络从原始数据中提取复杂特征。在本文中，我们将探讨 AI 的发展历史，并重点介绍深度学习在其中的关键作用。\n\n图 4\\. 人工智能、机器学习、神经网络、深度学习之间的关系\n\n### 3\\. 早期人工神经网络 (1940s – 1960s)\n\n#### 3.1 McCulloch-Pitts 神经元 (1943)\n\n神经网络的概念可以追溯到 1943 年，当时 Warren McCulloch 和 Walter Pitts 提出了第一个人工神经元模型。McCulloch-Pitts (MP) 神经元模型是对生物神经元的一种突破性简化。这个模型通过聚合二进制输入，并利用阈值激活函数来做出决策，从而为人工神经网络奠定了基础，输出结果为二进制 {\n0\n,\n1\n}\n\\\\{0, 1\\\\}\n{0,1}。\n\n图 5\\. 人工神经元的结构与原理\n\n这种简化的模型抓住了神经元行为的核心特征——接收多个输入，整合这些输入，并根据是否超过阈值来产生二进制输出。尽管MP神经元模型非常简单，但它能够实现基本的逻辑运算，展示了神经计算的潜力。\n\n#### 3.2 Rosenblatt 感知机模型 (1957)\n\nFrank Rosenblatt 在 1957 年引入了感知机，这是一种能够学习和识别模式的单层神经网络。感知机模型比 MP 神经元更为通用，设计用于处理实数值输入，并通过调整权重来最小化分类错误。\n\n图 6\\. 感知机模型\n\nRosenblatt 还为感知机开发了一种监督学习算法，使得网络能够直接从训练数据中进行学习。 L\n(\nW\n)\n=\n−\n∑\ni\n∈\nM\nW\nT\nX\ni\ny\ni\n\\\\mathcal{L}(W) = - \\\\sum\\_{i \\\\in M} W^T X\\_i y\\_i\nL(W)=−i∈M∑\u200bWTXi\u200byi\u200b\n\n图 7\\. Mark I 感知机，是一台实现了图像识别感知机算法的机器\n\nRosenblatt 的感知机展示出识别个人和在不同语言间翻译语音的潜力，这在当时引发了公众对 AI 的极大兴趣。感知机模型及其相关的学习算法成为神经网络发展历程中的重要里程碑。然而，很快就显现出一个关键限制：当训练数据是非线性可分时，感知机的学习规则无法收敛。\n\n#### 3.3 ADALINE (1959)\n\nWidrow 和 Hoff 在 1959 年引入了 ADALINE（自适应线性神经元，也称 Delta 学习规则），对感知机学习规则进行了改进。ADALINE 解决了二进制输出和噪声敏感性等限制，并能够学习并收敛非线性可分的数据，这是神经网络发展中的一大突破。\n\n图 8\\. ADALINE VS. 感知机\n\nADALINE 的主要特点包括：\n\n- **线性激活函数**：不同于感知器的阶跃函数，ADALINE 使用线性激活函数，因此适用于回归任务和连续输出。\n- **最小均方（LMS）算法**：ADALINE 采用 LMS 算法，该算法通过最小化预测输出与实际输出之间的均方误差，提供更高效和稳定的学习过程。\n- **自适应权重**：LMS 算法根据输出误差自适应调整权重，使 ADALINE 即使在有噪声的情况下也能有效地学习和收敛。\n\n**ADALINE 的引入标志着神经网络第一次黄金时代的开始**，它克服了 Rosenblatt 感知机学习的限制。这一突破实现了高效学习、连续输出和对噪声数据的适应能力，推动了该领域的创新和快速发展。\n\n图 9\\. ADALINE 开启了神经网络第一次黄金时代\n\n然而，与感知机类似，ADALINE 仍然无法解决线性可分的问题，无法应对更复杂的非线性任务。这一局限集中体现在异或（XOR）问题上，也促进了更高级神经网络架构的发展。\n\n#### 3.4 异或（XOR）问题 (1969)\n\n1969年，Marvin Minsky 和 Seymour Papert 在他们的著作《Perceptrons》中揭示了单层感知机的一个重要局限：由于其线性决策边界，感知机无法解决异或 (XOR) 问题，而这是一个简单的二元分类任务。异或问题不是线性可分的，也就是说，没有一个单一的线性边界能够正确地将所有的输入模式分类。\n\n图 10\\. Marvin Minsky 和 Seymour Papert 合著的《Perceptrons: An introduction to computational geometry》\n\n这一发现强调了需要开发更复杂的神经网络架构，以便能够学习非线性的决策边界。感知机的局限性被揭露后，人们对神经网络的信心减弱，转而研究符号人工智能方法， **这标志着从 20 世纪 70 年代初到 80 年代中期的“神经网络的第一次黑暗时代”的开始**。\n\n图 11\\. 异或问题将神经网络代入第一次黑暗时代\n\n然而，研究人员从解决异或问题中获得的见解促使他们意识到需要更复杂的模型来捕捉非线性关系。这种认识最终推动了多层感知机和其他先进神经网络模型的发展，为神经网络和深度学习在后来的复兴奠定了基础。\n\n### 4\\. 多层感知机 (1960)\n\n多层感知机 (MLP) 最早于 20 世纪 60 年代提出，作为对单层感知机的改进。MLP 由多个层次的相互连接的神经元组成，能够克服单层模型的局限性。苏联科学家 A. G. Ivakhnenko 和 V. Lapa 在感知机基础上进行研究，对多层感知机的发展中做出了重要贡献。\n\n图 12\\. 多层感知机模型\n\n#### 4.1 隐藏层 (Hidden Layers)\n\n增加隐藏层使得 MLP (多层感知器) 可以捕捉和表达数据中的复杂非线性关系。这些隐藏层极大地增强了网络的学习能力，使其能够解决诸如异或问题这样非线性可分的问题。\n\n图 13\\. 隐藏层解决异或问题\n\n#### 4.2 多层感知机的历史背景与挑战\n\nMLP 的出现标志着神经网络的研究向前迈出了重大一步，展示了深度学习架构在解决复杂问题方面的潜力。然而，在 1960 年代和 1970 年代，MLP 的发展面临若干挑战：\n\n- **缺乏训练算法**：早期的 MLP 模型缺乏高效的训练算法，无法有效地调整网络权重。此时反向传播算法还未诞生，训练多层深度网络非常困难。\n- **算力限制**：当时的算力不足以应对训练深度神经网络所需的复杂计算。这一限制拖慢了 MLP 的研究和发展进程。\n\n神经网络的第一个黑暗时代在 1986 年结束， **随着反向传播算法的诞生，开启了神经网络的第二个黄金时代**。\n\n### 5\\. 反向传播 (1970s – 1980s)\n\n1969 年，异或问题揭示了感知机（单层神经网络）的局限性。研究人员意识到，多层神经网络能够克服这些限制，但缺乏有效的训练算法。17年后，反向传播算法的开发使得神经网络在理论上可以逼近任何函数。值得注意的是，该算法实际上在发表之前就已被发明。如今，反向传播已成为深度学习的核心组件，自 20 世纪 60 年代和70 年代以来经历了显著的发展和完善。\n\n图 14\\. 反向传播原理示意图\n\n反向传播的关键特性：\n\n- **梯度下降**：反向传播与梯度下降联合使用以降低误差函数。该算法计算每个权重相对于误差的梯度，从而逐步调整权重以减少误差。\n- **链式法则**：反向传播算法的核心在于应用微积分的链式法则。此法则使得误差的梯度可以被分解为一系列偏导数，并通过网络的反向传递高效计算。\n- **分层计算**：反向传播逐层运作，从输出层向输入层反向传递。这种分层计算确保梯度在网络中正确传播，使得深度架构的训练成为可能。\n\n#### 5.1 早期发展 (1970 年代)\n\n- **Seppo Linnainmaa (1970)**: 提出了自动微分的概念，这是反向传播算法的重要组成部分。\n- **Paul Werbos (1974)**: 提议使用微积分的链式法则计算误差函数对网络权重的梯度，从而能够训练多层神经网络。\n\n#### 5.2 强化与普及（1980 年代）\n\n- **David Rumelhart, Geoffrey Hinton 和 Ronald Williams (1986)**: 将 **反向传播** 这一高效实用的方法，用于训练深度神经网络，并展示了其在多种问题中的应用。\n\n图 15\\. 反向传播算法的三位主要贡献者\n\n其中 Geoffrey Hinton 因其在人工神经网络和机器学习领域的贡献获得了 2018 年图灵奖和 2024 诺贝尔物理学奖，称为继 Herbert Simon 后第二位图灵奖-诺贝尔奖双料得主。\n\n#### 5.3 通用逼近定理 (1989)\n\nGeorge Cybenko 在 1989 年提出的通用逼近定理，为多层神经网络的功能提供了数学基础。该定理表明，只要神经元数量足够，并且使用非线性激活函数，具有单个隐藏层的前馈神经网络就能够以任意精度逼近任意连续函数。这个定理突显了神经网络的强大能力和灵活性，使其能够应用于各种领域。\n\n图 16\\. 具有单个隐藏层的神经网络可以将任意连续函数逼近到任意所需的精度，从而在各个领域解决复杂的问题\n\n#### 5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)\n\n\\*\\*反向传播算法的出现和通用逼近定理的提出，开启了神经网络研究的第二个黄金时代。\\*\\*反向传播提供了一种高效的多层神经网络训练方法，使研究人员能够构建更深层次和更复杂的模型。通用逼近定理则为使用多层神经网络提供了理论支持，并增强了人们对其解决复杂问题能力的信心。在 1980 年代末至 1990 年代初，这一时期见证了对神经网络领域的兴趣回升和显著的进步。\n\n图 17\\. 反向传播和通用逼近定理开启了神经网络研究的第二个黄金时代\n\n#### 5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)\n\n然而，由于一系列因素，神经网络领域在 1990 年代初至 2000 年代初经历了“第二个黑暗时代”：\n\n- **支持向量机 (SVM) 的兴起**：支持向量机为分类和回归任务提供了更优雅的数学方法。\n- **算力限制**：由于训练深度神经网络仍然耗时且对硬件要求高，计算能力受到限制。\n- **过拟合和泛化问题**：这两个问题导致早期神经网络在训练数据上表现良好，但在新数据上表现不佳，限制了其实用性。\n\n这些挑战使得许多研究人员转而关注其他领域，导致神经网络研究的停滞。\n\n图 18\\. 随着 SVM 的兴起，神经网络进入第二个黑暗时代\n\n#### 深度学习的复兴 (2000 年代末 – 现在)\n\n在 2000 年代末和 2010 年代初，神经网络领域经历了复兴，这得益于以下方面的进步：\n\n- **深度学习架构的发展**（如 CNNs、RNNs、Transformers、Diffusion Models）\n- **硬件的改进**（如 GPUs、TPUs、LPUs）\n- **大规模数据集的可用性**（如 ImageNet、COCO、OpenWebText、WikiText 等）\n- **训练算法的优化**（如 SGD、Adam、dropout）\n\n这些进展带来了计算机视觉、自然语言处理、语音识别和强化学习的重大突破。通用逼近定理与实际技术的进步相结合，为深度学习技术的广泛应用和成功奠定了基础。\n\n### 6\\. 卷积神经网络 (1980s – 2010s)\n\n卷积神经网络 (CNN) 在深度学习领域，尤其是计算机视觉和图像处理方面，带来了革命性的变化。从上个世纪 80 年代到本世纪最初的 10 年，CNN 在架构、训练技术和应用等方面取得了显著的进步。\n\n卷积神经网络由以下三个主要组件构成：\n\n- **卷积层 (Convolutional Layers)**：这些层通过一组可调整的滤波器，从输入图像中自动学习和提取特征的空间层次结构。\n- **池化层 (Pooling Layers)**：池化层通过缩小输入的空间尺寸，来提高对输入变化的适应性，并减少计算量。\n- **全连接层 (Fully Connected Layers)**：在卷积层和池化层之后，全连接层用于分类任务，负责整合之前层中提取的特征。\n\n卷积神经网络的主要特性\n\n- **局部感受野**：CNN 利用局部感受野来捕捉输入数据中的局部特征，使其在处理图像和其他视觉任务时表现出色。\n- **权重共享**：通过在卷积层中共享权重，CNN 能够减少网络中参数的数量，从而提高训练效率。\n- **平移不变性**：池化层赋予网络平移不变性，使其能够识别输入图像中不同位置的相同模式。\n\n#### 6.1 早期发展 (1980 – 1998)\n\n1980 年代，福岛邦彦 (Kunihiko Fukushima) 首次提出了 CNN 的概念，他设计了一种称为神经认知机 (Neocognitron) 的分层神经网络，这种网络模仿了人类视觉皮层的结构。这项开创性的研究为之后 CNN 的发展奠定了基础。\n\n图 19\\. 福岛邦彦与他的神经认知机\n\n到了 1980 年代末和 1990 年代初，Yann LeCun 和他的团队在此基础上进一步发展了 CNN，并推出了 LeNet-5 架构，该架构专为手写数字识别而设计。\n\n图 20\\. Yann LeCun 与他的 LeNet-5\n\n#### 6.2 CNN 的崛起：AlexNet (2012)\n\n2012 年，AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了重大胜利，这是 CNN 发展中的一个重要里程碑。这次胜利不仅以压倒性优势赢得了比赛，也在图像分类领域取得了重大突破。\n\n图 21\\. ILSVRC 历年冠军及其表现\n\nILSVRC 是一个年度图像识别基准测试，用于评估算法在一个包含 1000 万多张注释图像的数据集上的表现，这些图像被划分为 1000 个类别。AlexNet 的创新之处包括：\n\n- **ReLU 激活函数**：为解决传统激活函数的问题而引入，ReLU 提高了训练速度并改善了性能。\n- **Dropout 正则化**：这种技术通过在训练过程中随机丢弃神经元来减少过拟合现象。\n- **数据增强**：通过人为增加训练数据的多样性，增强了数据集的丰富性，从而改善了模型的泛化能力。\n\nAlexNet 的成功成为 CNN 发展中的一个转折点，为图像分类和物体检测的进一步发展奠定了基础。\n\n图 22\\. AlexNet 架构\n\n#### 6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）\n\n自 2010 年代直至今天，当前的科技发展黄金时代以深度学习、大数据和强大计算平台的结合为特征。在这一时期，图像识别、自然语言处理和机器人技术等领域取得了显著的突破。持续的研究不断推动着人工智能（AI）能力的边界。\n\n图 23\\. AlexNet 开启神经网络的第三次黄金时代\n\n#### 6.4 后续架构改进\n\n继 AlexNet 之后，又相继出现了几个有影响力的架构：\n\n- **VGGNet (2014)**：由牛津大学的视觉几何组开发，VGGNet 强调使用更深的网络架构，并采用较小的卷积滤波器 (\n3\n×\n3\n3 \\\\times 3\n3×3)，从而取得了显著的准确率。\n图 24\\. 原始 VGGNet 架构\n- **GoogLeNet/Inception (2014)**：引入了 inception 模块，使得网络能够以更高效的方式捕捉不同尺度的特征。\n图 25\\. GooLeNet 架构\n- **ResNet (2015)**：', 'doi': '', 'published_date': '2024-12-25T00:00:00+00:00', 'pdf_url': '', 'url': 'https://blog.csdn.net/jarodyv/article/details/144699658', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能简史— 深入浅出PyTorch', 'authors': [], 'abstract': '人工智能简史 &#8212; 深入浅出PyTorch\nToggle navigation sidebar\nToggle in-page Table of Contents\n[# 深入浅出PyTorch\n] \n**\nTheme by the[Executable Book Project] \n**\n**\n**\n* [**repository] \n* [**open issue] \n* [**suggest edit] \n**\n* [**.md] \n* **.pdf\n**\n**Contents\n# 人工智能简史## Contents\n# 人工智能简史[#] \n自从图灵在1950年第一次提出“机器智能（Machine Intelligence）”这个概念以来，人工智能已经经历了七十余年的发展。在这七十多年中，人工智能的发展先后经历了三次浪潮，每一次浪潮对人工智能的发展来说，都是具有里程碑意义的。接下来我们将以这三次浪潮为主线，为大家介绍人工智能的发展历程。除此之外，我们也将会给大家介绍现在常说的Deep learning，Machine Learning和AI之间的关系。\n[\\* ]通过本章学习，你将收获：\n* 了解人工智能的三次浪潮* 了解Deep learning，Machine learning和AI之间的关系\n## 1.1 人工智能的三次浪潮[#] \n### 1.1.1 第一次浪潮[#] \n1950年，阿兰·图灵发表著名论文《计算机器与智能》，在这篇论文中，他提出了机器思维的概念和图灵测试，标志着“机器的智能化”正式进入人类的科技树。在此之后的数年间，机器智能有了进一步的发展。两年后的1952年，计算机科学家阿瑟·萨缪尔开发出一款跳棋程序，并提出了“机器学习”这个概念。在此之后的4年里，机器智能化也取得了一定的进步，直到1956年的达特茅斯会议上，约翰·麦卡锡正式提出了“人工智能”这个词语，1956年，也就成为了实际意义上的人工智能元年。\n达特茅斯会议之后，人工智能进入了一个高速发展的时期，也就是所谓的“第一次浪潮”。这次浪潮一直持续到二十世纪六十年代中期。在这近10年的时间里，计算机本身的“智能”并没有得到发展，快速进步的是人工智能的一些理论与算法方面。很多对后来人工智能发展起到奠基作用的算法——如罗森布拉特在1957年发明感知机——就是在这个时间段诞生的。感知机是机器学习人工神经网络理论中神经元的最早模型，这一模型也使得人工神经网络理论得到了巨大的突破。除此之外，强化学习的雏形也是在那段时间提出的。彼时的科学界都弥漫着快乐的气氛，大家都认为，只要坚持走下去，人工智能就一定会得到跨越式的发展。但事与愿违，不久后人工智能的第一次寒冬（AI Winter）就到来了。\n1966年前后，AI遭遇了瓶颈。人们发现逻辑证明器、感知器、强化学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。研究者们很快就意识到，要求程序对这个世界具有儿童水平的认识这个要求都太高了——那时没人能够做出人工智能需要的巨大数据库，也没人知道一个程序怎样才能学到如此丰富的信息。另一方面，有很多计算复杂度以指数程度增加，这成为了不可能完成的计算任务。\n可以说，人工智能的第一次浪潮在发展到“非智能对话机器”的智能化初级阶段时，就因为当时的技术限制不得不停摆。人工智能的发展似乎陷入了一个无解的“死胡同”里，并被计算机科学家们逐渐冷落。### 1.1.2 第二次浪潮[#] \n时间来到了20世纪80年代。经过了数十年的研究，科学家们逐渐放弃了初代的符号学派思路，改用统计学的思路来研究人工智能。研究思路的改变再加上硬件技术的升级，人工智能的发展又一次迎来的新的契机。在那个时代，基于人工智能的“专家系统”受到了绝对的热捧。特定领域的“专家系统”程序被更广泛的采纳，该系统能够根据领域内的专业知识，推理出专业问题的答案，人工智能也由此变得更加“实用”，专家系统所依赖的知识库系统和知识工程成为了当时主要的研究方向。\n但由于专家系统仅适用于某些特定场景，很快人们就对这一系统由狂热的追捧逐渐走向巨大的失望。与此同时，现代电子计算机的出现让“知识查询”的费用进一步降低，人们更加深刻的意识到专家系统是如此的古老陈旧。因此，政府部门下调了专家系统的研发资金。缺少了资金的支持，由专家系统再次兴起的人工智能研究又一次陷入了低谷之中。虽然第二次浪潮持续的时间比较短，但它在整个人工智能发展历史中仍然起到了举足轻重的作用。它彻底改变了人工智能研究的大思路，将统计学思想引入研究之中，为人工智能在未来几十年的发展打下了基础。除此之外，在这次浪潮中提出的BP神经网络，为之后机器感知、交互的能力奠定了基础。\n### 1.1.3 第三次浪潮[#] \n1993年后，新的数学工具，理论和摩尔定律的出现，使得计算机的算力进一步提高，以深度学习为核心的机器学习算法获得发展，新的芯片和云计算的发展使得可用的计算能力获得飞跃式提高，大数据的发展使得海量数据的储存和分析成为可能。在这样的技术背景下，人工智能的第三次浪潮即将到来。\n人工智能的第三次浪潮有两个重要的时间节点：2006年和2016年。2006年是深度学习发展史的分水岭。杰弗里辛顿在这一年发表了《一种深度置信网络的快速学习算法》，其他重要的深度学习学术文章也在这一年被发布，在基本理论层面取得了若干重大突破。而2016年3月，谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭，“人工智能”一词正式进入普通民众的视野并被逐渐熟知。至此，人工智能正式迈向了从“科研领域的应用型工具”到“实用性，功能性工具”的转变，人工智能有了新的研究方向和研究模式，即从过去的学术主导型研究逐渐走向了商业主导型研究。随着人类社会对智能化工具的不断追求和探索，人工智能的发展迎来了全新的时代。\n### 1.1.4 总结[#] \n![] \n上图是对人工智能发展中经历的三次浪潮和两次寒冬的形象总结。除此之外，有观点认为，深度学习算法带来的“技术红利”，将支撑我们再发展5\\~10年时间，随后就会遇到瓶颈。人工智能不是一个简单的从1到100进步的过程，它往往趋向于两个极端：要么90分以上，其它的都是10分以下。目前，人工智能急需寻找到一个“技术奇点”，让人工智能迅速发展到通用人工智能甚至是超级人工智能的水平。否则，在人工智能研究商业化的今天，无法从中获利的投资人们将快速撤资退场，人工智能或将进入下一个寒冬。\n## 1.2 DL,ML,AI三者之间的关系[#] \n大家对“人工智能”这个词，也就是我们所谓的“AI”（Artificial Intelligence）想必是非常熟悉，无论是近几年各行各业都喜欢用作营销噱头的“智能化”还是早期电影如《黑客帝国》、《终结者》等，都让AI这个概念深入人心。但近几年，另外两个词语也在逐步进入我们的生活，即就是“机器学习（Machine Learning，ML）”和“深度学习（Deep Learning，DL）”。在接下来的叙述中，我们就将了解DL和ML究竟是什么，以及它们和AI之间的关系。\n### 1.2.1 DL和ML是什么[#] \nMachine Learning（机器学习）。它在1959年被机器学习的先驱者之一的阿瑟·塞缪尔定义为：一门研究领域，它赋予计算机无需明确编程就能学习的能力。也就是说，机器学习程序不同于传统编程那样，使用if-then语句那样明确地输入到计算机中以便它根据条件执行。在某种意义上，机器学习程序赋予机器根据所接触到的数据进行自我调整的能力。机器学习更像是一种优化算法，如果我们在事先就对它进行了正确的调整，那么它就会在一遍又一遍的尝试和猜测之中不断减少它的错误，以无限逼近于最终的正确结果。而机器学习的基本思路，也就是将现实问题抽象成为一个数学问题，机器通过训练，寻找到解决数学问题的方法，进而解决现实问题。\nDeep Learning（深度学习）。它在2006年被提出，并在近些年得到了迅速的发展。它通过建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据。李开复教授在《人工智能》一书中这样解释深度学习：“假设深度学习要处理的信息是“水流”，而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。网络的入口是若干管道开口，网络的出口也是若干管道开口。这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节阀的总数可以成千上万甚至更多。水管网络中，每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来，组成一个从前到后，逐层完全连通的水流系统。”\n### 1.2.2 它们和AI的关系[#] \n众所周知，人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。既然如此，那么计算器算是人工智能吗？严格地说是算的，因为它至少做了“模拟”人在计算方面的智能，并扩展了这个能力（比人算得更快）。我们通过代码驱动计算机去帮我们干活，这个算是人工智能吗？也算的。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，说白了，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。\n随着人对计算机的期望越来越高，要求它解决的问题越来越复杂，仅仅算的更快，看的更准已经远远不能满足人们的诉求了。要解决的问题域越来越复杂，即使是同一个问题，其面对的场景也越来越多。传统的思路就是查找问题的条件和解决方法，在计算机程序中再加入一个if-then。但这只是治标不治本。随着我们期待解决的问题越来越多，计算机程序将越来越复杂，越来越难以维护。那怎么办呢？于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n至此，“机器学习”的概念，正式诞生。机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器自行学会如何执行任务。说白了，机器学习只是人们实现让机器“模拟、延伸和扩展人的智能”的一种较为轻松的方法罢了。它的成功与否取决于我们喂给机器的数据集是否准确且有效。因此，机器学习是大数据技术领域内的一个应用，人们只是借用这个应用，来发展人工智能罢了。机器学习发展了几十年之后，再次遇到了瓶颈期。随着问题场景的更加复杂多变，需要进行判断的条件更加苛刻，人们不得不重新思考一种方式来优化机器学习。深度学习就是带着这个目的被提出的。机器学习中有一个概念叫“神经网络”，深度学习正是通过优化这个网络来更好的解决通过机器学习难以解决的问题。它的基本特点，就是试图模仿大脑的神经元之间传递，处理信息的模式，通过不同的“层”来拆分问题，每一层解决问题的一个部分。比如在利用深度学习解决智能驾驶问题中，第一层可能用于识别车辆与道路边缘的距离，第二层用于识别道路标线，第三层用于识别路上的其他车辆等等。通过以上几段话的简单描述，DL,ML和AI之间的关系也就明确了。它们三者的关系就像是俄罗斯套娃：AI最大，它的目的是通过让机器模仿人类进而超越人类；ML次之，它是AI的一个分支（也是最重要分支），是让机器模仿人类的一种方法；DL更次之，它是ML的一个分支，它的目的是让机器不借助人工标注，也能自主提取目标特征进而解决问题的一种方法。\n最后，借用一张经典的关系图作为结尾：![]', 'doi': '', 'published_date': '2026-02-02T20:25:02.973010', 'pdf_url': '', 'url': 'https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E9%9B%B6%E7%AB%A0/0.1%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI 有着怎样的发展历程？ - Cloudflare', 'authors': [], 'abstract': 'AI 有着怎样的发展历程？| Cloudflare\n[注册] \n语言* [English] \n* [English (United Kingdom)] \n* [Deutsch] \n* [Español (Latinoamérica)] \n* [Español (España)] \n* [Français] \n* [Italiano] \n* [日本語] \n* [한국어] \n* [Polski] \n* [Português (Brasil)] \n* [Русский] \n* [繁體中文] \n* [简体中文] \n# AI 有着怎样的发展历程？当今最先进的AI 模型建立在几十年前的发现基础之上。AI 的历史可以追溯到第一台数字计算机诞生之前。#### 学习目标阅读本文后，您将能够：* 识别AI 发展的关键进展* 了解Alan Turing、Frank Rosenblatt 和Geoffrey Hinton 等发明家和创新者多年来对AI 发展做出的贡献* 列举促成当今AI 热潮的发展相关内容[\n什么是代理式AI？\n] [\n什么是生成式AI？\n] [\n预测式AI\n] [\n神经网络] [\n什么是人工智能(AI)？\n] \n复制文章链接## AI 有着怎样的发展历程？[人工智能 (AI)] 是指机器（通常特指计算机）模仿人类认知过程、解决问题的能力以及行动能力。如今，AI 涵盖了一系列能力，从[预测式 AI] 和[自然语言处理] ，到[大型语言模型 (LLM)] 和[代理式 AI] 。\n从古代世界的自动机到最早的计算机，这些都是AI 的前身。当今最先进的模型，其基础是几十年前发展起来的理论和算法。## AI 历史上的重大事件：时间线虽然“人工智能”一词最早出现在1955 年，但对AI 发展至关重要的事件却可以追溯到几个世纪以前。#### 20 世纪之前* **大约公元前 400 年：**根据一些古希腊文献记载，阿尔希塔斯 (Archytas of Tarentum) 制作了一只能够拍打翅膀并飞翔的木鸽。* **大约 1495 年：**莱昂纳多•达•芬奇 (Leonardo da Vinci) 绘制了一幅外形类似德国骑士的自动机详细图纸，并且可能已经制造了一台（即便确实如此，这台自动机也无法流传至今）。* **大约 1560 年：**西班牙国王费利佩二世 (Phillip II) 委托钟表匠Juanelo Turriano 模仿方济各会修士Diego de Alcalá（后来被封为圣徒 St. Diego）制作一台自动机。这种自动机由发条驱动，可以模仿人类的基本动作和姿势。\n* **1764 - 1770 年：**名为*Canard Digérateur*（或“消化鸭”）以及 Automaton Chess Player（或“自动行棋的傀儡”）的自动机令公众欣喜。虽然两者后来都被证明是骗局，但它们拓展了人们对自动化可能性的普遍理解。\n* **1822 年：**查尔斯•巴贝奇 (Charles Babbage) 完成了“差分引擎”的研制，这是一种机械计算装置，它是计算机的早期前身。#### 1900 - 1973 年* **1914年：**数学家兼发明家 Leonardo Torres y Quevedo 首次推出了"El Ajedrecista"，这是一款能够自动进行国际象棋对局并在特定情况下击败人类棋手的自动机。\n* **1943 年：**神经生理学家 Warren McCulloch 和数学家Walter Pitts 共同发表了题为《神经活动内在概念的逻辑演算》(A Logical Calculus of the Ideas Imminent in Nervous Activity) 的论文，文中介绍了神经元的数学描述。这篇论文成为了构建[人工神经网络] 的关键一步。\n* **1945 年：**第一台数字计算机 ENIAC 诞生。* **1949 年：**心理专家唐纳德•赫布 (Donald Hebb) 出版了*《行为的组织》*，这本书对神经网络的发展产生了深远的影响。\n* **1950 年：**颇具影响力的数学家和计算机科学家 Alan Turing 发表了《计算机器与智能》(Computing Machinery and Intelligence)，这篇论文探讨了“机器能否思考”的问题。论文描述了著名的“图灵测试”，用于判断计算机智能是否已变得与人类智能无法区分。\n* **1951 年：**Dean Edmunds 和Marvin Minsky 一起建造了随机神经模拟强化计算器(SNARC)，这是世界上第一台神经网络计算机。它只有 40 个神经元。* **1955 年：**在计算机科学家约翰•麦卡锡 (John McCarthy) 主持的一次研讨会上，“人工智能”一词首次出现。* **1957 年：**心理学家兼计算机科学家弗兰克•罗森布拉特 (Frank Rosenblatt) 创建了感知器，这是一种早期的人工神经网络。* **1959 年：**斯坦福大学研究员 Bernard Widrow 和Marcian Hoff 开发了出现实世界中使用的第一个神经网络模型：多自适应线性元素(Madaline)，用于消除电话线路回声。\n* **1966 年：**计算机科学家 Joseph Weizenbaum 发布了ELIZA 程序，这被认为是第一个[聊天机器人] （尽管按照如今的标准，其底层模式匹配算法相当简单）。\n* **1969 年：**Marvin Minsky 和Seymour Papert 出版了*《感知器：计算几何学导论》*(Perceptrons: An Introduction to Computational Geometry)，这本书对感知器提出了质疑（最初由 Frank Rosenblatt 提出）。引人争议的是，书中还论述了感知器的一些局限性，某些研究员后来认为这些局限性削弱了对AI 研究的资助热情。#### AI 的寒冬与复苏：1973 - 2000 年* **1973 年：**第一个“AI 寒冬”开始，英国科学研究委员会的一份报告指出，这一领域的工作未能兑现其承诺，英国削减了对AI 研究的资助。在七十年代这十年的剩余时间里，AI 研究速度放缓。* **1980 年：**人工智能促进协会 (AAAI) 召开了第一次会议。对AI 研究的兴趣开始复苏。* **1982 年：**加州理工学院的 John Hopfield 向美国国家研究院提交了一篇关于在人工神经元之间使用双向连接的论文（以前一直都只使用了单向连接）。此外，日本启动了该国的第五代计算机系统项目(FGCS)，为 AI 研究提供了更多资金。* **1987 年：**第二个 AI 寒冬开始，在此期间，由于研究进展停滞不前，AI 研究的投资极少。* **1995 年：**Richard Wallace 开发了聊天机器人A.L.I.C.E.，它以 20 世纪60 年代的聊天机器人ELIZA 为基础。* **1997 年：**IBM 的超级计算机“深蓝”(Deep Blue) 在六局棋国际象棋比赛中击败了国际象棋大师加里•卡斯帕罗夫(Garry Kasparov)。#### 21 世纪：AI 热潮* **2002 年：**Roomba 机器人发布，这是最早具备完全自主功能的消费产品之一。* **2007 年：**计算机科学家 Geoffrey Hinton 发表了题为“Learning Multiple Layers of Representation”的论文，这是一篇在[深度学习] 方面具有重大意义的论文。\n* **2009 年：**研究员 Rajat Raina、Anand Madhavan 和Andrew Ng 共同发表了题为“Large-scale Deep Unsupervised Learning using Graphics Processors”的论文，文中指出 GPU 在机器学习方面优于CPU。未来几年，向 GPU 转变将会催生出比以往任何时候都更加强大的AI 模型。* **2011 年：**IBM 的自然语言处理器Watson 参加了美国智力竞猜电视节目*《危险边缘》(Jeopardy!)*并获胜。同一年，Apple 推出了首个广受欢迎的虚拟助手Siri。\n* **2012 年：**Google 研究员Jeff Dean 和Andrew Ng 训练一个神经网络，使其能够仅使用未标记的图像识别猫。大约在这个时候，“AI 热潮”开始了。* **2016 年：**Google 计算机程序AlphaGo 在围棋比赛中击败了围棋世界冠军李世石。* **2017 年：**Google 提出了Transformer 神经网络框架，这种架构为[大型语言模型 (LLM)] 的开发铺平了道路。\n* **2020 年：**OpenAI 发布了GPT-3，这是首批 LLM 之一。* **2021 年：**Google 发布了多任务统一模型(MUM)，这是一种由 AI 驱动的搜索算法，能够理解并生成语言。* **2022 年：**ChatGPT 4.0 版本正式发布可供大众使用，彻底改变了人们对AI 能力的理解。其他LLM，例如 Bard、Llama、Bing Chat 和Copilot，也相继发布。## 什么是AI 的“第三次浪潮”？凭借一系列硬件突破和进步，AI 在经历了数十年的缓慢发展和寒冬之后，近几年迎来了加速发展。行业观察人士认为，在这一轮AI 发展热潮中，三种类型的AI[浪潮] 相继快速成为主流，它们分别是：[预测式 AI] 、[生成式 AI] （例如 LLM），以及[代理式 AI] 。\n代理式AI 可以创建计算机程序，即使没有明确的指令，也能够自主执行任务，而且也无需基于提示的特定上下文。AI 代理可以自行决策，从过去的经验中学习，并相应地调整行动。因此，它们可以独立运行，或者只需极少的人工干预就能运行。## 未来AI 将会如何发展？近年来，新的发现和更强大的硬件帮助AI 获得了前所未有的能力。AI 的历史将会继续延续，未来或许会有更多激动人心的发展。Cloudflare 赋能开发人员，让其能够为AI 的发展史贡献自己的力量。凭借遍布全球的分布式无服务器AI 基础设施、免费的训练数据出口、分布式[矢量数据库] 和其他关键的 AI 构建块，Cloudflare 平台让开发人员能够利用最先进的AI 技术进行构建。[立即为 AI 发展史贡献自己的力量] 。\n*来源：*\n* *https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html*\n* *https://www.history.com/articles/7-early-robots-and-automatons*\n* *https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(07)00217-3*\n* *https://www.historyofinformation.com/detail.php?entryid=782*\n* *https://www.historyofinformation.com/detail.php?id=4137*\n* *https://www.techtarget.com/searchenterpriseai/definition/AI-winter*\n* *https://aaai.org/conference/aaai/aaai80/*\n* *https://blog.google/products/search/introducing-mum/*\n* *https://news.harvard.edu/gazette/story/2012/09/alan-turing-at-100/*\n开始使用* [Free 计划] \n* [小型企业计划] \n* [企业级服务] \n* [获得推荐] \n* [请求演示] \n* [联系销售] \n人工智能* [什么是人工智能 (AI)？] \n* [人工智能推理与训练] \n* [AI 发展史] \n机器学习* [什么是机器学习？] \n* [什么是深度学习？] \n* [什么是大型语言模型(LLM)？] \n* [低秩自适应 (LoRA)] \n* [AI 图像生成] \n大数据* [什么是嵌入？] \n* [什么是大数据？] \n* [如何构建 RAG 管道] \n词汇* [什么是 AI 安全？] \n* [向量数据库] \n* [预测式 AI] \n* [ChatGPT 插件] \n* [神经网络] \n* [什么是生成式 AI？] \n* [什么是自然语言处理 (NLP)？] \n* [AI 幻觉] \n* [AI 量化] \n* [OWASP Top 10 for LLM] \n* [AI 数据投毒] \n* [检索增强生成 (RAG)] \n* [什么是代理式 AI？] \n* [AI 的第三次浪潮] \n* [什么是氛围编码？] \n* [模型上下文协议 (MCP)] \n* [AI 在网络安全领域的应用] \n* [如何开始氛围编码] \n* [如何管理 AI 智能体] \n* [如何阻止 AI 爬网程序] \n* [如何防止抓取] \n* [如何保护 AI 系统] \n* [如何保护 AI 训练数据安全] \n学习中心* [安全性学习中心] \n* [CDN 学习中心] \n* [DDoS 学习中心] \n* [DNS 学习中心] \n* [性能学习中心] \n* [无服务器学习中心] \n* [SSL 学习中心] \n* [机器人学习中心] \n* [云学习中心] \n* [访问管理学习中心] \n* [网络层学习中心] \n* [隐私学习中心] \n* [视频流式传输学习中心] \n* [电子邮件安全性学习中心] \n* [学习中心主页] \n[] [] [] [] [] \n©2026Cloudflare 公司[隐私政策] [使用条款] [报告安全问题] [信任与安全]![privacy options] Cookie 首选项[商标]', 'doi': '', 'published_date': '2026-02-02T20:25:02.973020', 'pdf_url': '', 'url': 'https://www.cloudflare.com/zh-cn/learning/ai/history-of-ai/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI世界漫遊指南- 人工智能簡史與十問十答 - iso.cuhk.edu.hk', 'authors': [], 'abstract': 'AI世界漫遊指南 - 人工智能簡史與十問十答| CUHKUPDates | 香港中文大學敬告讀者： 《中大通訊》已停刊，本網暫停更新。請移玉步造訪本校最新通訊《走進中大》網頁：[https://focus.cuhk.edu.hk，閱讀大學報道和消息] 。\n[主頁] \n[類別] \n[ENG] [简] \n[頭條] [榜上友名] [學術探奇] [六物窺人] [AI：人算不如機算？] [藝士匹靈] [雅共賞] [字裏科技] [所有主題] \n* [主頁] |[ENG] |[简体] |\n* [頭條] \n[榜上友名] \n[學術探奇] \n[社創薈動] \n[六物窺人] \n[AI：人算不如機算？] \n[藝士匹靈] \n[雅共賞] \n[字裏科技] \n[所有主題] \nAI：人算不如機算？\n# AI世界漫遊指南\n## 人工智能簡史與十問十答![] \nAI世界漫遊指南\n人工智能簡史與十問十答由空中樓閣成為現實，人工智能歷經千百年起落跌宕。「[AI：人算不如機算？] 」系列來到最後一期，《中大通訊》特意爬梳史料，以年表方式呈現人工智能在世界各地及中大的發展脈絡。我們亦請來[計算機科學與工程學系] 系主任**金國慶**教授指點迷津，解答十條關於人工智能的熱門問題。\n![] **人工智能到底是甚麼？有統一的定義嗎？**\n「人工智能」一詞為時任達慕斯大學數學系教授的電腦科學家約翰・麥卡錫（John McCarthy）於1956年所創。當時麥卡錫教授等人正進行研究，探討以機器精準模擬人類各項智能的可能。簡而言之，人工智能旨在讓機器模仿人類工作，執行視覺感知、語言運用、運籌決策等任務。\n[![科學家要掌握冰雪圈在氣候變化下的轉變，往往要從衞星圖片勾勒出各地冰川的邊界，從而判斷其萎縮情況，過程頗費心力。中大一款運用深度學習（deep learning）技術的人工智能模型，正可為一眾學者代勞。透過反覆觀察多個衞星由2002至2019年為格陵蘭三條冰川拍攝的相片，模型現能自動分析影像，從中辨認冰川，準確畫出其形態，誤差小至三個像素]] \n**人工智能有哪些不得不知的概念？**\n人工智能的核心概念之一是**機器學習**（deep learning）。所謂機器學習，就是指機器利用各種演算法分析數據、揣摩事物法則，以作出合乎常理的決斷。而機器之所以能學習學習，則有賴於一種名為**神經網絡**（neural network）的電腦系統。神經網絡一般由一連串名為人工神經元的數學模型組成，模擬人腦神經。\n針對人工智能的研究五花八門，當中以**自然語言處理**（natural language processing，簡稱NLP）為熱門之一。此範疇的目標在於讓機器學習人類語言並領略箇中規律，從而懂得處理情感分析、文本分類、問答生成等牽涉語音和文字的工作。\n**哪些國家對人工智能的發展舉足輕重？**\n美國是人工智能發源地，一直領先群倫。歐洲各國亦時有新猷，如因擊敗職業圍棋棋手而成國際焦點的英國人工智能程式AlphaGo。近十年中國急起直追，在人工智能研究和專利方面名列前茅，並銳意將人工智能引進各行各業，獨佔鰲頭。\n[![中大與啟悟有限公司受香港機場管理局委託，研發以物聯網（Internet of Things，簡稱IoT）數據管理香港國際機場飛行區的系統AS2，方便地勤人員隨時隨地綜覽各航班在停機坪上的裝卸、補給和流轉。項目已見雛形，並於2019年獲香港資訊及通訊科技獎智慧出行大獎。最新生產版本配備人工智能，可整理取自數千部裝置的數據，準確分析以至預測停機坪上各種狀況]] \n**日常生活中，人工智能有何用途？**\n人工智能的用途多不勝數，但大致可分為強弱兩類：弱人工智能泛指用以處理簡單工作的程式，如Siri之類的虛擬助理和網絡上各種即問即答的聊天機械人；強人工智能則指能夠執行複雜任務的器械，如無人車與服務型機械人。\n**人工智能有何好處？**\n人工智能無疑能改善人類生活，整個社會都能受惠。譬如無人車可令交通更為暢順，並為旅客提供多一個選擇。而配備人工智能的機械人亦可代我們執行拆彈、深海探索、能源開採等艱險工作，減少傷亡。![] \n**人工智能蔚然成風，為我們帶來怎樣的挑戰？**\n人工智能對勞動市場的衝擊是其帶來的一大挑戰。無論在速度或準繩度上，機器很多時已勝過人類，不少原先由人類佔據的職位自然落入它們手中。當然，機器仍時有失誤，何況孰是孰非，有時根本難以說清。這正是人工智能另一問題，後果可以十分嚴重。試想像一架無人車煞制失靈，前方有一老一幼的行人，系統應指令車輛轉向何方？而扭軚又可能傷及乘客，系統該優先保護何人？凡此種種，到頭來也許並無定論。**人工智能是否正把我們的工作搶走？**\n可以說是，也可以說不是。面對重重複複的簡單工作，人工智能遊刃有餘，但這不代表人人都要失業。以會計為例，業內不少軟件已具備一定智力，足以應付基本工作，然而人類仍是不可或缺。要及早發現問題，還是要有個經驗老到、先知先覺的會計師坐鎮。又如面對面的溝通、與客戶打交道，機器也是力有不逮。說到底，人類在很多事情上仍無法被替代。而隨着人工智能變得更為普遍，市場對受過相關訓練的人只會有更大需求。當然，我們也要勤於進修，方能把握人工智能帶來的工作機會。[![中大一套運用聯邦學習（federated learning）技術的人工智能系統，現能快而準地從胸部電腦斷層掃瞄影像偵測新冠肺炎病變。系統由各間參與開發的醫院同時訓練，過程中藉着觀察各醫院庫存中的胸部斷層影像，熟習新冠肺炎病灶形態。經中央伺服器整合其學習成果後，系統即可自動分析影像，準確度達九成半。訓練用的影像全程由各醫院保管而不經手於中央，外泄風險得以分散]] \n**但人工智能仍在發展，我們到最終會否還是被取代？**\n不會。須知人機之間，有着難以跨越的鴻溝。人工智能乃針對特定工作而生，除此之外，甚麼也做不了。再者，機器只能以邏輯語言理解事物，行事墨守成規。反觀人類不只是一個程式或演算法，還有自主意識、能體察情感。而生命之所以多姿多彩，某程度上就是因為人類時時不按常理出牌，這也是人工智能所難企及。**人工智能前景如何？在人工智能時代，我們又該如何自處？**\n人工智能方興未艾，日後必會更為普遍，前景可謂一片光明。另一邊廂，我們或會怕人類的地位被動搖，然而危中自有機。機器確實會導致職位流失，但此消彼長，人工智能的普及也為不少人帶來出頭的機會，電腦科學家和數據分析師便是例子。[![紅樹林可藉吸碳延緩氣候暖化，但同時會排出甲烷此一強勁的溫室氣體。此消彼長下，其降溫效能可於二十年間減逾五成。中大與國際學者組成團隊，運用一套名為隨機森林（random forest）的人工智能演算法分析米埔自然保護區內一片紅樹林，發現土壤溫度和鹽度為導致其排放甲烷的主因]] \n**不是天才，也能學習人工智能嗎？**\n當然可以。人工智能與很多領域都有交集，如電腦編程、工程、數學、統計乃至語言，不勝枚舉。這個大千世界，可說是來者不拒。當然，要學有所成，能夠明辨慎思十分重要，但若有志於此，這不見得是難事。*編纂／ronaldluk@cuhkcontents、jasonyuen@cuhkcontents\n中譯／jasonyuen@cuhkcontents\n年表設計／amytam@cuhkimages*\n**標籤**\n[人工智能] [金國慶] [計算機科學與工程學系] [工程學院] \n[] [] \n### 本期推介[![海納百川]] \n[海納百川] \n陳新安的科學、教育與人生哲學[![打開意義的世界]] \n[打開意義的世界] \n文研學者梁以文的塔羅和療癒心語[![六物窺人——林志秀]] \n[六物窺人——林志秀] \n香港中西醫結合醫學研究所所長回首英倫奮鬥史### 熱門文章### 編者推介[![來吧，人之子]] \n[來吧，人之子] \n淺談AI教育\n### 緊貼更新[訂閱] 電子版以閱讀最新文章\n### 推介文章[人工智能課程\u3000孕育百業專才] \n[慧眼識病灶] \n[The Chinese University of Hong Kong] \n香港中文大學2026版權所有\n[中大主頁] |[中大像素] |[聯絡我們] |[免責聲明] |[私隱政策]', 'doi': '', 'published_date': '2026-02-02T20:25:02.973025', 'pdf_url': '', 'url': 'https://www.iso.cuhk.edu.hk/chinese/publications/CUHKUPDates/article.aspx?articleid=4068', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的发展时间轴：从过去到未来-百度开发者中心', 'authors': [], 'abstract': '人工智能的发展时间轴：从过去到未来-百度开发者中心\n[![logo]] \n* [登录] \n* |\n* [注册] \n### 开发者热搜* [人工智能] \n* [云原生] \n* [AI应用] \n[推荐] \n[云原生] \n[文心快码 Baidu Comate] \n[飞桨PaddlePaddle] \n[人工智能] \n[超级链] \n[数据库] \n[百度安全] \n[物联网] \n[开源技术] \n[云计算] \n[大数据] \n[开发者] \n[企业服务] \n[更多内容] \n[千帆大模型平台] \n[客悦智能客服] \n# 人工智能的发展时间轴：从过去到未来作者：[谁偷走了我的奶酪] 2024.01.08 08:38浏览量：33\n*简介：*本文将带你了解人工智能的发展历程，从早期的思想萌芽到现代的应用普及，我们将通过时间轴的方式揭示人工智能的冷知识和发展趋势。\n人工智能（AI）的发展历程可以追溯到上个世纪。在这个漫长的时间里，AI经历了多次高潮和低谷，不断推动着科技的进步。下面让我们一起沿着时间轴，了解AI的成长历程和未来展望。\n1943年，美国神经科学家Warren McCulloch和数学家Walter Pitts提出了[神经网络] 的初步概念，他们认为神经元的工作原理与逻辑门相似。这一思想成为人工智能发展的重要起点。\n1956年，美国达特茅斯学院的一次研讨会上，正式提出了“人工智能”这一概念。这次会议标志着AI作为一个独立的学术领域正式诞生。\n1957年，加拿大心理学家Frank Rosenblatt开发了感知机模型，这是一种基于神经网络的[机器学习] 模型。然而，由于当时计算机性能的限制，这一模型并未得到广泛应用。\n1966年，美国科学家Joseph Weizenbaum开发了名为Eliza的自然语言对话程序，这是最早的聊天机器人之一。Eliza能够通过简单的文本对话模拟人类对话，引起了人们对AI的关注。\n1970年，日本ATR实验室开发了名为Shakey的机器人，它是世界上最早的移动机器人之一。Shakey能够自主导航、识别物体并执行任务。\n1981年，日本科学家Satoshi Sekiguchi提出了基于规则的专家系统，这是一种基于知识的计算机系统，用于提供专业领域的建议和决策。\n1988年，美国斯坦福大学教授Fei-Fei Li和她的团队开发了用于[图像识别] 的卷积神经网络LeNet-5。虽然当时的技术有限，但这一研究为现代计算机视觉领域奠定了基础。\n1997年，IBM的超级计算机“深蓝”战胜了国际象棋世界冠军Garry Kasparov，这是计算机首次在传统智力[游戏] 中击败人类。\n2006年，加拿大多伦多大学教授Geoffrey Hinton提出了[深度学习] 的概念，这是一种模拟人脑神经网络的机器学习方法。深度学习在[语音识别] 、图像识别等领域取得了巨大成功。\n2011年，苹果公司发布Siri语音助手，成为首个在消费市场上广泛应用的智能助手。Siri能够理解语音指令并回答问题，为用户提供便利的信息和服务。\n2016年，谷歌DeepMind开发的AlphaGo战胜了围棋世界冠军李世石，这是计算机在围棋领域首次击败人类。AlphaGo使用深度学习和蒙特卡洛树搜索算法，展现了AI在复杂决策问题上的强大能力。\n2020年，Open[AI开发] 的GPT-3语言模型引发了AI文本生成的热潮。GPT-3能够生成连贯、有逻辑的文本内容，被广泛应用于[自然语言处理] 和对话系统等领域。\n未来展望：随着技术的不断进步，AI将在更多领域发挥重要作用。例如，自动驾驶、医疗诊断、金融投资等领域都将受益于AI的发展。同时，我们也需要关注AI带来的伦理和隐私问题，确保技术的可持续发展。\n### 相关文章推荐* [### 文心一言接入指南：通过百度智能云千帆大模型平台API调用\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。\n] \n[十万个为什么] 2023.10.20 16:562564931910\n* [### 从MLOps 到LMOps 的关键技术嬗变本文整理自QCon 全球软件开发大会-从 MLOps 到LMOps 分论坛的同名主题演讲] \n[百度智能云开发者中心] 2023.11.15 18:033441095\n* [### Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n[百度智能云开发者中心] 2023.03.21 10:563032831\n* [### 更轻量的百度百舸，CCE Stack 智算版发布百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的AI 工程能力面向市场推出的解决方案。] \n[百度智能云开发者中心] 2023.03.02 12:172626811\n* [### 打造合规数据闭环，加速自动驾驶技术研发今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n[百度智能云开发者中心] 2023.03.02 15:002767501\n* [### LMOps 工具链与千帆大模型平台LMOps 相关的概念以及关键技术] \n[百度智能云开发者中心] 2023.11.17 15:492395533\n### 发表评论登录后可评论，请前往[登录] 或[注册] \n评论### 开发者关注产品榜* [\n*1*\n### 百度千帆·大模型服务及Agent开发平台\n企业级一站式大模型开发及服务平台模型训练限时免费] \n* [\n*2*\n### 百度千帆·数据智能平台一站式多模态数据管理、加工和分析应用平台平台体验全免费] \n* [\n*3*\n### 秒哒-生成式应用开发平台\n不用写代码，就能实现任意想法全功能免费体验] \n* [\n*4*\n### 百度智能云客悦智能客服平台大模型重塑营销与客服体验0元试用一个月\n] \n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践] \n### 关于作者[![] ### ] \n* 被阅读数* 被赞数* 被收藏数关注活动[\n咨询]', 'doi': '', 'published_date': '2024-01-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2733815', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能简史-腾讯云开发者社区-腾讯云', 'authors': [], 'abstract': '人工智能简史-腾讯云开发者社区-腾讯云\n[] \n[用户9624935] \n## 人工智能简史**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布用户9624935\n**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;人工智能简史\n# 人工智能简史![作者头像] \n用户9624935\n**关注\n发布于2022-04-02 14:58:47\n发布于2022-04-02 14:58:47\n2.2K0\n举报**文章被收录于专栏：[凯云实验室] 凯云实验室\n![] \nArtificial Intelligence (AI)，是在1956年的达特茅斯会议上提出来的，标志着人工智能这一学科的诞生。\n从1956年到2016年，刚好是60年。在过去的60年里，人工智能经历了三个阶段：\n* 二十世纪五十年代到七十年代：推理期，其出发点是，数学家真聪明。让计算机具有逻辑推理能力：为什么仅有逻辑推理能力不能实现人工智能？困难在哪里？* 二十世纪七十年代中期开始：知识期，其出发点是，知识就是力量。让计算机具有知识：由人把知识总结出来，再教给计算机——这是相当困难的。* 二十世纪九十年代到现在：学习期，其出发点是，让系统自己学。同时，也催生了人工智能的三大派别：* 符号主义：主要内容是关于符号计算、演算和逻辑推理，用演算和推理的办法来证明。比如说像机器证明就是符号主义。* 连接主义：目前非常流行的神经网络、神经元网络、深度学习，这些都是连接主义。* 行为主义：行为主义其实是从控制论衍生出来的，目前提及较少，但不能忽略。> 作者注：关于学派的分法，《终极算法》一书分为五类：符号学派，联结学派，进化学派，贝叶斯学派和类推学派。人工智能的三个派别和三个阶段并没有对应和界限，三个派别是在三个阶段的交织中发展起来的。著名信息论和人工智能专家钟义信在《弘扬Simon的源头创新精神，开拓AI的新理念新路径》报告中指出三大学派的的出现是一直以来还原论把复杂的系统分而治之研究的结果。因为整体上解决智能问题在物理和数学上都存在巨大的困难，所以在模仿大脑的功能研究上，出现了符号主义；在模仿大脑结构的研究上，出现了连接主义，在模仿人类行为的研究上（什么样的环境刺激会产生什么样的行为反应），出现了行为主义。\n> 作者注：看待人工智能的历史，要把人工智能的历史和神经网路的历史稍微区分一下，不能把神经网络的历史看作是人工智能的历史。所以本文不单独列举神经网络的发展历史和重大事件，留在下一篇文章中探讨。人工智能发展的过程中，经历了三次大事件，这些大事件导致了人工智能的发展进入三次低谷，被称为&quot;AI winter&quot;：\n* 1973年，英国发表了James Lighthill报告，批评人工智能研究进展令人失望，建议取消机器人的研究。为了回应批评和国会的压力，美国和英国政府停止了人工智能研究的资助。\n* 1992年，日本智能（第五代）计算机的研制宣告失败。这次失败有一个收获，是在潘云鹤《人工智能走向2.0》一文指出的，这次失败表明：驱动人工智能的发展主要靠创新的知识和软件，硬件的作用是支持其运行。\n* 在80年代，也诞生了cyc项目，一个包含所有人类常识的数据库。该项目随着互联网搜索引擎的崛起而衰败。潘云鹤在《人工智能走向2.0》指出：海量知识不能靠专家人工表达，要从环境中自动学习。也就是周志华指出的：由人把知识总结出来，再教给计算机——这是相当困难的。\n在过去的60年里，人工智能领域共有8位科学家成为图领奖得主：\n* 1969，Marvin Minsky：奖励他在创造，塑造，推动和加速人工智能这一领域的核心作用。\n* 1971，John McCarthy：麦卡锡的讲座《人工智能的研究现状》概括了他在人工智能领域的成就，也概括了值得奖励的原因。\n* 1975，Allen Newell and Herbert A. Simon：奖励他们在二十多年的联合科学工作中，最初与兰德公司的JC Shaw合作，随后与卡内基梅隆大学的众多教师和学生同事合作，对人工智能，人类认知心理学和列表处理方面做出的基础贡献。\n* 1994，Edward Feigenbaum and Raj Reddy：奖励他们在开创了大规模人工智能系统的设计和建造，展示了人工智能技术的实际重要性和潜在的商业影响。\n* 2010，Leslie G. Valiant：奖励他对于计算理论的变革性贡献，包括可能近似正确（PAC）学习的理论，枚举和代数计算的复杂性以及并行和分布式计算的理论。\n* 2011，Judea Pearl：奖励他对人工智能的基础贡献：概率和因果推理的微积分。\n上面这8位科学家，Marvin Minsky是MIT教授，最早提出连接主义，后来发表的《Perceptrons》一书指出感知机无法处理异或问题，导致连接主义长时间陷入低谷。不过著名信息论和人工智能专家钟义信说，另一个方面来看，马文·明斯基指出这个问题以后，经过人们的研究，提出了所谓的多层感知机，我们只要增加一个顶层就可以极大地提高神经网络表达的能力，可以逼近任意的问题。所以这个事情又从它的负面走向了正面，产生了积极的效果。\nJohn McCarthy，Allen Newell， Herbert A. Simon、Edward Feigenbaum几位都是非常典型的符号主义代表，他们最早推动了机器证明、人工智能、通用人工智能机、知识工程的进步。\n> 作者注：值得一提的是Herbert A. Simon是美国卡内基－梅隆大学心理学教授，1978年诺贝尔奖金获得者（经济学）。1968-1972年任美国总统科学顾问、行为科学和人工智能的创始人之一。西蒙教授为科学界的知名学者，在企业管理、计算机设计和决策理论方面有所创见。\nRaj Reddy主要是做语音识别的，李开复、沈向阳的老师。\nLeslie G. Valiant的贡献是机器学习理论，Judea Pearl的贡献是概率计算和因果推理，高文院士说，他们的工作是未来人工智能的重点走向。\n以上从分别从三个时期，三大学派，三次大事件以及8位图领奖得主的角度，总结了人工智能的简史。以下是我的一些不成熟思考：\n第一，计算的本质与智能的本质。《类脑智能研究的回顾和展望》指出，现有人工智能系统通用性较差与其计算理论基础和系统设计原理有密不可分的关系。计算机的计算本质和基础架构是图灵机模型和冯诺伊曼体系结构，其共同的缺点是缺乏自适应性。图灵计算的本质是使用预定义的规则对一组输入符号进行处理，规则是限定的，输入也受限于预定义的形式。图灵机模型取决于人对物理世界的认知程度，因此人限定了机器描述问题，解决问题的程度。而冯诺伊曼体系结构是存储程序式计算，程序也是预先设定好的，无法根据外界的变化和需求的变化进行自我演化。总结来看，计算的本质可以用一个数学公式f(x)=y来表达，是问题求解的范畴。\n那智能的本质是什么？如何表达？著名信息论和人工智能专家钟义信给了一个探讨性的定义：智能一定是在环境的作用下，人跟环境相互作用，不断的去学习，不断的去进化，在这个过程当中展开了智能的活动。反之，如果没有这种主体跟客体的相互作用，如果一切都是十全十美，如果不需要做出任何的改进，那就不需要思考、不需要学习，也就不需要智能。所以，一定要在主体跟客体相互作用过程当中来考察智能才有意义。李衍达院士在《沿Simon 开拓下去》的报告中探讨了智能的功能与智能的机理问题，指出基因的层次没有鸿沟，人和所有生物的机理是相同的，区别的是进化：自动适应外界变化而优化自身结构的功能。而且人脑在进化过程里面通过DNA的改变，改变了神经元的连接，这个连接既记录了学习的结果，又优化了学习算法。既简化了所需要的元件，又节省了能耗，非常巧妙。\n> 智能路径：感知反应-&gt;条件反射（存储，记忆）-&gt;决策（意志、欲望和目的）\n第二，关于程序员转型。和第一个问题有关，我们都是学习图灵机模型和冯诺伊曼架构长大的，思维方式相对固定。深度学习今年非常火爆，程序员又要开始转型。关于转型，我注意到几个论调：* 转型深度学习，数学是首要的基础；* 转型深度学习，开始大量学习TensorFlow框架；\n* 大二大三优秀学生学习起来很快，有经验的程序员学习来很苦；以上我都不太认同，人类是万物之灵，遇到新问题，学习新东西，再正常不过的事情，何来转型之说？如果非要说有什么需要转变，我觉得是到思维方式的转变：* 数学只是工具，TensorFlow只是封装的平台，而深度学习是有理论瓶颈的，工程界一直以来轻视学术的思维定势需要改变了。国内程序员同时是科学家的太少了，科学家有点高，做个学者吧。感觉要做一个好的科学家，不只是研究技术，而是在研究哲学，研究一些物质的本质、规律，研究一些最基础的东西。\n* 大多数程序员都是“程序员”思维，这是软件工业化的结果。重接口，重输入，重交付，这是一种软件外包的思维。输入是什么？输出是什么？程序如何实现？这些都造成了思维懒惰的一代程序员，从来不去问为什么程序这么做。而深度学习恰恰是讨论程序为什么这么实现的问题，其输出是模型，是算法。这是程序员需要改变的思维方式。* 人工智能更强调创新，特别是源头创新。在这个领域，有大量的问题都是崭新的，需要采用一些数学理论，结合实际需求来探索。我们在学习机器学习理论和算法的时候，需要有意识的突破已有的认知，特别是图灵机模型和冯诺伊曼体系结构。第三，脑复杂？还是环境复杂？傅小兰在《Simon与认知科学研究》报告中提到了《分布式认知》，指出认知现象在认知主体和环境间分布的本质：认知既分布于个体内与个体间，也分布于媒介、环境、文化、社会和时间等之中（Cole &amp; Engestrom, 1993）。Herbert A. Simon 也指出，一个人，若视作行为系统，是很简单的。他的行为随时间而表现出的表面复杂性主要是他所处环境的复杂性的反映。人——或至少人的智力要素——也许是比较简单的，人的行为的复杂性也许大半来自人的环境，来自人对优秀设计的搜索，因此，“在相当大的程度上，要研究人类便要研究设计科学。它不仅是技术教育的专业要素，也是每个知书识字人的核心学科”。第四，从上而下还是从下而上？人工智能从上而下研究的开创者和代表人物是Herbert A. Simon，他当时想到，人的大脑活动是分层次的，在底层的机理没有搞清楚时，他认为也不妨碍对于高层概念、推理、问题求解层次进行研究。符号学派就是自上而下的典型代表，但至今符号学派一直受到自下而上的连接主义压制。自下而上的代表是日本的第五代计算机计划，东京大学元岗达教授提出“第五代计算机的构想”，随后日本制定了研制五代机的十年计划，总预算达4.3亿美元。以渊一博为所长的“新一代计算机技术研究所”苦苦奋战了近十年，他们几乎没有回过家，近乎玩命式的拼搏；然而，由于没有突破关键性技术难题，无法实现自然语言人机对话，程序自动生成等目标，最终于1992年宣告失败！这或许也是图灵机模型和冯诺伊曼架构的失败。然而，峰回路转，得益于分布式计算和大数据时代，深度学习成为主流的自下而上方法。近五年来，深度学习在“视”、“听”、“说”等领域取得了的巨大成功，但这还不能表明自下而上的胜利或者神经网络模型的正确。神经网络只是从下而上对大脑的粗糙模拟和抽象，是否是正确的大脑学习隐喻还不得而知。但神经网络的成功又引发了一些自下而上的尝试，据称IBM有一个名为“突触”的项目，研究芯片级类脑计算设备，支持低频率，低功耗，和大量链接等神经网络功能。\n第五，鲁棒性？可解释性？魔术性？这几个问题是现在机器学习，特别是深度学习面临的主要问题。人类犯错：水平从九段降到八段，机器犯错：水平从九段降到业余，这就是鲁棒性。鲁棒性要求，“好的时候”要好，“坏的时候”不能太坏。在封闭静态环境中，重要因素大多是“定”的，而在开放动态环境中，一切都是变的，开放环境的鲁棒性，这也是自动驾驶面临的困难所在。关于可解释性，也被称为深度学习的黑箱模型。若学习器不能给出治疗理由，则难以说服患者接受昂贵的治疗方案。若学习器不能给出停机检测的理由，则难以判断停机检测的风险和代价。这些案例都需要机器学习的模型给出解释，否则难以应用到难以用于高风险应用。而机器学习魔术性是指即便相同数据，普通用户很难获得机器学习专家级性能。就是专家之间，是特别考验团队实力的，也有一点运气在里面。门派都一样，功力不一般。第六，目前的研究热点和我的方向。深度学习是很火的，不过周志华说的很中肯：“深度学习中间还有很多困难而又重要的问题值得深入研究，但这些真正值得研究的问题，就我看到的情况而言，好像做的人非常少。大多数人在干什么呢？拿它做做应用，调调参数，性能刷几个点，然后发几篇文章。这样虽然容易发表文章，但恐怕很难产生有影响的成果。”另外，周志华在引领集成学习的发展方向，CCAI17可以看到一些方向，中国香港科技大学计算机系主任杨强谈到的迁移学习，日本理化学研究所杉山将谈到的弱监督机器学习等。我的计划是，从历史中观其大略；感知机，神经网络，反向传播，深度学习是一条线，已经是必备的基础了；然后向增强学习发力；在技术上打通分布式系统，大数据和机器学习；在业务和需求上结合金融场景。\n![] \n第七，已知和未知。我们参考神经生理学，研制了神经网络和深度学习，并且取得了良好的效果。有人指出，大脑的生物物理结构，机制和功能只是大脑处理信息过程中的印记，其中很少一部分可用于有意识的思想（认知）。在学习未知的过程中，我们对学习到底了解了多少？在未知的区域里，既有要学习的对象，也有学习本身。参考文献：《人工智能走向2.0》 潘云鹤《类脑智能研究的回顾与展望》曾毅等《脑启发计算》苏中《机器学习》序言陆汝钤《机器学习：发展与未来》周志华《H. A. Simon学术生平》林建祥\n《Simon的认知科学思想》傅小兰\n《人工智能--螺旋上升的60年》高文院士\n《沿Simon 开拓下去》李衍达《塞蒙终生学术经历简介》林建祥《人工智能的历史》中国人工智能学会《司马贺的创新之路》史忠植《弘扬Simon学术思想 》钟义信《探寻大师足迹，一览马文•明斯基学术风采》史忠植《站在巨人的肩膀上，从人工智能与认知商务》苏中《弘扬Simon的源头创新精神开拓“AI”的新理念新路径》钟义信\n《独家| 周志华：深度学习很有用，但过度追捧就有危险了》AI科技大本营\n本文参与[腾讯云自媒体同步曝光计划] ，分享自微信公众号。\n原始发表：2017-08-06，如有侵权请联系[cloudcommunity@tencent.com] 删除\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n本文分享自补天遗石微信公众号，前往查看如有侵权，请联系[cloudcommunity@tencent.com] 删除。\n本文参与[腾讯云自媒体同步曝光计划] ，欢迎热爱写作的你一起参与！\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n评论登录后参与评论0条评论\n热度最新登录后参与评论推荐阅读相关产品与服务人工智能与机器学习提供全球领先的人脸识别、文字识别、图像识别、语音技术、NLP、人工智能服务平台等多项人工智能技术，共享 AI 领域应用场景和解决方案。[**产品介绍] \n[**AI驱动 智领未来] \n领券* ### 社区* [技术文章] \n* [技术问答] \n* [技术沙龙] \n* [技术视频] \n* [学习中心] \n* [技术百科] \n* [技术专区] \n* ### 活动* [自媒体同步曝光计划] \n* [邀请作者入驻] \n* [自荐上首页] \n* [技术竞赛] \n* ### 圈层* [腾讯云最具价值专家] \n* [腾讯云架构师技术同盟] \n* [腾讯云创作之星] \n* [腾讯云TDP] \n* ### 关于* [社区规范] \n* [免责声明] \n* [联系我们] \n* [友情链接] \n* [MCP广场开源版权声明] \n### 腾讯云开发者![扫码关注腾讯云开发者] \n扫码关注腾讯云开发者领取腾讯云代金券### 热门产品* [域名注册] \n* [云服务器] \n* [区块链服务] \n* [消息队列] \n* [网络加速] \n* [云数据库] \n* [域名解析] \n* [云存储] \n* [视频直播] \n### 热门推荐* [人脸识别] \n* [腾讯会议] \n* [企业云] \n* [CDN加速] \n* [视频通话] \n* [图像分析] \n* [MySQL 数据库] \n* [SSL 证书] \n* [语音识别] \n### 更多推荐* [数据安全] \n* [负载均衡] \n* [短信] \n* [文字识别] \n* [云点播] \n* [大数据] \n* [小程序开发] \n* [网站监控] \n* [数据迁移] \nCopyright ©2013 -2026Tencent Cloud. All Rights Reserved. 腾讯云版权所有[深圳市腾讯计算机系统有限公司] ICP备案/许可证号：[粤B2-20090059]![] [粤公网安备44030502008569号] \n[腾讯云计算（北京）有限责任公司] 京ICP证150476号 |[京ICP备11018762号] \n[问题归档] [专栏文章] [快讯文章归档] [关键词归档] [开发者手册归档] [开发者手册 Section 归档] \nCopyright ©2013 -2026Tencent Cloud.\nAll Rights Reserved. 腾讯云版权所有登录后参与评论**\n**\n**\n000\n推', 'doi': '', 'published_date': '2022-04-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://cloud.tencent.com.cn/developer/article/1971641', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能发展简史 - 中央网信办', 'authors': [], 'abstract': '人工智能发展简史\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能发展简史2017年01月23日 11:10来源：\n网络传播杂志[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n“人工智能之父”艾伦·图灵。**1、 人工智能的诞生（20世纪40～50年代）**\n1950年：图灵测试\n1950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n1954年：第一台可编程机器人诞生\n1954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n1956年：人工智能诞生\n1956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n1966年\\~1972年：首台人工智能机器人Shakey诞生\n1966年\\~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n1966年：世界上第一个聊天机器人ELIZA发布\n美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n1968年：计算机鼠标发明\n1968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n**3、 人工智能的低谷（20世纪70～80年代）**\n20世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n![] \n1997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n**4、 人工智能的繁荣期（1980年\\~1987年）**\n1981年：日本研发人工智能计算机\n1981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n1984年：启动Cyc（大百科全书）项目\n在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n1986年：3D打印机问世\n美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n**5、 人工智能的冬天（1987年\\~1993年）**\n“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n**6、 人工智能真正的春天（1993年至今）**\n1997年：电脑深蓝战胜国际象棋世界冠军\n1997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n2011年：开发出使用自然语言回答问题的人工智能程序\n2011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n2012年：Spaun诞生\n加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n2013年：深度学习算法被广泛运用在产品开发中\nFacebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n2015年：人工智能突破之年\nGoogle开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n2016年：AlphaGo战胜围棋世界冠军李世石\n2016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）![] \n2016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n**大事记**\n①1942年：“机器人三定律”提出\n美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。②1956年：人工智能的诞生\n达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n③1959年：第一代机器人出现\n德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n④1965年：兴起研究“有感觉”的机器人\n约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n⑤1968年：世界第一台智能机器人诞生\n美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n⑥2002年：家用机器人诞生\n美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n⑦2014年：机器人首次通过图灵测试\n在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n⑧2016年：AlphaGo打败人类\n2016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': '2017-01-23T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能历史 - IBM', 'authors': [], 'abstract': '人工智能历史 | IBM\n[Artificial Intelligence] \n# AI 的历史![高耸入云的摩天大楼尖顶] \n## 作者[Tim Mucci] \nIBM Writer\nGather\n## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。\nGPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;\n## 20 世纪以前### 1726\nJonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。\n学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;\n“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”\n- Jonathan Swift 的《格列佛游记》(1726)\nSwift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。\n## 1900–1950\n### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。\n### 1921\n一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。\n### 1939\n爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。\n虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。\n与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。\n### 1950\n英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;\n图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。\n## 1950–1980\n### 1951\nMarvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。\nSNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952\n数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。\n### 1955\n“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。\n### 1958\nJohn McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959\nArthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。\nOliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。\n### 1965\n哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。\n### 1966\nShakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969\nArthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。\nMarvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。\n### 1970\nTerry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。\n### 1973\nJames Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000\n### 1980\nWABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。\n### 1982\n日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。\n### 1986\nDavid Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。\n这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987\n在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988\nJudea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21\nRollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。\nMarvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。\n### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。\n### 1993\n科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。\n这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。\n### 1995\nRichard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;', 'doi': '', 'published_date': '2026-02-02T20:25:02.973523', 'pdf_url': '', 'url': 'https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:26:16,923 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '人工智能的创新发展与社会影响 - 中国人大网', 'authors': [], 'abstract': '当前位置：[首页](../../../ "首页")\xa0>\xa0[常委会专题讲座](../ "常委会专题讲座")\n\n## 十三届全国人大常委会专题讲座第七讲\n\n# 人工智能的创新发展与社会影响\n\n来源： 中国人大网\xa0\xa0浏览字号： [大](#) [中](#) [小](#) 2018年10月29日 10:26\n\n一、引言\n\n1956年人工智能（Artificial Intelligence，简称AI）的概念被正式提出，标志着人工智能学科的诞生，其发展目标是赋予机器类人的感知、学习、思考、决策和行动等能力。经过60多年的发展，人工智能已取得突破性进展，在经济社会各领域开始得到广泛应用并形成引领新一轮产业变革之势，推动人类社会进入智能化时代。美国、日本、德国、英国、法国、俄罗斯等国家都制定了发展人工智能的国家战略，我国也于2017年发布了《新一代人工智能发展规划》，发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏等地政府也相继出台推动人工智能发展的相关政策文件，社会各界对人工智能的重大战略意义已形成广泛共识。\n\n跟其他高科技一样，人工智能也是一把双刃剑。如何认识人工智能的社会影响，也有“天使派”和“魔鬼派”之分。“天使派”认为，人工智能领域的科技创新和成果应用取得重大突破，有望引领第四次工业革命，对社会、经济、军事等领域将产生变革性影响，在制造、交通、教育、医疗、服务等方面可以造福人类；“魔鬼派”认为，人工智能是人类的重大威胁，比核武器还危险，有可能引发第三次世界大战。2018年2月，牛津大学、剑桥大学和OpenAI公司等14家机构共同发布题为《人工智能的恶意使用：预测、预防和缓解》的报告，指出人工智能可能给人类社会带来数字安全、物理安全和政治安全等潜在威胁，并给出了一些建议来减少风险。\n\n总体上看，已过花甲之年的人工智能当前的发展具有“四新”特征：以深度学习为代表的人工智能核心技术取得新突破、“智能+”模式的普适应用为经济社会发展注入新动能、人工智能成为世界各国竞相战略布局的新高地、人工智能的广泛应用给人类社会带来法律法规、道德伦理、社会治理等方面一系列的新挑战。因此人工智能这个机遇与挑战并存的新课题引起了全球范围内的广泛关注和高度重视。虽然人工智能未来的创新发展还存在不确定性，但是大家普遍认可人工智能的蓬勃兴起将带来新的社会文明，将推动产业变革，将深刻改变人们的生产生活方式，将是一场影响深远的科技革命。\n\n为了客观认识人工智能的本质内涵和创新发展，本报告在简要介绍人工智能基本概念与发展历程的基础上，着重分析探讨人工智能的发展现状和未来趋势，试图揭示人工智能的真实面貌。很显然，在当下人工智能蓬勃发展的历史浪潮中如何选择中国路径特别值得我们深入思考和探讨。因此，本报告最后就我国人工智能发展态势、存在问题和对策建议也进行了阐述。\n\n二、人工智能的发展历程与启示\n\n1956年夏，麦卡锡（John McCarthy）、明斯基（Marvin Minsky）、罗切斯特（Nathaniel Rochester）和香农（Claude Shannon）等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能”这一概念，标志着人工智能学科的诞生。人工智能的目标是模拟、延伸和扩展人类智能，探寻智能本质，发展类人智能机器。人工智能充满未知的探索道路曲折起伏，如何描述1956年以来60余年的人工智能发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能60余年的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年-20世纪60年代初。人工智能概念在1956年首次被提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、LISP表处理语言等，掀起了人工智能发展的第一个高潮。\n\n二是反思发展期：60年代-70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入了低谷。\n\n三是应用发展期：70年代初-80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入了应用发展的新高潮。\n\n四是低迷发展期：80年代中-90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：90年代中-2010年。由于网络技术特别是互联网技术的发展，信息与数据的汇聚不断加速，互联网应用的不断普及加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年IBM深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念，这些都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年-至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器（Graphics Processing Unit，简称GPU）等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越科学与应用之间的“技术鸿沟”，图像分类、语音识别、知识问答、人机对弈、无人驾驶等具有广阔应用前景的人工智能技术突破了从“不能用、不好用”到“可以用”的技术瓶颈，人工智能发展进入爆发式增长的新高潮。\n\n通过总结人工智能发展历程中的经验和教训，我们可以得到以下启示：\n\n（一）尊重学科发展规律是推动学科健康发展的前提。科学技术的发展有其自身的规律，顺其者昌，违其者衰。人工智能学科发展需要基础理论、数据资源、计算平台、应用场景的协同驱动，当条件不具备时很难实现重大突破。\n\n（二）基础研究是学科可持续发展的基石。加拿大多伦多大学杰弗里·辛顿（Geoffrey Hinton）教授坚持研究深度神经网络30年，奠定人工智能蓬勃发展的重要理论基础。谷歌的DeepMind团队长期深入研究神经科学启发的人工智能等基础问题，取得了阿尔法狗等一系列重大成果。\n\n（三）应用需求是科技创新的不竭之源。引领学科发展的动力主要来自于科学和需求的双轮驱动。人工智能发展的驱动力除了知识与技术体系内在矛盾外，贴近应用、解决用户需求是创新的最大源泉与动力。比如专家系统人工智能实现了从理论研究走向实际应用的突破，近些年来安防监控、身份识别、无人驾驶、互联网和物联网大数据分析等实际应用需求带动了人工智能的技术突破。\n\n（四）学科交叉是创新突破的“捷径”。人工智能研究涉及信息科学、脑科学、心理科学等，上世纪50年代人工智能的出现本身就是学科交叉的结果。特别是脑认知科学与人工智能的成功结合，带来了人工智能神经网络几十年的持久发展。智能本源、意识本质等一些基本科学问题正在孕育重大突破，对人工智能学科发展具有重要促进作用。\n\n（五）宽容失败应是支持创新的题中应有之义。任何学科的发展都不可能一帆风顺，任何创新目标的实现都不会一蹴而就。人工智能60余载的发展生动地诠释了一门学科创新发展起伏曲折的历程。可以说没有过去发展历程中的“寒冬”就没有今天人工智能发展新的春天。\n\n（六）实事求是设定发展目标是制定学科发展规划的基本原则。达到全方位类人水平的机器智能是人工智能学科宏伟的终极目标，但是需要根据科技和经济社会发展水平来设定合理的阶段性研究目标，否则会有挫败感从而影响学科发展，人工智能发展过程中的几次低谷皆因不切实际的发展目标所致。\n\n三、人工智能的发展现状与影响\n\n人工智能经过60多年的发展，理论、技术和应用都取得了重要突破，已成为推动新一轮科技和产业革命的驱动力，深刻影响世界经济、政治、军事和社会发展，日益得到各国政府、产业界和学术界的高度关注。从技术维度来看，人工智能技术突破集中在专用智能，但是通用智能发展水平仍处于起步阶段；从产业维度来看，人工智能创新创业如火如荼，技术和商业生态已见雏形；从社会维度来看，世界主要国家纷纷将人工智能上升为国家战略，人工智能社会影响日益凸显。\n\n（一）专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定领域的人工智能技术（即专用人工智能）由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，因此形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域，统计学习是专用人工智能走向实用的理论基础。深度学习、强化学习、对抗学习等统计机器学习理论在计算机视觉、语音识别、自然语言理解、人机博弈等方面取得成功应用。例如，阿尔法狗在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，语音识别系统5.1%的错误率比肩专业速记员，人工智能系统诊断皮肤癌达到专业医生水平，等等。\n\n（二）通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。虽然包括图像识别、语音识别、自动驾驶等在内的专用人工智能领域已取得突破性进展，但是通用智能系统的研究与应用仍然是任重而道远，人工智能总体发展水平仍处于起步阶段。美国国防高级研究计划局（Defense Advanced Research Projects Agency，简称DARPA）把人工智能发展分为三个阶段：规则智能、统计智能和自主智能，认为当前国际主流人工智能水平仍然处于第二阶段，核心技术依赖于深度学习、强化学习、对抗学习等统计机器学习，AI系统在信息感知（Perceiving）、机器学习（Learning）等智能水平维度进步显著，但是在概念抽象（Abstracting）和推理决策（Reasoning）等方面能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n（三）人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，在其2017年的年度开发者大会上，谷歌明确提出发展战略从“Mobile First”（移动优先）转向“AI First”（AI优先）；微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿，麦肯锡报告2016年全球人工智能研发投入超300亿美元并处于高速增长，全球知名风投调研机构CB Insights报告显示2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n（四）创新生态布局成为人工智能产业发展的战略高地。信息技术（IT）和产业的发展史就是新老IT巨头抢滩布局IT创新生态的更替史。例如，传统信息产业IT（Information Technology）代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网IT（Internet Technology）代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等，目前智能科技IT（Intelligent Technology）的产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动AI技术生态的研发布局，全力抢占人工智能相关产业的制高点。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理GPU服务器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。在技术生态方面，人工智能算法、数据、图形处理器（Graphics Processing Unit，简称GPU）/张量处理器（Tensor Processing Unit，简称TPU）/神经网络处理器（Neural network Processing Unit，NPU）计算、运行/编译/管理等基础软件已有大量开源资源，例如谷歌的TensorFlow第二代人工智能学习系统、脸书的PyTorch深度学习框架、微软的DMTK分布式学习工具包、IBM的SystemML开源机器学习系统等；此外谷歌、IBM、英伟达、英特尔、苹果、华为、中国科学院等积极布局人工智能领域的计算芯片。在人工智能商业和应用生态布局方面，“智能+X”成为创新范式，例如“智能+制造”、“智能+医疗”、“智能+安防”等，人工智能技术向创新性的消费场景和不同行业快速渗透融合并重塑整个社会发展，这是人工智能作为第四次技术革命关键驱动力的最主要表现方式。人工智能商业生态竞争进入白热化，例如智能驾驶汽车领域的参与者既有通用、福特、奔驰、丰田等传统龙头车企，又有互联网造车者如谷歌、特斯拉、优步、苹果、百度等新贵。\n\n（五）人工智能上升为世界主要国家的重大发展战略。人工智能正在成为新一轮产业变革的引擎，必将深刻影响国际产业竞争格局和一个国家的国际竞争力。世界主要发达国家纷纷把发展人工智能作为提升国际竞争力、维护国家安全的重大战略，加紧积极谋划政策，围绕核心技术、顶尖人才、标准规范等强化部署，力图在新一轮国际科技竞争中掌握主导权。无论是德国的“工业4.0”、美国的“工业互联网”、日本的“超智能社会”、还是我国的“中国制造2025”等重大国家战略，人工智能都是其中的核心关键技术。2017年7月，国务院发布了《新一代人工智能发展规划》，开启了我国人工智能快速创新发展的新征程。\n\n（六）人工智能的社会影响日益凸显。人工智能的社会影响是多元的，既有拉动经济、服务民生、造福社会的正面效应，又可能出现安全失控、法律失准、道德失范、伦理失常、隐私失密等社会问题，以及利用人工智能热点进行投机炒作从而存在泡沫风险。首先，人工智能作为新一轮科技革命和产业变革的核心力量，促进社会生产力的整体跃升，推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域发展积极正面影响。与此同时，我们也要看到人工智能引发的法律、伦理等问题日益凸显，对当下的社会秩序及公共管理体制带来了前所未有的新挑战。例如，2016年欧盟委员会法律事务委员会提交一项将最先进的自动化机器人身份定位为“电子人（electronic persons）”的动议，2017年沙特阿拉伯授予机器人“索菲亚”公民身份，这些显然冲击了传统的民事主体制度。那么，是否应该赋予人工智能系统法律主体资格？另外在人工智能新时代，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题都需要我们从法律法规、道德伦理、社会管理等多个角度提供解决方案。\n\n由于人工智能与人类智能密切关联且应用前景广阔、专业性很强，容易造成人们的误解，也带来了不少炒作。例如，有些人错误地认为人工智能就是机器学习（深度学习），人工智能与人类智能是零和博弈，人工智能已经达到5岁小孩的水平，人工智能系统的智能水平即将全面超越人类水平，30年内机器人将统治世界，人类将成为人工智能的奴隶，等等。这些错误认识会给人工智能的发展带来不利影响。还有不少人对人工智能预期过高，以为通用智能很快就能实现，只要给机器人发指令就可以干任何事。另外，有意炒作并通过包装人工智能概念来谋取不当利益的现象时有发生。因此，我们有义务向社会大众普及人工智能知识，引导政府、企业和广大民众科学客观地认识和了解人工智能。\n\n四、人工智能的发展趋势与展望\n\n人工智能经过六十多年的发展突破了算法、算力和算料（数据）等“三算”方面的制约因素，拓展了互联网、物联网等广阔应用场景，开始进入蓬勃发展的黄金时期。从技术维度看，当前人工智能处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有数据、能耗、泛化、可解释性、可靠性、安全性等诸多瓶颈，创新发展空间巨大，从专用到通用智能，从机器智能到人机智能融合，从“人工+智能”到自主智能，后深度学习的新理论体系正在酝酿；从产业和社会发展维度看，人工智能通过对经济和社会各领域渗透融合实现生产力和生产关系的变革，带动人类社会迈向新的文明，人类命运共同体将形成保障人工智能技术安全、可控、可靠发展的理性机制。总体而言，人工智能的春天刚刚开始，创新空间巨大，应用前景广阔。\n\n（一）从专用智能到通用智能。如何实现从狭义或专用人工智能（也称弱人工智能，具备单一领域智能）向通用人工智能（也称强人工智能，具备多领域智能）的跨越式发展，既是下一代人工智能发展的必然趋势，也是国际研究与应用领域的挑战问题。2016年10月美国国家科学技术委员会发布了《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。DeepMind创始人戴密斯·哈萨比斯（Demis Hassabis）提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年7月成立了通用人工智能实验室，100多位感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n（二）从人工智能到人机混合智能。人工智能的一个重要研究方向就是借鉴脑科学和认知科学的研究成果，研究从智能产生机理和本质出发的新型智能计算模型与方法，实现具有脑神经信息处理机制和类人智能行为与智能水平的智能系统。在美国、欧盟、日本等国家和地区纷纷启动的脑计划中，类脑智能已成为核心目标之一。英国工程与自然科学研究理事会EPSRC发布并启动了类脑智能研究计划。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。人机混合智能得到了我国新一代人工智能规划、美国脑计划、脸书（脑机语音文本界面）、特斯拉汽车创始人埃隆·马斯克（人脑芯片嵌入和脑机接口）等的高度关注。\n\n（三）从“人工+智能”到自主智能系统。当前人工智能的研究集中在深度学习，但是深度学习的局限是需要大量人工干预：人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据（非常费时费力）、用户需要人工适配智能系统等。因此已有科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类AI”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低AI人员成本。\n\n（四）人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、材料等传统科学的发展。例如，2018年美国麻省理工学院启动的“智能探究计划”（MIT Intelligence Quest）就联合了五大学院进行协同攻关。\n\n（五）人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来十年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，在现有基础上能够提高劳动生产率40%；美、日、英、德、法等12个发达国家（现占全球经济总量的一半）到2035年，年经济增长率平均可以翻一番。2018年麦肯锡的研究报告表明到2030年人工智能新增经济规模将达到13万亿美元。\n\n（六）人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出未来五年人工智能提升各行业运转效率，其中教育业提升82%，零售业71%，制造业64%，金融业58%。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n（七）人工智能领域的国际竞争将日趋激烈。“未来谁率先掌握人工智能，谁就能称霸世界”。2018年4月，欧盟委员会计划2018-2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略》重点推动物联网建设和人工智能的应用。世界军事强国已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即提出谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n（八）人工智能的社会学将提上议程。水能载舟，亦能覆舟。任何高科技也都是一把双刃剑。随着人工智能的深入发展和应用的不断普及，其社会影响日益明显。人工智能应用得当、把握有度、管理规范，就能有效控制负面风险。为了确保人工智能的健康可持续发展并确保人工智能的发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，深入分析人工智能对未来经济社会发展的可能影响，制定完善的人工智能法律法规，规避可能风险，确保人工智能的正面效应。2017年9月，联合国犯罪和司法研究所(UNICRI)决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。2018年4月，欧洲25个国家签署了《人工智能合作宣言》，从国家战略合作层面来推动人工智能发展，确保欧洲人工智能研发的竞争力，共同面对人工智能在社会、经济、伦理及法律等方面的机遇和挑战。\n\n五、我国人工智能的发展态势与思考\n\n我国当前人工智能发展的总体态势良好。中国信通院联合高德纳咨询公司（Gartner）于2018年9月发布的《2018世界人工智能产业发展蓝皮书》报告统计，我国（不含港澳台地区）人工智能企业总数位列全球第二（1040家），仅次于美国（2039家）。在人工智能总体水平和应用方面，我国也处于国际前列，发展潜力巨大，有望率先突破成为全球领跑者。但是我们也要清醒地看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n一是高度重视。党和国家高度重视并大力发展人工智能。党的十八大以来，习近平总书记把创新摆在国家发展全局的核心位置，高度重视人工智能发展，多次谈及人工智能的重要性，为人工智能如何赋能新时代指明方向。2016年7月习总书记明确指出，人工智能技术的发展将深刻改变人类社会生活，改变世界，应抓住机遇，在这一高技术领域抢占先机。在党的十九大报告中，习总书记强调“要推动互联网、大数据、人工智能和实体经济深度融合”。在2018年两院院士大会上，习总书记再次强调要“推进互联网、大数据、人工智能同实体经济深度融合，做大做强数字经济”。在2017年和2018年的《政府工作报告》中，李克强总理都提到了要加强新一代人工智能发展。2017年7月，国务院发布了《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动，人工智能将成为今后一段时期的国家重大战略。发改委、工信部、科技部、教育部、中央网信办等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n二是态势喜人。根据2017年爱思唯尔（Elsevier）文献数据库SCOPUS统计结果，我国在人工智能领域发表的论文数量已居世界第一。从2012年开始，我国在人工智能领域新增专利数量已经开始超越美国。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成全球人工智能投融资规模最大国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。近两年，清华大学、北京大学、中国科学院大学、浙江大学、上海交通大学、南京大学等高校纷纷成立人工智能学院。2015年开始的中国人工智能大会（CCAI）已连续成功召开四届、规模不断扩大，人工智能领域的教育、科研与学术活动层出不穷。\n\n三是差距不小。我国人工智能在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在较大差距。英国牛津大学2018年的一项研究报告指出中国的人工智能发展能力大致为美国的一半水平。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，存在“头重脚轻”的不均衡现象。在Top700全球AI人才中，中国虽然名列第二，但入选人数远远低于占一半数量的美国。据领英《全球AI领域人才报告》统计，截至2017年一季度全球人工智能领域专业技术人才数量超过190万，其中美国超过85万，我国仅超过5万人，排名全球第7位。2018年市场研究顾问公司Compass Intelligence对全球100多家AI计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国制定完善人工智能相关法律法规的进程需要加快，对可能产生的社会影响还缺少深度分析。\n\n四是前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出到2030年，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n人类社会已开始迈入智能化时代，人工智能引领社会发展是大势所趋，不可逆转。经历六十余年积累后，人工智能开始进入爆发式增长的红利期。伴随着人工智能自身的创新发展和向经济社会的全面渗透，这个红利期将持续相当长的时期。现在是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧需要深入思考。\n\n（一）树立理性务实的发展理念。围棋人机大战中阿尔法狗战胜李世石后，社会大众误以为人工智能已经无所不能，一些地方政府、社会企业、风险资金因此不切实际一窝蜂发展人工智能产业，一些别有用心的机构则有意炒作并通过包装人工智能概念来谋取不当利益。这种“一拥而上、一哄而散”的跟风行为不利于人工智能的健康可持续发展。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。根据高德纳咨询公司发布的技术发展曲线，当前智能机器人、认知专家顾问、机器学习、自动驾驶等人工智能热门技术与领域正处于期望膨胀期，但是通用人工智能及人工智能的整体发展仍处于初步阶段，人工智能还有很多“不能”，实现机器在任意现实环境的自主智能和通用智能仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此发展人工智能不能以短期牟利为目的，要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，并务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n（二）加强基础扎实的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。在此发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。根据2017年爱思唯尔文献数据库SCOPUS统计结果，尽管我国在人工智能领域发表的论文数量已经排名世界第一，但加权引文影响力则只排名34位。为了客观评价我国在人工智能基础研究方面的整体实力，我们搜索了SCI期刊、神经信息处理系统大会（Conference on Neural Information Processing Systems，简称NIPS）等主流人工智能学术会议关于通用智能、深度学习、类脑智能、脑智融合、人机博弈等关键词的论文统计情况，可以清楚看到在人工智能前沿方向中国与美国相比基础实力存在巨大差距：在高质量论文数量方面（按中科院划定的SCI一区论文标准统计），美国是中国的5.34倍（1325:248）；在人才储备方面（SCI论文通讯作者），美国是中国的2.12倍（4804:2267）。\n\n我国应对标国际最高水平，建设面向未来的人工智能基础科学研究中心，重点发展原创性、基础性、前瞻性、突破性的人工智能科学。应该鼓励科研人员瞄准人工智能学科前沿方向开展引领性原创科学研究，通过人工智能与脑认知、神经科学、心理学等学科的交叉融合，重点聚焦人工智能领域的重大基础性科学问题，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n（三）构建自主可控的创新生态。美国谷歌、IBM、微软、脸书等企业在AI芯片、服务器、操作系统、开源算法、云服务、无人驾驶等方面积极构建创新生态、抢占创新高地，已经在国际人工智能产业格局中占据先机。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。美国对中兴通讯发禁令一事充分说明自主可控“核高基”技术的重要性，我国应该吸取在核心电子器件、高端通用芯片及基础软件方面依赖进口的教训，避免重蹈覆辙，着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如军民融合、产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。\n\n另外，我们需要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过标准实施加速人工智能驱动经济社会转型升级的进程。\n\n（四）建立协同高效的创新体系。我国经济社会转型升级对人工智能有重大需求，但是单一的创新主体很难实现政策、市场、技术、应用等方面的全面突破。目前我国学术界、产业界、行业部门在人工智能发展方面各自为政的倾向比较明显，数据资源开放共享不够，缺少对行业资源的有效整合。相比而言，美国已经形成了全社会、全场景、全生态协同互动的人工智能协同创新体系，军民融合和产学研结合都做得很好。我国应在体制机制方面进一步改革创新，建立“军、政、产、学、研、用”一体的人工智能协同创新体系。例如，国家进行顶层设计和战略规划，举全国优势力量设立军事智能的研发和应用平台，提供“人工智能+X”行业融合、打破行业壁垒和行政障碍的激励政策；科技龙头企业引领技术创新生态建设，突破人工智能的重大技术瓶颈；高校科研机构进行人才培养和原始创新，着力构建公共数据资源与技术平台，共同建设若干标杆性的应用创新场景，推动成熟人工智能技术在城市、医疗、金融、文化、农业、交通、能源、物流、制造、安全、服务、教育等领域的深度应用，建设低成本高效益广范围的普惠型智能社会。\n\n（五）加快创新人才的教育培养。发展人工智能关键在人才，中高端人才短缺已经成为我国人工智能做大做强的主要瓶颈。另外，我国社会大众的人工智能科技素养也需要进一步提升，每一个人都需要去适应人工智能时代的科技浪潮。在加强人工智能领军人才培养引进的同时，要面向技术创新和产业发展多层次培养人工智能创新创业人才。《新一代人工智能发展规划》提出逐步开展全民智能教育项目，在中小学阶段设置人工智能课程。目前人工智能科普活动受到各地学校的欢迎，但是缺少通俗易懂的高质量人工智能科普教材、寓教于乐的实验设备和器材、开放共享的教学互动资源平台。国家相关部门应高度重视人工智能教育领域的基础性工作，增加投入，组织优势力量，加强高水平人工智能教育内容和资源平台建设，加快人工智能专业的教学师资培训，从教材、教具、教师等多个环节全面保障我国人工智能教育工作的开展。\n\n（六）推动共担共享的全球治理。人工智能将重塑全球政治和经济格局，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能将进一步拉大发达国家和发展中国家的生产力发展水平差距。美国、日本、德国等通过人工智能和机器人的技术突破和广泛应用弥补他们的人力成本劣势，希望制造业从新兴国家回流发达国家。目前看，我国是发展中国家阵容中唯一有望成为全球人工智能竞争中的领跑者，应采取不同于一些国家的“经济垄断主义、技术保护主义、贸易霸凌主义”路线，尽快布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合国家“一带一路”战略，向亚洲、非洲、南美等经济欠发达地区输出高水平、低成本的“中国智造”成果、提供人工智能时代的中国方案，为让人工智能时代的“智能红利”普惠人类命运共同体做出中国贡献！\n\n（七）制定科学合理的法律法规。要想实实在在收获人工智能带来的红利，首先应保证其安全、可控、可靠发展。美国和欧洲等发达国家和地区十分重视人工智能领域的法律法规问题。美国白宫多次组织这方面的研讨会、咨询会；特斯拉等产业巨头牵头成立OpenAI等机构，旨在以有利于整个人类的方式促进和发展友好的人工智能；科研人员自发签署23条“阿西洛马人工智能原则”，意图在规范人工智能科研及应用等方面抢占先机。我国在人工智能领域的法律法规制定及风险管控方面相对滞后，这种滞后局面与我国现阶段人工智能发展的整体形势不相适应，并可能成为我国人工智能下一步创新发展的一大掣肘。因此，有必要大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法规环境。\n\n（八）加强和鼓励人工智能社会学研究。人工智能的社会影响将是深远的、全方位的。我们当未雨绸缪，从国家安全、社会治理、就业结构、伦理道德、隐私保护等多个维度系统深入研究人工智能可能的影响，制定合理可行的应对措施，确保人工智能的正面效应。应大力加强人工智能领域的科普工作，打造科技与伦理的高效对话机制和沟通平台，消除社会大众对人工智能的误解与恐慌，为人工智能的发展营造理性务实、积极健康的社会氛围。\n\n六、结束语\n\n人工智能经过60多年的发展，进入了创新突破的战略机遇期和产业应用的红利收获期，必将对生产力和产业结构以及国际格局产生革命性影响，并推动人类进入普惠型智能社会。但是，我们需要清醒看到通用人工智能及人工智能的整体发展仍处于初级阶段，人工智能不是万能，人工智能还有很多“不能”。我们应当采取理性务实的发展路径，扎实推进基础研究、技术生态、人才培养、法律规范等方面的工作，在开放中创新，在创新中发展，全速跑赢智能时代，着力建设人工智能科技强国！\n\n（主讲人系中国科学院院士）\n\n编 辑： 王伟\n\n责 编： 张绍敏\n\n[<< 返回首页](../../../)\n\n#### 相关文章\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'http://www.npc.gov.cn/npc/c12434/c541/201905/t20190521_268525.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9980122, 'save_path': None}}, {'paper_id': '', 'title': '[PDF] 现代人工智能：本质、途径和方向', 'authors': [], 'abstract': '现代人工智能：本质、途径和方向 张志华 北京大学数学科学学院，北京市海淀区颐和园5 号 100871 摘要：现代人工智能是通过机器学习及由其而发展起来的计算机视觉、自然语言处 理和语音识别技术来实现多模态数据融合的现实交互。数学上，人工智能是试图求 解具有组合结构的高维复杂问题，从而如何克服维数诅咒而利用维数祝福，核心要 素在于解决表示、计算和对齐问题。人工智能主要处理识别、决策和生成三大任 务，这和机器学习的三大学习范式有监督学习、强化学习和无监督学习相一致。推 断思维和算法思维相结合是研究问题途径，而利用数据的分布信息和问题的结构信 息可以有效帮助我们分析和设计算法。该篇文章将试图讨论了现代人工智能的本 质、技术路线以及一些未来研究方向。 一、引言 AlphaGo、AlphaFold、ChatGPT 和Sora 等人工智能产品相继发布震动了整个科技界， 同时由于其将可能给普通大众的生活带来深刻的影响，也引起了社会各界的广泛关注和讨 论。以多模态异构数据为基座的通用人工智能技术成为现实的趋势越来越大。人工智能是 指系统或智能体试图模拟或拥有人类的行为、思维和智能，虽然有不同途径期望通向人工 智能，但这里我们只关注数学和工程相结合的技术路线。在这篇文章，我主要阐述下面几 个内容：第一，现代的人工智能的本质是什么。第二，现在人工智能的一些主要的研究思 路和途径。第三，将讨论一些可能的研究方向。最后是回顾和总结。 二、人工智能的本质 首先，我们自然会问人工智能基础性的问题：什么是智能？《人工智能现代方法》 [1]一书从两种维度来定义智能，即人与理性，思想与行为。两个维度就有四种组合。但 是就我们现在所看到的人工智能技术，我更愿意把它定义为模拟人的行为和思维的信息处 理系统。因此我们主要关注是：计算机和统计学深度融合的数据科学方法，以及数学和工 程相结合的机器学习技术。 我们知道，图灵测试被广泛用于智能测试，但这是对智能的一种定性描述，迄今为止 并没有一种对智能的定量描述。所以我们设想，“智能”是否存在一种定量的、严谨的数 学定义，比如，象熵是一种用来量化不确定性的严格数学定义一样。或者，模仿统计学中 的p-value，给出智能的一种度量。我们知道，不同的p-value 可以反映对于假设检验结 果证据的度量。最近我们看到，出现了一些像无人驾驶一样对智能分级的定义，像 DeepMind 就提出来AGI(Artificial General Intelligence，通用人工智能)的一种分级 的定义。但现在我反而觉得，定性的描述并不见得是坏事，定量描述反而有可能把智能给 束约了，而定性描述则有可能让智能无远弗届，更富有遐想，更富有创造性。 图1：人工智能的发展历程 其次，我们来回顾人工智能的发展历程[1]。人工智能从1952 年发展到现在，可以把 它划分为下面几个时期：概念人工智能、玩具人工智能、统计人工智能、真实人工智能、 通用人工智能。第一个时期是诞生期，也就是人工智能概念的提出。第二个时期用直接的 搜索方式实现人工智能玩具任务。第三个时期尝试着解决较为复杂任务，是它的崛起期， 以基于规则的学习或者专家系统为代表，对应着计算机科学中的数据结构与算法发展。然 后是连接主义思想提出，神经网络模型兴起，但是由于计算机能力的限制，神经网络在这 时期很快地落入了低谷，被基于核技术(kernel trick)的支撑向量机所取代，由此统计机 器学习方法复兴，即利用统计数据加算法的思想来发展人工智能。在2010 年左右，大数 据驱动的深度神经网络崛起产生了革命性的突破。从2020 年到现在，又涌现了基于生成 模型的通用人工智能，这导致了人工智能发展的新阶段。 从人工智能发展历程，我们可以从两个角度来分析。第一，我们发现整个人工智能的 发展可以看成怎么解决搜索问题的过程，开始是利用暴力搜索，而后希望采取高级搜索来 寻找精确解。因为我们面临的要解决的问题会越来越复杂，寻找精确解不太可行，只好采 取近似搜索的方法。所以使用优化算法，随机算法，以及更为广泛的学习方法。第二，从 如何处理知识表示的角度看待人工智能，这触及到了人工智能的本质。基于规则学习是期 望把人类对事物的理解形式化，从而机器能够有效和人类认知对齐而达到智能的目的。迄 今为止这个路径没有获得成功，大家转而采取较为可行的数据统计的方法，即用统计数据 来代表知识表示，然后在数据上面运行算法。而深度神经网络则被发现提供了一个统计数 据和系统的认知对齐的表示，使得系统可以更为有效地进行端对端学习。强化学习则被用 来把系统的输出结果同人类的价值对齐。 我们看到技术思路的改变对人工智能的发展起到了关键作用。这种思路的转变也存在 于其他领域，产生了一个非常有趣的异曲同工现象。比如，模式识别、自然语言处理、语 音识别、视觉处理等都利用统计方法获取了巨大的成功，此外，从统计学的数据建模到计 算机的算法建模兴起，而人工智能则从机器学习中找到到了新的可行路径。 根据人工智能的发展历史，我们可以来总结人工智能实际在做什么。我理解，人工智 能主要是要处理三个任务：识别（我们可以把识别看做搜索的一个高级形态），决策和生 成。而这个三个任务刚好又和机器学习的三大学习范式：有监督学习、强化学习和无监督 学习是相一致的。实现人工智能的关键主要包含三个技术要素：表示、计算和对齐。 现代人工智能技术我认为大致可以分成两个主要代表性方式。第一，以OpenAI 大语 言生成模型为代表的通用智能系统。第二，以DeepMind 为代表的科学研究的赋能范式， 即科学研究的自动化方法。 第一个方式包括大模型构架、数据和算法等。大语言模型主要利用语言数据，而现在 则希望使用语言、图像和音频等融合的多模态异构数据。考虑到，计算机视觉、自然语言 处理和语音识别等也是由机器学习发展起来的。所以，现代人工智能可以理解成是通过机 器学习及由其驱动而发展起来的计算机视觉、自然语言处理和语音识别等技术来实现多模 态数据的现实交互。 至于科学研究的赋能范式,DeepMind 或谷歌及其合作机构等最近做出了一系列突破性 的代表工作。比如，利用强化学习寻找矩阵相乘中利用加法运算来代替乘法运算[2]，从 而达到使用尽可能小的乘法运算的目的。这实际是个搜索匹配问题。第二个是蛋白质结构 预测AlphaFold [3]，它是在一个三维空间，或者在某个坐标系框架里，找到氨基酸序列 的一个坐标对应，当然这里需要满足氨基酸序列原有的结构信息，因此，是在一个约束体 系里找到一个位置对应。第三个是芯片设计[4]。这是一个序贯的决策或者一个有顺序关 系的排列组合问题。此外，在数学研究中通过AI 辅助去找到一些证明启示或新的数学规 律[5,6],以及欧几里得平面几何数学问题的自动化证明[7]。 从这几个例子我们可以归纳：人工智能可以描述为如何求解具有组合结构的高维复杂 问题。第一，问题有组合或离散结构的，比如，对应关系、顺序关系、或稀疏特性等。第 二，它是高维的，通常规模也很大。我们需要从满足这种结构的不同组合中找到一个最佳 的方案或者代价最小的解。这是人工智能的数学上的一个描述，因此，重点是如何解决维 数诅咒和规模可扩展性问题。 三、人工智能的途径 正如前面所说的，人工智能蕴含的关键数学问题可以描述为如何求解具有组合结构的 高维复杂问题。为了求解问题，有两个里程碑的思想被提出。一是引入了不确定性。因为 我们面对的问题无论是规模和维度都是巨大的，求其精确解是不可行的，因此近似解是一 种必然。不确定性机制可以为寻找有效的近似解提供潜在途径，比如Monte Carlo 树搜索 和强化学习在AlphaGo 中的成功应用。不确定性产生了众所周知的“探索与利用”权衡问 题。二是数据驱动方法。这是因为数据的获取变得容易，且规模越来越大，同时数据表示 和处理的算法不断在进步，比如深度神经网络的崛起。数据驱动方法则伴随着“信息与计 算”权衡问题。 总的来说，是把不确定性和数据驱动这两种思路融合在一起来求解高维复杂的问题。 本质上，我们是要利用机器学习方法。机器学习是从数据中得出结论的算法。因此我们希 望数据尽可能多，希望知道数据的内在统计性质或者统计分布。在数据或者信息层面，数 据越多，越可能理解数据潜在的分布。在计算方面，有了数据，我们就在其上运行算法做 推理。所以这里就存在一个统计有效性和计算有效性之间的权衡。 所以人工智能的关键科学问题，我们可以概括为：第一，我们希望要设计尽可能高效 地使用我们的资源信息和计算的算法，从而为实际问题提供一种可行的解决方案。第二， 我们希望了解何时信息和计算有效的算法是不存在的，也就是建立不可行的结果，即算法 的应用边界。 具体来说，我们要面对很多问题：首先是学习的误差。也就是什么样的规模能达到什 么样的精度。然后是在迭代的时候能不能找到一个最优解，最优解的收敛率是什么。我们 往往采取分布式的计算方式，所以还有计算、通讯等问题。另外大家普遍关注隐私问题、 公平性问题、偏见性问题等。 我们要从样本有效性和计算有效性两方面来研究这些问题。样本有效性推断是统计学 的一个经典主题，而计算有效算法是计算机科学研究的核心课题。但是现在我们是要把这 两者结合在一起，而不是把他们孤立地研究。 从算法的角度，问题的结构是很重要的，数据的分布也是很重要的。所以我们尽可能 要利用问题的结构，同时也要利用数据的分布信息，利用两者来设计算法。采用离散的和 连续的、全局的和局部的、对抗的和合作的等这些更现代的观点来设计和分析算法，这也 可能会带来一些新的洞察。 让我们来看看机器学习。机器学习起源于计算机科学，但它跟统计学是一脉相承的, 都是利用算法从数据中得出结论[8]。经典统计学偏重于方法论的提出，而机器学习则重 于计算工具的开发。机器学习更关注分类或者聚类，即它的关注侧重离散问题。而统计学 侧重于回归或者密度估计等连续问题。现代机器学习和统计学通常要通过一个优化算法来 求解模型，但他们和传统优化又不一样。传统的优化往往只关注于算法是否找到了最优 解，以及算法的收敛性和收敛率。但是机器学习更关注找到了一个最优解之后的模型性 能，即模型在未来数据里的泛化性。所以从这个角度可以将机器学习理解为优化和泛化的 统一。 机器学习主要有四个非常重要的因素：泛化、计算、表示和归因。泛化性是指未知数 据上的表现。对于有监督的学习，泛化性是预测的结果，而无监督学习的泛化性体现在数 据生成的质量上。所有的问题都要通过计算去求解，所以第二要素是计算。统计学家比较 关注归因，即了解到底是哪些输入特征对输出结果产生了关键的作用，从而模型具有可解 释性。 这里我把重点放在表示或表征上。因为我认为表示应该是现代机器学习或者人工智能 的核心和关键。一个好的表示有如下特征：适合预测，因为我们的目的是预测；适合于计 算，因为结果是要通过计算来获得的。如果这个表示还适合于归因，那就更好了。所以自 然地想到有两种表示：一种是比较经济性的表示，另外一种是过参数化的表示。因为通过 数据降维，经济性的表示当然会带来一些计算的便利，但可能会制约了这个模型的表示能 力。一个高维的或者过参数化模型的表示能力会强，但会带来计算上的著名维数诅咒问 题。但维数越高，表示越强，预测能力随之也越好，带来所谓的维数祝福。比如如果在低 维不能做分类，但在高维里，它往往是容易分类的。既要克服维数诅咒，又要利用维数祝 福，在这两者之间找到一种有效的解决方法是机器学习的最核心思想。 一个自然的思路是宽度表示，机器学习领域由此发展起了核方法。核方法的思想将原 始数据映射到一个高维特征空间，然后通过这个特征空间的内积运算，可以有效地避免了 高维特征上的直接计算。这个想法跟统计学的非参方法是一致的。我们知道最重要的一个 机器学习方法叫核SVM。这可以理解成宽度表示的求和模型，宽度表示的可解释性良好 的。但它是一个存粹数学上抽象起来的技术，不能够对问题的物理层面进行有效刻画，所 以它没法用于生成真实数据，如图像和语言。 所以我们想是否可以利用某种深度表示，能够达到数据的物理表示。随机森林方法是 一个最直接的深度方法。而深度神经网络作为一种数据表示技术由此而崛起。它可以解决 维数诅咒问题，同时又能对数据进行物理层面建模。 我们来回顾深度学习的一些关键技术[9]。深度学习自产生以后，开发了一些重要实 现技术，如卷积、ReLU 激活函数、ResNet、Attention、 U-type 结构的编码和解码等。 其次可以用BP 去算梯度，利用SGD 或Adam 这些方法训练参数。在稳定执行上有Dropout 和Batch Normalization 等技术。更为关键的，GPU 刚好适合深度神经网络的并行训练。 所以我们认为深度学习是目前最有效的一种把维数诅咒变为维数祝福，同时又能解决物理 建模的技术。它是通过算法的思路，而不是基于形式化的思路来做表示。 我们关注的是数据表示。但是我们同样需要注意到求解的问题本身以及求解算法也有 表示的问题。算法的表示可以理解成数学上的描述。如果一个问题能够在数学上把它表述 出来，同时对这个算法有一个数学上的表示，那么就有了解决方案。强化学习提供了这种 表示[10]。所以我们可以将强化学习理解成在问题和算法层面的一种表示技术。具体地， 它使用马尔科夫决策过程给我们提供了一种表示的数学框架，而Bellman 最优性方程提供 了求解保证，即基于不动点理论导致了的价值迭代和策略优化方法。 深度学习和强化学习构成了现代人工智能的两翼。深度学习提供了多模态数据表示的 潜在途径，而强化学习提供了一种算法的表示。深度学习还从数学角度提供了一种非常强 大的非线性逼近能力。强化学习同样体现了一种在线决策、序贯决策的思路。而深度学习 与强化学习的结合为现代人工智能赋予了巨大的可能。当然现在大家都在说人工智能可解 释性差，所以自然想到因果学习。因果学习具有一种能很好地解释内在关系的方式，所以 可以考虑引入因果学习进来。但是目前看来，因果学习并没有达到象深度学习和强化学习 那样的成功。最重要的原因是因果学习还没有解决计算可扩展性的问题。 机器学习不仅仅是算法，而且也是工程。现代人工智能的第一次大突破是在深度学习 和计算机视觉中算法和工程的相结合的巅峰之作。最近的第二次突破，则可以理解成算法 和工程在自然语言处理和强化学习结合的又一个巅峰之作。机器学习系统实际上已成为一 个非常重要的研究领域。 四、研究方向 回到学术领域，存在哪些潜在的研究方向。人工智能存在三个层面：算法、应用、基础理 论。具体地，第一，如何做？提出和开发新的模型、技术、算法和场景。AlphaGo、 AlphaFold、ChatGPT 和Sora 所包含的技术不会是终点，新的技术和算法会不断地被提 出。第二，如何用？寻找人工智能更广泛的应用，针对一些特定的应用领域或场景制定方 案。第三，为什么？分析它的运行机理。前面提到了机理应该包含探索和利用权衡、信息 和计算权衡、以及统计有效性和计算有效性之间的权衡等基础性问题。为理解问题的计算 属性、统计属性和科学属性之间差异提供洞察。现在我尝试给出一些更为具体的研究方向 或问题。 基于数据驱动的人工智能算法。首先，我们更希望是混合的数据驱动方法，结合随机和对 抗的思想，能更好地适应信息约束和目标结构的信息。此外，一方面我们希望计算数据规 模很大，但如果存储全部数据则是不可行的。所以我们希望利用在线的方法或更为一般的 自适应方法更有效地利用数据。我认为有几点特别值得关注：第一是高维随机优化的统计 推断。第二是高维随机在线算法。我们一般认为随机或者在线的算法主要是来解决数据量 的问题，更为挑战的是如何去设计一些高效的算法来处理高维且数据量大的问题。第三是 高维采样，在我们面对高维或离散问题时，比如在扩散生成模型中，如何利用蒙特卡罗等 方法找到一个有效的采样方法。第四是分布或鲁棒马尔科夫决策过程。第五是算法的下界 理论分析，刚才说过，给定了有效的资源或算力时，能否给出算法的下界，从而避免不必 要的失败尝试。理论计算机界正试图建立不同下界分析方法之间的内在联系，从而 希望可以形成一个统一的分析框架。 大语言模型的一些重要问题。第一是基础模型的结构和训练算法，现在模型普遍采用 Transformer，训练算法采用AdamW，有可能存在其他更好模型和算法。第二，制约我国人 工智能发展最重要的问题是中文语言的数据质量和中文分词技术，我们现在很多时候直接 套用英文分词技术到在中文上，因为中文有自己的特性，这肯定是不能完全适用的。当然 还有对齐和精调、模型的评估等。我们同样需要关注大模型的机理，我们知道的scaling law、压缩理论是大模型的一些值得关注的基本问题。最后，一般研究机构是没有能力来 搭建大语言模型，所以当然会想到要研究小型化模型，只有小型化才能使其具有更大的实 用性。此外，我们可能看到新闻，Richard Sutton 等人打算利用在线的思路构架通用智能 系统，因为在线可以避免大数据的存储和计算代价。 强化学习的一些重要问题。我们知道强化学习在游戏类的应用非常成功，因为游戏问题的 规则非常明确。而面对实际的应用问题，虽然在大语言模型中强化学习可能有很大的作 用，但在很多问题中强化学习的潜力远远没有被挖掘出来。所以我认为强化学习有以下几 点值得关注：第一是能否开发出并行化的计算框架。强化学习是一个序贯决策过程，天然 和并行不相配。但是只有并行才能够从根本上解决其计算瓶颈。第二是稳定性良好的策略 优化算法。强化学习需要随机采样，所以其算法稳定性是非常重要的课题。第三，强化学 习一般有交互的过程，搭建通用友好的模拟平台很重要。当然最重要的是深度强化学习的 更广泛地应用。 扩散生成模型的一些重要问题。扩散生成模型是目前最活跃的AIGC 方向。我认为值得研 究的方向首先是多模态数据生成。目前单一数据生成较为成熟，但多模态数据生成仍有待 研究。第二是扩散生成模型的性能和训练不稳定性，这是一个很重要的研究方向。第三是 扩散模型怎样去和大语言模型相结合。 最后我想谈一点富有远景的研究方向。我们可以回顾一下人工智能最近十余年的两个最重 大的突破，首先在2010 年左右，深度神经网络在视觉图像的应用产生了第一个人工智能 的里程牌突破，我把它理解为视觉+深度学习。第二里程碑工作ChatGPT 则是在前一个突 破基础上，深度强化学习在自然语言领域的成功，我理解为语言+强化学习或者多模态数 据+深度强化学习。那么我们可以思考下一个突破可能会是什么。我大胆地预测，如果要 产生真正的通用人工智能，很可能是利用贝叶斯技术来进行信念推理。贝叶斯推理包括经 验贝叶斯、概率图模型等。因为信念(belief)是更接近智能的因素，所以我认为在大语言 模型基础上信念+贝叶斯学习将值得期待，让我们拭目以待。 五、回顾和思考 著名的统计学家和机器学习主要奠基人Leo Breiman 在他著名两种文化建模论文[11] 中提出了和反思了数据建模的文化和算法建模的文化[12]。而现代人工智能则是将这两种 文化深度融合。既要数据建模，也要算法建模，是两个文化的结合而不是分叉。另外 Breiman 在文章里还提到他的三个关切：导致不相关的理论和有问题的科学结论(“Led to irrelevant theory and questionable scientific conclusion”)，阻止统计学家使用 更为合适的算法模型(“Kept statisticians from using more suitable algorithmic models”)，阻碍统计学家研究令人兴奋的新问题（“Prevented statisticians from working on exciting new problems”）。这些关切对今天我们发展人工智能仍然是真知 灼见。我们普遍将我国人工智能的发展现状归结于对数学基础的重视或数学家参与程度不 够。但我认为一定要了解人工智能和计算机领域真正关心的问题，只有真正理解其核心所 在，才能有的放矢，才能对人工智能乃至本学科起到实质性的促进作用。 人工智能和计算机领域真正关心的问题：建立模型，设计算法，揭示机理。而且他们 也是有优先级的，第一，我认为目前理论分析肯定是要次于模型的建立和计算算法的设 计。先产生效果再考虑理论，不能脱离实际效果空谈无用的理论。第二，存在性的结果总 是要小于构造性的结果。相比存在性的结果，我们更希望有构造性的算法。第三，大家总 说人工智能不可解释，但归因的解释没有模型的机理来得更重要。对于大模型而言，如果 能将其压缩理论分析清楚，这比究竟是哪个特征起作用要重要。第四，模型的机理没有科 学对齐更迫切，系统输出结果要与问题的本质属性对齐。统计属性要与科学属性相对齐， 系统的价值要与人的价值对齐。 现代计算机视觉的建立者David Marr 把视觉视为一个信息处理系统，提出了理解该 系统的三个不同层次。第一个是物理和执行层次；第二是算法和表示层次；第三个层次是 计算层面。可惜天妒其才，他英年早逝，未能完成他的著作“Vision”[13]。但正如 Marvin Minsky 认为的，Marr 没有真正碰触知识表示问题，未能为他的视觉系统的知识表 示提出好的想法。他的合作者Tomaso Poggio 帮他完成了著作，Poggio 认为在计算层次上 面应该再加上一个学习层次。Marr 关于视觉的三层次的思想同样适用于人工智能，我们也 可以把人工智能看成模拟人类行为和思维的信息处理系统。它有三个层次或要素：表示、 计算和对齐。深度学习和强化学习分别在数据层面和算法层面为我们提供了有效的表示途 径。随机优化算法和计算基座等帮助解决计算问题。最近人工智能技术在对齐层次也获得 突破性进展。实际上，表示也是一种对齐，可以理解表示是把统计数据与机器系统进行对 齐。因此，人工智能是把输入的统计数据与系统的价值对齐，而把系统的输出结果与人的 价值对齐，形成了一个对齐的闭环。 最后，让我们回溯20 世纪统计学的两位主要奠基者Ronald Fisher 和Jerzy Neyman 关于归纳推理（Inductive Inference）和演绎推理（Deductive Inference）的辩论 (The Fisher-Neyman Controversy) 。Fisher 相信统计学可以具有从样本到数据的归纳推 理能力[14,15]，即外推性，而Neyman 则认为只能从数据中进行演绎推理[16]，即内插。 这个著名辩论可以帮助我们来理解大语言模型是否可能会发生涌现。特别是，我们注意到 [7]结合了两种推理来利用AI 求解奥数几何题取得了成功。我有一个很主观的看法， Neyman 是坚定的频率派大师，他认为统计过程的选择应该要基于误差的频率派概念。我们 知道虽然Fisher 也是频率学派的奠基者，但他不排斥贝叶斯，他其实也是经验贝叶斯的 开山鼻祖。贝叶斯赋予先验，利用后验信息推理，因此具有某种程度的外推能力。这也是 为什么我认为贝叶斯推断方法，特别是经验贝叶斯方法在人工智能的未来发展具有潜在作 用，值得我们关注。 总之，现代人工智能是数据建模和算法建模两种文化的深度融合，它本质上是一个模 拟人类行为和思维的信息处理系统，它试图集成归纳推理和演绎推理来让系统实现自主推 理的能力。有境界则自成高格，自有名作，学科能常青在此。当我们不解和疑惑时，可以 多读读这些经典，从中寻找启迪和灵感。空洞无物的炒作和造势或许能得到一时之利，但 再炫丽的泡沫总是要破灭的，唯思想永恒！ 参考文献 1. Stuart Russel and Peter Norvig. Artificial Intelligence: A Modern Approach (Fourth edition). Pearson, 2021. 2. Alhussein Fawzi et al. Discovering faster matrix multiplication algorithms with reinforcement learning. Nature, 610, 47-53 2022. 3. John Jumper et al. (2021). Highly accurate protein structure prediction with AlphaFold, Nature, 596, 583-589. 4. Azalia Mirhoseini et al. A Graph Placement Methodology for Fast Chip Design, Nature, Vol 594, 207-2012, 2021. 5. Alex Davies et al. Advancing mathematics by guiding human intuition with AI, Nature, Vol 600, 70-74, 2021. 6. Bernarding Romera-Paredes et al. Mathematical discoveries from program search with large language models. Nature, 1-10, 2023. 7. Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. Solving Olympiad geometry without human demonstrations. Nature, 625, 476-482 (2024). 8. Bradley Efron and Trevor Hastie. Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. The Cambridge University Press, 2016. 9. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. The MIT Press, 2016. 10. Richard S. Sutton and Andrew G. Barto. Reinforcement Learning (second edition). The MIT Press, 2018. 11. Leo Bregman. Statistical Modeling: The Two Cultures (with Discussion). Statistical Science, 2001. 12. Bradley Efron. Prediction, Estimation, and Attribution (with Discussion). JASA, 2020. 13. David Marr. Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. The MIT Press, 2010. 14. R A Fisher. The Logic of Inductive Inference, 1934. 15. R A Fisher. Statistical Methods and Scientific Inference, 1957. 16. Jerzy Neyman. ‘Inductive Behavior’ as a Basic Concept of Philosophy of Science, 1957.', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.math.pku.edu.cn/teachers/zhzhang/MAI2.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9941347, 'save_path': None}}, {'paper_id': '', 'title': '为何重视通用人工智能发展', 'authors': [], 'abstract': '为何重视通用人工智能发展\n\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  | 常见问题 |  |\n\n|  |  |  |\n| --- | --- | --- |\n|  | 开放目录 |  |\n|  | 按主题 |  |\n|  | 按机构 |  |\n|  | 区级单位 |  |\n|  | 历史数据 |  |\n|  | 有条件开放AI数据 |  |\n|  | 无条件开放AI数据 |  |\n|  | 往年开放数据 |  |\n|  | 多模态数据专区 |  |\n\n* [需求反馈](../../hdfk/index.htm)\n* [开放协议](../../hdfk/index.htm)\n* [提交成果](../../hdfk/index.htm)\n* [纠错申诉](../../hdfk/index.htm)\n\n* [登录](/cms/web/bjdata/sso/ssoLogin.jsp)\n\n搜本网\xa0\xa0\n一网通查\n\n全站检索\n\n[登录](/cms/web/bjdata/sso/ssoLogin.jsp)\n[需求反馈](../../hdjl/wjtc/index.htm)\n[开放协议](../../hdjl/cjwt/index.htm)\n[提交成果](../../hdjl/tjappyy/index.htm)\n[纠错申诉](../../hdjl/jcjb/index.htm)\n\n* [首页](../../index.htm)\n* [开放数据](../../zyml/kfml/index.htm)**+**\n\n  :   [开放目录](../../zyml/kfml/index.htm)\n  :   [按主题](../../zyml/azt/index.htm)\n  :   [按机构](../../zyml/ajg/index.htm)\n  :   [地理空间](../../dlkj/index.htm)\n  :   [往年开放数据](../../zyml/wnkfsj/index.htm)\n  :   [历史归档清单](https://data.beijing.gov.cn/docs/guidang.pdf)\n  :   [下架资源清单](https://data.beijing.gov.cn/docs/xiajia.pdf)\n  :   [多模态数据专区](../../zyml/dmtsjzq/index.htm)\n* [数据登记](#)\n* [授权开放](../../dxsjfb/index.htm)**+**\n\n  :   [历届竞赛回顾](../../dxsjfb/index.htm)\n  :   [授权运营平台](https://www.bjzhengxin.com.cn/index)\n* [开放计划](../../jkfb/index.htm)**+**\n\n  :   [历史开放计划](https://data.beijing.gov.cn/hdjl/kfqs/index.htm)\n  :   [无障碍数据](https://data.beijing.gov.cn/wzazt/)\n  :   [信用开放数据](https://data.beijing.gov.cn/xyzt/)\n* [数据伙伴](https://data.beijing.gov.cn/hzhbzt/)**+**\n\n  :   [开放京津冀](https://data.beijing.gov.cn/jjjzt/)\n  :   [产业伙伴计划](https://data.beijing.gov.cn/hzhbzt/)\n  :   [应用实践案例](../../appyy/index.htm)\n  :   [开放共性工具](../../gjfb/index.htm)\n* [政策动态](../index.htm)**+**\n\n  :   [数据开放](../zcfgsjkf/index.htm)\n  :   [标准指南](https://data.beijing.gov.cn/sjkfzxfw/index.htm)\n  :   [北京开放](index.htm)\n  :   [其他省市](../qtss/index.htm)\n* [互动反馈](../../hdfk/index.htm)\n\n搜本网\xa0\xa0\n一网通查\n\n全站检索\n\n* [首页](../../index.htm)\n* [开放数据](../../zyml/kfml/index.htm)\n\n  :   [开放目录](../../zyml/kfml/index.htm)\n  :   [按主题](../../zyml/azt/index.htm)\n  :   [按机构](../../zyml/ajg/index.htm)\n  :   [地理空间](../../dlkj/index.htm)\n  :   [往年开放数据](../../zyml/wnkfsj/index.htm)\n  :   [历史归档清单](https://data.beijing.gov.cn/docs/guidang.pdf)\n  :   [下架资源清单](https://data.beijing.gov.cn/docs/xiajia.pdf)\n  :   [多模态数据专区](../../zyml/dmtsjzq/index.htm)\n* [数据登记](#)\n* [授权开放](../../dxsjfb/index.htm)\n\n  :   [历届竞赛回顾](../../dxsjfb/index.htm)\n  :   [授权运营平台](https://www.bjzhengxin.com.cn/index)\n* [开放计划](../../jkfb/index.htm)\n\n  :   [历史开放计划](https://data.beijing.gov.cn/jkfb/kfqs/index.htm)\n  :   [无障碍数据](https://data.beijing.gov.cn/wzazt/)\n  :   [信用开放数据](https://data.beijing.gov.cn/xyzt/)\n* [数据伙伴](https://data.beijing.gov.cn/hzhbzt/)\n\n  :   [开放京津冀](https://data.beijing.gov.cn/jjjzt/)\n  :   [产业伙伴计划](https://data.beijing.gov.cn/hzhbzt/)\n  :   [应用实践案例](../../appyy/index.htm)\n  :   [开放共性工具](../../gjfb/index.htm)\n* [政策动态](../index.htm)\n\n  :   [数据开放](../zcfgsjkf/index.htm)\n  :   [标准指南](https://data.beijing.gov.cn/sjkfzxfw/index.htm)\n  :   [北京开放](index.htm)\n  :   [其他省市](../qtss/index.htm)\n* [互动反馈](../../hdfk/index.htm)\n\n## 当前位置： [首页](../../index.htm)» [政策法规](../index.htm)» 新闻动态-北京开放\n\n* 新闻动态-北京开放\n\n为何重视通用人工智能发展\n\n# 为何重视通用人工智能发展\n\n**作者：张凌寒（中国政法大学数据法治研究院教授）**\n\n\u3000\u3000中央政治局4月28日召开会议指出，要重视通用人工智能发展，营造创新生态，重视防范风险。人工智能概念诞生于20世纪50年代，在半个多世纪的发展历程中，由于受到智能算法、计算速度、存储水平等多方面因素的影响，人工智能技术和应用发展经历了曲折的发展过程。2023年初，以ChatGPT为代表的生成式人工智能引发广泛关注，人工智能正在从专用智能迈向通用智能，进入了全新的发展阶段。\n\n\u3000\u3000（一）\n\n\u3000\u3000习近平总书记强调，人工智能是引领这一轮科技革命和产业变革的战略性技术，具有溢出带动性很强的“头雁”效应。什么是通用人工智能？所谓通用人工智能是够处理更加广泛和复杂任务，并且可以向某个方向特化的人工智能。以ChatGPT为代表的生成式人工智能大模型在海量多源数据、多元应用和超算能力、算法模型的共同驱动下，强调通用学习和建立大规模训练模型的机器学习，获得强大的自我学习和自适应能力。在实际应用中，通用人工智能的组成部分被嵌入到智能助手、机器翻译、自动化客服等场景中，从而实现更加个性化、智能化、自适应的服务和应用。未来通用人工智能的实现将沿着这一思路展开。\n\n\u3000\u3000通用智能的发展引领了新一代的产业变革，也给经济社会生活带来深刻变革。首先，人工智能将带动大规模产业升级。人工智能技术的发展将持续推进传统产业逐渐走向数字化、智能化，许多新兴产业借助这一技术得到迅速发展。尤其在医疗、金融、教育、交通等领域，成熟的人工智能技术已经成为提高效率、优化体验、降低成本的重要手段。广泛的产业结构调整将带动全球经济结构的变化，加速科技企业的崛起，甚至影响世界经济格局。其次，人工智能发展也随之带来劳动力转移。人工智能技术的发展在导致部分传统行业岗位被自动化取代的同时，也会创造出更多的人工智能相关岗位。未来将会出现大规模的劳动力转移，就业结构也会产生变化。最后，人工智能与实体经济利好融合，将成为撬动产业转型的杠杆、引领转型方向的船舵和提供转型动力的引擎。无论是促进传统产业提质增效，还是培育新的经济增长点，都需要互联网、大数据、人工智能开辟更广阔的应用场景。与此同时，人工智能发展也不可避免带来安全风险。人工智能技术的发展给各国数据安全、网络安全等方面提出了更加严峻的挑战，掌握关键人工智能技术对国家整体安全意义重大。人工智能的发展还可能带来新的道德和伦理困惑，如何规范其应用、避免技术失控将成为行业持续关注的问题。\n\n\u3000\u3000（二）\n\n\u3000\u3000人工智能技术的出现，使得信息交互效率得到全面提升。民意的传递有了更广、更快的途径。利用智能技术分析和运用数据，搭建大数据民智平台，用创新的形式和丰富的载体汲取群众的智慧和力量、回应群众的期待。人工智能技术的合理运用，将进一步实现科学决策与民主决策的结合，有利于构建良好稳定的社会环境。\n\n\u3000\u30002018年习近平总书记在中央政治局集体学习中指出，要加强人工智能同保障和改善民生的结合，从保障和改善民生、为人民创造美好生活的需要出发，推动人工智能在人们日常工作、学习、生活中的深度运用，创造更加智能的工作方式和生活方式。如社区工作人员依托人工智能技术，将窗口与手机端相结合，打造有温度的数字化社区服务新模式。工作人员通过即时聊天软件等与孤寡老人建立联系，实时关注孤寡老人的身体、生活、安全等方面情况，定期打电话或上门看望，通过线上线下的工作模式，智能、高效开展服务工作。\n\n\u3000\u3000（三）\n\n\xa0 \xa0 \xa0 \xa0 原文链接：[为何重视通用人工智能发展](https://theory.gmw.cn/2023-06/09/content_36619831.htm)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://data.beijing.gov.cn/publish/bjdata/xydt/ljhd/d48b57e85cec47f0b608e27eaaeafc7c.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9462003, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:26:16,924 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:26:16,924 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:26:16,926 - __main__ - INFO - handle_download: downloaded=3
2026-02-02 20:26:16,926 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=3
2026-02-02 20:26:16,926 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能的创新发展与社会影响 - 中国人大网', 'authors': [], 'abstract': '当前位置：[首页](../../../ "首页")\xa0>\xa0[常委会专题讲座](../ "常委会专题讲座")\n\n## 十三届全国人大常委会专题讲座第七讲\n\n# 人工智能的创新发展与社会影响\n\n来源： 中国人大网\xa0\xa0浏览字号： [大](#) [中](#) [小](#) 2018年10月29日 10:26\n\n一、引言\n\n1956年人工智能（Artificial Intelligence，简称AI）的概念被正式提出，标志着人工智能学科的诞生，其发展目标是赋予机器类人的感知、学习、思考、决策和行动等能力。经过60多年的发展，人工智能已取得突破性进展，在经济社会各领域开始得到广泛应用并形成引领新一轮产业变革之势，推动人类社会进入智能化时代。美国、日本、德国、英国、法国、俄罗斯等国家都制定了发展人工智能的国家战略，我国也于2017年发布了《新一代人工智能发展规划》，发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏等地政府也相继出台推动人工智能发展的相关政策文件，社会各界对人工智能的重大战略意义已形成广泛共识。\n\n跟其他高科技一样，人工智能也是一把双刃剑。如何认识人工智能的社会影响，也有“天使派”和“魔鬼派”之分。“天使派”认为，人工智能领域的科技创新和成果应用取得重大突破，有望引领第四次工业革命，对社会、经济、军事等领域将产生变革性影响，在制造、交通、教育、医疗、服务等方面可以造福人类；“魔鬼派”认为，人工智能是人类的重大威胁，比核武器还危险，有可能引发第三次世界大战。2018年2月，牛津大学、剑桥大学和OpenAI公司等14家机构共同发布题为《人工智能的恶意使用：预测、预防和缓解》的报告，指出人工智能可能给人类社会带来数字安全、物理安全和政治安全等潜在威胁，并给出了一些建议来减少风险。\n\n总体上看，已过花甲之年的人工智能当前的发展具有“四新”特征：以深度学习为代表的人工智能核心技术取得新突破、“智能+”模式的普适应用为经济社会发展注入新动能、人工智能成为世界各国竞相战略布局的新高地、人工智能的广泛应用给人类社会带来法律法规、道德伦理、社会治理等方面一系列的新挑战。因此人工智能这个机遇与挑战并存的新课题引起了全球范围内的广泛关注和高度重视。虽然人工智能未来的创新发展还存在不确定性，但是大家普遍认可人工智能的蓬勃兴起将带来新的社会文明，将推动产业变革，将深刻改变人们的生产生活方式，将是一场影响深远的科技革命。\n\n为了客观认识人工智能的本质内涵和创新发展，本报告在简要介绍人工智能基本概念与发展历程的基础上，着重分析探讨人工智能的发展现状和未来趋势，试图揭示人工智能的真实面貌。很显然，在当下人工智能蓬勃发展的历史浪潮中如何选择中国路径特别值得我们深入思考和探讨。因此，本报告最后就我国人工智能发展态势、存在问题和对策建议也进行了阐述。\n\n二、人工智能的发展历程与启示\n\n1956年夏，麦卡锡（John McCarthy）、明斯基（Marvin Minsky）、罗切斯特（Nathaniel Rochester）和香农（Claude Shannon）等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能”这一概念，标志着人工智能学科的诞生。人工智能的目标是模拟、延伸和扩展人类智能，探寻智能本质，发展类人智能机器。人工智能充满未知的探索道路曲折起伏，如何描述1956年以来60余年的人工智能发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能60余年的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年-20世纪60年代初。人工智能概念在1956年首次被提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、LISP表处理语言等，掀起了人工智能发展的第一个高潮。\n\n二是反思发展期：60年代-70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入了低谷。\n\n三是应用发展期：70年代初-80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入了应用发展的新高潮。\n\n四是低迷发展期：80年代中-90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：90年代中-2010年。由于网络技术特别是互联网技术的发展，信息与数据的汇聚不断加速，互联网应用的不断普及加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年IBM深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念，这些都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年-至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器（Graphics Processing Unit，简称GPU）等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越科学与应用之间的“技术鸿沟”，图像分类、语音识别、知识问答、人机对弈、无人驾驶等具有广阔应用前景的人工智能技术突破了从“不能用、不好用”到“可以用”的技术瓶颈，人工智能发展进入爆发式增长的新高潮。\n\n通过总结人工智能发展历程中的经验和教训，我们可以得到以下启示：\n\n（一）尊重学科发展规律是推动学科健康发展的前提。科学技术的发展有其自身的规律，顺其者昌，违其者衰。人工智能学科发展需要基础理论、数据资源、计算平台、应用场景的协同驱动，当条件不具备时很难实现重大突破。\n\n（二）基础研究是学科可持续发展的基石。加拿大多伦多大学杰弗里·辛顿（Geoffrey Hinton）教授坚持研究深度神经网络30年，奠定人工智能蓬勃发展的重要理论基础。谷歌的DeepMind团队长期深入研究神经科学启发的人工智能等基础问题，取得了阿尔法狗等一系列重大成果。\n\n（三）应用需求是科技创新的不竭之源。引领学科发展的动力主要来自于科学和需求的双轮驱动。人工智能发展的驱动力除了知识与技术体系内在矛盾外，贴近应用、解决用户需求是创新的最大源泉与动力。比如专家系统人工智能实现了从理论研究走向实际应用的突破，近些年来安防监控、身份识别、无人驾驶、互联网和物联网大数据分析等实际应用需求带动了人工智能的技术突破。\n\n（四）学科交叉是创新突破的“捷径”。人工智能研究涉及信息科学、脑科学、心理科学等，上世纪50年代人工智能的出现本身就是学科交叉的结果。特别是脑认知科学与人工智能的成功结合，带来了人工智能神经网络几十年的持久发展。智能本源、意识本质等一些基本科学问题正在孕育重大突破，对人工智能学科发展具有重要促进作用。\n\n（五）宽容失败应是支持创新的题中应有之义。任何学科的发展都不可能一帆风顺，任何创新目标的实现都不会一蹴而就。人工智能60余载的发展生动地诠释了一门学科创新发展起伏曲折的历程。可以说没有过去发展历程中的“寒冬”就没有今天人工智能发展新的春天。\n\n（六）实事求是设定发展目标是制定学科发展规划的基本原则。达到全方位类人水平的机器智能是人工智能学科宏伟的终极目标，但是需要根据科技和经济社会发展水平来设定合理的阶段性研究目标，否则会有挫败感从而影响学科发展，人工智能发展过程中的几次低谷皆因不切实际的发展目标所致。\n\n三、人工智能的发展现状与影响\n\n人工智能经过60多年的发展，理论、技术和应用都取得了重要突破，已成为推动新一轮科技和产业革命的驱动力，深刻影响世界经济、政治、军事和社会发展，日益得到各国政府、产业界和学术界的高度关注。从技术维度来看，人工智能技术突破集中在专用智能，但是通用智能发展水平仍处于起步阶段；从产业维度来看，人工智能创新创业如火如荼，技术和商业生态已见雏形；从社会维度来看，世界主要国家纷纷将人工智能上升为国家战略，人工智能社会影响日益凸显。\n\n（一）专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定领域的人工智能技术（即专用人工智能）由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，因此形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域，统计学习是专用人工智能走向实用的理论基础。深度学习、强化学习、对抗学习等统计机器学习理论在计算机视觉、语音识别、自然语言理解、人机博弈等方面取得成功应用。例如，阿尔法狗在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，语音识别系统5.1%的错误率比肩专业速记员，人工智能系统诊断皮肤癌达到专业医生水平，等等。\n\n（二）通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。虽然包括图像识别、语音识别、自动驾驶等在内的专用人工智能领域已取得突破性进展，但是通用智能系统的研究与应用仍然是任重而道远，人工智能总体发展水平仍处于起步阶段。美国国防高级研究计划局（Defense Advanced Research Projects Agency，简称DARPA）把人工智能发展分为三个阶段：规则智能、统计智能和自主智能，认为当前国际主流人工智能水平仍然处于第二阶段，核心技术依赖于深度学习、强化学习、对抗学习等统计机器学习，AI系统在信息感知（Perceiving）、机器学习（Learning）等智能水平维度进步显著，但是在概念抽象（Abstracting）和推理决策（Reasoning）等方面能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n（三）人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，在其2017年的年度开发者大会上，谷歌明确提出发展战略从“Mobile First”（移动优先）转向“AI First”（AI优先）；微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿，麦肯锡报告2016年全球人工智能研发投入超300亿美元并处于高速增长，全球知名风投调研机构CB Insights报告显示2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n（四）创新生态布局成为人工智能产业发展的战略高地。信息技术（IT）和产业的发展史就是新老IT巨头抢滩布局IT创新生态的更替史。例如，传统信息产业IT（Information Technology）代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网IT（Internet Technology）代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等，目前智能科技IT（Intelligent Technology）的产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动AI技术生态的研发布局，全力抢占人工智能相关产业的制高点。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理GPU服务器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。在技术生态方面，人工智能算法、数据、图形处理器（Graphics Processing Unit，简称GPU）/张量处理器（Tensor Processing Unit，简称TPU）/神经网络处理器（Neural network Processing Unit，NPU）计算、运行/编译/管理等基础软件已有大量开源资源，例如谷歌的TensorFlow第二代人工智能学习系统、脸书的PyTorch深度学习框架、微软的DMTK分布式学习工具包、IBM的SystemML开源机器学习系统等；此外谷歌、IBM、英伟达、英特尔、苹果、华为、中国科学院等积极布局人工智能领域的计算芯片。在人工智能商业和应用生态布局方面，“智能+X”成为创新范式，例如“智能+制造”、“智能+医疗”、“智能+安防”等，人工智能技术向创新性的消费场景和不同行业快速渗透融合并重塑整个社会发展，这是人工智能作为第四次技术革命关键驱动力的最主要表现方式。人工智能商业生态竞争进入白热化，例如智能驾驶汽车领域的参与者既有通用、福特、奔驰、丰田等传统龙头车企，又有互联网造车者如谷歌、特斯拉、优步、苹果、百度等新贵。\n\n（五）人工智能上升为世界主要国家的重大发展战略。人工智能正在成为新一轮产业变革的引擎，必将深刻影响国际产业竞争格局和一个国家的国际竞争力。世界主要发达国家纷纷把发展人工智能作为提升国际竞争力、维护国家安全的重大战略，加紧积极谋划政策，围绕核心技术、顶尖人才、标准规范等强化部署，力图在新一轮国际科技竞争中掌握主导权。无论是德国的“工业4.0”、美国的“工业互联网”、日本的“超智能社会”、还是我国的“中国制造2025”等重大国家战略，人工智能都是其中的核心关键技术。2017年7月，国务院发布了《新一代人工智能发展规划》，开启了我国人工智能快速创新发展的新征程。\n\n（六）人工智能的社会影响日益凸显。人工智能的社会影响是多元的，既有拉动经济、服务民生、造福社会的正面效应，又可能出现安全失控、法律失准、道德失范、伦理失常、隐私失密等社会问题，以及利用人工智能热点进行投机炒作从而存在泡沫风险。首先，人工智能作为新一轮科技革命和产业变革的核心力量，促进社会生产力的整体跃升，推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域发展积极正面影响。与此同时，我们也要看到人工智能引发的法律、伦理等问题日益凸显，对当下的社会秩序及公共管理体制带来了前所未有的新挑战。例如，2016年欧盟委员会法律事务委员会提交一项将最先进的自动化机器人身份定位为“电子人（electronic persons）”的动议，2017年沙特阿拉伯授予机器人“索菲亚”公民身份，这些显然冲击了传统的民事主体制度。那么，是否应该赋予人工智能系统法律主体资格？另外在人工智能新时代，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题都需要我们从法律法规、道德伦理、社会管理等多个角度提供解决方案。\n\n由于人工智能与人类智能密切关联且应用前景广阔、专业性很强，容易造成人们的误解，也带来了不少炒作。例如，有些人错误地认为人工智能就是机器学习（深度学习），人工智能与人类智能是零和博弈，人工智能已经达到5岁小孩的水平，人工智能系统的智能水平即将全面超越人类水平，30年内机器人将统治世界，人类将成为人工智能的奴隶，等等。这些错误认识会给人工智能的发展带来不利影响。还有不少人对人工智能预期过高，以为通用智能很快就能实现，只要给机器人发指令就可以干任何事。另外，有意炒作并通过包装人工智能概念来谋取不当利益的现象时有发生。因此，我们有义务向社会大众普及人工智能知识，引导政府、企业和广大民众科学客观地认识和了解人工智能。\n\n四、人工智能的发展趋势与展望\n\n人工智能经过六十多年的发展突破了算法、算力和算料（数据）等“三算”方面的制约因素，拓展了互联网、物联网等广阔应用场景，开始进入蓬勃发展的黄金时期。从技术维度看，当前人工智能处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有数据、能耗、泛化、可解释性、可靠性、安全性等诸多瓶颈，创新发展空间巨大，从专用到通用智能，从机器智能到人机智能融合，从“人工+智能”到自主智能，后深度学习的新理论体系正在酝酿；从产业和社会发展维度看，人工智能通过对经济和社会各领域渗透融合实现生产力和生产关系的变革，带动人类社会迈向新的文明，人类命运共同体将形成保障人工智能技术安全、可控、可靠发展的理性机制。总体而言，人工智能的春天刚刚开始，创新空间巨大，应用前景广阔。\n\n（一）从专用智能到通用智能。如何实现从狭义或专用人工智能（也称弱人工智能，具备单一领域智能）向通用人工智能（也称强人工智能，具备多领域智能）的跨越式发展，既是下一代人工智能发展的必然趋势，也是国际研究与应用领域的挑战问题。2016年10月美国国家科学技术委员会发布了《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。DeepMind创始人戴密斯·哈萨比斯（Demis Hassabis）提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年7月成立了通用人工智能实验室，100多位感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n（二）从人工智能到人机混合智能。人工智能的一个重要研究方向就是借鉴脑科学和认知科学的研究成果，研究从智能产生机理和本质出发的新型智能计算模型与方法，实现具有脑神经信息处理机制和类人智能行为与智能水平的智能系统。在美国、欧盟、日本等国家和地区纷纷启动的脑计划中，类脑智能已成为核心目标之一。英国工程与自然科学研究理事会EPSRC发布并启动了类脑智能研究计划。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。人机混合智能得到了我国新一代人工智能规划、美国脑计划、脸书（脑机语音文本界面）、特斯拉汽车创始人埃隆·马斯克（人脑芯片嵌入和脑机接口）等的高度关注。\n\n（三）从“人工+智能”到自主智能系统。当前人工智能的研究集中在深度学习，但是深度学习的局限是需要大量人工干预：人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据（非常费时费力）、用户需要人工适配智能系统等。因此已有科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类AI”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低AI人员成本。\n\n（四）人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、材料等传统科学的发展。例如，2018年美国麻省理工学院启动的“智能探究计划”（MIT Intelligence Quest）就联合了五大学院进行协同攻关。\n\n（五）人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来十年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，在现有基础上能够提高劳动生产率40%；美、日、英、德、法等12个发达国家（现占全球经济总量的一半）到2035年，年经济增长率平均可以翻一番。2018年麦肯锡的研究报告表明到2030年人工智能新增经济规模将达到13万亿美元。\n\n（六）人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出未来五年人工智能提升各行业运转效率，其中教育业提升82%，零售业71%，制造业64%，金融业58%。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n（七）人工智能领域的国际竞争将日趋激烈。“未来谁率先掌握人工智能，谁就能称霸世界”。2018年4月，欧盟委员会计划2018-2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略》重点推动物联网建设和人工智能的应用。世界军事强国已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即提出谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n（八）人工智能的社会学将提上议程。水能载舟，亦能覆舟。任何高科技也都是一把双刃剑。随着人工智能的深入发展和应用的不断普及，其社会影响日益明显。人工智能应用得当、把握有度、管理规范，就能有效控制负面风险。为了确保人工智能的健康可持续发展并确保人工智能的发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，深入分析人工智能对未来经济社会发展的可能影响，制定完善的人工智能法律法规，规避可能风险，确保人工智能的正面效应。2017年9月，联合国犯罪和司法研究所(UNICRI)决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。2018年4月，欧洲25个国家签署了《人工智能合作宣言》，从国家战略合作层面来推动人工智能发展，确保欧洲人工智能研发的竞争力，共同面对人工智能在社会、经济、伦理及法律等方面的机遇和挑战。\n\n五、我国人工智能的发展态势与思考\n\n我国当前人工智能发展的总体态势良好。中国信通院联合高德纳咨询公司（Gartner）于2018年9月发布的《2018世界人工智能产业发展蓝皮书》报告统计，我国（不含港澳台地区）人工智能企业总数位列全球第二（1040家），仅次于美国（2039家）。在人工智能总体水平和应用方面，我国也处于国际前列，发展潜力巨大，有望率先突破成为全球领跑者。但是我们也要清醒地看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n一是高度重视。党和国家高度重视并大力发展人工智能。党的十八大以来，习近平总书记把创新摆在国家发展全局的核心位置，高度重视人工智能发展，多次谈及人工智能的重要性，为人工智能如何赋能新时代指明方向。2016年7月习总书记明确指出，人工智能技术的发展将深刻改变人类社会生活，改变世界，应抓住机遇，在这一高技术领域抢占先机。在党的十九大报告中，习总书记强调“要推动互联网、大数据、人工智能和实体经济深度融合”。在2018年两院院士大会上，习总书记再次强调要“推进互联网、大数据、人工智能同实体经济深度融合，做大做强数字经济”。在2017年和2018年的《政府工作报告》中，李克强总理都提到了要加强新一代人工智能发展。2017年7月，国务院发布了《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动，人工智能将成为今后一段时期的国家重大战略。发改委、工信部、科技部、教育部、中央网信办等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n二是态势喜人。根据2017年爱思唯尔（Elsevier）文献数据库SCOPUS统计结果，我国在人工智能领域发表的论文数量已居世界第一。从2012年开始，我国在人工智能领域新增专利数量已经开始超越美国。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成全球人工智能投融资规模最大国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。近两年，清华大学、北京大学、中国科学院大学、浙江大学、上海交通大学、南京大学等高校纷纷成立人工智能学院。2015年开始的中国人工智能大会（CCAI）已连续成功召开四届、规模不断扩大，人工智能领域的教育、科研与学术活动层出不穷。\n\n三是差距不小。我国人工智能在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在较大差距。英国牛津大学2018年的一项研究报告指出中国的人工智能发展能力大致为美国的一半水平。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，存在“头重脚轻”的不均衡现象。在Top700全球AI人才中，中国虽然名列第二，但入选人数远远低于占一半数量的美国。据领英《全球AI领域人才报告》统计，截至2017年一季度全球人工智能领域专业技术人才数量超过190万，其中美国超过85万，我国仅超过5万人，排名全球第7位。2018年市场研究顾问公司Compass Intelligence对全球100多家AI计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国制定完善人工智能相关法律法规的进程需要加快，对可能产生的社会影响还缺少深度分析。\n\n四是前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出到2030年，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n人类社会已开始迈入智能化时代，人工智能引领社会发展是大势所趋，不可逆转。经历六十余年积累后，人工智能开始进入爆发式增长的红利期。伴随着人工智能自身的创新发展和向经济社会的全面渗透，这个红利期将持续相当长的时期。现在是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧需要深入思考。\n\n（一）树立理性务实的发展理念。围棋人机大战中阿尔法狗战胜李世石后，社会大众误以为人工智能已经无所不能，一些地方政府、社会企业、风险资金因此不切实际一窝蜂发展人工智能产业，一些别有用心的机构则有意炒作并通过包装人工智能概念来谋取不当利益。这种“一拥而上、一哄而散”的跟风行为不利于人工智能的健康可持续发展。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。根据高德纳咨询公司发布的技术发展曲线，当前智能机器人、认知专家顾问、机器学习、自动驾驶等人工智能热门技术与领域正处于期望膨胀期，但是通用人工智能及人工智能的整体发展仍处于初步阶段，人工智能还有很多“不能”，实现机器在任意现实环境的自主智能和通用智能仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此发展人工智能不能以短期牟利为目的，要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，并务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n（二）加强基础扎实的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。在此发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。根据2017年爱思唯尔文献数据库SCOPUS统计结果，尽管我国在人工智能领域发表的论文数量已经排名世界第一，但加权引文影响力则只排名34位。为了客观评价我国在人工智能基础研究方面的整体实力，我们搜索了SCI期刊、神经信息处理系统大会（Conference on Neural Information Processing Systems，简称NIPS）等主流人工智能学术会议关于通用智能、深度学习、类脑智能、脑智融合、人机博弈等关键词的论文统计情况，可以清楚看到在人工智能前沿方向中国与美国相比基础实力存在巨大差距：在高质量论文数量方面（按中科院划定的SCI一区论文标准统计），美国是中国的5.34倍（1325:248）；在人才储备方面（SCI论文通讯作者），美国是中国的2.12倍（4804:2267）。\n\n我国应对标国际最高水平，建设面向未来的人工智能基础科学研究中心，重点发展原创性、基础性、前瞻性、突破性的人工智能科学。应该鼓励科研人员瞄准人工智能学科前沿方向开展引领性原创科学研究，通过人工智能与脑认知、神经科学、心理学等学科的交叉融合，重点聚焦人工智能领域的重大基础性科学问题，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n（三）构建自主可控的创新生态。美国谷歌、IBM、微软、脸书等企业在AI芯片、服务器、操作系统、开源算法、云服务、无人驾驶等方面积极构建创新生态、抢占创新高地，已经在国际人工智能产业格局中占据先机。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。美国对中兴通讯发禁令一事充分说明自主可控“核高基”技术的重要性，我国应该吸取在核心电子器件、高端通用芯片及基础软件方面依赖进口的教训，避免重蹈覆辙，着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如军民融合、产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。\n\n另外，我们需要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过标准实施加速人工智能驱动经济社会转型升级的进程。\n\n（四）建立协同高效的创新体系。我国经济社会转型升级对人工智能有重大需求，但是单一的创新主体很难实现政策、市场、技术、应用等方面的全面突破。目前我国学术界、产业界、行业部门在人工智能发展方面各自为政的倾向比较明显，数据资源开放共享不够，缺少对行业资源的有效整合。相比而言，美国已经形成了全社会、全场景、全生态协同互动的人工智能协同创新体系，军民融合和产学研结合都做得很好。我国应在体制机制方面进一步改革创新，建立“军、政、产、学、研、用”一体的人工智能协同创新体系。例如，国家进行顶层设计和战略规划，举全国优势力量设立军事智能的研发和应用平台，提供“人工智能+X”行业融合、打破行业壁垒和行政障碍的激励政策；科技龙头企业引领技术创新生态建设，突破人工智能的重大技术瓶颈；高校科研机构进行人才培养和原始创新，着力构建公共数据资源与技术平台，共同建设若干标杆性的应用创新场景，推动成熟人工智能技术在城市、医疗、金融、文化、农业、交通、能源、物流、制造、安全、服务、教育等领域的深度应用，建设低成本高效益广范围的普惠型智能社会。\n\n（五）加快创新人才的教育培养。发展人工智能关键在人才，中高端人才短缺已经成为我国人工智能做大做强的主要瓶颈。另外，我国社会大众的人工智能科技素养也需要进一步提升，每一个人都需要去适应人工智能时代的科技浪潮。在加强人工智能领军人才培养引进的同时，要面向技术创新和产业发展多层次培养人工智能创新创业人才。《新一代人工智能发展规划》提出逐步开展全民智能教育项目，在中小学阶段设置人工智能课程。目前人工智能科普活动受到各地学校的欢迎，但是缺少通俗易懂的高质量人工智能科普教材、寓教于乐的实验设备和器材、开放共享的教学互动资源平台。国家相关部门应高度重视人工智能教育领域的基础性工作，增加投入，组织优势力量，加强高水平人工智能教育内容和资源平台建设，加快人工智能专业的教学师资培训，从教材、教具、教师等多个环节全面保障我国人工智能教育工作的开展。\n\n（六）推动共担共享的全球治理。人工智能将重塑全球政治和经济格局，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能将进一步拉大发达国家和发展中国家的生产力发展水平差距。美国、日本、德国等通过人工智能和机器人的技术突破和广泛应用弥补他们的人力成本劣势，希望制造业从新兴国家回流发达国家。目前看，我国是发展中国家阵容中唯一有望成为全球人工智能竞争中的领跑者，应采取不同于一些国家的“经济垄断主义、技术保护主义、贸易霸凌主义”路线，尽快布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合国家“一带一路”战略，向亚洲、非洲、南美等经济欠发达地区输出高水平、低成本的“中国智造”成果、提供人工智能时代的中国方案，为让人工智能时代的“智能红利”普惠人类命运共同体做出中国贡献！\n\n（七）制定科学合理的法律法规。要想实实在在收获人工智能带来的红利，首先应保证其安全、可控、可靠发展。美国和欧洲等发达国家和地区十分重视人工智能领域的法律法规问题。美国白宫多次组织这方面的研讨会、咨询会；特斯拉等产业巨头牵头成立OpenAI等机构，旨在以有利于整个人类的方式促进和发展友好的人工智能；科研人员自发签署23条“阿西洛马人工智能原则”，意图在规范人工智能科研及应用等方面抢占先机。我国在人工智能领域的法律法规制定及风险管控方面相对滞后，这种滞后局面与我国现阶段人工智能发展的整体形势不相适应，并可能成为我国人工智能下一步创新发展的一大掣肘。因此，有必要大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法规环境。\n\n（八）加强和鼓励人工智能社会学研究。人工智能的社会影响将是深远的、全方位的。我们当未雨绸缪，从国家安全、社会治理、就业结构、伦理道德、隐私保护等多个维度系统深入研究人工智能可能的影响，制定合理可行的应对措施，确保人工智能的正面效应。应大力加强人工智能领域的科普工作，打造科技与伦理的高效对话机制和沟通平台，消除社会大众对人工智能的误解与恐慌，为人工智能的发展营造理性务实、积极健康的社会氛围。\n\n六、结束语\n\n人工智能经过60多年的发展，进入了创新突破的战略机遇期和产业应用的红利收获期，必将对生产力和产业结构以及国际格局产生革命性影响，并推动人类进入普惠型智能社会。但是，我们需要清醒看到通用人工智能及人工智能的整体发展仍处于初级阶段，人工智能不是万能，人工智能还有很多“不能”。我们应当采取理性务实的发展路径，扎实推进基础研究、技术生态、人才培养、法律规范等方面的工作，在开放中创新，在创新中发展，全速跑赢智能时代，着力建设人工智能科技强国！\n\n（主讲人系中国科学院院士）\n\n编 辑： 王伟\n\n责 编： 张绍敏\n\n[<< 返回首页](../../../)\n\n#### 相关文章\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'http://www.npc.gov.cn/npc/c12434/c541/201905/t20190521_268525.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9980122, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_人工智能的创新发展与社会影响 - 中国人大网.md'}}
2026-02-02 20:35:10,895 - __main__ - INFO - call_tool: name=exa_context_search, args={'query': '人工智能的发展历史？'}
2026-02-02 20:35:10,895 - __main__ - INFO - handle_search: searcher=ExaSearcherContext, query=人工智能的发展历史？, search_type=None
2026-02-02 20:35:10,905 - __main__ - INFO - call_tool: name=wikipedia_search, args={'query': '人工智能的发展历史？'}
2026-02-02 20:35:10,906 - __main__ - INFO - handle_search: searcher=WikipediaSearcher, query=人工智能的发展历史？, search_type=None
2026-02-02 20:35:10,950 - __main__ - INFO - call_tool: name=tavily_search, args={'query': '人工智能的发展历史？'}
2026-02-02 20:35:10,951 - __main__ - INFO - handle_search: searcher=TavilySearch, query=人工智能的发展历史？, search_type=None
2026-02-02 20:35:14,667 - __main__ - INFO - handle_search: returned=7
2026-02-02 20:35:14,667 - __main__ - INFO - call_tool: name=tavily_search, result_type=papers, count=7
2026-02-02 20:35:14,668 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '![](/static/images/icons/zhwiki-25.svg)\n![维基百科](/static/images/mobile/copyright/wikipedia-wordmark-zh-25-hans.svg)\n![自由的百科全书](/static/images/mobile/copyright/wikipedia-tagline-zh-25-hans.svg)\n\n## 目录\n\n# 人工智能史\n\n| [人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")系列内容 |\n| --- |\n|  |\n| 主要目标  * [知识表示](/wiki/%E7%9F%A5%E8%AF%86%E8%A1%A8%E7%A4%BA "知识表示") * [自动规划](/w/index.php?title=%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92%E5%92%8C%E8%B0%83%E5%BA%A6&action=edit&redlink=1 "自动规划和调度（页面不存在）")（英语：[Automated planning and scheduling](https://en.wikipedia.org/wiki/Automated_planning_and_scheduling "en:Automated planning and scheduling")） * [机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习") * [语言处理](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理") * [电脑视觉](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89 "计算机视觉") * [机器人学](/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%AD%A6 "机器人学") * [强人工智慧](/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "通用人工智慧") * [弱人工智慧](/wiki/%E5%BC%B1%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "弱人工智慧") * [人工智能对齐](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AF%B9%E9%BD%90 "人工智能对齐") |\n| 实现方式  * [符号人工智能](/wiki/%E7%AC%A6%E8%99%9F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "符号人工智能") * [深度学习](/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0 "深度学习") * [贝氏网路](/wiki/%E8%B2%9D%E6%B0%8F%E7%B6%B2%E8%B7%AF "贝氏网路") * [进化算法](/wiki/%E8%BF%9B%E5%8C%96%E7%AE%97%E6%B3%95 "进化算法") * [混合智能系统](/wiki/%E6%B7%B7%E5%90%88%E6%99%BA%E8%83%BD%E7%B3%BB%E7%B5%B1 "混合智能系统")   + [混合专家模型](/wiki/%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B "混合专家模型") * [生成式人工智慧](/wiki/%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "生成式人工智慧") * [代理式人工智能](/w/index.php?title=%E4%BB%A3%E7%90%86%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "代理式人工智能（页面不存在）")（英语：[AI agent](https://en.wikipedia.org/wiki/AI_agent "en:AI agent")） |\n| [人工智能哲学](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%93%B2%E5%AD%B8 "人工智能哲学")  * [伦理](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BC%A6%E7%90%86&action=edit&redlink=1 "人工智能伦理（页面不存在）")（英语：[Ethics of artificial intelligence](https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence "en:Ethics of artificial intelligence")） * [人工智能安全](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AE%89%E5%85%A8&action=edit&redlink=1 "人工智能安全（页面不存在）")（英语：[AI safety](https://en.wikipedia.org/wiki/AI_safety "en:AI safety")）   + [幻觉](/wiki/%E5%B9%BB%E8%A7%89_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD) "幻觉 (人工智能)")   + [存在风险](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AD%98%E5%9C%A8%E9%A3%8E%E9%99%A9&action=edit&redlink=1 "人工智能的存在风险（页面不存在）")（英语：[Existential risk from artificial general intelligence](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence "en:Existential risk from artificial general intelligence")） * [图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试") * [中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间") * [可解释人工智慧](/wiki/%E5%8F%AF%E8%A7%A3%E9%87%8B%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "可解释人工智慧") * [友好的人工智能](/w/index.php?title=%E5%8F%8B%E5%A5%BD%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&action=edit&redlink=1 "友好的人工智能（页面不存在）")（英语：[Friendly artificial intelligence](https://en.wikipedia.org/wiki/Friendly_artificial_intelligence "en:Friendly artificial intelligence")） * [人工智能监管](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9B%91%E7%AE%A1&action=edit&redlink=1 "人工智能监管（页面不存在）")（英语：[Regulation of artificial intelligence](https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence "en:Regulation of artificial intelligence")） |\n| 历史  * [时间轴](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%97%B6%E9%97%B4%E8%BD%B4&action=edit&redlink=1 "人工智能时间轴（页面不存在）")（英语：[Timeline of artificial intelligence](https://en.wikipedia.org/wiki/Timeline_of_artificial_intelligence "en:Timeline of artificial intelligence")） * [发展](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%91%E5%B1%95&action=edit&redlink=1 "人工智能发展（页面不存在）")（英语：[Progress in artificial intelligence](https://en.wikipedia.org/wiki/Progress_in_artificial_intelligence "en:Progress in artificial intelligence")） * [专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统") * [人工智慧低谷](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷") * [人工智能热潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%83%AD%E6%BD%AE "人工智能热潮") * [人工智能法案](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%B3%95%E6%A1%88 "人工智能法案") |\n| [人工智能的应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")  * [应用](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%BA%94%E7%94%A8 "人工智能应用")   + [AlphaFold](/wiki/AlphaFold "AlphaFold")   + [深度伪造](/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%AA%E9%80%A0 "深度伪造")   + [AI艺术](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E8%97%9D%E8%A1%93 "人工智慧艺术")   + [音乐](/wiki/%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "音乐和人工智能")   + [医疗保健](/wiki/%E5%8C%BB%E7%96%97%E9%A2%86%E5%9F%9F%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "医疗领域的人工智能")   + [工业](/wiki/%E5%B7%A5%E4%B8%9A%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "工业人工智能")   + [机器翻译](/wiki/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91 "机器翻译")   + [军事](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BB%8D%E5%82%99%E7%AB%B6%E8%B3%BD "人工智能军备竞赛") * [项目](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E9%A1%B9%E7%9B%AE%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能项目列表（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） * [编程语言](/w/index.php?title=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E5%88%97%E8%A1%A8&action=edit&redlink=1 "人工智能编程语言列表（页面不存在）")（英语：[List of programming languages for artificial intelligence](https://en.wikipedia.org/wiki/List_of_programming_languages_for_artificial_intelligence "en:List of programming languages for artificial intelligence")） |\n| 主题与列表  * [主题](/wiki/Portal:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Portal:人工智能") * [术语表](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%9C%AF%E8%AF%AD%E8%A1%A8 "人工智能术语表") * [AI概述](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%A6%82%E8%BF%B0 "人工智能概述") * [AI公司列表](/w/index.php?title=List_of_artificial_intelligence_companies&action=edit&redlink=1 "List of artificial intelligence companies（页面不存在）")（英语：[List of artificial intelligence companies](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_companies "en:List of artificial intelligence companies")） * [AI项目列表](/w/index.php?title=List_of_artificial_intelligence_projects&action=edit&redlink=1 "List of artificial intelligence projects（页面不存在）")（英语：[List of artificial intelligence projects](https://en.wikipedia.org/wiki/List_of_artificial_intelligence_projects "en:List of artificial intelligence projects")） |\n| * [查](/wiki/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template:人工智能") * [论](/wiki/Template_talk:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Template talk:人工智能") * [编](/wiki/Special:EditPage/Template:%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "Special:EditPage/Template:人工智能") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png/250px-Dall-e_3_%28jan_%2724%29_artificial_intelligence_icon.png)\n\n**人工智能的历史**源远流长。在古代的[神话](/wiki/%E7%A5%9E%E8%A9%B1 "神话")[传说](/wiki/%E4%BC%A0%E8%AF%B4 "传说")中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)现代意义上的[AI](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑](/wiki/%E9%9B%BB%E8%85%A6 "电脑")的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n\n1956年，[人工智能](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD "人工智能")的研究领域确立于在[达特茅斯学院](/wiki/%E8%BE%BE%E7%89%B9%E8%8C%85%E6%96%AF%E5%AD%A6%E9%99%A2 "达特茅斯学院")举行的[会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[[2]](#cite_note-2)他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")（也被称作AI之冬）。由于[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")爵士的批评和国会方面的压力，[美国](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[[3]](#cite_note-3)\n\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平](/wiki/%E5%BC%B7%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7 "强人工智慧")的机器至今仍未出现。[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[[4]](#cite_note-TuringQuote-4)\n\n在21世纪的第一个十年，[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n| [计算历史](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） |\n| --- |\n| [硬件](/wiki/%E7%A1%AC%E4%BB%B6 "硬件") |\n| * [1960年代之前](/wiki/%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2 "计算机硬体历史") * [1960年代至今](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A1%AC%E9%AB%94%E6%AD%B7%E5%8F%B2_(1960%E5%B9%B4%E4%BB%A3%E8%87%B3%E4%BB%8A)&action=edit&redlink=1 "计算机硬体历史 (1960年代至今)（页面不存在）")（英语：[History of computing hardware (1960s–present)](https://en.wikipedia.org/wiki/History_of_computing_hardware_(1960s%E2%80%93present) "en:History of computing hardware (1960s–present)")） |\n| [软件](/wiki/%E8%BD%AF%E4%BB%B6 "软件") |\n| * [软体](/w/index.php?title=%E8%BB%9F%E9%AB%94%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体历史（页面不存在）")（英语：[History of software](https://en.wikipedia.org/wiki/History_of_software "en:History of software")） * [Unix](/w/index.php?title=Unix%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Unix历史（页面不存在）")（英语：[History of Unix](https://en.wikipedia.org/wiki/History_of_Unix "en:History of Unix")） * [自由和开源软件](/w/index.php?title=%E8%87%AA%E7%94%B1%E5%92%8C%E9%96%8B%E6%BA%90%E8%BB%9F%E4%BB%B6%E7%9A%84%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "自由和开源软件的历史（页面不存在）")（英语：[History of free and open-source software](https://en.wikipedia.org/wiki/History_of_free_and_open-source_software "en:History of free and open-source software")） |\n| [计算机科学](/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6 "计算机科学") |\n| * 人工智能 * [编译器构造](/w/index.php?title=%E7%BC%96%E8%AF%91%E5%99%A8%E6%9E%84%E9%80%A0%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "编译器构造历史（页面不存在）")（英语：[History of compiler construction](https://en.wikipedia.org/wiki/History_of_compiler_construction "en:History of compiler construction")） * [计算机科学](/w/index.php?title=%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "计算机科学历史（页面不存在）")（英语：[History of computing](https://en.wikipedia.org/wiki/History_of_computing "en:History of computing")） * [操作系统](/wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%8E%86%E5%8F%B2 "操作系统历史") * [程式语言](/wiki/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80%E6%AD%B7%E5%8F%B2 "程式语言历史") * [杰出先驱者](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E5%85%88%E9%A9%B1%E8%80%85%E5%88%97%E8%A1%A8&action=edit&redlink=1 "计算机科学先驱者列表（页面不存在）")（英语：[List of pioneers in computer science](https://en.wikipedia.org/wiki/List_of_pioneers_in_computer_science "en:List of pioneers in computer science")） * [软体工程](/w/index.php?title=%E8%BB%9F%E9%AB%94%E5%B7%A5%E7%A8%8B%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "软体工程历史（页面不存在）")（英语：[History of software engineering](https://en.wikipedia.org/wiki/History_of_software_engineering "en:History of software engineering")） |\n| 现代概念 |\n| * [通用CPU](/w/index.php?title=%E9%80%9A%E7%94%A8%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "通用中央处理器历史（页面不存在）")（英语：[History of general-purpose CPUs](https://en.wikipedia.org/wiki/History_of_general-purpose_CPUs "en:History of general-purpose CPUs")） * [图形用户界面](/wiki/%E5%9B%BE%E5%BD%A2%E7%94%A8%E6%88%B7%E7%95%8C%E9%9D%A2 "图形用户界面") * [互联网](/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E5%8E%86%E5%8F%B2 "互联网历史") * [个人电脑](/w/index.php?title=%E5%80%8B%E4%BA%BA%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "个人电脑历史（页面不存在）")（英语：[History of personal computers](https://en.wikipedia.org/wiki/History_of_personal_computers "en:History of personal computers")） * [笔记型电脑](/w/index.php?title=%E7%AD%86%E8%A8%98%E5%9E%8B%E9%9B%BB%E8%85%A6%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "笔记型电脑历史（页面不存在）")（英语：[History of laptops](https://en.wikipedia.org/wiki/History_of_laptops "en:History of laptops")） * [电子游戏](/wiki/%E9%9B%BB%E5%AD%90%E9%81%8A%E6%88%B2%E5%8F%B2 "电子游戏史") * [全球资讯网](/w/index.php?title=%E5%85%A8%E7%90%83%E8%B3%87%E8%A8%8A%E7%B6%B2%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "全球资讯网历史（页面不存在）")（英语：[History of the World Wide Web](https://en.wikipedia.org/wiki/History_of_the_World_Wide_Web "en:History of the World Wide Web")） |\n| 按国家 |\n| * [保加利亚](/w/index.php?title=%E4%BF%9D%E5%8A%A0%E5%88%A9%E4%BA%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "保加利亚计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Bulgaria](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Bulgaria "en:History of computer hardware in Bulgaria")） * [波兰](/w/index.php?title=%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "波兰计算历史（页面不存在）")（英语：[History of computing in Poland](https://en.wikipedia.org/wiki/History_of_computing_in_Poland "en:History of computing in Poland")） * [罗马尼亚](/w/index.php?title=%E7%BD%97%E9%A9%AC%E5%B0%BC%E4%BA%9A%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "罗马尼亚计算历史（页面不存在）")（英语：[History of computing in Romania](https://en.wikipedia.org/wiki/History_of_computing_in_Romania "en:History of computing in Romania")） * [苏联集团国家](/w/index.php?title=%E8%8B%8F%E8%81%94%E9%9B%86%E5%9B%A2%E5%9B%BD%E5%AE%B6%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联集团国家计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Soviet Bloc countries](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Soviet_Bloc_countries "en:History of computer hardware in Soviet Bloc countries")） * [苏联](/w/index.php?title=%E8%8B%8F%E8%81%94%E8%AE%A1%E7%AE%97%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "苏联计算历史（页面不存在）")（英语：[History of computing in the Soviet Union](https://en.wikipedia.org/wiki/History_of_computing_in_the_Soviet_Union "en:History of computing in the Soviet Union")） * [南斯拉夫](/w/index.php?title=%E5%8D%97%E6%96%AF%E6%8B%89%E5%A4%AB%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A1%AC%E4%BB%B6%E5%8E%86%E5%8F%B2&action=edit&redlink=1 "南斯拉夫计算机硬件历史（页面不存在）")（英语：[History of computer hardware in Yugoslavia](https://en.wikipedia.org/wiki/History_of_computer_hardware_in_Yugoslavia "en:History of computer hardware in Yugoslavia")） |\n| [计算年表](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "计算年表（页面不存在）")（英语：[Timeline of computing](https://en.wikipedia.org/wiki/Timeline_of_computing "en:Timeline of computing")） |\n| * [1950年之前](/w/index.php?title=1950%E5%B9%B4%E4%B9%8B%E5%89%8D%E7%9A%84%E8%AE%A1%E7%AE%97%E7%A1%AC%E4%BB%B6%E5%B9%B4%E8%A1%A8&action=edit&redlink=1 "1950年之前的计算硬件年表（页面不存在）")（英语：[Timeline of computing hardware before 1950](https://en.wikipedia.org/wiki/Timeline_of_computing_hardware_before_1950 "en:Timeline of computing hardware before 1950")） * [1950–1979](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1950%E2%80%931979)&action=edit&redlink=1 "计算年表 (1950–1979)（页面不存在）")（英语：[Timeline of computing 1950–1979](https://en.wikipedia.org/wiki/Timeline_of_computing_1950%E2%80%931979 "en:Timeline of computing 1950–1979")） * [1980–1989](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1980%E2%80%931989)&action=edit&redlink=1 "计算年表 (1980–1989)（页面不存在）")（英语：[Timeline of computing 1980–1989](https://en.wikipedia.org/wiki/Timeline_of_computing_1980%E2%80%931989 "en:Timeline of computing 1980–1989")） * [1990–1999](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(1990%E2%80%931999)&action=edit&redlink=1 "计算年表 (1990–1999)（页面不存在）")（英语：[Timeline of computing 1990–1999](https://en.wikipedia.org/wiki/Timeline_of_computing_1990%E2%80%931999 "en:Timeline of computing 1990–1999")） * [2000–2009](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2000%E2%80%932009)&action=edit&redlink=1 "计算年表 (2000–2009)（页面不存在）")（英语：[Timeline of computing 2000–2009](https://en.wikipedia.org/wiki/Timeline_of_computing_2000%E2%80%932009 "en:Timeline of computing 2000–2009")） * [2010–2019](/w/index.php?title=%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8_(2010%E2%80%932019)&action=edit&redlink=1 "计算年表 (2010–2019)（页面不存在）")（英语：[Timeline of computing 2010–2019](https://en.wikipedia.org/wiki/Timeline_of_computing_2010%E2%80%932019 "en:Timeline of computing 2010–2019")） * [更多年表……](/wiki/Category:%E8%A8%88%E7%AE%97%E5%B9%B4%E8%A1%A8 "Category:计算年表") |\n| [计算机科学词汇](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E8%AF%8D%E6%B1%87&action=edit&redlink=1 "计算机科学词汇（页面不存在）")（英语：[Glossary of computer science](https://en.wikipedia.org/wiki/Glossary_of_computer_science "en:Glossary of computer science")） |\n| * [分类](/wiki/Category:%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%8E%86%E5%8F%B2 "Category:计算机历史") |\n| * [查](/wiki/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Template:计算历史") * [论](/w/index.php?title=Template_talk:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2&action=edit&redlink=1 "Template talk:计算历史（页面不存在）") * [编](/wiki/Special:EditPage/Template:%E8%A8%88%E7%AE%97%E6%AD%B7%E5%8F%B2 "Special:EditPage/Template:计算历史") |\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/96/Symbol_category_class.svg/20px-Symbol_category_class.svg.png)\n\n## 先驱\n\n奥特曼写道[[1]](#cite_note-FOOTNOTEMcCorduck2004-1)：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机](/wiki/%E8%87%AA%E5%8B%95%E6%A9%9F "自动机")）的实践之中。[[5]](#cite_note-FOOTNOTEMcCorduck20045–35-5)\n\n### 神话，幻想和预言中的AI\n\n[希腊神话](/wiki/%E5%B8%8C%E8%85%8A%E7%A5%9E%E8%AF%9D "希腊神话")中已经出现了机械人和人造人，如[赫淮斯托斯](/wiki/%E8%B5%AB%E6%B7%AE%E6%96%AF%E6%89%98%E6%96%AF "赫淮斯托斯")的黄金机器人和[皮格马利翁](/wiki/%E7%9A%AE%E6%A0%BC%E9%A9%AC%E5%88%A9%E7%BF%81 "皮格马利翁")的[伽拉忒亚](/wiki/%E4%BC%BD%E6%8B%89%E5%BF%92%E4%BA%9A "伽拉忒亚")。[[6]](#cite_note-6)中世纪出现了使用巫术或[炼金术](/wiki/%E7%82%BC%E9%87%91%E6%9C%AF "炼金术")将意识赋予无生命物质的传说，如[贾比尔](/wiki/%E8%B4%BE%E6%AF%94%E5%B0%94 "贾比尔")的*Takwin*，[帕拉塞尔苏斯](/wiki/%E5%B8%95%E6%8B%89%E5%A1%9E%E5%B0%94%E8%8B%8F%E6%96%AF "帕拉塞尔苏斯")的[何蒙库鲁兹](/wiki/%E4%BD%95%E8%92%99%E5%BA%93%E9%B2%81%E5%85%B9 "何蒙库鲁兹")和Judah Loew的[魔像](/wiki/%E9%AD%94%E5%83%8F "魔像")。[[7]](#cite_note-7)19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱](/wiki/%E7%8E%9B%E4%B8%BD%C2%B7%E9%9B%AA%E8%8E%B1 "玛丽·雪莱")的《[弗兰肯斯坦](/wiki/%E5%BC%97%E5%85%B0%E8%82%AF%E6%96%AF%E5%9D%A6 "弗兰肯斯坦")》和[卡雷尔·恰佩克](/wiki/%E5%8D%A1%E9%9B%B7%E5%B0%94%C2%B7%E6%81%B0%E4%BD%A9%E5%85%8B "卡雷尔·恰佩克")的《罗素姆的万能机器人》。[[8]](#cite_note-FOOTNOTEMcCorduck200417–25-8)Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[[9]](#cite_note-FOOTNOTEButler1863-9)至今人工智能仍然是科幻小说的重要元素。\n\n### 自动人偶\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Al-jazari_robots.jpg/250px-Al-jazari_robots.jpg)\n\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师](/wiki/%E5%81%83%E5%B8%88 "偃师")（中国西周）[[10]](#cite_note-10)，[希罗](/wiki/%E5%B8%8C%E7%BD%97 "希罗")（希腊）[[11]](#cite_note-11)，[加扎利](/wiki/%E5%8A%A0%E6%89%8E%E5%88%A9 "加扎利")[[12]](#cite_note-FOOTNOTENick2005-12)和Wolfgang von Kempelen[[13]](#cite_note-13) 等等。已知最古老的“机器人”是[古埃及](/wiki/%E5%8F%A4%E5%9F%83%E5%8F%8A "古埃及")和[古希腊](/wiki/%E5%8F%A4%E5%B8%8C%E8%85%8A "古希腊")的[圣像](/wiki/%E8%81%96%E5%83%8F "圣像")，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")（[赫耳墨斯·特里斯墨吉斯忒斯](/wiki/%E8%B5%AB%E8%80%B3%E5%A2%A8%E6%96%AF%C2%B7%E7%89%B9%E9%87%8C%E6%96%AF%E5%A2%A8%E5%90%89%E6%96%AF%E5%BF%92%E6%96%AF "赫耳墨斯·特里斯墨吉斯忒斯")）写道“当发现神的本性时，人就能够重现他”[[14]](#cite_note-14)[[15]](#cite_note-15)。\n\n### 形式推理\n\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德](/wiki/%E4%BA%9A%E9%87%8C%E5%A3%AB%E5%A4%9A%E5%BE%B7 "亚里士多德")（对三段论逻辑进行了形式分析），[欧几里得](/wiki/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97 "欧几里得")（其著作《[几何原本](/wiki/%E5%87%A0%E4%BD%95%E5%8E%9F%E6%9C%AC "几何原本")》是形式推理的典范），[花剌子密](/wiki/%E8%8A%B1%E5%89%8C%E5%AD%90%E5%AF%86 "花剌子密")（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉](/wiki/%E5%A5%A5%E5%8D%A1%E5%A7%86%E7%9A%84%E5%A8%81%E5%BB%89 "奥卡姆的威廉")和[邓斯·司各脱](/wiki/%E9%82%93%E6%96%AF%C2%B7%E5%8F%B8%E5%90%84%E8%84%B1 "邓斯·司各脱")。[[16]](#cite_note-Berlinski_2000-16)\n\n[马略卡](/wiki/%E9%A9%AC%E7%95%A5%E5%8D%A1 "马略卡")哲学家[拉蒙·柳利](/wiki/%E6%8B%89%E8%92%99%C2%B7%E6%9F%B3%E5%88%A9 "拉蒙·柳利")（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[[17]](#cite_note-17) 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[[18]](#cite_note-18)Llull的工作对[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")产生了很大影响，后者进一步发展了他的思想。[[19]](#cite_note-19)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Gottfried_Wilhelm_von_Leibniz.jpg/250px-Gottfried_Wilhelm_von_Leibniz.jpg)\n\n在17世纪中，[莱布尼兹](/wiki/%E8%8E%B1%E5%B8%83%E5%B0%BC%E5%85%B9 "莱布尼兹")，[托马斯·霍布斯](/wiki/%E6%89%98%E9%A9%AC%E6%96%AF%C2%B7%E9%9C%8D%E5%B8%83%E6%96%AF "托马斯·霍布斯")和[笛卡儿](/wiki/%E7%AC%9B%E5%8D%A1%E5%84%BF "笛卡儿")尝试将理性的思考系统化为代数学或几何学那样的体系。[[20]](#cite_note-20)霍布斯在其著作《[利维坦](/wiki/%E5%88%A9%E7%BB%B4%E5%9D%A6_(%E9%9C%8D%E5%B8%83%E6%96%AF) "利维坦 (霍布斯)")》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” [[21]](#cite_note-21)莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字](/wiki/%E9%80%9A%E7%94%A8%E8%A1%A8%E6%84%8F%E6%96%87%E5%AD%97 "通用表意文字")），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[[22]](#cite_note-22) 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n\n在20世纪，[数理逻辑](/wiki/%E6%95%B0%E7%90%86%E9%80%BB%E8%BE%91 "数理逻辑")研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔](/wiki/%E4%B9%94%E6%B2%BB%C2%B7%E5%B8%83%E5%B0%94 "乔治·布尔")的《思维的定律》与[弗雷格](/wiki/%E6%88%88%E7%89%B9%E6%B4%9B%E5%B8%83%C2%B7%E5%BC%97%E9%9B%B7%E6%A0%BC "戈特洛布·弗雷格")的《[概念文字](/wiki/%E6%A6%82%E5%BF%B5%E6%96%87%E5%AD%97 "概念文字")》。基于弗雷格的系统，[罗素](/wiki/%E7%BD%97%E7%B4%A0 "罗素")和[怀特海](/wiki/%E6%80%80%E7%89%B9%E6%B5%B7 "怀特海")在他们于1913年出版的巨著《[数学原理](/wiki/%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86 "数学原理")》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特](/wiki/%E5%B8%8C%E5%B0%94%E4%BC%AF%E7%89%B9 "希尔伯特")，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” [[16]](#cite_note-Berlinski_2000-16)这个问题的最终回答由[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")，[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")和[Alonzo Church](/wiki/Alonzo_Church "Alonzo Church")的[λ演算](/wiki/%CE%9B%E6%BC%94%E7%AE%97 "Λ演算")给出。[[16]](#cite_note-Berlinski_2000-16)[[23]](#cite_note-23)他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/16/Classic_shot_of_the_ENIAC.jpg/250px-Classic_shot_of_the_ENIAC.jpg)\n\n[邱奇-图灵论题](/wiki/%E9%82%B1%E5%A5%87-%E5%9B%BE%E7%81%B5%E8%AE%BA%E9%A2%98 "邱奇-图灵论题")暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机](/wiki/%E5%9B%BE%E7%81%B5%E6%9C%BA "图灵机")：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[[16]](#cite_note-Berlinski_2000-16)[[24]](#cite_note-24)\n\n### 计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇](/wiki/%E6%9F%A5%E5%B0%94%E6%96%AF%C2%B7%E5%B7%B4%E8%B4%9D%E5%A5%87 "查尔斯·巴贝奇")设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝](/wiki/%E6%84%9B%E9%81%94%C2%B7%E5%8B%92%E8%8A%99%E8%95%BE%E7%B5%B2 "爱达·勒芙蕾丝")预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[[25]](#cite_note-Menabrea1843-25)（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数](/wiki/%E4%BC%AF%E5%8A%AA%E5%88%A9%E6%95%B0 "伯努利数")的方法。）\n\n第一批现代计算机是[二战](/wiki/%E4%BA%8C%E6%88%98 "二战")期间建造的大型译码机（包括Z3，[ENIAC](/wiki/ENIAC "ENIAC")和Colossus等）。[[26]](#cite_note-26)后两个机器的理论基础是[图灵](/wiki/%E5%9B%BE%E7%81%B5 "图灵")和[约翰·冯·诺伊曼](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E5%86%AF%C2%B7%E8%AF%BA%E4%BC%8A%E6%9B%BC "约翰·冯·诺伊曼")提出和发展的学说。[[27]](#cite_note-27)\n\n## 人工智能的诞生：1943 - 1956\n\n[[28]](#cite_note-28)在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n### 控制论与早期神经网络\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/1/10/BRL61-IBM_702.jpg/250px-BRL61-IBM_702.jpg)\n\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳](/wiki/%E8%AF%BA%E4%BC%AF%E7%89%B9%C2%B7%E7%BB%B4%E7%BA%B3 "诺伯特·维纳")的[控制论](/wiki/%E6%8E%A7%E5%88%B6%E8%AE%BA "控制论")描述了电子网络的控制和稳定性。[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")提出的[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")则描述了[数字信号](/wiki/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7 "数字信号")（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[[29]](#cite_note-29)\n\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[[30]](#cite_note-30)\n\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")”的学者。[[31]](#cite_note-31)[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为[SNARC](/w/index.php?title=SNARC&action=edit&redlink=1 "SNARC（页面不存在）")。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n### 游戏AI\n\n1951年，[克里斯托弗·斯特雷奇](/wiki/%E5%85%8B%E9%87%8C%E6%96%AF%E6%89%98%E5%BC%97%C2%B7%E6%96%AF%E7%89%B9%E9%9B%B7%E5%A5%87 "克里斯托弗·斯特雷奇")使用[曼彻斯特大学](/wiki/%E6%9B%BC%E5%BD%BB%E6%96%AF%E7%89%B9%E5%A4%A7%E5%AD%A6 "曼彻斯特大学")的Ferranti Mark 1机器写出了一个[西洋跳棋](/wiki/%E8%A5%BF%E6%B4%8B%E8%B7%B3%E6%A3%8B "西洋跳棋")（checkers）程序；[迪特里希·普林茨](/w/index.php?title=%E8%BF%AA%E7%89%B9%E9%87%8C%E5%B8%8C%C2%B7%E6%99%AE%E6%9E%97%E8%8C%A8&action=edit&redlink=1 "迪特里希·普林茨（页面不存在）")（Dietrich Prinz）则写出了一个[国际象棋](/wiki/%E5%9B%BD%E9%99%85%E8%B1%A1%E6%A3%8B "国际象棋")程序。[[32]](#cite_note-32)[亚瑟·李·塞谬尔](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E6%9D%8E%C2%B7%E5%A1%9E%E8%AC%AC%E7%88%BE "亚瑟·李·塞谬尔")（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。[[33]](#cite_note-33)游戏AI一直被认为是评价AI进展的一种标准。\n\n### 图灵测试\n\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。[[34]](#cite_note-34)由于注意到“智能”这一概念难以确切定义，他提出了著名的[图灵测试](/wiki/%E5%9B%BE%E7%81%B5%E6%B5%8B%E8%AF%95 "图灵测试")：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。[[35]](#cite_note-35)图灵测试是人工智能哲学方面第一个严肃的提案。\n\n### 符号推理与“逻辑理论家”程序\n\n50年代中期，随着数位计算机的兴起，一些科学家直觉地感到可以进行数字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。[[36]](#cite_note-36)\n\n1955年，[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和后来荣获诺贝尔奖的[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")在J. C. Shaw的协助下开发了“[逻辑理论家](/wiki/%E9%80%BB%E8%BE%91%E7%90%86%E8%AE%BA%E5%AE%B6 "逻辑理论家")（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。[[37]](#cite_note-37)Simon认为他们已经“解决了神秘的[心/身问题](/wiki/%E5%BF%83%E8%BA%AB%E4%BA%8C%E5%88%86%E6%B3%95 "心身二分法")，解释了物质构成的系统如何获得心灵的性质。”[[38]](#cite_note-38) （这一断言的哲学立场后来被[约翰·罗杰斯·希尔勒](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E7%BD%97%E6%9D%B0%E6%96%AF%C2%B7%E5%B8%8C%E5%B0%94%E5%8B%92 "约翰·罗杰斯·希尔勒")称为“强人工智能”，即机器可以像人一样具有思想。）[[39]](#cite_note-39)\n\n### 1956年达特茅斯会议：AI的诞生\n\n1956年[达特矛斯会议](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")[[40]](#cite_note-40)的组织者是[马文·明斯基](/wiki/%E9%A9%AC%E6%96%87%C2%B7%E6%98%8E%E6%96%AF%E5%9F%BA "马文·明斯基")，[约翰·麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")和另两位资深科学家[克劳德·香农](/wiki/%E5%85%8B%E5%8A%B3%E5%BE%B7%C2%B7%E9%A6%99%E5%86%9C "克劳德·香农")以及内森·罗彻斯特（Nathan Rochester），后者来自[IBM](/wiki/IBM "IBM")。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” [[41]](#cite_note-41)与会者包括[雷·索罗门诺夫](/w/index.php?title=%E9%9B%B7%C2%B7%E7%B4%A2%E7%BE%85%E9%96%80%E8%AB%BE%E5%A4%AB&action=edit&redlink=1 "雷·索罗门诺夫（页面不存在）")（Ray Solomonoff），奥利佛·塞尔弗里奇（Oliver Selfridge），Trenchard More，亚瑟·山谬尔（Arthur Samuel），[艾伦·纽厄尔](/wiki/%E8%89%BE%E4%BC%A6%C2%B7%E7%BA%BD%E5%8E%84%E5%B0%94 "艾伦·纽厄尔")和[赫伯特·西蒙](/wiki/%E8%B5%AB%E4%BC%AF%E7%89%B9%C2%B7%E8%A5%BF%E8%92%99 "赫伯特·西蒙")，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。[[42]](#cite_note-42)会上纽厄尔和西蒙讨论了“逻辑理论家”，而[麦卡锡](/wiki/%E7%BA%A6%E7%BF%B0%C2%B7%E9%BA%A6%E5%8D%A1%E9%94%A1 "约翰·麦卡锡")则说服与会者接受“人工智能”一词作为本领域的名称。[[43]](#cite_note-43)1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。[[44]](#cite_note-44)\n\n## 第一波浪潮 - 黄金年代：1956 - 1974\n\n[达特矛斯](/wiki/%E8%BE%BE%E7%89%B9%E7%9F%9B%E6%96%AF%E4%BC%9A%E8%AE%AE "达特矛斯会议")会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：[[45]](#cite_note-45)计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。[[46]](#cite_note-46) 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。[[47]](#cite_note-47) [DARPA](/wiki/DARPA "DARPA")（[国防高等研究计划署](/wiki/%E5%9C%8B%E9%98%B2%E9%AB%98%E7%AD%89%E7%A0%94%E7%A9%B6%E8%A8%88%E5%8A%83%E7%BD%B2 "国防高等研究计划署")）等政府机构向这一新兴领域投入了大笔资金。[[48]](#cite_note-48)\n\n### 研究工作\n\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n#### 搜索式推理\n\n许多AI程序使用相同的基本[算法](/wiki/%E7%AE%97%E6%B3%95 "算法")。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行[回溯](/wiki/%E5%9B%9E%E6%BA%AF%E6%B3%95 "回溯法")。这就是“搜索式推理”。[[49]](#cite_note-49)\n\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用[启发式算法](/wiki/%E5%90%AF%E5%8F%91%E5%BC%8F%E7%AE%97%E6%B3%95 "启发式算法")去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。[[50]](#cite_note-50)\n\n艾伦·纽厄尔和赫伯特·西蒙试图通过其“[通用解题器](/wiki/%E4%B8%80%E8%88%AC%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E5%99%A8 "一般问题解决器")（General Problem Solver）”程序，将这一算法推广到一般情形。[[51]](#cite_note-51)另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉宁特（Herbert Gelernter）的几何定理证明机（1958）和马文·李·闵斯基的学生James Slagle开发的SAINT（1961）。[[52]](#cite_note-52)还有一些程序通过搜索目标和子目标作出决策，如[斯坦福大学](/wiki/%E6%96%AF%E5%9D%A6%E7%A6%8F%E5%A4%A7%E5%AD%A6 "斯坦福大学")为控制机器人Shakey而开发的STRIPS系统。[[53]](#cite_note-53)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/6/67/Semantic_Net.svg/250px-Semantic_Net.svg.png)\n\n#### 自然语言\n\nAI研究的一个重要目标是使计算机能够通过[自然语言](/wiki/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86 "自然语言处理")（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。[[54]](#cite_note-54)\n\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“[语义网](/wiki/%E8%AF%AD%E4%B9%89%E7%BD%91 "语义网")（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发；[[55]](#cite_note-55) 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。[[56]](#cite_note-56)\n\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。[[57]](#cite_note-57)\n\n#### 微世界\n\n60年代后期，[麻省理工大学](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")AI实验室的马文·闵斯基和[西摩尔·派普特](/wiki/%E8%A5%BF%E6%91%A9%E7%88%BE%C2%B7%E6%B4%BE%E6%99%AE%E7%89%B9 "西摩尔·派普特")建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。[[58]](#cite_note-58)\n\n在这一指导思想下，[杰拉德·杰伊·萨斯曼](/wiki/%E5%82%91%E6%8B%89%E5%BE%B7%C2%B7%E5%82%91%E4%BC%8A%C2%B7%E8%96%A9%E6%96%AF%E6%9B%BC "杰拉德·杰伊·萨斯曼")（研究组长），阿道佛·古兹曼（Adolfo Guzman），[大卫·瓦尔兹](/w/index.php?title=%E5%A4%A7%E8%A1%9B%C2%B7%E7%93%A6%E7%88%BE%E8%8C%B2&action=edit&redlink=1 "大卫·瓦尔兹（页面不存在）")（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在[机器视觉](/wiki/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89 "机器视觉")领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的[SHRDLU](/wiki/SHRDLU "SHRDLU")，它能用普通的英语句子与人交流，还能作出决策并执行操作。[[59]](#cite_note-59)\n\n### 乐观思潮\n\n第一代AI研究者们曾作出了如下预言:\n\n### 经费\n\n1963年6月，[MIT](/wiki/%E9%BA%BB%E7%9C%81%E7%90%86%E5%B7%A5%E5%A4%A7%E5%AD%A6 "麻省理工大学")从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。[[64]](#cite_note-64)ARPA还对艾伦·纽厄尔和赫伯特·西蒙在[卡内基梅隆大学](/wiki/%E5%8D%A1%E5%86%85%E5%9F%BA%E6%A2%85%E9%9A%86%E5%A4%A7%E5%AD%A6 "卡内基梅隆大学")的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。[[65]](#cite_note-65)另一个重要的AI实验室于1965年由Donald Michie在[爱丁堡大学](/wiki/%E7%88%B1%E4%B8%81%E5%A0%A1%E5%A4%A7%E5%AD%A6 "爱丁堡大学")建立。[[66]](#cite_note-66)在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。[[67]](#cite_note-67)\n\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。[[68]](#cite_note-68)这导致了MIT无约无束的研究氛围及其[hacker](/wiki/Hacker "Hacker")文化的形成，[[69]](#cite_note-69)但是好景不长。\n\n## 第一次AI低谷：1974 - 1980\n\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。[[70]](#cite_note-70)同时，由于马文·闵斯基对[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")的激烈批评，[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")（即[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")）销声匿迹了十年。[[71]](#cite_note-Perceptrons-71)70年代后期，尽管遭遇了公众的误解，AI在[逻辑编程](/wiki/%E9%80%BB%E8%BE%91%E7%BC%96%E7%A8%8B "逻辑编程")，常识推理等一些领域还是有所进展。[[72]](#cite_note-72)\n\n### 问题\n\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。[[73]](#cite_note-73)AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。[[74]](#cite_note-74)\n\n### 停止拨款\n\n由于AI的进展缓慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。[[81]](#cite_note-81)1973年[詹姆斯·莱特希尔](/wiki/%E8%A9%B9%E5%A7%86%E6%96%AF%C2%B7%E8%8E%B1%E7%89%B9%E5%B8%8C%E5%B0%94 "詹姆斯·莱特希尔")针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮[[82]](#cite_note-82)（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。[[83]](#cite_note-83)DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。[[84]](#cite_note-84)到了1974年已经很难再找到对AI项目的资助。\n\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。[[85]](#cite_note-85)还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。[[86]](#cite_note-86)\n\n### 来自大学的批评\n\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为[哥德尔不完备定理](/wiki/%E5%93%A5%E5%BE%B7%E5%B0%94%E4%B8%8D%E5%AE%8C%E5%A4%87%E5%AE%9A%E7%90%86 "哥德尔不完备定理")已经证明[形式系统](/wiki/%E5%BD%A2%E5%BC%8F%E7%B3%BB%E7%BB%9F "形式系统")（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。[[87]](#cite_note-87)修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。[[88]](#cite_note-88)[[89]](#cite_note-89) 约翰·希尔勒于1980年提出“[中文房间](/wiki/%E4%B8%AD%E6%96%87%E6%88%BF%E9%97%B4 "中文房间")”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“[意向性](/wiki/%E6%84%8F%E5%90%91%E6%80%A7 "意向性")（intentionality）”问题。希尔勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。[[90]](#cite_note-90)\n\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而[计算复杂性](/wiki/%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7 "计算复杂性")和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。马文·闵斯基提到德雷福斯和希尔勒时说，“他们误解了，所以应该忽略”。[[91]](#cite_note-91)在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。[[92]](#cite_note-92) ELIZA程序的作者约瑟夫·维森鲍姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。[[93]](#cite_note-93)\n\n约瑟夫·维森鲍姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为约瑟夫·维森鲍姆对他的程序没有贡献，但这于事无补。1976年约瑟夫·维森鲍姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。[[94]](#cite_note-94)\n\n### 感知器与联结主义遭到冷落\n\n[感知器](/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8 "感知器")是[神经网络](/wiki/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C "神经网络")的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：[联结主义](/wiki/%E8%81%94%E7%BB%93%E4%B8%BB%E4%B9%89 "联结主义")的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。[[71]](#cite_note-Perceptrons-71)\n\n### “简约派（the neats）”：逻辑，Prolog语言和专家系统\n\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。[[95]](#cite_note-95)1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。[[96]](#cite_note-96)70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言[Prolog](/wiki/Prolog "Prolog")。[[97]](#cite_note-97)Prolog使用一组逻辑(与“规则”和“[生产规则](/w/index.php?title=%E7%94%9F%E7%94%A2%E8%A6%8F%E5%89%87&action=edit&redlink=1 "生产规则（页面不存在）")（英语：[Production\\_system\\_(computer\\_science)](https://en.wikipedia.org/wiki/Production_system_(computer_science) "en:Production system (computer science)")）”密切相关的“[霍恩子句](/wiki/%E9%9C%8D%E6%81%A9%E5%AD%90%E5%8F%A5 "霍恩子句")”)，并允许进行可处理的计算。规则持续带来影响，为[爱德华·费根鲍姆](/wiki/%E6%84%9B%E5%BE%B7%E8%8F%AF%C2%B7%E8%B2%BB%E6%A0%B9%E9%AE%91%E5%A7%86 "爱德华·费根鲍姆")的[专家系统](/wiki/%E5%B0%88%E5%AE%B6%E7%B3%BB%E7%B5%B1 "专家系统")以及艾伦·纽厄尔和赫伯特·西蒙的工作奠定基础，使其完成了[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")及[认知统一理论](/wiki/%E8%AA%8D%E7%9F%A5%E7%B5%B1%E4%B8%80%E7%90%86%E8%AB%96 "认知统一理论")。[[98]](#cite_note-98)\n\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，[阿摩司·特沃斯基](/wiki/%E9%98%BF%E6%91%A9%E5%8F%B8%C2%B7%E7%89%B9%E6%B2%83%E6%96%AF%E5%9F%BA "阿摩司·特沃斯基")，Daniel Kahneman等人的实验证明了这一点。[[99]](#cite_note-99)McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。[[100]](#cite_note-100)\n\n### “芜杂派（the scruffies）”：框架和脚本\n\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。[[101]](#cite_note-101)Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。[[102]](#cite_note-102)\n\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。[[103]](#cite_note-103) 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n## 第二波浪潮 - 繁荣：1980—1987\n\n在80年代，一类名为“[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n### 专家系统获得赏识\n\n[专家系统](/wiki/%E4%B8%93%E5%AE%B6%E7%B3%BB%E7%BB%9F "专家系统")是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。[[104]](#cite_note-104)\n\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。[[105]](#cite_note-105)\n\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。[[106]](#cite_note-106)全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。[[107]](#cite_note-107)\n\n### 知识革命\n\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。 [[108]](#cite_note-108) Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” [[109]](#cite_note-109)知识库系统和知识工程成为了80年代AI研究的主要方向。[[110]](#cite_note-110)\n\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。[[111]](#cite_note-111)\n\n### 重获拨款：第五代工程\n\n1981年，日本经济产业省拨款八亿五千万美元支持[第五代计算机](/wiki/%E7%AC%AC%E4%BA%94%E4%BB%A3%E9%9B%BB%E8%85%A6 "第五代电脑")项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。[[112]](#cite_note-112)令“芜杂派”不满的是，他们选用[Prolog](/wiki/Prolog "Prolog")作为该项目的主要编程语言。[[113]](#cite_note-113)\n\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。[[114]](#cite_note-114)[[115]](#cite_note-Norvig_25-115) DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。[[116]](#cite_note-116)\n\n![](//upload.wikimedia.org/wikipedia/commons/thumb/9/95/Hopfield-net.png/250px-Hopfield-net.png)\n\n### 联结主义的重生\n\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了[反向传播算法](/wiki/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95 "反向传播算法")，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。[[115]](#cite_note-Norvig_25-115)[[117]](#cite_note-117)\n\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“[分布式并行处理](/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86 "分布式并行处理")”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。[[115]](#cite_note-Norvig_25-115)[[118]](#cite_note-118)\n\n## 第二次AI低谷：1987—1993\n\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n### 人工智慧的低谷\n\n“[AI之冬](/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E4%BD%8E%E8%B0%B7 "人工智慧低谷")”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。[[119]](#cite_note-119)事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。[[120]](#cite_note-120)\n\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")）））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。[[121]](#cite_note-121)\n\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。[[122]](#cite_note-122)\n\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。[[123]](#cite_note-FifthGenEnd-123) 与其他AI项目一样，期望比真正可能实现的要高得多。[[123]](#cite_note-FifthGenEnd-123)\n\n### 躯体的重要性：Nouvelle AI与嵌入式推理\n\n80年代后期，一些研究者根据机器人学的成就提出了一种全新的人工智能方案。[[124]](#cite_note-124) 他们相信，为了获得真正的智能，机器必须具有躯体 - 它需要感知，移动，生存，与这个世界交互。他们认为这些感知运动技能对于常识推理等高层次技能是至关重要的，而抽象推理不过是人类最不重要，也最无趣的技能（参见[莫拉维克悖论](/wiki/%E8%8E%AB%E6%8B%89%E7%B6%AD%E5%85%8B%E6%82%96%E8%AB%96 "莫拉维克悖论")）。[[125]](#cite_note-125)他们号召“[自底向上](/wiki/%E8%87%AA%E4%B8%8A%E8%80%8C%E4%B8%8B%E5%92%8C%E8%87%AA%E4%B8%8B%E8%80%8C%E4%B8%8A%E8%A8%AD%E8%A8%88 "自上而下和自下而上设计")”地创造智能，这一主张复兴了从60年代就沉寂下来的控制论。\n\n另一位先驱是在理论神经科学上造诣深厚的David Marr，他于70年代来到MIT指导视觉研究组的工作。他排斥所有符号化方法（不论是McCarthy的逻辑学还是Minsky的框架），认为实现AI需要自底向上地理解视觉的物理机制，而符号处理应在此之后进行。[[126]](#cite_note-126)\n\n在发表于1990年的论文“大象不玩象棋（Elephants Don\'t Play Chess）”中，机器人研究者Rodney Brooks针对“[物理符号系统假设](/wiki/%E7%89%A9%E7%90%86%E7%AC%A6%E8%99%9F%E7%B3%BB%E7%B5%B1 "物理符号系统")”提出批评，他认为符号是可有可无的，因为“这个世界就是描述它自己最好的模型。它总是最新的。它总是包括了需要研究的所有细节。诀窍在于正确地，足够频繁地感知它。” [[127]](#cite_note-127)在80年代和90年代也有许多认知科学家反对基于符号处理的智能模型，认为身体是推理的必要条件，这一理论被称为“[具身的心灵/理性/ 认知](/wiki/%E9%AB%94%E5%8C%96%E8%AA%8D%E7%9F%A5 "体化认知")（embodied mind/reason/cognition）”论题。[[128]](#cite_note-128)\n\n## 第三波浪潮 - 大数据与机器学习：1993—2019\n\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。[[129]](#cite_note-129)AI比以往的任何时候都更加谨慎，却也更加成功。\n\n### 里程碑和摩尔定律\n\n1997年5月11日，深蓝成为战胜国际象棋世界冠军[卡斯帕罗夫](/wiki/%E5%8D%A1%E6%96%AF%E5%B8%95%E7%BE%85%E5%A4%AB "卡斯帕罗夫")的第一个计算机系统。[[130]](#cite_note-130)2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。[[131]](#cite_note-131)2009年，[蓝脑计画](/wiki/%E8%97%8D%E8%85%A6%E8%A8%88%E7%95%AB "蓝脑计画")声称已经成功地模拟了部分鼠脑。2011年，[IBM 沃森](/w/index.php?title=IBM_%E6%B2%83%E6%A3%AE_(%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E7%A8%8B%E5%BA%8F)&action=edit&redlink=1 "IBM 沃森 (人工智慧程序)（页面不存在）")参加《[危险边缘](/wiki/%E5%8D%B1%E9%99%A9%E8%BE%B9%E7%BC%98 "危险边缘")》节目，在最后一集打败了人类选手。2016年3月，[AlphaGo](/wiki/AlphaGo "AlphaGo")击败[李世乭](/wiki/%E6%9D%8E%E4%B8%96%E4%B9%AD "李世乭")，成为第一个不让子而击败职业[围棋](/wiki/%E5%9C%8D%E6%A3%8B "围棋")棋士的[电脑围棋](/wiki/%E7%94%B5%E8%84%91%E5%9B%B4%E6%A3%8B "电脑围棋")程式。2017年5月，AlphaGo在[中国乌镇围棋峰会](/wiki/%E4%B8%AD%E5%9B%BD%E4%B9%8C%E9%95%87%E5%9B%B4%E6%A3%8B%E5%B3%B0%E4%BC%9A "中国乌镇围棋峰会")的三局比赛中击败[[132]](#cite_note-wuzhensecond-132)当时世界排名第一[[133]](#cite_note-133)[[134]](#cite_note-134)的中国棋手[柯洁](/wiki/%E6%9F%AF%E6%B4%81 "柯洁")。\n\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。[[135]](#cite_note-135)事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。[[136]](#cite_note-136)这种剧烈增长可以用[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n### 智能代理\n\n90年代，被称为“[智能代理](/wiki/%E6%99%BA%E8%83%BD%E4%BB%A3%E7%90%86 "智能代理")”的新范式被广泛接受。[[137]](#cite_note-137)尽管早期研究者提出了模块化的分治策略，[[138]](#cite_note-138) 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。[[139]](#cite_note-R27-139)当经济学中的“[理性代理](/wiki/%E7%90%86%E6%80%A7%E4%B8%BB%E4%BD%93 "理性主体")（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。[[140]](#cite_note-140)\n\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的[代理架构](/w/index.php?title=%E4%BB%A3%E7%90%86%E6%9E%B6%E6%9E%84&action=edit&redlink=1 "代理架构（页面不存在）")（英语：[Agent\\_architecture](https://en.wikipedia.org/wiki/Agent_architecture "en:Agent architecture")）（像Newell的[Soar](/wiki/Soar_(%E8%AA%8D%E7%9F%A5%E6%9E%B6%E6%A7%8B) "Soar (认知架构)")那样），允许研究者们应用交互的智能代理建立起通用的智能系统。[[139]](#cite_note-R27-139)[[141]](#cite_note-141)\n\n### “简约派”的胜利\n\n越来越多的AI研究者们开始开发和使用复杂的数学工具。[[142]](#cite_note-142)人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。[[143]](#cite_note-143) Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。[[144]](#cite_note-RN25-144)[[145]](#cite_note-145)\n\nJudea Pearl发表于1988年的名著[[146]](#cite_note-146)将概率论和决策理论引入AI。现已投入应用的新工具包括[贝叶斯网络](/wiki/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C "贝叶斯网络")，[隐马尔可夫模型](/wiki/%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E6%A8%A1%E5%9E%8B "隐马尔可夫模型")，[信息论](/wiki/%E4%BF%A1%E6%81%AF%E8%AE%BA "信息论")，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。[[144]](#cite_note-RN25-144)\n\n### 幕后的AI\n\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，[[147]](#cite_note-147)这些解决方案在产业界起到了重要作用。[[148]](#cite_note-148)应用了AI技术的有[数据挖掘](/wiki/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98 "数据挖掘")，[工业机器人](/wiki/%E5%B7%A5%E4%B8%9A%E6%9C%BA%E5%99%A8%E4%BA%BA "工业机器人")，[物流](/wiki/%E7%89%A9%E6%B5%81 "物流")[[149]](#cite_note-149)，[语音识别](/wiki/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB "语音识别")[[150]](#cite_note-150)，银行业软件[[151]](#cite_note-CNN7242006-151)，医疗诊断[[151]](#cite_note-CNN7242006-151)和[Google](/wiki/Google "Google")搜索引擎等。[[152]](#cite_note-152)\n\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。[[153]](#cite_note-153)[尼克·博斯特罗姆](/wiki/%E5%B0%BC%E5%85%8B%C2%B7%E5%8D%9A%E6%96%AF%E7%89%B9%E7%BD%97%E5%A7%86 "尼克·博斯特罗姆")解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”[[154]](#cite_note-154)\n\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如[信息学](/wiki/%E4%BF%A1%E6%81%AF%E5%AD%A6 "信息学")，[知识系统](/w/index.php?title=%E7%9F%A5%E8%AF%86%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "知识系统（页面不存在）")，[认知系统](/w/index.php?title=%E8%AE%A4%E7%9F%A5%E7%B3%BB%E7%BB%9F&action=edit&redlink=1 "认知系统（页面不存在）")或[计算智能](/w/index.php?title=%E8%AE%A1%E7%AE%97%E6%99%BA%E8%83%BD&action=edit&redlink=1 "计算智能（页面不存在）")。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”[[155]](#cite_note-155)[[156]](#cite_note-156)[[157]](#cite_note-157)\n\n### HAL 9000在哪里?\n\n1968年[亚瑟·克拉克](/wiki/%E4%BA%9E%E7%91%9F%C2%B7%E5%85%8B%E6%8B%89%E5%85%8B "亚瑟·克拉克")和[史丹利·库柏力克](/wiki/%E5%8F%B2%E4%B8%B9%E5%88%A9%C2%B7%E5%BA%AB%E6%9F%8F%E5%8A%9B%E5%85%8B "史丹利·库柏力克")创作的《“[2001太空漫游](/wiki/2001%E5%A4%AA%E7%A9%BA%E6%BC%AB%E6%B8%B8 "2001太空漫游")”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。[[158]](#cite_note-158)\n\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。[[159]](#cite_note-159) Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，约翰·麦卡锡则归咎于资格问题（[qualification problem](/w/index.php?title=Qualification_problem&action=edit&redlink=1 "Qualification problem（页面不存在）")（英语：[qualification problem](https://en.wikipedia.org/wiki/qualification_problem "en:qualification problem")））。[[160]](#cite_note-160)[雷蒙德·库茨魏尔](/wiki/%E9%9B%B7%E8%92%99%E5%BE%B7%C2%B7%E5%BA%93%E8%8C%A8%E9%AD%8F%E5%B0%94 "雷蒙德·库茨魏尔")相信问题在于计算机性能，根据[摩尔定律](/wiki/%E6%91%A9%E5%B0%94%E5%AE%9A%E5%BE%8B "摩尔定律")，他预测具有人类智能水平的机器将在2029年出现。[[161]](#cite_note-161)杰夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。[[162]](#cite_note-162)还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n### 深度学习，大数据和通用人工智能：2011至2019\n\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的[机器学习](/wiki/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0 "机器学习")技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n#### 深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如[MNIST数据集](/wiki/MNIST%E6%95%B0%E6%8D%AE%E9%9B%86 "MNIST数据集")（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n#### 大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n## 第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n### 大型语言模型\n\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序[ChatGPT](/wiki/ChatGPT "ChatGPT")基于[GPT-3.5](/wiki/GPT-3 "GPT-3")架构的[大型语言模型](/wiki/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B "大型语言模型")并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，[GPT-4](/wiki/GPT-4 "GPT-4")正式推出，进一步加强大型语言模型的推理能力。2023年8月，中国百度公司向公众开放使用[文心一言](/wiki/%E6%96%87%E5%BF%83%E4%B8%80%E8%A8%80 "文心一言")，让中国内地民众都可以使用内地版的大型语言模型。2025年1月，[深度求索](/wiki/%E6%B7%B1%E5%BA%A6%E6%B1%82%E7%B4%A2 "深度求索")推出著名的[DeepSeek-R1](/wiki/DeepSeek-R1 "DeepSeek-R1") [开源](/wiki/%E9%96%8B%E6%BA%90 "开源")大型语言模型，并使用新的算法减低训练成本。\n\n### 机器人整合与人工智能的实际应用（2025年至今）\n\n先进的人工智能（AI）系统能够高精度理解和回应人类对话，已成熟到能够与机器人无缝整合，改变了制造业、医疗保健、公共服务和材料研究等行业。[[163]](#cite_note-163) 人工智能还通过高级数据分析和假设生成加速科学研究。[[164]](#cite_note-164) 包括中国、美国和日本在内的国家在政策和资金方面进行了大量投资，以部署人工智能驱动的机器人和人工智能的实际应用，解决劳动力短缺问题，促进创新并提高效率，同时实施监管框架以确保道德和安全发展。[[165]](#cite_note-165)\n\n#### 中国\n\n2025年被誉为“人工智能机器人年”，标志著人工智能（AI）与机器人无缝整合的关键时刻。在2025年，中国投资约7300亿元人民币（约1000亿美元）用于智能制造和医疗保健领域的人工智能和机器人技术发展。[[166]](#cite_note-166) [[167]](#cite_note-167) 第十四个五年规划（2021-2025年）优先发展服务机器人，人工智能系统使机器人能够执行复杂任务，例如协助手术或自动化工厂装配线。[[168]](#cite_note-168) 例如，中国医院中的人工智能人形机器人可以解读患者请求、运送物资并协助护士完成日常任务，显示现有的人工智能对话能力足以应用于实际的机器人应用。部分资金还支持国防应用，例如自主无人机。[[169]](#cite_note-169)[[170]](#cite_note-170) 自2025年9月起，中国要求对人工智能生成的内容进行标记，以确保技术的透明度和公众信任。[[171]](#cite_note-171)\n\n#### 美国\n\n2025年1月，人工智能基础设施投资取得重大进展，[星际之门计划](/wiki/%E6%98%9F%E9%99%85%E4%B9%8B%E9%97%A8%E8%AE%A1%E5%88%92 "星际之门计划") 成立。这家由 [OpenAI](/wiki/OpenAI "OpenAI")、[SoftBank Group](/wiki/SoftBank_Group "SoftBank Group")、[Oracle](/wiki/Oracle_Corporation "Oracle Corporation") 和 [MGX](/w/index.php?title=MGX_Fund_Management_Limited&action=edit&redlink=1 "MGX Fund Management Limited（页面不存在）") 组成的合资企业宣布计划到2029年在[美国](/wiki/%E7%BE%8E%E5%9C%8B "美国")投资5000亿美元用于人工智能基础设施，首期投资1000亿美元，以支持美国的再工业化并提供保护美国及其盟友国家安全的战略能力。[[172]](#cite_note-172) 该合资企业于2025年1月21日由美国总统唐纳德·特朗普正式宣布，SoftBank Group首席执行官 [孙正义](/wiki/%E5%AD%AB%E6%AD%A3%E7%BE%A9 "孙正义") 被任命为主席。[[173]](#cite_note-reuters-173)[[174]](#cite_note-174)\n\n美国政府拨款约20亿美元用于在制造业和物流业中整合人工智能和机器人技术，利用人工智能处理自然语言和执行用户指令的能力。[[175]](#cite_note-175) 各州政府补充资金支持服务机器人，例如部署在仓库中执行口头指令进行库存管理，或在养老院中回应居民的援助请求。[[176]](#cite_note-176) 这些应用表明，将已经熟练于人类交互的高级人工智能与机器人硬体结合是一项实际的前进步骤。\n\n2025年1月，第14179号行政命令确立了“人工智能行动计划”，以加速这些技术的创新和部署。[[177]](#cite_note-177)\n\n#### 影响\n\n2020年代各国政府和机构对AI的投资加速了人工智能的发展，推动了科学进步，提高了劳动效率，并通过自动化复杂任务改变了各行业。[[178]](#cite_note-178) 通过将成熟的人工智能系统整合到各行业的应用当中，这些发展有望彻底改变智能制造和服务行业，重塑人类的日常生活。\n\n## 注释\n\n## 参考文献\n\n`|date=`\n`|date=`\n`|date=`\n\n.\n\n![](https://zh.wikipedia.org/wiki/Special:CentralAutoLogin/start?useformat=desktop&type=1x1&usesul3=1)\n![Wikimedia Foundation](/static/images/footer/wikimedia.svg)\n![Powered by MediaWiki](/w/resources/assets/mediawiki_compact.svg)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.99847525, 'save_path': None}}
2026-02-02 20:35:14,838 - __main__ - INFO - handle_search: returned=10
2026-02-02 20:35:14,838 - __main__ - INFO - call_tool: name=exa_context_search, result_type=papers, count=10
2026-02-02 20:35:14,838 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '人工智能史 - 维基百科，自由的百科全书[跳转到内容] \n[![]![维基百科]![自由的百科全书]] \n[搜索] \n搜索# 人工智能史30种语言\n* [Afrikaans] \n* [العربية] \n* [Azərbaycanca] \n* [বাংলা] \n* [Català] \n* [کوردی] \n* [Deutsch] \n* [Ελληνικά] \n* [English] \n* [Español] \n* [Euskara] \n* [فارسی] \n* [Français] \n* [עברית] \n* [हिन्दी] \n* [Հայերեն] \n* [Bahasa Indonesia] \n* [Íslenska] \n* [日本語] \n* [한국어] \n* [پښتو] \n* [Português] \n* [Русский] \n* [Српски / srpski] \n* [தமிழ்] \n* [Türkçe] \n* [Українська] \n* [Tiếng Việt] \n* [粵語] \n* [IsiZulu] \n[编辑链接] \n维基百科，自由的百科全书|[人工智能] 系列内容|\n[![]] |\n主要目标* [知识表示] \n* [自动规划] （英语：[Automated planning and scheduling] ）\n* [机器学习] \n* [语言处理] \n* [电脑视觉] \n* [机器人学] \n* [强人工智慧] \n* [弱人工智慧] \n* [人工智能对齐] \n|\n实现方式* [符号人工智能] \n* [深度学习] \n* [贝氏网路] \n* [进化算法] \n* [混合智能系统] \n* [混合专家模型] \n* [生成式人工智慧] \n* [代理式人工智能] （英语：[Agentic AI] ）\n|\n[人工智能哲学] \n* [伦理] （英语：[Ethics of artificial intelligence] ）\n* [人工智能安全] （英语：[AI safety] ）\n* [幻觉] \n* [存在风险] （英语：[Existential risk from artificial general intelligence] ）\n* [图灵测试] \n* [中文房间] \n* [可解释人工智慧] \n* [友好的人工智能] （英语：[Friendly artificial intelligence] ）\n* [人工智能监管] （英语：[Regulation of artificial intelligence] ）\n|\n历史* [时间轴] （英语：[Timeline of artificial intelligence] ）\n* [发展] （英语：[Progress in artificial intelligence] ）\n* [专家系统] \n* [人工智慧低谷] \n* [人工智能热潮] \n* [人工智能法案] \n|\n[人工智能的应用] \n* [应用] \n* [AlphaFold] \n* [深度伪造] \n* [AI艺术] \n* [音乐] \n* [医疗保健] \n* [工业] \n* [机器翻译] \n* [军事] \n* [项目] （英语：[List of artificial intelligence projects] ）\n* [编程语言] （英语：[List of programming languages for artificial intelligence] ）\n|\n主题与列表* [主题] \n* [术语表] \n* [AI概述] \n* [AI公司列表] （英语：[List of artificial intelligence companies] ）\n* [AI项目列表] （英语：[List of artificial intelligence projects] ）\n|\n* [查] \n* [论] \n* [编] \n|\n参见：[人工智能发展年表] （英语：[Timeline of artificial intelligence] ）\n**人工智能的历史**源远流长。在古代的[神话] [传说] 中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[&#91;1&#93;] 现代意义上的[AI] 始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑] 的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，[人工智能] 的研究领域确立于在[达特茅斯学院] 举行的[会议] 。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[&#91;2&#93;] 他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮] （也被称作AI之冬）。由于[詹姆斯·莱特希尔] 爵士的批评和国会方面的压力，[美国] 和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[&#91;3&#93;] \n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平] 的机器至今仍未出现。[图灵] 在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[&#91;4&#93;] \n在21世纪的第一个十年，[机器学习] 得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n|[计算历史] （英语：[History of computing] ）|\n[硬件] |\n* [1960年代之前] \n* [1960年代至今] （英语：[History of computing hardware (1960s–present)] ）|\n[软件] |\n* [软体] （英语：[History of software] ）\n* [Unix] （英语：[History of Unix] ）\n* [自由和开源软件] （英语：[History of free and open-source software] ）|\n[计算机科学] |\n* 人工智能* [编译器构造] （英语：[History of compiler construction] ）\n* [计算机科学] （英语：[History of computing] ）\n* [操作系统] \n* [程式语言] \n* [杰出先驱者] （英语：[List of pioneers in computer science] ）\n* [软体工程] （英语：[History of software engineering] ）|\n现代概念|\n* [通用CPU] （英语：[History of general-purpose CPUs] ）\n* [图形用户界面] \n* [互联网] \n* [个人电脑] （英语：[History of personal computers] ）\n* [笔记型电脑] （英语：[History of laptops] ）\n* [电子游戏] \n* [全球资讯网] （英语：[History of the World Wide Web] ）|\n按国家|\n* [保加利亚] （英语：[History of computer hardware in Bulgaria] ）\n* [波兰] （英语：[History of computing in Poland] ）\n* [罗马尼亚] （英语：[History of computing in Romania] ）\n* [苏联集团国家] （英语：[History of computer hardware in Soviet Bloc countries] ）\n* [苏联] （英语：[History of computing in the Soviet Union] ）\n* [南斯拉夫] （英语：[History of computer hardware in Yugoslavia] ）|\n[计算年表] （英语：[Timeline of computing] ）|\n* [1950年之前] （英语：[Timeline of computing hardware before 1950] ）\n* [1950–1979] （英语：[Timeline of computing 1950–1979] ）\n* [1980–1989] （英语：[Timeline of computing 1980–1989] ）\n* [1990–1999] （英语：[Timeline of computing 1990–1999] ）\n* [2000–2009] （英语：[Timeline of computing 2000–2009] ）\n* [2010–2019] （英语：[Timeline of computing 2010–2019] ）\n* [更多年表……] |\n[计算机科学词汇] （英语：[Glossary of computer science] ）|\n* ![分类] [分类] |\n* [查] \n* [论] \n* [编] \n|\n## 先驱[[编辑]]\n奥特曼写道[&#91;1&#93;] ：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机] ）的实践之中。[&#91;5&#93;] \n### 神话，幻想和预言中的AI\n[[编辑]]\n[希腊神话] 中已经出现了机械人和人造人，如[赫淮斯托斯] 的黄金机器人和[皮格马利翁] 的[伽拉忒亚] 。[&#91;6&#93;] 中世纪出现了使用巫术或[炼金术] 将意识赋予无生命物质的传说，如[贾比尔] 的*Takwin*，[帕拉塞尔苏斯] 的[何蒙库鲁兹] 和Judah Loew的[魔像] 。[&#91;7&#93;] 19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱] 的《[弗兰肯斯坦] 》和[卡雷尔·恰佩克] 的《罗素姆的万能机器人》。[&#91;8&#93;] Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[&#91;9&#93;] 至今人工智能仍然是科幻小说的重要元素。\n### 自动人偶[[编辑]]\n主条目：[自动机] \n[![]] [加扎利] 的可编程自动人偶（1206年）\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师] （中国西周）[&#91;10&#93;] ，[希罗] （希腊）[&#91;11&#93;] ，[加扎利] [&#91;12&#93;] 和Wolfgang von Kempelen[&#91;13&#93;] 等等。已知最古老的“机器人”是[古埃及] 和[古希腊] 的[圣像] ，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯] （[赫耳墨斯·特里斯墨吉斯忒斯] ）写道“当发现神的本性时，人就能够重现他”[&#91;14&#93;] [&#91;15&#93;] 。\n### 形式推理[[编辑]]\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德] （对三段论逻辑进行了形式分析），[欧几里得] （其著作《[几何原本] 》是形式推理的典范），[花剌子密] （代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉] 和[邓斯·司各脱] 。[&#91;16&#93;] \n[马略卡] 哲学家[拉蒙·柳利] （1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[&#91;17&#93;] 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[&#91;18&#93;] Llull的工作对[莱布尼兹] 产生了很大影响，后者进一步发展了他的思想。[&#91;19&#93;] \n[![]] [莱布尼兹] 猜测人类的思想可以简化为机械计算\n在17世纪中，[莱布尼兹] ，[托马斯·霍布斯] 和[笛卡儿] 尝试将理性的思考系统化为代数学或几何学那样的体系。[&#91;20&#93;] 霍布斯在其著作《[利维坦] 》中有一句名言：“推理就是计算（reason is nothing but reckoning）。”[&#91;21&#93;] 莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字] ），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[&#91;22&#93;] 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，[数理逻辑] 研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔] 的《思维的定律》与[弗雷格] 的《[概念文字] 》。基于弗雷格的系统，[罗素] 和[怀特海] 在他们于1913年出版的巨著《[数学原理] 》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特] ，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?”[&#91;16&#93;] 这个问题的最终回答由[哥德尔不完备定理] ，[图灵机] 和[Alonzo Church] 的[λ演算] 给出。[&#91;16&#93;] [&#91;23&#93;] 他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n[![]] 在摩尔学校的电气工程的ENIAC计算机\n[邱奇-图灵论题] 暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机] ：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[&#91;16&#93;] [&#91;24&#93;] \n### 计算机科学[[编辑]]\n主条目：[计算机硬体历史] \n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇] 设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝] 预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[&#91;25&#93;] （她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数] 的方法。）\n第一批现代计算机是[二战] 期间建造的大型译码机（包括Z3，[ENIAC] 和Colossus等）。[&#91;26&#93;] 后两个机器的理论基础是[图灵] 和[约翰·冯·诺伊曼] 提出和发展的学说。[&#91;27&#93;] \n## 人工智能的诞生：1943 - 1956\n[[编辑]]\n[&#91;28&#93;] 在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n### 控制论与早期神经网络[[编辑]]\n[![]] IBM 702：第一代AI研究者使用的电脑\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳] 的[控制论] 描述了电子网络的控制和稳定性。[克劳德·香农] 提出的[信息论] 则描述了[数字信号] （即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[&#91;29&#93;] \n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[&#91;30&#93;] \nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。', 'doi': '', 'published_date': '2026-02-02T20:35:14.837855', 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}
2026-02-02 20:35:17,333 - __main__ - INFO - handle_search: returned=3
2026-02-02 20:35:17,333 - __main__ - INFO - call_tool: name=wikipedia_search, result_type=papers, count=3
2026-02-02 20:35:17,334 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-02T20:35:17.332875', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-02 20:35:17', 'language': 'zh'}}
2026-02-02 20:35:42,912 - __main__ - INFO - call_tool: name=exa_context_download, args={'papers': [{'paper_id': '', 'title': '人工智能史- 维基百科，自由的百科全书', 'authors': [], 'abstract': '人工智能史 - 维基百科，自由的百科全书[跳转到内容] \n[![]![维基百科]![自由的百科全书]] \n[搜索] \n搜索# 人工智能史30种语言\n* [Afrikaans] \n* [العربية] \n* [Azərbaycanca] \n* [বাংলা] \n* [Català] \n* [کوردی] \n* [Deutsch] \n* [Ελληνικά] \n* [English] \n* [Español] \n* [Euskara] \n* [فارسی] \n* [Français] \n* [עברית] \n* [हिन्दी] \n* [Հայերեն] \n* [Bahasa Indonesia] \n* [Íslenska] \n* [日本語] \n* [한국어] \n* [پښتو] \n* [Português] \n* [Русский] \n* [Српски / srpski] \n* [தமிழ்] \n* [Türkçe] \n* [Українська] \n* [Tiếng Việt] \n* [粵語] \n* [IsiZulu] \n[编辑链接] \n维基百科，自由的百科全书|[人工智能] 系列内容|\n[![]] |\n主要目标* [知识表示] \n* [自动规划] （英语：[Automated planning and scheduling] ）\n* [机器学习] \n* [语言处理] \n* [电脑视觉] \n* [机器人学] \n* [强人工智慧] \n* [弱人工智慧] \n* [人工智能对齐] \n|\n实现方式* [符号人工智能] \n* [深度学习] \n* [贝氏网路] \n* [进化算法] \n* [混合智能系统] \n* [混合专家模型] \n* [生成式人工智慧] \n* [代理式人工智能] （英语：[Agentic AI] ）\n|\n[人工智能哲学] \n* [伦理] （英语：[Ethics of artificial intelligence] ）\n* [人工智能安全] （英语：[AI safety] ）\n* [幻觉] \n* [存在风险] （英语：[Existential risk from artificial general intelligence] ）\n* [图灵测试] \n* [中文房间] \n* [可解释人工智慧] \n* [友好的人工智能] （英语：[Friendly artificial intelligence] ）\n* [人工智能监管] （英语：[Regulation of artificial intelligence] ）\n|\n历史* [时间轴] （英语：[Timeline of artificial intelligence] ）\n* [发展] （英语：[Progress in artificial intelligence] ）\n* [专家系统] \n* [人工智慧低谷] \n* [人工智能热潮] \n* [人工智能法案] \n|\n[人工智能的应用] \n* [应用] \n* [AlphaFold] \n* [深度伪造] \n* [AI艺术] \n* [音乐] \n* [医疗保健] \n* [工业] \n* [机器翻译] \n* [军事] \n* [项目] （英语：[List of artificial intelligence projects] ）\n* [编程语言] （英语：[List of programming languages for artificial intelligence] ）\n|\n主题与列表* [主题] \n* [术语表] \n* [AI概述] \n* [AI公司列表] （英语：[List of artificial intelligence companies] ）\n* [AI项目列表] （英语：[List of artificial intelligence projects] ）\n|\n* [查] \n* [论] \n* [编] \n|\n参见：[人工智能发展年表] （英语：[Timeline of artificial intelligence] ）\n**人工智能的历史**源远流长。在古代的[神话] [传说] 中，技艺高超的工匠可以制作人造人，并为其赋予智能或意识。[&#91;1&#93;] 现代意义上的[AI] 始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的[可编程数字电脑] 的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，[人工智能] 的研究领域确立于在[达特茅斯学院] 举行的[会议] 。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。[&#91;2&#93;] 他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出现过几次[低潮] （也被称作AI之冬）。由于[詹姆斯·莱特希尔] 爵士的批评和国会方面的压力，[美国] 和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。[&#91;3&#93;] \n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，[具有与人类同等智能水平] 的机器至今仍未出现。[图灵] 在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。[&#91;4&#93;] \n在21世纪的第一个十年，[机器学习] 得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n|[计算历史] （英语：[History of computing] ）|\n[硬件] |\n* [1960年代之前] \n* [1960年代至今] （英语：[History of computing hardware (1960s–present)] ）|\n[软件] |\n* [软体] （英语：[History of software] ）\n* [Unix] （英语：[History of Unix] ）\n* [自由和开源软件] （英语：[History of free and open-source software] ）|\n[计算机科学] |\n* 人工智能* [编译器构造] （英语：[History of compiler construction] ）\n* [计算机科学] （英语：[History of computing] ）\n* [操作系统] \n* [程式语言] \n* [杰出先驱者] （英语：[List of pioneers in computer science] ）\n* [软体工程] （英语：[History of software engineering] ）|\n现代概念|\n* [通用CPU] （英语：[History of general-purpose CPUs] ）\n* [图形用户界面] \n* [互联网] \n* [个人电脑] （英语：[History of personal computers] ）\n* [笔记型电脑] （英语：[History of laptops] ）\n* [电子游戏] \n* [全球资讯网] （英语：[History of the World Wide Web] ）|\n按国家|\n* [保加利亚] （英语：[History of computer hardware in Bulgaria] ）\n* [波兰] （英语：[History of computing in Poland] ）\n* [罗马尼亚] （英语：[History of computing in Romania] ）\n* [苏联集团国家] （英语：[History of computer hardware in Soviet Bloc countries] ）\n* [苏联] （英语：[History of computing in the Soviet Union] ）\n* [南斯拉夫] （英语：[History of computer hardware in Yugoslavia] ）|\n[计算年表] （英语：[Timeline of computing] ）|\n* [1950年之前] （英语：[Timeline of computing hardware before 1950] ）\n* [1950–1979] （英语：[Timeline of computing 1950–1979] ）\n* [1980–1989] （英语：[Timeline of computing 1980–1989] ）\n* [1990–1999] （英语：[Timeline of computing 1990–1999] ）\n* [2000–2009] （英语：[Timeline of computing 2000–2009] ）\n* [2010–2019] （英语：[Timeline of computing 2010–2019] ）\n* [更多年表……] |\n[计算机科学词汇] （英语：[Glossary of computer science] ）|\n* ![分类] [分类] |\n* [查] \n* [论] \n* [编] \n|\n## 先驱[[编辑]]\n奥特曼写道[&#91;1&#93;] ：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（[自动机] ）的实践之中。[&#91;5&#93;] \n### 神话，幻想和预言中的AI\n[[编辑]]\n[希腊神话] 中已经出现了机械人和人造人，如[赫淮斯托斯] 的黄金机器人和[皮格马利翁] 的[伽拉忒亚] 。[&#91;6&#93;] 中世纪出现了使用巫术或[炼金术] 将意识赋予无生命物质的传说，如[贾比尔] 的*Takwin*，[帕拉塞尔苏斯] 的[何蒙库鲁兹] 和Judah Loew的[魔像] 。[&#91;7&#93;] 19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如[玛丽·雪莱] 的《[弗兰肯斯坦] 》和[卡雷尔·恰佩克] 的《罗素姆的万能机器人》。[&#91;8&#93;] Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。[&#91;9&#93;] 至今人工智能仍然是科幻小说的重要元素。\n### 自动人偶[[编辑]]\n主条目：[自动机] \n[![]] [加扎利] 的可编程自动人偶（1206年）\n许多文明中都有创造自动人偶的杰出工匠，例如[偃师] （中国西周）[&#91;10&#93;] ，[希罗] （希腊）[&#91;11&#93;] ，[加扎利] [&#91;12&#93;] 和Wolfgang von Kempelen[&#91;13&#93;] 等等。已知最古老的“机器人”是[古埃及] 和[古希腊] 的[圣像] ，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。[赫耳墨斯·特里斯墨吉斯忒斯] （[赫耳墨斯·特里斯墨吉斯忒斯] ）写道“当发现神的本性时，人就能够重现他”[&#91;14&#93;] [&#91;15&#93;] 。\n### 形式推理[[编辑]]\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有[亚里士多德] （对三段论逻辑进行了形式分析），[欧几里得] （其著作《[几何原本] 》是形式推理的典范），[花剌子密] （代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如[奥卡姆的威廉] 和[邓斯·司各脱] 。[&#91;16&#93;] \n[马略卡] 哲学家[拉蒙·柳利] （1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。[&#91;17&#93;] 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。[&#91;18&#93;] Llull的工作对[莱布尼兹] 产生了很大影响，后者进一步发展了他的思想。[&#91;19&#93;] \n[![]] [莱布尼兹] 猜测人类的思想可以简化为机械计算\n在17世纪中，[莱布尼兹] ，[托马斯·霍布斯] 和[笛卡儿] 尝试将理性的思考系统化为代数学或几何学那样的体系。[&#91;20&#93;] 霍布斯在其著作《[利维坦] 》中有一句名言：“推理就是计算（reason is nothing but reckoning）。”[&#91;21&#93;] 莱布尼兹设想了一种用于推理的普适语言（他的[通用表意文字] ），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’”[&#91;22&#93;] 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，[数理逻辑] 研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括[布尔] 的《思维的定律》与[弗雷格] 的《[概念文字] 》。基于弗雷格的系统，[罗素] 和[怀特海] 在他们于1913年出版的巨著《[数学原理] 》中对数学的基础给出了形式化描述。这一成就激励了[希尔伯特] ，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?”[&#91;16&#93;] 这个问题的最终回答由[哥德尔不完备定理] ，[图灵机] 和[Alonzo Church] 的[λ演算] 给出。[&#91;16&#93;] [&#91;23&#93;] 他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n[![]] 在摩尔学校的电气工程的ENIAC计算机\n[邱奇-图灵论题] 暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是[图灵机] ：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。[&#91;16&#93;] [&#91;24&#93;] \n### 计算机科学[[编辑]]\n主条目：[计算机硬体历史] \n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，[查尔斯·巴贝奇] 设计了一台可编程计算机（“分析机”），但未能建造出来。[爱达·勒芙蕾丝] 预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。[&#91;25&#93;] （她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算[伯努利数] 的方法。）\n第一批现代计算机是[二战] 期间建造的大型译码机（包括Z3，[ENIAC] 和Colossus等）。[&#91;26&#93;] 后两个机器的理论基础是[图灵] 和[约翰·冯·诺伊曼] 提出和发展的学说。[&#91;27&#93;] \n## 人工智能的诞生：1943 - 1956\n[[编辑]]\n[&#91;28&#93;] 在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n### 控制论与早期神经网络[[编辑]]\n[![]] IBM 702：第一代AI研究者使用的电脑\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。[维纳] 的[控制论] 描述了电子网络的控制和稳定性。[克劳德·香农] 提出的[信息论] 则描述了[数字信号] （即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。[&#91;29&#93;] \n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。[&#91;30&#93;] \nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。', 'doi': '', 'published_date': '2026-02-02T20:35:14.837855', 'pdf_url': '', 'url': 'https://zh.wikipedia.org/zh-hans/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI 简史：从神经元到现代大模型 - CSDN博客', 'authors': [], 'abstract': '# AI 简史：从神经元到现代大模型\n\n原创已于\xa02024-12-25 16:28:52\xa0修改·1.4w 阅读\n\n·46\n\n·86\n·\n\nCC 4.0 BY-SA版权\n\n版权声明：本文为博主原创文章，遵循 [CC 4.0 BY-NC-SA] 版权协议，转载请附上原文出处链接和本声明。\n\n文章标签：\n\n[#深度学习] [#人工智能] [#ai] [#神经网络] [#transformer] [#卷积神经网络] [#机器学习] \n\n于\xa02024-12-25 10:54:28\xa0首次发布\n\n[生成AI专栏收录该内容] \n\n45 篇文章\n\n订阅专栏\n\n## AI 简史：从神经元到现代大模型\n\n人工智能 (AI) 和深度学习 (DL) 在过去的几十年中飞速发展，推动了计算机视觉、自然语言处理和机器人等领域的进步。今年的诺贝尔物理学奖更是颁给了美国科学家约翰·霍普菲尔德 (John Hopfield）和英国科学家杰弗里·辛顿（Geoffrey Hinton），表彰他们“在人工神经网络机器学习方面的基础性发现和发明”。本文将为大家概述 AI 的发展历程，梳理出从早期神经网络模型到现代大型语言模型发展过程中的重要里程碑。\n\n图 1\\. AI 发展全景图\n\n#### 文章目录\n\n- [1\\. 人工智能诞生 (1956)] \n- [2\\. AI 的演进：从基于规则的系统到深度神经网络] \n- [3\\. 早期人工神经网络 (1940s – 1960s)] \n - [3.1 McCulloch-Pitts 神经元 (1943)] \n - [3.2 Rosenblatt 感知机模型 (1957)] \n - [3.3 ADALINE (1959)] \n - [3.4 异或（XOR）问题 (1969)] \n- [4\\. 多层感知机 (1960)] \n - [4.1 隐藏层 (Hidden Layers)] \n - [4.2 多层感知机的历史背景与挑战] \n- [5\\. 反向传播 (1970s – 1980s)] \n - [5.1 早期发展 (1970 年代)] \n - [5.2 强化与普及（1980 年代）] \n - [5.3 通用逼近定理 (1989)] \n - [5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)] \n - [5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)] \n - [深度学习的复兴 (2000 年代末 – 现在)] \n- [6\\. 卷积神经网络 (1980s – 2010s)] \n - [6.1 早期发展 (1980 – 1998)] \n - [6.2 CNN 的崛起：AlexNet (2012)] \n - [6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）] \n - [6.4 后续架构改进] \n - [6.5 CNN 的应用] \n- [7\\. 循环神经网络 (1986 – 2017)] \n - [7.1 早期发展 (1980s – 1990s)] \n - [7.2 LSTM, GRU 和 Seq2Seq 模型 (1997 – 2014)] \n - [7.3 RNN 的应用] \n - [7.4 RNN 的挑战] \n- [8\\. Transformer (2017 – 现在)] \n - [8.1 Transformer 简介] \n - [8.2 Transformer 的衍生模型] \n - [8.3 OpenAI GPT 的发展历程] \n - [8.4 其他知名大语言模型] \n- [9\\. 多模态模型 (2023 – 现在)] \n - [9.1 GPT-4V (2023) 和 GPT-4o (2024)] \n - [9.2 Google’s Gemini (2023 – 现在)] \n - [9.3 Claude 3.0 和 Claude 3.5 (2023 – 现在)] \n - [9.4 LLaVA (2023)] \n- [10\\. 扩散模型 (2015 – 现在)] \n - [10.1 扩散模型简介 (2015)] \n - [10.2 扩散模型的发展 (2020 – 现在)] \n - [10.3 文生图模型] \n - [10.4 文生视频模型] \n- [11\\. 尾声] \n\n### 1\\. 人工智能诞生 (1956)\n\n人工智能（AI）的概念由来已久，但现代 AI 的雏形是在 20 世纪中期逐渐形成的。“人工智能”这个术语是由计算机科学家和认知科学家约翰·麦卡锡 (John McCarthy) 在 1956 年召开的达特茅斯人工智能夏季研讨项目上首次提出并被大家接受，AI 从此走上历史舞台。\n\n图 2.\n[A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence] (1955)\n\n达特茅斯会议通常被视为 AI 研究的发源地。这次会议汇聚了计算机科学家、数学家和认知科学家，共同探讨创造能够模拟人类智能的机器的可能性。与会者中大佬云集，包括：\n\n- **约翰·麦卡锡 (John McCarthy)** ：计算机科学家、Lisp 编程语言发明人之一。\n\n- **马文·明斯基 (Marvin Minsky)**：计算机科学家、框架理论的创立者。\n\n- **雷·索洛莫诺夫 (Ray Solomonoff)**：算法概率论创始人，通用概率分布之父，通用归纳推理理论的创建者。\n\n- **纳撒尼尔·罗切斯特 (Nathaniel Rochester)** ：IBM 701 的首席设计师，编写了世界上第一个汇编程序。\n\n- **克劳德·香农 (Claude Shannon)** ：数学家、发明家、密码学家，信息论创始人。\n\n- **奥利弗·塞弗里奇 (Oliver Selfridge)**：模式识别的奠基人、人工智能的先驱，被誉为“机器知觉之父”。\n\n\n图 3\\. 参加达特茅斯会议的部分重量级人物\n\n达特茅斯会议对计算机科学的发展产生了深远的影响，它为计算机科学的发展指明了方向，推动了计算机科学的快速发展。会议的成果为后来的计算机科学研究提供了重要的思想和方法支持，为计算机科学的教育和培训提供了重要的参考。达特茅斯会议也为跨学科合作和交流提供了一个成功的范例，为后来的跨学科研究提供了重要的经验和启示。\n\n### 2\\. AI 的演进：从基于规则的系统到深度神经网络\n\n纵观整个 AI 的发展史，有一条清晰的发展脉络，那就是从基于规则的系统向深度神经网络的不断进化。\n\n人工智能 (AI) 的发展始于上个世纪 50 年代，那时人们开始开发用于国际象棋和问题求解的算法。第一个 AI 程序 Logical Theorist 于 1956 年诞生。到了 1960 和 1970 年代，基于规则的专家系统如 MYCIN 被引入，它们可以帮助进行复杂的决策。1980 年代，机器学习开始兴起，使 AI 系统能够从数据中学习并不断改进，为现代深度学习技术奠定了基础。\n\n今天，大多数最前沿的 AI 技术都由深度学习驱动，深刻改变了 AI 的发展格局。深度学习是机器学习的一个独立分支，它通过多层人工神经网络从原始数据中提取复杂特征。在本文中，我们将探讨 AI 的发展历史，并重点介绍深度学习在其中的关键作用。\n\n图 4\\. 人工智能、机器学习、神经网络、深度学习之间的关系\n\n### 3\\. 早期人工神经网络 (1940s – 1960s)\n\n#### 3.1 McCulloch-Pitts 神经元 (1943)\n\n神经网络的概念可以追溯到 1943 年，当时 Warren McCulloch 和 Walter Pitts 提出了第一个人工神经元模型。McCulloch-Pitts (MP) 神经元模型是对生物神经元的一种突破性简化。这个模型通过聚合二进制输入，并利用阈值激活函数来做出决策，从而为人工神经网络奠定了基础，输出结果为二进制 {\n0\n,\n1\n}\n\\\\{0, 1\\\\}\n{0,1}。\n\n图 5\\. 人工神经元的结构与原理\n\n这种简化的模型抓住了神经元行为的核心特征——接收多个输入，整合这些输入，并根据是否超过阈值来产生二进制输出。尽管MP神经元模型非常简单，但它能够实现基本的逻辑运算，展示了神经计算的潜力。\n\n#### 3.2 Rosenblatt 感知机模型 (1957)\n\nFrank Rosenblatt 在 1957 年引入了感知机，这是一种能够学习和识别模式的单层神经网络。感知机模型比 MP 神经元更为通用，设计用于处理实数值输入，并通过调整权重来最小化分类错误。\n\n图 6\\. 感知机模型\n\nRosenblatt 还为感知机开发了一种监督学习算法，使得网络能够直接从训练数据中进行学习。 L\n(\nW\n)\n=\n−\n∑\ni\n∈\nM\nW\nT\nX\ni\ny\ni\n\\\\mathcal{L}(W) = - \\\\sum\\_{i \\\\in M} W^T X\\_i y\\_i\nL(W)=−i∈M∑\u200bWTXi\u200byi\u200b\n\n图 7\\. Mark I 感知机，是一台实现了图像识别感知机算法的机器\n\nRosenblatt 的感知机展示出识别个人和在不同语言间翻译语音的潜力，这在当时引发了公众对 AI 的极大兴趣。感知机模型及其相关的学习算法成为神经网络发展历程中的重要里程碑。然而，很快就显现出一个关键限制：当训练数据是非线性可分时，感知机的学习规则无法收敛。\n\n#### 3.3 ADALINE (1959)\n\nWidrow 和 Hoff 在 1959 年引入了 ADALINE（自适应线性神经元，也称 Delta 学习规则），对感知机学习规则进行了改进。ADALINE 解决了二进制输出和噪声敏感性等限制，并能够学习并收敛非线性可分的数据，这是神经网络发展中的一大突破。\n\n图 8\\. ADALINE VS. 感知机\n\nADALINE 的主要特点包括：\n\n- **线性激活函数**：不同于感知器的阶跃函数，ADALINE 使用线性激活函数，因此适用于回归任务和连续输出。\n- **最小均方（LMS）算法**：ADALINE 采用 LMS 算法，该算法通过最小化预测输出与实际输出之间的均方误差，提供更高效和稳定的学习过程。\n- **自适应权重**：LMS 算法根据输出误差自适应调整权重，使 ADALINE 即使在有噪声的情况下也能有效地学习和收敛。\n\n**ADALINE 的引入标志着神经网络第一次黄金时代的开始**，它克服了 Rosenblatt 感知机学习的限制。这一突破实现了高效学习、连续输出和对噪声数据的适应能力，推动了该领域的创新和快速发展。\n\n图 9\\. ADALINE 开启了神经网络第一次黄金时代\n\n然而，与感知机类似，ADALINE 仍然无法解决线性可分的问题，无法应对更复杂的非线性任务。这一局限集中体现在异或（XOR）问题上，也促进了更高级神经网络架构的发展。\n\n#### 3.4 异或（XOR）问题 (1969)\n\n1969年，Marvin Minsky 和 Seymour Papert 在他们的著作《Perceptrons》中揭示了单层感知机的一个重要局限：由于其线性决策边界，感知机无法解决异或 (XOR) 问题，而这是一个简单的二元分类任务。异或问题不是线性可分的，也就是说，没有一个单一的线性边界能够正确地将所有的输入模式分类。\n\n图 10\\. Marvin Minsky 和 Seymour Papert 合著的《Perceptrons: An introduction to computational geometry》\n\n这一发现强调了需要开发更复杂的神经网络架构，以便能够学习非线性的决策边界。感知机的局限性被揭露后，人们对神经网络的信心减弱，转而研究符号人工智能方法， **这标志着从 20 世纪 70 年代初到 80 年代中期的“神经网络的第一次黑暗时代”的开始**。\n\n图 11\\. 异或问题将神经网络代入第一次黑暗时代\n\n然而，研究人员从解决异或问题中获得的见解促使他们意识到需要更复杂的模型来捕捉非线性关系。这种认识最终推动了多层感知机和其他先进神经网络模型的发展，为神经网络和深度学习在后来的复兴奠定了基础。\n\n### 4\\. 多层感知机 (1960)\n\n多层感知机 (MLP) 最早于 20 世纪 60 年代提出，作为对单层感知机的改进。MLP 由多个层次的相互连接的神经元组成，能够克服单层模型的局限性。苏联科学家 A. G. Ivakhnenko 和 V. Lapa 在感知机基础上进行研究，对多层感知机的发展中做出了重要贡献。\n\n图 12\\. 多层感知机模型\n\n#### 4.1 隐藏层 (Hidden Layers)\n\n增加隐藏层使得 MLP (多层感知器) 可以捕捉和表达数据中的复杂非线性关系。这些隐藏层极大地增强了网络的学习能力，使其能够解决诸如异或问题这样非线性可分的问题。\n\n图 13\\. 隐藏层解决异或问题\n\n#### 4.2 多层感知机的历史背景与挑战\n\nMLP 的出现标志着神经网络的研究向前迈出了重大一步，展示了深度学习架构在解决复杂问题方面的潜力。然而，在 1960 年代和 1970 年代，MLP 的发展面临若干挑战：\n\n- **缺乏训练算法**：早期的 MLP 模型缺乏高效的训练算法，无法有效地调整网络权重。此时反向传播算法还未诞生，训练多层深度网络非常困难。\n- **算力限制**：当时的算力不足以应对训练深度神经网络所需的复杂计算。这一限制拖慢了 MLP 的研究和发展进程。\n\n神经网络的第一个黑暗时代在 1986 年结束， **随着反向传播算法的诞生，开启了神经网络的第二个黄金时代**。\n\n### 5\\. 反向传播 (1970s – 1980s)\n\n1969 年，异或问题揭示了感知机（单层神经网络）的局限性。研究人员意识到，多层神经网络能够克服这些限制，但缺乏有效的训练算法。17年后，反向传播算法的开发使得神经网络在理论上可以逼近任何函数。值得注意的是，该算法实际上在发表之前就已被发明。如今，反向传播已成为深度学习的核心组件，自 20 世纪 60 年代和70 年代以来经历了显著的发展和完善。\n\n图 14\\. 反向传播原理示意图\n\n反向传播的关键特性：\n\n- **梯度下降**：反向传播与梯度下降联合使用以降低误差函数。该算法计算每个权重相对于误差的梯度，从而逐步调整权重以减少误差。\n- **链式法则**：反向传播算法的核心在于应用微积分的链式法则。此法则使得误差的梯度可以被分解为一系列偏导数，并通过网络的反向传递高效计算。\n- **分层计算**：反向传播逐层运作，从输出层向输入层反向传递。这种分层计算确保梯度在网络中正确传播，使得深度架构的训练成为可能。\n\n#### 5.1 早期发展 (1970 年代)\n\n- **Seppo Linnainmaa (1970)**: 提出了自动微分的概念，这是反向传播算法的重要组成部分。\n- **Paul Werbos (1974)**: 提议使用微积分的链式法则计算误差函数对网络权重的梯度，从而能够训练多层神经网络。\n\n#### 5.2 强化与普及（1980 年代）\n\n- **David Rumelhart, Geoffrey Hinton 和 Ronald Williams (1986)**: 将 **反向传播** 这一高效实用的方法，用于训练深度神经网络，并展示了其在多种问题中的应用。\n\n图 15\\. 反向传播算法的三位主要贡献者\n\n其中 Geoffrey Hinton 因其在人工神经网络和机器学习领域的贡献获得了 2018 年图灵奖和 2024 诺贝尔物理学奖，称为继 Herbert Simon 后第二位图灵奖-诺贝尔奖双料得主。\n\n#### 5.3 通用逼近定理 (1989)\n\nGeorge Cybenko 在 1989 年提出的通用逼近定理，为多层神经网络的功能提供了数学基础。该定理表明，只要神经元数量足够，并且使用非线性激活函数，具有单个隐藏层的前馈神经网络就能够以任意精度逼近任意连续函数。这个定理突显了神经网络的强大能力和灵活性，使其能够应用于各种领域。\n\n图 16\\. 具有单个隐藏层的神经网络可以将任意连续函数逼近到任意所需的精度，从而在各个领域解决复杂的问题\n\n#### 5.4 第二次黄金时代 (1980 年代末 – 1990 年代初)\n\n\\*\\*反向传播算法的出现和通用逼近定理的提出，开启了神经网络研究的第二个黄金时代。\\*\\*反向传播提供了一种高效的多层神经网络训练方法，使研究人员能够构建更深层次和更复杂的模型。通用逼近定理则为使用多层神经网络提供了理论支持，并增强了人们对其解决复杂问题能力的信心。在 1980 年代末至 1990 年代初，这一时期见证了对神经网络领域的兴趣回升和显著的进步。\n\n图 17\\. 反向传播和通用逼近定理开启了神经网络研究的第二个黄金时代\n\n#### 5.5 第二次黑暗时代 (1990 年代初 – 2000 年代初)\n\n然而，由于一系列因素，神经网络领域在 1990 年代初至 2000 年代初经历了“第二个黑暗时代”：\n\n- **支持向量机 (SVM) 的兴起**：支持向量机为分类和回归任务提供了更优雅的数学方法。\n- **算力限制**：由于训练深度神经网络仍然耗时且对硬件要求高，计算能力受到限制。\n- **过拟合和泛化问题**：这两个问题导致早期神经网络在训练数据上表现良好，但在新数据上表现不佳，限制了其实用性。\n\n这些挑战使得许多研究人员转而关注其他领域，导致神经网络研究的停滞。\n\n图 18\\. 随着 SVM 的兴起，神经网络进入第二个黑暗时代\n\n#### 深度学习的复兴 (2000 年代末 – 现在)\n\n在 2000 年代末和 2010 年代初，神经网络领域经历了复兴，这得益于以下方面的进步：\n\n- **深度学习架构的发展**（如 CNNs、RNNs、Transformers、Diffusion Models）\n- **硬件的改进**（如 GPUs、TPUs、LPUs）\n- **大规模数据集的可用性**（如 ImageNet、COCO、OpenWebText、WikiText 等）\n- **训练算法的优化**（如 SGD、Adam、dropout）\n\n这些进展带来了计算机视觉、自然语言处理、语音识别和强化学习的重大突破。通用逼近定理与实际技术的进步相结合，为深度学习技术的广泛应用和成功奠定了基础。\n\n### 6\\. 卷积神经网络 (1980s – 2010s)\n\n卷积神经网络 (CNN) 在深度学习领域，尤其是计算机视觉和图像处理方面，带来了革命性的变化。从上个世纪 80 年代到本世纪最初的 10 年，CNN 在架构、训练技术和应用等方面取得了显著的进步。\n\n卷积神经网络由以下三个主要组件构成：\n\n- **卷积层 (Convolutional Layers)**：这些层通过一组可调整的滤波器，从输入图像中自动学习和提取特征的空间层次结构。\n- **池化层 (Pooling Layers)**：池化层通过缩小输入的空间尺寸，来提高对输入变化的适应性，并减少计算量。\n- **全连接层 (Fully Connected Layers)**：在卷积层和池化层之后，全连接层用于分类任务，负责整合之前层中提取的特征。\n\n卷积神经网络的主要特性\n\n- **局部感受野**：CNN 利用局部感受野来捕捉输入数据中的局部特征，使其在处理图像和其他视觉任务时表现出色。\n- **权重共享**：通过在卷积层中共享权重，CNN 能够减少网络中参数的数量，从而提高训练效率。\n- **平移不变性**：池化层赋予网络平移不变性，使其能够识别输入图像中不同位置的相同模式。\n\n#### 6.1 早期发展 (1980 – 1998)\n\n1980 年代，福岛邦彦 (Kunihiko Fukushima) 首次提出了 CNN 的概念，他设计了一种称为神经认知机 (Neocognitron) 的分层神经网络，这种网络模仿了人类视觉皮层的结构。这项开创性的研究为之后 CNN 的发展奠定了基础。\n\n图 19\\. 福岛邦彦与他的神经认知机\n\n到了 1980 年代末和 1990 年代初，Yann LeCun 和他的团队在此基础上进一步发展了 CNN，并推出了 LeNet-5 架构，该架构专为手写数字识别而设计。\n\n图 20\\. Yann LeCun 与他的 LeNet-5\n\n#### 6.2 CNN 的崛起：AlexNet (2012)\n\n2012 年，AlexNet 在 ImageNet 大规模视觉识别挑战赛（ILSVRC）中取得了重大胜利，这是 CNN 发展中的一个重要里程碑。这次胜利不仅以压倒性优势赢得了比赛，也在图像分类领域取得了重大突破。\n\n图 21\\. ILSVRC 历年冠军及其表现\n\nILSVRC 是一个年度图像识别基准测试，用于评估算法在一个包含 1000 万多张注释图像的数据集上的表现，这些图像被划分为 1000 个类别。AlexNet 的创新之处包括：\n\n- **ReLU 激活函数**：为解决传统激活函数的问题而引入，ReLU 提高了训练速度并改善了性能。\n- **Dropout 正则化**：这种技术通过在训练过程中随机丢弃神经元来减少过拟合现象。\n- **数据增强**：通过人为增加训练数据的多样性，增强了数据集的丰富性，从而改善了模型的泛化能力。\n\nAlexNet 的成功成为 CNN 发展中的一个转折点，为图像分类和物体检测的进一步发展奠定了基础。\n\n图 22\\. AlexNet 架构\n\n#### 6.3 AlexNet 开启神经网络的第三次黄金时代（2010 年代至今）\n\n自 2010 年代直至今天，当前的科技发展黄金时代以深度学习、大数据和强大计算平台的结合为特征。在这一时期，图像识别、自然语言处理和机器人技术等领域取得了显著的突破。持续的研究不断推动着人工智能（AI）能力的边界。\n\n图 23\\. AlexNet 开启神经网络的第三次黄金时代\n\n#### 6.4 后续架构改进\n\n继 AlexNet 之后，又相继出现了几个有影响力的架构：\n\n- **VGGNet (2014)**：由牛津大学的视觉几何组开发，VGGNet 强调使用更深的网络架构，并采用较小的卷积滤波器 (\n3\n×\n3\n3 \\\\times 3\n3×3)，从而取得了显著的准确率。\n图 24\\. 原始 VGGNet 架构\n- **GoogLeNet/Inception (2014)**：引入了 inception 模块，使得网络能够以更高效的方式捕捉不同尺度的特征。\n图 25\\. GooLeNet 架构\n- **ResNet (2015)**：', 'doi': '', 'published_date': '2024-12-25T00:00:00+00:00', 'pdf_url': '', 'url': 'https://blog.csdn.net/jarodyv/article/details/144699658', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能简史— 深入浅出PyTorch', 'authors': [], 'abstract': '人工智能简史 &#8212; 深入浅出PyTorch\nToggle navigation sidebar\nToggle in-page Table of Contents\n[# 深入浅出PyTorch\n] \n**\nTheme by the[Executable Book Project] \n**\n**\n**\n* [**repository] \n* [**open issue] \n* [**suggest edit] \n**\n* [**.md] \n* **.pdf\n**\n**Contents\n# 人工智能简史## Contents\n# 人工智能简史[#] \n自从图灵在1950年第一次提出“机器智能（Machine Intelligence）”这个概念以来，人工智能已经经历了七十余年的发展。在这七十多年中，人工智能的发展先后经历了三次浪潮，每一次浪潮对人工智能的发展来说，都是具有里程碑意义的。接下来我们将以这三次浪潮为主线，为大家介绍人工智能的发展历程。除此之外，我们也将会给大家介绍现在常说的Deep learning，Machine Learning和AI之间的关系。\n[\\* ]通过本章学习，你将收获：\n* 了解人工智能的三次浪潮* 了解Deep learning，Machine learning和AI之间的关系\n## 1.1 人工智能的三次浪潮[#] \n### 1.1.1 第一次浪潮[#] \n1950年，阿兰·图灵发表著名论文《计算机器与智能》，在这篇论文中，他提出了机器思维的概念和图灵测试，标志着“机器的智能化”正式进入人类的科技树。在此之后的数年间，机器智能有了进一步的发展。两年后的1952年，计算机科学家阿瑟·萨缪尔开发出一款跳棋程序，并提出了“机器学习”这个概念。在此之后的4年里，机器智能化也取得了一定的进步，直到1956年的达特茅斯会议上，约翰·麦卡锡正式提出了“人工智能”这个词语，1956年，也就成为了实际意义上的人工智能元年。\n达特茅斯会议之后，人工智能进入了一个高速发展的时期，也就是所谓的“第一次浪潮”。这次浪潮一直持续到二十世纪六十年代中期。在这近10年的时间里，计算机本身的“智能”并没有得到发展，快速进步的是人工智能的一些理论与算法方面。很多对后来人工智能发展起到奠基作用的算法——如罗森布拉特在1957年发明感知机——就是在这个时间段诞生的。感知机是机器学习人工神经网络理论中神经元的最早模型，这一模型也使得人工神经网络理论得到了巨大的突破。除此之外，强化学习的雏形也是在那段时间提出的。彼时的科学界都弥漫着快乐的气氛，大家都认为，只要坚持走下去，人工智能就一定会得到跨越式的发展。但事与愿违，不久后人工智能的第一次寒冬（AI Winter）就到来了。\n1966年前后，AI遭遇了瓶颈。人们发现逻辑证明器、感知器、强化学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围就无法应对。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。研究者们很快就意识到，要求程序对这个世界具有儿童水平的认识这个要求都太高了——那时没人能够做出人工智能需要的巨大数据库，也没人知道一个程序怎样才能学到如此丰富的信息。另一方面，有很多计算复杂度以指数程度增加，这成为了不可能完成的计算任务。\n可以说，人工智能的第一次浪潮在发展到“非智能对话机器”的智能化初级阶段时，就因为当时的技术限制不得不停摆。人工智能的发展似乎陷入了一个无解的“死胡同”里，并被计算机科学家们逐渐冷落。### 1.1.2 第二次浪潮[#] \n时间来到了20世纪80年代。经过了数十年的研究，科学家们逐渐放弃了初代的符号学派思路，改用统计学的思路来研究人工智能。研究思路的改变再加上硬件技术的升级，人工智能的发展又一次迎来的新的契机。在那个时代，基于人工智能的“专家系统”受到了绝对的热捧。特定领域的“专家系统”程序被更广泛的采纳，该系统能够根据领域内的专业知识，推理出专业问题的答案，人工智能也由此变得更加“实用”，专家系统所依赖的知识库系统和知识工程成为了当时主要的研究方向。\n但由于专家系统仅适用于某些特定场景，很快人们就对这一系统由狂热的追捧逐渐走向巨大的失望。与此同时，现代电子计算机的出现让“知识查询”的费用进一步降低，人们更加深刻的意识到专家系统是如此的古老陈旧。因此，政府部门下调了专家系统的研发资金。缺少了资金的支持，由专家系统再次兴起的人工智能研究又一次陷入了低谷之中。虽然第二次浪潮持续的时间比较短，但它在整个人工智能发展历史中仍然起到了举足轻重的作用。它彻底改变了人工智能研究的大思路，将统计学思想引入研究之中，为人工智能在未来几十年的发展打下了基础。除此之外，在这次浪潮中提出的BP神经网络，为之后机器感知、交互的能力奠定了基础。\n### 1.1.3 第三次浪潮[#] \n1993年后，新的数学工具，理论和摩尔定律的出现，使得计算机的算力进一步提高，以深度学习为核心的机器学习算法获得发展，新的芯片和云计算的发展使得可用的计算能力获得飞跃式提高，大数据的发展使得海量数据的储存和分析成为可能。在这样的技术背景下，人工智能的第三次浪潮即将到来。\n人工智能的第三次浪潮有两个重要的时间节点：2006年和2016年。2006年是深度学习发展史的分水岭。杰弗里辛顿在这一年发表了《一种深度置信网络的快速学习算法》，其他重要的深度学习学术文章也在这一年被发布，在基本理论层面取得了若干重大突破。而2016年3月，谷歌DeepMind研发的AlphaGo在围棋人机大战中击败韩国职业九段棋手李世乭，“人工智能”一词正式进入普通民众的视野并被逐渐熟知。至此，人工智能正式迈向了从“科研领域的应用型工具”到“实用性，功能性工具”的转变，人工智能有了新的研究方向和研究模式，即从过去的学术主导型研究逐渐走向了商业主导型研究。随着人类社会对智能化工具的不断追求和探索，人工智能的发展迎来了全新的时代。\n### 1.1.4 总结[#] \n![] \n上图是对人工智能发展中经历的三次浪潮和两次寒冬的形象总结。除此之外，有观点认为，深度学习算法带来的“技术红利”，将支撑我们再发展5\\~10年时间，随后就会遇到瓶颈。人工智能不是一个简单的从1到100进步的过程，它往往趋向于两个极端：要么90分以上，其它的都是10分以下。目前，人工智能急需寻找到一个“技术奇点”，让人工智能迅速发展到通用人工智能甚至是超级人工智能的水平。否则，在人工智能研究商业化的今天，无法从中获利的投资人们将快速撤资退场，人工智能或将进入下一个寒冬。\n## 1.2 DL,ML,AI三者之间的关系[#] \n大家对“人工智能”这个词，也就是我们所谓的“AI”（Artificial Intelligence）想必是非常熟悉，无论是近几年各行各业都喜欢用作营销噱头的“智能化”还是早期电影如《黑客帝国》、《终结者》等，都让AI这个概念深入人心。但近几年，另外两个词语也在逐步进入我们的生活，即就是“机器学习（Machine Learning，ML）”和“深度学习（Deep Learning，DL）”。在接下来的叙述中，我们就将了解DL和ML究竟是什么，以及它们和AI之间的关系。\n### 1.2.1 DL和ML是什么[#] \nMachine Learning（机器学习）。它在1959年被机器学习的先驱者之一的阿瑟·塞缪尔定义为：一门研究领域，它赋予计算机无需明确编程就能学习的能力。也就是说，机器学习程序不同于传统编程那样，使用if-then语句那样明确地输入到计算机中以便它根据条件执行。在某种意义上，机器学习程序赋予机器根据所接触到的数据进行自我调整的能力。机器学习更像是一种优化算法，如果我们在事先就对它进行了正确的调整，那么它就会在一遍又一遍的尝试和猜测之中不断减少它的错误，以无限逼近于最终的正确结果。而机器学习的基本思路，也就是将现实问题抽象成为一个数学问题，机器通过训练，寻找到解决数学问题的方法，进而解决现实问题。\nDeep Learning（深度学习）。它在2006年被提出，并在近些年得到了迅速的发展。它通过建立、模拟人脑进行分析学习的神经网络，并模仿人脑的机制来解释数据。李开复教授在《人工智能》一书中这样解释深度学习：“假设深度学习要处理的信息是“水流”，而处理数据的深度学习网络是一个由管道和阀门组成的巨大水管网络。网络的入口是若干管道开口，网络的出口也是若干管道开口。这个水管网络有许多层，每一层由许多个可以控制水流流向与流量的调节阀。根据不同任务的需要，水管网络的层数、每层的调节阀数量可以有不同的变化组合。对复杂任务来说，调节阀的总数可以成千上万甚至更多。水管网络中，每一层的每个调节阀都通过水管与下一层的所有调节阀连接起来，组成一个从前到后，逐层完全连通的水流系统。”\n### 1.2.2 它们和AI的关系[#] \n众所周知，人工智能是研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统的一门技术科学。既然如此，那么计算器算是人工智能吗？严格地说是算的，因为它至少做了“模拟”人在计算方面的智能，并扩展了这个能力（比人算得更快）。我们通过代码驱动计算机去帮我们干活，这个算是人工智能吗？也算的。我们现在看到的貌似很高端的技术，如图像识别、NLP，其实依然没有脱离这个范围，说白了，就是“模拟人在看图方面的智能”和“模拟人在听话方面的智能”，本质上和“模拟人在计算方面的智能”没啥两样，虽然难度有高低，但目的是一样的——模拟、延伸和扩展人的智能。\n随着人对计算机的期望越来越高，要求它解决的问题越来越复杂，仅仅算的更快，看的更准已经远远不能满足人们的诉求了。要解决的问题域越来越复杂，即使是同一个问题，其面对的场景也越来越多。传统的思路就是查找问题的条件和解决方法，在计算机程序中再加入一个if-then。但这只是治标不治本。随着我们期待解决的问题越来越多，计算机程序将越来越复杂，越来越难以维护。那怎么办呢？于是有人提出了一个新的思路——能否不为难码农，让机器自己去学习呢？\n至此，“机器学习”的概念，正式诞生。机器学习就是用算法解析数据，不断学习，对世界中发生的事做出判断和预测的一项技术。研究人员不会亲手编写软件、确定特殊指令集、然后让程序完成特殊任务；相反，研究人员会用大量数据和算法“训练”机器，让机器自行学会如何执行任务。说白了，机器学习只是人们实现让机器“模拟、延伸和扩展人的智能”的一种较为轻松的方法罢了。它的成功与否取决于我们喂给机器的数据集是否准确且有效。因此，机器学习是大数据技术领域内的一个应用，人们只是借用这个应用，来发展人工智能罢了。机器学习发展了几十年之后，再次遇到了瓶颈期。随着问题场景的更加复杂多变，需要进行判断的条件更加苛刻，人们不得不重新思考一种方式来优化机器学习。深度学习就是带着这个目的被提出的。机器学习中有一个概念叫“神经网络”，深度学习正是通过优化这个网络来更好的解决通过机器学习难以解决的问题。它的基本特点，就是试图模仿大脑的神经元之间传递，处理信息的模式，通过不同的“层”来拆分问题，每一层解决问题的一个部分。比如在利用深度学习解决智能驾驶问题中，第一层可能用于识别车辆与道路边缘的距离，第二层用于识别道路标线，第三层用于识别路上的其他车辆等等。通过以上几段话的简单描述，DL,ML和AI之间的关系也就明确了。它们三者的关系就像是俄罗斯套娃：AI最大，它的目的是通过让机器模仿人类进而超越人类；ML次之，它是AI的一个分支（也是最重要分支），是让机器模仿人类的一种方法；DL更次之，它是ML的一个分支，它的目的是让机器不借助人工标注，也能自主提取目标特征进而解决问题的一种方法。\n最后，借用一张经典的关系图作为结尾：![]', 'doi': '', 'published_date': '2026-02-02T20:35:14.838065', 'pdf_url': '', 'url': 'https://datawhalechina.github.io/thorough-pytorch/%E7%AC%AC%E9%9B%B6%E7%AB%A0/0.1%20%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%AE%80%E5%8F%B2.html', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': 'AI 有着怎样的发展历程？ - Cloudflare', 'authors': [], 'abstract': 'AI 有着怎样的发展历程？| Cloudflare\n[注册] \n语言* [English] \n* [English (United Kingdom)] \n* [Deutsch] \n* [Español (Latinoamérica)] \n* [Español (España)] \n* [Français] \n* [Italiano] \n* [日本語] \n* [한국어] \n* [Polski] \n* [Português (Brasil)] \n* [Русский] \n* [繁體中文] \n* [简体中文] \n# AI 有着怎样的发展历程？当今最先进的AI 模型建立在几十年前的发现基础之上。AI 的历史可以追溯到第一台数字计算机诞生之前。#### 学习目标阅读本文后，您将能够：* 识别AI 发展的关键进展* 了解Alan Turing、Frank Rosenblatt 和Geoffrey Hinton 等发明家和创新者多年来对AI 发展做出的贡献* 列举促成当今AI 热潮的发展相关内容[\n什么是代理式AI？\n] [\n什么是生成式AI？\n] [\n预测式AI\n] [\n神经网络] [\n什么是人工智能(AI)？\n] \n复制文章链接## AI 有着怎样的发展历程？[人工智能 (AI)] 是指机器（通常特指计算机）模仿人类认知过程、解决问题的能力以及行动能力。如今，AI 涵盖了一系列能力，从[预测式 AI] 和[自然语言处理] ，到[大型语言模型 (LLM)] 和[代理式 AI] 。\n从古代世界的自动机到最早的计算机，这些都是AI 的前身。当今最先进的模型，其基础是几十年前发展起来的理论和算法。## AI 历史上的重大事件：时间线虽然“人工智能”一词最早出现在1955 年，但对AI 发展至关重要的事件却可以追溯到几个世纪以前。#### 20 世纪之前* **大约公元前 400 年：**根据一些古希腊文献记载，阿尔希塔斯 (Archytas of Tarentum) 制作了一只能够拍打翅膀并飞翔的木鸽。* **大约 1495 年：**莱昂纳多•达•芬奇 (Leonardo da Vinci) 绘制了一幅外形类似德国骑士的自动机详细图纸，并且可能已经制造了一台（即便确实如此，这台自动机也无法流传至今）。* **大约 1560 年：**西班牙国王费利佩二世 (Phillip II) 委托钟表匠Juanelo Turriano 模仿方济各会修士Diego de Alcalá（后来被封为圣徒 St. Diego）制作一台自动机。这种自动机由发条驱动，可以模仿人类的基本动作和姿势。\n* **1764 - 1770 年：**名为*Canard Digérateur*（或“消化鸭”）以及 Automaton Chess Player（或“自动行棋的傀儡”）的自动机令公众欣喜。虽然两者后来都被证明是骗局，但它们拓展了人们对自动化可能性的普遍理解。\n* **1822 年：**查尔斯•巴贝奇 (Charles Babbage) 完成了“差分引擎”的研制，这是一种机械计算装置，它是计算机的早期前身。#### 1900 - 1973 年* **1914年：**数学家兼发明家 Leonardo Torres y Quevedo 首次推出了"El Ajedrecista"，这是一款能够自动进行国际象棋对局并在特定情况下击败人类棋手的自动机。\n* **1943 年：**神经生理学家 Warren McCulloch 和数学家Walter Pitts 共同发表了题为《神经活动内在概念的逻辑演算》(A Logical Calculus of the Ideas Imminent in Nervous Activity) 的论文，文中介绍了神经元的数学描述。这篇论文成为了构建[人工神经网络] 的关键一步。\n* **1945 年：**第一台数字计算机 ENIAC 诞生。* **1949 年：**心理专家唐纳德•赫布 (Donald Hebb) 出版了*《行为的组织》*，这本书对神经网络的发展产生了深远的影响。\n* **1950 年：**颇具影响力的数学家和计算机科学家 Alan Turing 发表了《计算机器与智能》(Computing Machinery and Intelligence)，这篇论文探讨了“机器能否思考”的问题。论文描述了著名的“图灵测试”，用于判断计算机智能是否已变得与人类智能无法区分。\n* **1951 年：**Dean Edmunds 和Marvin Minsky 一起建造了随机神经模拟强化计算器(SNARC)，这是世界上第一台神经网络计算机。它只有 40 个神经元。* **1955 年：**在计算机科学家约翰•麦卡锡 (John McCarthy) 主持的一次研讨会上，“人工智能”一词首次出现。* **1957 年：**心理学家兼计算机科学家弗兰克•罗森布拉特 (Frank Rosenblatt) 创建了感知器，这是一种早期的人工神经网络。* **1959 年：**斯坦福大学研究员 Bernard Widrow 和Marcian Hoff 开发了出现实世界中使用的第一个神经网络模型：多自适应线性元素(Madaline)，用于消除电话线路回声。\n* **1966 年：**计算机科学家 Joseph Weizenbaum 发布了ELIZA 程序，这被认为是第一个[聊天机器人] （尽管按照如今的标准，其底层模式匹配算法相当简单）。\n* **1969 年：**Marvin Minsky 和Seymour Papert 出版了*《感知器：计算几何学导论》*(Perceptrons: An Introduction to Computational Geometry)，这本书对感知器提出了质疑（最初由 Frank Rosenblatt 提出）。引人争议的是，书中还论述了感知器的一些局限性，某些研究员后来认为这些局限性削弱了对AI 研究的资助热情。#### AI 的寒冬与复苏：1973 - 2000 年* **1973 年：**第一个“AI 寒冬”开始，英国科学研究委员会的一份报告指出，这一领域的工作未能兑现其承诺，英国削减了对AI 研究的资助。在七十年代这十年的剩余时间里，AI 研究速度放缓。* **1980 年：**人工智能促进协会 (AAAI) 召开了第一次会议。对AI 研究的兴趣开始复苏。* **1982 年：**加州理工学院的 John Hopfield 向美国国家研究院提交了一篇关于在人工神经元之间使用双向连接的论文（以前一直都只使用了单向连接）。此外，日本启动了该国的第五代计算机系统项目(FGCS)，为 AI 研究提供了更多资金。* **1987 年：**第二个 AI 寒冬开始，在此期间，由于研究进展停滞不前，AI 研究的投资极少。* **1995 年：**Richard Wallace 开发了聊天机器人A.L.I.C.E.，它以 20 世纪60 年代的聊天机器人ELIZA 为基础。* **1997 年：**IBM 的超级计算机“深蓝”(Deep Blue) 在六局棋国际象棋比赛中击败了国际象棋大师加里•卡斯帕罗夫(Garry Kasparov)。#### 21 世纪：AI 热潮* **2002 年：**Roomba 机器人发布，这是最早具备完全自主功能的消费产品之一。* **2007 年：**计算机科学家 Geoffrey Hinton 发表了题为“Learning Multiple Layers of Representation”的论文，这是一篇在[深度学习] 方面具有重大意义的论文。\n* **2009 年：**研究员 Rajat Raina、Anand Madhavan 和Andrew Ng 共同发表了题为“Large-scale Deep Unsupervised Learning using Graphics Processors”的论文，文中指出 GPU 在机器学习方面优于CPU。未来几年，向 GPU 转变将会催生出比以往任何时候都更加强大的AI 模型。* **2011 年：**IBM 的自然语言处理器Watson 参加了美国智力竞猜电视节目*《危险边缘》(Jeopardy!)*并获胜。同一年，Apple 推出了首个广受欢迎的虚拟助手Siri。\n* **2012 年：**Google 研究员Jeff Dean 和Andrew Ng 训练一个神经网络，使其能够仅使用未标记的图像识别猫。大约在这个时候，“AI 热潮”开始了。* **2016 年：**Google 计算机程序AlphaGo 在围棋比赛中击败了围棋世界冠军李世石。* **2017 年：**Google 提出了Transformer 神经网络框架，这种架构为[大型语言模型 (LLM)] 的开发铺平了道路。\n* **2020 年：**OpenAI 发布了GPT-3，这是首批 LLM 之一。* **2021 年：**Google 发布了多任务统一模型(MUM)，这是一种由 AI 驱动的搜索算法，能够理解并生成语言。* **2022 年：**ChatGPT 4.0 版本正式发布可供大众使用，彻底改变了人们对AI 能力的理解。其他LLM，例如 Bard、Llama、Bing Chat 和Copilot，也相继发布。## 什么是AI 的“第三次浪潮”？凭借一系列硬件突破和进步，AI 在经历了数十年的缓慢发展和寒冬之后，近几年迎来了加速发展。行业观察人士认为，在这一轮AI 发展热潮中，三种类型的AI[浪潮] 相继快速成为主流，它们分别是：[预测式 AI] 、[生成式 AI] （例如 LLM），以及[代理式 AI] 。\n代理式AI 可以创建计算机程序，即使没有明确的指令，也能够自主执行任务，而且也无需基于提示的特定上下文。AI 代理可以自行决策，从过去的经验中学习，并相应地调整行动。因此，它们可以独立运行，或者只需极少的人工干预就能运行。## 未来AI 将会如何发展？近年来，新的发现和更强大的硬件帮助AI 获得了前所未有的能力。AI 的历史将会继续延续，未来或许会有更多激动人心的发展。Cloudflare 赋能开发人员，让其能够为AI 的发展史贡献自己的力量。凭借遍布全球的分布式无服务器AI 基础设施、免费的训练数据出口、分布式[矢量数据库] 和其他关键的 AI 构建块，Cloudflare 平台让开发人员能够利用最先进的AI 技术进行构建。[立即为 AI 发展史贡献自己的力量] 。\n*来源：*\n* *https://cs.stanford.edu/people/eroberts/courses/soco/projects/neural-networks/History/history1.html*\n* *https://www.history.com/articles/7-early-robots-and-automatons*\n* *https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(07)00217-3*\n* *https://www.historyofinformation.com/detail.php?entryid=782*\n* *https://www.historyofinformation.com/detail.php?id=4137*\n* *https://www.techtarget.com/searchenterpriseai/definition/AI-winter*\n* *https://aaai.org/conference/aaai/aaai80/*\n* *https://blog.google/products/search/introducing-mum/*\n* *https://news.harvard.edu/gazette/story/2012/09/alan-turing-at-100/*\n开始使用* [Free 计划] \n* [小型企业计划] \n* [企业级服务] \n* [获得推荐] \n* [请求演示] \n* [联系销售] \n人工智能* [什么是人工智能 (AI)？] \n* [人工智能推理与训练] \n* [AI 发展史] \n机器学习* [什么是机器学习？] \n* [什么是深度学习？] \n* [什么是大型语言模型(LLM)？] \n* [低秩自适应 (LoRA)] \n* [AI 图像生成] \n大数据* [什么是嵌入？] \n* [什么是大数据？] \n* [如何构建 RAG 管道] \n词汇* [什么是 AI 安全？] \n* [向量数据库] \n* [预测式 AI] \n* [ChatGPT 插件] \n* [神经网络] \n* [什么是生成式 AI？] \n* [什么是自然语言处理 (NLP)？] \n* [AI 幻觉] \n* [AI 量化] \n* [OWASP Top 10 for LLM] \n* [AI 数据投毒] \n* [检索增强生成 (RAG)] \n* [什么是代理式 AI？] \n* [AI 的第三次浪潮] \n* [什么是氛围编码？] \n* [模型上下文协议 (MCP)] \n* [AI 在网络安全领域的应用] \n* [如何开始氛围编码] \n* [如何管理 AI 智能体] \n* [如何阻止 AI 爬网程序] \n* [如何防止抓取] \n* [如何保护 AI 系统] \n* [如何保护 AI 训练数据安全] \n学习中心* [安全性学习中心] \n* [CDN 学习中心] \n* [DDoS 学习中心] \n* [DNS 学习中心] \n* [性能学习中心] \n* [无服务器学习中心] \n* [SSL 学习中心] \n* [机器人学习中心] \n* [云学习中心] \n* [访问管理学习中心] \n* [网络层学习中心] \n* [隐私学习中心] \n* [视频流式传输学习中心] \n* [电子邮件安全性学习中心] \n* [学习中心主页] \n[] [] [] [] [] \n©2026Cloudflare 公司[隐私政策] [使用条款] [报告安全问题] [信任与安全]![privacy options] Cookie 首选项[商标]', 'doi': '', 'published_date': '2026-02-02T20:35:14.838071', 'pdf_url': '', 'url': 'https://www.cloudflare.com/zh-cn/learning/ai/history-of-ai/', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的发展时间轴：从过去到未来-百度开发者中心', 'authors': [], 'abstract': '人工智能的发展时间轴：从过去到未来-百度开发者中心\n[![logo]] \n* [登录] \n* |\n* [注册] \n### 开发者热搜* [人工智能] \n* [云原生] \n* [AI应用] \n[推荐] \n[云原生] \n[文心快码 Baidu Comate] \n[飞桨PaddlePaddle] \n[人工智能] \n[超级链] \n[数据库] \n[百度安全] \n[物联网] \n[开源技术] \n[云计算] \n[大数据] \n[开发者] \n[企业服务] \n[更多内容] \n[千帆大模型平台] \n[客悦智能客服] \n# 人工智能的发展时间轴：从过去到未来作者：[谁偷走了我的奶酪] 2024.01.08 08:38浏览量：33\n*简介：*本文将带你了解人工智能的发展历程，从早期的思想萌芽到现代的应用普及，我们将通过时间轴的方式揭示人工智能的冷知识和发展趋势。\n人工智能（AI）的发展历程可以追溯到上个世纪。在这个漫长的时间里，AI经历了多次高潮和低谷，不断推动着科技的进步。下面让我们一起沿着时间轴，了解AI的成长历程和未来展望。\n1943年，美国神经科学家Warren McCulloch和数学家Walter Pitts提出了[神经网络] 的初步概念，他们认为神经元的工作原理与逻辑门相似。这一思想成为人工智能发展的重要起点。\n1956年，美国达特茅斯学院的一次研讨会上，正式提出了“人工智能”这一概念。这次会议标志着AI作为一个独立的学术领域正式诞生。\n1957年，加拿大心理学家Frank Rosenblatt开发了感知机模型，这是一种基于神经网络的[机器学习] 模型。然而，由于当时计算机性能的限制，这一模型并未得到广泛应用。\n1966年，美国科学家Joseph Weizenbaum开发了名为Eliza的自然语言对话程序，这是最早的聊天机器人之一。Eliza能够通过简单的文本对话模拟人类对话，引起了人们对AI的关注。\n1970年，日本ATR实验室开发了名为Shakey的机器人，它是世界上最早的移动机器人之一。Shakey能够自主导航、识别物体并执行任务。\n1981年，日本科学家Satoshi Sekiguchi提出了基于规则的专家系统，这是一种基于知识的计算机系统，用于提供专业领域的建议和决策。\n1988年，美国斯坦福大学教授Fei-Fei Li和她的团队开发了用于[图像识别] 的卷积神经网络LeNet-5。虽然当时的技术有限，但这一研究为现代计算机视觉领域奠定了基础。\n1997年，IBM的超级计算机“深蓝”战胜了国际象棋世界冠军Garry Kasparov，这是计算机首次在传统智力[游戏] 中击败人类。\n2006年，加拿大多伦多大学教授Geoffrey Hinton提出了[深度学习] 的概念，这是一种模拟人脑神经网络的机器学习方法。深度学习在[语音识别] 、图像识别等领域取得了巨大成功。\n2011年，苹果公司发布Siri语音助手，成为首个在消费市场上广泛应用的智能助手。Siri能够理解语音指令并回答问题，为用户提供便利的信息和服务。\n2016年，谷歌DeepMind开发的AlphaGo战胜了围棋世界冠军李世石，这是计算机在围棋领域首次击败人类。AlphaGo使用深度学习和蒙特卡洛树搜索算法，展现了AI在复杂决策问题上的强大能力。\n2020年，Open[AI开发] 的GPT-3语言模型引发了AI文本生成的热潮。GPT-3能够生成连贯、有逻辑的文本内容，被广泛应用于[自然语言处理] 和对话系统等领域。\n未来展望：随着技术的不断进步，AI将在更多领域发挥重要作用。例如，自动驾驶、医疗诊断、金融投资等领域都将受益于AI的发展。同时，我们也需要关注AI带来的伦理和隐私问题，确保技术的可持续发展。\n### 相关文章推荐* [### 文心一言接入指南：通过百度智能云千帆大模型平台API调用\n本文介绍了如何通过百度智能云千帆大模型平台接入文心一言，包括创建千帆应用、API授权、获取访问凭证及调用API接口的详细流程。文心一言作为百度的人工智能大语言模型，拥有强大的语义理解与生成能力，通过千帆平台可轻松实现多场景应用。\n] \n[十万个为什么] 2023.10.20 16:562564931910\n* [### 从MLOps 到LMOps 的关键技术嬗变本文整理自QCon 全球软件开发大会-从 MLOps 到LMOps 分论坛的同名主题演讲] \n[百度智能云开发者中心] 2023.11.15 18:033441095\n* [### Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然Sugar BI教你怎么做数据可视化 - 拓扑图，让节点连接信息一目了然] \n[百度智能云开发者中心] 2023.03.21 10:563032831\n* [### 更轻量的百度百舸，CCE Stack 智算版发布百度百舸·AI 异构计算平台，是百度智能云将百度内部强大的AI 工程能力面向市场推出的解决方案。] \n[百度智能云开发者中心] 2023.03.02 12:172626811\n* [### 打造合规数据闭环，加速自动驾驶技术研发今天跟大家的演讲主题，主要是想交流如何去构建这样两个自动驾驶的数据闭环链路。] \n[百度智能云开发者中心] 2023.03.02 15:002767501\n* [### LMOps 工具链与千帆大模型平台LMOps 相关的概念以及关键技术] \n[百度智能云开发者中心] 2023.11.17 15:492395533\n### 发表评论登录后可评论，请前往[登录] 或[注册] \n评论### 开发者关注产品榜* [\n*1*\n### 百度千帆·大模型服务及Agent开发平台\n企业级一站式大模型开发及服务平台模型训练限时免费] \n* [\n*2*\n### 百度千帆·数据智能平台一站式多模态数据管理、加工和分析应用平台平台体验全免费] \n* [\n*3*\n### 秒哒-生成式应用开发平台\n不用写代码，就能实现任意想法全功能免费体验] \n* [\n*4*\n### 百度智能云客悦智能客服平台大模型重塑营销与客服体验0元试用一个月\n] \n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践] \n### 关于作者[![] ### ] \n* 被阅读数* 被赞数* 被收藏数关注活动[\n咨询]', 'doi': '', 'published_date': '2024-01-08T00:00:00+00:00', 'pdf_url': '', 'url': 'https://developer.baidu.com/article/details/2733815', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能简史-腾讯云开发者社区-腾讯云', 'authors': [], 'abstract': '人工智能简史-腾讯云开发者社区-腾讯云\n[] \n[用户9624935] \n## 人工智能简史**关注作者\n[*腾讯云*] \n[*开发者社区*] \n[文档] [建议反馈] [控制台] \n登录/注册\n[首页] \n学习活动专区圈层工具[MCP广场![]] \n文章/答案/技术大牛搜索**\n搜索**关闭**\n发布用户9624935\n**\n**\n**\n**\n**\n[社区首页] &gt;[专栏] &gt;人工智能简史\n# 人工智能简史![作者头像] \n用户9624935\n**关注\n发布于2022-04-02 14:58:47\n发布于2022-04-02 14:58:47\n2.2K0\n举报**文章被收录于专栏：[凯云实验室] 凯云实验室\n![] \nArtificial Intelligence (AI)，是在1956年的达特茅斯会议上提出来的，标志着人工智能这一学科的诞生。\n从1956年到2016年，刚好是60年。在过去的60年里，人工智能经历了三个阶段：\n* 二十世纪五十年代到七十年代：推理期，其出发点是，数学家真聪明。让计算机具有逻辑推理能力：为什么仅有逻辑推理能力不能实现人工智能？困难在哪里？* 二十世纪七十年代中期开始：知识期，其出发点是，知识就是力量。让计算机具有知识：由人把知识总结出来，再教给计算机——这是相当困难的。* 二十世纪九十年代到现在：学习期，其出发点是，让系统自己学。同时，也催生了人工智能的三大派别：* 符号主义：主要内容是关于符号计算、演算和逻辑推理，用演算和推理的办法来证明。比如说像机器证明就是符号主义。* 连接主义：目前非常流行的神经网络、神经元网络、深度学习，这些都是连接主义。* 行为主义：行为主义其实是从控制论衍生出来的，目前提及较少，但不能忽略。> 作者注：关于学派的分法，《终极算法》一书分为五类：符号学派，联结学派，进化学派，贝叶斯学派和类推学派。人工智能的三个派别和三个阶段并没有对应和界限，三个派别是在三个阶段的交织中发展起来的。著名信息论和人工智能专家钟义信在《弘扬Simon的源头创新精神，开拓AI的新理念新路径》报告中指出三大学派的的出现是一直以来还原论把复杂的系统分而治之研究的结果。因为整体上解决智能问题在物理和数学上都存在巨大的困难，所以在模仿大脑的功能研究上，出现了符号主义；在模仿大脑结构的研究上，出现了连接主义，在模仿人类行为的研究上（什么样的环境刺激会产生什么样的行为反应），出现了行为主义。\n> 作者注：看待人工智能的历史，要把人工智能的历史和神经网路的历史稍微区分一下，不能把神经网络的历史看作是人工智能的历史。所以本文不单独列举神经网络的发展历史和重大事件，留在下一篇文章中探讨。人工智能发展的过程中，经历了三次大事件，这些大事件导致了人工智能的发展进入三次低谷，被称为&quot;AI winter&quot;：\n* 1973年，英国发表了James Lighthill报告，批评人工智能研究进展令人失望，建议取消机器人的研究。为了回应批评和国会的压力，美国和英国政府停止了人工智能研究的资助。\n* 1992年，日本智能（第五代）计算机的研制宣告失败。这次失败有一个收获，是在潘云鹤《人工智能走向2.0》一文指出的，这次失败表明：驱动人工智能的发展主要靠创新的知识和软件，硬件的作用是支持其运行。\n* 在80年代，也诞生了cyc项目，一个包含所有人类常识的数据库。该项目随着互联网搜索引擎的崛起而衰败。潘云鹤在《人工智能走向2.0》指出：海量知识不能靠专家人工表达，要从环境中自动学习。也就是周志华指出的：由人把知识总结出来，再教给计算机——这是相当困难的。\n在过去的60年里，人工智能领域共有8位科学家成为图领奖得主：\n* 1969，Marvin Minsky：奖励他在创造，塑造，推动和加速人工智能这一领域的核心作用。\n* 1971，John McCarthy：麦卡锡的讲座《人工智能的研究现状》概括了他在人工智能领域的成就，也概括了值得奖励的原因。\n* 1975，Allen Newell and Herbert A. Simon：奖励他们在二十多年的联合科学工作中，最初与兰德公司的JC Shaw合作，随后与卡内基梅隆大学的众多教师和学生同事合作，对人工智能，人类认知心理学和列表处理方面做出的基础贡献。\n* 1994，Edward Feigenbaum and Raj Reddy：奖励他们在开创了大规模人工智能系统的设计和建造，展示了人工智能技术的实际重要性和潜在的商业影响。\n* 2010，Leslie G. Valiant：奖励他对于计算理论的变革性贡献，包括可能近似正确（PAC）学习的理论，枚举和代数计算的复杂性以及并行和分布式计算的理论。\n* 2011，Judea Pearl：奖励他对人工智能的基础贡献：概率和因果推理的微积分。\n上面这8位科学家，Marvin Minsky是MIT教授，最早提出连接主义，后来发表的《Perceptrons》一书指出感知机无法处理异或问题，导致连接主义长时间陷入低谷。不过著名信息论和人工智能专家钟义信说，另一个方面来看，马文·明斯基指出这个问题以后，经过人们的研究，提出了所谓的多层感知机，我们只要增加一个顶层就可以极大地提高神经网络表达的能力，可以逼近任意的问题。所以这个事情又从它的负面走向了正面，产生了积极的效果。\nJohn McCarthy，Allen Newell， Herbert A. Simon、Edward Feigenbaum几位都是非常典型的符号主义代表，他们最早推动了机器证明、人工智能、通用人工智能机、知识工程的进步。\n> 作者注：值得一提的是Herbert A. Simon是美国卡内基－梅隆大学心理学教授，1978年诺贝尔奖金获得者（经济学）。1968-1972年任美国总统科学顾问、行为科学和人工智能的创始人之一。西蒙教授为科学界的知名学者，在企业管理、计算机设计和决策理论方面有所创见。\nRaj Reddy主要是做语音识别的，李开复、沈向阳的老师。\nLeslie G. Valiant的贡献是机器学习理论，Judea Pearl的贡献是概率计算和因果推理，高文院士说，他们的工作是未来人工智能的重点走向。\n以上从分别从三个时期，三大学派，三次大事件以及8位图领奖得主的角度，总结了人工智能的简史。以下是我的一些不成熟思考：\n第一，计算的本质与智能的本质。《类脑智能研究的回顾和展望》指出，现有人工智能系统通用性较差与其计算理论基础和系统设计原理有密不可分的关系。计算机的计算本质和基础架构是图灵机模型和冯诺伊曼体系结构，其共同的缺点是缺乏自适应性。图灵计算的本质是使用预定义的规则对一组输入符号进行处理，规则是限定的，输入也受限于预定义的形式。图灵机模型取决于人对物理世界的认知程度，因此人限定了机器描述问题，解决问题的程度。而冯诺伊曼体系结构是存储程序式计算，程序也是预先设定好的，无法根据外界的变化和需求的变化进行自我演化。总结来看，计算的本质可以用一个数学公式f(x)=y来表达，是问题求解的范畴。\n那智能的本质是什么？如何表达？著名信息论和人工智能专家钟义信给了一个探讨性的定义：智能一定是在环境的作用下，人跟环境相互作用，不断的去学习，不断的去进化，在这个过程当中展开了智能的活动。反之，如果没有这种主体跟客体的相互作用，如果一切都是十全十美，如果不需要做出任何的改进，那就不需要思考、不需要学习，也就不需要智能。所以，一定要在主体跟客体相互作用过程当中来考察智能才有意义。李衍达院士在《沿Simon 开拓下去》的报告中探讨了智能的功能与智能的机理问题，指出基因的层次没有鸿沟，人和所有生物的机理是相同的，区别的是进化：自动适应外界变化而优化自身结构的功能。而且人脑在进化过程里面通过DNA的改变，改变了神经元的连接，这个连接既记录了学习的结果，又优化了学习算法。既简化了所需要的元件，又节省了能耗，非常巧妙。\n> 智能路径：感知反应-&gt;条件反射（存储，记忆）-&gt;决策（意志、欲望和目的）\n第二，关于程序员转型。和第一个问题有关，我们都是学习图灵机模型和冯诺伊曼架构长大的，思维方式相对固定。深度学习今年非常火爆，程序员又要开始转型。关于转型，我注意到几个论调：* 转型深度学习，数学是首要的基础；* 转型深度学习，开始大量学习TensorFlow框架；\n* 大二大三优秀学生学习起来很快，有经验的程序员学习来很苦；以上我都不太认同，人类是万物之灵，遇到新问题，学习新东西，再正常不过的事情，何来转型之说？如果非要说有什么需要转变，我觉得是到思维方式的转变：* 数学只是工具，TensorFlow只是封装的平台，而深度学习是有理论瓶颈的，工程界一直以来轻视学术的思维定势需要改变了。国内程序员同时是科学家的太少了，科学家有点高，做个学者吧。感觉要做一个好的科学家，不只是研究技术，而是在研究哲学，研究一些物质的本质、规律，研究一些最基础的东西。\n* 大多数程序员都是“程序员”思维，这是软件工业化的结果。重接口，重输入，重交付，这是一种软件外包的思维。输入是什么？输出是什么？程序如何实现？这些都造成了思维懒惰的一代程序员，从来不去问为什么程序这么做。而深度学习恰恰是讨论程序为什么这么实现的问题，其输出是模型，是算法。这是程序员需要改变的思维方式。* 人工智能更强调创新，特别是源头创新。在这个领域，有大量的问题都是崭新的，需要采用一些数学理论，结合实际需求来探索。我们在学习机器学习理论和算法的时候，需要有意识的突破已有的认知，特别是图灵机模型和冯诺伊曼体系结构。第三，脑复杂？还是环境复杂？傅小兰在《Simon与认知科学研究》报告中提到了《分布式认知》，指出认知现象在认知主体和环境间分布的本质：认知既分布于个体内与个体间，也分布于媒介、环境、文化、社会和时间等之中（Cole &amp; Engestrom, 1993）。Herbert A. Simon 也指出，一个人，若视作行为系统，是很简单的。他的行为随时间而表现出的表面复杂性主要是他所处环境的复杂性的反映。人——或至少人的智力要素——也许是比较简单的，人的行为的复杂性也许大半来自人的环境，来自人对优秀设计的搜索，因此，“在相当大的程度上，要研究人类便要研究设计科学。它不仅是技术教育的专业要素，也是每个知书识字人的核心学科”。第四，从上而下还是从下而上？人工智能从上而下研究的开创者和代表人物是Herbert A. Simon，他当时想到，人的大脑活动是分层次的，在底层的机理没有搞清楚时，他认为也不妨碍对于高层概念、推理、问题求解层次进行研究。符号学派就是自上而下的典型代表，但至今符号学派一直受到自下而上的连接主义压制。自下而上的代表是日本的第五代计算机计划，东京大学元岗达教授提出“第五代计算机的构想”，随后日本制定了研制五代机的十年计划，总预算达4.3亿美元。以渊一博为所长的“新一代计算机技术研究所”苦苦奋战了近十年，他们几乎没有回过家，近乎玩命式的拼搏；然而，由于没有突破关键性技术难题，无法实现自然语言人机对话，程序自动生成等目标，最终于1992年宣告失败！这或许也是图灵机模型和冯诺伊曼架构的失败。然而，峰回路转，得益于分布式计算和大数据时代，深度学习成为主流的自下而上方法。近五年来，深度学习在“视”、“听”、“说”等领域取得了的巨大成功，但这还不能表明自下而上的胜利或者神经网络模型的正确。神经网络只是从下而上对大脑的粗糙模拟和抽象，是否是正确的大脑学习隐喻还不得而知。但神经网络的成功又引发了一些自下而上的尝试，据称IBM有一个名为“突触”的项目，研究芯片级类脑计算设备，支持低频率，低功耗，和大量链接等神经网络功能。\n第五，鲁棒性？可解释性？魔术性？这几个问题是现在机器学习，特别是深度学习面临的主要问题。人类犯错：水平从九段降到八段，机器犯错：水平从九段降到业余，这就是鲁棒性。鲁棒性要求，“好的时候”要好，“坏的时候”不能太坏。在封闭静态环境中，重要因素大多是“定”的，而在开放动态环境中，一切都是变的，开放环境的鲁棒性，这也是自动驾驶面临的困难所在。关于可解释性，也被称为深度学习的黑箱模型。若学习器不能给出治疗理由，则难以说服患者接受昂贵的治疗方案。若学习器不能给出停机检测的理由，则难以判断停机检测的风险和代价。这些案例都需要机器学习的模型给出解释，否则难以应用到难以用于高风险应用。而机器学习魔术性是指即便相同数据，普通用户很难获得机器学习专家级性能。就是专家之间，是特别考验团队实力的，也有一点运气在里面。门派都一样，功力不一般。第六，目前的研究热点和我的方向。深度学习是很火的，不过周志华说的很中肯：“深度学习中间还有很多困难而又重要的问题值得深入研究，但这些真正值得研究的问题，就我看到的情况而言，好像做的人非常少。大多数人在干什么呢？拿它做做应用，调调参数，性能刷几个点，然后发几篇文章。这样虽然容易发表文章，但恐怕很难产生有影响的成果。”另外，周志华在引领集成学习的发展方向，CCAI17可以看到一些方向，中国香港科技大学计算机系主任杨强谈到的迁移学习，日本理化学研究所杉山将谈到的弱监督机器学习等。我的计划是，从历史中观其大略；感知机，神经网络，反向传播，深度学习是一条线，已经是必备的基础了；然后向增强学习发力；在技术上打通分布式系统，大数据和机器学习；在业务和需求上结合金融场景。\n![] \n第七，已知和未知。我们参考神经生理学，研制了神经网络和深度学习，并且取得了良好的效果。有人指出，大脑的生物物理结构，机制和功能只是大脑处理信息过程中的印记，其中很少一部分可用于有意识的思想（认知）。在学习未知的过程中，我们对学习到底了解了多少？在未知的区域里，既有要学习的对象，也有学习本身。参考文献：《人工智能走向2.0》 潘云鹤《类脑智能研究的回顾与展望》曾毅等《脑启发计算》苏中《机器学习》序言陆汝钤《机器学习：发展与未来》周志华《H. A. Simon学术生平》林建祥\n《Simon的认知科学思想》傅小兰\n《人工智能--螺旋上升的60年》高文院士\n《沿Simon 开拓下去》李衍达《塞蒙终生学术经历简介》林建祥《人工智能的历史》中国人工智能学会《司马贺的创新之路》史忠植《弘扬Simon学术思想 》钟义信《探寻大师足迹，一览马文•明斯基学术风采》史忠植《站在巨人的肩膀上，从人工智能与认知商务》苏中《弘扬Simon的源头创新精神开拓“AI”的新理念新路径》钟义信\n《独家| 周志华：深度学习很有用，但过度追捧就有危险了》AI科技大本营\n本文参与[腾讯云自媒体同步曝光计划] ，分享自微信公众号。\n原始发表：2017-08-06，如有侵权请联系[cloudcommunity@tencent.com] 删除\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n本文分享自补天遗石微信公众号，前往查看如有侵权，请联系[cloudcommunity@tencent.com] 删除。\n本文参与[腾讯云自媒体同步曝光计划] ，欢迎热爱写作的你一起参与！\n[机器学习] \n[深度学习] \n[神经网络] \n[人工智能] \n评论登录后参与评论0条评论\n热度最新登录后参与评论推荐阅读相关产品与服务人工智能与机器学习提供全球领先的人脸识别、文字识别、图像识别、语音技术、NLP、人工智能服务平台等多项人工智能技术，共享 AI 领域应用场景和解决方案。[**产品介绍] \n[**AI驱动 智领未来] \n领券* ### 社区* [技术文章] \n* [技术问答] \n* [技术沙龙] \n* [技术视频] \n* [学习中心] \n* [技术百科] \n* [技术专区] \n* ### 活动* [自媒体同步曝光计划] \n* [邀请作者入驻] \n* [自荐上首页] \n* [技术竞赛] \n* ### 圈层* [腾讯云最具价值专家] \n* [腾讯云架构师技术同盟] \n* [腾讯云创作之星] \n* [腾讯云TDP] \n* ### 关于* [社区规范] \n* [免责声明] \n* [联系我们] \n* [友情链接] \n* [MCP广场开源版权声明] \n### 腾讯云开发者![扫码关注腾讯云开发者] \n扫码关注腾讯云开发者领取腾讯云代金券### 热门产品* [域名注册] \n* [云服务器] \n* [区块链服务] \n* [消息队列] \n* [网络加速] \n* [云数据库] \n* [域名解析] \n* [云存储] \n* [视频直播] \n### 热门推荐* [人脸识别] \n* [腾讯会议] \n* [企业云] \n* [CDN加速] \n* [视频通话] \n* [图像分析] \n* [MySQL 数据库] \n* [SSL 证书] \n* [语音识别] \n### 更多推荐* [数据安全] \n* [负载均衡] \n* [短信] \n* [文字识别] \n* [云点播] \n* [大数据] \n* [小程序开发] \n* [网站监控] \n* [数据迁移] \nCopyright ©2013 -2026Tencent Cloud. All Rights Reserved. 腾讯云版权所有[深圳市腾讯计算机系统有限公司] ICP备案/许可证号：[粤B2-20090059]![] [粤公网安备44030502008569号] \n[腾讯云计算（北京）有限责任公司] 京ICP证150476号 |[京ICP备11018762号] \n[问题归档] [专栏文章] [快讯文章归档] [关键词归档] [开发者手册归档] [开发者手册 Section 归档] \nCopyright ©2013 -2026Tencent Cloud.\nAll Rights Reserved. 腾讯云版权所有登录后参与评论**\n**\n**\n000\n推', 'doi': '', 'published_date': '2022-04-02T00:00:00+00:00', 'pdf_url': '', 'url': 'https://cloud.tencent.com.cn/developer/article/1971641', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能六十年技术革新与发展历程', 'authors': [], 'abstract': '人工智能六十年技术革新与发展历程 \n# 人工智能六十年技术革新与发展历程作者：渣渣辉2024.11.25 19:16浏览量：12\n*简介：*人工智能自1956年诞生以来，经历了黄金时期、寒冬、兴盛等多个阶段，技术不断突破。本文回顾了AI的60年技术简史，包括起源、关键节点、标志性成就及未来展望，并探讨了小数据、优质数据、全模态大模型等前沿趋势。\n人类的进化发展史就是一部人类制造和使用工具的历史，不同的工具代表了不同的进化水平。从石器时代到信息时代，工具不断演进，旨在延伸和拓展人类的能力。其中，人工智能（AI）作为信息时代的重要工具，自诞生以来已经走过了60年的技术历程。\n### AI的起源与早期探索\nAI的起源可以追溯到1956年的达特茅斯会议，计算机专家约翰·麦卡锡首次提出了“人工智能”的概念，标志着AI学科的诞生。在此之前，莱布尼茨曾试图制造能够进行自动符号计算的机器，为AI的萌芽奠定了基础。在AI的早期发展阶段，研究主要集中在符号逻辑、自动定理证明和专家系统等领域。\n### 黄金时期与寒冬1956年至1974年是AI的黄金时期，大量的资金用于支持这个学科的研究和发展。在这一阶段，LISP语言成为AI领域的主要编程语言，为AI的发展提供了强大的工具支持。同时，首台工业机器人、首台聊天机器人等标志性成果的诞生，进一步推动了AI技术的发展。然而，随着期望与现实之间的差距逐渐扩大，以及计算机硬件性能的限制和数据量的不足，AI在实际应用中难以达到预期效果，进入了第一次寒冬期（1974-1980）。\n### 复苏与繁荣进入20世纪80年代后，随着计算机性能的提高和数据量的增加，AI迎来了复苏和繁荣的时期。[机器学习] 成为AI的一个重要分支，神经网络和深度学习等技术的出现为AI的发展提供了新的动力。特别是近年来，随着大数据、[云计算] 等技术的普及和应用，AI在语音识别、[图像识别] 、[自然语言处理] 等领域取得了显著进展。AlphaGo在围棋领域战胜人类世界冠军李世石，更是展示了AI技术的强大实力。\n### 关键技术节点与标志性成就在AI的60年发展历程中，涌现出了许多关键技术节点和标志性成就。例如，LISP语言为AI编程提供了有力支持；通用问题求解器和聊天机器人ELIZA等早期应用展示了AI的潜力；深度学习的兴起推动了AI技术的快速发展；AlphaGo等AI系统在围棋等复杂领域战胜人类，标志着AI技术达到了新的高度。\n### 前沿趋势与未来展望当前，AI技术正朝着更加智能化、精细化的方向发展。小数据和优质数据的价值越来越重要，它们能够减少算法对数据量的依赖，提高模型的精度和可靠性。同时，全模态大模型能够处理和理解多种类型的数据输入，生成多种类型的输出，为AI的应用提供了更广阔的空间。此外，具身智能和实体人工智能系统的出现，将使AI在物理世界中发挥更大的作用。\n未来，人工智能将继续保持快速发展的势头。随着技术的不断进步和应用场景的不断拓展，AI将在医疗、[教育] 、交通、金融等领域发挥越来越重要的作用。例如，在医疗领域，AI可以帮助医生进行疾病诊断和治疗方案制定；在教育领域，AI可以根据学生的学习情况提供个性化的教学服务；在交通领域，AI可以实现智能驾驶和交通流量优化等功能。\n然而，AI的发展也面临着诸多挑战和风险。隐私保护、就业问题、伦理道德等都是需要关注和解决的问题。因此，我们需要加强跨学科的研究和合作，共同推动AI技术的健康发展。\n### 产品关联：千帆[大模型开发] 与服务平台\n在AI技术的快速发展和应用过程中，千帆大模型开发与服务平台作为一款专业的AI开发平台，为AI技术的创新和应用提供了有力支持。该平台提供了丰富的AI算法和模型资源，以及强大的计算和[存储] 能力，可以帮助[开发者] 快速构建和部署AI应用。同时，千帆大模型开发与服务平台还支持多种数据格式和接口，方便开发者与各种系统进行集成和对接。通过该平台，开发者可以更加高效地利用AI技术解决实际问题，推动AI技术的创新和发展。\n综上所述，人工智能的60年技术简史是一部充满挑战和机遇的历史。回顾过去，我们为AI取得的成就感到自豪；展望未来，我们对AI的发展前景充满信心。随着技术的不断进步和应用场景的不断拓展，AI将在更多领域发挥重要作用，为人类社会的发展贡献更多力量。\n325\n### 最热文章* [零基础调用文心大模型4.5API实操手册] \n* [生产力UP！文心快码 Rules 功能实战指南] \n* [Redis 数据恢复的月光宝盒，闪回到任意指定时间] \n* [用文心快码Zulu打造太阳系3D模拟器：从需求到落地的全流程实践]', 'doi': '', 'published_date': '2024-11-25T11:16:36+00:00', 'pdf_url': '', 'url': 'https://cloud.baidu.com/article/3376781', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能的80年进化编年史：从想象到现实', 'authors': [], 'abstract': '人工智能的80年进化编年史：从想象到现实\\_腾讯新闻\n# 人工智能的80年进化编年史：从想象到现实\n![头像]![] \n[\nWeb3天空之城\n] \n2023-03-01 20:44发布于浙江科技领域创作者\nAGI是Artificial General Intelligence的缩写，即通用人工智能。\nAGI的目标是实现人类般的通用智能，这意味着AI可以像人类一样理解任意通用任务, 并以人类的智力水平执行完成。基本上, 除了&quot;自我意识&quot;的生成，AGI就是人类对人工智能的终极梦想了。\n无论是近一年来火爆的AI绘画，还是当红炸子鸡ChatGPT，AI研究应用的终极目标, 都是向着AGI通用人工智能的大一统目标在迈进。\n读者是否有同感,\xa0这几年各种AI大模型的发展和突破, 着实有让人眼花缭乱之感?\n本文主要把现代到当下一些AI的重要节点做了时间线梳理和简单分析，或有助于大家来理清楚这些年AI发展的关键脉络。\n1942年\n时间回到80年前, 科幻泰斗阿西莫夫提出了著名的&quot;机器人三定律”：\n机器人不得伤害人类，或坐视人类受到伤害；除非违背第一定律，否则机器人必须服从人类命令；除非违背第一或第二定律，否则机器人必须保护自己。这三个定律是人工智能和机器人技术的哲学基础，是对如何设计人工智能系统的基本原则的阐述，至今都有着重要的参考意义。1950年\n计算机科学之父艾伦·图灵（Alan Turing）发表了具有里程碑意义的论文《Computing Machinery and Intelligence（计算机器与智能）》。论文预言了创造出具有真正智能的机器的可能性，第一次提出图灵测试（The Turing test）的概念：\n如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。1956年\nAI概念诞生。\n美国的达特茅斯学院举行了一次具有传奇色彩的学术会议（Dartmouth Conference）， 探讨用机器模拟人类智能的问题。计算机专家约翰·麦卡锡提出了AI&quot;人工智能”一词。这被广泛认为是人工智能正式诞生的日子。参与会议的学者们是最早的AI研究先驱。\n从1956年到现代，这几十年来AI研究的起伏，有兴趣的读者可以参考本号另一篇文章从爆火的chatGPT讲起: 自然语言生成式AI的前世今生, 你想了解的一切&gt;\n当今大众关于AI的记忆，或许是从1997年开始的：\n1997年\n5月11日, IBM公司的电脑&quot;深蓝”战胜了国际象棋世界冠军卡斯帕罗夫，成为首个击败国际象棋世界冠军的AI系统。\n1998年\n现代卷积神经网络CNN诞生。\n1980年，日本学者福岛邦彦（Kunihiko Fukushima）模仿生物的视觉皮层（visual cortex），设计了人工神经网络&quot;neocognitron”，这是现代卷积神经网络的雏形。\n经过多年前赴后继的研究，1998年杨立昆（Yann LeCun，现任Meta首席人工智能科学家）基于前人基础，构建了更加完备的卷积神经网络LeNet-5，在手写数字的识别问题中取得了成功。LeNet-5被认为是现代卷积神经网络的基本结构。\n卷积神经网络CNN是当今&quot;深度学习&quot;AI模型的计算基础架构。一直到2017年Transformer架构横空出世后，CNN才被取代。\n2003年\nYoshua Bengio在2003年发表了《A Neural Probabilistic Language Model》，这是第一篇基于人工神经网络打造自然语言模型的论文，提出了具有奠基意义的NNLM&quot;神经网络语言模型&quot;。它在得到语言模型的同时也产生了副产品&quot;词向量&quot;。\n2006年\n杰弗里·辛顿（Geoffrey Hinton）在science期刊上发表了重要的论文《Reducing the dimensionality of data with neural networks》，提出深度信念网络（Deep Belief Networks，DBNs），&quot;深度学习&quot;正式诞生。\n2009年\n李飞飞主导的Image Net正式发布，有超过1000万数据，两万多个类别。为全世界的AI学者提供了开放的标注图像大数据集。\n2010年开始，Image Net大规模视觉识别挑战赛（ILSVCR）开始举办，全世界图像领域深度学习的专家们同台竞技和交流，从此拉开了计算机视觉的新篇章。\n2012年\nGoogle的吴恩达和Jef Dean使用1.6万个CPU（那时的GPU生态还在婴幼儿阶段）训练了一个当时世界上最大的人工神经网络，用来教AI绘制猫脸图片。训练数据是来自youtube的1000万个猫脸图片，1.6万个CPU整整训练了3天。\n对于计算机AI领域，这是一次具有突破性意义的尝试。AI第一次&quot;生成&quot;了一个图像内容：一张模糊的猫脸\n![图片] \n2013年\nGoogle的托马斯·米科洛夫（Tomas Mikolov）带领研究团队发表了论文《Efficient Estimation of Word Representations inVector Space》，提出了Word2Vec。\nWord2Vec可以根据给定的语料库，通过优化后的训练模型可以快速有效地将一个词语表达成高维空间里的词向量形式，为自然语言处理领域的应用研究提供了新的工具。\n2014年1月\n谷歌斥资400亿美元收购了位于伦敦的明星人工智能企业DeepMind。\n2014年12月\nGAN（对抗式生成网络）诞生。\n2014 年，Lan Goodfellow从博弈论中的&quot;二人零和博弈&quot;得到启发 ，创造性的提出了生成对抗网络（GAN，Generative Adversarial Networks），他在2014年的NIPS会议上首次发表了相关论文，用两个神经网络即生成器（Generator）和判别器（Discriminator）进行对抗。在两个神经网络的对抗和自我迭代中，GAN会逐渐演化出强大的能力。\n作者在最早的文章里形象的把GAN比喻为伪造者和警察：伪造者总想造出以假乱真的钞票，而警察则努力用更先进的技术去鉴别真伪。在博弈过程中，双方都不断提升了自己的技术水平。\nGAN号称21世纪最强大的算法模型之一，&quot;Gan之父&quot;Ian Goodfellow也一跃成为AI领域的顶级专家。\n2015年12月\nOpenAI公司于美国旧金山成立。\nOpenAI诞生的原因是很有趣的：DeepMind被Google收购的消息震动了硅谷，如果发展下去，DeepMind很有可能成为最早实现AGI通用人工智能的公司。为了打破GoogleAI技术的垄断，在一次私人聚会后，大佬们一拍即合成立了OpenAI。\n其中包括，钢铁侠Elon Musk，当时已是著名创业孵化器 Y Combinator 的负责人现在成为OpenAI CEO的Sam Altman，以及著名天使投资人 Peter Thiel等硅谷大佬。\nOpenAI作为一个非营利性组织运营，并立志要做DeepMind和Google无法做到的事情：开放和共享AI技术。\n从今天的眼光看，尽管OpenAI后来的商业模式有所变化，但绝对实现了它诞生的最大愿景之一：狙击Google和DeepMind。\nChatGPT的推出加上微软Bing的推波助澜搞得Google实在是狼狈不堪。\n2015年\n11月， Google开源了重要的深度学习框架Tensor Flow；\n同年，还是Google，开源了用来分类和整理图像的 AI 程序Inceptionism，并命名为 DeepDream。尽管还很初级，但DeepDream被认为是第一个现代的AI绘画应用。\n2016年\n3月，Google的AlphaGo战胜围棋世界冠军李世石;\n4月，Google深度学习框架TensorFlow发布分布式版本;\n9月，Google上线基于深度学习的机器翻译;\n2015到2016年，Google的AI能力可谓是风头一时无两。\n2017年1月\nFacebook人工智能研究院（FAIR）开源了PyTorch。PyTorch和tensorFlow从此成为了当今两大主流深度学习框架。\n2017年7月\nFacebook联合罗格斯大学和查尔斯顿学院艺术史系三方合作得到新AI绘画模型，号称创造性对抗网络（CAN，Creative Adversarial Networks），\nCAN在测试中，有53%的观众认为AI作品出自人类之手，这是类似的图灵测试历史上首次突破半数，这是AI绘画模型小小而扎实的一步。\nFacebook在AI领域其实耕耘了很久，做过很多贡献，可惜后面搞Metaverse连公司名字都改成Meta了， 差点错过了当下这波AI的浪潮。\n不过最近小札醒悟过来，终于官宣要All in AI。Meta还是很有实力的，奋起直追应为时未晚。\n2017年12月\n颠覆性的Tranformer架构出世了!\nGoogl机器翻译团队在年底的顶级会议NIPS上发表了里程碑式的论文《Attention is all you need》，提出只使用自注意力（Self Attention）机制来训练自然语言模型，并给这种架构起了个霸气的名字：Transformer。\n所谓&quot;自我注意力&quot;机制，简单说就是只关心输入信息之间的关系，而不再关注输入和对应输出的关系。和之前大模型训练需要匹配的输入输出标注数据相比，这是一个革命性的变化。\nTransformer彻底抛弃了传统的CNN和RNN等神经网络结构。在这篇论文发布之前，主流AI模型都基于CNN卷积神经网络和RNN循环神经网络（recurrent neural network）; 而之后，便是Transformer一统天下。\nTransformer架构的详细描述不在本文范围，读者只需要知道它具有两点无敌的优势：\n自我注意力机制，让模型训练只需使用未经标注的原始数据，而无需再进行昂贵的的人工标注（标注输入和对应输出）。并行效率是之前的AI模型结构被一直诟病的地方。抛弃了传统CNN/RNN架构后，基于Transformer架构的大模型训练可以实现高度并行化，这大大提高了模型训练的效率;\n从此，大模型大数据大算力，大力出奇迹，成为了AI领域的标配。\n感慨一下，Google首先发明了划时代的Transformer架构，但在5年后的今天，却被OpenAI打得喘不过气。这是命运的偶然吗？\n2018年6月\nOpenAI发布了第一版的GPT（Generative Pre-training Transformers）系列模型 GPT-1。\n同时，OpenAI发表了论文《Improving Language Understanding by Generative Pre-training》\n从论文里可以了解到，GPT-1具有1.17个参数，采用了12层的Transformer 解码器结构，使用5GB的无标注文本数据，在8个GPU上训练了一个月，然后再进行人工监督的微调。\n不过，GPT-1并不是当年的明星，因为同年，Google的BERT大模型也发布了（当时的Google就是强啊）。\n2018年10月\n谷歌发布3亿参数的BERT（Bidirectional Encoder Representation from Transformers），意思即&quot;来自Transformers的双向编码表示”模型。\nGPT和BERT的诞生意味着预训练大模型（Pre-trained Models）成为了自然语言处理领域的主流。\n和GPT相比，BERT最大的区别就是使用文本的上下文来训练模型，而专注于&quot;文本生成&quot;的GPT-1，使用的是上文。\n基于&quot;双向编码&quot;的能力让BERT的性能在当时明显优异于第一代的GPT-1。\n幸好，Open AI 并没有那么容易放弃，一直坚持只用上文训练的&quot;单向编码&quot;纯生成模式。直到GPT-3，神功初成。\n2018年底\n在共同创立公司三年后，钢铁侠马斯克辞去了Open AI董事会职务，原因是&quot;为了消除潜在的未来冲突&quot;。\n实际情况是，2017年6月，马斯克挖走了OpenAI的核心人员Andrej Karpathy，担任Tesla的AI部门主管并直接向自己汇报，负责构建特斯拉的自动驾驶系统。\n所以，确实是存在人才竞争&quot;潜在冲突&quot;的。\n有趣的是，根据前不久的最新消息，ChatGPT大火之后，Andrej Karpathy同学又离开了Tesla回到了OpenAI。这是所谓&quot;鸟择良木而栖&quot;：）\n而马斯克放出了声音，要打造OpenAI的竞争者。不知首富同学是否遗憾当年不得不放走了OpenAI。\n2019年2月\nOpenAI发布了GPT-2。\nGPT-2有48层Transformer结构，使用40GB文本数据训练，参数量突破到了15亿。\n在同时发布的论文《Language Models are Unsupervised Multitask Learners》 中，OpenAI描述了GPT2在经过大量无标注数据生成式训练后，展示出来的零样本（zero-shot）多任务能力。\n所谓零样本学习就是用很大的通用语料去训练模型，然后不再需要做特定任务的训练，大模型就可以直接完成一些具体任务。一个典型例子是翻译。GPT-2具备了良好的语言翻译能力; 而有趣的是，专门做翻译的模型通常使用标注好的语料（即两个不同语言的匹配数据）来训练。但GPT-2并没有使用这类数据，翻译效果还超过了很多专职翻译的小模型。\nGPT-2揭示了一个有趣的现象，仅作为生成式任务来训练打造的大模型，开始具备了多种通用任务能力，比如GPT-2所具备的阅读理解和翻译等等。\n2019年3-7月\n3月份，OpenAI正式宣布重组，成为一家&quot;利润上限（caped-profit）&quot;的公司，规定了投资收益的上限。这是一个很特别的架构。\n而近期披露的OpenAI最新投资架构也再次揭示了这个公司股权结构的与众不同。简单的说，OpenAI把自己租借给了微软，赚到1500亿美金后，将重新变为非营利性组织 -- 至少说是这么说的。5月，Sam Altman辞去了 YC总裁的工作，开始担任新 OpenAI 的CEO。\n7月，重组后的OpenAI拿到了微软包括Azure云计算资源在内的10亿美金投资， 微软将作为&quot;首选合作伙伴”，今后可获得OpenAI 技术成果的独家授权。自此，OpenAI后续技术成果不再承诺开源。\n2020年5月\nOpenAI发布了GPT-3。\nGPT-3的初始版本在内部代号为&quot;davinci&quot;，使用45TB文本数据训练，有1750亿参数。根据公开信息，模型的训练费用是1200万美金。因为太贵，只训练了一次。\n随后，OpenAI发表了近70页的论文《Language Models are Few-Shot Learner》。这篇论文阐述了大模型的各种新能力，而最重要的就是标题所指出的小样本（few-shot）学习能力。\n&quot;few-shot&quot;是一个专业术语，理解起来也简单，就是通过少量的几个例子就能学习一个新的任务。人们发现，GPT-3开始具有类似人类的能力，只要在提示里展示特定任务的几个示例，GPT-3就能完成新示例的输出。而无需进行针对性的额外微调训练。这也被称之为&quot;上下文学习&quot;（in context learning）\n2020年6月\n对AI绘画有重要意义的论文 《Denoising Diffusion Probabilistic Models》发表， 引入了DDPM模型。 作为领域的奠基之作，这篇论文第一次把2015年诞生的Diffusion&quot;扩散模型&quot;用在了图像生成上。\n用扩散模型生成图像的过程，简单理解，就是我们熟知的图片&quot;降噪&quot;：把一幅全部是噪点的随机图像通过AI算法反复&quot;降噪&quot;到最清晰，一个图像便生成了。\nDDPM的出现把Diffusion扩散模型带到了一个新的高度。在不久之后，DDPM以及后续的Diffusion扩散模型就全面取代了GAN（生成式对抗网络），成为了AI绘画大模型当仁不让的主流技术。\n2020年12月\n由于不再认同转型后的公司文化和战略，OpenAI的部分核心团队出走。\n12月31日，OpenAI发布新闻稿，宣布其研究副总裁Dario Amodei在OpenAI工作了近五年后离开了OpenAI。\nOpenAI正是5年前成立的，这位研究副总看来是妥妥的创始核心。\nDario Amodei带着一些OpenAI的早期核心员工随后创办了Anthropic，推出了ChatGPT的直接竞品Claude。\n被ChatGPT逼急了的Google最近刚给Anthropic紧急投资了3亿美金，以获得其10%的股份，并绑定了其云计算提供商的身份。\n这里说个小知识，加州没有竞业协议，真的是创业者的天堂!\n2021年1月\n1月11日，Google发表论文《Switch Transformers：Scaling to Trillion Parameter Models with Simple and Efficient Sparsity》，提出了最新语言模型—Switch Transformer。\n这个Switch Transformer 模型以高达1.6 万亿的参数量打破了GPT-3 作为最大AI 模型的统治地位，成为史上首个万亿级语言模型。然而，时间会证明一切。2年后的今天，这个万亿参数的Switch大模型在当下似乎没产生任何水花，而千亿参数级别的GPT-3.5系列依然风生水起。这是不是说明一个问题：突破千亿阈值后，参数多少并不代表一切。\n2021年2月\nOpen AI开源了新的深度学习模型 CLIP（Contrastive Language-Image Pre-Training）。\nCLIP是一个多模态模型，用来判断文字和图像两个不同&quot;模态&quot;信息的关联匹配程度。\n在CLIP之前，也有人尝试过这个方向，但OpenAI最大的创意是直接使用全互联网上已经标记过的图像数据，巧妙的避免了海量数据标注的昂贵费用。最后以接近40亿的互联网&quot;文本-图像&quot;训练数据打造了CLIP。\n这次重要的开源直接推动了各大AI绘画模型的迅猛发展。CLIP的多模态能力正是各AI绘画大模型从文字到画面想象力的核心基础。\n同时，OpenAI还发布了自己基于CLIP的 AI绘画DALL-E 模型。这或许是大众听说的第一个&quot;文本生成图像&quot;的AI绘画模型了。\n从CLIP到DALL-E，显然OpenAI走在了AI绘画大模型潮流的最前端。\n只是，OpenAI在AI绘画模型的商业决策上出现了失误：因为没有开放使用DALL-E以及后续DALL-E2，而又开源了关键的CLIP模型，导致目前AI绘画模型的光芒完全被其开源继承者Stable Diffusion，还有付费的Midjourney服务掩盖了。\n正是在AI绘画模型上有苦说不出的经历，直接影响了后来OpenAI管理层的决策：决定在第一时间面向公众抢先推出 ChatGPT聊天机器人。\n2021年4月\n华为的盘古NLP大模型发布，号称是中国第一个千亿参数语言大模型。\n2021年6月\n6 月30 日，OpenAI 和GitHub 联合发布了AI 代码补全工具GitHub Copilot，这个工具可以在 VS Code 编辑器中自动完成代码片段，也是OpenAI 拿了微软10 亿美元之后的第一个重大成果。而Copilot 的AI技术核心正是OpenAI的新模型CodeX。这个模型在随后的8月份也对外发布了。\n根据相关论文《Evaluating Large Language Models Trained on Code》，OpenAI基于GPT-3，使用大量公开代码数据训练出了Codex模型。\nCodex拥有120亿参数，使用了159G代码数据进行训练，模型可以将自然语言描述转换为代码。而效果吗，看看码农们对Copilot的赞不绝口就知道了。\nAI生成代码的时代终于到来了。\n据称，Codex的训练数据来自于公共数据源的数十亿行源代码，而其中最重要的来源，无疑正是微软所买下的GitHub 这个世界上最大的开源代码平台。使用GitHub代码训练模型这个事情还引起了一些程序员关于代码版权的热烈讨论。\n不过，正如画师们对砸了自己饭碗的AI绘画大模型怨声载道而然并卵。。。能力突破的AI对人类初级技能的全面覆盖，恐怕是一个不得不接受的事实。\n从商业角度上看，CodeX的诞生和Copilot的成功证明了OpenAI和微软的商业合作确实是一个双赢。\n2021年10月\n第一个开源的AI绘画大模型Disco-Diffusion诞生!\n发布在Github上的Disco-Diffusion是整个2022年AI绘画旋风的起点。从Disco-Diffusion开始，AI绘画大模型突飞猛进的发展让所有人目不暇接，揭开了AI的新时代。\n2021年12月\n百度第三代文心语言大模型，2600亿参数的ERNIE3.0 Titan发布。\n百度文心和华为盘古都是GPT-3量级的模型，关于国产大模型的具体判断，读者有兴趣可以参考本号国产ChatGPT们的真相&gt;一文\n2022 年3 月OpenAI发布InstructGPT， 同时发表论文《Training language models to follow instructions with human feedback》。\n根据论文，InstructGPT基于GPT-3模型做了进一步微调，并且在模型训练中加入了人类的反馈评价数据。\n这里出现的RLHF &quot;从人类反馈中强化学习&quot;，正是后面ChatGPT所依赖的一个关键技术。\n2022年4月\nOpenAI发布了AI绘画大模型DALL-E 2。\n同一时间，面向公众的付费AI绘画服务Midjourney也发布了。\n和开局王炸，第一年就赚取了大把真金白银的MidJourney相比，使用受限的DALL-E 2并没有在大众人群里产生多少影响力。\n如之前所说，OpenAI在绘画大模型的开放上过于保守了，也许还有优先和微软技术合作的考量在内...\n总之，非常遗憾，绘画模型的风头完全被付费的Midjourney和随后的Stable diffusion抢走。\n2022年5月\nOpenAI发布代号为text-davinci-002的新版大模型，GPT系列正式迈入3.5时代。\n有趣的是，按照OpenAI官方文档说法：\nis a base model，so good for pure code-completion tasks\nis an InstructGPT model based on\n就是说，代号为code的002号模型是3.5系列的基础模型，而代号为text的002号模型是基于code 002模型用指令微调技术得到的 （insturctGPT）\n如果，OpenAI没有在模型名字上混淆视听，一个有趣而合理的推断是：GPT-3.5系列的基础核心模型首先是依赖于代码（Code）大数据训练，而不是普通文本（Text）训练的\n如果这个推断差不太多，那么众多ChatGPT的追随者们，如希望自家能力真正比肩基于GPT-3.5的ChatGPT， 那必须要补的一课，就是代码数据的训练了。2022年6月\n6月15日，谷歌研究院联合DeepMind和斯坦福大学等在arxiv上发表了一篇论文：《Emergent Abilities of Large Language', 'doi': '', 'published_date': '2023-03-01T00:00:00+00:00', 'pdf_url': '', 'url': 'https://view.inews.qq.com/a/20230301A08BTW00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '万字长文解读AI发展史，看人工智能将如何改变下个时代_腾讯新闻', 'authors': [], 'abstract': '万字长文解读AI发展史，看人工智能将如何改变下个时代\\_腾讯新闻\n# 万字长文解读AI发展史，看人工智能将如何改变下个时代\n![头像]![] \n[\nINDIGO的数字镜像\n] \n2022-11-15 09:06发布于中国香港科技领域创作者\n就在过去几个月里，因为美联储的加息，科技公司的资本狂欢宣告结束，美国上市的SaaS 公司股价基本都跌去了70%，裁员与紧缩是必要选项。但正当市场一片哀嚎的时候，Dall-E 2 发布了，紧接着就是一大批炫酷的AI 公司登场。这些事件在风投界引发了一股风潮，我们看到那些兜售着基于生成式AI（Generative AI）产品的公司，估值达到了数十亿美元，虽然收入还不到百万美元，也没有经过验证的商业模式。不久前，同样的故事在 Web 3 上也发生过！感觉我们又将进入一个全新的繁荣时代，但人工智能这次真的能带动科技产业复苏么？划重点本文将带你领略一次人工智能领域波澜壮阔的发展史，从关键人物推动的学术进展、算法和理念的涌现、公司和产品的进步、还有脑科学对神经网络的迭代影响，这四个维度来深刻理解“机器之心的进化”。先忘掉那些花里胡哨的图片生产应用，我们一起来学点接近AI 本质的东西。文章较长，累计22800 字，请留出一小时左右的阅读时间，欢迎先收藏再阅读！文中每一个链接和引用都是有价值的，特别作为衍生阅读推荐给大家。阅读之前先插播一段Elon Musk 和Jack Ma 在WAIC 2019 关于人工智能的对谈的经典老视频，全程注意Elon Ma 的表情大家觉得机器智能能否超过人类么？带着这个问题来阅读，相信看完就会有系统性的答案！本文在无特别指明的情况下，为了书写简洁，在同一个段落中重复词汇大量出现时，会用AI（Artifical Intelligence）来代表 人工智能，用ML（Machine Learning）来代表机器学习，DL（Deep Learning）来代表深度学习，以及各种英文缩写来优先表达。\n01\nAI 进化史对于机器是否真能&quot;知道&quot;、&quot;思考 &quot;等问题，我们很难严谨地定义这些。我们对人类心理过程的理解，或许只比鱼对游泳的理解更好一点。\n- John McCarthy\n早在1945 年，Alan Turing 就已经在考虑如何用计算机来模拟人脑了。他设计了ACE（Automatic Computing Engine - 自动计算引擎）来模拟大脑工作。在给一位同事的信中写道：&quot;与计算的实际应用相比，我对制作大脑运作的模型可能更感兴趣 ...... 尽管大脑运作机制是通过轴突和树突的生长来计算的复杂神经元回路，但我们还是可以在ACE 中制作一个模型，允许这种可能性的存在，ACE 的实际构造并没有改变，它只是记住了数据......&quot; 这就是机器智能的起源，至少那时在英国都这样定义。1.1 前神经网络时代神经网络是以模仿人脑中的神经元的运作为模型的计算机系统。AI 是伴随着神经网络的发展而出现的。1956年，美国心理学家 Frank Rosenblatt 实现了一个早期的神经网络演示- 感知器模型（Perceptron Model），该网络通过监督 Learning的方法将简单的图像分类，如三角形和正方形。这是一台只有八个模拟神经元的计算机，这些神经元由马达和转盘制成，与 400 个光探测器连接。![图片] 配图01：Frank Rosenblatt &amp; Perceptron Model\nIBM 的Georgetown 实验室在这些研究的基础上，实现了最早的机器语言翻译系统，可以在英语和俄语之间互译。1956年的夏天，在 Dartmouth College 的一次会议上，AI被定义为计算机科学的一个研究领域，Marvin Minsky（明斯基）, John McCarthy（麦卡锡）, Claude Shannon（香农）, 还有Nathaniel Rochester（罗切斯特）组织了这次会议，他们后来被称为 AI 的&quot;奠基人&quot;。\n![图片] 配图02：Participants of the 1956 Dartmouth Summer Research Project on AI\nDARPA 在这个“黄金”时期，将大部分资金投入AI 领域，就在十年后他们还发明了ARPANET（互联网的前身）。早期的 AI 先驱们试图教计算机做模仿人类的复杂心理任务，他们将其分成五个子领域：推理、知识表述、规划、自然语言处理（NLP）和感知，这些听起来很笼统的术语一直沿用至今。\n从专家系统到机器学习1966年，Marvin Minsky 和Seymour Papert 在《感知器：计算几何学导论》一书中阐述了因为硬件的限制，只有几层的神经网络仅能执行最基本的计算，一下子浇灭了这条路线上研发的热情，AI 领域迎来了第一次泡沫破灭。这些先驱们怎么也没想到，计算机的速度能够在随后的几十年里指数级增长，提升了上亿倍。在上世纪八十年代，随着电脑性能的提升，新计算机语言Prolog &amp; Lisp 的流行，可以用复杂的程序结构，例如条件循环来实现逻辑，这时的人工智能就是专家系统（Expert System），iRobot 公司绝对是那个时代明星；但短暂的繁荣之后，硬件存储空间的限制，还有专家系统无法解决具体的、难以计算的逻辑问题，人工智能再一次陷入窘境。我怀疑任何非常类似于形式逻辑的东西能否成为人类推理的良好模型。- Marvin Minsky\n直到IBM 深蓝在1997年战胜了国际象棋冠军卡斯帕罗夫后，新的基于概率推论（Probabilistic Reasoning）思路开始被广泛应用在 AI 领域，随后IBM Watson 的项目使用这种方法在电视游戏节目《Jeopardy》中经常击败参赛的人类。\n概率推论就是典型的机器学习（Machine Learning）。今天的大多数 AI 系统都是由ML 驱动的，其中预测模型是根据历史数据训练的，并用于对未来的预测。这是AI 领域的第一次范式转变，算法不指定如何解决一个任务，而是根据数据来诱导它，动态地达成目标。因为有了ML，才有了大数据（Big Data）这个概念。\n1.2 Machine Learning 的跃迁Machine Learning 算法一般通过分析数据和推断模型来建立参数，或者通过与环境互动，获得反馈来学习。人类可以注释这些数据，也可以不注释，环境可以是模拟的，也可以是真实世界。Deep Learning\nDeep Learning 是一种Machine Learning算法，它使用多层神经网络和反向传播（Backpropagation）技术来训练神经网络。该领域是几乎是由 Geoffrey Hinton 开创的，早在1986年，Hinton 与他的同事一起发表了关于深度神经网络（DNNs - Deep Neural Networks）的开创性论文，这篇文章引入了反向传播的概念，这是一种调整权重的算法，每当你改变权重时，神经网络就会比以前更快接近正确的输出，可以轻松的实现多层的神经网络，突破了 1966 年Minsky 写的感知器局限的魔咒。![图片] 配图03：Geoffrey Hinton &amp; Deep Neural Networks\nDeep Learning 在2012 年才真正兴起，当时Hinton 和他在多伦多的两个学生表明，使用反向传播训练的深度神经网络在图像识别方面击败了最先进的系统，几乎将以前的错误率减半。由于他的工作和对该领域的贡献，Hinton 的名字几乎成为Deep Learning 的代名词。数据是新的石油Deep Learning 是一个革命性的领域，但为了让它按预期工作，需要数据。而最重要的数据集之一，就是由李飞飞创建的ImageNet。曾任斯坦福大学人工智能实验室主任，同时也是谷歌云 AI/ML 首席科学家的李飞飞，早在2009 年就看出数据对Machine Learning 算法的发展至关重要，同年在计算机视觉和模式识别（CVPR）上发表了相关论文。\n![图片] 配图04：FeiFei Li &amp; ImageNet\n该数据集对研究人员非常有用，正因为如此，它变得越来越有名，为最重要的年度DL 竞赛提供了基准。仅仅七年时间，ImageNet 让获胜算法对图像中的物体进行分类的准确率从72% 提高到了98%，超过了人类的平均能力。\nImageNet 成为DL 革命的首选数据集，更确切地说，是由Hinton 领导的AlexNet 卷积神经网络（CNN - Convolution Neural Networks）的数据集。ImageNet 不仅引领了DL 的革命，也为其他数据集开创了先例。自其创建以来，数十种新的数据集被引入，数据更丰富，分类更精确。神经网络大爆发在Deep Learning 理论和数据集的加持下，2012年以来深度神经网络算法开始大爆发，卷积神经网络（CNN）、递归神经网络（RNN - Recurrent Neural Network）和长短期记忆网络（LSTM - Long Short-Term Memory）等等，每一种都有不同的特性。例如，递归神经网络是较高层的神经元直接连接到较低层的神经元。\n来自日本的计算机研究员福岛邦彦（Kunihiko Fukushima）根据人脑中视觉的运作方式，创建了一个人工神经网络模型。该架构是基于人脑中两种类型的神经元细胞，称为简单细胞和复杂细胞。它们存在于初级视觉皮层中，是大脑中处理视觉信息的部分。简单细胞负责检测局部特征，如边缘；复杂细胞汇集了简单细胞在一个区域内产生的结果。例如，一个简单细胞可能检测到一个椅子的边缘，复杂细胞汇总信息产生结果，通知下一个更高层次的简单细胞，这样逐级识别得到完整结果。\n![图片] 配图05：深度神经网络如何识别物体（TensorFlow）\nCNN 的结构是基于这两类细胞的级联模型，主要用于模式识别任务。它在计算上比大多数其他架构更有效、更快速，在许多应用中，包括自然语言处理和图像识别，已经被用来击败大多数其他算法。我们每次对大脑的工作机制的认知多一点，神经网络的算法和模型也会前进一步！1.3 开启潘多拉的魔盒从2012 到现在，深度神经网络的使用呈爆炸式增长，进展惊人。现在Machine Learning 领域的大部分研究都集中在Deep Learning 方面，就像进入了潘多拉的魔盒被开启了的时代。![图片] 配图06：AI 进化史GAN\n生成对抗网络（GAN - Generative Adversarial Network） 是Deep Learning 领域里面另一个重要的里程碑，诞生于2014 年，它可以帮助神经网络用更少的数据进行学习，生成更多的合成图像，然后用来识别和创建更好的神经网络。GANs 的创造者Ian Goodfellow 是在蒙特利尔的一个酒吧里想出这个主意的，它由两个神经网络玩着猫捉老鼠的游戏，一个创造出看起来像真实图像的假图像，而另一个则决定它们是否是真的。![图片] 配图07：GANs 模拟生产人像的进化GANs 将有助于创建图像，还可以创建现实世界的软件模拟，Nvidia 就大量采用这种技术来增强他的现实模拟系统，开发人员可以在那里训练和测试其他类型的软件。你可以用一个神经网络来“压缩”图像，另一个神经网络来生成原始视频或图像，而不是直接压缩数据，Demis Hassabis 在他的一篇论文中就提到了人类大脑“海马体”的记忆回放也是类似的机制。大规模神经网络大脑的工作方式肯定不是靠某人用规则来编程。- Geoffrey Hinton\n大规模神经网络的竞赛从成立于2011 年的Google Brain 开始，现在属于Google Research。他们推动了 TensorFlow 语言的开发，提出了万能模型Transformer 的技术方案并在其基础上开发了BERT，我们在第四章中将详细讨论这些。\nDeepMind 是这个时代的传奇之一，在2014年被 Google 以5.25 亿美元收购的。它专注游戏算法，其使命是&quot;解决智能问题&quot;，然后用这种智能来 &quot;解决其他一切问题&quot;！DeepMind 的团队开发了一种新的算法Deep Q-Network (DQN)，它可以从经验中学习。2015 年10 月AlphaGo 项目首次在围棋中击败人类冠军李世石；之后的AlphaGo Zero 用新的可以自我博弈的改进算法让人类在围棋领域再也无法翻盘。另一个传奇OpenAI，它是一个由Elon Musk, Sam Altman, Peter Thiel, 还有Reid Hoffman 在2015年共同出资十亿美金创立的科研机构，其主要的竞争对手就是 DeepMind。OpenAI 的使命是通用人工智能（AGI –Artificial General Intelligence），即一种高度自主且在大多数具有经济价值的工作上超越人类的系统。2020年推出的 GPT-3 是目前最好的自然语言生成工具（NLP - Natural Language Processing）之一，通过它的 API 可以实现自然语言同步翻译、对话、撰写文案，甚至是代码（Codex），以及现在最流行的生成图像（DALL·E）。\nGartner AI HypeCycle\nGartner 的技术炒作周期（HypeCycle）很值得一看，这是他们 2022 年最新的关于AI 领域下各个技术发展的成熟度预估，可以快速了解AI 进化史这一章中不同技术的发展阶段。![图片] 配图08：Gartner AI HypeCycle 2022\n神经网络，这个在上世纪60 年代碰到的挫折，然后在2012 年之后却迎来了新生。反向传播花了这么长时间才被开发出来的原因之一就是该功能需要计算机进行乘法矩阵运算。在上世纪70 年代末，世界上最强的的超级电脑之一Cray-1，每秒浮点运算速度 50 MFLOP，现在衡量 GPU 算力的单位是TFLOP（Trillion FLOPs），Nvidia 用于数据中心的最新GPU Nvidia Volta 的性能可以达到125 TFLOP，单枚芯片的速度就比五十年前世界上最快的电脑强大 250 万倍。技术的进步是多维度的，一些生不逢时的理论或者方法，在另一些技术条件达成时，就能融合出巨大的能量。02\n软件2.0 的崛起未来的计算机语言将更多得关注目标，而不是由程序员来考虑实现的过程。- Marvin Minsky\nSoftware 2.0 概念的最早提出人是Andrej Karpathy，这位从小随家庭从捷克移民来加拿大的天才少年在多伦多大学师从 Geoffrey Hinton，然后在斯坦福李飞飞团队获得博士学位，主要研究 NLP 和计算机视觉，同时作为创始团队成员加入了OpenAI，Deep Learning 的关键人物和历史节点都被他点亮。在2017 年被Elon Musk 挖墙脚到了Tesla 负责自动驾驶研发，然后就有了重构的FSD（Full Self-Driving）。\n按照Andrej Karpathy 的定义- “软件2.0 使用更抽象、对人类不友好的语言生成，比如神经网络的权重。没人参与编写这些代码，一个典型的神经网络可能有数百万个权重，用权重直接编码比较困难”。Andrej 说他以前试过，这几乎不是人类能干的事儿。。![图片] 配图09：Andrej Karpathy 和神经网络权重2.1 范式转移在创建深度神经网络时，程序员只写几行代码，让神经网络自己学习，计算权重，形成网络连接，而不是手写代码。这种软件开发的新范式始于第一个Machine Learning 语言TensorFlow，我们也把这种新的编码方式被称为软件 2.0。在 Deep Learning 兴起之前，大多数人工智能程序是用Python 和JavaScript 等编程语言手写的。人类编写了每一行代码，也决定了程序的所有规则。![图片] 配图10：How does Machine Learning work？（TensorFlow）\n相比之下，随着Deep Learning 技术的出现，程序员利用这些新方式，给程序指定目标。如赢得围棋比赛，或通过提供适当输入和输出的数据，如向算法提供具有&quot;SPAM” 特征的邮件和其他没有&quot;SPAM” 特征的邮件。编写一个粗略的代码骨架（一个神经网络架构），确定一个程序空间的可搜索子集，并使用我们所能提供的算力在这个空间中搜索，形成一个有效的程序路径。在神经网络里，我们一步步地限制搜索范围到连续的子集上，搜索过程通过反向传播和随机梯度下降（Stochastic Gradient Descent）而变得十分高效。\n神经网络不仅仅是另一个分类器，它代表着我们开发软件的范式开始转移，它是软件2.0。\n软件1.0 人们编写代码，编译后生成可以执行的二进制文件；但在软件2.0 中人们提供数据和神经网络框架，通过训练将数据编译成二进制的神经网络。在当今大多数实际应用中，神经网络结构和训练系统日益标准化为一种商品，因此大多数软件2.0 的开发都由模型设计实施和数据清理标记两部分组成。这从根本上改变了我们在软件开发迭代上的范式，团队也会因此分成了两个部分:2.0 程序员负责模型和数据，而那些1.0 程序员则负责维护和迭代运转模型和数据的基础设施、分析工具以及可视化界面。Marc Andreessen 的经典文章标题《Why Software Is Eating the World》现在可以改成这样：“软件（1.0）正在吞噬世界，而现在人工智能（2.0）正在吞噬软件！\n2.2 软件的演化软件从1.0 发展到软件2.0，经过了一个叫做“数据产品”的中间态。当顶级软件公司在了解大数据的商业潜力后，并开始使用 Machine Learning 构建数据产品时，这种状态就出现了。下图来自Ahmad Mustapha 的一篇文章《The Rise of Software 2.0》很好地呈现了这个过渡。\n![图片] 配图11：软件产品演化的三种状态\n这个中间态也叫大数据和算法推荐。在现实生活中，这样的产品可以是Amazon 的商品推荐，它们可以预测客户会感兴趣什么，可以是Facebook 好友推荐，还可以是Netflix 电影推荐或Tiktok 的短视频推荐。还有呢？Waze 的路由算法、Airbnb 背后的排名算法等等，总之琳琅满目。数据产品有几个重要特点：1、它们都不是软件的主要功能，通常是为了增加体验，达成更好的用户活跃以及销售目标；2、能够随着数据的增加而进化；3、大部分都是基于传统 ML 实现的，最重要的一点数据产品是可解释的。但有些行业正在改变，Machine Learning 是主体。当我们放弃通过编写明确的代码来解决复杂问题时，这个到2.0 技术栈的转变就发生了，在过去几年中，很多领域都在突飞猛进。语音识别曾经涉及大量的预处理、高斯混合模型和隐式Markov 模型，但今天几乎完全被神经网络替代了。早在1985 年，知名信息论和语言识别专家Fred Jelinek 就有一句经常被引用的段子：“每当我解雇一个语言学家，我们的语音识别系统的性能就会得到提高”。![图片] 配图12：图解软件 2.0 的代表应用除了大家熟悉的图像语音识别、语音合成、机器翻译、游戏挑战之外，AI 在很多传统系统也看到了早期的转型迹象。例如The Case for Learned Index Structures 用神经网络取代了数据管理系统的核心组件，在速度上比B-Trees 缓存优化快70%，同时节省了一个数量级的内存。\n所以，软件2.0 的范式具备了这几个新特征：1、Deep Learning 是主体，所有的功能都是围绕神经网络的输入输出构建的，例如语音识别、自动驾驶；2、可解释性并不重要，一个好的大数据推荐广告可以告诉客户用户看到这条广告的理由，但你没法从神经网络中找到规则，至少目前不行；3、高研发投入与低开发投入，现在大量的成功都来自大学和科技公司的研究部门，论文绝对比应用多。。\n2.3 软件2.0 的优势为什么我们应该倾向于将复杂的程序移植到软件2.0 中？Andrej Karpathy 在《Software 2.0》中给出了一个简单的答案：它们在实践中表现得更好！\n容易被写入芯片由于神经网络的指令集相对较小，主要是矩阵乘法（Matrix Multiplication）和阈值判断（Thresholding at Zero），因此把它们写入芯片要容易得多，例如使用定制的 ASIC、神经形态芯片等等（Alan Turing 在设计ACE 时就这样考虑了）。例如，小而廉价的芯片可以带有一个预先训练好的卷积网络，它们可以识别语音、合成音频、处理视觉信号。当我们周围充斥着低能耗的智能时，世界将会因此而大不同（好坏皆可）。非常敏捷敏捷开发意味着灵活高效。如果你有一段C++ 代码，有人希望你把它的速度提高一倍，那么你需要系统性地调优甚至是重写。然而，在软件2.0 中，我们在网络中删除一半的通道，重新训练，然后就可以了。。它的运行速度正好提升两倍，只是输出更差一些，这就像魔法。相反，如果你有更多的数据或算力，通过添加更多的通道和再次训练，你的程序就能工作得更好。模块可以融合成一个最佳的整体做过软件开发的同学都知道，程序模块通常利用公共函数、API 或远程调用来通讯。然而，如果让两个原本分开训练的软件2.0 模块进行互动，我们可以很容易地通过整体进行反向传播来实现。想象一下，如果你的浏览器能够自动整合改进低层次的系统指令，来提升网页加载效率，这将是一件令人惊奇的事情。但在软件2.0 中，这是默认行为。它做得比你好最后，也是最重要的一点，神经网络比你能想到的任何有价值的垂直领域的代码都要好，目前至少在图像、视频、声音、语音相关的任何东西上，比你写的代码要好。2.4 Bug 2.0\n对于传统软件，即软件1.0，大多数程序都通过源代码保存，这些代码可能少至数千行，多至上亿行。据说，谷歌的整个代码库大约有 20 亿行代码。无论代码有多少，传统的软件工程实践表明，使用封装和模块化设计，有助于创建可维护的代码，很容易隔离Bug 来进行修改。但在新的范式中，程序被存储在内存中，作为神经网络架构的权重，程序员编写的代码很少。软件2.0 带来了两个新问题：不可解释和数据污染。因为训练完成的神经网络权重，工程师无法理解（不过现在对理解神经网络的研究有了很多进展，第六章会讲到），所以我们无法知道正确的执行是为什么？错误又是因为什么？这个和大数据算法有很大的不同，虽然大多数的应用只关心结果，无需解释；但对于一些安全敏感的领域，比如自动驾驶和医疗应用，这确实很重要。在2.0 的堆栈中，数据决定了神经网络的连接，所以不正确的数据集和标签，都会混淆神经网络。错误的数据可能来自失误、也可能是人为设计，或者是有针对性地投喂混淆数据（这也是人工智能领域中新的程序道德规范问题）。例如iOS 系统的自动拼写功能被意外的数据训练污染了，我们在输入某些字符的时候就永远得不到正确的结果。训练模型会认为污染数据是一个重要的修正，一旦完成训练部署，这个错误就像病毒一样传播，到达了数百万部iPhone 手机。所以在这种2.0 版的Bug 中，需要对数据以及程序结果进行良好的测试，确保这些边缘案例不会使程序失败。在短期内，软件2.0 将变得越来越普遍，那些没法通过清晰算法和软件逻辑化表述的问题，都会转入2.0 的新范式，现实世界并不适合整齐地封装。', 'doi': '', 'published_date': '2022-11-15T09:06:40+00:00', 'pdf_url': '', 'url': 'https://news.qq.com/rain/a/20221112A04S4N00', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}, {'paper_id': '', 'title': '人工智能发展简史 - 中央网信办', 'authors': [], 'abstract': '人工智能发展简史\\_中央网络安全和信息化委员会办公室\n[设为首页] [加入收藏] [手机版] [繁体] \n* ![] \n* ![] \n**[搜索] \n* ### [**首 页] \n* ### [**时政要闻] \n* ### [**网信政务] \n* ### [**互动服务] \n* ### [**热点专题] \n当前位置：[首页] &gt;[正文] \n* ![] \n* ![] \n* [首页] \n* [时政要闻] \n* [网信政务] \n* [互动服务] \n* [热点专题] \n![]![] \n![] \n![] \n# 人工智能发展简史2017年01月23日 11:10来源：\n网络传播杂志[] [] \n[] [] \n[【打印】] 【纠错】\n![] \n“人工智能之父”艾伦·图灵。**1、 人工智能的诞生（20世纪40～50年代）**\n1950年：图灵测试\n1950年，著名的图灵测试诞生，按照“人工智能之父”艾伦·图灵的定义：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。同一年，图灵还预言会创造出具有真正智能的机器的可能性。\n1954年：第一台可编程机器人诞生\n1954年美国人乔治·戴沃尔设计了世界上第一台可编程机器人。\n1956年：人工智能诞生\n1956年夏天，美国达特茅斯学院举行了历史上第一次人工智能研讨会，被认为是人工智能诞生的标志。会上，麦卡锡首次提出了“人工智能”这个概念，纽厄尔和西蒙则展示了编写的逻辑理论机器。\n**2、 人工智能的黄金时代（20世纪50～70年代）**\n1966年\\~1972年：首台人工智能机器人Shakey诞生\n1966年\\~1972年期间，美国斯坦福国际研究所研制出机器人Shakey，这是首台采用人工智能的移动机器人。\n1966年：世界上第一个聊天机器人ELIZA发布\n美国麻省理工学院（MIT）的魏泽鲍姆发布了世界上第一个聊天机器人ELIZA。ELIZA的智能之处在于她能通过脚本理解简单的自然语言，并能产生类似人类的互动。\n1968年：计算机鼠标发明\n1968年12月9日，美国加州斯坦福研究所的道格·恩格勒巴特发明计算机鼠标，构想出了超文本链接概念，它在几十年后成了现代互联网的根基。\n**3、 人工智能的低谷（20世纪70～80年代）**\n20世纪70年代初，人工智能遭遇了瓶颈。当时的计算机有限的内存和处理速度不足以解决任何实际的人工智能问题。要求程序对这个世界具有儿童水平的认识，研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。由于缺乏进展，对人工智能提供资助的机构（如英国政府、美国国防部高级研究计划局和美国国家科学委员会）对无方向的人工智能研究逐渐停止了资助。美国国家科学委员会（NRC）在拨款二千万美元后停止资助。\n![] \n1997年5月10日，IBM“深蓝”超级计算机再度挑战卡斯帕罗夫，比赛在5月11日结束，最终“深蓝”以3.5:2.5击败卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。供图/CFP\n**4、 人工智能的繁荣期（1980年\\~1987年）**\n1981年：日本研发人工智能计算机\n1981年，日本经济产业省拨款8.5亿美元用以研发第五代计算机项目，在当时被叫做人工智能计算机。随后，英国、美国纷纷响应，开始向信息技术领域的研究提供大量资金。\n1984年：启动Cyc（大百科全书）项目\n在美国人道格拉斯·莱纳特的带领下，启动了Cyc项目，其目标是使人工智能的应用能够以类似人类推理的方式工作。\n1986年：3D打印机问世\n美国发明家查尔斯·赫尔制造出人类历史上首个3D打印机。\n**5、 人工智能的冬天（1987年\\~1993年）**\n“AI（人工智能）之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中，专家系统的实用性仅仅局限于某些特定情景。到了上世纪80年代晚期，美国国防部高级研究计划局（DARPA）的新任领导认为人工智能并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n**6、 人工智能真正的春天（1993年至今）**\n1997年：电脑深蓝战胜国际象棋世界冠军\n1997年5月11日，IBM公司的电脑“深蓝”战胜国际象棋世界冠军卡斯帕罗夫，成为首个在标准比赛时限内击败国际象棋世界冠军的电脑系统。\n2011年：开发出使用自然语言回答问题的人工智能程序\n2011年，Watson（沃森）作为IBM公司开发的使用自然语言回答问题的人工智能程序参加美国智力问答节目，打败两位人类冠军，赢得了100万美元的奖金。\n2012年：Spaun诞生\n加拿大神经学家团队创造了一个具备简单认知能力、有250万个模拟“神经元”的虚拟大脑，命名为“Spaun”，并通过了最基本的智商测试。\n2013年：深度学习算法被广泛运用在产品开发中\nFacebook人工智能实验室成立，探索深度学习领域，借此为Facebook用户提供更智能化的产品体验；Google收购了语音和图像识别公司DNNResearch，推广深度学习平台；百度创立了深度学习研究院等。\n2015年：人工智能突破之年\nGoogle开源了利用大量数据直接就能训练计算机来完成任务的第二代机器学习平台Tensor Flow；剑桥大学建立人工智能研究所等。\n2016年：AlphaGo战胜围棋世界冠军李世石\n2016年3月15日，Google人工智能AlphaGo与围棋世界冠军李世石的人机大战最后一场落下了帷幕。人机大战第五场经过长达5个小时的搏杀，最终李世石与AlphaGo总比分定格在1比4，以李世石认输结束。这一次的人机对弈让人工智能正式被世人所熟知，整个人工智能市场也像是被引燃了导火线，开始了新一轮爆发。（整理 / 本刊编辑部）![] \n2016年3月9日，韩国，李世石人机围棋大战引广泛关注，韩国民众纷纷观战电视直播。供图/CFP\n**大事记**\n①1942年：“机器人三定律”提出\n美国科幻巨匠阿西莫夫提出“机器人三定律”，后来成为学术界默认的研发原则。②1956年：人工智能的诞生\n达特茅斯会议上，科学家们探讨用机器模拟人类智能等问题，并首次提出了人工智能（AI）的术语，AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者。\n③1959年：第一代机器人出现\n德沃尔与美国发明家约瑟夫·英格伯格联手制造出第一台工业机器人。随后，成立了世界上第一家机器人制造工厂——Unimation公司。\n④1965年：兴起研究“有感觉”的机器人\n约翰·霍普金斯大学应用物理实验室研制出Beast机器人。Beast已经能通过声纳系统、光电管等装置，根据环境校正自己的位置。\n⑤1968年：世界第一台智能机器人诞生\n美国斯坦福研究所公布他们研发成功的机器人Shakey。它带有视觉传感器，能根据人的指令发现并抓取积木，不过控制它的计算机有一个房间那么大，可以算是世界第一台智能机器人。\n⑥2002年：家用机器人诞生\n美国iRobot公司推出了吸尘器机器人Roomba，它能避开障碍，自动设计行进路线，还能在电量不足时，自动驶向充电座。Roomba是目前世界上销量较大的家用机器人。\n⑦2014年：机器人首次通过图灵测试\n在英国皇家学会举行的“2014图灵测试”大会上，聊天程序“尤金·古斯特曼”（Eugene Goostman）首次通过了图灵测试，预示着人工智能进入全新时代。\n⑧2016年：AlphaGo打败人类\n2016年3月，AlphaGo对战世界围棋冠军、职业九段选手李世石，并以4:1的总比分获胜 。这并不是机器人首次打败人类事件。关闭中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有[联系我们] \n承办：国家互联网应急中心\u3000技术支持：长安通信科技有限责任公司[京ICP备14042428号] [**京公网安备11040102700108号] \n[![党政机关标识]] \n* ###### 学习强国*◆*◆\n![] \n* ###### 微信*◆*◆\n![] \n* ###### 返回顶部中央网络安全和信息化委员会办公室中华人民共和国国家互联网信息办公室&copy; 版权所有承办：国家互联网应急中心技术支持：长安通信科技有限责任公司京ICP备14042428号\n[京公网安备11040102700108号] \n![] [![] PC版] \nProduced By CMS 网站群内容管理系统publishdate:2024/01/05 22:26:29', 'doi': '', 'published_date': '2017-01-23T00:00:00+00:00', 'pdf_url': '', 'url': 'https://www.cac.gov.cn/2017-01/23/c_1120366748.htm', 'source': 'exa_context', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:35:42,913 - __main__ - INFO - handle_download: searcher=ExaSearcherContext, input_papers=10, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:35:42,931 - __main__ - INFO - call_tool: name=wikipedia_download, args={'papers': [{'paper_id': '317', 'title': '人工智能', 'authors': ['Wikipedia'], 'abstract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'doi': '', 'published_date': '2026-02-02T20:35:17.332875', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '人工智能（英語：artificial intelligence，缩写为AI），是指计算机系统执行通常与人类智慧相关的任务的能力，例如学习、推理、解决问题、感知和决策。它是计算机科学的一个研究领域，致力于开发和研究使机器能够感知其环境并利用学习和智能采取行动以最大限度地提高其实现既定目标的可能性的方法和软件。\n\n\n详细定义\n通常人工智能是指用普通電腦程式來呈現人類智能的技術。該詞也指出研究這樣的智能系統是否能夠實現，以及如何實現。同时，隨著醫學、神經科學、机器人学及統計學等方面的發展，普遍認為人類的部分職業也逐漸被其取代。\n人工智能於一般教材中的定义领域是“智慧主体的研究与设计”，智慧主体指一个可以观察周遭环境并作出行动以达致目标的系统。约翰·麦卡锡于1955年對人工智能的定义是「制造智能机器的科学与工程」。安德烈亚斯·卡普兰和迈克尔·海恩莱因（Michael Haenlein）将人工智能定义为“系统正确解释外部数据，从这些数据中学习，并利用这些知识通过灵活适应实现特定目标和任务的能力”。人工智能可以定義為模仿人類與人類思維相關的認知功能的機器或計算機，如學習和解決問題。人工智能是計算機科學的一個分支，它感知其環境並採取行動，最大限度地提高其成功機會。此外，人工智能能夠從過去的經驗中學習，做出合理的決策，並快速回應。因此，人工智能研究人員的科學目標是通過構建具有象徵意義的推理或推理的計算機程式來理解智慧。在計算基礎設施之外，人工智能的主要基础组成部分是：\n\n学习（包括机器学习、深度学习、强化学习等子领域）\n知识表示、推理与决策\n问题解决——包括使用泛型或特设的方法,以有序的方式,寻找问题解决方案\n感知（例如计算机视觉）\n自然语言处理（NLP）\n生成能力：生成模型与生成式人工智能\n人工智能的研究是高度技术性和专业的，各分支领域都是深入且各不相通的，因而涉及範圍極廣。人工智能的研究可以分为几个技术问题。其分支领域主要集中在解决具体问题，其中之一是，如何使用各种不同的工具完成特定的应用程序。\nAI的核心问题包括建構能夠跟人類相似，甚至超卓的推理、知识、計划、学习、交流、感知、移動 、移物、使用工具和操控机械的能力等。通用人工智能（AGI）目前仍然是该领域的长远目标。目前弱人工智慧已經有初步成果，甚至在一些影像辨識、語言分析、棋類遊戲等等單方面的能力達到了超越人類的水平，而且人工智慧的通用性代表著，能解決上述的問題的是一樣的AI程式，無須重新開發算法就可以直接使用現有的AI完成任務，與人類的處理能力相同，但達到具備思考能力的統合強人工智慧還需要時間研究，比较流行的方法包括统计方法，计算智能和传统意义的AI。目前有大量的工具应用了人工智能，其中包括搜索和数学优化、逻辑推演。而基於仿生學、認知心理學，以及基于概率论和经济学的演算法等等也在逐步探索當中。\n\n\n概論\n\n人工智能的定義可以分為兩部分，即「人工」和「智能」。「人工」即由人设计，为人创造、制造。\n關於甚麼是「智能」，较有争议性。這涉及到其它諸如意識、自我、心靈，包括無意識的精神等等問題。人唯一瞭解的智能是人本身的智能，這是普遍認同的觀點。但是目前，人類對人類自身智能，與對構成人所擁有智能的必要元素的瞭解都十分有限，因此很難準確定義甚麼是「人工」製造的「智能」。因此人工智能的研究往往涉及對人智能本身的研究。其它關於動物或其它人造系統的智能也普遍被認為是人工智能相關的研究課題。\n人工智慧目前在電腦領域內，得到了愈加廣泛的发挥。並在機器人、經濟政治決策、控制系統、仿真系統中得到應用。\n人工智能也廣泛應用於許多不同領域。機器人經營餐館和商店並修復城市基礎設施。人工智能管理運輸系統和自動駕駛車輛。智能平台管理多個城市領域，例如垃圾收集和空氣質量監測。事實上，城市人工智能體現在城市空間、基礎設施和技術中，將我們的城市變成了無人監督的自治實體。可以方便地實時實現數字化支持的智能響應服務。許多城市現在主動利用大數據和人工智能，通過為我們的基礎設施提供更好的能源、計算能力和連接性來提高經濟回報。\n最近，由於人工智能減少了行政成本和時間，許多政府開始將人工智能用於各種公共服務。例如，移民流程的機器人自動化減少了處理時間並提高了效率。人工智能為地方政府服務帶來技術突破。人工智能代理協助城市規劃者基於目標導向的蒙特卡羅樹搜索進行場景規劃。目標推理人工智能代理提供最佳的土地利用解決方案，幫助人類制定民主的城市土地利用規劃。人工智能利用在線數據來監控和修改環境威脅政策。在2019 年水危機期間，潛在狄利克雷分配方法確定了Twitter (X) 中討論最多的主題，這是一種樸素的推文分類方法，對乾旱的影響和原因、政府響應和潛在解決方案等主題進行了分類。人工智能工具與司法部門的人類法官相輔相成，提供客觀、一致的風險評估。\n\n\n發展史\n\n对机器或“形式”的推理研究起源于古代哲学家和数学家。逻辑学的研究直接催生了艾伦·图灵的计算理论，理论提出，一台通过操作简单符号“0”和“1”的机器，能够模拟任意复杂的数学推理过程。这一理论，连同在控制论、信息论及神经生物学方面的同期发现，推动研究人员考虑构建一台“电子大脑”的可能性。 此外，他们还开拓了未来成为人工智能领域一部分的多个研究分支，比如1943年沃伦·麦卡洛克与沃尔特·皮茨设计的“人工神经元”，以及图灵于1950年发表的具有深远影响的论文《计算机器与智能》，其中提出了“图灵测试”，展示了“机器智能”的可行性。\n人工智能研究领域正式成立于1956年在达特茅斯学院举行的“达特茅斯会议”。\n与会者后来在20世纪60年代成为该领域的先驱者。 他们及其学生研发出的程序被媒体誉为“令人惊叹”： 计算机不仅能学会国际跳棋策略，还能解决代数文字难题、证明逻辑定理，甚至能进行英语对话。在20世纪50年代末至60年代初，许多英国和美国的大学纷纷建立了人工智能实验室。\n20世纪60年代至70年代，研究人员坚信他们的方法最终能够成功创造出具有通用智能的机器，并将此视为他们研究领域的最高目标。赫伯特·西蒙（Herbert Simon）曾预言：“在未来二十年内，机器能够胜任所有人类能够完成的工作。”马文·明斯基（Marvin Minsky）对此表示赞同，他认为：“在一代人的时间内，‘人工智能’这一难题将会得到实质性的解决。”但事实证明他们低估了这个问题所涉及的复杂性。1974年，受到詹姆斯·莱特希尔爵士（Sir James Lighthill）的批评以及美国国会倾向于资助更为有成效项目的趋势，美国和英国政府都中断了探索性研究。明斯基和西摩·佩珀特（Seymour Papert）在其著作《感知器》（Perceptrons）中提出的观点，被误认为已经证明人工神经网络在解决现实世界问题上毫无用处，从而完全否定了这种方法。随后出现了 “人工智能寒冬”，即人工智能项目难以获得资助的时期。\n20世纪80年代初期，人工智能研究因专家系统的商业成功而再次活跃，一种人工智能程序，旨在模拟人类专家的知识和分析技巧。到了1985年，AI市场估值超过10亿美元。与此同时，日本的第五代计算机项目推动英美两国恢复学术研究的资助。但从1987年Lisp机器市场的衰退开始，人工智能再次发展挫折，第二个较长的低迷期开始了。\n在此之前，人工智能的主要资金用于高级符号项目，用以表征如计划、目标、信念等概念性对象。20世纪80年代，一些研究人员开始怀疑，这种方法能否模仿人类认知的所有过程，特别是感知、机器人、学习和模式识别，并开始研究“次符号”方法。罗德尼·布鲁克斯（Rodney Brooks）普遍不认同“表征”这一概念，并将研究重心转向了设计能够移动和自持生存的机器工程。 朱迪亚·珀尔、卢特菲·泽德等学者发展了多种方法，这些方法基于合理推断处理不完备或不确定的信息，而非依赖于严格的逻辑。但最显著的进展是，杰弗里·辛顿与其他研究者协力，在“联结主义”及其涉及的神经网络研究方面，取得了重要突破。1990年，杨立昆（Yann Le Cun）展示了卷积神经网络能够识别手写数字，这项突破性的研究为神经网络在多个实际应用领域的应用奠定了基础。\n20世纪末至21世纪初期，人工智能利用形式化的数学方法，结合针对特定问题制定的策略，逐步在学术界重建了声誉。这种“聚焦”与“规范化”的研究方法让研究者能产出可验证的成果，并促进了与统计学、经济学及数学等其他学科的交叉合作。至2000年，人工智能领域研究的解决方案获得了广泛的应用，尽管在1990年代，这些方案往往不被直接标识为“人工智能”。当前，部分人工智能领域的学者提出观点，关注研究重点可能未全面覆盖创造具备多功能性和全面智能的机器这一初始目标。2002至2010年间，通用人工智能（AGI）领域内成立了多个获得充分资金支持的研究机构。\n2012年以来，深度学习开始主导行业标准，并迅速成为该领域内广泛采用的方法。在多种场合，替代性方法被淘汰，深度学习得到优先采用。深度学习的突破性成果，既得力于硬件的显著进步（如计算速度更快的电脑、图形处理单元以及云计算技术），也依赖于广泛的数据可用性（包括精心策划的数据集，譬如ImageNet）。深度学习的成果引发了公众对于人工智能的浓厚兴趣并促使资金投入的大幅度增加。2015年至2019年期间，机器学习领域的出版物数目上升了50%。\n2016年，在机器学习会议上，公平性与技术滥用成为突出话题；相关论文发表数量急剧增加，研究经费随之提供，众多研究人员转而聚焦这些议题。对齐问题逐渐成为学术探讨的重要议题。\n2010年代末至2020年代初，AGI公司推出引发广泛关注的程序。2015年，由Google DeepMind研发的“阿尔法狗”战胜了世界围棋冠军。该程序仅被输入了游戏规则并自主形成了策略。GPT-3是OpenAI在2020年推出的一款强大的语言模型，它能生成高质量、类人的文本。这些及其他程序引发了剧烈的AI热潮，主要企业投入数十亿美元于AI研究。AI Impacts预测，到2022年，仅在美国，人工智能领域的年投资就将达到约500亿美元，大约20%的美国新晋计算机科学博士生将专注于AI领域。在2022年，美国预计将有大约80万的人工智能相关职位空缺。\n進入2023年，OpenAI推出了GPT-4，其多模態能力和推理性能顯著提升，能處理文本和圖像輸入，並在複雜問題解決方面展現出更強大的能力。隔年(2024年)，OpenAI進一步發布GPT-4o，這款模型能夠處理文本、圖像等多種數據類型，並以更自然的對話能力獲得廣泛應用。\n截至2024年，AI技術的應用範圍進一步擴大。例如，Anthropic的Claude模型因其安全性和可解釋性受到關注，被廣泛用於企業應用。與此同時，xAI於2023年推出Grok，旨在加速人類科學發現，特別是在太空探索和物理學領域。根據市場研究，至2024年，全球AI市場規模已達到約1640億美元，並預計以年複合增長率（CAGR）36.6%持續增長。\n2025年，中小型AI模型開始崛起，這些模型以更低的計算需求提供高效性能，受到廣泛關注。DeepSeek於2024年12月24日推出了DeepSeek V3，這是一款通用大型語言模型（LLM），並於2025年1月發布DeepSeek R1，專注於複雜邏輯任務的推理模型，兩者均提供開源權重和訓練方法。DeepSeek R1擁有6710億(610B)個參數，被認為在推理能力上與OpenAI的o1模型相當，並因其高效的訓練方法引发了全球AI競爭的熱潮。2025年3月6日，Alibaba Group發布了QwQ-32B，一款320億(32B)參數的開源推理模型，據稱其性能可媲美DeepSeek R1，並在數學、編碼和一般問題解決等基準測試中超越OpenAI的o1-mini，且計算需求顯著降低。QwQ-32B的發布使阿里巴巴香港上市股票在2025年3月6日上漲超過8%，反映市場對中小型高效模型的看好。\n\n\n研究課題\n目前人工智慧的研究方向已經被分成幾個子領域，研究人員希望一個人工智慧系統應該具有某些特定能力，以下將這些能力列出並說明。\n\n\n演绎、推理和解决问题\n早期的人工智慧研究人员直接模仿人类进行逐步的推理，就像是玩棋盘游戏或进行逻辑推理时人类的思考模式。到了1980和1990年代，利用概率和经济学上的概念，人工智慧研究还发展了非常成功的方法处理不确定或不完整的资讯。\n对于困难的问题，有可能需要大量的运算资源，也就是发生了「可能组合爆增」：当问题超过一定的规模时，电脑会需要天文数量级的存储器或是运算时间。寻找更有效的演算法是优先的人工智慧研究项目。\n人类解决问题的模式通常是用最快捷、直观的判断，而不是有意识的、一步一步的推导，早期人工智慧研究通常使用逐步推导的方式。人工智慧研究已经于这种「次表征性的」解决问题方法取得进展：实体化Agent研究强调感知运动的重要性。神经网络研究试图以模拟人类和动物的大脑结构重现这种技能。\n\n\n知識表示法\n\n知识表示是人工智能领域的核心研究问题之一，它的目标是让机器存储相应的知识，并且能够按照某种规则推理演绎得到新的知识。有许多需要解决的问题需要大量的对世界的知识,这些知识包括事先存储的先验知识和通过智能推理得到的知识。事先存储的先验知识指：人类用某种方式告诉给机器的知识。通过智能推理得到的知识指：结合先验知识和某种特定的推理规则（逻辑推理）得到的知识。首先，先验知识可以指描述目标，特征，种类及物件之间的关系的知识， 也可以描述事件，时间，状态，原因和结果， 以及任何知识你想要机器存储的。比如：今天没有太阳，没有太阳就是阴天。那么以命题逻辑语言，这些知识可以被表示为：今天 → 没有太阳，没有太阳 → 阴天。这些知识是先验知识，那么推理可以得到新知识：今天 → 阴天。由此例子可以看出，先验知识的正确性非常重要，这个例子中没有太阳就是阴天，这个命题是不严谨的、比较笼统的，因为没有太阳可能是下雨，也可能下雪。另外如果人工智慧能看出太陽，除了該如何判斷的這件問題，在這個前提之下，應該也能判斷出陰天與晴天的差異。逻辑命题表示在知识表示中非常重要，逻辑推理规则是目前主要推理规则。可以在机器中用逻辑符号定义每一个逻辑命题，然后再让机器存储相应的逻辑推理规则，那么自然而然机器便可进行推理。目前知识表达有许多困境尚无法解决，比如：建立一个完备的知识库几乎不可能，所以知识库的资源受到限制；先验知识的正确性需要进行检验，而且先验知识有时候不一定是只有对或者错两种选择。\n\n\n规划\n智能Agent必须能够制定目标和实现这些目标。他们需要一种方法来建立一个可预测的世界模型（将整个世界状态用数学模型表现出来，并能预测它们的行为将如何改变这个世界），这样就可以选择功效最大的行为。\n在传统的规划问题中，智能Agent被假定它是世界中唯一具有影响力的，所以它要做出什么行为是已经确定的。但是，如果事实并非如此，它必须定期检查世界模型的状态是否和自己的预测相符合。如果不符合，它必须改变它的计划。因此智能代理必须具有在不确定结果的状态下推理的能力。在多Agent中，多个Agent规划以合作和竞争的方式去完成一定的目标，使用演化演算法和群体智慧可以达成一个整体的突现行为目标。\n\n\n機器學習\n\n机器学习的主要目的是为了让机器从使用者和输入数据等处获得知识，从而让机器自动地去判断和输出相应的结果。这一方法可以帮助解决更多问题、减少错误，提高解决问题的效率。对于人工智能来说，机器学习从一开始就很重要。\n机器学习的方法各种各样，主要分为监督学习和非监督学习两大类。监督学习指事先给定机器一些训练样本并且告诉样本的类别，然后根据这些样本的类别进行训练，提取出这些样本的共同属性或者训练一个分类器，等新来一个样本，则通过训练得到的共同属性或者分类器进行判断该样本的类别。监督学习根据输出结果的离散性和连续性，分为分类和回归两类。非监督学习是不给定训练样本，直接给定一些样本和一些规则，让机器自动根据一些规则进行分类。无论哪种学习方法都会进行误差分析，从而知道所提的方法在理论上是否误差有上限。\n\n\n自然語言處理\n\n自然語言處理探討如何處理及運用自然語言，自然語言認知則是指讓電腦「懂」人類的語言。自然語言生成系統把計算機數據轉化為自然語言。自然語言理解系統把自然語言轉化為計算機程序更易于處理的形式。\n\n\n運動和控制\n\n\n機器感知\n\n機器感知是指能夠使用感測器所輸入的資料（如照相機、麥克風、聲納以及其他的特殊感測器）然後推斷世界的狀態。電腦視覺能夠分析影像輸入。另外還有語音識別、人臉辨識和物體辨識。\n\n\n社交\n\n情感和社交技能對於一個智能agent是很重要的。首先，通过了解他們的動機和情感狀態，代理人能夠預測別人的行動（這涉及要素 博弈論、決策理論以及能夠塑造人的情感和情緒感知能力檢測）。此外，為了良好的人機互動，智慧代理人也需要表現出情緒來。至少它必須出現禮貌地和人類打交道。至少，它本身應該有正常的情緒。\n\n\n創造力\n一個人工智慧的子領域，代表了理論（從哲學和心理學的角度）和實際（通過特定的實現產生的系統的輸出是可以考慮的創意，或系統識別和評估創造力）所定義的創造力。相關領域的研究包括了人工直覺和人工想像。\n\n\n研究方法\n目前没有统一的原理或范式指导人工智能研究。许多问题上研究者都存在争论。\n其中几个长久以来仍没有结论的问题是：是否应从心理或神经方面模拟人工智能?或者像鸟类生物学对于航空工程一样，人类生物学对于人工智能研究是没有关系的？智能行为能否用简单的原则（如逻辑或优化）来描述？还是必须解决大量完全无关的问题？\n智能是否可以使用高级符号表达，如词和想法？还是需要“子符号”的处理？約翰·豪格兰德（John Haugeland）提出了GOFAI（出色的老式人工智能）的概念，也提议人工智能应归类为synthetic intelligence，这个概念后来被某些非GOFAI研究者采纳。\n\n\n控制论与大脑模拟\n\n20世纪40年代到50年代，许多研究者探索神经学、信息理论及控制论之间的联系。其中还造出一些使用电子网络构造的初步智能，如威廉·格雷·沃尔特的烏龜（turtle）和約翰霍普金斯野獸。\n这些研究者还经常在普林斯顿大学和英国的Ratio Club举行技术协会会议。直到1960，大部分人已经放弃这个方法，尽管在80年代再次提出这些原理。\n\n\n符号处理\n\n当20世纪50年代，數位计算机研制成功，研究者开始探索人类智能是否能简化成符号处理。研究主要集中在卡内基梅隆大学，斯坦福大学和麻省理工學院，而各自有独立的研究风格。約翰·豪格兰德（John Haugeland）称这些方法为GOFAI（出色的老式人工智能）。60年代，符号方法在小型证明程序上模拟高级思考有很大的成就。基于控制论或人工神经网络的方法则置于次要。60－70年代的研究者确信符号方法最终可以成功创造强人工智能的机器，同时这也是他们的目标。\n\n认知模拟：经济学家赫伯特·西蒙和艾伦·纽厄尔研究人类问题解决能力和尝试将其形式化，同时他们为人工智能的基本原理打下基础，如认知科学、运筹学和经营科学。他们的研究团队使用心理学实验的结果开发模拟人类解决问题方法的程序。这方法一直在卡内基梅隆大学沿袭下来，并在80年代于Soar发展到高峰。\n基于逻辑：不像艾伦·纽厄尔和赫伯特·西蒙，约翰·麦卡锡认为机器不需要模拟人类的思想，而应尝试找到抽象推理和解决问题的本质，不管人们是否使用同样的算法。他在斯坦福大学的实验室致力于使用形式化逻辑解决多种问题，包括知识表示，智能规划和机器学习。致力于逻辑方法的还有爱丁堡大学，而促成欧洲的其他地方开发编程语言Prolog和逻辑编程科学。\n“反逻辑”: 斯坦福大学的研究者 （如马文·明斯基和西摩爾·派普特）发现要解决计算机视觉和自然语言处理的困难问题，需要专门的方案：他们主张不存在简单和通用原理（如逻辑）能够达到所有的智能行为。罗杰·尚克描述他们的“反逻辑”方法为“scruffy”。常识知识库（如道格拉斯·莱纳特的Cyc）就是“scruffy”AI的例子，因为他们必须人工一次编写一个复杂的概念。\n基于知识：大约在1970年出现大容量内存计算机，研究者分别以三个方法开始把知识构造成应用软件。这场“知识革命”促成专家系统的开发与计划，这是第一个成功的人工智能软件形式。“知识革命”同时让人们意识到许多简单的人工智能软件可能需要大量的知识。\n\n\n子符号方法\n1980年代符号人工智能停滞不前，很多人认为符号系统永远不可能模仿人类所有的认知过程，特别是感知、机器人、机器学习和模式识别。很多研究者开始关注子符号方法解决特定的人工智能问题。\n\n自下而上、接口agent、嵌入环境（机器人）、行为主义、新式AI：机器人领域相关的研究者，如罗德尼·布鲁克斯，否定符号人工智能而专注于机器人移动和求生等基本的工程问题。他们的工作再次关注早期控制论研究者的观点，同时提出了在人工智能中使用控制理论。这与认知科学领域中的表征感知论点是一致的:更高的智能需要个体的表征（如移动，感知和形象）。\n计算智能：1980年代中David Rumelhart等再次提出神经网络和联结主义。这和其他的子符号方法，如模糊控制和进化计算，都属于计算智能学科研究范畴。\n\n\n统计学方法\n1990年代，人工智能研究发展出复杂的数学工具来解决特定的分支问题。这些工具是真正的科学方法，即这些方法的结果是可测量的和可验证的，同时也是近期人工智能成功的原因。共用的数学语言也允许已有学科的合作（如数学，经济或运筹学）。斯图亚特·鲁塞尔和彼德·諾米格指出这些进步不亚于“革命”和“neats的成功”。有人批评这些技术太专注于特定的问题，而没有考虑长远的强人工智能目标。\n\n\n集成方法\n智能agent范式：智能agent是一个会感知环境并作出行动以达致目标的系统。最简单的智能agent是那些可以解决特定问题的程序。更复杂的agent包括人类和人类组织（如公司）。这些范式可以让研究者研究单独的问题和找出有用且可验证的方案，而不需考虑单一的方法。一个解决特定问题的agent可以使用任何可行的方法-一些agent用符号方法和逻辑方法，一些则是子符号神经网络或其他新的方法。范式同时也给研究者提供一个与其他领域沟通的共同语言—如决策论和经济学（也使用abstract agents的概念）。1990年代智能agent范式被广泛接受。\n代理架構和認知架構：研究者设计出一些系统来处理多agent系统中智能agent之间的相互作用。一个系统中包含符号和子符号部分的系统称为混合智能系統，而对这种系统的研究则是人工智能系统集成。分级控制系统则给反应级别的子符号AI和最高级别的传统符号AI提供桥梁，同时放宽了规划和世界建模的时间。\n\n\n基本應用\n\n人工智慧基本的應用（Fundamental Applications）可分為四大部分：\n\n\n感知能力（Perception）\n指的是人類透過感官所收到環境的刺激，察覺訊息的能力，簡單的說就是人類五官的看、聽、說、讀、寫等能力，學習人類的感知能力是AI目前主要的焦點之一，包括：\n\n「看」：電腦視覺（Computer Vision）、圖像辨識（Image Recognition）、人臉辨識（Face Recognition）、物件偵測（Object Detection）。\n「聽」：語音辨識（Sound Recognition）。\n「說」：語音生成（Sound Generation）、文本轉換語音（Text-to-Speech）。\n「讀」：自然語言處理（Natural Language Processing，NLP）、語音轉換文本（Speech-to-Text）。\n「寫」：機器翻譯（Machine Translation）、文本生成（Text Generation）\n\n\n認知能力（Cognition）\n指的是人類透過學習、判斷、分析等等心理活動來瞭解訊息、獲取知識的過程與能力，對人類認知的模仿與學習也是目前AI第二個焦點領域，主要包括：\n\n分析辨識能力：例如醫學圖像分析、產品推薦、垃圾郵件辨識、法律案件分析、犯罪偵測、信用風險分析、消費行為分析等。\n預測能力：例如AI執行的預防性維修（Predictive Maintenance）、智慧天然災害預測與防治。\n判斷能力：例如AI下圍棋、自動駕駛車、健保詐欺判斷、癌症判斷等。\n學習能力：例如機器學習、深度學習、增強式學習等等各種學習方法。\n\n\n創造力（Creativity）\n指的是人類產生新思想，新發現，新方法，新理論，新設計，創造新事物的能力，它是結合知識、智力、能力、個性及潛意識等各種因素優化而成，這個領域目前人類仍遙遙領先AI，但AI也試著急起直追，主要領域包括：AI作曲、AI作詩、AI小說、AI繪畫、AI設計等。\n\n\n智慧（Wisdom）\n指的是人類深刻瞭解人、事、物的真相，能探求真實真理、明辨是非，指導人類可以過著有意義生活的一種能力，這個領域牽涉人類自我意識、自我認知與價值觀，是目前AI尚未觸及的一部分，也是人類最難以模仿的一個領域。\n\n\n實際應用\n\n机器视觉、指纹识别、人脸识别、视网膜识别、虹膜识别、掌纹识别、专家系统、自动规划、無人載具等。\n\n\n應用領域\n智能控制\n機器人學\n自動化技術\n語言和圖像理解\n遺傳編程\n法學資訊系統\n下棋\n醫學領域\n\n\n人工智能倫理\n\n\n倫理管理\n史蒂芬·霍金、比爾蓋茲、埃隆·马斯克、Jaan Tallinn以及Nick Bostrom等人都對於人工智慧技術的未來公開表示憂心，人工智慧若在許多方面超越人類智慧水平的智能、不斷更新、自我提升，進而取得控制管理權，人類是否有足夠的能力及時停止人工智慧領域的「軍備競賽」，能否保有最高掌控權，現有事實是：機器常失控導致人員傷亡，這樣的情況是否會更加擴大規模出現，歷史顯然無法給出可靠的樂觀答案。特斯拉電動車馬斯克（Elon Musk）在麻省理工學院（MIT）航空航天部門百年紀念研討會上稱人工智能是「召喚惡魔」行為，英國發明家Clive Sinclair認為一旦開始製造抵抗人類和超越人類的智能機器，人類可能很難生存，蓋茲同意馬斯克和其它人所言，且不知道為何有些人不擔憂這個問題。\nGoogle DeepMind的人工智慧（AI）系統在2016年「AlphaGo」對戰南韓棋王李世乭獲勝，開發商表示在內部設立倫理委員會，針對人工智慧的應用制定政策，防範人工智慧淪為犯罪開發者。\n科技進步，人工智慧科技產生「自主武器」軍備競賽已悄悄展開，英國、以色列與挪威，都已部署自主飛彈與無人操控的無人機，具「射後不理」（fire-and-forget）能力的飛彈，多枚飛彈還可互相溝通，分享找到攻擊目標。這些武器還未被大量投入，但很快就會出現在戰場上，且並非使用人類所設計的程序，而是完全利用機器自行決策。 霍金等人在英國獨立報發表文章警告未來人工智慧可能會比人類金融市場、科學家、人類領袖更能操縱人心、甚至研發出人們無法理解的武器。專家恐發展到無法控制的局面，援引聯合國禁止研發某些特定武器的「特定常規武器公約」加以限制。新南威尔士大学人工智慧的托比·沃尔什教授認為這是一種欺騙，因為機器無區別戰敵和平民的技術。\n\n\n經濟衝擊\nCNN財經網數字媒體未來學家Amy Webb、美国在线等紛紛預測一些即將被機器人取代的職業，日本野村综合研究所也與英國牛津大学的研究學者共同調查指出，10至20年後，日本有49%的職業（235種職業）可能會被機械和人工智慧取代而消失，直接影響約達2500萬人，例如：超市店員、一般事務員、計程車司機、收費站運營商和收銀員、市場營銷人員、客服人員、製造業工人、金融中間人和分析師、新聞記者、電話公司職員、麻醉師、士兵和保安、律師、醫生、軟體開發者和操盤手、股票交易員等等高薪酬的腦力職業將最先受到衝擊。\n2017年6月份马云在美國底特律舉行「鏈結世界」（Gateway 17）產業大會，會上提出人工智慧可能導致第三次世界大戰，因為前兩次產業革命都導致兩次大戰，戰爭原因並非這些創新發明本身，而是發明對社會上許多人的生活方式衝擊處理不當，新科技在社會上產生新工作也取代舊工作，產生了新的輸家和贏家，若是輸家的人數太多將造成一股社會不穩的能量而這股能量被有心人利用可能導致各種事件。他認為各國應該強制訂定規定AI機器只能用於人類不能做的工作，避免短時間大量人類被取代的失業大潮，但馬雲沒有提出這種世界性規定將如何實現並確保遵守的細節方案。\n数据科学和人工智能被哈佛商業評論称为《二十一世纪最Sexy的職业》，人工智能需求量大，鼓励了不少大学诸如伯克利大学专门成立数据科学系。硅谷和纽约为主的《The Data Incubator》公司於2012年成立，焦点是数据科学，大数据，和人工智能企业培训，提供国际大数据培训服务。\n\n\nAI對人類的威脅\n此議題目前分成兩個學派：\n\n\n悲觀學派\n此學派的代表是天文物理學家史蒂芬·霍金，以及特斯拉執行長伊隆·馬斯克。霍金認為AI對人類將來有很大的威脅，主要有以下理由：\n\nAI會遵循科技發展的加速度理論。\nAI可能會有自我改造創新的能力。\nAI進步的速度遠遠超過人類。\n人類會有被滅絕的危機。\n\n\n樂觀學派\n主要是Google、Facebook等AI的主要技術發展者，他們對AI持樂觀看法的理由：\n\n人類只要關掉電源就能除掉AI機器人。\n任何的科技都會有瓶頸，摩爾定律到目前也遇到相當的瓶頸，AI科技也不會無限成長，依然存在許多難以克服的瓶頸。\n依目前的研究方向，電腦無法突變、甦醒、產生自我意志，AI也不可能具有創意與智慧、同情心與審美等這方面的能力。\n\n\nAI與管理\nAI逐漸普及後，將會在企業管理中扮演很重要的角色，而人類的管理者應如何適度的調整自己的工作職能，有以下幾點建議：\n\n放棄行政工作；\n退守分析預測的領域而強化自己的綜合判斷力；\n把AI當作同事，形成協同合作的團隊；\n多琢磨在創造力以及各種流程架構設計師角色；\n強化自己人際網路、溝通協調、談判上的能力；\n培養自身領導能力，能有效地帶領一個士氣高、團結及凝結力高的工作夥伴。\n\n\n滥用\n\n2019年6月，基于神经网络技术DeepNude软件面世，该软件可以将人物照片的衣着褪去，显示出裸体。随后，经该软件处理后的色情图片在网络上泛滥并引发争议，此后该软件在批评声中被下架。据美国网络安全公司Sensity统计，DeepNude已经产生了68万以上女性的假裸照，其中70%的原照片来自社交网络中的真实女性，而经DeepFake技术处理的视频在以每6个月翻一番的数量增长。截至2020年12月 (2020-12)，Sensity检测到的相关视频数量超过8.5万个。而恶用该技术则可能涉嫌违反《著作权法》等法律，日本警方便多次处理过使用人工智能技术去除色情影片中的马赛克、替换色情影片中女优容貌等相关案件。\n\n\n學科範疇\n人工智能是一門邊緣學科，屬於自然科學和社會科學的交叉。\n\n\n涉及学科\n认知科学\n数学及统计学\n物理学\n逻辑学\n控制论及決定論\n社会学\n犯罪學及智慧犯罪学\n\n\n研究範疇\n\n\n哲學\n\n\n強人工智能和弱人工智能\n人工智能的一個比較流行的定義，也是該領域較早的定義，是由當時麻省理工學院的约翰·麦卡锡于1956年的達特矛斯會議上提出的：人工智能就是要讓機器的行為看起來就像是人所表現出的智能行為一樣。但是這個定義似乎忽略了強人工智能的可能性（見下）。另一個定義指人工智能是人造機器所表現出來的智能。總體來講，目前對人工智能的定義大多可劃分為四類，即機器「像人一樣思考」、「像人一樣行動」、「理性地思考」和「理性地行動」。這裡「行動」應廣義地理解為採取行動，或制定行動的決策，而不是肢體動作。\n\n\n強人工智能\n\n強人工智能觀點認為「有可能」製造出「真正」能推理和解決問題的智能機器，並且，這樣的機器將被認為是具有知覺、有自我意識的。強人工智能可以有兩類：\n\n人類的人工智能，即機器的思考和推理就像人的思維一樣。\n非人類的人工智能，即機器產生了和人完全不一樣的知覺和意識，使用和人完全不一樣的推理方式。\n\n\n弱人工智能\n\n弱人工智能觀點認為「不可能」製造出能「真正」地推理和解決問題的智能機器，這些機器只不過「看起來」像是智能的，但是並不真正擁有智能，也不會有自主意識。\n弱人工智能是對比強人工智能才出現的，因為人工智能的研究一度處於停滯不前的狀態下，直到類神經網路有了強大的運算能力加以模擬後，才開始改變並大幅超前。但人工智能研究者不一定同意弱人工智能，也不一定在乎或者了解強人工智能和弱人工智能的內容與差別，對定義爭論不休。\n就當下的人工智能研究領域來看，研究者已大量造出「看起來」像是智能的機器，取得相當豐碩的理論上和實質上的成果，如2009年康乃爾大學教授Hod Lipson 和其博士研究生Michael Schmidt 研發出的 Eureqa電腦程式，只要給予一些資料，這電腦程式自己只用幾十個小時計算就推論出牛頓花費多年研究才發現的牛頓力學公式，等於只用幾十個小時就自己重新發現牛頓力學公式，這電腦程式也能用來研究很多其他領域的科學問題上。這些所謂的弱人工智慧在神經網路發展下已經有巨大進步，但對於要如何整合成強人工智慧，現在還沒有明確定論。\n\n\n對強人工智能的哲學爭論\n主條目：人工智能哲學、图灵测试、物理符號系統、皇帝新脑、德雷福斯對人工智能的看法、AI效應\n「強人工智能」一詞最初是约翰·瑟尔針對電腦和其它資訊處理機器創造的，其定義為：\n「強人工智能觀點認為計算機不僅是用來研究人的思維的一種工具；相反，只要运行適當的程序，計算機本身就是有思維的。」（J Searle in Minds Brains and Programs. The Behavioral and Brain Sciences, vol. 3, 1980）\n關於強人工智能的爭論，不同於更廣義的一元論和二元論的爭論。其爭論要點是：如果一台機器的唯一工作原理就是轉換編碼數據，那麼這台機器是不是有思維的？希爾勒認為這是不可能的。他舉了個中文房間的例子來說明，如果機器僅僅是轉換數據，而數據本身是對某些事情的一種編碼表現，那麼在不理解這一編碼和這實際事情之間的對應關係的前提下，機器不可能對其處理的數據有任何理解。基於這一論點，希爾勒認為即使有機器通過了圖靈測試，也不一定說明機器就真的像人一樣有自我思維和自由意識。\n也有哲學家持不同的觀點。丹尼爾·丹尼特在其著作《意識的解釋》（Consciousness Explained）裡認為，人也不過是一台有靈魂的機器而已，為什麼我們認為：「人可以有智能，而普通機器就不能」呢？他認為像上述的數據轉換機器是有可能有思維和意識的。\n有的哲學家認為如果弱人工智能是可實現的，那麼強人工智能也是可實現的。比如西蒙·布莱克本（Simon Blackburn）在其哲學入門教材Think裡說道，一個人的看起來是「智能」的行動並不能真正說明這個人就真的是智能的。我永遠不可能知道另一個人是否真的像我一樣是智能的，還是說她／他僅僅是「看起來」是智能的。基於這個論點，既然弱人工智能認為可以令機器「看起來」像是智能的，那就不能完全否定這機器是真的有智能的。布莱克本認為這是一個主觀認定的問題。\n需要指出的是，弱人工智能並非和強人工智能完全對立，也就是說，即使強人工智能是可能的，弱人工智能仍然是有意義的。至少，今日的計算機能做的事，像算術運算等，在一百多年前是被認為很需要智能的。並且，即使強人工智能被證明為可能的，也不代表強人工智能必定能被研製出來。\n\n\n挑战与风险\n幻觉 (人工智能)——由AI做出的非事實聲稱\n可解释人工智能\n人工智能安全及人工智能伦理\n人工智能法案——歐盟法律\nartificial intelligence in the labour market\n通用人工智能的生存风险——一种认为通用人工智能最终可能毁灭人类的假说\n\n\n參看\n\n\n参考文献\n\n\n引用\n\n\n来源\n\n\n注解\n\n\n扩展阅读\n\n\n外部連結\n\nWhat Is AI?—An introduction to artificial intelligence by AI founder John McCarthy.\n开放目录项目中的“AI”\nAITopics—A large directory of links and other resources maintained by the Association for the Advancement of Artificial Intelligence, the leading organization of academic AI researchers.\nArtificial Intelligence Discussion group （页面存档备份，存于互联网档案馆）\n机器人智能机器人智能\nLoebner Prize website（页面存档备份，存于互联网档案馆）\nGame AI—計算機遊戲開發者的AI資源\nKurzweil CyberArt Technologies（页面存档备份，存于互联网档案馆）—關於人工智能藝術的網站，裡面有著名的人工智能繪畫程序AARON\n中華民國人工智慧學會 （页面存档备份，存于互联网档案馆）—以促進中華民國人工智慧及相關領域之研究、發展、應用與交流為宗旨的民間組織。', 'pageid': 317, 'fetch_time': '2026-02-02 20:35:17', 'language': 'zh'}}, {'paper_id': '1394764', 'title': '人工智能史', 'authors': ['Wikipedia'], 'abstract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'doi': '', 'published_date': '2026-02-02T20:35:17.332893', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8F%B2', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': "人工智能的历史源远流长。在古代的神話传说中，技藝高超的工匠可以制作人造人，并为其赋予智能或意识。現代意義上的AI始于古典哲学家试图将人类的思维过程描述为对符号的机械操作。20世纪40年代，基于抽象数学推理的可编程数字電腦的发明使一批科学家开始严肃地探讨构造一个电子大脑的可能性。\n1956年，人工智能的研究领域确立于在达特茅斯学院举行的会议。此次会议的参加者在接下来的数十年间成为AI研究领域的领军人物。他们中有许多人曾预言，与人类具有同等智能水平的机器将在不超过一代人的时间中出现。同时，上千万美元被投入到AI研究中，以期实现这一目标。\n然而，研究人员发现自己大大低估了这一工程的难度，人工智慧史上共出現過幾次低潮（也被称作AI之冬）。由于詹姆斯·莱特希尔爵士的批评和国会方面的压力，美国和英国政府于1973年停止向没有明确目标的人工智能研究项目拨款。七年之后受到日本政府研究规划的刺激，美国政府和企业再次在AI领域投入数十亿研究经费，但这些投资者在80年代末重新撤回了投资。AI研究领域诸如此类的高潮和低谷不断交替出现；至今仍有人对AI的前景作出异常乐观的预测。\n尽管在政府官僚和风投资本家那里经历了大起大落，AI领域仍在取得进展。某些在20世纪70年代被认为不可能解决的问题今天已经获得了圆满解决并已成功应用在商业产品上。与第一代AI研究人员的乐观估计不同，具有与人类同等智能水平的机器至今仍未出现。图灵在1950年发表的一篇催生现代智能机器研究的著名论文中称，“我们只能看到眼前的一小段距离……但是，我们可以看到仍有许多工作要做”。\n在21世纪的第一个十年，机器学习得益于新方法的出现、性能强大的计算机硬件的应用庞大数据集的收集，被广泛应用解决学术和工业上的问题，这重新引发了人们对AI的投资和兴趣。\n\n\n先驱\n奧特曼写道：“某种形式上的人工智能是一个遍布于西方知识分子历史的观点，是一个急需被实现的梦想，”先民对人工智能的追求表现在诸多神话，传说，故事，预言以及制作机器人偶（自動機）的实践之中。\n\n\n神话，幻想和预言中的AI\n希腊神话中已经出现了机械人和人造人，如赫淮斯托斯的黄金机器人和皮格马利翁的伽拉忒亚。中世纪出现了使用巫术或炼金术将意识赋予无生命物质的传说，如贾比尔的Takwin，帕拉塞尔苏斯的何蒙库鲁兹和Judah Loew的魔像。19世纪的幻想小说中出现了人造人和会思考的机器之类题材，例如玛丽·雪莱的《弗兰肯斯坦》和卡雷尔·恰佩克的《罗素姆的万能机器人》。Samuel Butler的《机器中的达尔文（Darwin among the Machines）》一文（1863）探讨了机器通过自然选择进化出智能的可能性。至今人工智能仍然是科幻小说的重要元素。\n\n\n自动人偶\n\n许多文明中都有创造自动人偶的杰出工匠，例如偃师（中国西周），希罗（希腊），加扎利和Wolfgang von Kempelen 等等。已知最古老的“机器人”是古埃及和古希腊的圣像，忠实的信徒认为工匠为这些神像赋予了思想，使它们具有智慧和激情。赫耳墨斯·特里斯墨吉斯忒斯（赫耳墨斯·特里斯墨吉斯忒斯）写道“当发现神的本性时，人就能够重现他”。\n\n\n形式推理\n人工智能的基本假设是人类的思考过程可以机械化。对于机械化推理（即所谓“形式推理（formal reasoning）”）的研究已有很长历史。中国，印度和希腊哲学家均已在公元前的第一个千年里提出了形式推理的结构化方法。他们的想法为后世的哲学家所继承和发展，其中著名的有亚里士多德（对三段论逻辑进行了形式分析），欧几里得（其著作《几何原本》是形式推理的典范），花剌子密（代数学的先驱，“algorithm”一词由他的名字演变而来）以及一些欧洲经院哲学家，如奧卡姆的威廉和邓斯·司各脱。\n马略卡哲学家拉蒙·柳利（1232-1315）开发了一些“逻辑机”，试图通过逻辑方法获取知识。 柳利的机器能够将基本的，无可否认的真理通过机械手段用简单的逻辑操作进行组合，以求生成所有可能的知识。Llull的工作对莱布尼兹产生了很大影响，后者进一步发展了他的思想。\n\n在17世纪中，莱布尼兹，托马斯·霍布斯和笛卡儿尝试将理性的思考系统化为代数学或几何学那样的体系。霍布斯在其著作《利维坦》中有一句名言：“推理就是计算（reason is nothing but reckoning）。” 莱布尼兹设想了一种用于推理的普适语言（他的通用表意文字），能将推理规约为计算，从而使“哲学家之间，就像会计师之间一样，不再需要争辩。他们只需拿出铅笔放在石板上，然后向对方说（如果想要的话，可以请一位朋友作为证人）：‘我们开始算吧。’” 这些哲学家已经开始明确提出形式符号系统的假设，而这一假设将成为AI研究的指导思想。\n在20世纪，数理逻辑研究上的突破使得人工智能好像呼之欲出。这方面的基础著作包括布尔的《思维的定律》与弗雷格的《概念文字》。基于弗雷格的系统，罗素和怀特海在他们于1913年出版的巨著《数学原理》中对数学的基础给出了形式化描述。这一成就激励了希尔伯特，后者向20世纪20年代和30年代的数学家提出了一个基础性的难题：“能否将所有的数学推理形式化?” 这个问题的最终回答由哥德尔不完备定理，图灵机和Alonzo Church的λ演算给出。他们的答案令人震惊：首先，他们证明了数理逻辑的局限性；其次（这一点对AI更重要），他们的工作隐含了任何形式的数学推理都能在这些限制之下机械化的可能性。\n\n邱奇-图灵论题暗示，一台仅能处理0和1这样简单二元符号的机械设备能够模拟任意数学推理过程。这里最关键的灵感是图灵机：这一看似简单的理论构造抓住了抽象符号处理的本质。这一创造激发科学家们探讨让机器思考的可能。\n\n\n计算机科学\n\n用于计算的机器古已有之；历史上许多数学家对其作出了改进。19世纪初，查尔斯·巴贝奇设计了一台可编程计算机（“分析机”），但未能建造出来。愛達·勒芙蕾絲预言，这台机器“将创作出无限复杂，无限宽广的精妙的科学乐章”。（她常被认为是第一个程序员，因为她留下的一些笔记完整地描述了使用这一机器计算伯努利数的方法。）\n第一批现代计算机是二战期间建造的大型译码机（包括Z3，ENIAC和Colossus等）。后两个机器的理论基础是图灵和约翰·冯·诺伊曼提出和发展的学说。\n\n\n人工智能的诞生：1943 - 1956\n在20世纪40年代和50年代，来自不同领域（数学，心理学，工程学，经济学和政治学）的一批科学家开始探讨制造人工大脑的可能性。1956年，人工智能被确立为一门学科。\n\n\n控制论与早期神经网络\n最初的人工智能研究是30年代末到50年代初的一系列科学进展交汇的产物。神经学研究发现大脑是由神经元组成的电子网络，其激励电平只存在“有”和“无”两种状态，不存在中间状态。维纳的控制论描述了电子网络的控制和稳定性。克劳德·香农提出的信息论则描述了数字信号（即高低电平代表的二进制信号）。图灵的计算理论证明数字信号足以描述任何形式的计算。这些密切相关的想法暗示了构建电子大脑的可能性。\n这一阶段的工作包括一些机器人的研发，例如W. Grey Walter的“乌龟（turtles）”，还有“约翰霍普金斯兽”（Johns Hopkins Beast）。这些机器并未使用计算机，数字电路和符号推理；控制它们的是纯粹的模拟电路。\nWalter Pitts和Warren McCulloch分析了理想化的人工神经元网络，并且指出了它们进行简单逻辑运算的机制。他们是最早描述所谓“神经网络”的学者。马文·明斯基是他们的学生，当时是一名24岁的研究生。1951年他与Dean Edmonds一道建造了第一台神经网络机，称为SNARC。在接下来的五十年中，明斯基是AI领域最重要的领导者和创新者之一。\n\n\n游戏AI\n1951年，克里斯托弗·斯特雷奇使用曼彻斯特大学的Ferranti Mark 1机器写出了一个西洋跳棋（checkers）程序；迪特里希·普林茨（Dietrich Prinz）则写出了一个国际象棋程序。亞瑟·李·塞謬爾（Arthur Samuel）在五十年代中期和六十年代初开发的西洋棋程序的棋力已经可以挑战具有相当水平的业余爱好者。游戏AI一直被认为是评价AI进展的一种标准。\n\n\n图灵测试\n1950年，图灵发表了一篇划时代的论文，文中预言了创造出具有真正智能的机器的可能性。由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试：如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。这一简化使得图灵能够令人信服地说明“思考的机器”是可能的。论文中还回答了对这一假说的各种常见质疑。图灵测试是人工智能哲学方面第一个严肃的提案。\n\n\n符号推理与“逻辑理论家”程序\n50年代中期，随着數位计算机的兴起，一些科学家直觉地感到可以进行數字操作的机器也应当可以进行符号操作，而符号操作可能是人类思维的本质。这是创造智能机器的一条新路。\n1955年，艾伦·纽厄尔和后来荣获诺贝尔奖的赫伯特·西蒙在J. C. Shaw的协助下开发了“逻辑理论家（Logic Theorist）”。这个程序能够证明《数学原理》中前52个定理中的38个，其中某些证明比原著更加新颖和精巧。Simon认为他们已经“解决了神秘的心/身问题，解释了物质构成的系统如何获得心灵的性质。” （这一断言的哲学立场后来被约翰·罗杰斯·希尔勒称为“强人工智能”，即机器可以像人一样具有思想。）\n\n\n1956年达特茅斯会议：AI的诞生\n\n1956年达特矛斯会议的组织者是马文·明斯基，约翰·麦卡锡和另两位资深科学家克劳德·香农以及內森·羅徹斯特（Nathan Rochester），后者来自IBM。会议提出的断言之一是“学习或者智能的任何其他特性的每一个方面都应能被精确地加以描述，使得机器可以对其进行模拟。” 与会者包括雷·索羅門諾夫（Ray Solomonoff），奧利佛·塞爾弗里奇（Oliver Selfridge），Trenchard More，亞瑟·山謬爾（Arthur Samuel），艾伦·纽厄尔和赫伯特·西蒙，他们中的每一位都将在AI研究的第一个十年中作出重要贡献。会上纽厄尔和西蒙讨论了“逻辑理论家”，而麦卡锡则说服与会者接受“人工智能”一词作为本领域的名称。1956年达特矛斯会议上AI的名称和任务得以确定，同时出现了最初的成就和最早的一批研究者，因此这一事件被广泛承认为AI诞生的标志。\n\n\n第一波浪潮 - 黄金年代：1956 - 1974\n达特矛斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的程序堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。 研究者们在私下的交流和公开发表的论文中表达出相当乐观的情绪，认为具有完全智能的机器将在二十年内出现。 DARPA（國防高等研究計劃署）等政府机构向这一新兴领域投入了大笔资金。\n\n\n研究工作\n从50年代后期到60年代涌现了大批成功的AI程序和新的研究方向。下面列举其中最具影响的几个。\n\n\n搜索式推理\n许多AI程序使用相同的基本算法。为实现一个目标（例如赢得游戏或证明定理），它们一步步地前进，就像在迷宫中寻找出路一般；如果遇到了死胡同则进行回溯。这就是“搜索式推理”。\n这一思想遇到的主要困难是，在很多问题中，“迷宫”里可能的线路总数是一个天文数字（所谓“指数爆炸”）。研究者使用启发式算法去掉那些不太可能导出正确答案的支路，从而缩小搜索范围。\n艾倫·紐厄爾和赫伯特·西蒙试图通过其“通用解题器（General Problem Solver）”程序，将这一算法推广到一般情形。另一些基于搜索算法证明几何与代数问题的程序也给人们留下了深刻印象，例如赫伯特·吉寧特（Herbert Gelernter）的几何定理证明机（1958）和馬文·李·閔斯基的学生James Slagle开发的SAINT（1961）。还有一些程序通过搜索目标和子目标作出决策，如斯坦福大学为控制机器人Shakey而开发的STRIPS系统。\n\n\n自然语言\nAI研究的一个重要目标是使计算机能够通过自然语言（例如英语）进行交流。早期的一个成功范例是Daniel Bobrow的程序STUDENT，它能够解决高中程度的代数应用题。\n如果用节点表示语义概念（例如“房子”，“门”），用节点间的连线表示语义关系（例如“有 -- 一个”），就可以构造出“语义网（semantic net）”。第一个使用语义网的AI程序由Ross Quillian开发； 而最为成功（也是最有争议）的一个则是Roger Schank的“概念关联（Conceptual Dependency）”。\nJoseph Weizenbaum的ELIZA是第一个聊天机器人，可能也是最有趣的会说英语的程序。与ELIZA“聊天”的用户有时会误以为自己是在和人类，而不是和一个程序，交谈。但是实际上ELIZA根本不知道自己在说什么。它只是按固定套路作答，或者用符合语法的方式将问题复述一遍。\n\n\n微世界\n60年代后期，麻省理工大学AI实验室的马文·闵斯基和西摩爾·派普特建议AI研究者们专注于被称为“微世界”的简单场景。他们指出在成熟的学科中往往使用简化模型帮助基本原则的理解，例如物理学中的光滑平面和完美刚体。许多这类研究的场景是“积木世界”，其中包括一个平面，上面摆放着一些不同形状，尺寸和颜色的积木。\n在这一指导思想下，傑拉德·傑伊·薩斯曼（研究组长），阿道佛·古兹曼（Adolfo Guzman），大衛·瓦爾茲（David Waltz，“约束传播（constraint propagation）”的提出者），特别是Patrick Winston等人在机器视觉领域作出了创造性贡献。同时，Minsky和Papert制作了一个会搭积木的机器臂，从而将“积木世界”变为现实。微世界程序的最高成就是Terry Winograd的SHRDLU，它能用普通的英语句子与人交流，还能作出决策并执行操作。\n\n\n乐观思潮\n第一代AI研究者们曾作出了如下预言:\n\n1958年，艾倫·紐厄爾和赫伯特·西蒙：“十年之内，数字计算机将成为国际象棋世界冠军” “十年之内，数字计算机将发现并证明一个重要的数学定理”。\n1965年，赫伯特·西蒙：“二十年内，机器将能完成人能做到的一切工作。”\n1967年，馬文·閔斯基：“一代之内……创造‘人工智能’的问题将获得实质上的解决。”\n1970年，馬文·閔斯基：“在三到八年的时间里我们将得到一台具有人类平均智能的机器。”\n\n\n经费\n1963年6月，MIT从新建立的ARPA（即后来的DARPA，国防高等研究计划局）获得了二百二十万美元经费，用于资助MAC工程，其中包括Minsky和McCarthy五年前建立的AI研究组。此后ARPA每年提供三百万美元，直到七十年代为止。ARPA还对艾倫·紐厄爾和赫伯特·西蒙在卡内基梅隆大学的工作组以及斯坦福大学AI项目（由John McCarthy于1963年创建）进行类似的资助。另一个重要的AI实验室于1965年由Donald Michie在爱丁堡大学建立。在接下来的许多年间，这四个研究机构一直是AI学术界的研究（和经费）中心。\n经费几乎是无条件地提供的：时任ARPA主任的J. C. R. Licklider相信他的组织应该“资助人，而不是项目”，并且允许研究者去做任何感兴趣的方向。这导致了MIT无约无束的研究氛围及其hacker文化的形成，但是好景不长。\n\n\n第一次AI低谷：1974 - 1980\n到了70年代，AI开始遭遇批评，随之而来的还有资金上的困难。AI研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对AI的资助就缩减或取消了。同时，由于马文·闵斯基对感知器的激烈批评，联结主义（即神经网络）销声匿迹了十年。70年代后期，尽管遭遇了公众的误解，AI在逻辑编程，常识推理等一些领域还是有所进展。\n\n\n问题\n70年代初，AI遭遇了瓶颈。即使是最杰出的AI程序也只能解决它们尝试解决的问题中最简单的一部分，也就是说所有的AI程序都只是“玩具”。AI研究者们遭遇了无法克服的基础性障碍，尽管某些局限后来被成功突破。\n\n计算机的运算能力。当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。例如，羅斯·奎利恩（Ross Quillian）在自然语言方面的研究结果只能用一个含二十个单词的词汇表进行演示，因为内存只能容纳这么多。1976年，汉斯·莫拉维克指出，计算机离智能的要求还差上百万倍。他做了个类比：人工智能需要强大的计算能力，就像飞机需要大功率动力一样，低于一个门限时是无法实现的；但是随着能力的提升，问题逐渐会变得简单。\n计算复杂性和指数爆炸。1972年理查德·卡普根据史提芬·古克于1971年提出的Cook-Levin理論证明，许多问题只可能在指数时间内获解（即，计算时间与输入规模的幂成正比）。除了那些最简单的情况，这些问题的解决需要近乎无限长的时间。这就意味着AI中的许多玩具程序恐怕永远也不会发展为实用的系统。\n常识与推理。许多重要的AI应用，例如机器视觉和自然语言，都需要大量对世界的认识信息。程序应该知道它在看什么，或者在说些什么。这要求程序对这个世界具有儿童水平的认识。研究者们很快发现这个要求太高了：1970年没人能够做出如此巨大的数据库，也没人知道一个程序怎样才能学到如此丰富的信息。\n莫拉維克悖論。证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。这也是70年代中期机器视觉和机器人方面进展缓慢的原因。\n框架和资格问题。采取逻辑观点的AI研究者们（例如John McCarthy）发现，如果不对逻辑的结构进行调整，他们就无法对常见的涉及自动规划（planning or default reasoning）的推理进行表达。为解决这一问题，他们发展了新逻辑学（如非单调逻辑（non-monotonic logics）和模态逻辑（modal logics））。\n\n\n停止拨款\n由于AI的进展緩慢，对AI提供资助的机构（如英国政府，DARPA和NRC）对无方向的AI研究逐渐停止了资助。早在1966年ALPAC（Automatic Language Processing Advisory Committee，自动语言处理顾问委员会）的报告中就有批评机器翻译进展的意味，预示了这一局面的来临。NRC（National Research Council，美国国家科学委员会）在拨款二千万美元后停止资助。1973年詹姆斯·莱特希尔针对英国AI研究状况的报告批评了AI在实现其“宏伟目标”上的完全失败，并导致了英国AI研究的低潮（该报告特别提到了指数爆炸问题，以此作为AI失败的一个原因）。DARPA则对CMU的语音理解研究项目深感失望，从而取消了每年三百万美元的资助。到了1974年已经很难再找到对AI项目的资助。\nHans Moravec将批评归咎于他的同行们不切实际的预言：“许多研究者落进了一张日益浮夸的网中”。还有一点，自从1969年Mansfield修正案通过后，DARPA被迫只资助“具有明确任务方向的研究，而不是无方向的基础研究”。60年代那种对自由探索的资助一去不复返；此后资金只提供给目标明确的特定项目，比如自动坦克，或者战役管理系统。\n\n\n来自大学的批评\n一些哲学家强烈反对AI研究者的主张。其中最早的一个是John Lucas，他认为哥德尔不完备定理已经证明形式系统（例如计算机程序）不可能判断某些陈述的真理性，但是人类可以。修伯特·德雷福斯（Hubert Dreyfus）讽刺六十年代AI界那些未实现的预言，并且批评AI的基础假设，认为人类推理实际上仅涉及少量“符号处理”，而大多是具体的，直觉的，下意识的“窍门（know how）”。 約翰·希爾勒于1980年提出“中文房间”实验，试图证明程序并不“理解”它所使用的符号，即所谓的“意向性（intentionality）”问题。希爾勒认为，如果符号对于机器而言没有意义，那么就不能认为机器是在“思考”。\nAI研究者们并不太把这些批评当回事，因为它们似乎有些离题，而计算复杂性和“让程序具有常识”等问题则显得更加紧迫和严重。对于实际的计算机程序而言，“常识”和“意向性”的区别并不明显。馬文·閔斯基提到德雷福斯和希爾勒时说，“他们误解了，所以应该忽略”。在MIT任教的德雷福斯遭到了AI阵营的冷遇：他后来说，AI研究者们“生怕被人看到在和我一起吃午饭”。 ELIZA程序的作者約瑟夫·維森鮑姆感到他的同事们对待德雷福斯的态度不太专业，而且有些孩子气。虽然他直言不讳地反对德雷福斯的论点，但他“清楚地表明了他们待人的方式不对”。\n約瑟夫·維森鮑姆后来开始思考AI相关的伦理问题，起因是Kenneth Colby开发了一个模仿医师的聊天机器人DOCTOR，并用它当作真正的医疗工具。二人发生争执；虽然Colby认为約瑟夫·維森鮑姆对他的程序没有贡献，但这于事无补。1976年約瑟夫·維森鮑姆出版著作《计算机的力量与人类的推理》，书中表示人工智能的滥用可能损害人类生命的价值。\n\n\n感知器与联结主义遭到冷落\n感知器是神经网络的一种形式，由弗兰克·罗森巴特（Frank Rosenblatt）于1958年提出。与多数AI研究者一样，他对这一发明的潜力非常乐观，预言说“感知器最终将能够学习，作出决策和翻译语言”。整个六十年代里这一方向的研究工作都很活跃。\n1969年Minsky和Papert出版了著作《感知器》，书中暗示感知器具有严重局限，而Frank Rosenblatt的预言过于夸张。这本书的影响是破坏性的：联结主义的研究因此停滞了十年。后来新一代研究者使这一领域获得重生，并使其成为人工智能中的重要部分；遗憾的是Rosenblatt没能看到这些，他在《感知器》问世后不久即因游船事故去世。\n\n\n“简约派（the neats）”：逻辑，Prolog语言和专家系统\n早在1958年，John McCarthy就提出了名为“纳谏者（Advice Taker）”的一个程序构想，将逻辑学引入了AI研究界。1963年，J. Alan Robinson发现了在计算机上实现推理的简单方法：归结（resolution）与合一（unification）算法。然而，根据60年代末McCarthy和他的学生们的工作，对这一想法的直接实现具有极高的计算复杂度：即使是证明很简单的定理也需要天文数字的步骤。70年代Robert Kowalsky在Edinburgh大学的工作则更具成效：法国学者Alain Colmerauer和Phillipe Roussel在他的合作下开发出成功的逻辑编程语言Prolog。Prolog使用一組邏輯(與「規則」和「生產規則」密切相關的「霍恩子句」)，並允許進行可處理的計算。規則持續帶來影響，為愛德華·費根鮑姆的專家系統以及艾倫·紐厄爾和赫伯特·西蒙的工作奠定基礎，使其完成了Soar及認知統一理論。\nDreyfus等人针对逻辑方法的批评观点认为，人类在解决问题时并没有使用逻辑运算。心理学家Peter Wason，Eleanor Rosch，阿摩司·特沃斯基，Daniel Kahneman等人的实验证明了这一点。McCarthy则回应说，人类怎么思考是无关紧要的：真正想要的是解题机器，而不是模仿人类进行思考的机器。\n\n\n“芜杂派（the scruffies）”：框架和脚本\n对McCarthy的做法持批评意见的还有他在MIT的同行们。马文·闵斯基，Seymour Papert和Roger Schank等试图让机器像人一样思考，使之能够解决“理解故事”和“目标识别”一类问题。为了使用“椅子”，“饭店”之类最基本的概念，他们需要让机器像人一样作出一些非逻辑的假设。不幸的是，这些不精确的概念难以用逻辑进行表达。Gerald Sussman注意到，“使用精确的语言描述本质上不精确的概念，并不能使它们变得精确起来”。Schank用“芜杂（scruffy）”一词描述他们这一“反逻辑”的方法，与McCarthy，Kowalski，Feigenbaum，Newell和Simon等人的“简约（neat）”方案相对。\n在1975年的一篇开创性论文中，Minsky注意到与他共事的“芜杂派”研究者在使用同一类型的工具，即用一个框架囊括所有相关的常识性假设。例如，当我们使用“鸟”这一概念时，脑中会立即浮现出一系列相关事实，如会飞，吃虫子，等等。我们知道这些假设并不一定正确，使用这些事实的推理也未必符合逻辑，但是这一系列假设组成的结构正是我们所想和所说的一部分。他把这个结构称为“框架（frames）”。Schank使用了“框架”的一个变种，他称之为“脚本（scripts）”，基于这一想法他使程序能够回答关于一篇英语短文的提问。 多年之后的面向对象编程采纳了AI“框架”研究中的“继承（inheritance）”概念。\n\n\n第二波浪潮 - 繁荣：1980—1987\n在80年代，一类名为“专家系统”的AI程序开始为全世界的公司所采纳，而“知识处理”成为了主流AI研究的焦点。日本政府在同一年代积极投资AI以促进其第五代计算机工程。80年代早期另一个令人振奋的事件是John Hopfield和David Rumelhart使联结主义重获新生。AI再一次获得了成功。\n\n\n专家系统获得赏识\n专家系统是一种程序，能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。最早的示例由Edward Feigenbaum和他的学生们开发。1965年起设计的Dendral能够根据分光计读数分辨混合物。1972年设计的MYCIN能够诊断血液传染病。它们展示了这一方法的威力。\n专家系统仅限于一个很小的知识领域，从而避免了常识问题；其简单的设计又使它能够较为容易地编程实现或修改。总之，实践证明了这类程序的实用性。直到现在AI才开始变得实用起来。\n1980年CMU为DEC（Digital Equipment Corporation，数字设备公司）设计了一个名为XCON的专家系统，这是一个巨大的成功。在1986年之前，它每年为公司省下四千万美元。全世界的公司都开始研发和应用专家系统，到1985年它们已在AI上投入十亿美元以上，大部分用于公司内设的AI部门。为之提供支持的产业应运而生，其中包括Symbolics，Lisp Machines等硬件公司和IntelliCorp，Aion等软件公司。\n\n\n知识革命\n专家系统的能力来自于它们存储的专业知识。这是80年代以来AI研究的一个新方向。  Pamela McCorduck在书中写道，“不情愿的AI研究者们开始怀疑，因为它违背了科学研究中对最简化的追求。智能可能需要建立在对分门别类的大量知识的多种处理方法之上。” “80年代的教训是智能行为与知识处理关系非常密切。有时还需要在特定任务领域非常细致的知识。” 知识库系统和知识工程成为了80年代AI研究的主要方向。\n第一个试图解决常识问题的程序Cyc也在80年代出现，其方法是建立一个容纳一个普通人知道的所有常识的巨型数据库。发起和领导这一项目的Douglas Lenat认为别无捷径，让机器理解人类概念的唯一方法是一个一个地教会它们。这一工程几十年也没有完成。\n\n\n重获拨款：第五代工程\n1981年，日本经济产业省拨款八亿五千万美元支持第五代计算机项目。其目标是造出能够与人对话，翻译语言，解释图像，并且像人一样推理的机器。令“芜杂派”不满的是，他们选用Prolog作为该项目的主要编程语言。\n其他国家纷纷作出响应。英国开始了耗资三亿五千万英镑的Alvey工程。美国一个企业协会组织了MCC（Microelectronics and Computer Technology Corporation，微电子与计算机技术集团），向AI和信息技术的大规模项目提供资助。 DARPA也行动起来，组织了战略计算促进会（Strategic Computing Initiative），其1988年向AI的投资是1984年的三倍。\n\n\n联结主义的重生\n1982年，物理学家John Hopfield证明一种新型的神经网络（现被称为“Hopfield网络”）能够用一种全新的方式学习和处理信息。大约在同时（早于Paul Werbos），David Rumelhart推广了反向传播算法，一种神经网络训练方法。这些发现使1970年以来一直遭人遗弃的联结主义重获新生。\n1986年由Rumelhart和心理学家James McClelland主编的两卷本论文集“分布式并行处理”问世，这一新领域从此得到了统一和促进。90年代神经网络获得了商业上的成功，它们被应用于光字符识别和语音识别软件。\n\n\n第二次AI低谷：1987—1993\n80年代中商业机构对AI的追捧与冷落符合经济泡沫的经典模式，泡沫的破裂也在政府机构和投资者对AI的观察之中。尽管遇到各种批评，这一领域仍在不断前进。来自机器人学这一相关研究领域的Rodney Brooks和Hans Moravec提出了一种全新的人工智能方案。\n\n\n人工智慧的低谷\n“AI之冬”一词由经历过1974年经费削减的研究者们创造出来。他们注意到了对专家系统的狂热追捧，预计不久后人们将转向失望。事实被他们不幸言中：从80年代末到90年代初，AI遭遇了一系列财政问题。\n变天的最早征兆是1987年AI硬件市场需求的突然下跌。Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了Symbolics和其他厂家生产的昂贵的Lisp机。老产品失去了存在的理由：一夜之间这个价值五亿美元的产业土崩瓦解。\nXCON等最初大获成功的专家系统维护费用居高不下。它们难以升级，难以使用，脆弱（当输入异常时会出现莫名其妙的错误），成了以前已经暴露的各种各样的问题（例如资格问题（qualification problem））的牺牲品。专家系统的实用性仅仅局限于某些特定情景。\n到了80年代晚期，战略计算促进会大幅削减对AI的资助。DARPA的新任领导认为AI并非“下一个浪潮”，拨款将倾向于那些看起来更容易出成果的项目。\n直到1991年，“第五代工程”并没有实现，事实上其中一些目标，比如“与人展开交谈”，直到2010年也没有实现。 与其他AI项目一样，期望比真正可能实现的要高得多。\n\n\n軀體的重要性：Nouvelle AI與嵌入式推理\n80年代後期，一些研究者根據機器人學的成就提出了一種全新的人工智能方案。 他們相信，為了獲得真正的智能，機器必須具有軀體 - 它需要感知，移動，生存，與這個世界交互。他們認為這些感知運動技能對於常識推理等高層次技能是至關重要的，而抽象推理不過是人類最不重要，也最無趣的技能（參見莫拉維克悖論）。他們號召「自底向上」地創造智能，這一主張復興了從60年代就沉寂下來的控制論。\n另一位先驅是在理論神經科學上造詣深厚的David Marr，他於70年代來到MIT指導視覺研究組的工作。他排斥所有符號化方法（不論是McCarthy的邏輯學還是Minsky的框架），認為實現AI需要自底向上地理解視覺的物理機制，而符號處理應在此之後進行。\n在發表於1990年的論文「大象不玩象棋（Elephants Don't Play Chess）」中，機器人研究者Rodney Brooks針對「物理符號系統假設」提出批評，他認為符號是可有可無的，因為「這個世界就是描述它自己最好的模型。它總是最新的。它總是包括了需要研究的所有細節。訣竅在於正確地，足夠頻繁地感知它。」 在80年代和90年代也有許多認知科學家反對基於符號處理的智能模型，認為身體是推理的必要條件，這一理論被稱為「具身的心靈/理性/ 認知（embodied mind/reason/cognition）」論題。\n\n\n第三波浪潮 - 大數據與機器學習：1993—2019\n现已年过半百的AI终于实现了它最初的一些目标。它已被成功地用在技术产业中，不过有时是在幕后。这些成就有的归功于计算机性能的提升，有的则是在高尚的科学责任感驱使下对特定的课题不断追求而获得的。不过，至少在商业领域里AI的声誉已经不如往昔了。“实现人类水平的智能”这一最初的梦想曾在60年代令全世界的想象力为之着迷，其失败的原因至今仍众说纷纭。各种因素的合力将AI拆分为各自为战的几个子领域，有时候它们甚至会用新名词来掩饰“人工智能”这块被玷污的金字招牌。AI比以往的任何时候都更加谨慎，却也更加成功。\n\n\n里程碑和摩尔定律\n1997年5月11日，深蓝成为战胜国际象棋世界冠军卡斯帕罗夫的第一个计算机系统。2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。2009年，藍腦計畫声称已经成功地模拟了部分鼠脑。2011年，IBM 沃森參加《危險邊緣》節目，在最後一集打敗了人類選手。2016年3月，AlphaGo擊敗李世乭，成為第一個不讓子而擊敗職業圍棋棋士的電腦圍棋程式。2017年5月，AlphaGo在中国乌镇围棋峰会的三局比赛中击败当时世界排名第一的中国棋手柯洁。\n这些成就的取得并不是因为范式上的革命。它们仍然是工程技术的复杂应用，但是计算机性能已经今非昔比了。事实上，深蓝计算机比克里斯多福·斯特雷奇（Christopher Strachey）在1951年用来下棋的Ferranti Mark 1快一千万倍。这种剧烈增长可以用摩尔定律描述：计算速度和内存容量每两年翻一番。计算性能上的基础性障碍已被逐渐克服。\n\n\n智能代理\n90年代，被称为“智能代理”的新范式被广泛接受。尽管早期研究者提出了模块化的分治策略， 但是直到Judea Pearl，Alan Newell等人将一些概念从决策理论和经济学中引入AI之后现代智能代理范式才逐渐形成。当经济学中的“理性代理（rational agent）”与计算机科学中的“对象”或“模块”相结合，“智能代理”范式就完善了。\n智能代理是一个系统，它感知周围环境，然后采取措施使成功的几率最大化。最简单的智能代理是解决特定问题的程序。已知的最复杂的智能代理是理性的，会思考的人类。智能代理范式将AI研究定义为“对智能代理的学习”。这是对早期一些定义的推广：它超越了研究人类智能的范畴，涵盖了对所有种类的智能的研究。\n这一范式让研究者们通过学习孤立的问题找到可证的并且有用的解答。它为AI各领域乃至经济学，控制论等使用抽象代理概念的领域提供了描述问题和共享解答的一种通用语言。人们希望能找到一种完整的代理架构（像Newell的Soar那样），允许研究者们应用交互的智能代理建立起通用的智能系统。\n\n\n“简约派”的胜利\n越来越多的AI研究者们开始开发和使用复杂的数学工具。人们广泛地认识到，许多AI需要解决的问题已经成为数学，经济学和运筹学领域的研究课题。数学语言的共享不仅使AI可以与其他学科展开更高层次的合作，而且使研究结果更易于评估和证明。AI已成为一门更严格的科学分支。 Russell和Norvig（2003）将这些变化视为一场“革命”和“简约派的胜利”。\nJudea Pearl发表于1988年的名著将概率论和决策理论引入AI。现已投入应用的新工具包括贝叶斯网络，隐马尔可夫模型，信息论，随机模型和经典优化理论。针对神经网络和进化算法等“计算智能”范式的精确数学描述也被发展出来。\n\n\n幕后的AI\nAI研究者们开发的算法开始变为较大的系统的一部分。AI曾经解决了大量的难题，这些解决方案在产业界起到了重要作用。应用了AI技术的有数据挖掘，工业机器人，物流，语音识别，银行业软件，医疗诊断和Google搜索引擎等。\nAI领域并未从这些成就之中获得多少益处。AI的许多伟大创新仅被看作计算机科学工具箱中的一件工具。尼克·博斯特罗姆解释说，“很多AI的前沿成就已被应用在一般的程序中，不过通常没有被称为AI。这是因为，一旦变得足够有用和普遍，它就不再被称为AI了。”\n90年代的许多AI研究者故意用其他一些名字称呼他们的工作，例如信息学，知识系统，认知系统或计算智能。部分原因是他们认为他们的领域与AI存在根本的不同，不过新名字也有利于获取经费。至少在商业领域，导致AI之冬的那些未能兑现的承诺仍然困扰着AI研究，正如New York Times在2005年的一篇报道所说：“计算机科学家和软件工程师们避免使用人工智能一词，因为怕被认为是在说梦话。”\n\n\nHAL 9000在哪里?\n1968年亞瑟·克拉克和史丹利·庫柏力克创作的《“2001太空漫游”》中设想2001年将会出现达到或超过人类智能的机器。他们创造的这一名为HAL-9000的角色是以科学事实为依据的：当时许多顶极AI研究者相信到2001年这样的机器会出现。\n“那么问题是，为什么在2001年我们并未拥有HAL呢?” 马文·闵斯基问道。 Minsky认为，问题的答案是绝大多数研究者醉心于钻研神经网络和遗传算法之类商业应用，而忽略了常识推理等核心问题。另一方面，約翰·麥卡錫则归咎于资格问题（qualification problem）。雷蒙德·库茨魏尔相信问题在于计算机性能，根据摩尔定律，他预测具有人类智能水平的机器将在2029年出现。傑夫·霍金认为神经网络研究忽略了人类大脑皮质的关键特性，而简单的模型只能用于解决简单的问题。还有许多别的解释，每一个都对应着一个正在进行的研究计划。\n\n\n深度学习，大数据和通用人工智能：2011至2019\n进入21世纪，得益于大数据和计算机技术的快速发展，许多先进的机器学习技术成功应用于经济社会中的许多问题。麦肯锡全球研究院在一份题为《大数据：创新、竞争和生产力的下一个前沿领域》的报告中估计，到2009年，美国经济所有行业中具有1000名以上员工的公司都至少平均拥有一个200兆兆字节的存储数据。\n到2016年，AI相关产品、硬件、软件等的市场规模已经超过80亿美元，纽约时报评价道AI已经到达了一个热潮。大数据应用也开始逐渐渗透到其他领域，例如生态学模型训练、经济领域中的各种应用、医学研究中的疾病预测及新药研发等。深度学习（特别是深度卷积神经网络和循环网络）更是极大地推动了图像和视频处理、文本分析、语音识别等问题的研究进程。\n\n\n深度学习\n\n深度学习是机器学习的一个分支，它通过一个有着很多层处理单元的深层网络对数据中的高级抽象进行建模。根据全局逼近原理（Universal approximation theorem），对于神经网络而言，如果要拟合任意连续函数，深度性并不是必须的，即使一个单层的网络，只要拥有足够多的非线性激活单元，也可以达到拟合目的。但是，目前深度神经网络得到了更多的关注，这主要是源于其结构层次性，能够快速建模更加复杂的情况，同时避免浅层网络可能遭遇的诸多缺点。\n然而，深度学习也有自身的缺点。以循环神经网络为例，一个最常见的问题是梯度消失问题（沿着时间序列反向传播过程中，梯度逐渐减小到0附近，造成学习停滞）。为了解决这些问题，很多针对性的模型被提出来，例如LSTM（长短期记忆网络，早在1997年就已经提出，最近随着RNN的大火，又重新进入大众视野）、GRU（门控循环神经单元）等等。\n现在，最先进的神经网络结构在某些领域已经能够达到甚至超过人类平均准确率，例如在计算机视觉领域，特别是一些具体的任务上，比如MNIST数据集（一个手写数字识别数据集）、交通信号灯识别等。再如游戏领域，Google的deepmind团队研发的AlphaGo，在问题搜索复杂度极高的围棋上，已经打遍天下无敌手。\n\n\n大数据\n\n大数据是指在一定时间内无法被传统软件工具捕获、管理和处理的数据集合，需要新的处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应结构化数据的高增长率和多样化的信息资产。在Victor Meyer Schonberg和Kenneth Cooke撰写的《大数据时代》中，大数据意味着所有数据都用于分析，而不是随机分析（抽样调查）。大数据的5V特性（由IBM提出）：Volume（数量）、Velocity（高速）、Variety（多样）、Value（低价值密度）、Veracity（真实）。大数据技术的战略意义不在于掌握庞大的数据信息，而在于专门研究这些有意义的数据。换言之，如果将大数据比喻为一个行业，那么这个行业实现盈利的关键是增加数据的“处理能力”，通过“处理”实现数据的“增值”。\n\n\n第四波浪潮 - 强化学习与大型语言模型: 2020至今\n\n\n大型語言模型\n强化学习是机器学习中的一个领域，强调如何基于环境而行动，以取得最大化的预期利益。强化学习是除了监督学习和非监督学习之外的第三种基本的机器学习方法。2022年，人工智能聊天机器人程序ChatGPT基于GPT-3.5架构的大型语言模型并通过强化学习进行训练，以文字方式交互，可通过人类自然对话方式进行交互，还可用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。在2023年3月，GPT-4正式推出，進一步加強大型語言模型的推理能力。2023年8月，中國百度公司向公眾開放使用文心一言，讓中國內地民眾都可以使用內地版的大型語言模型。2025年1月，深度求索推出著名的DeepSeek-R1 開源大型語言模型，並使用新的算法減低訓練成本。\n\n\n機器人整合與人工智能的實際應用（2025年至今）\n先進的人工智能（AI）系統能夠高精度理解和回應人類對話，已成熟到能夠與機器人無縫整合，改變了製造業、醫療保健、公共服務和材料研究等行業。 人工智能還通過高級數據分析和假設生成加速科學研究。 包括中國、美國和日本在內的國家在政策和資金方面進行了大量投資，以部署人工智能驅動的機器人和人工智能的實際應用，解決勞動力短缺問題，促進創新並提高效率，同時實施監管框架以確保道德和安全發展。\n\n\n中國\n2025年被譽為“人工智能機器人年”，標誌著人工智能（AI）與機器人無縫整合的關鍵時刻。在2025年，中國投資約7300億元人民幣（約1000億美元）用於智能製造和醫療保健領域的人工智能和機器人技術發展。  第十四個五年規劃（2021-2025年）優先發展服務機器人，人工智能系統使機器人能夠執行複雜任務，例如協助手術或自動化工廠裝配線。 例如，中國醫院中的人工智能人形機器人可以解讀患者請求、運送物資並協助護士完成日常任務，顯示現有的人工智能對話能力足以應用於實際的機器人應用。部分資金還支持國防應用，例如自主無人機。 自2025年9月起，中國要求對人工智能生成的內容進行標記，以確保技術的透明度和公眾信任。\n\n\n美國\n2025年1月，人工智能基礎設施投資取得重大進展，星際之門計劃 成立。這家由 OpenAI、SoftBank Group、Oracle 和 MGX 組成的合資企業宣布計劃到2029年在美國投資5000億美元用於人工智能基礎設施，首期投資1000億美元，以支持美國的再工業化並提供保護美國及其盟友國家安全的戰略能力。 該合資企業於2025年1月21日由美國總統唐納德·特朗普正式宣布，SoftBank Group首席執行官 孫正義 被任命為主席。\n美國政府撥款約20億美元用於在製造業和物流業中整合人工智能和機器人技術，利用人工智能處理自然語言和執行用戶指令的能力。 各州政府補充資金支持服務機器人，例如部署在倉庫中執行口頭指令進行庫存管理，或在養老院中回應居民的援助請求。 這些應用表明，將已經熟練於人類交互的高級人工智能與機器人硬體結合是一項實際的前進步驟。\n2025年1月，第14179號行政命令確立了“人工智能行動計劃”，以加速這些技術的創新和部署。\n\n\n影響\n2020年代各國政府和機構對AI的投資加速了人工智能的發展，推動了科學進步，提高了勞動效率，並通過自動化複雜任務改變了各行業。 通過將成熟的人工智能系統整合到各行業的應用當中，這些發展有望徹底改變智能製造和服務行業，重塑人類的日常生活。\n\n\n注释\n\n\n参考文献\n.", 'pageid': 1394764, 'fetch_time': '2026-02-02 20:35:17', 'language': 'zh'}}, {'paper_id': '1468546', 'title': '通用人工智慧', 'authors': ['Wikipedia'], 'abstract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'doi': '', 'published_date': '2026-02-02T20:35:17.332901', 'pdf_url': None, 'url': 'https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7', 'source': 'wikipedia', 'categories': [], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'full_extract': '通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。\n通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。\n关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。\n\n\n概述\n強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。\n因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。\n而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。\n一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。\n\n\n标准\n\n人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：\n\n自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；\n知识表示，包括常识知识库；\n自动规划；\n自主学习、创新；\n使用自然语言进行沟通；\n以及，整合以上这些手段来达到同一个的目标；\n还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。\n\n\n检验强人工智能的操作性手段\n一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：\n\n\n图灵测试（图灵）\n\n同人類交流的試驗。\n\n\n咖啡测试\n生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。\n\n\n机器人学生测试\n透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。\n\n\n雇员测试\n測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。\n这些测试检测了一系列必要的特质，包括推理和学习能力。\n\n\n强人工智能需要解决的问题\n人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。\n人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。\n\n\n人工智能研究的主流\n\n\n强人工智能研究的主流历史\n\n现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。\n然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。\n1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。\n\n\n今日的人工智能研究主流\n\n在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。\n\n大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"\n\n\n现代通用人工智能研究\n“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。\n王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。\nMIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。\n\n\n理论\n\n“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。\n关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。\n也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。\n\n\n參見\n\n\n參考資料', 'pageid': 1468546, 'fetch_time': '2026-02-02 20:35:17', 'language': 'zh'}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:35:42,932 - __main__ - INFO - handle_download: searcher=WikipediaSearcher, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:35:42,955 - __main__ - INFO - call_tool: name=tavily_download, args={'papers': [{'paper_id': '', 'title': '人工智能的创新发展与社会影响 - 中国人大网', 'authors': [], 'abstract': '当前位置：[首页](../../../ "首页")\xa0>\xa0[常委会专题讲座](../ "常委会专题讲座")\n\n## 十三届全国人大常委会专题讲座第七讲\n\n# 人工智能的创新发展与社会影响\n\n来源： 中国人大网\xa0\xa0浏览字号： [大](#) [中](#) [小](#) 2018年10月29日 10:26\n\n一、引言\n\n1956年人工智能（Artificial Intelligence，简称AI）的概念被正式提出，标志着人工智能学科的诞生，其发展目标是赋予机器类人的感知、学习、思考、决策和行动等能力。经过60多年的发展，人工智能已取得突破性进展，在经济社会各领域开始得到广泛应用并形成引领新一轮产业变革之势，推动人类社会进入智能化时代。美国、日本、德国、英国、法国、俄罗斯等国家都制定了发展人工智能的国家战略，我国也于2017年发布了《新一代人工智能发展规划》，发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏等地政府也相继出台推动人工智能发展的相关政策文件，社会各界对人工智能的重大战略意义已形成广泛共识。\n\n跟其他高科技一样，人工智能也是一把双刃剑。如何认识人工智能的社会影响，也有“天使派”和“魔鬼派”之分。“天使派”认为，人工智能领域的科技创新和成果应用取得重大突破，有望引领第四次工业革命，对社会、经济、军事等领域将产生变革性影响，在制造、交通、教育、医疗、服务等方面可以造福人类；“魔鬼派”认为，人工智能是人类的重大威胁，比核武器还危险，有可能引发第三次世界大战。2018年2月，牛津大学、剑桥大学和OpenAI公司等14家机构共同发布题为《人工智能的恶意使用：预测、预防和缓解》的报告，指出人工智能可能给人类社会带来数字安全、物理安全和政治安全等潜在威胁，并给出了一些建议来减少风险。\n\n总体上看，已过花甲之年的人工智能当前的发展具有“四新”特征：以深度学习为代表的人工智能核心技术取得新突破、“智能+”模式的普适应用为经济社会发展注入新动能、人工智能成为世界各国竞相战略布局的新高地、人工智能的广泛应用给人类社会带来法律法规、道德伦理、社会治理等方面一系列的新挑战。因此人工智能这个机遇与挑战并存的新课题引起了全球范围内的广泛关注和高度重视。虽然人工智能未来的创新发展还存在不确定性，但是大家普遍认可人工智能的蓬勃兴起将带来新的社会文明，将推动产业变革，将深刻改变人们的生产生活方式，将是一场影响深远的科技革命。\n\n为了客观认识人工智能的本质内涵和创新发展，本报告在简要介绍人工智能基本概念与发展历程的基础上，着重分析探讨人工智能的发展现状和未来趋势，试图揭示人工智能的真实面貌。很显然，在当下人工智能蓬勃发展的历史浪潮中如何选择中国路径特别值得我们深入思考和探讨。因此，本报告最后就我国人工智能发展态势、存在问题和对策建议也进行了阐述。\n\n二、人工智能的发展历程与启示\n\n1956年夏，麦卡锡（John McCarthy）、明斯基（Marvin Minsky）、罗切斯特（Nathaniel Rochester）和香农（Claude Shannon）等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能”这一概念，标志着人工智能学科的诞生。人工智能的目标是模拟、延伸和扩展人类智能，探寻智能本质，发展类人智能机器。人工智能充满未知的探索道路曲折起伏，如何描述1956年以来60余年的人工智能发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能60余年的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年-20世纪60年代初。人工智能概念在1956年首次被提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、LISP表处理语言等，掀起了人工智能发展的第一个高潮。\n\n二是反思发展期：60年代-70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入了低谷。\n\n三是应用发展期：70年代初-80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入了应用发展的新高潮。\n\n四是低迷发展期：80年代中-90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：90年代中-2010年。由于网络技术特别是互联网技术的发展，信息与数据的汇聚不断加速，互联网应用的不断普及加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年IBM深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念，这些都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年-至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器（Graphics Processing Unit，简称GPU）等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越科学与应用之间的“技术鸿沟”，图像分类、语音识别、知识问答、人机对弈、无人驾驶等具有广阔应用前景的人工智能技术突破了从“不能用、不好用”到“可以用”的技术瓶颈，人工智能发展进入爆发式增长的新高潮。\n\n通过总结人工智能发展历程中的经验和教训，我们可以得到以下启示：\n\n（一）尊重学科发展规律是推动学科健康发展的前提。科学技术的发展有其自身的规律，顺其者昌，违其者衰。人工智能学科发展需要基础理论、数据资源、计算平台、应用场景的协同驱动，当条件不具备时很难实现重大突破。\n\n（二）基础研究是学科可持续发展的基石。加拿大多伦多大学杰弗里·辛顿（Geoffrey Hinton）教授坚持研究深度神经网络30年，奠定人工智能蓬勃发展的重要理论基础。谷歌的DeepMind团队长期深入研究神经科学启发的人工智能等基础问题，取得了阿尔法狗等一系列重大成果。\n\n（三）应用需求是科技创新的不竭之源。引领学科发展的动力主要来自于科学和需求的双轮驱动。人工智能发展的驱动力除了知识与技术体系内在矛盾外，贴近应用、解决用户需求是创新的最大源泉与动力。比如专家系统人工智能实现了从理论研究走向实际应用的突破，近些年来安防监控、身份识别、无人驾驶、互联网和物联网大数据分析等实际应用需求带动了人工智能的技术突破。\n\n（四）学科交叉是创新突破的“捷径”。人工智能研究涉及信息科学、脑科学、心理科学等，上世纪50年代人工智能的出现本身就是学科交叉的结果。特别是脑认知科学与人工智能的成功结合，带来了人工智能神经网络几十年的持久发展。智能本源、意识本质等一些基本科学问题正在孕育重大突破，对人工智能学科发展具有重要促进作用。\n\n（五）宽容失败应是支持创新的题中应有之义。任何学科的发展都不可能一帆风顺，任何创新目标的实现都不会一蹴而就。人工智能60余载的发展生动地诠释了一门学科创新发展起伏曲折的历程。可以说没有过去发展历程中的“寒冬”就没有今天人工智能发展新的春天。\n\n（六）实事求是设定发展目标是制定学科发展规划的基本原则。达到全方位类人水平的机器智能是人工智能学科宏伟的终极目标，但是需要根据科技和经济社会发展水平来设定合理的阶段性研究目标，否则会有挫败感从而影响学科发展，人工智能发展过程中的几次低谷皆因不切实际的发展目标所致。\n\n三、人工智能的发展现状与影响\n\n人工智能经过60多年的发展，理论、技术和应用都取得了重要突破，已成为推动新一轮科技和产业革命的驱动力，深刻影响世界经济、政治、军事和社会发展，日益得到各国政府、产业界和学术界的高度关注。从技术维度来看，人工智能技术突破集中在专用智能，但是通用智能发展水平仍处于起步阶段；从产业维度来看，人工智能创新创业如火如荼，技术和商业生态已见雏形；从社会维度来看，世界主要国家纷纷将人工智能上升为国家战略，人工智能社会影响日益凸显。\n\n（一）专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定领域的人工智能技术（即专用人工智能）由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，因此形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域，统计学习是专用人工智能走向实用的理论基础。深度学习、强化学习、对抗学习等统计机器学习理论在计算机视觉、语音识别、自然语言理解、人机博弈等方面取得成功应用。例如，阿尔法狗在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，语音识别系统5.1%的错误率比肩专业速记员，人工智能系统诊断皮肤癌达到专业医生水平，等等。\n\n（二）通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。虽然包括图像识别、语音识别、自动驾驶等在内的专用人工智能领域已取得突破性进展，但是通用智能系统的研究与应用仍然是任重而道远，人工智能总体发展水平仍处于起步阶段。美国国防高级研究计划局（Defense Advanced Research Projects Agency，简称DARPA）把人工智能发展分为三个阶段：规则智能、统计智能和自主智能，认为当前国际主流人工智能水平仍然处于第二阶段，核心技术依赖于深度学习、强化学习、对抗学习等统计机器学习，AI系统在信息感知（Perceiving）、机器学习（Learning）等智能水平维度进步显著，但是在概念抽象（Abstracting）和推理决策（Reasoning）等方面能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n（三）人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，在其2017年的年度开发者大会上，谷歌明确提出发展战略从“Mobile First”（移动优先）转向“AI First”（AI优先）；微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿，麦肯锡报告2016年全球人工智能研发投入超300亿美元并处于高速增长，全球知名风投调研机构CB Insights报告显示2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n（四）创新生态布局成为人工智能产业发展的战略高地。信息技术（IT）和产业的发展史就是新老IT巨头抢滩布局IT创新生态的更替史。例如，传统信息产业IT（Information Technology）代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网IT（Internet Technology）代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等，目前智能科技IT（Intelligent Technology）的产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动AI技术生态的研发布局，全力抢占人工智能相关产业的制高点。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理GPU服务器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。在技术生态方面，人工智能算法、数据、图形处理器（Graphics Processing Unit，简称GPU）/张量处理器（Tensor Processing Unit，简称TPU）/神经网络处理器（Neural network Processing Unit，NPU）计算、运行/编译/管理等基础软件已有大量开源资源，例如谷歌的TensorFlow第二代人工智能学习系统、脸书的PyTorch深度学习框架、微软的DMTK分布式学习工具包、IBM的SystemML开源机器学习系统等；此外谷歌、IBM、英伟达、英特尔、苹果、华为、中国科学院等积极布局人工智能领域的计算芯片。在人工智能商业和应用生态布局方面，“智能+X”成为创新范式，例如“智能+制造”、“智能+医疗”、“智能+安防”等，人工智能技术向创新性的消费场景和不同行业快速渗透融合并重塑整个社会发展，这是人工智能作为第四次技术革命关键驱动力的最主要表现方式。人工智能商业生态竞争进入白热化，例如智能驾驶汽车领域的参与者既有通用、福特、奔驰、丰田等传统龙头车企，又有互联网造车者如谷歌、特斯拉、优步、苹果、百度等新贵。\n\n（五）人工智能上升为世界主要国家的重大发展战略。人工智能正在成为新一轮产业变革的引擎，必将深刻影响国际产业竞争格局和一个国家的国际竞争力。世界主要发达国家纷纷把发展人工智能作为提升国际竞争力、维护国家安全的重大战略，加紧积极谋划政策，围绕核心技术、顶尖人才、标准规范等强化部署，力图在新一轮国际科技竞争中掌握主导权。无论是德国的“工业4.0”、美国的“工业互联网”、日本的“超智能社会”、还是我国的“中国制造2025”等重大国家战略，人工智能都是其中的核心关键技术。2017年7月，国务院发布了《新一代人工智能发展规划》，开启了我国人工智能快速创新发展的新征程。\n\n（六）人工智能的社会影响日益凸显。人工智能的社会影响是多元的，既有拉动经济、服务民生、造福社会的正面效应，又可能出现安全失控、法律失准、道德失范、伦理失常、隐私失密等社会问题，以及利用人工智能热点进行投机炒作从而存在泡沫风险。首先，人工智能作为新一轮科技革命和产业变革的核心力量，促进社会生产力的整体跃升，推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域发展积极正面影响。与此同时，我们也要看到人工智能引发的法律、伦理等问题日益凸显，对当下的社会秩序及公共管理体制带来了前所未有的新挑战。例如，2016年欧盟委员会法律事务委员会提交一项将最先进的自动化机器人身份定位为“电子人（electronic persons）”的动议，2017年沙特阿拉伯授予机器人“索菲亚”公民身份，这些显然冲击了传统的民事主体制度。那么，是否应该赋予人工智能系统法律主体资格？另外在人工智能新时代，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题都需要我们从法律法规、道德伦理、社会管理等多个角度提供解决方案。\n\n由于人工智能与人类智能密切关联且应用前景广阔、专业性很强，容易造成人们的误解，也带来了不少炒作。例如，有些人错误地认为人工智能就是机器学习（深度学习），人工智能与人类智能是零和博弈，人工智能已经达到5岁小孩的水平，人工智能系统的智能水平即将全面超越人类水平，30年内机器人将统治世界，人类将成为人工智能的奴隶，等等。这些错误认识会给人工智能的发展带来不利影响。还有不少人对人工智能预期过高，以为通用智能很快就能实现，只要给机器人发指令就可以干任何事。另外，有意炒作并通过包装人工智能概念来谋取不当利益的现象时有发生。因此，我们有义务向社会大众普及人工智能知识，引导政府、企业和广大民众科学客观地认识和了解人工智能。\n\n四、人工智能的发展趋势与展望\n\n人工智能经过六十多年的发展突破了算法、算力和算料（数据）等“三算”方面的制约因素，拓展了互联网、物联网等广阔应用场景，开始进入蓬勃发展的黄金时期。从技术维度看，当前人工智能处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有数据、能耗、泛化、可解释性、可靠性、安全性等诸多瓶颈，创新发展空间巨大，从专用到通用智能，从机器智能到人机智能融合，从“人工+智能”到自主智能，后深度学习的新理论体系正在酝酿；从产业和社会发展维度看，人工智能通过对经济和社会各领域渗透融合实现生产力和生产关系的变革，带动人类社会迈向新的文明，人类命运共同体将形成保障人工智能技术安全、可控、可靠发展的理性机制。总体而言，人工智能的春天刚刚开始，创新空间巨大，应用前景广阔。\n\n（一）从专用智能到通用智能。如何实现从狭义或专用人工智能（也称弱人工智能，具备单一领域智能）向通用人工智能（也称强人工智能，具备多领域智能）的跨越式发展，既是下一代人工智能发展的必然趋势，也是国际研究与应用领域的挑战问题。2016年10月美国国家科学技术委员会发布了《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。DeepMind创始人戴密斯·哈萨比斯（Demis Hassabis）提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年7月成立了通用人工智能实验室，100多位感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n（二）从人工智能到人机混合智能。人工智能的一个重要研究方向就是借鉴脑科学和认知科学的研究成果，研究从智能产生机理和本质出发的新型智能计算模型与方法，实现具有脑神经信息处理机制和类人智能行为与智能水平的智能系统。在美国、欧盟、日本等国家和地区纷纷启动的脑计划中，类脑智能已成为核心目标之一。英国工程与自然科学研究理事会EPSRC发布并启动了类脑智能研究计划。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。人机混合智能得到了我国新一代人工智能规划、美国脑计划、脸书（脑机语音文本界面）、特斯拉汽车创始人埃隆·马斯克（人脑芯片嵌入和脑机接口）等的高度关注。\n\n（三）从“人工+智能”到自主智能系统。当前人工智能的研究集中在深度学习，但是深度学习的局限是需要大量人工干预：人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据（非常费时费力）、用户需要人工适配智能系统等。因此已有科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类AI”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低AI人员成本。\n\n（四）人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、材料等传统科学的发展。例如，2018年美国麻省理工学院启动的“智能探究计划”（MIT Intelligence Quest）就联合了五大学院进行协同攻关。\n\n（五）人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来十年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，在现有基础上能够提高劳动生产率40%；美、日、英、德、法等12个发达国家（现占全球经济总量的一半）到2035年，年经济增长率平均可以翻一番。2018年麦肯锡的研究报告表明到2030年人工智能新增经济规模将达到13万亿美元。\n\n（六）人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出未来五年人工智能提升各行业运转效率，其中教育业提升82%，零售业71%，制造业64%，金融业58%。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n（七）人工智能领域的国际竞争将日趋激烈。“未来谁率先掌握人工智能，谁就能称霸世界”。2018年4月，欧盟委员会计划2018-2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略》重点推动物联网建设和人工智能的应用。世界军事强国已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即提出谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n（八）人工智能的社会学将提上议程。水能载舟，亦能覆舟。任何高科技也都是一把双刃剑。随着人工智能的深入发展和应用的不断普及，其社会影响日益明显。人工智能应用得当、把握有度、管理规范，就能有效控制负面风险。为了确保人工智能的健康可持续发展并确保人工智能的发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，深入分析人工智能对未来经济社会发展的可能影响，制定完善的人工智能法律法规，规避可能风险，确保人工智能的正面效应。2017年9月，联合国犯罪和司法研究所(UNICRI)决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。2018年4月，欧洲25个国家签署了《人工智能合作宣言》，从国家战略合作层面来推动人工智能发展，确保欧洲人工智能研发的竞争力，共同面对人工智能在社会、经济、伦理及法律等方面的机遇和挑战。\n\n五、我国人工智能的发展态势与思考\n\n我国当前人工智能发展的总体态势良好。中国信通院联合高德纳咨询公司（Gartner）于2018年9月发布的《2018世界人工智能产业发展蓝皮书》报告统计，我国（不含港澳台地区）人工智能企业总数位列全球第二（1040家），仅次于美国（2039家）。在人工智能总体水平和应用方面，我国也处于国际前列，发展潜力巨大，有望率先突破成为全球领跑者。但是我们也要清醒地看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n一是高度重视。党和国家高度重视并大力发展人工智能。党的十八大以来，习近平总书记把创新摆在国家发展全局的核心位置，高度重视人工智能发展，多次谈及人工智能的重要性，为人工智能如何赋能新时代指明方向。2016年7月习总书记明确指出，人工智能技术的发展将深刻改变人类社会生活，改变世界，应抓住机遇，在这一高技术领域抢占先机。在党的十九大报告中，习总书记强调“要推动互联网、大数据、人工智能和实体经济深度融合”。在2018年两院院士大会上，习总书记再次强调要“推进互联网、大数据、人工智能同实体经济深度融合，做大做强数字经济”。在2017年和2018年的《政府工作报告》中，李克强总理都提到了要加强新一代人工智能发展。2017年7月，国务院发布了《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动，人工智能将成为今后一段时期的国家重大战略。发改委、工信部、科技部、教育部、中央网信办等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n二是态势喜人。根据2017年爱思唯尔（Elsevier）文献数据库SCOPUS统计结果，我国在人工智能领域发表的论文数量已居世界第一。从2012年开始，我国在人工智能领域新增专利数量已经开始超越美国。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成全球人工智能投融资规模最大国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。近两年，清华大学、北京大学、中国科学院大学、浙江大学、上海交通大学、南京大学等高校纷纷成立人工智能学院。2015年开始的中国人工智能大会（CCAI）已连续成功召开四届、规模不断扩大，人工智能领域的教育、科研与学术活动层出不穷。\n\n三是差距不小。我国人工智能在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在较大差距。英国牛津大学2018年的一项研究报告指出中国的人工智能发展能力大致为美国的一半水平。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，存在“头重脚轻”的不均衡现象。在Top700全球AI人才中，中国虽然名列第二，但入选人数远远低于占一半数量的美国。据领英《全球AI领域人才报告》统计，截至2017年一季度全球人工智能领域专业技术人才数量超过190万，其中美国超过85万，我国仅超过5万人，排名全球第7位。2018年市场研究顾问公司Compass Intelligence对全球100多家AI计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国制定完善人工智能相关法律法规的进程需要加快，对可能产生的社会影响还缺少深度分析。\n\n四是前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出到2030年，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n人类社会已开始迈入智能化时代，人工智能引领社会发展是大势所趋，不可逆转。经历六十余年积累后，人工智能开始进入爆发式增长的红利期。伴随着人工智能自身的创新发展和向经济社会的全面渗透，这个红利期将持续相当长的时期。现在是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧需要深入思考。\n\n（一）树立理性务实的发展理念。围棋人机大战中阿尔法狗战胜李世石后，社会大众误以为人工智能已经无所不能，一些地方政府、社会企业、风险资金因此不切实际一窝蜂发展人工智能产业，一些别有用心的机构则有意炒作并通过包装人工智能概念来谋取不当利益。这种“一拥而上、一哄而散”的跟风行为不利于人工智能的健康可持续发展。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。根据高德纳咨询公司发布的技术发展曲线，当前智能机器人、认知专家顾问、机器学习、自动驾驶等人工智能热门技术与领域正处于期望膨胀期，但是通用人工智能及人工智能的整体发展仍处于初步阶段，人工智能还有很多“不能”，实现机器在任意现实环境的自主智能和通用智能仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此发展人工智能不能以短期牟利为目的，要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，并务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n（二）加强基础扎实的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。在此发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。根据2017年爱思唯尔文献数据库SCOPUS统计结果，尽管我国在人工智能领域发表的论文数量已经排名世界第一，但加权引文影响力则只排名34位。为了客观评价我国在人工智能基础研究方面的整体实力，我们搜索了SCI期刊、神经信息处理系统大会（Conference on Neural Information Processing Systems，简称NIPS）等主流人工智能学术会议关于通用智能、深度学习、类脑智能、脑智融合、人机博弈等关键词的论文统计情况，可以清楚看到在人工智能前沿方向中国与美国相比基础实力存在巨大差距：在高质量论文数量方面（按中科院划定的SCI一区论文标准统计），美国是中国的5.34倍（1325:248）；在人才储备方面（SCI论文通讯作者），美国是中国的2.12倍（4804:2267）。\n\n我国应对标国际最高水平，建设面向未来的人工智能基础科学研究中心，重点发展原创性、基础性、前瞻性、突破性的人工智能科学。应该鼓励科研人员瞄准人工智能学科前沿方向开展引领性原创科学研究，通过人工智能与脑认知、神经科学、心理学等学科的交叉融合，重点聚焦人工智能领域的重大基础性科学问题，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n（三）构建自主可控的创新生态。美国谷歌、IBM、微软、脸书等企业在AI芯片、服务器、操作系统、开源算法、云服务、无人驾驶等方面积极构建创新生态、抢占创新高地，已经在国际人工智能产业格局中占据先机。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。美国对中兴通讯发禁令一事充分说明自主可控“核高基”技术的重要性，我国应该吸取在核心电子器件、高端通用芯片及基础软件方面依赖进口的教训，避免重蹈覆辙，着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如军民融合、产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。\n\n另外，我们需要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过标准实施加速人工智能驱动经济社会转型升级的进程。\n\n（四）建立协同高效的创新体系。我国经济社会转型升级对人工智能有重大需求，但是单一的创新主体很难实现政策、市场、技术、应用等方面的全面突破。目前我国学术界、产业界、行业部门在人工智能发展方面各自为政的倾向比较明显，数据资源开放共享不够，缺少对行业资源的有效整合。相比而言，美国已经形成了全社会、全场景、全生态协同互动的人工智能协同创新体系，军民融合和产学研结合都做得很好。我国应在体制机制方面进一步改革创新，建立“军、政、产、学、研、用”一体的人工智能协同创新体系。例如，国家进行顶层设计和战略规划，举全国优势力量设立军事智能的研发和应用平台，提供“人工智能+X”行业融合、打破行业壁垒和行政障碍的激励政策；科技龙头企业引领技术创新生态建设，突破人工智能的重大技术瓶颈；高校科研机构进行人才培养和原始创新，着力构建公共数据资源与技术平台，共同建设若干标杆性的应用创新场景，推动成熟人工智能技术在城市、医疗、金融、文化、农业、交通、能源、物流、制造、安全、服务、教育等领域的深度应用，建设低成本高效益广范围的普惠型智能社会。\n\n（五）加快创新人才的教育培养。发展人工智能关键在人才，中高端人才短缺已经成为我国人工智能做大做强的主要瓶颈。另外，我国社会大众的人工智能科技素养也需要进一步提升，每一个人都需要去适应人工智能时代的科技浪潮。在加强人工智能领军人才培养引进的同时，要面向技术创新和产业发展多层次培养人工智能创新创业人才。《新一代人工智能发展规划》提出逐步开展全民智能教育项目，在中小学阶段设置人工智能课程。目前人工智能科普活动受到各地学校的欢迎，但是缺少通俗易懂的高质量人工智能科普教材、寓教于乐的实验设备和器材、开放共享的教学互动资源平台。国家相关部门应高度重视人工智能教育领域的基础性工作，增加投入，组织优势力量，加强高水平人工智能教育内容和资源平台建设，加快人工智能专业的教学师资培训，从教材、教具、教师等多个环节全面保障我国人工智能教育工作的开展。\n\n（六）推动共担共享的全球治理。人工智能将重塑全球政治和经济格局，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能将进一步拉大发达国家和发展中国家的生产力发展水平差距。美国、日本、德国等通过人工智能和机器人的技术突破和广泛应用弥补他们的人力成本劣势，希望制造业从新兴国家回流发达国家。目前看，我国是发展中国家阵容中唯一有望成为全球人工智能竞争中的领跑者，应采取不同于一些国家的“经济垄断主义、技术保护主义、贸易霸凌主义”路线，尽快布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合国家“一带一路”战略，向亚洲、非洲、南美等经济欠发达地区输出高水平、低成本的“中国智造”成果、提供人工智能时代的中国方案，为让人工智能时代的“智能红利”普惠人类命运共同体做出中国贡献！\n\n（七）制定科学合理的法律法规。要想实实在在收获人工智能带来的红利，首先应保证其安全、可控、可靠发展。美国和欧洲等发达国家和地区十分重视人工智能领域的法律法规问题。美国白宫多次组织这方面的研讨会、咨询会；特斯拉等产业巨头牵头成立OpenAI等机构，旨在以有利于整个人类的方式促进和发展友好的人工智能；科研人员自发签署23条“阿西洛马人工智能原则”，意图在规范人工智能科研及应用等方面抢占先机。我国在人工智能领域的法律法规制定及风险管控方面相对滞后，这种滞后局面与我国现阶段人工智能发展的整体形势不相适应，并可能成为我国人工智能下一步创新发展的一大掣肘。因此，有必要大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法规环境。\n\n（八）加强和鼓励人工智能社会学研究。人工智能的社会影响将是深远的、全方位的。我们当未雨绸缪，从国家安全、社会治理、就业结构、伦理道德、隐私保护等多个维度系统深入研究人工智能可能的影响，制定合理可行的应对措施，确保人工智能的正面效应。应大力加强人工智能领域的科普工作，打造科技与伦理的高效对话机制和沟通平台，消除社会大众对人工智能的误解与恐慌，为人工智能的发展营造理性务实、积极健康的社会氛围。\n\n六、结束语\n\n人工智能经过60多年的发展，进入了创新突破的战略机遇期和产业应用的红利收获期，必将对生产力和产业结构以及国际格局产生革命性影响，并推动人类进入普惠型智能社会。但是，我们需要清醒看到通用人工智能及人工智能的整体发展仍处于初级阶段，人工智能不是万能，人工智能还有很多“不能”。我们应当采取理性务实的发展路径，扎实推进基础研究、技术生态、人才培养、法律规范等方面的工作，在开放中创新，在创新中发展，全速跑赢智能时代，着力建设人工智能科技强国！\n\n（主讲人系中国科学院院士）\n\n编 辑： 王伟\n\n责 编： 张绍敏\n\n[<< 返回首页](../../../)\n\n#### 相关文章\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'http://www.npc.gov.cn/npc/c12434/c541/201905/t20190521_268525.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9980122, 'save_path': None}}, {'paper_id': '', 'title': '[PDF] 现代人工智能：本质、途径和方向', 'authors': [], 'abstract': '现代人工智能：本质、途径和方向 张志华 北京大学数学科学学院，北京市海淀区颐和园5 号 100871 摘要：现代人工智能是通过机器学习及由其而发展起来的计算机视觉、自然语言处 理和语音识别技术来实现多模态数据融合的现实交互。数学上，人工智能是试图求 解具有组合结构的高维复杂问题，从而如何克服维数诅咒而利用维数祝福，核心要 素在于解决表示、计算和对齐问题。人工智能主要处理识别、决策和生成三大任 务，这和机器学习的三大学习范式有监督学习、强化学习和无监督学习相一致。推 断思维和算法思维相结合是研究问题途径，而利用数据的分布信息和问题的结构信 息可以有效帮助我们分析和设计算法。该篇文章将试图讨论了现代人工智能的本 质、技术路线以及一些未来研究方向。 一、引言 AlphaGo、AlphaFold、ChatGPT 和Sora 等人工智能产品相继发布震动了整个科技界， 同时由于其将可能给普通大众的生活带来深刻的影响，也引起了社会各界的广泛关注和讨 论。以多模态异构数据为基座的通用人工智能技术成为现实的趋势越来越大。人工智能是 指系统或智能体试图模拟或拥有人类的行为、思维和智能，虽然有不同途径期望通向人工 智能，但这里我们只关注数学和工程相结合的技术路线。在这篇文章，我主要阐述下面几 个内容：第一，现代的人工智能的本质是什么。第二，现在人工智能的一些主要的研究思 路和途径。第三，将讨论一些可能的研究方向。最后是回顾和总结。 二、人工智能的本质 首先，我们自然会问人工智能基础性的问题：什么是智能？《人工智能现代方法》 [1]一书从两种维度来定义智能，即人与理性，思想与行为。两个维度就有四种组合。但 是就我们现在所看到的人工智能技术，我更愿意把它定义为模拟人的行为和思维的信息处 理系统。因此我们主要关注是：计算机和统计学深度融合的数据科学方法，以及数学和工 程相结合的机器学习技术。 我们知道，图灵测试被广泛用于智能测试，但这是对智能的一种定性描述，迄今为止 并没有一种对智能的定量描述。所以我们设想，“智能”是否存在一种定量的、严谨的数 学定义，比如，象熵是一种用来量化不确定性的严格数学定义一样。或者，模仿统计学中 的p-value，给出智能的一种度量。我们知道，不同的p-value 可以反映对于假设检验结 果证据的度量。最近我们看到，出现了一些像无人驾驶一样对智能分级的定义，像 DeepMind 就提出来AGI(Artificial General Intelligence，通用人工智能)的一种分级 的定义。但现在我反而觉得，定性的描述并不见得是坏事，定量描述反而有可能把智能给 束约了，而定性描述则有可能让智能无远弗届，更富有遐想，更富有创造性。 图1：人工智能的发展历程 其次，我们来回顾人工智能的发展历程[1]。人工智能从1952 年发展到现在，可以把 它划分为下面几个时期：概念人工智能、玩具人工智能、统计人工智能、真实人工智能、 通用人工智能。第一个时期是诞生期，也就是人工智能概念的提出。第二个时期用直接的 搜索方式实现人工智能玩具任务。第三个时期尝试着解决较为复杂任务，是它的崛起期， 以基于规则的学习或者专家系统为代表，对应着计算机科学中的数据结构与算法发展。然 后是连接主义思想提出，神经网络模型兴起，但是由于计算机能力的限制，神经网络在这 时期很快地落入了低谷，被基于核技术(kernel trick)的支撑向量机所取代，由此统计机 器学习方法复兴，即利用统计数据加算法的思想来发展人工智能。在2010 年左右，大数 据驱动的深度神经网络崛起产生了革命性的突破。从2020 年到现在，又涌现了基于生成 模型的通用人工智能，这导致了人工智能发展的新阶段。 从人工智能发展历程，我们可以从两个角度来分析。第一，我们发现整个人工智能的 发展可以看成怎么解决搜索问题的过程，开始是利用暴力搜索，而后希望采取高级搜索来 寻找精确解。因为我们面临的要解决的问题会越来越复杂，寻找精确解不太可行，只好采 取近似搜索的方法。所以使用优化算法，随机算法，以及更为广泛的学习方法。第二，从 如何处理知识表示的角度看待人工智能，这触及到了人工智能的本质。基于规则学习是期 望把人类对事物的理解形式化，从而机器能够有效和人类认知对齐而达到智能的目的。迄 今为止这个路径没有获得成功，大家转而采取较为可行的数据统计的方法，即用统计数据 来代表知识表示，然后在数据上面运行算法。而深度神经网络则被发现提供了一个统计数 据和系统的认知对齐的表示，使得系统可以更为有效地进行端对端学习。强化学习则被用 来把系统的输出结果同人类的价值对齐。 我们看到技术思路的改变对人工智能的发展起到了关键作用。这种思路的转变也存在 于其他领域，产生了一个非常有趣的异曲同工现象。比如，模式识别、自然语言处理、语 音识别、视觉处理等都利用统计方法获取了巨大的成功，此外，从统计学的数据建模到计 算机的算法建模兴起，而人工智能则从机器学习中找到到了新的可行路径。 根据人工智能的发展历史，我们可以来总结人工智能实际在做什么。我理解，人工智 能主要是要处理三个任务：识别（我们可以把识别看做搜索的一个高级形态），决策和生 成。而这个三个任务刚好又和机器学习的三大学习范式：有监督学习、强化学习和无监督 学习是相一致的。实现人工智能的关键主要包含三个技术要素：表示、计算和对齐。 现代人工智能技术我认为大致可以分成两个主要代表性方式。第一，以OpenAI 大语 言生成模型为代表的通用智能系统。第二，以DeepMind 为代表的科学研究的赋能范式， 即科学研究的自动化方法。 第一个方式包括大模型构架、数据和算法等。大语言模型主要利用语言数据，而现在 则希望使用语言、图像和音频等融合的多模态异构数据。考虑到，计算机视觉、自然语言 处理和语音识别等也是由机器学习发展起来的。所以，现代人工智能可以理解成是通过机 器学习及由其驱动而发展起来的计算机视觉、自然语言处理和语音识别等技术来实现多模 态数据的现实交互。 至于科学研究的赋能范式,DeepMind 或谷歌及其合作机构等最近做出了一系列突破性 的代表工作。比如，利用强化学习寻找矩阵相乘中利用加法运算来代替乘法运算[2]，从 而达到使用尽可能小的乘法运算的目的。这实际是个搜索匹配问题。第二个是蛋白质结构 预测AlphaFold [3]，它是在一个三维空间，或者在某个坐标系框架里，找到氨基酸序列 的一个坐标对应，当然这里需要满足氨基酸序列原有的结构信息，因此，是在一个约束体 系里找到一个位置对应。第三个是芯片设计[4]。这是一个序贯的决策或者一个有顺序关 系的排列组合问题。此外，在数学研究中通过AI 辅助去找到一些证明启示或新的数学规 律[5,6],以及欧几里得平面几何数学问题的自动化证明[7]。 从这几个例子我们可以归纳：人工智能可以描述为如何求解具有组合结构的高维复杂 问题。第一，问题有组合或离散结构的，比如，对应关系、顺序关系、或稀疏特性等。第 二，它是高维的，通常规模也很大。我们需要从满足这种结构的不同组合中找到一个最佳 的方案或者代价最小的解。这是人工智能的数学上的一个描述，因此，重点是如何解决维 数诅咒和规模可扩展性问题。 三、人工智能的途径 正如前面所说的，人工智能蕴含的关键数学问题可以描述为如何求解具有组合结构的 高维复杂问题。为了求解问题，有两个里程碑的思想被提出。一是引入了不确定性。因为 我们面对的问题无论是规模和维度都是巨大的，求其精确解是不可行的，因此近似解是一 种必然。不确定性机制可以为寻找有效的近似解提供潜在途径，比如Monte Carlo 树搜索 和强化学习在AlphaGo 中的成功应用。不确定性产生了众所周知的“探索与利用”权衡问 题。二是数据驱动方法。这是因为数据的获取变得容易，且规模越来越大，同时数据表示 和处理的算法不断在进步，比如深度神经网络的崛起。数据驱动方法则伴随着“信息与计 算”权衡问题。 总的来说，是把不确定性和数据驱动这两种思路融合在一起来求解高维复杂的问题。 本质上，我们是要利用机器学习方法。机器学习是从数据中得出结论的算法。因此我们希 望数据尽可能多，希望知道数据的内在统计性质或者统计分布。在数据或者信息层面，数 据越多，越可能理解数据潜在的分布。在计算方面，有了数据，我们就在其上运行算法做 推理。所以这里就存在一个统计有效性和计算有效性之间的权衡。 所以人工智能的关键科学问题，我们可以概括为：第一，我们希望要设计尽可能高效 地使用我们的资源信息和计算的算法，从而为实际问题提供一种可行的解决方案。第二， 我们希望了解何时信息和计算有效的算法是不存在的，也就是建立不可行的结果，即算法 的应用边界。 具体来说，我们要面对很多问题：首先是学习的误差。也就是什么样的规模能达到什 么样的精度。然后是在迭代的时候能不能找到一个最优解，最优解的收敛率是什么。我们 往往采取分布式的计算方式，所以还有计算、通讯等问题。另外大家普遍关注隐私问题、 公平性问题、偏见性问题等。 我们要从样本有效性和计算有效性两方面来研究这些问题。样本有效性推断是统计学 的一个经典主题，而计算有效算法是计算机科学研究的核心课题。但是现在我们是要把这 两者结合在一起，而不是把他们孤立地研究。 从算法的角度，问题的结构是很重要的，数据的分布也是很重要的。所以我们尽可能 要利用问题的结构，同时也要利用数据的分布信息，利用两者来设计算法。采用离散的和 连续的、全局的和局部的、对抗的和合作的等这些更现代的观点来设计和分析算法，这也 可能会带来一些新的洞察。 让我们来看看机器学习。机器学习起源于计算机科学，但它跟统计学是一脉相承的, 都是利用算法从数据中得出结论[8]。经典统计学偏重于方法论的提出，而机器学习则重 于计算工具的开发。机器学习更关注分类或者聚类，即它的关注侧重离散问题。而统计学 侧重于回归或者密度估计等连续问题。现代机器学习和统计学通常要通过一个优化算法来 求解模型，但他们和传统优化又不一样。传统的优化往往只关注于算法是否找到了最优 解，以及算法的收敛性和收敛率。但是机器学习更关注找到了一个最优解之后的模型性 能，即模型在未来数据里的泛化性。所以从这个角度可以将机器学习理解为优化和泛化的 统一。 机器学习主要有四个非常重要的因素：泛化、计算、表示和归因。泛化性是指未知数 据上的表现。对于有监督的学习，泛化性是预测的结果，而无监督学习的泛化性体现在数 据生成的质量上。所有的问题都要通过计算去求解，所以第二要素是计算。统计学家比较 关注归因，即了解到底是哪些输入特征对输出结果产生了关键的作用，从而模型具有可解 释性。 这里我把重点放在表示或表征上。因为我认为表示应该是现代机器学习或者人工智能 的核心和关键。一个好的表示有如下特征：适合预测，因为我们的目的是预测；适合于计 算，因为结果是要通过计算来获得的。如果这个表示还适合于归因，那就更好了。所以自 然地想到有两种表示：一种是比较经济性的表示，另外一种是过参数化的表示。因为通过 数据降维，经济性的表示当然会带来一些计算的便利，但可能会制约了这个模型的表示能 力。一个高维的或者过参数化模型的表示能力会强，但会带来计算上的著名维数诅咒问 题。但维数越高，表示越强，预测能力随之也越好，带来所谓的维数祝福。比如如果在低 维不能做分类，但在高维里，它往往是容易分类的。既要克服维数诅咒，又要利用维数祝 福，在这两者之间找到一种有效的解决方法是机器学习的最核心思想。 一个自然的思路是宽度表示，机器学习领域由此发展起了核方法。核方法的思想将原 始数据映射到一个高维特征空间，然后通过这个特征空间的内积运算，可以有效地避免了 高维特征上的直接计算。这个想法跟统计学的非参方法是一致的。我们知道最重要的一个 机器学习方法叫核SVM。这可以理解成宽度表示的求和模型，宽度表示的可解释性良好 的。但它是一个存粹数学上抽象起来的技术，不能够对问题的物理层面进行有效刻画，所 以它没法用于生成真实数据，如图像和语言。 所以我们想是否可以利用某种深度表示，能够达到数据的物理表示。随机森林方法是 一个最直接的深度方法。而深度神经网络作为一种数据表示技术由此而崛起。它可以解决 维数诅咒问题，同时又能对数据进行物理层面建模。 我们来回顾深度学习的一些关键技术[9]。深度学习自产生以后，开发了一些重要实 现技术，如卷积、ReLU 激活函数、ResNet、Attention、 U-type 结构的编码和解码等。 其次可以用BP 去算梯度，利用SGD 或Adam 这些方法训练参数。在稳定执行上有Dropout 和Batch Normalization 等技术。更为关键的，GPU 刚好适合深度神经网络的并行训练。 所以我们认为深度学习是目前最有效的一种把维数诅咒变为维数祝福，同时又能解决物理 建模的技术。它是通过算法的思路，而不是基于形式化的思路来做表示。 我们关注的是数据表示。但是我们同样需要注意到求解的问题本身以及求解算法也有 表示的问题。算法的表示可以理解成数学上的描述。如果一个问题能够在数学上把它表述 出来，同时对这个算法有一个数学上的表示，那么就有了解决方案。强化学习提供了这种 表示[10]。所以我们可以将强化学习理解成在问题和算法层面的一种表示技术。具体地， 它使用马尔科夫决策过程给我们提供了一种表示的数学框架，而Bellman 最优性方程提供 了求解保证，即基于不动点理论导致了的价值迭代和策略优化方法。 深度学习和强化学习构成了现代人工智能的两翼。深度学习提供了多模态数据表示的 潜在途径，而强化学习提供了一种算法的表示。深度学习还从数学角度提供了一种非常强 大的非线性逼近能力。强化学习同样体现了一种在线决策、序贯决策的思路。而深度学习 与强化学习的结合为现代人工智能赋予了巨大的可能。当然现在大家都在说人工智能可解 释性差，所以自然想到因果学习。因果学习具有一种能很好地解释内在关系的方式，所以 可以考虑引入因果学习进来。但是目前看来，因果学习并没有达到象深度学习和强化学习 那样的成功。最重要的原因是因果学习还没有解决计算可扩展性的问题。 机器学习不仅仅是算法，而且也是工程。现代人工智能的第一次大突破是在深度学习 和计算机视觉中算法和工程的相结合的巅峰之作。最近的第二次突破，则可以理解成算法 和工程在自然语言处理和强化学习结合的又一个巅峰之作。机器学习系统实际上已成为一 个非常重要的研究领域。 四、研究方向 回到学术领域，存在哪些潜在的研究方向。人工智能存在三个层面：算法、应用、基础理 论。具体地，第一，如何做？提出和开发新的模型、技术、算法和场景。AlphaGo、 AlphaFold、ChatGPT 和Sora 所包含的技术不会是终点，新的技术和算法会不断地被提 出。第二，如何用？寻找人工智能更广泛的应用，针对一些特定的应用领域或场景制定方 案。第三，为什么？分析它的运行机理。前面提到了机理应该包含探索和利用权衡、信息 和计算权衡、以及统计有效性和计算有效性之间的权衡等基础性问题。为理解问题的计算 属性、统计属性和科学属性之间差异提供洞察。现在我尝试给出一些更为具体的研究方向 或问题。 基于数据驱动的人工智能算法。首先，我们更希望是混合的数据驱动方法，结合随机和对 抗的思想，能更好地适应信息约束和目标结构的信息。此外，一方面我们希望计算数据规 模很大，但如果存储全部数据则是不可行的。所以我们希望利用在线的方法或更为一般的 自适应方法更有效地利用数据。我认为有几点特别值得关注：第一是高维随机优化的统计 推断。第二是高维随机在线算法。我们一般认为随机或者在线的算法主要是来解决数据量 的问题，更为挑战的是如何去设计一些高效的算法来处理高维且数据量大的问题。第三是 高维采样，在我们面对高维或离散问题时，比如在扩散生成模型中，如何利用蒙特卡罗等 方法找到一个有效的采样方法。第四是分布或鲁棒马尔科夫决策过程。第五是算法的下界 理论分析，刚才说过，给定了有效的资源或算力时，能否给出算法的下界，从而避免不必 要的失败尝试。理论计算机界正试图建立不同下界分析方法之间的内在联系，从而 希望可以形成一个统一的分析框架。 大语言模型的一些重要问题。第一是基础模型的结构和训练算法，现在模型普遍采用 Transformer，训练算法采用AdamW，有可能存在其他更好模型和算法。第二，制约我国人 工智能发展最重要的问题是中文语言的数据质量和中文分词技术，我们现在很多时候直接 套用英文分词技术到在中文上，因为中文有自己的特性，这肯定是不能完全适用的。当然 还有对齐和精调、模型的评估等。我们同样需要关注大模型的机理，我们知道的scaling law、压缩理论是大模型的一些值得关注的基本问题。最后，一般研究机构是没有能力来 搭建大语言模型，所以当然会想到要研究小型化模型，只有小型化才能使其具有更大的实 用性。此外，我们可能看到新闻，Richard Sutton 等人打算利用在线的思路构架通用智能 系统，因为在线可以避免大数据的存储和计算代价。 强化学习的一些重要问题。我们知道强化学习在游戏类的应用非常成功，因为游戏问题的 规则非常明确。而面对实际的应用问题，虽然在大语言模型中强化学习可能有很大的作 用，但在很多问题中强化学习的潜力远远没有被挖掘出来。所以我认为强化学习有以下几 点值得关注：第一是能否开发出并行化的计算框架。强化学习是一个序贯决策过程，天然 和并行不相配。但是只有并行才能够从根本上解决其计算瓶颈。第二是稳定性良好的策略 优化算法。强化学习需要随机采样，所以其算法稳定性是非常重要的课题。第三，强化学 习一般有交互的过程，搭建通用友好的模拟平台很重要。当然最重要的是深度强化学习的 更广泛地应用。 扩散生成模型的一些重要问题。扩散生成模型是目前最活跃的AIGC 方向。我认为值得研 究的方向首先是多模态数据生成。目前单一数据生成较为成熟，但多模态数据生成仍有待 研究。第二是扩散生成模型的性能和训练不稳定性，这是一个很重要的研究方向。第三是 扩散模型怎样去和大语言模型相结合。 最后我想谈一点富有远景的研究方向。我们可以回顾一下人工智能最近十余年的两个最重 大的突破，首先在2010 年左右，深度神经网络在视觉图像的应用产生了第一个人工智能 的里程牌突破，我把它理解为视觉+深度学习。第二里程碑工作ChatGPT 则是在前一个突 破基础上，深度强化学习在自然语言领域的成功，我理解为语言+强化学习或者多模态数 据+深度强化学习。那么我们可以思考下一个突破可能会是什么。我大胆地预测，如果要 产生真正的通用人工智能，很可能是利用贝叶斯技术来进行信念推理。贝叶斯推理包括经 验贝叶斯、概率图模型等。因为信念(belief)是更接近智能的因素，所以我认为在大语言 模型基础上信念+贝叶斯学习将值得期待，让我们拭目以待。 五、回顾和思考 著名的统计学家和机器学习主要奠基人Leo Breiman 在他著名两种文化建模论文[11] 中提出了和反思了数据建模的文化和算法建模的文化[12]。而现代人工智能则是将这两种 文化深度融合。既要数据建模，也要算法建模，是两个文化的结合而不是分叉。另外 Breiman 在文章里还提到他的三个关切：导致不相关的理论和有问题的科学结论(“Led to irrelevant theory and questionable scientific conclusion”)，阻止统计学家使用 更为合适的算法模型(“Kept statisticians from using more suitable algorithmic models”)，阻碍统计学家研究令人兴奋的新问题（“Prevented statisticians from working on exciting new problems”）。这些关切对今天我们发展人工智能仍然是真知 灼见。我们普遍将我国人工智能的发展现状归结于对数学基础的重视或数学家参与程度不 够。但我认为一定要了解人工智能和计算机领域真正关心的问题，只有真正理解其核心所 在，才能有的放矢，才能对人工智能乃至本学科起到实质性的促进作用。 人工智能和计算机领域真正关心的问题：建立模型，设计算法，揭示机理。而且他们 也是有优先级的，第一，我认为目前理论分析肯定是要次于模型的建立和计算算法的设 计。先产生效果再考虑理论，不能脱离实际效果空谈无用的理论。第二，存在性的结果总 是要小于构造性的结果。相比存在性的结果，我们更希望有构造性的算法。第三，大家总 说人工智能不可解释，但归因的解释没有模型的机理来得更重要。对于大模型而言，如果 能将其压缩理论分析清楚，这比究竟是哪个特征起作用要重要。第四，模型的机理没有科 学对齐更迫切，系统输出结果要与问题的本质属性对齐。统计属性要与科学属性相对齐， 系统的价值要与人的价值对齐。 现代计算机视觉的建立者David Marr 把视觉视为一个信息处理系统，提出了理解该 系统的三个不同层次。第一个是物理和执行层次；第二是算法和表示层次；第三个层次是 计算层面。可惜天妒其才，他英年早逝，未能完成他的著作“Vision”[13]。但正如 Marvin Minsky 认为的，Marr 没有真正碰触知识表示问题，未能为他的视觉系统的知识表 示提出好的想法。他的合作者Tomaso Poggio 帮他完成了著作，Poggio 认为在计算层次上 面应该再加上一个学习层次。Marr 关于视觉的三层次的思想同样适用于人工智能，我们也 可以把人工智能看成模拟人类行为和思维的信息处理系统。它有三个层次或要素：表示、 计算和对齐。深度学习和强化学习分别在数据层面和算法层面为我们提供了有效的表示途 径。随机优化算法和计算基座等帮助解决计算问题。最近人工智能技术在对齐层次也获得 突破性进展。实际上，表示也是一种对齐，可以理解表示是把统计数据与机器系统进行对 齐。因此，人工智能是把输入的统计数据与系统的价值对齐，而把系统的输出结果与人的 价值对齐，形成了一个对齐的闭环。 最后，让我们回溯20 世纪统计学的两位主要奠基者Ronald Fisher 和Jerzy Neyman 关于归纳推理（Inductive Inference）和演绎推理（Deductive Inference）的辩论 (The Fisher-Neyman Controversy) 。Fisher 相信统计学可以具有从样本到数据的归纳推 理能力[14,15]，即外推性，而Neyman 则认为只能从数据中进行演绎推理[16]，即内插。 这个著名辩论可以帮助我们来理解大语言模型是否可能会发生涌现。特别是，我们注意到 [7]结合了两种推理来利用AI 求解奥数几何题取得了成功。我有一个很主观的看法， Neyman 是坚定的频率派大师，他认为统计过程的选择应该要基于误差的频率派概念。我们 知道虽然Fisher 也是频率学派的奠基者，但他不排斥贝叶斯，他其实也是经验贝叶斯的 开山鼻祖。贝叶斯赋予先验，利用后验信息推理，因此具有某种程度的外推能力。这也是 为什么我认为贝叶斯推断方法，特别是经验贝叶斯方法在人工智能的未来发展具有潜在作 用，值得我们关注。 总之，现代人工智能是数据建模和算法建模两种文化的深度融合，它本质上是一个模 拟人类行为和思维的信息处理系统，它试图集成归纳推理和演绎推理来让系统实现自主推 理的能力。有境界则自成高格，自有名作，学科能常青在此。当我们不解和疑惑时，可以 多读读这些经典，从中寻找启迪和灵感。空洞无物的炒作和造势或许能得到一时之利，但 再炫丽的泡沫总是要破灭的，唯思想永恒！ 参考文献 1. Stuart Russel and Peter Norvig. Artificial Intelligence: A Modern Approach (Fourth edition). Pearson, 2021. 2. Alhussein Fawzi et al. Discovering faster matrix multiplication algorithms with reinforcement learning. Nature, 610, 47-53 2022. 3. John Jumper et al. (2021). Highly accurate protein structure prediction with AlphaFold, Nature, 596, 583-589. 4. Azalia Mirhoseini et al. A Graph Placement Methodology for Fast Chip Design, Nature, Vol 594, 207-2012, 2021. 5. Alex Davies et al. Advancing mathematics by guiding human intuition with AI, Nature, Vol 600, 70-74, 2021. 6. Bernarding Romera-Paredes et al. Mathematical discoveries from program search with large language models. Nature, 1-10, 2023. 7. Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. Solving Olympiad geometry without human demonstrations. Nature, 625, 476-482 (2024). 8. Bradley Efron and Trevor Hastie. Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. The Cambridge University Press, 2016. 9. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. The MIT Press, 2016. 10. Richard S. Sutton and Andrew G. Barto. Reinforcement Learning (second edition). The MIT Press, 2018. 11. Leo Bregman. Statistical Modeling: The Two Cultures (with Discussion). Statistical Science, 2001. 12. Bradley Efron. Prediction, Estimation, and Attribution (with Discussion). JASA, 2020. 13. David Marr. Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. The MIT Press, 2010. 14. R A Fisher. The Logic of Inductive Inference, 1934. 15. R A Fisher. Statistical Methods and Scientific Inference, 1957. 16. Jerzy Neyman. ‘Inductive Behavior’ as a Basic Concept of Philosophy of Science, 1957.', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://www.math.pku.edu.cn/teachers/zhzhang/MAI2.pdf', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9941347, 'save_path': None}}, {'paper_id': '', 'title': '为何重视通用人工智能发展', 'authors': [], 'abstract': '为何重视通用人工智能发展\n\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n|  |  |  |\n\n|  |  |  |\n| --- | --- | --- |\n|  |  |  |\n|  |  |  |\n|  | 常见问题 |  |\n\n|  |  |  |\n| --- | --- | --- |\n|  | 开放目录 |  |\n|  | 按主题 |  |\n|  | 按机构 |  |\n|  | 区级单位 |  |\n|  | 历史数据 |  |\n|  | 有条件开放AI数据 |  |\n|  | 无条件开放AI数据 |  |\n|  | 往年开放数据 |  |\n|  | 多模态数据专区 |  |\n\n* [需求反馈](../../hdfk/index.htm)\n* [开放协议](../../hdfk/index.htm)\n* [提交成果](../../hdfk/index.htm)\n* [纠错申诉](../../hdfk/index.htm)\n\n* [登录](/cms/web/bjdata/sso/ssoLogin.jsp)\n\n搜本网\xa0\xa0\n一网通查\n\n全站检索\n\n[登录](/cms/web/bjdata/sso/ssoLogin.jsp)\n[需求反馈](../../hdjl/wjtc/index.htm)\n[开放协议](../../hdjl/cjwt/index.htm)\n[提交成果](../../hdjl/tjappyy/index.htm)\n[纠错申诉](../../hdjl/jcjb/index.htm)\n\n* [首页](../../index.htm)\n* [开放数据](../../zyml/kfml/index.htm)**+**\n\n  :   [开放目录](../../zyml/kfml/index.htm)\n  :   [按主题](../../zyml/azt/index.htm)\n  :   [按机构](../../zyml/ajg/index.htm)\n  :   [地理空间](../../dlkj/index.htm)\n  :   [往年开放数据](../../zyml/wnkfsj/index.htm)\n  :   [历史归档清单](https://data.beijing.gov.cn/docs/guidang.pdf)\n  :   [下架资源清单](https://data.beijing.gov.cn/docs/xiajia.pdf)\n  :   [多模态数据专区](../../zyml/dmtsjzq/index.htm)\n* [数据登记](#)\n* [授权开放](../../dxsjfb/index.htm)**+**\n\n  :   [历届竞赛回顾](../../dxsjfb/index.htm)\n  :   [授权运营平台](https://www.bjzhengxin.com.cn/index)\n* [开放计划](../../jkfb/index.htm)**+**\n\n  :   [历史开放计划](https://data.beijing.gov.cn/hdjl/kfqs/index.htm)\n  :   [无障碍数据](https://data.beijing.gov.cn/wzazt/)\n  :   [信用开放数据](https://data.beijing.gov.cn/xyzt/)\n* [数据伙伴](https://data.beijing.gov.cn/hzhbzt/)**+**\n\n  :   [开放京津冀](https://data.beijing.gov.cn/jjjzt/)\n  :   [产业伙伴计划](https://data.beijing.gov.cn/hzhbzt/)\n  :   [应用实践案例](../../appyy/index.htm)\n  :   [开放共性工具](../../gjfb/index.htm)\n* [政策动态](../index.htm)**+**\n\n  :   [数据开放](../zcfgsjkf/index.htm)\n  :   [标准指南](https://data.beijing.gov.cn/sjkfzxfw/index.htm)\n  :   [北京开放](index.htm)\n  :   [其他省市](../qtss/index.htm)\n* [互动反馈](../../hdfk/index.htm)\n\n搜本网\xa0\xa0\n一网通查\n\n全站检索\n\n* [首页](../../index.htm)\n* [开放数据](../../zyml/kfml/index.htm)\n\n  :   [开放目录](../../zyml/kfml/index.htm)\n  :   [按主题](../../zyml/azt/index.htm)\n  :   [按机构](../../zyml/ajg/index.htm)\n  :   [地理空间](../../dlkj/index.htm)\n  :   [往年开放数据](../../zyml/wnkfsj/index.htm)\n  :   [历史归档清单](https://data.beijing.gov.cn/docs/guidang.pdf)\n  :   [下架资源清单](https://data.beijing.gov.cn/docs/xiajia.pdf)\n  :   [多模态数据专区](../../zyml/dmtsjzq/index.htm)\n* [数据登记](#)\n* [授权开放](../../dxsjfb/index.htm)\n\n  :   [历届竞赛回顾](../../dxsjfb/index.htm)\n  :   [授权运营平台](https://www.bjzhengxin.com.cn/index)\n* [开放计划](../../jkfb/index.htm)\n\n  :   [历史开放计划](https://data.beijing.gov.cn/jkfb/kfqs/index.htm)\n  :   [无障碍数据](https://data.beijing.gov.cn/wzazt/)\n  :   [信用开放数据](https://data.beijing.gov.cn/xyzt/)\n* [数据伙伴](https://data.beijing.gov.cn/hzhbzt/)\n\n  :   [开放京津冀](https://data.beijing.gov.cn/jjjzt/)\n  :   [产业伙伴计划](https://data.beijing.gov.cn/hzhbzt/)\n  :   [应用实践案例](../../appyy/index.htm)\n  :   [开放共性工具](../../gjfb/index.htm)\n* [政策动态](../index.htm)\n\n  :   [数据开放](../zcfgsjkf/index.htm)\n  :   [标准指南](https://data.beijing.gov.cn/sjkfzxfw/index.htm)\n  :   [北京开放](index.htm)\n  :   [其他省市](../qtss/index.htm)\n* [互动反馈](../../hdfk/index.htm)\n\n## 当前位置： [首页](../../index.htm)» [政策法规](../index.htm)» 新闻动态-北京开放\n\n* 新闻动态-北京开放\n\n为何重视通用人工智能发展\n\n# 为何重视通用人工智能发展\n\n**作者：张凌寒（中国政法大学数据法治研究院教授）**\n\n\u3000\u3000中央政治局4月28日召开会议指出，要重视通用人工智能发展，营造创新生态，重视防范风险。人工智能概念诞生于20世纪50年代，在半个多世纪的发展历程中，由于受到智能算法、计算速度、存储水平等多方面因素的影响，人工智能技术和应用发展经历了曲折的发展过程。2023年初，以ChatGPT为代表的生成式人工智能引发广泛关注，人工智能正在从专用智能迈向通用智能，进入了全新的发展阶段。\n\n\u3000\u3000（一）\n\n\u3000\u3000习近平总书记强调，人工智能是引领这一轮科技革命和产业变革的战略性技术，具有溢出带动性很强的“头雁”效应。什么是通用人工智能？所谓通用人工智能是够处理更加广泛和复杂任务，并且可以向某个方向特化的人工智能。以ChatGPT为代表的生成式人工智能大模型在海量多源数据、多元应用和超算能力、算法模型的共同驱动下，强调通用学习和建立大规模训练模型的机器学习，获得强大的自我学习和自适应能力。在实际应用中，通用人工智能的组成部分被嵌入到智能助手、机器翻译、自动化客服等场景中，从而实现更加个性化、智能化、自适应的服务和应用。未来通用人工智能的实现将沿着这一思路展开。\n\n\u3000\u3000通用智能的发展引领了新一代的产业变革，也给经济社会生活带来深刻变革。首先，人工智能将带动大规模产业升级。人工智能技术的发展将持续推进传统产业逐渐走向数字化、智能化，许多新兴产业借助这一技术得到迅速发展。尤其在医疗、金融、教育、交通等领域，成熟的人工智能技术已经成为提高效率、优化体验、降低成本的重要手段。广泛的产业结构调整将带动全球经济结构的变化，加速科技企业的崛起，甚至影响世界经济格局。其次，人工智能发展也随之带来劳动力转移。人工智能技术的发展在导致部分传统行业岗位被自动化取代的同时，也会创造出更多的人工智能相关岗位。未来将会出现大规模的劳动力转移，就业结构也会产生变化。最后，人工智能与实体经济利好融合，将成为撬动产业转型的杠杆、引领转型方向的船舵和提供转型动力的引擎。无论是促进传统产业提质增效，还是培育新的经济增长点，都需要互联网、大数据、人工智能开辟更广阔的应用场景。与此同时，人工智能发展也不可避免带来安全风险。人工智能技术的发展给各国数据安全、网络安全等方面提出了更加严峻的挑战，掌握关键人工智能技术对国家整体安全意义重大。人工智能的发展还可能带来新的道德和伦理困惑，如何规范其应用、避免技术失控将成为行业持续关注的问题。\n\n\u3000\u3000（二）\n\n\u3000\u3000人工智能技术的出现，使得信息交互效率得到全面提升。民意的传递有了更广、更快的途径。利用智能技术分析和运用数据，搭建大数据民智平台，用创新的形式和丰富的载体汲取群众的智慧和力量、回应群众的期待。人工智能技术的合理运用，将进一步实现科学决策与民主决策的结合，有利于构建良好稳定的社会环境。\n\n\u3000\u30002018年习近平总书记在中央政治局集体学习中指出，要加强人工智能同保障和改善民生的结合，从保障和改善民生、为人民创造美好生活的需要出发，推动人工智能在人们日常工作、学习、生活中的深度运用，创造更加智能的工作方式和生活方式。如社区工作人员依托人工智能技术，将窗口与手机端相结合，打造有温度的数字化社区服务新模式。工作人员通过即时聊天软件等与孤寡老人建立联系，实时关注孤寡老人的身体、生活、安全等方面情况，定期打电话或上门看望，通过线上线下的工作模式，智能、高效开展服务工作。\n\n\u3000\u3000（三）\n\n\xa0 \xa0 \xa0 \xa0 原文链接：[为何重视通用人工智能发展](https://theory.gmw.cn/2023-06/09/content_36619831.htm)', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'https://data.beijing.gov.cn/publish/bjdata/xydt/ljhd/d48b57e85cec47f0b608e27eaaeafc7c.htm', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9462003, 'save_path': None}}], 'save_path': '/home/qinshan/widthresearch/data/downloads'}
2026-02-02 20:35:42,961 - __main__ - INFO - handle_download: searcher=TavilySearch, input_papers=3, save_path=/home/qinshan/widthresearch/data/downloads
2026-02-02 20:35:42,963 - __main__ - INFO - handle_download: downloaded=3
2026-02-02 20:35:42,963 - __main__ - INFO - call_tool: name=tavily_download, result_type=papers, count=3
2026-02-02 20:35:42,964 - __main__ - DEBUG - call_tool payload sample: {'paper_id': '', 'title': '人工智能的创新发展与社会影响 - 中国人大网', 'authors': [], 'abstract': '当前位置：[首页](../../../ "首页")\xa0>\xa0[常委会专题讲座](../ "常委会专题讲座")\n\n## 十三届全国人大常委会专题讲座第七讲\n\n# 人工智能的创新发展与社会影响\n\n来源： 中国人大网\xa0\xa0浏览字号： [大](#) [中](#) [小](#) 2018年10月29日 10:26\n\n一、引言\n\n1956年人工智能（Artificial Intelligence，简称AI）的概念被正式提出，标志着人工智能学科的诞生，其发展目标是赋予机器类人的感知、学习、思考、决策和行动等能力。经过60多年的发展，人工智能已取得突破性进展，在经济社会各领域开始得到广泛应用并形成引领新一轮产业变革之势，推动人类社会进入智能化时代。美国、日本、德国、英国、法国、俄罗斯等国家都制定了发展人工智能的国家战略，我国也于2017年发布了《新一代人工智能发展规划》，发改委、工信部、科技部、教育部等国家部委和北京、上海、广东、江苏等地政府也相继出台推动人工智能发展的相关政策文件，社会各界对人工智能的重大战略意义已形成广泛共识。\n\n跟其他高科技一样，人工智能也是一把双刃剑。如何认识人工智能的社会影响，也有“天使派”和“魔鬼派”之分。“天使派”认为，人工智能领域的科技创新和成果应用取得重大突破，有望引领第四次工业革命，对社会、经济、军事等领域将产生变革性影响，在制造、交通、教育、医疗、服务等方面可以造福人类；“魔鬼派”认为，人工智能是人类的重大威胁，比核武器还危险，有可能引发第三次世界大战。2018年2月，牛津大学、剑桥大学和OpenAI公司等14家机构共同发布题为《人工智能的恶意使用：预测、预防和缓解》的报告，指出人工智能可能给人类社会带来数字安全、物理安全和政治安全等潜在威胁，并给出了一些建议来减少风险。\n\n总体上看，已过花甲之年的人工智能当前的发展具有“四新”特征：以深度学习为代表的人工智能核心技术取得新突破、“智能+”模式的普适应用为经济社会发展注入新动能、人工智能成为世界各国竞相战略布局的新高地、人工智能的广泛应用给人类社会带来法律法规、道德伦理、社会治理等方面一系列的新挑战。因此人工智能这个机遇与挑战并存的新课题引起了全球范围内的广泛关注和高度重视。虽然人工智能未来的创新发展还存在不确定性，但是大家普遍认可人工智能的蓬勃兴起将带来新的社会文明，将推动产业变革，将深刻改变人们的生产生活方式，将是一场影响深远的科技革命。\n\n为了客观认识人工智能的本质内涵和创新发展，本报告在简要介绍人工智能基本概念与发展历程的基础上，着重分析探讨人工智能的发展现状和未来趋势，试图揭示人工智能的真实面貌。很显然，在当下人工智能蓬勃发展的历史浪潮中如何选择中国路径特别值得我们深入思考和探讨。因此，本报告最后就我国人工智能发展态势、存在问题和对策建议也进行了阐述。\n\n二、人工智能的发展历程与启示\n\n1956年夏，麦卡锡（John McCarthy）、明斯基（Marvin Minsky）、罗切斯特（Nathaniel Rochester）和香农（Claude Shannon）等科学家在美国达特茅斯学院开会研讨“如何用机器模拟人的智能”，首次提出“人工智能”这一概念，标志着人工智能学科的诞生。人工智能的目标是模拟、延伸和扩展人类智能，探寻智能本质，发展类人智能机器。人工智能充满未知的探索道路曲折起伏，如何描述1956年以来60余年的人工智能发展历程，学术界可谓仁者见仁、智者见智。我们将人工智能60余年的发展历程划分为以下6个阶段：\n\n一是起步发展期：1956年-20世纪60年代初。人工智能概念在1956年首次被提出后，相继取得了一批令人瞩目的研究成果，如机器定理证明、跳棋程序、LISP表处理语言等，掀起了人工智能发展的第一个高潮。\n\n二是反思发展期：60年代-70年代初。人工智能发展初期的突破性进展大大提升了人们对人工智能的期望，人们开始尝试更具挑战性的任务，并提出了一些不切实际的研发目标。然而，接二连三的失败和预期目标的落空（例如无法用机器证明两个连续函数之和还是连续函数、机器翻译闹出笑话等），使人工智能的发展走入了低谷。\n\n三是应用发展期：70年代初-80年代中。20世纪70年代出现的专家系统模拟人类专家的知识和经验解决特定领域的问题，实现了人工智能从理论研究走向实际应用、从一般推理策略探讨转向运用专门知识的重大突破。专家系统在医疗、化学、地质等领域取得成功，推动人工智能走入了应用发展的新高潮。\n\n四是低迷发展期：80年代中-90年代中。随着人工智能的应用规模不断扩大，专家系统存在的应用领域狭窄、缺乏常识性知识、知识获取困难、推理方法单一、缺乏分布式功能、难以与现有数据库兼容等问题逐渐暴露出来。\n\n五是稳步发展期：90年代中-2010年。由于网络技术特别是互联网技术的发展，信息与数据的汇聚不断加速，互联网应用的不断普及加速了人工智能的创新研究，促使人工智能技术进一步走向实用化。1997年IBM深蓝超级计算机战胜了国际象棋世界冠军卡斯帕罗夫，2008年IBM提出“智慧地球”的概念，这些都是这一时期的标志性事件。\n\n六是蓬勃发展期：2011年-至今。随着大数据、云计算、互联网、物联网等信息技术的发展，泛在感知数据和图形处理器（Graphics Processing Unit，简称GPU）等计算平台推动以深度神经网络为代表的人工智能技术飞速发展，大幅跨越科学与应用之间的“技术鸿沟”，图像分类、语音识别、知识问答、人机对弈、无人驾驶等具有广阔应用前景的人工智能技术突破了从“不能用、不好用”到“可以用”的技术瓶颈，人工智能发展进入爆发式增长的新高潮。\n\n通过总结人工智能发展历程中的经验和教训，我们可以得到以下启示：\n\n（一）尊重学科发展规律是推动学科健康发展的前提。科学技术的发展有其自身的规律，顺其者昌，违其者衰。人工智能学科发展需要基础理论、数据资源、计算平台、应用场景的协同驱动，当条件不具备时很难实现重大突破。\n\n（二）基础研究是学科可持续发展的基石。加拿大多伦多大学杰弗里·辛顿（Geoffrey Hinton）教授坚持研究深度神经网络30年，奠定人工智能蓬勃发展的重要理论基础。谷歌的DeepMind团队长期深入研究神经科学启发的人工智能等基础问题，取得了阿尔法狗等一系列重大成果。\n\n（三）应用需求是科技创新的不竭之源。引领学科发展的动力主要来自于科学和需求的双轮驱动。人工智能发展的驱动力除了知识与技术体系内在矛盾外，贴近应用、解决用户需求是创新的最大源泉与动力。比如专家系统人工智能实现了从理论研究走向实际应用的突破，近些年来安防监控、身份识别、无人驾驶、互联网和物联网大数据分析等实际应用需求带动了人工智能的技术突破。\n\n（四）学科交叉是创新突破的“捷径”。人工智能研究涉及信息科学、脑科学、心理科学等，上世纪50年代人工智能的出现本身就是学科交叉的结果。特别是脑认知科学与人工智能的成功结合，带来了人工智能神经网络几十年的持久发展。智能本源、意识本质等一些基本科学问题正在孕育重大突破，对人工智能学科发展具有重要促进作用。\n\n（五）宽容失败应是支持创新的题中应有之义。任何学科的发展都不可能一帆风顺，任何创新目标的实现都不会一蹴而就。人工智能60余载的发展生动地诠释了一门学科创新发展起伏曲折的历程。可以说没有过去发展历程中的“寒冬”就没有今天人工智能发展新的春天。\n\n（六）实事求是设定发展目标是制定学科发展规划的基本原则。达到全方位类人水平的机器智能是人工智能学科宏伟的终极目标，但是需要根据科技和经济社会发展水平来设定合理的阶段性研究目标，否则会有挫败感从而影响学科发展，人工智能发展过程中的几次低谷皆因不切实际的发展目标所致。\n\n三、人工智能的发展现状与影响\n\n人工智能经过60多年的发展，理论、技术和应用都取得了重要突破，已成为推动新一轮科技和产业革命的驱动力，深刻影响世界经济、政治、军事和社会发展，日益得到各国政府、产业界和学术界的高度关注。从技术维度来看，人工智能技术突破集中在专用智能，但是通用智能发展水平仍处于起步阶段；从产业维度来看，人工智能创新创业如火如荼，技术和商业生态已见雏形；从社会维度来看，世界主要国家纷纷将人工智能上升为国家战略，人工智能社会影响日益凸显。\n\n（一）专用人工智能取得重要突破。从可应用性看，人工智能大体可分为专用人工智能和通用人工智能。面向特定领域的人工智能技术（即专用人工智能）由于任务单一、需求明确、应用边界清晰、领域知识丰富、建模相对简单，因此形成了人工智能领域的单点突破，在局部智能水平的单项测试中可以超越人类智能。人工智能的近期进展主要集中在专用智能领域，统计学习是专用人工智能走向实用的理论基础。深度学习、强化学习、对抗学习等统计机器学习理论在计算机视觉、语音识别、自然语言理解、人机博弈等方面取得成功应用。例如，阿尔法狗在围棋比赛中战胜人类冠军，人工智能程序在大规模图像识别和人脸识别中达到了超越人类的水平，语音识别系统5.1%的错误率比肩专业速记员，人工智能系统诊断皮肤癌达到专业医生水平，等等。\n\n（二）通用人工智能尚处于起步阶段。人的大脑是一个通用的智能系统，能举一反三、融会贯通，可处理视觉、听觉、判断、推理、学习、思考、规划、设计等各类问题，可谓“一脑万用”。真正意义上完备的人工智能系统应该是一个通用的智能系统。虽然包括图像识别、语音识别、自动驾驶等在内的专用人工智能领域已取得突破性进展，但是通用智能系统的研究与应用仍然是任重而道远，人工智能总体发展水平仍处于起步阶段。美国国防高级研究计划局（Defense Advanced Research Projects Agency，简称DARPA）把人工智能发展分为三个阶段：规则智能、统计智能和自主智能，认为当前国际主流人工智能水平仍然处于第二阶段，核心技术依赖于深度学习、强化学习、对抗学习等统计机器学习，AI系统在信息感知（Perceiving）、机器学习（Learning）等智能水平维度进步显著，但是在概念抽象（Abstracting）和推理决策（Reasoning）等方面能力还很薄弱。总体上看，目前的人工智能系统可谓有智能没智慧、有智商没情商、会计算不会“算计”、有专才无通才。因此，人工智能依旧存在明显的局限性，依然还有很多“不能”，与人类智慧还相差甚远。\n\n（三）人工智能创新创业如火如荼。全球产业界充分认识到人工智能技术引领新一轮产业变革的重大意义，纷纷调整发展战略。比如，在其2017年的年度开发者大会上，谷歌明确提出发展战略从“Mobile First”（移动优先）转向“AI First”（AI优先）；微软2017财年年报首次将人工智能作为公司发展愿景。人工智能领域处于创新创业的前沿，麦肯锡报告2016年全球人工智能研发投入超300亿美元并处于高速增长，全球知名风投调研机构CB Insights报告显示2017年全球新成立人工智能创业公司1100家，人工智能领域共获得投资152亿美元，同比增长141%。\n\n（四）创新生态布局成为人工智能产业发展的战略高地。信息技术（IT）和产业的发展史就是新老IT巨头抢滩布局IT创新生态的更替史。例如，传统信息产业IT（Information Technology）代表企业有微软、英特尔、IBM、甲骨文等，互联网和移动互联网IT（Internet Technology）代表企业有谷歌、苹果、脸书、亚马逊、阿里巴巴、腾讯、百度等，目前智能科技IT（Intelligent Technology）的产业格局还没有形成垄断，因此全球科技产业巨头都在积极推动AI技术生态的研发布局，全力抢占人工智能相关产业的制高点。人工智能创新生态包括纵向的数据平台、开源算法、计算芯片、基础软件、图形处理GPU服务器等技术生态系统和横向的智能制造、智能医疗、智能安防、智能零售、智能家居等商业和应用生态系统。在技术生态方面，人工智能算法、数据、图形处理器（Graphics Processing Unit，简称GPU）/张量处理器（Tensor Processing Unit，简称TPU）/神经网络处理器（Neural network Processing Unit，NPU）计算、运行/编译/管理等基础软件已有大量开源资源，例如谷歌的TensorFlow第二代人工智能学习系统、脸书的PyTorch深度学习框架、微软的DMTK分布式学习工具包、IBM的SystemML开源机器学习系统等；此外谷歌、IBM、英伟达、英特尔、苹果、华为、中国科学院等积极布局人工智能领域的计算芯片。在人工智能商业和应用生态布局方面，“智能+X”成为创新范式，例如“智能+制造”、“智能+医疗”、“智能+安防”等，人工智能技术向创新性的消费场景和不同行业快速渗透融合并重塑整个社会发展，这是人工智能作为第四次技术革命关键驱动力的最主要表现方式。人工智能商业生态竞争进入白热化，例如智能驾驶汽车领域的参与者既有通用、福特、奔驰、丰田等传统龙头车企，又有互联网造车者如谷歌、特斯拉、优步、苹果、百度等新贵。\n\n（五）人工智能上升为世界主要国家的重大发展战略。人工智能正在成为新一轮产业变革的引擎，必将深刻影响国际产业竞争格局和一个国家的国际竞争力。世界主要发达国家纷纷把发展人工智能作为提升国际竞争力、维护国家安全的重大战略，加紧积极谋划政策，围绕核心技术、顶尖人才、标准规范等强化部署，力图在新一轮国际科技竞争中掌握主导权。无论是德国的“工业4.0”、美国的“工业互联网”、日本的“超智能社会”、还是我国的“中国制造2025”等重大国家战略，人工智能都是其中的核心关键技术。2017年7月，国务院发布了《新一代人工智能发展规划》，开启了我国人工智能快速创新发展的新征程。\n\n（六）人工智能的社会影响日益凸显。人工智能的社会影响是多元的，既有拉动经济、服务民生、造福社会的正面效应，又可能出现安全失控、法律失准、道德失范、伦理失常、隐私失密等社会问题，以及利用人工智能热点进行投机炒作从而存在泡沫风险。首先，人工智能作为新一轮科技革命和产业变革的核心力量，促进社会生产力的整体跃升，推动传统产业升级换代，驱动“无人经济”快速发展，在智能交通、智能家居、智能医疗等民生领域发展积极正面影响。与此同时，我们也要看到人工智能引发的法律、伦理等问题日益凸显，对当下的社会秩序及公共管理体制带来了前所未有的新挑战。例如，2016年欧盟委员会法律事务委员会提交一项将最先进的自动化机器人身份定位为“电子人（electronic persons）”的动议，2017年沙特阿拉伯授予机器人“索菲亚”公民身份，这些显然冲击了传统的民事主体制度。那么，是否应该赋予人工智能系统法律主体资格？另外在人工智能新时代，个人信息和隐私保护、人工智能创作内容的知识产权、人工智能歧视和偏见、无人驾驶系统的交通法规、脑机接口和人机共生的科技伦理等问题都需要我们从法律法规、道德伦理、社会管理等多个角度提供解决方案。\n\n由于人工智能与人类智能密切关联且应用前景广阔、专业性很强，容易造成人们的误解，也带来了不少炒作。例如，有些人错误地认为人工智能就是机器学习（深度学习），人工智能与人类智能是零和博弈，人工智能已经达到5岁小孩的水平，人工智能系统的智能水平即将全面超越人类水平，30年内机器人将统治世界，人类将成为人工智能的奴隶，等等。这些错误认识会给人工智能的发展带来不利影响。还有不少人对人工智能预期过高，以为通用智能很快就能实现，只要给机器人发指令就可以干任何事。另外，有意炒作并通过包装人工智能概念来谋取不当利益的现象时有发生。因此，我们有义务向社会大众普及人工智能知识，引导政府、企业和广大民众科学客观地认识和了解人工智能。\n\n四、人工智能的发展趋势与展望\n\n人工智能经过六十多年的发展突破了算法、算力和算料（数据）等“三算”方面的制约因素，拓展了互联网、物联网等广阔应用场景，开始进入蓬勃发展的黄金时期。从技术维度看，当前人工智能处于从“不能用”到“可以用”的技术拐点，但是距离“很好用”还有数据、能耗、泛化、可解释性、可靠性、安全性等诸多瓶颈，创新发展空间巨大，从专用到通用智能，从机器智能到人机智能融合，从“人工+智能”到自主智能，后深度学习的新理论体系正在酝酿；从产业和社会发展维度看，人工智能通过对经济和社会各领域渗透融合实现生产力和生产关系的变革，带动人类社会迈向新的文明，人类命运共同体将形成保障人工智能技术安全、可控、可靠发展的理性机制。总体而言，人工智能的春天刚刚开始，创新空间巨大，应用前景广阔。\n\n（一）从专用智能到通用智能。如何实现从狭义或专用人工智能（也称弱人工智能，具备单一领域智能）向通用人工智能（也称强人工智能，具备多领域智能）的跨越式发展，既是下一代人工智能发展的必然趋势，也是国际研究与应用领域的挑战问题。2016年10月美国国家科学技术委员会发布了《国家人工智能研究与发展战略计划》，提出在美国的人工智能中长期发展策略中要着重研究通用人工智能。DeepMind创始人戴密斯·哈萨比斯（Demis Hassabis）提出朝着“创造解决世界上一切问题的通用人工智能”这一目标前进。微软在2017年7月成立了通用人工智能实验室，100多位感知、学习、推理、自然语言理解等方面的科学家参与其中。\n\n（二）从人工智能到人机混合智能。人工智能的一个重要研究方向就是借鉴脑科学和认知科学的研究成果，研究从智能产生机理和本质出发的新型智能计算模型与方法，实现具有脑神经信息处理机制和类人智能行为与智能水平的智能系统。在美国、欧盟、日本等国家和地区纷纷启动的脑计划中，类脑智能已成为核心目标之一。英国工程与自然科学研究理事会EPSRC发布并启动了类脑智能研究计划。人机混合智能旨在将人的作用或认知模型引入到人工智能系统中，提升人工智能系统的性能，使人工智能成为人类智能的自然延伸和拓展，通过人机协同更加高效地解决复杂问题。人机混合智能得到了我国新一代人工智能规划、美国脑计划、脸书（脑机语音文本界面）、特斯拉汽车创始人埃隆·马斯克（人脑芯片嵌入和脑机接口）等的高度关注。\n\n（三）从“人工+智能”到自主智能系统。当前人工智能的研究集中在深度学习，但是深度学习的局限是需要大量人工干预：人工设计深度神经网络模型、人工设定应用场景、人工采集和标注大量训练数据（非常费时费力）、用户需要人工适配智能系统等。因此已有科研人员开始关注减少人工干预的自主智能方法，提高机器智能对环境的自主学习能力。例如阿法元从零开始，通过自我对弈强化学习实现围棋、国际象棋、日本将棋的“通用棋类AI”。在人工智能系统的自动化设计方面，2017年谷歌提出的自动化学习系统（AutoML）试图通过自动创建机器学习系统降低AI人员成本。\n\n（四）人工智能将加速与其他学科领域交叉渗透。人工智能本身是一门综合性的前沿学科和高度交叉的复合型学科，研究范畴广泛而又异常复杂，其发展需要与计算机科学、数学、认知科学、神经科学和社会科学等学科深度融合。随着超分辨率光学成像、光遗传学调控、透明脑、体细胞克隆等技术的突破，脑与认知科学的发展开启了新时代，能够大规模、更精细解析智力的神经环路基础和机制，人工智能将进入生物启发的智能阶段，依赖于生物学、脑科学、生命科学和心理学等学科的发现，将机理变为可计算的模型，同时人工智能也会促进脑科学、认知科学、生命科学甚至化学、物理、材料等传统科学的发展。例如，2018年美国麻省理工学院启动的“智能探究计划”（MIT Intelligence Quest）就联合了五大学院进行协同攻关。\n\n（五）人工智能产业将蓬勃发展。随着人工智能技术的进一步成熟以及政府和产业界投入的日益增长，人工智能应用的云端化将不断加速，全球人工智能产业规模在未来十年将进入高速增长期。例如，2016年9月，咨询公司埃森哲发布报告指出，人工智能技术的应用将为经济发展注入新动力，在现有基础上能够提高劳动生产率40%；美、日、英、德、法等12个发达国家（现占全球经济总量的一半）到2035年，年经济增长率平均可以翻一番。2018年麦肯锡的研究报告表明到2030年人工智能新增经济规模将达到13万亿美元。\n\n（六）人工智能将推动人类进入普惠型智能社会。“人工智能+X”的创新模式将随着技术和产业的发展日趋成熟，对生产力和产业结构产生革命性影响，并推动人类进入普惠型智能社会。2017年国际数据公司IDC在《信息流引领人工智能新时代》白皮书中指出未来五年人工智能提升各行业运转效率，其中教育业提升82%，零售业71%，制造业64%，金融业58%。我国经济社会转型升级对人工智能有重大需求，在消费场景和行业应用的需求牵引下，需要打破人工智能的感知瓶颈、交互瓶颈和决策瓶颈，促进人工智能技术与社会各行各业的融合提升，建设若干标杆性的应用场景创新，实现低成本、高效益、广范围的普惠型智能社会。\n\n（七）人工智能领域的国际竞争将日趋激烈。“未来谁率先掌握人工智能，谁就能称霸世界”。2018年4月，欧盟委员会计划2018-2020年在人工智能领域投资240亿美元；法国总统在2018年5月宣布《法国人工智能战略》，目的是迎接人工智能发展的新时代，使法国成为人工智能强国；2018年6月，日本《未来投资战略》重点推动物联网建设和人工智能的应用。世界军事强国已逐步形成以加速发展智能化武器装备为核心的竞争态势，例如美国特朗普政府发布的首份《国防战略》报告即提出谋求通过人工智能等技术创新保持军事优势，确保美国打赢未来战争；俄罗斯2017年提出军工拥抱“智能化”，让导弹和无人机这样的“传统”兵器威力倍增。\n\n（八）人工智能的社会学将提上议程。水能载舟，亦能覆舟。任何高科技也都是一把双刃剑。随着人工智能的深入发展和应用的不断普及，其社会影响日益明显。人工智能应用得当、把握有度、管理规范，就能有效控制负面风险。为了确保人工智能的健康可持续发展并确保人工智能的发展成果造福于民，需要从社会学的角度系统全面地研究人工智能对人类社会的影响，深入分析人工智能对未来经济社会发展的可能影响，制定完善的人工智能法律法规，规避可能风险，确保人工智能的正面效应。2017年9月，联合国犯罪和司法研究所(UNICRI)决定在海牙成立第一个联合国人工智能和机器人中心，规范人工智能的发展。2018年4月，欧洲25个国家签署了《人工智能合作宣言》，从国家战略合作层面来推动人工智能发展，确保欧洲人工智能研发的竞争力，共同面对人工智能在社会、经济、伦理及法律等方面的机遇和挑战。\n\n五、我国人工智能的发展态势与思考\n\n我国当前人工智能发展的总体态势良好。中国信通院联合高德纳咨询公司（Gartner）于2018年9月发布的《2018世界人工智能产业发展蓝皮书》报告统计，我国（不含港澳台地区）人工智能企业总数位列全球第二（1040家），仅次于美国（2039家）。在人工智能总体水平和应用方面，我国也处于国际前列，发展潜力巨大，有望率先突破成为全球领跑者。但是我们也要清醒地看到，我国人工智能发展存在过热和泡沫化风险，特别在基础研究、技术体系、应用生态、创新人才、法律规范等方面仍然存在不少问题。总体而言，我国人工智能发展现状可以用“高度重视，态势喜人，差距不小，前景看好”来概括。\n\n一是高度重视。党和国家高度重视并大力发展人工智能。党的十八大以来，习近平总书记把创新摆在国家发展全局的核心位置，高度重视人工智能发展，多次谈及人工智能的重要性，为人工智能如何赋能新时代指明方向。2016年7月习总书记明确指出，人工智能技术的发展将深刻改变人类社会生活，改变世界，应抓住机遇，在这一高技术领域抢占先机。在党的十九大报告中，习总书记强调“要推动互联网、大数据、人工智能和实体经济深度融合”。在2018年两院院士大会上，习总书记再次强调要“推进互联网、大数据、人工智能同实体经济深度融合，做大做强数字经济”。在2017年和2018年的《政府工作报告》中，李克强总理都提到了要加强新一代人工智能发展。2017年7月，国务院发布了《新一代人工智能发展规划》，将新一代人工智能放在国家战略层面进行部署，描绘了面向2030年的我国人工智能发展路线图，旨在构筑人工智能先发优势，把握新一轮科技革命战略主动，人工智能将成为今后一段时期的国家重大战略。发改委、工信部、科技部、教育部、中央网信办等国家部委和北京、上海、广东、江苏、浙江等地方政府都推出了发展人工智能的鼓励政策。\n\n二是态势喜人。根据2017年爱思唯尔（Elsevier）文献数据库SCOPUS统计结果，我国在人工智能领域发表的论文数量已居世界第一。从2012年开始，我国在人工智能领域新增专利数量已经开始超越美国。据清华大学发布的《中国人工智能发展报告2018》统计，我国已成全球人工智能投融资规模最大国家，我国人工智能企业在人脸识别、语音识别、安防监控、智能音箱、智能家居等人工智能应用领域处于国际前列。近两年，清华大学、北京大学、中国科学院大学、浙江大学、上海交通大学、南京大学等高校纷纷成立人工智能学院。2015年开始的中国人工智能大会（CCAI）已连续成功召开四届、规模不断扩大，人工智能领域的教育、科研与学术活动层出不穷。\n\n三是差距不小。我国人工智能在基础研究、原创成果、顶尖人才、技术生态、基础平台、标准规范等方面距离世界领先水平还存在较大差距。英国牛津大学2018年的一项研究报告指出中国的人工智能发展能力大致为美国的一半水平。目前我国在人工智能前沿理论创新方面总体上尚处于“跟跑”地位，大部分创新偏重于技术应用，存在“头重脚轻”的不均衡现象。在Top700全球AI人才中，中国虽然名列第二，但入选人数远远低于占一半数量的美国。据领英《全球AI领域人才报告》统计，截至2017年一季度全球人工智能领域专业技术人才数量超过190万，其中美国超过85万，我国仅超过5万人，排名全球第7位。2018年市场研究顾问公司Compass Intelligence对全球100多家AI计算芯片企业进行了排名，我国没有一家企业进入前十。另外，我国人工智能开源社区和技术生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。我国参与制定人工智能国际标准的积极性和力度不够，国内标准制定和实施也较为滞后。我国制定完善人工智能相关法律法规的进程需要加快，对可能产生的社会影响还缺少深度分析。\n\n四是前景看好。我国发展人工智能具有市场规模、应用场景、数据资源、人力资源、智能手机普及、资金投入、国家政策支持等多方面的综合优势，人工智能发展前景看好。全球顶尖管理咨询公司埃森哲于2017年发布的《人工智能：助力中国经济增长》报告显示，到2035年人工智能有望推动中国劳动生产率提高27%。我国发布的《新一代人工智能发展规划》提出到2030年，人工智能核心产业规模超过1万亿元，带动相关产业规模超过10万亿元。在我国未来的发展征程中，“智能红利”将有望弥补人口红利的不足。\n\n人类社会已开始迈入智能化时代，人工智能引领社会发展是大势所趋，不可逆转。经历六十余年积累后，人工智能开始进入爆发式增长的红利期。伴随着人工智能自身的创新发展和向经济社会的全面渗透，这个红利期将持续相当长的时期。现在是我国加强人工智能布局、收获人工智能红利、引领智能时代的重大历史机遇期，如何在人工智能蓬勃发展的浪潮中选择好中国路径、抢抓中国机遇、展现中国智慧需要深入思考。\n\n（一）树立理性务实的发展理念。围棋人机大战中阿尔法狗战胜李世石后，社会大众误以为人工智能已经无所不能，一些地方政府、社会企业、风险资金因此不切实际一窝蜂发展人工智能产业，一些别有用心的机构则有意炒作并通过包装人工智能概念来谋取不当利益。这种“一拥而上、一哄而散”的跟风行为不利于人工智能的健康可持续发展。任何事物的发展不可能一直处于高位，有高潮必有低谷，这是客观规律。根据高德纳咨询公司发布的技术发展曲线，当前智能机器人、认知专家顾问、机器学习、自动驾驶等人工智能热门技术与领域正处于期望膨胀期，但是通用人工智能及人工智能的整体发展仍处于初步阶段，人工智能还有很多“不能”，实现机器在任意现实环境的自主智能和通用智能仍然需要中长期理论和技术积累，并且人工智能对工业、交通、医疗等传统领域的渗透和融合是个长期过程，很难一蹴而就。因此发展人工智能不能以短期牟利为目的，要充分考虑到人工智能技术的局限性，充分认识到人工智能重塑传统产业的长期性和艰巨性，理性分析人工智能发展需求，理性设定人工智能发展目标，理性选择人工智能发展路径，并务实推进人工智能发展举措，只有这样才能确保人工智能健康可持续发展。\n\n（二）加强基础扎实的原创研究。人工智能前沿基础理论是人工智能技术突破、行业革新、产业化推进的基石。在此发展的临界点，要想取得最终的话语权，必须在人工智能基础理论和前沿技术方面取得重大突破。根据2017年爱思唯尔文献数据库SCOPUS统计结果，尽管我国在人工智能领域发表的论文数量已经排名世界第一，但加权引文影响力则只排名34位。为了客观评价我国在人工智能基础研究方面的整体实力，我们搜索了SCI期刊、神经信息处理系统大会（Conference on Neural Information Processing Systems，简称NIPS）等主流人工智能学术会议关于通用智能、深度学习、类脑智能、脑智融合、人机博弈等关键词的论文统计情况，可以清楚看到在人工智能前沿方向中国与美国相比基础实力存在巨大差距：在高质量论文数量方面（按中科院划定的SCI一区论文标准统计），美国是中国的5.34倍（1325:248）；在人才储备方面（SCI论文通讯作者），美国是中国的2.12倍（4804:2267）。\n\n我国应对标国际最高水平，建设面向未来的人工智能基础科学研究中心，重点发展原创性、基础性、前瞻性、突破性的人工智能科学。应该鼓励科研人员瞄准人工智能学科前沿方向开展引领性原创科学研究，通过人工智能与脑认知、神经科学、心理学等学科的交叉融合，重点聚焦人工智能领域的重大基础性科学问题，形成具有国际影响力的人工智能原创理论体系，为构建我国自主可控的人工智能技术创新生态提供领先跨越的理论支撑。\n\n（三）构建自主可控的创新生态。美国谷歌、IBM、微软、脸书等企业在AI芯片、服务器、操作系统、开源算法、云服务、无人驾驶等方面积极构建创新生态、抢占创新高地，已经在国际人工智能产业格局中占据先机。我国人工智能开源社区和技术创新生态布局相对滞后，技术平台建设力度有待加强，国际影响力有待提高。美国对中兴通讯发禁令一事充分说明自主可控“核高基”技术的重要性，我国应该吸取在核心电子器件、高端通用芯片及基础软件方面依赖进口的教训，避免重蹈覆辙，着力防范人工智能时代“空心化”风险，系统布局并重点发展人工智能领域的“新核高基”：“新”指新型开放创新生态，如军民融合、产学研融合等；“核”指核心关键技术与器件，如先进机器学习技术、鲁棒模式识别技术、低功耗智能计算芯片等；“高”指高端综合应用系统与平台，如机器学习软硬件平台、大型数据平台等；“基”指具有重大原创意义和技术带动性的基础理论与方法，如脑机接口、类脑智能等。\n\n另外，我们需要重视人工智能技术标准的建设、产品性能与系统安全的测试。特别是我国在人工智能技术应用方面走在世界前列，在人工智能国际标准制定方面应当掌握话语权，并通过标准实施加速人工智能驱动经济社会转型升级的进程。\n\n（四）建立协同高效的创新体系。我国经济社会转型升级对人工智能有重大需求，但是单一的创新主体很难实现政策、市场、技术、应用等方面的全面突破。目前我国学术界、产业界、行业部门在人工智能发展方面各自为政的倾向比较明显，数据资源开放共享不够，缺少对行业资源的有效整合。相比而言，美国已经形成了全社会、全场景、全生态协同互动的人工智能协同创新体系，军民融合和产学研结合都做得很好。我国应在体制机制方面进一步改革创新，建立“军、政、产、学、研、用”一体的人工智能协同创新体系。例如，国家进行顶层设计和战略规划，举全国优势力量设立军事智能的研发和应用平台，提供“人工智能+X”行业融合、打破行业壁垒和行政障碍的激励政策；科技龙头企业引领技术创新生态建设，突破人工智能的重大技术瓶颈；高校科研机构进行人才培养和原始创新，着力构建公共数据资源与技术平台，共同建设若干标杆性的应用创新场景，推动成熟人工智能技术在城市、医疗、金融、文化、农业、交通、能源、物流、制造、安全、服务、教育等领域的深度应用，建设低成本高效益广范围的普惠型智能社会。\n\n（五）加快创新人才的教育培养。发展人工智能关键在人才，中高端人才短缺已经成为我国人工智能做大做强的主要瓶颈。另外，我国社会大众的人工智能科技素养也需要进一步提升，每一个人都需要去适应人工智能时代的科技浪潮。在加强人工智能领军人才培养引进的同时，要面向技术创新和产业发展多层次培养人工智能创新创业人才。《新一代人工智能发展规划》提出逐步开展全民智能教育项目，在中小学阶段设置人工智能课程。目前人工智能科普活动受到各地学校的欢迎，但是缺少通俗易懂的高质量人工智能科普教材、寓教于乐的实验设备和器材、开放共享的教学互动资源平台。国家相关部门应高度重视人工智能教育领域的基础性工作，增加投入，组织优势力量，加强高水平人工智能教育内容和资源平台建设，加快人工智能专业的教学师资培训，从教材、教具、教师等多个环节全面保障我国人工智能教育工作的开展。\n\n（六）推动共担共享的全球治理。人工智能将重塑全球政治和经济格局，发达国家通过人工智能技术创新掌控了产业链上游资源，难以逾越的技术鸿沟和产业壁垒有可能将进一步拉大发达国家和发展中国家的生产力发展水平差距。美国、日本、德国等通过人工智能和机器人的技术突破和广泛应用弥补他们的人力成本劣势，希望制造业从新兴国家回流发达国家。目前看，我国是发展中国家阵容中唯一有望成为全球人工智能竞争中的领跑者，应采取不同于一些国家的“经济垄断主义、技术保护主义、贸易霸凌主义”路线，尽快布局构建开放共享、质优价廉、普惠全球的人工智能技术和应用平台，配合国家“一带一路”战略，向亚洲、非洲、南美等经济欠发达地区输出高水平、低成本的“中国智造”成果、提供人工智能时代的中国方案，为让人工智能时代的“智能红利”普惠人类命运共同体做出中国贡献！\n\n（七）制定科学合理的法律法规。要想实实在在收获人工智能带来的红利，首先应保证其安全、可控、可靠发展。美国和欧洲等发达国家和地区十分重视人工智能领域的法律法规问题。美国白宫多次组织这方面的研讨会、咨询会；特斯拉等产业巨头牵头成立OpenAI等机构，旨在以有利于整个人类的方式促进和发展友好的人工智能；科研人员自发签署23条“阿西洛马人工智能原则”，意图在规范人工智能科研及应用等方面抢占先机。我国在人工智能领域的法律法规制定及风险管控方面相对滞后，这种滞后局面与我国现阶段人工智能发展的整体形势不相适应，并可能成为我国人工智能下一步创新发展的一大掣肘。因此，有必要大力加强人工智能领域的立法研究，制定相应的法律法规，建立健全公开透明的人工智能监管体系，构建人工智能创新发展的良好法规环境。\n\n（八）加强和鼓励人工智能社会学研究。人工智能的社会影响将是深远的、全方位的。我们当未雨绸缪，从国家安全、社会治理、就业结构、伦理道德、隐私保护等多个维度系统深入研究人工智能可能的影响，制定合理可行的应对措施，确保人工智能的正面效应。应大力加强人工智能领域的科普工作，打造科技与伦理的高效对话机制和沟通平台，消除社会大众对人工智能的误解与恐慌，为人工智能的发展营造理性务实、积极健康的社会氛围。\n\n六、结束语\n\n人工智能经过60多年的发展，进入了创新突破的战略机遇期和产业应用的红利收获期，必将对生产力和产业结构以及国际格局产生革命性影响，并推动人类进入普惠型智能社会。但是，我们需要清醒看到通用人工智能及人工智能的整体发展仍处于初级阶段，人工智能不是万能，人工智能还有很多“不能”。我们应当采取理性务实的发展路径，扎实推进基础研究、技术生态、人才培养、法律规范等方面的工作，在开放中创新，在创新中发展，全速跑赢智能时代，着力建设人工智能科技强国！\n\n（主讲人系中国科学院院士）\n\n编 辑： 王伟\n\n责 编： 张绍敏\n\n[<< 返回首页](../../../)\n\n#### 相关文章\n\n ', 'doi': '', 'published_date': None, 'pdf_url': '', 'url': 'http://www.npc.gov.cn/npc/c12434/c541/201905/t20190521_268525.html', 'source': 'tavily', 'categories': ['web_search'], 'keywords': [], 'citations': 0, 'references': [], 'extra': {'score': 0.9980122, 'save_path': '/home/qinshan/widthresearch/data/downloads/tavily_人工智能的创新发展与社会影响 - 中国人大网.md'}}
