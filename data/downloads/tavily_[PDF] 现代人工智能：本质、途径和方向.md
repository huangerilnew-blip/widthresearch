现代人工智能：本质、途径和方向 张志华 北京大学数学科学学院，北京市海淀区颐和园5 号 100871 摘要：现代人工智能是通过机器学习及由其而发展起来的计算机视觉、自然语言处 理和语音识别技术来实现多模态数据融合的现实交互。数学上，人工智能是试图求 解具有组合结构的高维复杂问题，从而如何克服维数诅咒而利用维数祝福，核心要 素在于解决表示、计算和对齐问题。人工智能主要处理识别、决策和生成三大任 务，这和机器学习的三大学习范式有监督学习、强化学习和无监督学习相一致。推 断思维和算法思维相结合是研究问题途径，而利用数据的分布信息和问题的结构信 息可以有效帮助我们分析和设计算法。该篇文章将试图讨论了现代人工智能的本 质、技术路线以及一些未来研究方向。 一、引言 AlphaGo、AlphaFold、ChatGPT 和Sora 等人工智能产品相继发布震动了整个科技界， 同时由于其将可能给普通大众的生活带来深刻的影响，也引起了社会各界的广泛关注和讨 论。以多模态异构数据为基座的通用人工智能技术成为现实的趋势越来越大。人工智能是 指系统或智能体试图模拟或拥有人类的行为、思维和智能，虽然有不同途径期望通向人工 智能，但这里我们只关注数学和工程相结合的技术路线。在这篇文章，我主要阐述下面几 个内容：第一，现代的人工智能的本质是什么。第二，现在人工智能的一些主要的研究思 路和途径。第三，将讨论一些可能的研究方向。最后是回顾和总结。 二、人工智能的本质 首先，我们自然会问人工智能基础性的问题：什么是智能？《人工智能现代方法》 [1]一书从两种维度来定义智能，即人与理性，思想与行为。两个维度就有四种组合。但 是就我们现在所看到的人工智能技术，我更愿意把它定义为模拟人的行为和思维的信息处 理系统。因此我们主要关注是：计算机和统计学深度融合的数据科学方法，以及数学和工 程相结合的机器学习技术。 我们知道，图灵测试被广泛用于智能测试，但这是对智能的一种定性描述，迄今为止 并没有一种对智能的定量描述。所以我们设想，“智能”是否存在一种定量的、严谨的数 学定义，比如，象熵是一种用来量化不确定性的严格数学定义一样。或者，模仿统计学中 的p-value，给出智能的一种度量。我们知道，不同的p-value 可以反映对于假设检验结 果证据的度量。最近我们看到，出现了一些像无人驾驶一样对智能分级的定义，像 DeepMind 就提出来AGI(Artificial General Intelligence，通用人工智能)的一种分级 的定义。但现在我反而觉得，定性的描述并不见得是坏事，定量描述反而有可能把智能给 束约了，而定性描述则有可能让智能无远弗届，更富有遐想，更富有创造性。 图1：人工智能的发展历程 其次，我们来回顾人工智能的发展历程[1]。人工智能从1952 年发展到现在，可以把 它划分为下面几个时期：概念人工智能、玩具人工智能、统计人工智能、真实人工智能、 通用人工智能。第一个时期是诞生期，也就是人工智能概念的提出。第二个时期用直接的 搜索方式实现人工智能玩具任务。第三个时期尝试着解决较为复杂任务，是它的崛起期， 以基于规则的学习或者专家系统为代表，对应着计算机科学中的数据结构与算法发展。然 后是连接主义思想提出，神经网络模型兴起，但是由于计算机能力的限制，神经网络在这 时期很快地落入了低谷，被基于核技术(kernel trick)的支撑向量机所取代，由此统计机 器学习方法复兴，即利用统计数据加算法的思想来发展人工智能。在2010 年左右，大数 据驱动的深度神经网络崛起产生了革命性的突破。从2020 年到现在，又涌现了基于生成 模型的通用人工智能，这导致了人工智能发展的新阶段。 从人工智能发展历程，我们可以从两个角度来分析。第一，我们发现整个人工智能的 发展可以看成怎么解决搜索问题的过程，开始是利用暴力搜索，而后希望采取高级搜索来 寻找精确解。因为我们面临的要解决的问题会越来越复杂，寻找精确解不太可行，只好采 取近似搜索的方法。所以使用优化算法，随机算法，以及更为广泛的学习方法。第二，从 如何处理知识表示的角度看待人工智能，这触及到了人工智能的本质。基于规则学习是期 望把人类对事物的理解形式化，从而机器能够有效和人类认知对齐而达到智能的目的。迄 今为止这个路径没有获得成功，大家转而采取较为可行的数据统计的方法，即用统计数据 来代表知识表示，然后在数据上面运行算法。而深度神经网络则被发现提供了一个统计数 据和系统的认知对齐的表示，使得系统可以更为有效地进行端对端学习。强化学习则被用 来把系统的输出结果同人类的价值对齐。 我们看到技术思路的改变对人工智能的发展起到了关键作用。这种思路的转变也存在 于其他领域，产生了一个非常有趣的异曲同工现象。比如，模式识别、自然语言处理、语 音识别、视觉处理等都利用统计方法获取了巨大的成功，此外，从统计学的数据建模到计 算机的算法建模兴起，而人工智能则从机器学习中找到到了新的可行路径。 根据人工智能的发展历史，我们可以来总结人工智能实际在做什么。我理解，人工智 能主要是要处理三个任务：识别（我们可以把识别看做搜索的一个高级形态），决策和生 成。而这个三个任务刚好又和机器学习的三大学习范式：有监督学习、强化学习和无监督 学习是相一致的。实现人工智能的关键主要包含三个技术要素：表示、计算和对齐。 现代人工智能技术我认为大致可以分成两个主要代表性方式。第一，以OpenAI 大语 言生成模型为代表的通用智能系统。第二，以DeepMind 为代表的科学研究的赋能范式， 即科学研究的自动化方法。 第一个方式包括大模型构架、数据和算法等。大语言模型主要利用语言数据，而现在 则希望使用语言、图像和音频等融合的多模态异构数据。考虑到，计算机视觉、自然语言 处理和语音识别等也是由机器学习发展起来的。所以，现代人工智能可以理解成是通过机 器学习及由其驱动而发展起来的计算机视觉、自然语言处理和语音识别等技术来实现多模 态数据的现实交互。 至于科学研究的赋能范式,DeepMind 或谷歌及其合作机构等最近做出了一系列突破性 的代表工作。比如，利用强化学习寻找矩阵相乘中利用加法运算来代替乘法运算[2]，从 而达到使用尽可能小的乘法运算的目的。这实际是个搜索匹配问题。第二个是蛋白质结构 预测AlphaFold [3]，它是在一个三维空间，或者在某个坐标系框架里，找到氨基酸序列 的一个坐标对应，当然这里需要满足氨基酸序列原有的结构信息，因此，是在一个约束体 系里找到一个位置对应。第三个是芯片设计[4]。这是一个序贯的决策或者一个有顺序关 系的排列组合问题。此外，在数学研究中通过AI 辅助去找到一些证明启示或新的数学规 律[5,6],以及欧几里得平面几何数学问题的自动化证明[7]。 从这几个例子我们可以归纳：人工智能可以描述为如何求解具有组合结构的高维复杂 问题。第一，问题有组合或离散结构的，比如，对应关系、顺序关系、或稀疏特性等。第 二，它是高维的，通常规模也很大。我们需要从满足这种结构的不同组合中找到一个最佳 的方案或者代价最小的解。这是人工智能的数学上的一个描述，因此，重点是如何解决维 数诅咒和规模可扩展性问题。 三、人工智能的途径 正如前面所说的，人工智能蕴含的关键数学问题可以描述为如何求解具有组合结构的 高维复杂问题。为了求解问题，有两个里程碑的思想被提出。一是引入了不确定性。因为 我们面对的问题无论是规模和维度都是巨大的，求其精确解是不可行的，因此近似解是一 种必然。不确定性机制可以为寻找有效的近似解提供潜在途径，比如Monte Carlo 树搜索 和强化学习在AlphaGo 中的成功应用。不确定性产生了众所周知的“探索与利用”权衡问 题。二是数据驱动方法。这是因为数据的获取变得容易，且规模越来越大，同时数据表示 和处理的算法不断在进步，比如深度神经网络的崛起。数据驱动方法则伴随着“信息与计 算”权衡问题。 总的来说，是把不确定性和数据驱动这两种思路融合在一起来求解高维复杂的问题。 本质上，我们是要利用机器学习方法。机器学习是从数据中得出结论的算法。因此我们希 望数据尽可能多，希望知道数据的内在统计性质或者统计分布。在数据或者信息层面，数 据越多，越可能理解数据潜在的分布。在计算方面，有了数据，我们就在其上运行算法做 推理。所以这里就存在一个统计有效性和计算有效性之间的权衡。 所以人工智能的关键科学问题，我们可以概括为：第一，我们希望要设计尽可能高效 地使用我们的资源信息和计算的算法，从而为实际问题提供一种可行的解决方案。第二， 我们希望了解何时信息和计算有效的算法是不存在的，也就是建立不可行的结果，即算法 的应用边界。 具体来说，我们要面对很多问题：首先是学习的误差。也就是什么样的规模能达到什 么样的精度。然后是在迭代的时候能不能找到一个最优解，最优解的收敛率是什么。我们 往往采取分布式的计算方式，所以还有计算、通讯等问题。另外大家普遍关注隐私问题、 公平性问题、偏见性问题等。 我们要从样本有效性和计算有效性两方面来研究这些问题。样本有效性推断是统计学 的一个经典主题，而计算有效算法是计算机科学研究的核心课题。但是现在我们是要把这 两者结合在一起，而不是把他们孤立地研究。 从算法的角度，问题的结构是很重要的，数据的分布也是很重要的。所以我们尽可能 要利用问题的结构，同时也要利用数据的分布信息，利用两者来设计算法。采用离散的和 连续的、全局的和局部的、对抗的和合作的等这些更现代的观点来设计和分析算法，这也 可能会带来一些新的洞察。 让我们来看看机器学习。机器学习起源于计算机科学，但它跟统计学是一脉相承的, 都是利用算法从数据中得出结论[8]。经典统计学偏重于方法论的提出，而机器学习则重 于计算工具的开发。机器学习更关注分类或者聚类，即它的关注侧重离散问题。而统计学 侧重于回归或者密度估计等连续问题。现代机器学习和统计学通常要通过一个优化算法来 求解模型，但他们和传统优化又不一样。传统的优化往往只关注于算法是否找到了最优 解，以及算法的收敛性和收敛率。但是机器学习更关注找到了一个最优解之后的模型性 能，即模型在未来数据里的泛化性。所以从这个角度可以将机器学习理解为优化和泛化的 统一。 机器学习主要有四个非常重要的因素：泛化、计算、表示和归因。泛化性是指未知数 据上的表现。对于有监督的学习，泛化性是预测的结果，而无监督学习的泛化性体现在数 据生成的质量上。所有的问题都要通过计算去求解，所以第二要素是计算。统计学家比较 关注归因，即了解到底是哪些输入特征对输出结果产生了关键的作用，从而模型具有可解 释性。 这里我把重点放在表示或表征上。因为我认为表示应该是现代机器学习或者人工智能 的核心和关键。一个好的表示有如下特征：适合预测，因为我们的目的是预测；适合于计 算，因为结果是要通过计算来获得的。如果这个表示还适合于归因，那就更好了。所以自 然地想到有两种表示：一种是比较经济性的表示，另外一种是过参数化的表示。因为通过 数据降维，经济性的表示当然会带来一些计算的便利，但可能会制约了这个模型的表示能 力。一个高维的或者过参数化模型的表示能力会强，但会带来计算上的著名维数诅咒问 题。但维数越高，表示越强，预测能力随之也越好，带来所谓的维数祝福。比如如果在低 维不能做分类，但在高维里，它往往是容易分类的。既要克服维数诅咒，又要利用维数祝 福，在这两者之间找到一种有效的解决方法是机器学习的最核心思想。 一个自然的思路是宽度表示，机器学习领域由此发展起了核方法。核方法的思想将原 始数据映射到一个高维特征空间，然后通过这个特征空间的内积运算，可以有效地避免了 高维特征上的直接计算。这个想法跟统计学的非参方法是一致的。我们知道最重要的一个 机器学习方法叫核SVM。这可以理解成宽度表示的求和模型，宽度表示的可解释性良好 的。但它是一个存粹数学上抽象起来的技术，不能够对问题的物理层面进行有效刻画，所 以它没法用于生成真实数据，如图像和语言。 所以我们想是否可以利用某种深度表示，能够达到数据的物理表示。随机森林方法是 一个最直接的深度方法。而深度神经网络作为一种数据表示技术由此而崛起。它可以解决 维数诅咒问题，同时又能对数据进行物理层面建模。 我们来回顾深度学习的一些关键技术[9]。深度学习自产生以后，开发了一些重要实 现技术，如卷积、ReLU 激活函数、ResNet、Attention、 U-type 结构的编码和解码等。 其次可以用BP 去算梯度，利用SGD 或Adam 这些方法训练参数。在稳定执行上有Dropout 和Batch Normalization 等技术。更为关键的，GPU 刚好适合深度神经网络的并行训练。 所以我们认为深度学习是目前最有效的一种把维数诅咒变为维数祝福，同时又能解决物理 建模的技术。它是通过算法的思路，而不是基于形式化的思路来做表示。 我们关注的是数据表示。但是我们同样需要注意到求解的问题本身以及求解算法也有 表示的问题。算法的表示可以理解成数学上的描述。如果一个问题能够在数学上把它表述 出来，同时对这个算法有一个数学上的表示，那么就有了解决方案。强化学习提供了这种 表示[10]。所以我们可以将强化学习理解成在问题和算法层面的一种表示技术。具体地， 它使用马尔科夫决策过程给我们提供了一种表示的数学框架，而Bellman 最优性方程提供 了求解保证，即基于不动点理论导致了的价值迭代和策略优化方法。 深度学习和强化学习构成了现代人工智能的两翼。深度学习提供了多模态数据表示的 潜在途径，而强化学习提供了一种算法的表示。深度学习还从数学角度提供了一种非常强 大的非线性逼近能力。强化学习同样体现了一种在线决策、序贯决策的思路。而深度学习 与强化学习的结合为现代人工智能赋予了巨大的可能。当然现在大家都在说人工智能可解 释性差，所以自然想到因果学习。因果学习具有一种能很好地解释内在关系的方式，所以 可以考虑引入因果学习进来。但是目前看来，因果学习并没有达到象深度学习和强化学习 那样的成功。最重要的原因是因果学习还没有解决计算可扩展性的问题。 机器学习不仅仅是算法，而且也是工程。现代人工智能的第一次大突破是在深度学习 和计算机视觉中算法和工程的相结合的巅峰之作。最近的第二次突破，则可以理解成算法 和工程在自然语言处理和强化学习结合的又一个巅峰之作。机器学习系统实际上已成为一 个非常重要的研究领域。 四、研究方向 回到学术领域，存在哪些潜在的研究方向。人工智能存在三个层面：算法、应用、基础理 论。具体地，第一，如何做？提出和开发新的模型、技术、算法和场景。AlphaGo、 AlphaFold、ChatGPT 和Sora 所包含的技术不会是终点，新的技术和算法会不断地被提 出。第二，如何用？寻找人工智能更广泛的应用，针对一些特定的应用领域或场景制定方 案。第三，为什么？分析它的运行机理。前面提到了机理应该包含探索和利用权衡、信息 和计算权衡、以及统计有效性和计算有效性之间的权衡等基础性问题。为理解问题的计算 属性、统计属性和科学属性之间差异提供洞察。现在我尝试给出一些更为具体的研究方向 或问题。 基于数据驱动的人工智能算法。首先，我们更希望是混合的数据驱动方法，结合随机和对 抗的思想，能更好地适应信息约束和目标结构的信息。此外，一方面我们希望计算数据规 模很大，但如果存储全部数据则是不可行的。所以我们希望利用在线的方法或更为一般的 自适应方法更有效地利用数据。我认为有几点特别值得关注：第一是高维随机优化的统计 推断。第二是高维随机在线算法。我们一般认为随机或者在线的算法主要是来解决数据量 的问题，更为挑战的是如何去设计一些高效的算法来处理高维且数据量大的问题。第三是 高维采样，在我们面对高维或离散问题时，比如在扩散生成模型中，如何利用蒙特卡罗等 方法找到一个有效的采样方法。第四是分布或鲁棒马尔科夫决策过程。第五是算法的下界 理论分析，刚才说过，给定了有效的资源或算力时，能否给出算法的下界，从而避免不必 要的失败尝试。理论计算机界正试图建立不同下界分析方法之间的内在联系，从而 希望可以形成一个统一的分析框架。 大语言模型的一些重要问题。第一是基础模型的结构和训练算法，现在模型普遍采用 Transformer，训练算法采用AdamW，有可能存在其他更好模型和算法。第二，制约我国人 工智能发展最重要的问题是中文语言的数据质量和中文分词技术，我们现在很多时候直接 套用英文分词技术到在中文上，因为中文有自己的特性，这肯定是不能完全适用的。当然 还有对齐和精调、模型的评估等。我们同样需要关注大模型的机理，我们知道的scaling law、压缩理论是大模型的一些值得关注的基本问题。最后，一般研究机构是没有能力来 搭建大语言模型，所以当然会想到要研究小型化模型，只有小型化才能使其具有更大的实 用性。此外，我们可能看到新闻，Richard Sutton 等人打算利用在线的思路构架通用智能 系统，因为在线可以避免大数据的存储和计算代价。 强化学习的一些重要问题。我们知道强化学习在游戏类的应用非常成功，因为游戏问题的 规则非常明确。而面对实际的应用问题，虽然在大语言模型中强化学习可能有很大的作 用，但在很多问题中强化学习的潜力远远没有被挖掘出来。所以我认为强化学习有以下几 点值得关注：第一是能否开发出并行化的计算框架。强化学习是一个序贯决策过程，天然 和并行不相配。但是只有并行才能够从根本上解决其计算瓶颈。第二是稳定性良好的策略 优化算法。强化学习需要随机采样，所以其算法稳定性是非常重要的课题。第三，强化学 习一般有交互的过程，搭建通用友好的模拟平台很重要。当然最重要的是深度强化学习的 更广泛地应用。 扩散生成模型的一些重要问题。扩散生成模型是目前最活跃的AIGC 方向。我认为值得研 究的方向首先是多模态数据生成。目前单一数据生成较为成熟，但多模态数据生成仍有待 研究。第二是扩散生成模型的性能和训练不稳定性，这是一个很重要的研究方向。第三是 扩散模型怎样去和大语言模型相结合。 最后我想谈一点富有远景的研究方向。我们可以回顾一下人工智能最近十余年的两个最重 大的突破，首先在2010 年左右，深度神经网络在视觉图像的应用产生了第一个人工智能 的里程牌突破，我把它理解为视觉+深度学习。第二里程碑工作ChatGPT 则是在前一个突 破基础上，深度强化学习在自然语言领域的成功，我理解为语言+强化学习或者多模态数 据+深度强化学习。那么我们可以思考下一个突破可能会是什么。我大胆地预测，如果要 产生真正的通用人工智能，很可能是利用贝叶斯技术来进行信念推理。贝叶斯推理包括经 验贝叶斯、概率图模型等。因为信念(belief)是更接近智能的因素，所以我认为在大语言 模型基础上信念+贝叶斯学习将值得期待，让我们拭目以待。 五、回顾和思考 著名的统计学家和机器学习主要奠基人Leo Breiman 在他著名两种文化建模论文[11] 中提出了和反思了数据建模的文化和算法建模的文化[12]。而现代人工智能则是将这两种 文化深度融合。既要数据建模，也要算法建模，是两个文化的结合而不是分叉。另外 Breiman 在文章里还提到他的三个关切：导致不相关的理论和有问题的科学结论(“Led to irrelevant theory and questionable scientific conclusion”)，阻止统计学家使用 更为合适的算法模型(“Kept statisticians from using more suitable algorithmic models”)，阻碍统计学家研究令人兴奋的新问题（“Prevented statisticians from working on exciting new problems”）。这些关切对今天我们发展人工智能仍然是真知 灼见。我们普遍将我国人工智能的发展现状归结于对数学基础的重视或数学家参与程度不 够。但我认为一定要了解人工智能和计算机领域真正关心的问题，只有真正理解其核心所 在，才能有的放矢，才能对人工智能乃至本学科起到实质性的促进作用。 人工智能和计算机领域真正关心的问题：建立模型，设计算法，揭示机理。而且他们 也是有优先级的，第一，我认为目前理论分析肯定是要次于模型的建立和计算算法的设 计。先产生效果再考虑理论，不能脱离实际效果空谈无用的理论。第二，存在性的结果总 是要小于构造性的结果。相比存在性的结果，我们更希望有构造性的算法。第三，大家总 说人工智能不可解释，但归因的解释没有模型的机理来得更重要。对于大模型而言，如果 能将其压缩理论分析清楚，这比究竟是哪个特征起作用要重要。第四，模型的机理没有科 学对齐更迫切，系统输出结果要与问题的本质属性对齐。统计属性要与科学属性相对齐， 系统的价值要与人的价值对齐。 现代计算机视觉的建立者David Marr 把视觉视为一个信息处理系统，提出了理解该 系统的三个不同层次。第一个是物理和执行层次；第二是算法和表示层次；第三个层次是 计算层面。可惜天妒其才，他英年早逝，未能完成他的著作“Vision”[13]。但正如 Marvin Minsky 认为的，Marr 没有真正碰触知识表示问题，未能为他的视觉系统的知识表 示提出好的想法。他的合作者Tomaso Poggio 帮他完成了著作，Poggio 认为在计算层次上 面应该再加上一个学习层次。Marr 关于视觉的三层次的思想同样适用于人工智能，我们也 可以把人工智能看成模拟人类行为和思维的信息处理系统。它有三个层次或要素：表示、 计算和对齐。深度学习和强化学习分别在数据层面和算法层面为我们提供了有效的表示途 径。随机优化算法和计算基座等帮助解决计算问题。最近人工智能技术在对齐层次也获得 突破性进展。实际上，表示也是一种对齐，可以理解表示是把统计数据与机器系统进行对 齐。因此，人工智能是把输入的统计数据与系统的价值对齐，而把系统的输出结果与人的 价值对齐，形成了一个对齐的闭环。 最后，让我们回溯20 世纪统计学的两位主要奠基者Ronald Fisher 和Jerzy Neyman 关于归纳推理（Inductive Inference）和演绎推理（Deductive Inference）的辩论 (The Fisher-Neyman Controversy) 。Fisher 相信统计学可以具有从样本到数据的归纳推 理能力[14,15]，即外推性，而Neyman 则认为只能从数据中进行演绎推理[16]，即内插。 这个著名辩论可以帮助我们来理解大语言模型是否可能会发生涌现。特别是，我们注意到 [7]结合了两种推理来利用AI 求解奥数几何题取得了成功。我有一个很主观的看法， Neyman 是坚定的频率派大师，他认为统计过程的选择应该要基于误差的频率派概念。我们 知道虽然Fisher 也是频率学派的奠基者，但他不排斥贝叶斯，他其实也是经验贝叶斯的 开山鼻祖。贝叶斯赋予先验，利用后验信息推理，因此具有某种程度的外推能力。这也是 为什么我认为贝叶斯推断方法，特别是经验贝叶斯方法在人工智能的未来发展具有潜在作 用，值得我们关注。 总之，现代人工智能是数据建模和算法建模两种文化的深度融合，它本质上是一个模 拟人类行为和思维的信息处理系统，它试图集成归纳推理和演绎推理来让系统实现自主推 理的能力。有境界则自成高格，自有名作，学科能常青在此。当我们不解和疑惑时，可以 多读读这些经典，从中寻找启迪和灵感。空洞无物的炒作和造势或许能得到一时之利，但 再炫丽的泡沫总是要破灭的，唯思想永恒！ 参考文献 1. Stuart Russel and Peter Norvig. Artificial Intelligence: A Modern Approach (Fourth edition). Pearson, 2021. 2. Alhussein Fawzi et al. Discovering faster matrix multiplication algorithms with reinforcement learning. Nature, 610, 47-53 2022. 3. John Jumper et al. (2021). Highly accurate protein structure prediction with AlphaFold, Nature, 596, 583-589. 4. Azalia Mirhoseini et al. A Graph Placement Methodology for Fast Chip Design, Nature, Vol 594, 207-2012, 2021. 5. Alex Davies et al. Advancing mathematics by guiding human intuition with AI, Nature, Vol 600, 70-74, 2021. 6. Bernarding Romera-Paredes et al. Mathematical discoveries from program search with large language models. Nature, 1-10, 2023. 7. Trieu H. Trinh, Yuhuai Wu, Quoc V. Le, He He, and Thang Luong. Solving Olympiad geometry without human demonstrations. Nature, 625, 476-482 (2024). 8. Bradley Efron and Trevor Hastie. Computer Age Statistical Inference: Algorithms, Evidence, and Data Science. The Cambridge University Press, 2016. 9. Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. The MIT Press, 2016. 10. Richard S. Sutton and Andrew G. Barto. Reinforcement Learning (second edition). The MIT Press, 2018. 11. Leo Bregman. Statistical Modeling: The Two Cultures (with Discussion). Statistical Science, 2001. 12. Bradley Efron. Prediction, Estimation, and Attribution (with Discussion). JASA, 2020. 13. David Marr. Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. The MIT Press, 2010. 14. R A Fisher. The Logic of Inductive Inference, 1934. 15. R A Fisher. Statistical Methods and Scientific Inference, 1957. 16. Jerzy Neyman. ‘Inductive Behavior’ as a Basic Concept of Philosophy of Science, 1957.