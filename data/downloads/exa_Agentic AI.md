# Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践

**URL**:
https://aws.amazon.com/cn/blogs/china/agentic-ai-infrastructure-deep-practice-experience-thinking-series-three-best-practices-for-agent-memory-module/

## 元数据
- 发布日期: 2025-09-19T00:00:00+00:00

## 完整内容
---
Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践 | 亚马逊AWS官方博客[Skip to Main Content] 
AWS Blog
* [首页] 
* 版本## [亚马逊AWS官方博客] 
# Agentic AI基础设施实践经验系列（三）：Agent记忆模块的最佳实践
[![]] |
*本文将深入探讨 Agent**应用中的记忆需求、记忆类型、技术组件和主流开源框架，并介绍基于亚马逊云科技的数据产品自行构建记忆模块，以及基于Agent**构建平台Bedrock AgentCore**的Agent memory**的托管方案。*
## 前言### 当前大语言模型的困境大语言模型在处理和生成文本方面表现出色，但它们在本质上是**无状态（****stateless****）**的。这意味着每次与LLM的交互都是独立的，模型本身不会“记住”过去的对话或经验。大模型在“记忆”上主要局限于：
* **上下文窗口的限制导致遗忘问题。**LLM通过一个有限的“上下文窗口”（Context Window）来处理信息。所有输入（包括Prompt和之前的对话片段）都必须塞入这个窗口。一旦信息超出这个窗口，LLM就“忘记”了它，无法再访问。这导致了所谓的**“****遗忘”**问题；
* **难以处理多轮/****复杂任务。**对于需要跨越多轮对话、追踪状态或执行一系列子任务的复杂任务，LLM很难保持连贯性和进展，因为它会不断“忘记”之前的步骤和决策。特别是在Agent的场景，工具的定义和工具的返回值都会存在于上下文中，同时由于Agent具有自主工作的能力，和LLM的平均交互的轮数也大大增加；
* **无法个性化。**由于不记住特定用户的历史偏好、习惯或之前的互动，LLM难以提供真正个性化的体验。每次互动都像是第一次见面；
* **长上下文带来的性能和成本影响。推理速度变慢：**LLM在处理更长的上下文时，需要进行更多的计算来处理和理解所有输入信息。这会导致推理时间增加，响应速度变慢。**模型表现下降：**尽管LLM的上下文窗口越来越大，但研究发现，模型在超长上下文中检索关键信息的能力可能会下降。**更高的****Token****费用：**上下文越长，输入的token数量就越多，从而导致每次API调用的成本更高。对于需要频繁交互或处理大量文本的应用来说，这会迅速累积成可观的费用。### 为什么需要记忆模块记忆系统旨在克服LLM的局限性，赋予智能体以下核心能力：
* **长期保留与高效管理：**存储超出LLM上下文窗口的信息，实现高效检索和过滤，避免信息遗忘；
* **持续知识更新：**通过存储与环境和用户的交互经验，实现自我改进和知识更新；
* **个性化服务：**记录用户偏好和历史互动，提供定制化回应；
* **复杂任务支持：**追踪多Agent任务进展和中间结果，确保连贯完成并优化决策；
* **提升交互质量：**保持上下文连贯性，支持深入推理，并通过反思机制从错误中学习。## AI Agent 记忆类型智能体的记忆系统主要分为短期记忆和长期记忆两大类。### 短期记忆/工作记忆
短期记忆（Short-term Memory, STM）是智能体维护当前对话和任务的即时上下文系统，主要包括：
* **会话缓冲（Context****）记忆**：保留最近对话历史的滚动窗口，确保回答上下文相关性；
* **工作记忆**：存储当前任务的临时信息，如中间结果、变量值等。
短期记忆受限于上下文窗口大小，适用于简单对话和单一任务场景。### 长期记忆**长期记忆**（Long-term Memory, LTM）是智能体用于**跨会话、跨任务长期保存知识**的记忆形式。它对应于人类的大脑中持久保存的记忆，例如事实知识、过去经历等。长期记忆的实现通常依赖于**外部存储**或**知识库**，包括但不限于：
* **摘要记忆**：将长对话内容提炼为关键摘要存储；
* **结构化知识库**：使用数据库或知识图谱存储结构化信息；
* **向量化存储**：通过向量数据库实现基于语义的记忆检索。
长期记忆使智能体能够**随着时间累积经验和知识，**它特别适用于**知识密集型应用**和**需要长期个性化**的场景。
## 记忆管理与使用相关技术设计开发Agent的记忆系统时要考虑**不同场景下如何选择记忆内容、设计写入策略、组织记忆结构、实现检索召回**四个方面。
### 记忆产生：判断哪些信息需要被记忆在构建智能体记忆系统时，首先要根据具体的场景确定**哪些信息值得记忆**。这些记忆往往是多维度和动态的信息结构，包括**时间**维度（理解时间依赖的关系和序列）、**空间**维度（解释基于位置的和几何关系）、参与者**状态**（跟踪多个实体及其不断变化的状况）、意图**上下文**（理解目标、动机和隐含的目的），以及文化上下文（在特定社会和文化框架内解释交流）。
并非所有对话内容都需要长期保存，下面以4种常见场景举例哪些是与任务相关、对后续交互有价值的记忆要点。
对于**代码助手类的智能体**，记忆应侧重**用户项目的上下文和偏好**。包括：用户项目的**代码库结构**（文件组织、模块关系）、**命名风格**（变量命名约定、代码格式风格）、常用的**框架****/****库**以及用户以前提供的代码片段或指令等。记忆这些信息可以更贴合定制化需求和项目实际情况给出建议。例如，没有记忆支持时，开发者常常需要重复告诉 AI 项目的架构或纠正AI 偏离项目规范的行为，这非常低效。而引入**持久记忆**后，AI 可以持续参考之前存储的项目背景，”记住”用户的技术栈，从而保持技术决策的一致性。同时，代码助手还能记忆用户过往的提问和反馈，例如某段代码曾反复修改，下一次遇到类似问题时可直接调用之前的方案，避免重复推理。总之，在代码场景中，记忆系统使AI能够理解**长期的项目上下文**，提供**风格一致**且**上下文相关**的代码补全和解释。
对于**智能客服类的智能体**，记忆的重点是**用户历史和偏好**，以便提供连贯且个性化的服务。包括：用户当前**任务的状态，**提过的问题、故障、产品使用，服务配置，和解决方案记录。当用户第二次来询问类似问题时，不必重复描述自己之前的问题细节，系统能够回忆起**上次给出的建议**或已经尝试过某些步骤，直接切入重点解决当前问题。此外，记忆用户的产品使用情况和喜好（例如偏好哪种通信渠道，是否倾向自助解决）可以使响应更加贴合用户习惯。这样实现**更快的问题解决**和**更高的客户满意度，**增强对品牌的信任。
对于**个人助理**智能体，记忆重点包括：**用户个人信息和日程表**、**目标**（如健身学习计划）、经常执行的**行为模式**（如每周几锻炼）以及对应用和服务的偏好（如偏好哪种提醒方式）等。这样智能体会提醒日程，并结合过往偏好提供个性化安排（比如知道用户周五喜欢外卖，在傍晚时主动推荐餐厅）。随着交互增加，**持续的长期记忆**使智能体能**不断适应用户**，逐渐减少对用户指令的依赖，实现更**主动**和**贴心**的服务。
对于**推荐服务**智能体，记忆重点包括：**用户的显式反馈**（如用户给某本书点赞或明确表达不喜欢某商品）**和隐式反馈**（如浏览记录、点击行为、购买历史）**，**以此构建兴趣档案，在后续交互中个性化推荐。并持续学习，对过往推荐的反馈（是否点击、购买），**不断调整推荐策略，更新画像。**提高推荐转化率也增强用户忠诚度。
#### 记忆管理的实际例子以下是在一个长文档处理的Agent项目中使用的上下文压缩提示词，当上下文超过指定的限额时，将触发基于LLM的压缩机制。
```
`# Custom system prompt for document processing domain summarization
custom\_system\_prompt = """您正在总结文档处理工作流对话。创建一个简明扼要的要点摘要，该摘要：
专注于文档处理任务、章节生成和工作流进度保留特定文件路径、章节名称和任务完成状态维护待办事项列表状态和进度跟踪信息省略对话元素，专注于可操作的工作流信息使用适合文档处理和内容生成的技术术语保留错误消息和重要状态更新以要点形式呈现，不使用对话语言，按以下方式组织：文档处理：[关键处理步骤和结果]
章节生成：[已完成的章节和当前进度]
待办状态：[当前工作流状态和待处理任务]
文件位置：[重要文件路径和输出]
错误/问题：[遇到的任何问题及解决方案]
"""`
```
### 记忆策略智能体的记忆更新可通过**轮数**或**事件**触发。轮数触发是每隔3-5轮对话自动生成摘要存入记忆；事件触发则在完成任务、场景转换等关键节点记录信息。例如，客服完成问题处理时保存解决方案，个人助理更新日程后写入日历。开发者可实现监控逻辑，在对话累积或话题转换时，让大模型对近期对话生成摘要，提取关键信息并添加标签便于检索。
系统也可支持用户主动标记需要记住的信息，如通过**口头指令**或**界面**操作。这不仅让用户指定重要内容，也支持删除特定记忆的需求，确保用户对数据的控制权。
### 记忆存储：记忆组织结构设计记忆数据通常采用**用户****→****会话→****记忆片段**的三层结构管理。**用户**层区分不同账号空间，**会话**层隔离各对话上下文，**记忆片段**层存储具体内容及元数据（如时间、关键词、来源等）。复杂系统可能需要维护多个记忆库，包括短期工作记忆、长期情节记忆、语义知识库等。合理的结构设计有助于快速检索和有效管理记忆内容。
### 记忆检索：记忆查询与召回逻辑智能体需要基于当前对话意图从记忆库中检索相关信息。主要检索方法包括关**键词匹配**、**向量语义搜索**和**元数据过滤**。系统将检索到的记忆按相关度排序，选取最相关内容加入到对话上下文中，用于生成更准确的响应。例如在推荐场景中，可基于用户历史偏好记忆提供个性化建议。
## 上下文工程（Context Engineering）与记忆
### 上下文工程上下文工程与记忆系统形成共生关系，共同支撑智能体的认知能力。记忆系统作为”信息仓库”，存储历史对话、知识和用户偏好；而上下文工程则扮演”智能调度员”，决定从记忆中检索哪些信息及如何组织呈现给LLM。
上下文工程的核心在于，LLM的性能和有效性根本上取决于其接收的**上下文**。实现了上下文工程的系统一般包含三类**基础组件**：
1. **上下文检索与生成：**涵盖Prompt生成和外部知识获取；
2. **上下文处理：**涉及长序列处理、自我完善和结构化信息集成；
3. **上下文管理：**关注记忆层次、压缩技术和优化策略。
这些组件是高级应用实现（如RAG、显式记忆系统和智能体系统）的基石。由此，我们可以将上下文工程定义为：上下文工程将上下文C重新概念化为一组动态结构化的信息组件，c1, c2, …, cn。这些组件由一组函数进行来源获取、过滤和格式化，最终由高级组装函数A进行编排。
### 上下文工程与记忆的关系上下文工程与记忆系统**紧密且共生**，都是AI智能体的重要构建手段。一方面**，记忆是上下文的****“****仓库”****，**智能体的记忆系统（如历史对话、知识库、用户偏好）是信息存储地，为LLM提供**潜在上下文**。另一方面，**上下文工程是记忆的****“****调度员”****和“****优化器”****，上下文工程**决定从记忆中检索哪些信息及如何检索，确保提取最相关的记忆片段。
### 上下文工程在项目中的例子在一个文档自动化处理生成的Agent项目中，我们面临一个关键挑战：输入文档总量超过500页，远超模型的最大Token限制，同时项目对生成内容的召回率和准确率有较高要求。
为解决这一问题，我们实施了以下上下文工程策略：1. **文档分块处理：**将大型文档集合切分为适当大小的chunks，并存储在文件系统中；
2. **摘要生成：**为每个文档块生成精炼的文字摘要，提供内容概览。并生成整个文档的摘要信息；
3. **动态上下文管理：**赋予Agent自主选择的能力，使其可以根据任务需求动态调取相关文档块；
4. **上下文优化：**任务完成后自动释放不再需要的上下文，优化资源利用。
这种方法使Agent能够在保持高准确率的同时，有效处理超过模型上下文限制的文档集合。
## 主流记忆框架分析基于上个章节介绍的设计思路，核心组件和优化策略，业界涌现了多种记忆机制的实现方案。以下我们从**开源框架（****Mem0****，MemGPT****，LangMem****以及他们与亚马逊云科技服务的集成）**和**亚马逊云科技商业解决方案（****AI Agent****构建托管服务Bedrock AgentCore****的记忆模块）**两个角度，对目前主流的Agent记忆方案进行分析，比较它们的特点、适用场景以及部署成本。
### Mem0
[Mem0] 是专为AI Agent设计的开源记忆框架，通过智能记忆管理帮助Agent实现状态持久化。它支持工作记忆、事实记忆、情景记忆和语义记忆等多种类型，提供智能的LLM提取、过滤和衰减机制，有效降低计算成本。同时支持多模态处理和Graph记忆功能，既可使用托管服务也可自建部署。
从架构来看，Mem0包含几个核心模块：**核心记忆层、大语言模型层、嵌入模型层、向量存储层、图存储层和持久化存储层**。核心记忆层是构建核心逻辑来判断新增、检索、更新和删除记忆的相应实现；大语言模型层负责根据用户输入提取出关键信息，以及生成如何更新记忆的决策；嵌入模型和向量存储层负责支持记忆的向量化存储和检索；图存储层负责存储抽取出的实体关系，丰富记忆的组织形态；持久化存储层负责存储对记忆系统的操作信息。这种分层架构设计确保了记忆系统的可扩展性和可维护性，
每层职责明确，便于针对不同场景进行优化配置。Mem0 的设计理念专注于智能记忆管理而非简单数据存储，融合了几个关键技术创新：* 双LLM 架构：系统通过两次不同的LLM 调用实现复杂的分工。第一次专注于信息提取，第二次专门处理决策过程，提高准确性并允许专门优化。* 上下文感知处理：在现有记忆上下文中分析新数据，确保记忆系统一致性和连贯性，防止碎片化并维护信息间逻辑关系。* 智能去重机制：结合向量相似性搜索与LLM判断，防止冗余信息存储，保持记忆质量和系统效率。
* 冲突解决能力：当出现矛盾信息时，智能确定保留、更新或删除的适当行动，适应用户偏好和环境的动态变化。#### Mem0与Agent框架的集成
开发者可以通过两种方式集成Mem0：一是在环境变量配置依赖信息后，直接调用Mem0的接口函数（如添加、查找、更新记忆等）；二是将Mem0封装成工具传入Agent框架，由Agent根据处理逻辑自主调用相应方法。
#### Mem0与亚马逊云科技的集成
亚马逊云科技的多项服务均支持与Mem0集成，为开发者提供完整的企业级记忆解决方案：
* 模型服务集成：支持Amazon Bedrock的多种模型，包括Claude-3.7-Sonnet用于复杂推理、Titan-Embed-Text-v2用于向量化处理。
* 存储服务集成：* 向量存储：Amazon Aurora Serverless V2 for PostgreSQL、Amazon OpenSearch
* 图数据存储：Amazon Neptune Analytics
* 开发框架集成：亚马逊云科技开源的StrandsAgent框架中内置了基于Mem0能力封装的mem0\_memory工具。
Mem0作为开源解决方案，为开发者提供了灵活的记忆管理能力。结合亚马逊云科技服务的强大生态，可以构建高性能、可扩展的Agent记忆系统，适合需要深度定制和成本优化的企业级应用场景。更多关于Mem0的深度解析以及和亚马逊云科技的服务的集成请见博客[https://amazon.awsapps.com/workdocs-amazon/index.html#/document/17faaf605c2b12a543d5b9223ec5301aca29c03ffd5f3d1f5dd929d5496471bc] 
### Letta (前身为MemGPT)
#### Letta 功能介绍Letta（前身为MemGPT）是一个专注于构建具有持续记忆能力的 AI Agent 的框架，它的设计思路是将LLM代理类比为计算机操作系统，采用”**虚拟内存**“的概念来管理智能体的记忆。其核心创新在于双层记忆架构，包括**上下文内记忆**（直接存在于模型上下文窗口中的系统指令、可读写记忆块和当前对话）和**上下文外记忆**（存储历史对话和外部知识的长期存储）。当上下文窗口接近填满时，系统会自动将对话历史压缩为递归摘要并存储为记忆块，同时保留原始对话供后续检索，通过工具如core\_memory\_append、core\_memory\_replace 和recall 实现记忆的编辑与检索，从而使AI 代理能够在长期交互中保持连贯性，真正实现记住过去、学习新知并随时间演化的能力。#### Letta与亚马逊云科技生态的深度集成
Letta可无缝对接亚马逊云科技服务栈，以下是一个通过 Letta 框架搭建的电商客服机器人问答流程示例：* 使用Amazon Bedrock 的Claude 或Titan 模型作为基础LLM
* 采用Amazon PostgreSQL、OpenSearch 作为向量存储后端* 利用ElastiCache 缓存来提升推理（框架原生支持）、问答等场景（需要搭建缓存中间件）的效率* 通过亚马逊云科技Lambda 实现记忆管理的无服务器架构[![]] |
图1. 通过Letta 框架搭建的电商客服机器人问答流程示例**LangMem**
LangMem 是由LangChain 开发的，旨在解决AI 代理的”健忘症”问题。传统的大语言模型在会话结束或上下文窗口被超出时会丢失之前的交互信息，而LangMem 为AI 代理提供了长期记忆能力，使其能够跨会话保持知识连续性，记住用户的偏好、过往交互和重要事实。这一创新将AI 代理从简单的反应系统转变为能够随时间学习和适应的动态助手。例如：你的AI 助手能够记住你上周提到的项目细节，了解你的工作习惯，甚至记得你喜欢的咖啡类型。LangMem 框架的设计理念是借鉴人类心理学对记忆的分类，为Agent设计了三种核心记忆类型，每种类型都有其独特的功能和应用场景。
* **语义记忆 (Semantic Memory)****：**语义记忆是 Agent 的知识基础，存储客观事实、用户偏好和基础知识，作为长期持久化记忆嵌入系统提示中，可通过Collection 方式保存完整历史信息，或通过Profile 方式只保留最新状态，为Agent 提供稳定的知识支撑，确保其能够准确理解和回应用户需求。* **情节记忆（Episodic Memory****）：**捕捉 Agent 的交互经历，不仅存储对话内容，还包含完整上下文和推理过程，作为短期记忆主要用于构建用户提示词，使Agent 能够从过往经验中学习，参考成功案例调整响应策略，从而在类似情境中提供更加个性化和有效的解决方案。* **程序记忆 (Procedural Memory)****：**专注于”如何做”的实操知识，从初始系统提示开始，通过持续反馈和经验积累不断优化，作为短期记忆帮助 Agent 学习最有效的行为模式，既可用于系统提示也可用于用户提示，使Agent 能够根据不同情境灵活调整策略，提高解决问题的效率和准确性。LangMem 不仅能存储对话中的重要信息，还能优化提示和行为，在多次交互后提供更连贯、个性化的响应。它消除了传统AI 代理在会话结束后丢失上下文的问题，减少了重复询问用户已提供信息的需要，显著提升了用户体验的连贯性和个性化程度。LangMem 提供通用存储兼容性和热路径内存工具，使AI代理能在实时会话中即时保存和检索信息。其智能后台内存管理功能自动提取、汇总并更新知识库，且与 LangGraph 平台无缝集成。LangMem 的高级特性包括**主动记忆管理、共享内存机制、命名空间组织和个性化持续进化**能力，使 AI Agent 能根据重要性动态存储信息，支持多个Agent 之间的知识共享，高效组织检索信息，并不断适应用户需求变化，提供越来越精准的服务。目前LangMem 主要是与LangGraph 集成，支持Amazon Bedrock。在记忆存储层面，针对开发场景，有内置的 InMemoryStore，支持快速的迭代、测试和原型设计；另外，提供对 PostgresqlSQL 的支持。对于其他记忆存储引擎，LangMem 提供开放的接口实现方式，需要用户定制开发集成。### Amazon Bedrock AgentCore Memory：亚马逊云科技的托管记忆解决方案
相比开源框架，亚马逊云科技也提供**开箱即用的托管服务**，通过AI Agent构建平台Bedrock AgentCore中的记忆模块帮助开发者更快捷地为AI Agent赋能记忆功能。您无需运维任何底层资源，只需一键即可集成业界领先的记忆系统。
[![]] |
图2-Bedrock AgentCore中的记忆模块核心功能展示
Amazon Bedrock AgentCore 的Memory 模块是一个由亚马逊云科技托管的持久化记忆系统，用于存储和管理AI Agent 的对话和知识。它提供**短期记忆（****short-term memory****）和长期记忆（long-term memory****）**两种模式。短期记忆负责在一次会话中记录最近的最近几轮对话，确保代理能够“记住”当前对话的上下文。长期记忆则从对话中提取结构化的关键信息，在多个会话之间保留知识，使Agent能够“学习”用户偏好、事实和摘要等信息。
**记忆的存储**
Memory 模块在架构上采用分层存储策略：短期记忆层存储原始交互事件作为即时上下文，长期记忆层存储从事件提取的概要知识。Memory 服务背后实现了自动的信息处理流水线：当新的事件被存储时，如果Memory 配置了长期记忆策略，服务会异步地对事件内容进行分析（例如调用基础模型）来提炼出可长期保存的知识片段。AgentCore Memory 内置了多种记忆策略（Memory Strategy）来定义如何将原始对话转化为结构化长期记忆。例如：
* **SemanticMemoryStrategy**（语义记忆策略）：从对话中抽取出**事实和知识**，以便日后查询。
* **SummaryMemoryStrategy**（摘要策略）：为每个会话生成**对话摘要**，提炼主要内容。
* **UserPreferenceMemoryStrategy**（用户偏好策略）：捕获用户的偏好、风格和重复选择等信息。
使用内置策略时，无需额外配置模型，AgentCore Memory 服务会在后台使用预置的模型来完成提取和归纳。当开发者调用CreateEvent 保存新事件后，这些策略会被自动触发，异步运行LLM分析内容并产生长期记忆记录（memory records）。长期记忆记录生成后存储于 Memory 中，对应特定的命名空间和类型（如事实、摘要、偏好），每条记录也有唯一ID以供检索。
此外，AgentCore 允许**自定义记忆策略（****CustomMemoryStrategy****）**，开发者可提供自定义的提示词（prompt）和选择特定的基础模型来执行记忆提取，例如只提取某类domain知识。



---
*数据来源: Exa搜索 | 获取时间: 2026-02-10 21:59:05*