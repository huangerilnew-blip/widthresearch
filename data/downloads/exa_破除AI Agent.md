# 破除AI Agent自主操控风险：万字解读LangGraph“人工干预”机制

**URL**:
https://zhuanlan.zhihu.com/p/1983908115285046678

## 元数据
- 发布日期: 2026-02-20T20:40:07.476428

## 完整内容
---
破除AI Agent自主操控风险：万字解读LangGraph“人工干预”机制 ，附零基础实战- 知乎[] 
​[直答] 
切换模式登录/注册
# 破除AI Agent自主操控风险：万字解读LangGraph“人工干预”机制 ，附零基础实战[![腾讯技术工程]] 
[腾讯技术工程] [​![]] 
编程话题下的优秀答主作者：yukixxwang
随着大型语言模型（LLM）驱动的自主代理（Agent）从学术走向应用，如何确保其行为的可靠性、安全性与可控性，已成为决定其能否在真实世界关键任务中落地的核心挑战。大语言模型能力虽然越来越强，但并非完美无缺，可能产生错误或不准确输出。当一个 Agent 被授权执行高风险领域或敏感操作时，一个小小的错误也可能带来不可预知的风险。所以我们需要“人工干预”机制，在关键决策点让Agent 停下来，将控制权交还给人类，让人类的智慧能够介入，弥补模型的不足。**引言**
随着大型语言模型（LLM）驱动的自主代理（Agent）从学术走向应用，如何确保其行为的可靠性、安全性与可控性，已成为决定其能否在真实世界关键任务中落地的核心挑战。大语言模型能力虽然越来越强，但并非完美无缺，可能产生错误或不准确输出。当一个 Agent 被授权执行高风险领域或敏感操作时，一个小小的错误也可能带来不可预知的风险。所以我们需要“人工干预”机制，在关键决策点让Agent 停下来，将控制权交还给人类，让人类的智慧能够介入，弥补模型的不足。**全文概览**
在介绍Multi-agent的人工干预机制之前，我们先简单介绍Multi-Agent的基本概念：定义、主流开发框架、人工干预。之后我们会着重以LangGraph为例，介绍LangGraph的人工干预机制的核心原理、四大经典模式、 以及具体的案例实践。在案例实践中，我们除了介绍LangGraph的四大经典模式案例之外，还通过MCP协议提供的智能搜索工具（Venus MCP server市场 - 网络综合搜索工具）搭建了真实案例来帮助大家理解LangGraph的中断机制。
**什么是Multi-Agent？**
简单来说，Multi-Agent（多智能体）系统不是由一个“无所不知”的超级AI来解决所有问题，而是由多个具有特定角色和能力的、相对简单的自主智能体（Agent）协同工作，共同完成一个复杂任务的系统。这些智能体各自有自己的专长（通过不同的Prompt、工具和知识库来定义），它们之间可以沟通、协作、互相反馈、甚至辩论，最终合力交付一个高质量的成果。
核心特征：●分解(Decomposition): 将一个宏大、模糊的任务分解成多个具体、可执行的子任务。●专长(Specialization): 每个智能体都有明确的角色和擅长的技能（例如，一个智能体专门用于网络搜索，另一个专门用于代码执行）。●协作(Collaboration): 智能体之间通过信息交换（类似内部聊天）来协调工作。例如，程序员写完代码后交给测试员。●自主性(Autonomy): 每个智能体可以在其职责范围内独立做出判断和执行操作，无需人类每一步都进行干预。**Multi-Agent主流开发框架**
随着LLM（大型语言模型）的发展，多智能体框架也迎来了爆发式增长。它们封装了智能体定义、通信、任务调度等复杂逻辑，让开发者能更专注于业务逻辑。目前主流的开发框架主要有：LangGraph、AutoGen、CrewAI、MetaGPT和Magentic。
**Multi-Agent中的人工干预**
**什么是人工干预**
简单来说，就是让人类能够参与到机器的工作流程中，深入到AI的核心工作环节，让人类能够实时审查、编辑甚至批准AI的决策和行动。尤其是在由大语言模型驱动的应用场景中，这种机制显得尤为重要。因为LLM虽然很强大，但有时候也会犯错，或者需要一些额外的背景知识才能做出正确的判断。这时候就需要人类来帮忙把关。
![] 
**引入人工干预的必要性**
大语言模型能力越来越强，写文章、写代码、翻译、做数学等，但并非完美无缺，可能产生错误或不准确输出。当一个Agent 被授权执行预订酒店、调用付费API 、修改数据库、或遇到法律、医疗这种高风险领域等敏感操作时，在拥有完全的自主性的情况下，甚至一个小小的错误也可能带来不可预知的风险。所以我们需要一种机制，需要一个“暂停按钮”，在关键决策点让Agent 停下来，将控制权交还给人类，让人类的智慧能够介入，结合人类的判断力、专业知识和经验给AI的工作加一道保险，弥补模型的不足。人类还可以通过审核、修正、验证等操作，提高应用的准确性和可靠性。在处理复杂或敏感任务时，人工干预能够提供更可靠的保障。
**LangGraph中的人工干预**
LangGraph 框架通过其强大的“人机协同”（Human-in-the-Loop）功能，提供了一套优雅而完备的解决方案。本文接下来将深入剖析 LangGraph 如何通过持久化状态与动态中断机制，实现灵活、可靠的人工干预，并详解其在实践中的四大核心设计模式。LangGraph 框架通过其创新的**interrupt（中断）**机制，使得构建需要人工审查、编辑和批准的“人机协同”（Human-in-the-Loop）工作流成为可能。当工作流（Graph）执行到中断点时，它会保存当前的所有状态，然后无限期暂停，直到接收到人类的输入指令后再从断点处继续。这为构建可靠、安全且透明的 Agent 应用奠定了基石。它允许用户在工作流的任何阶段进行干预。这对于大型语言模型驱动的应用程序尤其有用，因为模型输出可能需要验证、更正或补充上下文。该功能包括两种中断类型：**动态中断**和**静态中断**，允许用户暂停图执行并进行审查或编辑。此外，灵活的集成点使人类可以针对特定步骤进行干预，例如批准 API 调用、更正输出或引导对话。**作用及应用场景**
●对关键步骤（如外部API 调用）进行人工批准/拒绝，防止错误执行。
●纠正或补充模型输出，提升结果可靠性。●让业务人员在不阻塞整个系统的情况下提供上下文或修正。**核心能力**
LangGraph 的人机协同能力构建于两大基石之上：持久化的执行状态和灵活的中断机制。**持久化执行状态**
这是实现异步、无时间限制人工审查的关键。LangGraph 在工作流（Graph）的每一步执行后，都会利用其**持久化层（Persistence Layer）**来创建检查点（Checkpoint），完整地保存当前 Graph 的所有状态。这意味着，当一个工作流被中断时，它的全部上下文都被安全地保存下来。人类可以在任何时候（几秒、几小时甚至几天后）回来处理这个中断，然后系统可以从中断点无缝恢复，继续执行后续任务，而不会丢失任何信息。**灵活的中断机制**
●动态中断(Dynamic Interrupts)
在特定节点内部根据当前状态暂停，这种方式就像在程序里设置了一个条件判断，当满足某个特定条件时，就自动触发中断。例如，当你的LLM在生成一段文本后，你希望检查一下这段文本是否符合某些特定的要求（是否有敏感词、信息是否准确等），如果发现不符合要求，就可以动态触发中断，把工作流暂停下来，等待人工介入。这种方式非常灵活，可以根据实际情况随时调整中断的条件，真正做到按需暂停。
●静态中断(Static Interrupts)
在预定义的节点前后固定设置。中断后图会暂停，状态持久化，等待人工操作后再resume。
这种方式比较直接，它是在工作流设计阶段预先定义好的。你可以指定在某个特定的节点之前或者之后，必须暂停工作流，等待人工干预。或者，在某个关键步骤之后，需要人工确认结果是否正确，才能继续下一步。静态中断就像是在工作流中设置了几个固定的“关卡”，每到一个关卡，就必须有人来检查一下，确保万无一失。**触发方式**： 使用**interrupt\_before**和**interrupt\_after**，在预定义的节点前后暂停。
**适用场景**：需要在固定流程节点进行人工审核或确认的场景。
**示例**：在 API 调用前使用interrupt\_before，确保 API 请求的合规性。![] 
**灵活的集成点**
LangGraph的人工干预机制还有一个非常重要的特点，就是它的集成点非常灵活。也就是说，你可以把人工干预的逻辑放在工作流的任何位置。你可以根据不同的需求，选择在不同的节点进行人工干预。比如，你想让人类审批API调用，那就把中断点放在API调用节点之前；你想让人类纠正LLM的输出，那就把中断点放在LLM生成输出之后。这种灵活性使得我们可以根据具体的业务场景，定制化地设计人工干预的流程，真正做到精准定位，避免不必要的干预。
**典型模式**
基于上述强大的功能，我们可以构建出各种各样的典型应用场景。**● 模式一：批准/拒绝**
在工作流的关键步骤前暂停一下，让人类来审核一下，看看这个操作是不是应该执行。如果审核通过，就继续执行；如果审核不通过，就可以拒绝这个操作，甚至可以采取一些替代方案。![] 
●**应用场景**：API调用前的审批、敏感操作确认（财务交易确认、订单确认）
●**价值**：降低风险，防止错误操作，提高安全性。
**● 模式二：编辑图状态**
暂停后让人工修改状态后再继续。有时候，LLM在生成结果的过程中，可能会出现一些错误，或者信息不够完整。这时候，我们就可以暂停工作流，让人类来审核当前的状态，并进行修改。修改完成后，再把更新后的状态重新放回工作流中，让后续的步骤继续执行。这样就能保证整个工作流的数据质量，避免因为错误的信息而导致后续步骤出现问题。
![] 
●应用场景：纠正错误信息（纠正用户姓名拼写错误）、补充缺失信息、更新上下文等。●价值：修正错误，完善信息，提升后续步骤的准确性。**● 模式三：审查工具调用**
在LLM 发出工具请求前让人工检查并可编辑。我们知道，LLM往往需要借助各种工具来完成任务，比如搜索网络信息、查询数据库等。但是，LLM有时候可能会选错工具，或者调用工具的参数设置不正确。为了避免这种情况，我们可以再LLM发起工具调用之前，先暂停工作流，让人类来审核一下这个工具调用是否合理。比如，LLM可能想调用一个支付API来完成转账，但是参数设置错了，导致金额输入错误。这时候，人类就可以介入，检查一下工具调用的参数是否有错误，若有错误就及时纠正。
![] 
●应用场景：审核API请求参数、验证工具选择的合理性等。
●价值：确保工具调用的正确性和安全性，避免错误操作。**● 模式四：验证人工输入**
在后续步骤前确认人工提供的信息有效。这个模式听起来好像有点反直觉，因为我一直在讲“human-in-the-loop”，怎么又变成验证人类输入了呢？其实，这个模式主要是针对那些需要用户输入信息的场景。比如，用户填写一个表单，或者在聊天机器人中输入一些指令。为了确保用户输入的信息是有效的，我们可以利用人工干预机制，在系统处理用户输入之前，先暂停一下，让用户自己确认一下输入的信息是否正确。如果用户确认无误，就继续执行；如果用户发现输入有误，可以及时修改。
![] 
●**应用场景**：用户输入验证、表单数据校验等。
●**价值**：确保数据质量，防止无效或错误的输入影响后续流程。
**langGraph中的人工干预核心工作流**
实现一次完整的人机交互闭环，interrupt 的工作流遵循一个清晰的四步模式：1. **配置持久化层 (Checkpointer)**：中断的本质是状态的保存与恢复。因此，在编译 Graph 时，必须为其指定一个checkpointer，用于在每一步执行后自动保存状态。
from langgraph.checkpoint.memory import InMemorySaver
checkpointer = InMemorySaver()
graph = graph\_builder.compile(checkpointer=checkpointer)
1. **在节点中调用 interrupt()**：在需要人工干预的节点函数中，调用 interrupt() 函数。此函数会立即暂停执行，并可以向用户传递一个JSON 可序列化的对象，其中包含需要审查的数据。from langgraph.types import interrupt
def human\_review\_node(state: State):
*# 中断执行，并将state 中的摘要文本交给用户审查*
edited\_data = interrupt({
&#34;task&#34;: &#34;请审查并编辑下面的摘要&#34;,
&#34;&#34;summary\_to\_review&#34;&#34;: state[&#34;&#34;summary&#34;&#34;]
})
*# 恢复后，edited\_data 将是用户输入的新内容*
return {&#34;&#34;summary&#34;&#34;: edited\_data[&#34;&#34;edited\_summary&#34;&#34;]}
1. **运行并触发中断**：使用 invoke 或stream 方法并传入唯一的thread\_id 来运行Graph。当执行流遇到 interrupt() 时，Graph 会暂停，并在返回结果中包含一个特殊的**interrupt**键，其中包含了中断的详细信息（如传递给用户的数据）。
config = {&#34;&#34;configurable&#34;&#34;: {&#34;&#34;thread\_id&#34;&#34;: &#34;&#34;some-unique-id&#34;&#34;}}
result = graph.invoke({&#34;summary&#34;: &#34;初步生成的摘要...&#34;}, config=config)
*# 检查中断信息*
print(result[&#39;&#39;\_\_interrupt\_\_&#39;&#39;])
*# &gt;&gt; [Interrupt(value={&#39;&#39;task&#39;&#39;: &#39;&#39;请审查...&#39;&#39;, &#39;&#39;summary\_to\_review&#39;&#39;: &#39;&#39;...&#39;&#39;}, id=&#39;&#39;...&#39;&#39;)]*
1. **使用 Command 恢复执行**：当用户完成审查并提供输入后，通过再次调用 invoke 或stream，并传入一个 Command(resume=...) 对象来恢复Graph 的执行。resume 中包含的值将作为interrupt() 函数的返回值。from langgraph.types import Command
*# 用户提供了编辑后的摘要*
user\_input = {&#34;&#34;edited\_summary&#34;&#34;: &#34;&#34;这是经过人工编辑的最终摘要。&#34;&#34;}
final\_result = graph.invoke(Command(resume=user\_input), config=config)
⚠️**核心机制警示：恢复即重跑**(Resume Reruns the Node)
这是理解interrupt 最关键的一点：恢复执行并非从interrupt() 函数调用的那一行代码继续，而是从包含interrupt() 的那个节点的开头重新执行整个节点。在重跑期间，当执行流再次遇到interrupt() 时，它不会再次暂停，而是直接返回Command(resume=...) 中提供的值。这个设计虽然巧妙，但也意味着任何位于interrupt() 调用之前的、具有副作用的操作（如API 调用、数据库写入）都会被重复执行。因此，最佳实践是将副作用操作放在interrupt() 之后，或置于一个独立的后续节点中。**langGraph实战模式--interrupt的四大经典模式的应用**
基于其核心机制，interrupt 可以灵活地实现多种强大的人机交互模式。要在图中使用interrupt，您需要：
1. 指定一个检查点来保存每个步骤后的图形状态。2. interrupt()在适当的地方调用。
3. 使用线程ID运行图，直到interrupt命中。
4. 使用invoke/恢复执行stream。
我们挑选了两个模式（模式一和模式三），边运行边讲解执行过程。**模式一：审批或否决 (Approve or Reject)**
在执行高风险操作前，强制要求人工批准。根据用户的决策，Graph 可以走向不同的分支。**步骤一：基本函数定义**
*# 目标：中断图的执行，让用户做出决策（如批准/拒绝），然后根据决策跳转到不同的流程分支。*
from typing import Literal, TypedDict
import uuid
from langgraph.constants import END
from langgraph.graph import StateGraph
from langgraph.types import interrupt, Command
from langgraph.checkpoint.memory import InMemorySaver
*# 1. 定义图的共享状态，包含一个&#39;decision&#39; 字段来记录人类的决定*
class State(TypedDict):
llm\_output: str
decision: str
*# 模拟一个生成内容的节点*
def generate\_llm\_output(state: State) -&gt;&gt; State:
print(&#34;&#34;\\n--- 步骤1：AI生成内容 ---&#34;&#34;)
return {&#34;&#34;llm\_output&#34;&#34;: &#34;&#34;这是AI生成的一段需要审批的文本。&#34;&#34;}
*# 2. 定义人工审批节点。注意：返回值类型是Command，意味着此节点将发出控制指令。*
def human\_approval(state: State) -&gt;&gt; Command[Literal[&#34;&#34;approved\_path&#34;&#34;, &#34;&#34;rejected\_path&#34;&#34;]]:
&#34;&#34;&#34;
此节点暂停并等待人类决策，然后根据决策返回一个带有`goto` 指令的Command，
从而控制图的走向。&#34;&#34;&#34;
print(&#34;&#34;\\n--- 暂停：等待人工审批---&#34;&#34;)
*# 3. 暂停图的执行，等待人类做出决策（例如，输入&#34;approve&#34; 或&#34;reject&#34;）。*
decision = interrupt({
&#34;question&#34;: &#34;请审批以下内容，回复 &#39;approve&#39; 或&#39;reject&#39;：&#34;,
&#34;&#34;llm\_output&#34;&#34;: state[&#34;&#34;llm\_output&#34;&#34;]
})
*# 4. 核心逻辑：根据人类的决策（&#39;decision&#39; 变量的值）进行判断。*
if decision == &#34;approve&#34;:
print(&#34;&#34;\\n--- 决策：批准---&#34;&#34;)
*# 5. 如果批准，返回一个Command 指令，强制图跳转到&#39;&#39;approved\_path&#39;&#39; 节点。*
*# &#39;goto&#39; 是实现条件路由的关键。&#39;update&#39; 是一个可选参数，用于同时更新状态。*
return Command(goto=&#34;&#34;approved\_path&#34;&#34;, update={&#34;&#34;decision&#34;&#34;: &#34;&#34;approved&#34;&#34;})
else:
print(&#34;&#34;\\n--- 决策：拒绝---&#34;&#34;)
*# 6. 如果拒绝，则跳转到&#39;&#39;rejected\_path&#39;&#39; 节点。*
return Command(goto=&#34;&#34;rejected\_path&#34;&#34;, update={&#34;&#34;decision&#34;&#34;: &#34;&#34;rejected&#34;&#34;})
*# 批准后的流程节点*
def approved\_node(state: State) -&gt;&gt; State:
print(&#34;--- 步骤2 (分支A): 已进入批准流程。---&#34;)
return state
*# 拒绝后的流程节点*
def rejected\_node(state: State) -&gt;&gt; State:
print(&#34;--- 步骤2 (分支B): 已进入拒绝流程。---&#34;)
return state
**步骤二：构建图**
builder = StateGraph(State)
builder.add\_node(&#34;&#34;generate\_llm\_output&#34;&#34;, generate\_llm\_output)
builder.add\_node(&#34;&#34;human\_approval&#34;&#34;, human\_approval)
builder.add\_node(&#34;&#34;approved\_path&#34;&#34;, approved\_node)
builder.add\_node(&#34;&#34;rejected\_path&#34;&#34;, rejected\_node)
*# 7. 设置图的入口和边，定义了基本的流程。*
*# 注意，从human\_approval 节点出发的路径将由其返回的Command(goto=...) 动态决定。*
builder.set\_entry\_point(&#34;&#34;generate\_llm\_output&#34;&#34;)
builder.add\_edge(&#34;&#34;generate\_llm\_output&#34;&#34;, &#34;&#34;human\_approval&#34;&#34;)
builder.add\_edge(&#34;&#34;approved\_path&#34;&#34;, END)*# 批准分支的终点*
builder.add\_edge(&#34;&#34;rejected\_path&#34;&#34;, END)*# 拒绝分支的终点*
checkpointer = InMemorySaver()
graph = builder.compile(checkpointer=checkpointer)
**步骤三：首次运行，图会执行到


---
*数据来源: Exa搜索 | 获取时间: 2026-02-20 20:40:34*