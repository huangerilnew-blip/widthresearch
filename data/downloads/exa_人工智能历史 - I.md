# 人工智能历史 - IBM

**URL**:
https://www.ibm.com/cn-zh/think/topics/history-of-artificial-intelligence

## 元数据
- 发布日期: 2026-02-10T21:43:59.469335

## 完整内容
---
人工智能历史 | IBM
[Artificial Intelligence] 
# AI 的历史![高耸入云的摩天大楼尖顶] 
## 作者[Tim Mucci] 
IBM Writer
Gather
## 人工智能的历史人类自古以来就梦想着制造会思考的机器。民间故事中和历史上打造可编程设备的尝试反映了这种长期以来的雄心壮志&#xff0c;而虚构的故事充满了智能机器的可能性&#xff0c;设想着它们的优点和危险。也难怪当 OpenAI 发布第一个版本的[GPT] &#xff08;Generative Pretrained Transformer&#xff0c;生成式预训练转换器&#xff09;时&#xff0c;迅速获得了广泛关注&#xff0c;标志着向实现这一古老梦想迈出了重要一步。
GPT-3 是[AI] 领域具有里程碑意义的时刻&#xff0c;因为它具有前所未有的规模&#xff0c;具有 1,750 亿个参数&#xff0c;这使其无需进行大量微调即可执行各种自然语言任务。该模型使用大数据进行训练&#xff0c;使其能够生成类似人类的文本并参与对话。它还能够进行小样本学习&#xff0c;显著提高了其泛用性&#xff0c;并在聊天机器人和虚拟助理等商业 AI 应用中表现出了实用性。如今&#xff0c;AI 正逐渐融入日常生活的方方面面&#xff0c;从社交媒体到工作流程&#xff0c;随着技术的不断进步&#xff0c;其影响力也将持续增长。要了解这项技术的发展方向&#xff0c;首先要了解我们是如何走到今天的。以下是 AI 的主要发展历史&#xff1a;
## 20 世纪以前### 1726
Jonathan Swift 的奇幻小说《格列佛游记》提出了“引擎”的概念&#xff0c;这是一个大型机械装置&#xff0c;用于帮助学者产生新的想法、句子和书籍。
学者们转动机器的手柄&#xff0c;机器会旋转刻有文字的木块。据说这台机器通过以不同的排列方式组合单词来创造新的想法和哲学论文&#xff1a;
“大家都知道&#xff0c;用常规的手段要想在艺术和科学上取得成就需要付出多大的劳动&#xff0c;而如果用他的方法&#xff0c;就是最无知的人&#xff0c;只要适当付点学费&#xff0c;再出一点点体力&#xff0c;就可以不借助于任何天才或学力&#xff0c;写出关于哲学、诗歌、政治、法律、数学和神学的书来。”
- Jonathan Swift 的《格列佛游记》(1726)
Swift 的讽刺作品预示了算法文本生成的概念&#xff0c;而现代 AI 已将这一概念变为现实。AI 模型可以根据底层算法将词语和想法组合在一起&#xff0c;从而生成连贯的文本&#xff0c;这与斯威夫特虚构的“引擎”所要做的事情类似。
## 1900–1950
### 1914 年西班牙工程师Leonardo Torres y Quevedo 在巴黎*世界博览会*上展示了第一台国际象棋机*El Ajedrecista*。它使用电磁铁并且是完全自动化的。*El Ajedrecista*自动下了一个简单的国际象棋残局&#xff0c;即王、车对王。机器一旦设置好就不需要人工干预&#xff0c;它会自主进行符合规则的国际象棋移动&#xff0c;如果人类对手下出了不合规则的招法&#xff0c;机器会发出信号指示错误。如果机器被置于获胜位置&#xff0c;它就能够可靠地将死人类对手。
### 1921
一部名为《罗森的通用机器人》(R.U.R) 的戏剧在伦敦上演。这部由Karel Čapek 创作的戏剧是英语中首次使用“机器人”一词。在捷克语中&#xff0c;“robota”一词与封建制度下农民从事的强制性或强迫性工作有关。该剧获得成功后&#xff0c;“机器人”一词迅速获得国际认可&#xff0c;并成为机械或人造人执行任务的标准术语。虽然 Čapek 笔下的机器人是有机的&#xff0c;但该词却与机械、人形机器联系在一起&#xff0c;被设计用来从事单调、无技能的劳动。
### 1939
爱荷华州立大学物理和数学教授John Vincent Atanasoff 和他的研究生Clifford Berry 在爱荷华州立大学依靠650 美元的资助&#xff0c;创造了 Atanasoff-Berry Computer (ABC)。ABC 计算机被认为是最早的数字电子计算机之一&#xff0c;也是美国计算机科学领域的里程碑。
虽然ABC 从未充分运行或广泛使用&#xff0c;但它引入的几个关键概念将成为现代计算发展的基础。
与以前依赖十进制的计算设备不同&#xff0c;ABC 使用二进制&#xff08;1 和0&#xff09;来表示数据&#xff0c;二进制成为此后计算机的标准。ABC 也是最早使用电子电路而不是机械或机电系统进行计算的计算机之一&#xff0c;因此计算得更快、更可靠。ABC 将数据存储&#xff08;内存&#xff09;与处理单元&#xff08;逻辑运算&#xff09;分开&#xff0c;现代计算机体系结构仍在遵循这一原则。它使用电容器存储数据&#xff0c;可处理多达 30 个联立方程。ABC 采用大约300 个真空电子管进行逻辑运行&#xff0c;使其比早期的机械计算器更快。尽管真空电子管体积庞大且容易出现故障&#xff0c;但它们是电子计算领域的一项关键发展。ABC 重量超过700 磅&#xff0c;可以求解多达 29 个联立线性方程。### 1943 年Warren S. McCulloch 和Walter Pitts 在*Bulletin of Mathematical Biophysics*上发表了《A Logical Calculus of the Ideas Immanent in Nervous Activity》。1这是神经科学和 AI 史上影响深远的著作之一。这篇论文奠定了大脑可以被理解为一个计算系统的思想基础&#xff0c;并引入了人工神经网络的概念&#xff0c;而人工神经网络现已成为现代 AI 的一项关键技术。这一思想启发了计算机系统&#xff0c;特别是通过[神经网络] 和[深度学习] 来模拟类似大脑的功能和过程。
### 1950
英国数学家Alan Turing 的里程碑式论文《Computing Machinery and Intelligence》发表在*Mind*上。2这篇论文是 AI 领域的奠基性文章&#xff0c;探讨了“机器能思考吗&#xff1f;”这一问题。Turing 的方法为日后讨论会思考的机器的本质以及如何通过“模仿游戏”&#xff08;即现在的图灵测试&#xff09;来衡量其智能确立了基础。Turing 引入了一个思想实验&#xff0c;以避免直接回答“机器会思考吗&#xff1f;”&#xff1b;他是将这个问题重新表述为更具体、更可操作的形式&#xff1a;机器能否表现出与人类无异的智能行为&#xff1f;
图灵测试已成为AI 的核心概念&#xff0c;这是通过评估机器令人信服地模仿人类对话和行为的能力来衡量机器智能的一种方法。
## 1950–1980
### 1951
Marvin Minsky 和Dean Edmunds 构建了第一个人工神经网络。随机神经模拟强化计算器(SNARC) 是模拟人脑学习过程的早期尝试&#xff0c;特别是通过[强化学习] 。
SNARC 的设计目的是模拟老鼠在迷宫中的行为。其想法是让机器模仿动物通过奖惩进行学习的方式&#xff0c;即随时间推移根据反馈调整自己的行为。它是一台模拟计算机&#xff0c;使用 3,000 个真空电子管组成的网络和突触权重来模拟40 个类似神经元的单元。### 1952
数学家兼计算机科学家Allen Newell 和政治学家Herbert A. Simon 开发出了Logic Theorist 和General Problem Solve 等具有影响力的程序&#xff0c;这些程序是首批使用计算方法模拟人类解决问题能力的程序。
### 1955
“人工智能”一词最初出现在一份名为《A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence》3的研讨会提案中&#xff0c;由达特茅斯学院的 John McCarthy、哈佛大学的 Marvin Minsky、IBM 的Nathaniel Rochest 以及贝尔电话实验室的Claude Shannon 共同提交。一年后&#xff0c;即 1956 年7 月和8 月举行的这次研讨会被普遍认为是新兴AI 领域的正式诞生之时。### 1957 年Frank Rosenblatt 是一位心理学家兼计算机科学家&#xff0c;他开发了 Perceptron&#xff0c;这是一种早期的人工神经网络&#xff0c;可以实现基于两层计算机学习网络的模式识别。Perceptron 引入了二元分类器的概念&#xff0c;二元分类器可通过学习[算法] 调整其输入的权重&#xff0c;从而从数据中学习。虽然仅限于解决线性可分离问题&#xff0c;但它为未来神经网络和[机器学习] 的发展奠定了基础。
### 1958
John McCarthy 开发了编程语言Lisp4&#xff0c;Lisp 是LISt Processing 的缩写。Lisp 的诞生源于McCarthy 在形式化算法和数理逻辑方面的工作&#xff0c;特别是受到他希望创建一种可以处理符号信息的编程语言的影响。Lisp 很快成为AI 研究中最流行的编程语言。### 1959
Arthur Samuel 率先提出了机器学习的概念&#xff0c;他开发了一个计算机程序&#xff0c;随着时间的推移&#xff0c;该程序在跳棋方面的性能不断提高。Samuel 证明&#xff0c;可以对计算机进行编程&#xff0c;使其遵循预定义的规则&#xff0c;并从经验中“学习”&#xff0c;最终比程序员下得更好。他的工作标志着向教机器通过经验不断进步的方向迈出了重要一步&#xff0c;并在此过程中创造了“机器学习”这一术语。
Oliver Selfridge 发表了他的论文“Pandemonium: A paradigm for learning”。5他的“魔都”模型提出了一种系统&#xff0c;在该系统中&#xff0c;各种“恶魔”&#xff08;处理单元&#xff09;共同识别模式。恶魔们竞相识别未经预编程的数据中的特征&#xff0c;模拟无监督学习。Selfridge 的模型是对模式识别的早期贡献&#xff0c;影响了机器视觉和 AI 的未来发展。John McCarthy 在他的论文《具有常识的程序》中提出了&#34;建议接受者&#34;的概念。*6*该程序旨在通过处理形式逻辑中的句子来解决问题&#xff0c;为 AI 的推理奠定基础。McCarthy 设想的系统可以理解指令&#xff0c;利用常识性知识进行推理&#xff0c;并从经验中学习&#xff0c;其长远目标是开发出能像人类一样有效适应和学习的 AI。这一概念有助于形成早期的知识表示和自动推理研究。
### 1965
哲学家Hubert Dreyfus 出版了*《*Alchemy and Artificial Intelligence》7&#xff0c;文章认为人类大脑的运作方式与计算机有着根本的不同。他预测&#xff0c;由于复制人类直觉和理解力方面的挑战&#xff0c;AI 的进步会受到限制。他的批评在引发关于AI 的哲学和实践极限的辩论方面具有影响力。I.J. Good 撰写了《Speculations Concerning the First Ultraintelligent Machine》8&#xff0c;其中有一个著名的断言&#xff1a;一旦创造了一台超智能机器&#xff0c;它就可以设计出更智能的系统&#xff0c;使自己成为人类的最后一项发明—只要它保持可控。他的想法预示着现代关于 AI 超级智能及其风险的讨论。Joseph Weizenbaum 开发了ELIZA9&#xff0c;这是一个通过响应自然语言输入来模仿人类对话的程序。尽管 Weizenbaum 打算展示人机交流的表面化&#xff0c;但他感到惊讶的是&#xff0c;有很多用户认为该程序有类似人类的情绪&#xff0c;这引发了有关 AI 和人类互动的伦理问题。斯坦福大学的Edward Feigenbaum、Bruce Buchanan、Joshua Lederberg 和Carl Djerassi 开发了DENDRAL。10这是第一个通过模拟假设生成来实现有机化学家决策过程自动化的专家系统。DENDRAL 的成功标志着AI 的进步&#xff0c;展示了系统如何执行专业任务&#xff0c;甚至比人类专家更好。
### 1966
Shakey 于20 世纪60 年代末在SRI 研发&#xff0c;是第一个能够对自己的行动进行推理的移动机器人&#xff0c;集感知、规划和解决问题于一身。11Marvin Minsky 在1970 年《生活》杂志的一篇文章中预测&#xff0c;AI 将在三到八年内达到普通人的一般智能。Shakey 的成就标志着机器人和AI 领域的一个里程碑&#xff0c;尽管 Minsky 雄心勃勃的时间表被证明过于乐观。### 1969
Arthur Bryson 和Yu-Chi Ho 介绍了一种优化多级动态系统的方法-[反向传播] 。虽然该算法最初是为控制系统开发的&#xff0c;但在训练多层神经网络时却变得至关重要。。随着计算能力的进步&#xff0c;反向传播在 2000 和2010 年代才开始崭露头角&#xff0c;从而促成了深度学习的兴起。
Marvin Minsky 和Seymour Papert 出版了《*Perceptrons: An Introduction to Computational Geometry*》&#xff0c;*12*&#xff0c;该书批判性地分析了单层神经网络的局限性。他们的工作经常被指责为降低了人们对神经网络的兴趣。在 1988 年版中&#xff0c;他们认为&#xff0c;尽管到 20 世纪60 年代中期&#xff0c;对感知机进行了大量实验&#xff0c;但由于缺乏理论理解&#xff0c;相关进展已经停滞。
### 1970
Terry Winograd 创建了SHRDLU&#xff0c;这是一款开创性的自然语言理解程序。13SHRDLU 可以用简单的英语与用户交互&#xff0c;操作虚拟积木世界中的对象&#xff0c;这展示了计算机理解和响应复杂指令的潜力。这是[自然语言处理] 领域的一项早期成果&#xff0c;但其成功仅限于特定的高度结构化环境。SHRDLU 的功能凸显了实现更广泛的AI 语言理解的前景和挑战。### 1972 年MYCIN 由斯坦福大学开发&#xff0c;是最早创建的专家系统之一&#xff0c;用于帮助医生诊断细菌感染和推荐抗生素治疗。14MYCIN 使用基于规则的方法模拟人类专家的决策过程&#xff0c;并为医疗 AI 系统的开发创建了一个平台。然而&#xff0c;由于伦理和法律问题&#xff0c;它从未在临床实践中实施。
### 1973
James Lighthill 向英国科学研究理事会提交了一份关于AI 研究进展的关键报告&#xff0c;并得出 AI 未能兑现其早期承诺的结论。15他认为&#xff0c;该领域尚未产生重大突破&#xff0c;导致英国政府大幅减少了对 AI 的资助。这份报告导致了第一个AI 寒冬的爆发16&#xff0c;此时期人们对 AI 研究的兴趣和投资消减了。## 1980–2000
### 1980
WABOT-217是日本早稻田大学开发的仿人机器人&#xff0c;于 1980 年开始制造&#xff0c;1984 年左右完成。它是继1973 年制造的WABOT-1 之后的又一款机器人。WABOT-1 着重于基本的移动和交流&#xff0c;而 WABOT-2 则更为专业&#xff0c;专门设计为音乐家机器人。它可以用摄像&#34;眼睛&#34;阅读乐谱&#xff0c;与人类交谈&#xff0c;用电子风琴演奏音乐&#xff0c;甚至可以为人类歌手伴奏。该项目标志着仿人机器人和 AI 的发展迈出了有意义的一步&#xff0c;仿人机器人和 AI 能够执行复杂的、类似人类的任务&#xff0c;如艺术表达。
### 1982
日本启动了第五代计算机系统项目(FGCS)&#xff0c;旨在开发能够进行逻辑推理和解决问题的计算机&#xff0c;推动 AI 研究的发展。这个雄心勃勃的项目旨在制造能够执行自然语言处理等任务的机器和专家系统。尽管该项目于1992 年停止&#xff0c;但 FGCS 项目及其研究成果为并发逻辑编程领域的发展做出了巨大贡献。### 1984 年在人工智能发展协会(AAAI) 年会上&#xff0c;Roger Schank 和Marvin Minsky 对即将到来的“AI 之冬”发出警告。他们预测&#xff0c;对 AI 的过高期望很快就会导致投资和研究的崩溃&#xff0c;就像 20 世纪70 年代中期资金减少一样。他们的预言在三年内变成现实&#xff0c;人们对 AI 的兴趣因未兑现承诺而减弱&#xff0c;导致资助减少&#xff0c;进展放缓。这一时期被称为第二次 AI 寒冬。Schank 和Minsky 的警告凸显了AI 热潮的周期性质&#xff0c;当技术未能满足投资者和公众的预期时&#xff0c;迸发的乐观情绪之后是幻灭的寒冬。
### 1986
David Rumelhart、Geoffrey Hinton 和Ronald Williams 发表了开创性的论文《Learning representations by back-propagating errors》&#xff0c;他们在论文中描述了反向传播算法。18这种方法允许神经网络通过“反向传播”误差来调整内部权重&#xff0c;提高了多层网络学习复杂模式的能力。反向传播算法成为现代深度学习的基础&#xff0c;重新激发了人们对神经网络的兴趣&#xff0c;并克服了早期 AI 研究中凸显的一些局限性。这一发现以Arthur Bryson 和Yu-Chi Ho 1969 年的研究成果为基础&#xff0c;将反向传播算法专门应用于神经网络&#xff0c;克服了以往多层网络训练中的一些局限性。
这一突破使人工神经网络的实际应用变得可行&#xff0c;并为 21 世纪前十年和21 世纪10 年代的深度学习革命打开了大门。### 1987
在教育大会的主题演讲中&#xff0c;苹果公司 CEO John Sculley 展示了Knowledge Navigator 视频&#xff0c;想象未来数字智能代理将帮助用户通过网络系统获取海量信息。19这个富有远见的概念描述了一位教授与一位知识渊博的声控助手互动的场景&#xff0c;这位助手可以检索数据、回答问题并显示我们现在所认识的互联网信息。这段视频预见了现代技术的许多要素&#xff0c;如 AI 助手、网络知识数据库和我们互联的数字世界。### 1988
Judea Pearl 出版了《*Probabilistic Reasoning in Intelligent Systems*》&#xff0c;彻底改变了 AI 在不确定情况下处理信息的方式。*20*该工作引入了贝叶斯网络&#xff0c;一种表示复杂概率模型的形式主义&#xff0c;以及在其中执行推理的算法。Pearl 的方法使AI 系统能够在不确定的环境中做出合理的决策&#xff0c;影响到 AI 以外的领域&#xff0c;包括工程和自然科学。他的贡献得到了 2011 年图灵奖的认可&#xff0c;该奖表彰了他在为 AI 中的现代概率推理创建“表示和计算基础”方面的作用。21
Rollo Carpenter 开发了Jbberwacky22&#xff0c;这是一个早期的[聊天机器人] &#xff0c;旨在模拟像人类一般的有趣、娱乐性和有幽默感的对话。与基于规则的系统不同&#xff0c;Jbberwacky 从人类交互中学习以生成更自然的对话&#xff0c;为后来的会话式 AI 模型铺平了道路。该聊天机器人是创建通过从与用户的交互中不断学习来模仿自发的日常人类对话的首批AI 尝试之一。IBM T.J. Watson 研究中心的研究人员发表了《A Statistical Approach to Language Translation》&#xff0c;标志着机器翻译从基于规则的方法向概率方法的关键转变。23这种方法以 IBM 的Candide 项目为例24&#xff0c;使用了 220 万个英法句子对&#xff0c;主要来自加拿大议会的会议记录。这种新方法强调从数据中的统计模式中学习&#xff0c;而不是试图理解或“懂得”语言&#xff0c;这反映了依赖于分析已知示例的机器学习的更广泛趋势。这种概率模型为自然语言处理和机器翻译的许多未来进步铺平了道路。
Marvin Minsky 和Seymour Papert 发布了他们1969 年出版的《*Perceptrons*》一书的扩展版&#xff0c;这是对早期神经网络意义深远的批评。在题为“A View from 1988”的新序言中&#xff0c;他们反思了 AI 领域的缓慢进展&#xff0c;并指出由于不熟悉早期的挑战&#xff0c;许多研究人员继续重复过去的错误。12他们强调了对更深入理论理解的需求&#xff0c;这在早期的神经网络研究中是缺乏的。他们强调了最初的批评&#xff0c;同时认可了后来导致现代深度学习进步的新兴方法。
### 1989 年Yann LeCun 和AT&amp;T 贝尔实验室的研究团队取得了突破性进展&#xff0c;成功地将反向传播算法应用于多层神经网络&#xff0c;以识别手写邮政编码图像。24这是利用[卷积神经网络] 进行深度学习的首批实际应用之一。尽管当时的硬件条件有限&#xff0c;但神经网络的培训大约需要三天时间&#xff0c;与之前的尝试相比有了显著改进。该系统在手写数字识别&#xff08;邮政服务自动化的一项关键任务&#xff09;方面的成功&#xff0c;展示了神经网络在图像识别任务方面的潜力&#xff0c;并为深度学习在随后几十年的爆炸式增长奠定了基础。
### 1993
科幻小说作家兼数学家Vernor Vinge 发表了题为《The Coming Technological Singularity》的文章&#xff0c;其中他预测超人的智慧将在未来**30 年内诞生&#xff0c;从而从根本上改变人类文明。25Vinge 认为&#xff0c;技术进步&#xff0c;特别是 AI&#xff0c;将导致智能爆炸&#xff0c;机器将超越人类智能&#xff0c;并结束我们所知的人类时代。他的文章对于普及“技术奇点”这一概念发挥了重要作用&#xff0c;并引发了 AI、伦理和未来主义社区的讨论。
这一预测持续影响着有关AI 和超级智能潜在影响的讨论&#xff0c;特别是创造远超人类能力的智能机器所带来的生存风险和伦理考量。
### 1995
Richard Wallace 在Joseph Weizenbaum 的ELIZA 计划基础上开发了聊天机器人A.L.I.C.E.26&#xff08;


---
*数据来源: Exa搜索 | 获取时间: 2026-02-10 21:44:31*