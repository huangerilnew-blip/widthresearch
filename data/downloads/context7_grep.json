{"text": "### Re-assemble LangGraph with Human Review and Checkpointer (Python)\n\nSource: https://docs.langchain.com/oss/python/langgraph/sql-agent\n\nThis code reassembles a LangGraph, replacing programmatic checks with human review and introducing a checkpointer for pausing and resuming execution. It defines the graph structure, nodes, edges, and initializes an InMemorySaver checkpointer.\n\n```python\nfrom langgraph.checkpoint.memory import InMemorySaver\n\ndef should_continue(state: MessagesState) -> Literal[END, \"run_query\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    if not last_message.tool_calls:\n        return END\n    else:\n        return \"run_query\"\n\nbuilder = StateGraph(MessagesState)\nbuilder.add_node(list_tables)\nbuilder.add_node(call_get_schema)\nbuilder.add_node(get_schema_node, \"get_schema\")\nbuilder.add_node(generate_query)\nbuilder.add_node(run_query_node, \"run_query\")\n\nbuilder.add_edge(START, \"list_tables\")\nbuilder.add_edge(\"list_tables\", \"call_get_schema\")\nbuilder.add_edge(\"call_get_schema\", \"get_schema\")\nbuilder.add_edge(\"get_schema\", \"generate_query\")\nbuilder.add_conditional_edges(\n    \"generate_query\",\n    should_continue,\n)\nbuilder.add_edge(\"run_query\", \"generate_query\")\n\ncheckpointer = InMemorySaver() # [!code highlight]\nagent = builder.compile(checkpointer=checkpointer) # [!code highlight]\n```\n\n--------------------------------\n\n### Compile Parent Graph with Checkpointer in Python\n\nSource: https://docs.langchain.com/oss/python/langgraph/use-subgraphs\n\nDemonstrates compiling a parent LangGraph with a checkpointer, automatically propagating it to child subgraphs. This is the standard way to add persistence to the main graph.\n\n```python\nfrom langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom typing_extensions import TypedDict\n\nclass State(TypedDict):\n    foo: str\n\n# Subgraph\n\ndef subgraph_node_1(state: State):\n    return {\"foo\": state[\"foo\"] + \"bar\"}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# Parent graph\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)\nbuilder.add_edge(START, \"node_1\")\n\ncheckpointer = MemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n```\n\n--------------------------------\n\n### Subgraph Checkpointer Propagation\n\nSource: https://docs.langchain.com/oss/python/langgraph/add-memory\n\nDemonstrates how LangGraph automatically propagates checkpointers to subgraphs when the parent graph is compiled with one. This ensures state consistency across nested graph structures. The example shows a parent graph compiling a subgraph, with the checkpointer being applied at the parent level.\n\n```python\nfrom langgraph.graph import START, StateGraph\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom typing import TypedDict\n\nclass State(TypedDict):\n    foo: str\n\n# Subgraph\n\ndef subgraph_node_1(state: State):\n    return {\"foo\": state[\"foo\"] + \"bar\"}\n\nsubgraph_builder = StateGraph(State)\nsubgraph_builder.add_node(subgraph_node_1)\nsubgraph_builder.add_edge(START, \"subgraph_node_1\")\nsubgraph = subgraph_builder.compile()\n\n# Parent graph\n\nbuilder = StateGraph(State)\nbuilder.add_node(\"node_1\", subgraph)\nbuilder.add_edge(START, \"node_1\")\n\ncheckpointer = InMemorySaver()\ngraph = builder.compile(checkpointer=checkpointer)\n```\n\n--------------------------------\n\n### Compile and Stream Graph with Checkpointer\n\nSource: https://docs.langchain.com/oss/python/langgraph/add-memory\n\nCompiles a LangGraph graph with a checkpointer and demonstrates streaming messages. The checkpointer allows for state persistence across runs. Inputs are message dictionaries and configuration objects, outputs are streamed message chunks.\n\n```python\ngraph = builder.compile(checkpointer=checkpointer)\n\nconfig = {\n    \"configurable\": {\n        \"thread_id\": \"1\"\n    }\n}\n\nasync for chunk in graph.astream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n    config,\n    stream_mode=\"values\"\n):\n    chunk[\"messages\"][-1].pretty_print()\n\nasync for chunk in graph.astream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n    config,\n    stream_mode=\"values\"\n):\n    chunk[\"messages\"][-1].pretty_print()\n```\n\n--------------------------------\n\n### Invoke LangGraph and Inspect Result (Python)\n\nSource: https://docs.langchain.com/oss/python/langgraph/use-graph-api\n\nInvokes the compiled LangGraph with an initial state and captures the result. The result contains the entire updated state, including the messages list and any extra fields populated by the nodes.\n\n```python\nfrom langchain.messages import HumanMessage\n\nresult = graph.invoke({\"messages\": [HumanMessage(\"Hi\")]})\nresult\n```", "metadata": {"tool": "query-docs", "source": "context7_query_docs"}}
{"text": "### Invoke Graph with Checkpoints (Python)\n\nSource: https://docs.langchain.com/oss/python/langgraph/persistence\n\nThis snippet demonstrates how to set up and invoke a LangGraph with an `InMemorySaver` checkpointer. It defines a simple stateful graph and invokes it, resulting in multiple checkpoints being saved. The `RunnableConfig` includes a `thread_id` for state management.\n\n```python\nfrom langgraph.graph import StateGraph, START, END\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langchain_core.runnables import RunnableConfig\nfrom typing import Annotated\nfrom typing_extensions import TypedDict\nfrom operator import add\n\nclass State(TypedDict):\n    foo: str\n    bar: Annotated[list[str], add]\n\ndef node_a(state: State):\n    return {\"foo\": \"a\", \"bar\": [\"a\"]}\n\ndef node_b(state: State):\n    return {\"foo\": \"b\", \"bar\": [\"b\"]}\n\n\nworkflow = StateGraph(State)\nworkflow.add_node(node_a)\nworkflow.add_node(node_b)\nworkflow.add_edge(START, \"node_a\")\nworkflow.add_edge(\"node_a\", \"node_b\")\nworkflow.add_edge(\"node_b\", END)\n\ncheckpointer = InMemorySaver()\ngraph = workflow.compile(checkpointer=checkpointer)\n\nconfig: RunnableConfig = {\"configurable\": {\"thread_id\": \"1\"}}\ngraph.invoke({\"foo\": \"\", \"bar\":[]}, config)\n```\n\n--------------------------------\n\n### Resume LangGraph Execution After Errors with Checkpointing\n\nSource: https://docs.langchain.com/oss/python/langgraph/use-functional-api\n\nShows how to use InMemorySaver for checkpointing to resume workflow execution after an error. Tasks that have already completed successfully are not re-run, saving computation time. This is useful for long-running or potentially failing workflows.\n\n```python\nimport time\nfrom langgraph.checkpoint.memory import InMemorySaver\nfrom langgraph.func import entrypoint, task\nfrom langgraph.types import StreamWriter\n\n# This variable is just used for demonstration purposes to simulate a network failure.\n# It's not something you will have in your actual code.\nattempts = 0\n\n@task()\ndef get_info():\n    \"\"\"\n    Simulates a task that fails once before succeeding.\n    Raises an exception on the first attempt, then returns \"OK\" on subsequent tries.\n    \"\"\"\n    global attempts\n    attempts += 1\n\n    if attempts < 2:\n        raise ValueError(\"Failure\")  # Simulate a failure on the first attempt\n    return \"OK\"\n\n# Initialize an in-memory checkpointer for persistence\ncheckpointer = InMemorySaver()\n\n@task\ndef slow_task():\n    \"\"\"\n    Simulates a slow-running task by introducing a 1-second delay.\n    \"\"\"\n    time.sleep(1)\n    return \"Ran slow task.\"\n\n@entrypoint(checkpointer=checkpointer)\ndef main(inputs, writer: StreamWriter):\n    \"\"\"\n    Main workflow function that runs the slow_task and get_info tasks sequentially.\n\n    Parameters:\n    - inputs: Dictionary containing workflow input values.\n    - writer: StreamWriter for streaming custom data.\n\n    The workflow first executes `slow_task` and then attempts to execute `get_info`,\n    which will fail on the first invocation.\n    \"\"\"\n    slow_task_result = slow_task().result()  # Blocking call to slow_task\n    get_info().result()  # Exception will be raised here on the first attempt\n    return slow_task_result\n\n# Workflow execution configuration with a unique thread identifier\nconfig = {\n    \"configurable\": {\n        \"thread_id\": \"1\"  # Unique identifier to track workflow execution\n    }\n}\n\n# This invocation will take ~1 second due to the slow_task execution\ntry:\n    # First invocation will raise an exception due to the `get_info` task failing\n    main.invoke({'any_input': 'foobar'}, config=config)\nexcept ValueError:\n    pass  # Handle the failure gracefully\n\n\nmain.invoke(None, config=config)\n\n```\n\n--------------------------------\n\n### Async Workflow with AsyncPostgreSQL Checkpointer in LangGraph\n\nSource: https://docs.langchain.com/oss/python/langgraph/add-memory\n\nIllustrates an asynchronous implementation using `AsyncPostgresSaver` for LangGraph checkpointers. This example covers async model invocation, graph streaming, and state management, suitable for non-blocking production applications.\n\n```python\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.postgres.aio import AsyncPostgresSaver  # [!code highlight]\n\nmodel = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\nDB_URI = \"postgresql://postgres:postgres@localhost:5442/postgres?sslmode=disable\"\nasync with AsyncPostgresSaver.from_conn_string(DB_URI) as checkpointer:  # [!code highlight]\n    # await checkpointer.setup()\n\n    async def call_model(state: MessagesState):\n        response = await model.ainvoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(checkpointer=checkpointer)  # [!code highlight]\n\n    config = {\n        \"configurable\": {\n            \"thread_id\": \"1\"  # [!code highlight]\n        }\n    }\n\n    async for chunk in graph.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n        config,  # [!code highlight]\n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n\n    async for chunk in graph.astream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n        config,  # [!code highlight]\n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n```\n\n--------------------------------\n\n### LangGraph with Redis Checkpointer (Sync)\n\nSource: https://docs.langchain.com/oss/python/langgraph/add-memory\n\nThis snippet illustrates using Redis as a checkpointer for synchronous LangGraph operations. It includes the necessary installation command and demonstrates the setup and usage of the Redis checkpointer.\n\n```bash\npip install -U langgraph langgraph-checkpoint-redis\n```\n\n```python\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.redis import RedisSaver  # [!code highlight]\n\nmodel = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\nDB_URI = \"redis://localhost:6379\"\nwith RedisSaver.from_conn_string(DB_URI) as checkpointer:  # [!code highlight]\n    # checkpointer.setup()\n\n    def call_model(state: MessagesState):\n        response = model.invoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n    builder.add_node(call_model)\n    builder.add_edge(START, \"call_model\")\n\n    graph = builder.compile(checkpointer=checkpointer)  # [!code highlight]\n\n    config = {\n        \"configurable\": {\n            \"thread_id\": \"1\"  # [!code highlight]\n        }\n    }\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"hi! I'm bob\"}]},\n        config,  # [!code highlight]\n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n\n    for chunk in graph.stream(\n        {\"messages\": [{\"role\": \"user\", \"content\": \"what's my name?\"}]},\n        config,  # [!code highlight]\n        stream_mode=\"values\"\n    ):\n        chunk[\"messages\"][-1].pretty_print()\n```\n\n--------------------------------\n\n### Integrate MongoDB Checkpointer in LangGraph (Sync)\n\nSource: https://docs.langchain.com/oss/python/langgraph/add-memory\n\nShows how to configure and use the `MongoDBSaver` for LangGraph checkpointers with a MongoDB backend. This example covers the synchronous setup for persisting graph states in a MongoDB cluster.\n\n```python\nfrom langchain.chat_models import init_chat_model\nfrom langgraph.graph import StateGraph, MessagesState, START\nfrom langgraph.checkpoint.mongodb import MongoDBSaver  # [!code highlight]\n\nmodel = init_chat_model(model=\"claude-haiku-4-5-20251001\")\n\nDB_URI = \"localhost:27017\"\nwith MongoDBSaver.from_conn_string(DB_URI) as checkpointer:  # [!code highlight]\n\n    def call_model(state: MessagesState):\n        response = model.invoke(state[\"messages\"])\n        return {\"messages\": response}\n\n    builder = StateGraph(MessagesState)\n\n```", "metadata": {"tool": "query-docs", "source": "context7_query_docs"}}
