# 通用人工智慧

## 基本信息
- 词条ID: 1468546
- 来源: Wikipedia (zh)
- URL: https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7
- 获取时间: 2026-02-02 20:35:17

## 完整内容
通用人工智能（artificial general intelligence，AGI）是一种假想的智能体。一般认为，它能够学习并执行人或其他动物所能完成的任何智力任务；另一种定义则是，通用人工智能是在大多数具有经济价值的任务上超越人类能力的自主系统。创造通用人工智能是一些人工智能研究以及OpenAI、DeepMind和Anthropic等公司的首要目标。通用人工智能也是科幻小说和未来学中的常见主题。
通用人工智能的发展时间线仍然是研究人员和专家之间持续争论的话题，部分人认为可能在几年或几十年内实现，另一些人则坚称可能需要一个世纪或更长时间，还有少数人认为或许永远无法实现。此外，关于现代的深度学习系统（如GPT-4）是否是通用人工智能的一种早期但不完整的形式，也存在争议。
关于通用人工智能是否可能对人类构成威胁，存在着诸多争议。OpenAI将其视为一种生存风险，而也有观点认为通用人工智能的实现还相当遥远，尚不构成风险。


概述
強人工智慧（applied AI），是人工智慧研究的主要目標之一，同時也是科幻小說和未來學家所討論的主要議題。相對的，弱人工智慧（narrow AI，weak AI, artificial narrow intelligence, ANI）只處理特定的問題。弱人工智慧不需要具有人類完整的認知能力，甚至是完全不具有人類所擁有的感官認知能力，只要設計得看起來像有智慧就可以了；由於過去的智能程式多是弱人工智慧，發現其具有領域的侷限性，人們一度覺得強人工智慧是不可能的。而強人工智慧也指通用人工智能（artificial general intelligence，AGI），或具備執行一般智慧行為的能力。強人工智慧通常把人工智慧和意識、感性、知識和自覺等人類的特徵互相連結。
因而，這樣的具備意識的強人工智慧是否存在？目前，模擬出簡單的一個生物頭腦已經不是不可能的事，正如在化學技術累積發展下，現在許多研發藥品已經使用計算機模型來推演藥物效果，以減少受試動物的痛苦等。從前在使用電腦語言的時代，原先電腦被認為是不可能具備自我解決能力的，電腦只是看起來聰明，實質上還是按照設計好的規則行事，並不能應付突如其來的狀況，仍舊會犯下錯誤。
而近年來從電腦在摩爾定律與神經科學研究的協助下，透過在電腦上對生物神經元系統複雜的電位衝動模擬上取得了明顯的突破，使人工智慧越過發展中的坎——神經處理機制的發現，因為生物的獨特是在於刺激與反應下會強化其回饋作用，這類能夠透過試錯學習經驗並總結，以回應各種刺激的系統（例如玩多次網球遊戲便能從生疏至熟巧），還能從每種回饋中又觸發其他迴路來升級改進思考結構，做出更複雜的精細反應（例如在對話中選擇誠實、說謊、漠然之後考慮其不同行為的後果等），這樣的仿生領域已經得到長足的進步，使人腦與AI的區別逐漸變得模糊；但是，在機器是否存在有自主「思想」上的議題，將還會一直是人們爭辯的對象，特別是在智能理性與心理感性部分要如何區別、統合，更需要進一步引導其具有人性，來為人類提供最佳解，目前這些方法都還沒有探索出來。
一些能夠自動推理出最佳解的工具已經出現，如Google旗下的DeepMind在此領域進展最多，成功開發出能解決任意問題的通用思考機器，他們將其類人腦神經程式稱「人工通用智慧技術」，而「通用」一詞就代表這是一個可以透過自主「進化發展」的通用智慧。


标准

人们提出过很多人工智能的定义（例如能够通过图灵测试），但是没有一个定义能够得到所有人的认同；然而，人工智能的研究者们普遍同意，以下特质是一个智能所必须要拥有的：

自动推理，使用一些策略来解决问题，在不确定性的环境中作出决策；
知识表示，包括常识知识库；
自动规划；
自主学习、创新；
使用自然语言进行沟通；
以及，整合以上这些手段来达到同一个的目标；
还有一些重要的能力，包括机器知觉（例如计算机视觉），以及在智能行为的世界中行动的能力（例如机器人移动自身和其他物体的能力）。它可能包括探知与回避危险的能力。许多研究智能的交叉领域（例如认知科学、机器智能和决策）试图强调一些额外的特征，例如想象力（不依靠预设而建构精神影像与概念的能力）以及自主性。基于计算机的系统中的确已经存在许多这样的能力，例如计算创造性、自动推理、决策支持系统、机器人、进化计算、智能代理，然而并未达到人类的水平。


检验强人工智能的操作性手段
一个强人工智能需要通过什么样的测试标准，科学家们有很多不同的想法，他们之中包括阿兰·图灵、本·格策尔、尼尔斯·尼尔森，他们提出的测试包括：


图灵测试（图灵）

同人類交流的試驗。


咖啡测试
生活中空間、操作技能的測試。将一部机器带到任何一个普通的美国家庭中，让它在不經刻意設計的條件下，懂得泡好一杯咖啡。它需要主動在陌生空間中認識咖啡机、辨識咖啡和水、找到合適的杯子並放好，然后按正确的键和操作以冲泡咖啡。這需要仰賴機器人學、圖像辨識的演算。


机器人学生测试
透過機器學習，分析和回答單一問題的測試 。让一个机器去注册一所大学，参加和人类学生同样的考试，然后通过并获得学位。例如日本的東大AI或是IBM參加搶答節目的華生。


雇员测试
測試統籌、推斷、發想、規劃解決複雜問題的能力。让机器处在一个经济上重要的职位，需要它能够和同样职位的人类做得同样好或者更好。
这些测试检测了一系列必要的特质，包括推理和学习能力。


强人工智能需要解决的问题
人们将对于计算机来说最困难的问题，非正式地称为“人工智慧完備”（AI-complete）或者“人工智能困难”（AI-hard）的，以此说明解决了这些计算性问题就相当于解决了人工智能的核心问题——让计算机和人类或者强人工智能一样聪明。  将一个问题称为“人工智能完备的”，意味着它不能被一个简单的特定算法解决。
人们假定人工智能完备的问题包括计算机视觉、自然语言理解，以及处理真实世界中的意外情况。目前为止，人工智能完备的问题仍然不能单靠现代计算机技术解决，而是需要人类计算。这一点在某些方面很有用，例如通过验证码来判别人类和机器，以及在计算机安全方面用于阻止暴力破解法。


人工智能研究的主流


强人工智能研究的主流历史

现代人工智能研究开始于1950年代中期，最早的一批人工智能研究者相信强人工智能不仅是可能的，而且将在几十年内出现。人工智能先驱司马贺在1965年写道：“在20年之内，机器就能够做到一个人能做到的任何事。” 启发这一预言的是斯坦利·库布里克和亚瑟·查理斯·克拉克创作的角色，HAL 9000；当时的人工智能研究者确信，能够在2001年制造出这样的机器。值得一提的是，人工智能先驱马文·闵斯基在创作HAL 9000的工作中，担任了尽量将其制作得与当时主流研究界预言一致的项目顾问；根据Crevier所引用他在1967年所说的话：“在一代人之内...制造‘人工智能’的问题就将被基本解决” 。
然而到了1970年代初，研究者们意识到他们远远低估了其中的困难，资助AI项目的机构开始对强人工智能产生怀疑，向研究者们施压要求他们转向更有用的技术，所谓的“应用AI”。在1980年代初，日本的第五代电脑开始重新对强人工智能恢复兴趣，制定的十年计划中包括一些强人工智能的目标，比如“进行日常对话”；同时，专家系统的成功和它一起促成了工业界和政府的资金重新开始注入这个领域。
1980年代晚期，人工智能的市场发生剧烈崩塌，而第五代计算机的目标从未实现；再一次，人工智能研究者们对于强人工智能即将到来的预言在20年之内被证明超出了他们的能力。结果到了1990年代，人工智能研究者背上了无法实现自己承诺的名声，他们拒绝再作出任何预言，并且避免提到任何“人类水平”的人工智能，以免被贴上“白日梦”的标签。


今日的人工智能研究主流

在1990年代和21世纪初，主流的人工智能在商业成果和学术地位上已经达到了一个新高度，依靠的是专注于细分的专门问题的解决。他们可以提供许多方案和商业应用，例如人工神经网络、机器视觉以及数据挖掘。 这些“应用人工智能”今天已经在工业技术和研究中得到广泛和深入应用，在学术和产业方面都得到了许多资助。

大多数主流的人工智能研究者希望，能够通过将解决局部问题的方法组合起来实现强人工智能，例如将智能体架构、认知架构或者包容式架构整合起来。汉斯·莫拉维克在1988年写道： "我相信，有一天人工智能的自下而上的研究路线，会与传统的自上而下的路线半途相遇，从而获得真实世界中的能力，以及对于推理程序来说极其困难的常识知识库。这两种方向结合在一起的时刻，会成为了产生真正智能机器的所谓“金钉子”。" 然而，在人工智能研究者之间也存在一些争论，甚至涉及这个领域的哲学基础；例如，普林斯顿大学的S.Harnad在1990年关于符号基础假设的论文中这样写道： "人们期待，模型认知的“自上而下的”（符号的）研究会在某个点上遇到“自下而上”（感觉的）研究。但是如果这篇文章有关落地的考虑是正确的，那么这个希望不会实现，只有一个可行从感觉到符号的路线，就是自下而上。一个独立的符号层面，就像计算机的软件层面，从不需要这样的路径来到达（反之亦然）——也不清楚我们为何要努力达到这样的层面，因为这个过程反而将我们的符号从固有的意义中连根拔起（于是仅仅是将我们化简为与可编程计算机功能上等价的东西）。"


现代通用人工智能研究
“通用人工智能”这一术语于1997年被马克·古布鲁德在一次关于全自动军事生产于操作的研讨会中使用。大约在2002年，该术语被沙恩莱格和本·格策尔重新提及和推广。那些研究目标非常古老，例如如道格拉斯·莱纳特的 CYC 项目（始于1984年），以及艾伦·纽厄尔的 Soar 项目也被认为属于通用人工智能的范畴。
王培和本·格策尔将2006年的通用人工智能研究活动描述为“创作出版物和早期的结果”。第一次通用人工智能暑期学校于2009年，在中国厦门，厦门大学的人工大脑实验室和OpenCog所举办。在2010和2011年，保加利亚的普罗夫迪夫大学，托多尔·阿纳多夫开设了相关课程。
MIT在2018年开设了通用人工智能的课程，由莱克斯·弗里德曼组织，以众多客座讲师为特色。但是，在当下，伴随着“智能”过于复杂以至于无法在短期内被完全复制的警告，大多数AI研究者仅在通用人工智能投入少量精力。不过，仍然有一小批计算机科学家活跃在通用人工智能研究以及会议中，他们的研究形形色色并富有开拓性。格策尔在他的书中介绍到，实现真正灵活的通用人工智能所需要的时间从10年到一个世纪不等，但是，看起来通用人工智能社区中的共识是，雷蒙德·库茨魏尔在奇点迫近中讨论的时间表是可信的。


理论

“强人工智能”引发起一连串哲学争论，例如如果一台机器能完全理解语言并回答问题的机器是不是有思维。哲学家约翰·瑟尔认为不可能。
关于强人工智能的争论，不同于更广义的一元论和二元论的争论。其争论要点是：如果一台机器的唯一工作原理就是转换编码数据，那么这台机器是不是有思维的？瑟尔认为这是不可能的。他举了著名的中文房间的例子来说明，如果机器仅仅是转换数据，而数据本身是对某些事情的一种编码表现，那么在不理解这一编码和这实际事情之间的对应关系的前提下，机器不可能对其处理的数据有任何理解。基于这一论点，瑟尔认为即使有机器通过了图灵测试，也不一定说明机器就真的像人一样有思维和意识。
也有哲学家持不同的观点。丹尼爾·丹尼特（Daniel C. Dennett）在其著作《意识的阐释》（Consciousness Explained）里认为，人也不过是一台有灵魂的机器而已，为什么我们认为：“人可以有智能，而普通机器就不能”呢？他认为像上述的数据转换机器是有可能有思维和意识的。


參見


參考資料

---
*数据来源: Wikipedia | 获取时间: 2026-02-02 20:35:17*