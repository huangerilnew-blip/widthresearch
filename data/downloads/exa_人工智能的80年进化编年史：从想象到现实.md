# 人工智能的80年进化编年史：从想象到现实

**URL**:
https://view.inews.qq.com/a/20230301A08BTW00

## 元数据
- 发布日期: 2023-03-01T00:00:00+00:00

## 完整内容
---
人工智能的80年进化编年史：从想象到现实\_腾讯新闻
# 人工智能的80年进化编年史：从想象到现实
![头像]![] 
[
Web3天空之城
] 
2023-03-01 20:44发布于浙江科技领域创作者
AGI是Artificial General Intelligence的缩写，即通用人工智能。
AGI的目标是实现人类般的通用智能，这意味着AI可以像人类一样理解任意通用任务, 并以人类的智力水平执行完成。基本上, 除了&quot;自我意识&quot;的生成，AGI就是人类对人工智能的终极梦想了。
无论是近一年来火爆的AI绘画，还是当红炸子鸡ChatGPT，AI研究应用的终极目标, 都是向着AGI通用人工智能的大一统目标在迈进。
读者是否有同感, 这几年各种AI大模型的发展和突破, 着实有让人眼花缭乱之感?
本文主要把现代到当下一些AI的重要节点做了时间线梳理和简单分析，或有助于大家来理清楚这些年AI发展的关键脉络。
1942年
时间回到80年前, 科幻泰斗阿西莫夫提出了著名的&quot;机器人三定律”：
机器人不得伤害人类，或坐视人类受到伤害；除非违背第一定律，否则机器人必须服从人类命令；除非违背第一或第二定律，否则机器人必须保护自己。这三个定律是人工智能和机器人技术的哲学基础，是对如何设计人工智能系统的基本原则的阐述，至今都有着重要的参考意义。1950年
计算机科学之父艾伦·图灵（Alan Turing）发表了具有里程碑意义的论文《Computing Machinery and Intelligence（计算机器与智能）》。论文预言了创造出具有真正智能的机器的可能性，第一次提出图灵测试（The Turing test）的概念：
如果一台机器能够与人类展开对话（通过电传设备）而不能被辨别出其机器身份，那么称这台机器具有智能。1956年
AI概念诞生。
美国的达特茅斯学院举行了一次具有传奇色彩的学术会议（Dartmouth Conference）， 探讨用机器模拟人类智能的问题。计算机专家约翰·麦卡锡提出了AI&quot;人工智能”一词。这被广泛认为是人工智能正式诞生的日子。参与会议的学者们是最早的AI研究先驱。
从1956年到现代，这几十年来AI研究的起伏，有兴趣的读者可以参考本号另一篇文章从爆火的chatGPT讲起: 自然语言生成式AI的前世今生, 你想了解的一切&gt;
当今大众关于AI的记忆，或许是从1997年开始的：
1997年
5月11日, IBM公司的电脑&quot;深蓝”战胜了国际象棋世界冠军卡斯帕罗夫，成为首个击败国际象棋世界冠军的AI系统。
1998年
现代卷积神经网络CNN诞生。
1980年，日本学者福岛邦彦（Kunihiko Fukushima）模仿生物的视觉皮层（visual cortex），设计了人工神经网络&quot;neocognitron”，这是现代卷积神经网络的雏形。
经过多年前赴后继的研究，1998年杨立昆（Yann LeCun，现任Meta首席人工智能科学家）基于前人基础，构建了更加完备的卷积神经网络LeNet-5，在手写数字的识别问题中取得了成功。LeNet-5被认为是现代卷积神经网络的基本结构。
卷积神经网络CNN是当今&quot;深度学习&quot;AI模型的计算基础架构。一直到2017年Transformer架构横空出世后，CNN才被取代。
2003年
Yoshua Bengio在2003年发表了《A Neural Probabilistic Language Model》，这是第一篇基于人工神经网络打造自然语言模型的论文，提出了具有奠基意义的NNLM&quot;神经网络语言模型&quot;。它在得到语言模型的同时也产生了副产品&quot;词向量&quot;。
2006年
杰弗里·辛顿（Geoffrey Hinton）在science期刊上发表了重要的论文《Reducing the dimensionality of data with neural networks》，提出深度信念网络（Deep Belief Networks，DBNs），&quot;深度学习&quot;正式诞生。
2009年
李飞飞主导的Image Net正式发布，有超过1000万数据，两万多个类别。为全世界的AI学者提供了开放的标注图像大数据集。
2010年开始，Image Net大规模视觉识别挑战赛（ILSVCR）开始举办，全世界图像领域深度学习的专家们同台竞技和交流，从此拉开了计算机视觉的新篇章。
2012年
Google的吴恩达和Jef Dean使用1.6万个CPU（那时的GPU生态还在婴幼儿阶段）训练了一个当时世界上最大的人工神经网络，用来教AI绘制猫脸图片。训练数据是来自youtube的1000万个猫脸图片，1.6万个CPU整整训练了3天。
对于计算机AI领域，这是一次具有突破性意义的尝试。AI第一次&quot;生成&quot;了一个图像内容：一张模糊的猫脸
![图片] 
2013年
Google的托马斯·米科洛夫（Tomas Mikolov）带领研究团队发表了论文《Efficient Estimation of Word Representations inVector Space》，提出了Word2Vec。
Word2Vec可以根据给定的语料库，通过优化后的训练模型可以快速有效地将一个词语表达成高维空间里的词向量形式，为自然语言处理领域的应用研究提供了新的工具。
2014年1月
谷歌斥资400亿美元收购了位于伦敦的明星人工智能企业DeepMind。
2014年12月
GAN（对抗式生成网络）诞生。
2014 年，Lan Goodfellow从博弈论中的&quot;二人零和博弈&quot;得到启发 ，创造性的提出了生成对抗网络（GAN，Generative Adversarial Networks），他在2014年的NIPS会议上首次发表了相关论文，用两个神经网络即生成器（Generator）和判别器（Discriminator）进行对抗。在两个神经网络的对抗和自我迭代中，GAN会逐渐演化出强大的能力。
作者在最早的文章里形象的把GAN比喻为伪造者和警察：伪造者总想造出以假乱真的钞票，而警察则努力用更先进的技术去鉴别真伪。在博弈过程中，双方都不断提升了自己的技术水平。
GAN号称21世纪最强大的算法模型之一，&quot;Gan之父&quot;Ian Goodfellow也一跃成为AI领域的顶级专家。
2015年12月
OpenAI公司于美国旧金山成立。
OpenAI诞生的原因是很有趣的：DeepMind被Google收购的消息震动了硅谷，如果发展下去，DeepMind很有可能成为最早实现AGI通用人工智能的公司。为了打破GoogleAI技术的垄断，在一次私人聚会后，大佬们一拍即合成立了OpenAI。
其中包括，钢铁侠Elon Musk，当时已是著名创业孵化器 Y Combinator 的负责人现在成为OpenAI CEO的Sam Altman，以及著名天使投资人 Peter Thiel等硅谷大佬。
OpenAI作为一个非营利性组织运营，并立志要做DeepMind和Google无法做到的事情：开放和共享AI技术。
从今天的眼光看，尽管OpenAI后来的商业模式有所变化，但绝对实现了它诞生的最大愿景之一：狙击Google和DeepMind。
ChatGPT的推出加上微软Bing的推波助澜搞得Google实在是狼狈不堪。
2015年
11月， Google开源了重要的深度学习框架Tensor Flow；
同年，还是Google，开源了用来分类和整理图像的 AI 程序Inceptionism，并命名为 DeepDream。尽管还很初级，但DeepDream被认为是第一个现代的AI绘画应用。
2016年
3月，Google的AlphaGo战胜围棋世界冠军李世石;
4月，Google深度学习框架TensorFlow发布分布式版本;
9月，Google上线基于深度学习的机器翻译;
2015到2016年，Google的AI能力可谓是风头一时无两。
2017年1月
Facebook人工智能研究院（FAIR）开源了PyTorch。PyTorch和tensorFlow从此成为了当今两大主流深度学习框架。
2017年7月
Facebook联合罗格斯大学和查尔斯顿学院艺术史系三方合作得到新AI绘画模型，号称创造性对抗网络（CAN，Creative Adversarial Networks），
CAN在测试中，有53%的观众认为AI作品出自人类之手，这是类似的图灵测试历史上首次突破半数，这是AI绘画模型小小而扎实的一步。
Facebook在AI领域其实耕耘了很久，做过很多贡献，可惜后面搞Metaverse连公司名字都改成Meta了， 差点错过了当下这波AI的浪潮。
不过最近小札醒悟过来，终于官宣要All in AI。Meta还是很有实力的，奋起直追应为时未晚。
2017年12月
颠覆性的Tranformer架构出世了!
Googl机器翻译团队在年底的顶级会议NIPS上发表了里程碑式的论文《Attention is all you need》，提出只使用自注意力（Self Attention）机制来训练自然语言模型，并给这种架构起了个霸气的名字：Transformer。
所谓&quot;自我注意力&quot;机制，简单说就是只关心输入信息之间的关系，而不再关注输入和对应输出的关系。和之前大模型训练需要匹配的输入输出标注数据相比，这是一个革命性的变化。
Transformer彻底抛弃了传统的CNN和RNN等神经网络结构。在这篇论文发布之前，主流AI模型都基于CNN卷积神经网络和RNN循环神经网络（recurrent neural network）; 而之后，便是Transformer一统天下。
Transformer架构的详细描述不在本文范围，读者只需要知道它具有两点无敌的优势：
自我注意力机制，让模型训练只需使用未经标注的原始数据，而无需再进行昂贵的的人工标注（标注输入和对应输出）。并行效率是之前的AI模型结构被一直诟病的地方。抛弃了传统CNN/RNN架构后，基于Transformer架构的大模型训练可以实现高度并行化，这大大提高了模型训练的效率;
从此，大模型大数据大算力，大力出奇迹，成为了AI领域的标配。
感慨一下，Google首先发明了划时代的Transformer架构，但在5年后的今天，却被OpenAI打得喘不过气。这是命运的偶然吗？
2018年6月
OpenAI发布了第一版的GPT（Generative Pre-training Transformers）系列模型 GPT-1。
同时，OpenAI发表了论文《Improving Language Understanding by Generative Pre-training》
从论文里可以了解到，GPT-1具有1.17个参数，采用了12层的Transformer 解码器结构，使用5GB的无标注文本数据，在8个GPU上训练了一个月，然后再进行人工监督的微调。
不过，GPT-1并不是当年的明星，因为同年，Google的BERT大模型也发布了（当时的Google就是强啊）。
2018年10月
谷歌发布3亿参数的BERT（Bidirectional Encoder Representation from Transformers），意思即&quot;来自Transformers的双向编码表示”模型。
GPT和BERT的诞生意味着预训练大模型（Pre-trained Models）成为了自然语言处理领域的主流。
和GPT相比，BERT最大的区别就是使用文本的上下文来训练模型，而专注于&quot;文本生成&quot;的GPT-1，使用的是上文。
基于&quot;双向编码&quot;的能力让BERT的性能在当时明显优异于第一代的GPT-1。
幸好，Open AI 并没有那么容易放弃，一直坚持只用上文训练的&quot;单向编码&quot;纯生成模式。直到GPT-3，神功初成。
2018年底
在共同创立公司三年后，钢铁侠马斯克辞去了Open AI董事会职务，原因是&quot;为了消除潜在的未来冲突&quot;。
实际情况是，2017年6月，马斯克挖走了OpenAI的核心人员Andrej Karpathy，担任Tesla的AI部门主管并直接向自己汇报，负责构建特斯拉的自动驾驶系统。
所以，确实是存在人才竞争&quot;潜在冲突&quot;的。
有趣的是，根据前不久的最新消息，ChatGPT大火之后，Andrej Karpathy同学又离开了Tesla回到了OpenAI。这是所谓&quot;鸟择良木而栖&quot;：）
而马斯克放出了声音，要打造OpenAI的竞争者。不知首富同学是否遗憾当年不得不放走了OpenAI。
2019年2月
OpenAI发布了GPT-2。
GPT-2有48层Transformer结构，使用40GB文本数据训练，参数量突破到了15亿。
在同时发布的论文《Language Models are Unsupervised Multitask Learners》 中，OpenAI描述了GPT2在经过大量无标注数据生成式训练后，展示出来的零样本（zero-shot）多任务能力。
所谓零样本学习就是用很大的通用语料去训练模型，然后不再需要做特定任务的训练，大模型就可以直接完成一些具体任务。一个典型例子是翻译。GPT-2具备了良好的语言翻译能力; 而有趣的是，专门做翻译的模型通常使用标注好的语料（即两个不同语言的匹配数据）来训练。但GPT-2并没有使用这类数据，翻译效果还超过了很多专职翻译的小模型。
GPT-2揭示了一个有趣的现象，仅作为生成式任务来训练打造的大模型，开始具备了多种通用任务能力，比如GPT-2所具备的阅读理解和翻译等等。
2019年3-7月
3月份，OpenAI正式宣布重组，成为一家&quot;利润上限（caped-profit）&quot;的公司，规定了投资收益的上限。这是一个很特别的架构。
而近期披露的OpenAI最新投资架构也再次揭示了这个公司股权结构的与众不同。简单的说，OpenAI把自己租借给了微软，赚到1500亿美金后，将重新变为非营利性组织 -- 至少说是这么说的。5月，Sam Altman辞去了 YC总裁的工作，开始担任新 OpenAI 的CEO。
7月，重组后的OpenAI拿到了微软包括Azure云计算资源在内的10亿美金投资， 微软将作为&quot;首选合作伙伴”，今后可获得OpenAI 技术成果的独家授权。自此，OpenAI后续技术成果不再承诺开源。
2020年5月
OpenAI发布了GPT-3。
GPT-3的初始版本在内部代号为&quot;davinci&quot;，使用45TB文本数据训练，有1750亿参数。根据公开信息，模型的训练费用是1200万美金。因为太贵，只训练了一次。
随后，OpenAI发表了近70页的论文《Language Models are Few-Shot Learner》。这篇论文阐述了大模型的各种新能力，而最重要的就是标题所指出的小样本（few-shot）学习能力。
&quot;few-shot&quot;是一个专业术语，理解起来也简单，就是通过少量的几个例子就能学习一个新的任务。人们发现，GPT-3开始具有类似人类的能力，只要在提示里展示特定任务的几个示例，GPT-3就能完成新示例的输出。而无需进行针对性的额外微调训练。这也被称之为&quot;上下文学习&quot;（in context learning）
2020年6月
对AI绘画有重要意义的论文 《Denoising Diffusion Probabilistic Models》发表， 引入了DDPM模型。 作为领域的奠基之作，这篇论文第一次把2015年诞生的Diffusion&quot;扩散模型&quot;用在了图像生成上。
用扩散模型生成图像的过程，简单理解，就是我们熟知的图片&quot;降噪&quot;：把一幅全部是噪点的随机图像通过AI算法反复&quot;降噪&quot;到最清晰，一个图像便生成了。
DDPM的出现把Diffusion扩散模型带到了一个新的高度。在不久之后，DDPM以及后续的Diffusion扩散模型就全面取代了GAN（生成式对抗网络），成为了AI绘画大模型当仁不让的主流技术。
2020年12月
由于不再认同转型后的公司文化和战略，OpenAI的部分核心团队出走。
12月31日，OpenAI发布新闻稿，宣布其研究副总裁Dario Amodei在OpenAI工作了近五年后离开了OpenAI。
OpenAI正是5年前成立的，这位研究副总看来是妥妥的创始核心。
Dario Amodei带着一些OpenAI的早期核心员工随后创办了Anthropic，推出了ChatGPT的直接竞品Claude。
被ChatGPT逼急了的Google最近刚给Anthropic紧急投资了3亿美金，以获得其10%的股份，并绑定了其云计算提供商的身份。
这里说个小知识，加州没有竞业协议，真的是创业者的天堂!
2021年1月
1月11日，Google发表论文《Switch Transformers：Scaling to Trillion Parameter Models with Simple and Efficient Sparsity》，提出了最新语言模型—Switch Transformer。
这个Switch Transformer 模型以高达1.6 万亿的参数量打破了GPT-3 作为最大AI 模型的统治地位，成为史上首个万亿级语言模型。然而，时间会证明一切。2年后的今天，这个万亿参数的Switch大模型在当下似乎没产生任何水花，而千亿参数级别的GPT-3.5系列依然风生水起。这是不是说明一个问题：突破千亿阈值后，参数多少并不代表一切。
2021年2月
Open AI开源了新的深度学习模型 CLIP（Contrastive Language-Image Pre-Training）。
CLIP是一个多模态模型，用来判断文字和图像两个不同&quot;模态&quot;信息的关联匹配程度。
在CLIP之前，也有人尝试过这个方向，但OpenAI最大的创意是直接使用全互联网上已经标记过的图像数据，巧妙的避免了海量数据标注的昂贵费用。最后以接近40亿的互联网&quot;文本-图像&quot;训练数据打造了CLIP。
这次重要的开源直接推动了各大AI绘画模型的迅猛发展。CLIP的多模态能力正是各AI绘画大模型从文字到画面想象力的核心基础。
同时，OpenAI还发布了自己基于CLIP的 AI绘画DALL-E 模型。这或许是大众听说的第一个&quot;文本生成图像&quot;的AI绘画模型了。
从CLIP到DALL-E，显然OpenAI走在了AI绘画大模型潮流的最前端。
只是，OpenAI在AI绘画模型的商业决策上出现了失误：因为没有开放使用DALL-E以及后续DALL-E2，而又开源了关键的CLIP模型，导致目前AI绘画模型的光芒完全被其开源继承者Stable Diffusion，还有付费的Midjourney服务掩盖了。
正是在AI绘画模型上有苦说不出的经历，直接影响了后来OpenAI管理层的决策：决定在第一时间面向公众抢先推出 ChatGPT聊天机器人。
2021年4月
华为的盘古NLP大模型发布，号称是中国第一个千亿参数语言大模型。
2021年6月
6 月30 日，OpenAI 和GitHub 联合发布了AI 代码补全工具GitHub Copilot，这个工具可以在 VS Code 编辑器中自动完成代码片段，也是OpenAI 拿了微软10 亿美元之后的第一个重大成果。而Copilot 的AI技术核心正是OpenAI的新模型CodeX。这个模型在随后的8月份也对外发布了。
根据相关论文《Evaluating Large Language Models Trained on Code》，OpenAI基于GPT-3，使用大量公开代码数据训练出了Codex模型。
Codex拥有120亿参数，使用了159G代码数据进行训练，模型可以将自然语言描述转换为代码。而效果吗，看看码农们对Copilot的赞不绝口就知道了。
AI生成代码的时代终于到来了。
据称，Codex的训练数据来自于公共数据源的数十亿行源代码，而其中最重要的来源，无疑正是微软所买下的GitHub 这个世界上最大的开源代码平台。使用GitHub代码训练模型这个事情还引起了一些程序员关于代码版权的热烈讨论。
不过，正如画师们对砸了自己饭碗的AI绘画大模型怨声载道而然并卵。。。能力突破的AI对人类初级技能的全面覆盖，恐怕是一个不得不接受的事实。
从商业角度上看，CodeX的诞生和Copilot的成功证明了OpenAI和微软的商业合作确实是一个双赢。
2021年10月
第一个开源的AI绘画大模型Disco-Diffusion诞生!
发布在Github上的Disco-Diffusion是整个2022年AI绘画旋风的起点。从Disco-Diffusion开始，AI绘画大模型突飞猛进的发展让所有人目不暇接，揭开了AI的新时代。
2021年12月
百度第三代文心语言大模型，2600亿参数的ERNIE3.0 Titan发布。
百度文心和华为盘古都是GPT-3量级的模型，关于国产大模型的具体判断，读者有兴趣可以参考本号国产ChatGPT们的真相&gt;一文
2022 年3 月OpenAI发布InstructGPT， 同时发表论文《Training language models to follow instructions with human feedback》。
根据论文，InstructGPT基于GPT-3模型做了进一步微调，并且在模型训练中加入了人类的反馈评价数据。
这里出现的RLHF &quot;从人类反馈中强化学习&quot;，正是后面ChatGPT所依赖的一个关键技术。
2022年4月
OpenAI发布了AI绘画大模型DALL-E 2。
同一时间，面向公众的付费AI绘画服务Midjourney也发布了。
和开局王炸，第一年就赚取了大把真金白银的MidJourney相比，使用受限的DALL-E 2并没有在大众人群里产生多少影响力。
如之前所说，OpenAI在绘画大模型的开放上过于保守了，也许还有优先和微软技术合作的考量在内...
总之，非常遗憾，绘画模型的风头完全被付费的Midjourney和随后的Stable diffusion抢走。
2022年5月
OpenAI发布代号为text-davinci-002的新版大模型，GPT系列正式迈入3.5时代。
有趣的是，按照OpenAI官方文档说法：
is a base model，so good for pure code-completion tasks
is an InstructGPT model based on
就是说，代号为code的002号模型是3.5系列的基础模型，而代号为text的002号模型是基于code 002模型用指令微调技术得到的 （insturctGPT）
如果，OpenAI没有在模型名字上混淆视听，一个有趣而合理的推断是：GPT-3.5系列的基础核心模型首先是依赖于代码（Code）大数据训练，而不是普通文本（Text）训练的
如果这个推断差不太多，那么众多ChatGPT的追随者们，如希望自家能力真正比肩基于GPT-3.5的ChatGPT， 那必须要补的一课，就是代码数据的训练了。2022年6月
6月15日，谷歌研究院联合DeepMind和斯坦福大学等在arxiv上发表了一篇论文：《Emergent Abilities of Large Language


---
*数据来源: Exa搜索 | 获取时间: 2026-02-02 20:35:42*