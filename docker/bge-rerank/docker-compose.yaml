version: "3.9"

services:
  tei:
    image: ghcr.io/huggingface/text-embeddings-inference:86-1.6
    container_name: bge-rerank

    ports:
      - "8100:8100"

    volumes:
      - /root/autodl_tmp/my_llms/bge_rerank_v2_m3:/data

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    command: >
      --model-id /data/
      --dtype float16
      --port 8100
      --payload-limit 10000000
      --max-batch-tokens 1000000
    restart: "no"
